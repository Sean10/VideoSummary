---
title: "How we Operate Ceph at Scale | Ceph Days NYC 2024"
date: 2024-06-18
updated: 2024-06-19
tags:
categories:
- "视频总结"
subtitle: tech
---


---
title: "How we Operate Ceph at Scale | Ceph Days NYC 2024"
date: 2024-06-18
updated: 2024-06-19
tags:
categories:
- "视频总结"
subtitle: tech
---


### 会议纪要

#### 会议主题：DigitalOcean 大规模运营 Ceph 的实践

#### 会议时间：[具体日期]

#### 会议地点：[具体地点]

#### 主讲人：Matt（DigitalOcean 存储系统团队，加拿大东部）

#### 会议内容总结：

1. **DigitalOcean 简介**
   - DigitalOcean 是一家成立于2012年的云服务提供商，以简单性为核心理念。
   - 最初提供5美元的SSD后端虚拟机（Droplet），后续产品线扩展至包括Spaces（Ceph支持的S3兼容对象存储）、DBaaS、App Platform、LBaaS等。
   - 拥有9个不同区域的数据中心，为客户提供多样化的资源部署选择。

2. **Ceph 在 DigitalOcean 的应用**
   - DigitalOcean 持续扩展Ceph的使用，主要用于块存储和对象存储，支持Volumes和Spaces等服务。
   - 统计数据：58个集群，其中47个生产集群运行Pacific版本，8个测试集群，超过200PB的原始存储，最大集群超过12PB，28,000个OSDs，1,600台服务器运行Ceph。

3. **自动化与配置管理**
   - 使用Chef进行核心操作系统配置管理，Ansible用于Ceph特定任务，如集群部署和节点扩充。
   - AWX作为开源的自托管解决方案，用于运行Ansible playbooks，确保团队共享故障模式、保密信息并记录运行历史。

4. **集群操作与维护**
   - 自动化工具支持新集群部署、节点扩充、节点预检、安全重启、配置管理和Ceph升级。
   - 集群扩容通过PG Remapper进行，优化了对象存储的恢复过程，减少了块存储的并发控制以适应工作负载的延迟敏感性。

5. **性能监控与优化**
   - 使用自研工具Marigraph进行集群延迟测量，优化了OSD启动和PG peering过程，减少了延迟敏感应用的影响。
   - 针对对象存储，优化了RGW与RocksDB的交互，通过设置OSD异步恢复最小成本和启用TTL压缩，显著提高了性能和稳定性。

6. **监控与告警**
   - 使用Ceph Exporter和Store Exporter收集集群和硬件状态数据，监控网络可达性和硬件健康状况。
   - Marigraph工具持续运行合成负载，提供关键的延迟和IO性能指标，帮助识别和解决性能问题。

7. **反思与未来展望**
   - 早期块存储和对象存储团队的分离导致集群管理和自动化配置的差异，增加了复杂性和维护难度。
   - 建议未来更多地整合自动化工具，减少配置分散，提升集群的一致性和可管理性。

#### 后续行动计划：
- 继续优化自动化工具，特别是Ansible playbooks，以提升集群操作的效率和一致性。
- 加强监控系统的集成和告警策略，确保及时发现并解决潜在的性能和稳定性问题。
- 探索更多自动化服务的可能性，减少手动操作，提升团队的整体工作效率。

#### 会议结束：
- 招聘插件和Q&A环节，讨论了团队扩张和技术细节问题。

#### 备注：
- 会议内容涉及大量技术细节和特定工具的使用，建议团队成员根据自身职责深入研究相关部分，确保技术实施的准确性和效率。