---
title: "Ceph Code Walkthroughs: RADOS Snapshots"
date: 2021-04-01
updated: 2021-04-01
tags:
categories:
- "视频总结"
subtitle: tech
---


### 会议纪要：Ceph Snapshot 技术详解

#### 会议概要
- **日期与时间**：2023年3月23日，17:00 UTC
- **主讲人**：Samuel Just
- **主题**：Ceph Snapshot 技术详解
- **参与人员**：Ceph 社区成员
- **会议形式**：在线视频会议

#### 讨论内容
1. **Snapshot 概述**
   - Ceph 支持三种项目：RGW, RBD, 和 ZFS，其中 RBD 和 CephFS 大量使用快照功能。
   - RBD 在块设备层面使用快照，而 CephFS 在子树层面使用。
   - 两者都使用 Librados 来管理 I/O，并共享相同的底层快照机制。

2. **快照的工作原理**
   - **创建快照**：客户端维护快照元数据，CephFS 通过 MDS 和能力系统进行排序，RBD 则在每个 RBD 块设备的头对象上维护快照信息。
   - **读取快照**：OSD 维护每个对象的快照状态映射，通过在写操作中附加快照信息来更新。
   - **回滚快照**：必须逐对象执行，RBD 快照回滚时间与对象数量成线性关系。
   - **删除快照**：空间回收是懒惰的后台操作。

3. **客户端与快照交互**
   - 客户端通过 RBD 或 CephFS 的快照机制与快照交互。
   - RBD 在创建快照时，会请求新的快照 ID，并更新头对象的元数据，然后通知所有用户重新加载快照元数据。

4. **快照的底层接口**
   - Librados 提供了四个基本操作：`snap create`, `snap set snap right context`, `snap remove`, 和 `snap rollback`。
   - 快照创建和删除主要由监视器操作，OSD 通过接收 OSD 地图更新来处理快照信息。

5. **快照的恢复与优化**
   - 恢复过程中，需要先恢复头对象，然后根据快照集信息恢复克隆对象。
   - 通过计算克隆子集，优化恢复过程中的数据共享，减少空间使用。

#### 决定事项
- 无具体决定事项，主要为技术分享和讨论。

#### 后续行动计划
- 会议录像将上传至 Ceph 的 YouTube 频道。
- 社区成员应关注即将到来的技术讲座和用户调查。

#### 其他备注
- 会议中提到的 RBD 镜像功能，如快照镜像和稀疏克隆，为虚拟化环境提供了高效的存储解决方案。
- 社区成员对快照功能的深入理解有助于更好地利用 Ceph 的存储能力。

#### 会议结束
- 感谢 Samuel Just 的详细讲解和社区成员的积极参与。
- 期待下一次的 Ceph 技术分享会议。

---

以上为本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。