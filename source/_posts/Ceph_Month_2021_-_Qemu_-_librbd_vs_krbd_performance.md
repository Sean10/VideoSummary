---
title: "Ceph Month 2021: Qemu: librbd vs krbd performance"
date: 2021-06-21
updated: 2021-06-22
tags:
categories:
- "视频总结"
subtitle: tech
---


### 会议纪要

#### 会议主题：
讨论和比较Ceph的两种主要客户端（librbd和krbd）的性能表现。

#### 会议目的：
为了解答客户关于librbd和krbd性能差异的疑问，特别是针对特定工作负载（Kimu workloads），会议旨在通过数据收集和比较，展示这两种客户端的性能特点。

#### 主要讨论内容：
1. **测试目标和方法**：
   - 定义了四个主要测试场景，包括使用librbd和krbd的虚拟机测试，以及在物理主机上使用librbd和krbd的测试。
   - 测试包括随机读写，块大小为4k、64k和4MB，使用不同的I/O引擎。
   - 每个场景进行了五次非连续运行，以确保结果的可比性。

2. **测试结果**：
   - 在虚拟机环境中，librbd和krbd的性能几乎相同，平均性能差异在100%左右。
   - 在物理主机上，krbd的性能显著优于librbd，特别是在高队列深度（q depth）和大块大小的情况下。
   - 发现librbd在特定设置下有一个约20,000 IOPS的性能上限。

3. **后续行动计划**：
   - 计划使用Pacific版本进行进一步测试，并重新比较结果。
   - 将公开fio配置，以便其他人可以在自己的系统上进行测试。

#### 决定事项：
- 确认了librbd在特定环境下的性能上限约为20,000 IOPS。
- 计划进行进一步的测试以验证和探索性能差异的原因。

#### 后续行动：
- 使用Pacific版本进行测试，并重新评估性能数据。
- 公开fio配置，促进社区的进一步测试和验证。

#### 会议总结：
会议成功地定义了测试场景和方法，收集并分析了librbd和krbd的性能数据，为解答客户疑问提供了科学依据。后续将继续进行深入测试和分析，以更好地理解性能差异的原因，并探索可能的优化方案。