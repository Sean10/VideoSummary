---
title: "Stretch Clusters in Ceph: Algorithms, Use Cases, and Improvements"
date: 2023-05-05
updated: 2023-05-05
tags:
categories:
- "视频总结"
subtitle: tech
---


### 会议纪要

#### 会议主题：Ceph中对扩展集群（Stretch Clusters）的明确支持

#### 会议时间：会议开始于整点后6分钟

#### 会议参与者：Greg（Ceph资深开发者，现为IBM工程经理）

#### 会议内容总结：

1. **Greg的背景介绍**：
   - Greg自大学毕业后加入Sage，多年来一直从事Ceph的开发工作。
   - 他曾作为技术负责人和独立贡献者参与了多个Ceph特性，如缓存分层和新的扩展模式。
   - 目前，Greg已从软件开发转型为工程管理，服务于Red Hat和IBM的Ceph团队。

2. **Ceph基本组件介绍**：
   - 主要涉及监控器（monitors）和对象存储守护进程（OSDs），这些是今天讨论的重点。

3. **扩展集群（Stretch Clusters）概述**：
   - 扩展集群是指服务器在地理上分散部署的集群。
   - 用户通常在两个或三个站点之间运行扩展集群，面临网络分裂和数据中心故障的高风险。

4. **面临的问题**：
   - 网络分裂可能导致监控器选举循环。
   - 两站点扩展集群中，如果一个站点的OSD下线，另一个站点无法提供服务，因为数据被认为过时。

5. **解决方案**：
   - 引入新的选举算法，监控器之间互相ping并维护连接分数，选择最可靠的监控器作为领导者。
   - 扩展对等和恢复机制，确保在数据中心故障时，集群仍能正常运行。

6. **具体实施**：
   - 监控器在每个站点部署两个，限制OSD只与同数据中心的监控器通信。
   - 扩展对等算法，要求在多个数据中心中至少有一个OSD处于活动状态。

7. **测试和挑战**：
   - 单元测试证明选举逻辑无问题，但未覆盖的部分如OSD对等和监控器ID映射存在问题。
   - 需要更多的自动化测试来确保系统的稳定性和可靠性。

8. **未来工作**：
   - 支持三站点扩展集群和更好的用户体验。
   - 考虑支持纠删码（Erasure Coding）和更复杂的Crush规则。

9. **用户操作**：
   - 用户需要设置监控器位置和自定义Crush规则，然后启用扩展模式。

#### 后续行动计划：
- 继续完善和扩展扩展集群的功能，特别是支持更多的数据中心和纠删码。
- 增强自动化测试，确保系统的稳定性和可靠性。
- 改进用户体验，简化配置和管理流程。

#### 会议结束：
- 会议在提问环节后结束，Greg感谢大家的参与并鼓励大家继续关注Ceph的发展。