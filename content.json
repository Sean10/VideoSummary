{"meta":{"title":"ceph视频总结","subtitle":"youtube频道总结","description":"youtube频道总结","author":"sean10","url":"https://sean10.github.io/VideoSummary","root":"/VideoSummary/"},"pages":[{"title":"categories","date":"2016-04-15T07:04:50.000Z","updated":"2023-03-18T15:11:14.928Z","comments":true,"path":"categories/index.html","permalink":"https://sean10.github.io/VideoSummary/categories/index.html","excerpt":"","text":""},{"title":"ceph会议视频总结","date":"2024-08-25T16:00:00.000Z","updated":"2024-08-26T14:04:29.857Z","comments":true,"path":"about/index.html","permalink":"https://sean10.github.io/VideoSummary/about/index.html","excerpt":"","text":"主要使用大模型对会议视频字幕进行总结"},{"title":"tags","date":"2016-04-15T06:15:46.000Z","updated":"2023-03-18T15:11:14.927Z","comments":false,"path":"tags/index.html","permalink":"https://sean10.github.io/VideoSummary/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ceph RGW Refactoring Meeting 2024-08-21","slug":"Ceph_RGW_Refactoring_Meeting_2024-08-21","date":"2024-09-03T16:00:00.000Z","updated":"2024-09-03T16:00:00.000Z","comments":true,"path":"2024/09/04/Ceph_RGW_Refactoring_Meeting_2024-08-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/09/04/Ceph_RGW_Refactoring_Meeting_2024-08-21/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： [请列出参会人员姓名] 会议主题： Ceph 分布式存储项目进展及议题讨论 一、议题一：Ceph 追踪功能进展 当前追踪功能： Squid 前端请求追踪 RGW 追踪 OSD 追踪 Jager 排序通过 SEF ADM 多部分上传追踪 端到端追踪 条件追踪（使用 Lua 脚本） 正在进行中的工作： 块和清理（Adam 负责） 存储桶索引追踪 未来工作计划： 扩展端到端追踪至所有操作 完成存储桶索引日志追踪 添加其他多站点追踪点 优化追踪命名规范 通过 Rook 添加编排 实现其他端到端追踪（如 RBD 和 SEFS） 考虑迁移至 OpenTelemetry 协议 非开发相关： 推广追踪功能，教育团队 创建代码演示和文档 制定追踪策略 二、议题二：用户账户迁移 当前迁移方案： 用户需要移除所有订阅和主题 系统管理员迁移用户至账户 用户重新创建主题并重新订阅 问题： 迁移过程中用户无法接收通知 需要大量人工操作 改进方案： 用户继续使用现有通知订阅 系统管理员将用户迁移至账户 用户创建新的主题 用户将桶重新订阅到新主题 当旧主题不再使用时，管理员可以使用命令删除旧主题 后续工作： 更新官方文档 编写测试用例 三、其他议题 [请列出其他议题及讨论内容] 四、行动计划 [请列出各议题的行动计划及负责人] 五、会议总结 本次会议讨论了 Ceph 分布式存储项目的最新进展，并对一些关键议题进行了深入讨论和决策。会议明确了下一步的工作计划和行动计划，为项目的顺利推进奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-09-04","slug":"Ceph_RGW_Refactoring_Meeting_2024-09-04","date":"2024-09-03T16:00:00.000Z","updated":"2024-09-04T16:00:00.000Z","comments":true,"path":"2024/09/04/Ceph_RGW_Refactoring_Meeting_2024-09-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/09/04/Ceph_RGW_Refactoring_Meeting_2024-09-04/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Gabby（演示者）、Matt、Kyle、Seth等 会议主题： ddop（数据去重优化项目）演示及讨论 会议内容： ddop项目概述： ddop项目旨在优化Ceph存储中的数据去重功能，提高存储效率和性能。 第一阶段将支持大于4MB的对象进行去重。 ddop基于ref计数和manifest共享机制，通过sharding（分片）的方式并行处理数据。 项目将分为两个阶段：第一阶段基于对象名进行sharding，第二阶段基于md5进行sharding。 ddop项目将采用多线程并行处理，以提高效率。 ddop项目演示： Gabby展示了ddop项目的演示过程，包括数据加载、去重操作、统计结果等。 演示过程中，ddop项目能够有效地减少冗余数据，并提高存储效率。 会议中讨论了ddop项目的可扩展性、性能优化等方面。 ddop项目讨论： 会议讨论了ddop项目的以下方面： 可扩展性： ddop项目通过sharding的方式，可以实现线性扩展，提高处理效率。 性能优化： ddop项目通过并行处理和数据本地化，提高了去重操作的效率。 适用场景： ddop项目适合于存储大量数据的场景，例如备份、归档等。 未来方向： 支持更小的对象去重。 支持子文件去重。 将ddop项目与object packing（对象打包）技术结合。 将ddop项目与erasure coding（冗余编码）技术结合。 行动计划： Gabby将整理ddop项目的代码，并提交PR（Pull Request）。 参会人员将对ddop项目的代码进行审查，并提出改进意见。 将ddop项目与Ceph存储系统集成，并进行测试。 关键术语： ddop（数据去重优化项目） sharding（分片） ref计数 manifest共享 md5 object packing（对象打包） erasure coding（冗余编码） 总结： ddop项目是一个非常有潜力的Ceph存储优化项目，能够有效地提高存储效率和性能。会议中，参会人员对ddop项目进行了详细的讨论，并提出了改进意见。期待ddop项目能够尽快落地，为Ceph存储带来更多价值。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-08-28","slug":"Ceph_RGW_Refactoring_Meeting_2024-08-28","date":"2024-09-03T16:00:00.000Z","updated":"2024-09-03T16:00:00.000Z","comments":true,"path":"2024/09/04/Ceph_RGW_Refactoring_Meeting_2024-08-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/09/04/Ceph_RGW_Refactoring_Meeting_2024-08-28/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： 分布式存储Ceph的Bucket日志功能讨论 会议内容： Bucket日志功能介绍： 介绍了一个基于AWS的Bucket日志功能，该功能允许将桶的操作（如读取、写入、设置策略等）记录到另一个桶中，形成日志。 指出AWS实现中的局限性，如日志数量、滚动策略、写入频率、数据丢失风险等。 Ceph中Bucket日志功能的实现： 介绍了Ceph中Bucket日志功能的实现，重点在于满足备份系统的需求，包括： 仅记录读写操作，不记录其他操作。 保证日志的持久性，避免数据丢失。 控制日志的写入频率，例如每小时写入一次。 优化日志记录格式，只记录必要信息。 讨论与反馈： 讨论了Ceph中Bucket日志功能的实现细节，包括： 控制哪些操作生成日志条目。 日志的写入时机和频率。 日志的持久性和可靠性。 日志的格式和内容。 需要进一步收集反馈，特别是针对非备份用例的具体场景。 行动计划： 将Bucket日志功能的实现代码合并到Ceph的主分支，以便收集更多反馈。 在邮件列表和用户论坛上发布相关信息，邀请更多用户参与讨论。 根据反馈进一步完善Bucket日志功能。 关键词： Bucket日志、AWS、备份、持久性、可靠性、API、操作、日志格式、邮件列表、用户论坛 后续行动： [请填写后续行动计划，例如：将代码合并到主分支、发布邮件列表、收集用户反馈等]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"All things in Moderation | Ceph Days London 2024","slug":"All_things_in_Moderation_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/All_things_in_Moderation_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/All_things_in_Moderation_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： Jack（Bloomberg存储工程团队） 会议主题： 在SEF对象存储上应用集群级服务质量（QoS）技术的经验分享 会议内容： 1. 背景 Bloomberg拥有大量SEF存储集群，分布在生产、开发、测试和遗留环境中。 由于集群处理请求和数据传输量巨大，需要实施QoS策略来优化性能和用户体验。 2. 自定义QoS解决方案 由于现有解决方案无法满足Bloomberg的需求，团队自行开发了软件定义的QoS堆栈。 该堆栈旨在实现以下目标： 为用户提供一致的性能体验。 维护集群性能标准。 为每个用户提供可配置的速率限制。 支持多种环境，包括多站点集群。 3. QoS架构 系统架构包括： 用户 SEF集群 Haproxy代理（定制版本） 自定义CIS日志服务器 Reddis实例（用于存储数据） 策略生成器 4. 遇到的问题及解决方案 传输限制执行： 原始系统为完全被动式，只有在用户超过限制后才会采取措施。 现已改进，通过向Haproxy代理发送超出限制的程度信息，调整暂停时间。 正在探索更主动的解决方案，例如根据实例使用情况调整限制。 并发传输： 用户通过增加机器或硬件来提高传输速度。 需要限制客户端打开的连接数量，以防止资源耗尽。 正在研究防止创建新连接的方法。 昂贵请求： 下载大量对象或列出大存储桶中的对象可能导致性能问题。 需要更深入地分析请求，例如根据服务时间或请求复杂性进行限制。 5. 未来计划 进一步改进传输限制执行和并发传输问题。 研究更智能的请求分析方法，以处理昂贵请求。 考虑开源自定义QoS解决方案。 6. 总结 自定义QoS解决方案在Bloomberg的SEF存储集群中取得了成功。 通过不断改进和优化，该解决方案有助于提高性能和用户体验。 后续行动计划： Jack将分享更多关于QoS架构和实施细节的信息。 团队将继续研究改进QoS解决方案的方法。 考虑开源自定义QoS解决方案。 备注： 会议中提到的关键计算机科学/CEPH领域英文原文关键词包括：SEF object storage, cluster wide quality of service, Haproxy, Reddis, rate limiting, connection limiting, expensive requests。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Afternoon Lightning Talks | Ceph Days London 2024","slug":"Afternoon_Lightning_Talks_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Afternoon_Lightning_Talks_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Afternoon_Lightning_Talks_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： Gabriel Miss Williams (Rosen Franklin Institute 研究软件工程师)，Lee Sanders (IBM)，Mike Burkart (Ceph 产品经理) 会议主题： 分布式存储Ceph相关技术探讨 会议内容： 一、Gabriel Miss Williams：分布式存储Ceph在HPC集群中的应用 背景： Rosen Franklin Institute拥有高性能计算集群，但存在网络连接限制、存储成本高、资源使用效率低等问题。 解决方案： 使用分布式临时RAM存储（DistTrack）技术，将Ceph集群部署在计算节点上，利用节点内存进行高效存储。 工作原理： DistTrack通过并行部署OSD，创建隔离的内存文件或对象存储，将IO瓶颈转移到节点间网络连接，提高性能并降低存储成本。 案例研究： 使用DistTrack技术处理生物样本结构分析应用，将处理时间缩短5.1%，IO开销降低100%。 结论： DistTrack是一种高效、可扩展的Ceph部署工具，可提高HPC应用性能并优化资源使用。 二、Lee Sanders：Ceph性能分析工具CBT CBT简介： CBT是一个开源的性能评估工具，用于测试Ceph集群性能。 CBT局限性： CBT输出结果有限，无法展示整体性能，需要手动处理大量数据。 CBT改进方向： 改进YAML格式以支持更复杂的测试配置，生成更多性能曲线，提高自动化程度，生成完整的性能报告。 CBT愿景： 建立一个社区通用的性能评估方法，使Ceph性能结果具有可比性。 三、Mike Burkart：Ceph与VMware集成 Ceph与VMware集成： IBM开发了Ceph与VMware的集成插件，使Ceph集群易于在VMware环境中部署和管理。 插件功能： 插件提供管理界面，支持部署、扩展和生命周期管理等功能。 未来计划： 支持数据路径支持、数据保护等功能。 四、讨论 DistTrack的适用场景： 适用于IO密集型应用，可提高性能并降低存储成本。 CBT的改进方向： 提高自动化程度，生成更多性能曲线，提高结果的可比性。 Ceph与VMware集成： 可简化Ceph集群在VMware环境中的部署和管理。 五、行动计划 继续改进DistTrack和CBT工具。 推动Ceph与VMware的集成。 建立社区通用的性能评估方法。 会议总结： 本次会议探讨了分布式存储Ceph在HPC集群中的应用、Ceph性能分析工具CBT以及Ceph与VMware集成等技术。参会人员分享了各自的经验和见解，并提出了改进和发展的建议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - RBD","slug":"CDS_Tentacle_-_RBD","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/23/CDS_Tentacle_-_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/CDS_Tentacle_-_RBD/","excerpt":"","text":"会议纪要 会议主题： RBD (RADOS Block Device) 开发者峰会会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： RBD 团队成员，Zia（负责一致性组快照镜像），Roma（负责快照调度器），niia 和 RAM（负责相关子任务） 会议内容： 一、一致性组快照镜像 主要议题： 实现基于快照的一致性组镜像功能。 关键细节： Zia 正在工作的主要 PR 目前处于工作进度中，代码功能基本就绪，但尚需对处理一致性组强制提升、参数描述、同步元数据对象等细节进行完善。 Ramana 正在开发一致性组快照调度器，Nya 协助进行代码审查和快照列表功能开发。 重点关注强制提升的测试覆盖范围，目前测试用例过于简单，需要增加更复杂的测试用例，并考虑多快照测试。 快照调度器将支持组级别快照调度，并应用于组内所有镜像，但不会支持不同镜像的不同调度策略。 将 PR 切分成多个部分，以降低风险并确保现有功能的稳定性。 二、RBD 镜像相关缺陷 主要议题： 解决 RBD 镜像功能中存在的缺陷。 关键细节： 解决克隆镜像中快照镜像功能的问题，确保克隆镜像可以正常进行快照镜像。 解决内置 LUKS 加密中数据损坏的问题，确保在快照镜像过程中数据一致性。 解决丢弃操作无法正确传播到二级集群的问题，确保二级镜像占用空间正确。 解决强制提升和源集群不可用问题，提高镜像功能的健壮性。 三、内置 LUKS 加密和实时迁移改进 主要议题： 改进内置 LUKS 加密功能和实时迁移功能。 关键细节： 解决从加密源读取数据时数据损坏的问题。 保留读取操作时的空间信息，确保加密镜像的碎片信息正确。 支持从其他子集群导入镜像，提高实时迁移的灵活性。 支持 NBD 格式实时迁移流，扩展实时迁移的适用场景。 解决从克隆镜像迁移时加密操作重复执行的问题。 四、其他改进 主要议题： 改进缺陷 API 和 libRADOS 库，使其支持非用户快照。 关键细节： 确保非用户快照（如一致性组快照、镜像快照、垃圾箱快照）在 RBD 命令行工具中可访问，并修复仪表板中的相关问题。 五、后续行动计划 RBD 团队将继续推进 RBD 镜像功能、内置 LUKS 加密功能和实时迁移功能的改进，并修复相关缺陷。 将 PR 切分成多个部分，并逐步合并到 RBD 中。 与社区合作，解决其他改进项。 六、会议总结 本次会议讨论了 RBD 镜像功能和实时迁移功能的改进计划，并明确了后续行动计划。RBD 团队将继续努力，提高 RBD 的功能和稳定性，为用户提供更好的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson Project Updates | Ceph Days London 2024","slug":"Crimson_Project_Updates_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Crimson_Project_Updates_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Crimson_Project_Updates_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Matan（Crimson项目负责人）、其他Crimson项目成员 会议主题： Crimson项目概述及最新进展 会议内容： 一、Crimson项目背景 随着存储技术的发展，从硬盘到NVMe，存储速度和吞吐量有了显著提升。 传统Ceph架构在处理高吞吐量存储设备时，存在CPU开销大的问题。 Crimson项目旨在优化Ceph架构，提高CPU效率，更好地利用新型存储设备。 二、Crimson项目核心思想 Crimson项目采用异步编程模型，避免线程切换带来的开销。 使用Sear框架实现异步编程，提高CPU效率。 采用单线程每核心架构，避免线程间的竞争和同步开销。 三、Crimson项目架构 Crimson项目是Ceph OSD的完全重写，采用Sear框架实现异步编程。 项目包括以下组件： OSD：负责IO处理，使用Sear框架进行异步编程。 对象存储：负责数据存储，支持BlueStore和CStore两种后端。 CStore：Crimson项目自研对象存储后端，使用Sear框架实现，支持NVMe等新型存储设备。 四、Crimson项目进展 最新版本已进入技术评审阶段，支持RBD工作负载在副本池中运行。 支持多核CPU，提高性能。 支持BlueStore和CStore两种对象存储后端。 支持快速部署，自动识别可用CPU资源。 支持垃圾回收和快照功能。 支持RBD快照复制功能。 支持数据恢复和备份功能。 测试覆盖率持续提升，包括OSD测试、垃圾回收测试和快照测试。 五、Crimson项目未来计划 扩大测试覆盖率，包括PG拆分/合并、RBD快照复制等功能。 优化性能，特别是CStore后端性能。 支持动态分片，提高资源利用率。 支持异构存储配置。 六、讨论 项目成员讨论了CStore后端性能优化、测试覆盖率提升等问题。 Matan强调了Crimson项目的技术预览性质，提醒用户谨慎使用。 七、行动计划 继续进行技术预览版本的开发和测试。 优化CStore后端性能。 扩大测试覆盖率。 完善文档和开发指南。 八、总结 Crimson项目是Ceph架构的重要改进，旨在提高CPU效率，更好地利用新型存储设备。项目进展顺利，未来将继续优化性能，扩大功能覆盖范围。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Making the Right Hardware Choices | Ceph Days London 2024","slug":"Making_the_Right_Hardware_Choices_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Making_the_Right_Hardware_Choices_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Making_the_Right_Hardware_Choices_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： Ceph 存储系统硬件选型与优化 会议内容： 一、Ceph 存储系统介绍 Ceph 存储系统概述，包括其架构、功能和优势。 Ceph 的硬件需求，包括 CPU、内存、存储和网络等方面。 二、硬件选择常见问题 客户在选择硬件时常见的问题，例如： 未考虑 NVMe 存储，导致性能问题。 数据副本数过少，导致数据丢失风险。 使用 SATA 驱动器，性能低下。 未考虑网络带宽，导致恢复时网络拥堵。 三、硬件选型建议 节点数量：建议至少 4 个节点，以保证数据冗余和故障域隔离。 存储类型：建议使用 NVMe 存储，以提高性能和可靠性。 网络带宽：建议使用 25G 或 100G 以上的网络，以满足性能需求。 驱动器类型：建议使用 SAS 或 SSD 驱动器，避免使用 SMR 驱动器。 CPU 和内存：建议根据实际负载进行配置，避免资源瓶颈。 四、具体配置建议 节点配置：建议使用 2U 机架式服务器，每个节点配备 2-4 个 NVMe 驱动器，以及足够的 CPU 和内存。 网络配置：建议使用 25G 或 100G 以上的网络，并配置足够的网络端口。 存储配置：建议使用 1:2 的 NVMe 与 SAS/SSD 存储比例，以满足性能和容量需求。 五、案例分析 某客户使用 90 节点、720 个 OSD 的集群，在 S3 上运行，性能良好。 某客户使用 50 个 PyTorch 集群，存储了数十亿个文件，并进行了 IO 500 测试，性能稳定。 六、后续行动计划 客户根据建议进行硬件升级或优化。 持续关注 Ceph 社区和上游项目的更新，及时了解新技术和最佳实践。 为客户提供技术支持和培训。 七、会议总结 本次会议重点讨论了 Ceph 存储系统的硬件选型和优化，为参会人员提供了宝贵的经验和建议。希望参会人员能够将所学知识应用到实际工作中，提高 Ceph 存储系统的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Morning Lightning Talks | Ceph Days London 2024","slug":"Morning_Lightning_Talks_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Morning_Lightning_Talks_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Morning_Lightning_Talks_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： Dave Holland（Sanger Institute系统管理员），Jose Palas Perez（IBM SE团队），Ceph社区成员 会议主题： Sanger Institute的Ceph存储使用经验分享，Crimson性能测试及优化 会议内容： 一、Sanger Institute的Ceph存储使用经验 Sanger Institute简介： Sanger Institute是英国人类基因组计划的贡献者，致力于基因组研究和测序。 Ceph存储应用： Sanger Institute使用Ceph存储进行数据存储，包括： OpenStack私有云存储 S3对象存储 数据传输 Ceph存储优势： Ceph存储具有高可靠性、可扩展性和性能优势，能够满足Sanger Institute的存储需求。 Ceph存储挑战： Sanger Institute在Ceph存储使用过程中遇到了一些挑战，例如： OSD崩溃 性能瓶颈 监控和可观测性不足 二、Ceph存储优化方案 解决OSD崩溃： Sanger Institute通过将垃圾回收池迁移到NVMe存储来解决了OSD崩溃的问题。 性能优化： Sanger Institute通过调整Ceph配置和优化工作负载来提高了Ceph存储性能。 监控和可观测性： Sanger Institute正在实施新的监控系统，以更好地监控Ceph存储性能。 三、Crimson性能测试及优化 Crimson介绍： Crimson是Ceph的新一代OSD，具有更高的性能和可扩展性。 Crimson性能测试： Jose Palas Perez对Crimson进行了性能测试，主要关注CPU利用率。 测试结果： 测试结果表明，Crimson能够充分利用CPU资源，并具有良好的性能。 Crimson优化： Sanger Institute计划进一步优化Crimson的性能，例如： 调整CPU核心分配 优化Ceph配置 四、会议总结 Sanger Institute的Ceph存储使用经验为Ceph社区提供了宝贵的参考。 Crimson性能测试结果表明，Crimson具有很高的性能潜力。 Ceph社区需要共同努力，优化Ceph存储性能和可观测性。 后续行动计划： Sanger Institute将继续优化Ceph存储性能和可观测性。 Ceph社区将共同推进Crimson的性能优化和功能完善。 Ceph社区将加强监控和可观测性工具的开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Next Generation Erasure Coding | Ceph Days London 2024","slug":"Next_Generation_Erasure_Coding_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Next_Generation_Erasure_Coding_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Next_Generation_Erasure_Coding_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： Bill（存储开发人员），Seth（其他参会人员） 会议主题： Ceph分布式存储中Erasure Coding优化方案讨论 会议内容： 背景介绍： 当前Ceph存储系统中，对象存储使用Erasure Coding，块存储和文件存储使用Replicated Pools。 Erasure Coding的优势在于降低存储成本，但性能不如Replicated Pools。 目标是提高Erasure Coding的性能，使其在块存储和文件存储中更具竞争力。 性能瓶颈分析： 网络带宽：网络连接限制性能。 IOPS：硬盘性能限制，尤其是使用HDD时。 延迟：读取和写入数据的延迟。 CPU：CPU资源限制。 优化方案： 读取优化： 部分读取：仅读取所需数据，减少网络带宽和CPU开销。 直接读取：客户端直接向存储数据的OSD发送读取请求，减少网络跳数和CPU开销。 写入优化： 简单覆盖优化：仅读取未修改的数据，合并新数据，计算新的校验码，并仅写入修改的数据和校验码。 Apparity Delta写入优化：读取旧数据和新数据，计算Delta，并应用于校验码，减少IOPS。 块大小优化： 增加块大小：提高IOPS，减少网络带宽和CPU开销。 根据对象大小动态调整块大小：针对不同大小的对象选择合适的块大小，提高效率。 行动计划： 完成部分读取优化，并发布到主分支。 研究并实现其他优化方案。 在T版本中提供Erasure Coding优化功能。 讨论要点： 部分读取和直接读取优化对客户端性能的影响。 Apparity Delta写入优化对延迟的影响。 块大小优化对小对象的影响。 优化方案的复杂性和实施难度。 结论： 通过优化Erasure Coding，可以提高其在块存储和文件存储中的性能，使其更具竞争力。会议确定了具体的优化方案和行动计划，并讨论了相关技术细节。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"State of the Cephalopod| Ceph Days London 2024","slug":"State_of_the_Cephalopod_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/State_of_the_Cephalopod_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/State_of_the_Cephalopod_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议主题： Ceph 项目状态更新 会议时间： 2023年（具体日期未提及） 参会人员： Niha Oja（IBM 高级开发经理，SEF 执行委员会成员），以及其他来自 Ceph 社区和企业的参与者。 会议内容： 一、开场与感谢 Niha Oja 对组织此次会议的各方表示感谢，包括 Tony Phil、Danny Orit、Gorov Suan，以及对 Ceph 社区和贡献者的认可。 二、Ceph 项目历史与现状 Ceph 项目始于加州大学圣克鲁兹大学的博士项目，至今已有17年历史。 目前，Ceph 拥有超过1300位贡献者，700,000多行代码，超过146,000次提交。 Ceph 社区在过去几年举办了多次会议，包括 Ceph Days Amsterdam、Ceph Day New York、Ceph Day Bangalore 和 Ceph Day London。 Ceph 的存储足迹不断增长，接近1.5艾字节（EB）。 最新版本为 Squid，其中包含了多个优化和改进。 三、技术重点与未来方向 性能与可扩展性： Ceph 将重点改进性能和可扩展性，以满足大规模存储需求。 易用性： Ceph 将继续改进易用性，包括增强管理界面和自动化工具。 协议支持： Ceph 将扩展对各种协议的支持，以适应更多用例。 效率： Ceph 将寻找提高存储效率的方法，以降低成本。 四、Squid 版本亮点 Rados： 支持低延迟和低CPU使用率的快照密集型工作负载。 Scrub： 优化了 manager 的调试功能。 Telemetry： 增加了新的指标和面板，以更好地跟踪性能和资源使用情况。 Dashboard： 增加了更多管理功能，以简化操作。 Cephadm： 增加了更多协议支持，并改进了第一天和第二天操作。 RBD： 改进了快照和镜像功能。 RGW： 增加了 S3 相关功能和性能改进。 CephFS： 进行了代码加固和性能优化。 五、行动计划 继续改进 Ceph 的性能、可扩展性、易用性和效率。 举办更多 Ceph 社区活动。 扩大 Ceph 的用户基础。 六、问答环节 参会者就 Ceph 的未来方向、Dashboard 功能和客户支持等问题进行了提问。 七、总结 Ceph 社区在过去几年取得了显著进展，并将继续致力于推动开源存储技术的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Sunbeam and Ceph Sitting in a Tree | Ceph Days London 2024","slug":"Sunbeam_and_Ceph_Sitting_in_a_Tree_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Sunbeam_and_Ceph_Sitting_in_a_Tree_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Sunbeam_and_Ceph_Sitting_in_a_Tree_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： James Paage（Canonical公司首席工程师）、Luciano、其他IBM员工 会议主题： Sunbeam项目介绍 会议内容： James Paage开场致辞： 对Bill的Ceph PODS展示表示祝贺。 介绍自己，作为Canonical公司首席工程师，负责OpenStack Ceph和OVN团队的技术架构师。 简述了自2010年加入Canonical以来在开源领域的参与经历，包括参与Eucalyptus和OpenStack项目。 介绍了Ensemble项目（后更名为Juju），用于部署和操作分布式系统。 介绍了Metal as a Service（MAS）和LXD项目，用于容器化OpenStack组件。 介绍了OpenStack charms项目，用于部署和配置OpenStack。 介绍了MicroStack项目，用于简化OpenStack部署。 介绍了Ceph Snap，用于简化Ceph部署。 Sunbeam项目介绍： Sunbeam项目是一个在Open Infrastructure Foundation技术委员会指导下孵化的项目，旨在实现任何规模（从个人电脑到多数据中心）的OpenStack部署。 Sunbeam项目采用混合部署方法，结合了Juju和Kubernetes组件。 Sunbeam项目使用Ceph Snap进行部署，并与Juju和Kubernetes平台集成。 Sunbeam项目提供了MicroStack实现，用于简化Ceph部署。 Sunbeam项目使用Juju charm进行Ceph集群管理。 Sunbeam项目支持Cinder和Nova组件。 Sunbeam项目支持Rados Gateway，并通过Kubernetes进行暴露。 Sunbeam项目优势： 快速、可重复的部署和操作。 基于图像的部署，减少版本差异。 提高安全性，通过Snap封装。 简化软件，提高可维护性。 提高易用性，降低知识门槛。 提高可观察性和透明度。 提供可选功能，如可观察性、验证工具等。 Sunbeam项目发布计划： 预计2023年底发布基于OpenStack Caracol和Ceph Squid的稳定版。 预计2024年第一季度实现与Charmed OpenStack功能对等。 未来将提供从Charmed OpenStack迁移到Sunbeam的路径。 后续行动计划： 继续开发Sunbeam项目，并发布稳定版。 完善迁移路径，支持从Charmed OpenStack迁移到Sunbeam。 推广Sunbeam项目，并获取用户反馈。 会议总结： Sunbeam项目是一个具有潜力的OpenStack部署解决方案，它简化了部署和操作过程，并提供了多种功能。随着项目的不断发展，Sunbeam有望成为OpenStack部署的首选工具。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Taming a Cephalopod Swarm | Ceph Days London 2024","slug":"Taming_a_Cephalopod_Swarm_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Taming_a_Cephalopod_Swarm_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Taming_a_Cephalopod_Swarm_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储系统 SEF（StorageOS）多集群监控功能更新及未来规划 会议时间： 2023年10月（具体日期未提及） 参会人员： 邀请了 Ceph 社区成员和 SEF 用户参与讨论。 会议内容： 一、多集群监控功能介绍 背景： 由于用户对集群规模的需求不断增长，导致多个 SEF 集群的管理成为现实需求。 现状： 通过 SEF 用户调查和社区反馈，确认了多集群管理已成为 Ceph 社区的实际情况。 原因： 用户选择多集群管理的主要原因是基础设施复杂性、降低操作风险和满足合规性要求。 多集群概念： 将不同集群分组，可能相关也可能不相关，其中联邦是相关集群的特定案例。 多集群功能目标： 提高操作友好性，降低认知负荷。 提供单一来源的集群状态信息。 基于事件的通知机制。 简化多集群和镜像配置。 提高安全性。 多集群功能实现： 新增多集群连接功能，支持连接多个集群。 显示集群状态、警报、连接和容量信息。 利用图表展示集群利用率。 支持跨集群操作，例如迁移和复制。 二、特定案例：RGW 多地域配置 RGW 多地域配置： 可在 Squid 版本中使用，提供类似多集群功能的配置界面。 配置步骤： 连接到不同地域，查看拓扑视图，进行数据迁移和配置。 三、未来规划 SFS 改进： 支持子卷、子卷组、快照和克隆等功能。 CS 镜像： 支持跨集群文件系统（CephFS）的镜像功能。 RGW 改进： 支持高级工作流、用户策略、桶策略、生命周期等功能。 服务器端安全： 支持基于角色的访问控制（RBAC）和令牌管理。 UI/UX 改进： 使用 Angular Material 作为 UI 框架，提升用户体验。 四、贡献方式 开发者会议： 参加每月的开发者会议，分享应用和想法。 用户会议： 参加每月的用户会议，与 SEF 团队直接互动。 Slack 社区： 加入 SEF Slack 社区，获取帮助和支持。 GitHub 仓库： 贡献代码，参与 SEF 开发。 五、讨论 多集群监控功能的用户体验： 提出改进建议，例如更清晰的界面和更友好的操作方式。 RGW 多地域配置的改进： 讨论如何简化配置过程，提高易用性。 SFS 和 CS 镜像功能的实现： 讨论功能细节和实现方案。 UI/UX 改进的优先级： 确定改进重点和优先级。 行动计划： 收集用户反馈，改进多集群监控功能。 完善RGW多地域配置的文档和示例。 制定SFS和CS镜像功能的开发计划。 推进UI/UX改进工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Unlocking Ceph's Potential with NVMe oF Integration | Ceph Days London 2024","slug":"Unlocking_Ceph_s_Potential_with_NVMe_oF_Integration_Ceph_Days_London_2024","date":"2024-08-22T16:00:00.000Z","updated":"2024-08-23T16:00:00.000Z","comments":true,"path":"2024/08/23/Unlocking_Ceph_s_Potential_with_NVMe_oF_Integration_Ceph_Days_London_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/23/Unlocking_Ceph_s_Potential_with_NVMe_oF_Integration_Ceph_Days_London_2024/","excerpt":"","text":"会议纪要 会议主题： NVMe over Fabrics (NVMe-oF) 项目的进展与讨论 参会人员： NVMe-oF 项目成员、Ceph 研发人员等 会议内容： 一、NVMe-oF 介绍 NVMe-oF 是一种基于网络协议的存储访问方式，允许用户通过网络访问本地 NVMe 设备。 NVMe-oF 具有高性能、低延迟和可扩展性等优点，适用于数据中心存储场景。 二、NVMe-oF 项目的进展 NVMe-oF 项目已经取得了显著进展，包括： 支持多种网络协议，如 TCP、iSCSI、RoCE 等。 支持多种 NVMe 设备，如 NVMe SSD、NVMe-oF Target 等。 支持多种访问控制方式，如 ACL、RBAC 等。 三、NVMe-oF 的优势 相比于传统的 NVMe，NVMe-oF 具有以下优势： 更高的性能：通过网络传输，可以充分利用高速网络带宽，提高访问速度。 更低的延迟：网络传输延迟更低，可以提高数据处理的效率。 更好的可扩展性：可以通过增加网络带宽和 NVMe 设备，实现更高的存储容量和性能。 四、NVMe-oF 的应用场景 NVMe-oF 适用于以下场景： 数据中心存储：提高存储性能和可扩展性。 分布式存储：实现跨地域存储访问。 云计算：提供高性能、可扩展的存储服务。 五、后续行动计划 将 NVMe-oF CLI 集成到 Ceph 的主 CLI 中。 支持 NVMe-oF In-Band 消息通知。 支持子系统级别的访问控制。 支持名称空间屏蔽功能。 支持更广泛的网络协议和设备。 提高性能和可扩展性。 六、讨论要点 NVMe-oF 的网络协议支持： 讨论了 NVMe-oF 支持的网络协议，并分析了不同协议的优缺点。 NVMe-oF 的设备支持： 讨论了 NVMe-oF 支持的 NVMe 设备，并分析了不同设备的性能特点。 NVMe-oF 的访问控制： 讨论了 NVMe-oF 的访问控制方式，并分析了不同控制方式的适用场景。 NVMe-oF 的性能优化： 讨论了 NVMe-oF 的性能优化方法，并分析了不同方法的适用场景。 七、会议总结 NVMe-oF 项目取得了显著进展，具有广阔的应用前景。未来将继续优化 NVMe-oF 的性能和可扩展性，并支持更广泛的网络协议和设备，为用户提供更好的存储服务。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tenctacle - BlueStore","slug":"CDS_Tenctacle_-_BlueStore","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tenctacle_-_BlueStore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tenctacle_-_BlueStore/","excerpt":"","text":"会议纪要 会议主题： Blue Store (Tentacle) 项目进展及未来计划 会议时间： 2023年11月（具体日期未提及） 参会人员： Adam, Mat Vander Millan (Digital Ocean), Gary, Igor, Sam 等 会议内容： 一、项目进展 性能退化问题： 开发了抓取工具，用于捕获OSD操作日志，分析性能退化原因。 通过抓取工具获取了80百万操作日志样本，发现实际工作负载与测试环境存在显著差异。 正在开发重放工具，用于模拟实际工作负载，进一步分析性能退化原因。 RBD碎片化检查： 分析了Digital Ocean提供的RBD工作负载，发现存在未预期的碎片化模式。 正在进行RBD碎片化检查的研究，计划在Sealon会议上分享相关结果。 碎片化可视化： 计划开发碎片化可视化工具，以更直观地展示碎片化情况及其对性能的影响。 Blue Store性能优化： 优化了KVS线程，减少写操作延迟。 研究利用RoDB的管道功能，提高键值排序效率。 计划进行自定义RZB日志修改，实现并行写入和排序。 压缩改进： 开发了新的压缩算法，允许用户选择压缩程度和CPU资源消耗。 正在进行RBD工作负载测试，评估压缩算法的实际效果。 对象修改： Gary提出了在读取操作期间修改对象的方案，用于在线进行碎片化或压缩。 分配器优化： Igor开发了一种新的分配器，提高了内存组织和队列性能。 计划进一步研究分配器性能，并针对RBD OSD进行优化。 Blue Store与BlueFS的协同工作： 计划进行实验，研究在单设备上同时使用Blue Store和BlueFS的可行性。 元数据清理： 计划开发元数据清理工具，以简化Blue Store使用。 二、未来计划 性能测试： 对新的分配器进行性能测试，并评估其适用性。 收集分配器在长期运行环境中的性能数据。 性能计数器： 添加性能计数器，以跟踪关键性能指标。 开发性能分析工具，帮助用户识别性能瓶颈。 稀疏读取： 与Seagate团队合作，实现稀疏读取功能。 其他： 优化Blue Store性能。 支持更多存储类型。 三、行动计划 继续进行性能退化分析和优化。 完成RBD碎片化检查和可视化工具开发。 优化Blue Store性能，包括KVS线程、分配器、压缩等。 开发元数据清理工具。 与Seagate团队合作，实现稀疏读取功能。 四、其他 讨论了关于分配器的选择和测试问题。 讨论了关于性能计数器和性能分析工具的开发问题。 五、会议总结 本次会议详细讨论了Blue Store项目的进展和未来计划，明确了下一步的工作重点和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - Cephadm","slug":"CDS_Tentacle_-_Cephadm","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_Cephadm/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_Cephadm/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 会议地点： 线上会议 参会人员： 项目团队成员 会议主题： 讨论Ceph项目T版本的关键功能改进和开发计划 会议内容： 一、已进行中的工作 标签IDE折扣： 允许为服务分配多个标签，实现更灵活的资源分配和故障域管理。 OSD替换改进： 无替换标记： 允许标记即将替换的磁盘，避免其被误选为OSD。 一次性规格： 提供一次性OSD部署机制，方便用户进行手动部署。 容器镜像管理： 列出默认镜像： 列出默认的Ceph容器镜像，方便用户了解和使用。 生成Cephadm规格： 根据用户配置生成Cephadm规格文件，方便用户进行集群部署。 支持断开连接安装： 支持用户在本地仓库中部署容器镜像，无需连接互联网。 多架构镜像： 解决不同架构主机在升级过程中使用不同镜像的问题。 Cephadm兼容性测试： 测试Cephadm在基于oci容器镜像的操作系统上的兼容性。 Ceph Dashboard安全改进： 管理网关： 引入管理网关，提供单点登录和反向代理功能，提高安全性。 联合MLS： 实现组件间通信的联合MLS，提高安全性。 高可用性： 为监控服务提供高可用性，确保监控服务的稳定性。 二、讨论的主要议题 标签IDE折扣的文档： 需要编写详细的文档，解释如何使用标签IDE折扣功能。 一次性规格的自动化： 考虑将一次性规格功能与Cephadm集成，实现自动化部署。 断开连接安装的镜像镜像： 考虑使用Scopio等工具自动化镜像镜像过程。 多架构镜像的跟踪： 需要跟踪每个主机的架构和镜像摘要，以确保使用正确的镜像。 Cephadm兼容性测试的覆盖范围： 需要扩大Cephadm兼容性测试的覆盖范围，包括更多操作系统和容器镜像。 Ceph Dashboard安全改进的测试： 需要进行充分的测试，确保管理网关和联合MLS功能的安全性。 三、决定的事项 继续推进已进行中的工作，并确保按时完成。 完善相关文档，帮助用户了解和使用新功能。 扩大Cephadm兼容性测试的覆盖范围。 加强Ceph Dashboard安全改进的测试。 四、后续行动计划 项目团队成员负责完成各自负责的工作。 定期召开会议，跟踪项目进度。 及时解决项目开发过程中遇到的问题。 五、其他事项 讨论了SMB功能的开发计划，计划在T版本中提供SMB功能，并在后续版本中提供更稳定的支持。 讨论了Ceph项目的其他改进方向，例如性能优化、故障恢复等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - CephFS","slug":"CDS_Tentacle_-_CephFS","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_CephFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_CephFS/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员，包括负责self FS for the tentacle release的团队成员 会议主题： self FS for the tentacle release相关议题 Ceph相关功能讨论 会议内容： 1. sensor directory功能 Patrick介绍了sensor directory功能，该功能将支持客户端驱动的大小写敏感度实现，依赖于新增的alternate name元数据。 该功能将是tentacle release的优先事项，并可能回滚到squid。 目前已经开始相关工作，预计不久完成。 任何对该功能的反馈或问题，请在此处提出。 2. layout transformation功能 Beny介绍了layout transformation功能，该功能允许用户设置目录中文件的期望布局，MDS将逐步迁移数据以适应新的布局。 该功能将使用现有的迁移机制和代码，但需要进行详细的代码审查，以确保正确性和安全性。 有关该功能的讨论将持续进行，并将在tentacle release中进行评估。 3. manager volume switch功能 该功能涉及将subvolume元数据从文件存储迁移到SQLite数据库。 该迁移将提高元数据的可靠性和可扩展性，并支持事务操作。 讨论了数据库恢复、数据迁移和审计等问题。 该功能将在tentacle release中进行评估。 4. MDS manager identify metadata heavy workloads功能 该功能旨在通过分析MDS性能指标来识别潜在的瓶颈和问题。 讨论了性能指标收集、存储和分析的方法。 该功能将在tentacle release中进行评估。 5. Implement of the script and use功能 Chris介绍了ecript加密功能的实现情况，该功能已在libsefs和sefuse中实现。 目前已完成读写路径，并正在进行测试。 该功能将在tentacle release中进行评估。 6. reference for fast clone from snapshots功能 该功能旨在解决硬链接文件快照的问题。 讨论了升级和数据扫描工具等问题。 该功能将在tentacle release中进行评估。 后续行动计划： 各功能负责人将根据会议讨论结果，进一步完善相关设计和实现。 定期召开会议，跟踪项目进展。 及时更新相关跟踪项和文档。 其他事项： 会议时间超过预定时间，后续将安排时间继续讨论。 将会议纪要更新到相关跟踪项和文档中。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - Core RADOS","slug":"CDS_Tentacle_-_Core_RADOS","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_Core_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_Core_RADOS/","excerpt":"","text":"会议主题： Ceph 项目开发会议 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Laura, Ron, Ric, Bill, Mark, Laura, Adam, Greg, Sam, Patrick, Nia 等 会议内容： 1. E 优化： 主要议题： 讨论E优化方案的推进，重点关注成本优化和性能限制。 关键细节： Bill Scales已制作详细的设计文档，介绍了优化方案的主要思想。 优化方案中，增加chunk size将非常有用，但需要考虑对已存在代码路径的影响。 需要进一步讨论如何降低优化过程中引入的风险，例如通过引入开关级别或更细粒度的控制。 默认EC插件切换问题，需要考虑向后兼容性。 后续行动计划： 继续推进E优化方案的讨论和开发。 完善测试覆盖范围，以降低引入风险。 确定默认EC插件切换方案。 2. 零压缩： 主要议题： 讨论在消息缓冲列表和对象存储路径中压缩零数据，以提高性能。 关键细节： 优化方案将受益于增加chunk size，因此压缩零数据将非常有用。 需要解决缓冲列表中零数据的压缩问题，包括编码和接口问题。 可能需要新的消息类型或协议级别来支持压缩。 后续行动计划： 进一步讨论压缩零数据的实现方案。 考虑在性能会议上进行更深入的讨论。 3. 编码增强： 主要议题： 继续推进Squid项目的编码增强工作。 关键细节： Naiton在对象存储库中添加了缺失的类型，并进行了测试以确保兼容性。 需要继续扩展测试范围，包括使用旧编码器验证新编码器生成的字节流。 后续行动计划： 继续推进编码增强工作。 扩展测试范围，包括使用旧编码器验证新编码器生成的字节流。 4. PG池： 主要议题： 讨论PG池的稳定性改进。 关键细节： 已有PR对PG池T方案进行了重构，以支持未来的扩展。 后续行动计划： 继续推进PG池的稳定性改进工作。 5. QoS： 主要议题： 讨论QoS的改进，包括操作、回填操作、客户端API和RBD图像级别QoS。 关键细节： 已有PR对QoS功能进行了改进，包括改进回填操作和客户端API。 需要进一步研究RBD图像级别QoS的实现方案。 后续行动计划： 继续推进QoS的改进工作。 6. Scrub： 主要议题： 讨论Scrub的改进，包括拆分存储、设计Scrub队列和改进Deep Scrub调度。 关键细节： 将Scrub存储拆分为浅层错误和深层错误。 设计Scrub队列，以简化代码并提高可理解性。 改进Deep Scrub调度，以提供更好的控制。 后续行动计划： 继续推进Scrub的改进工作。 7. MGR： 主要议题： 讨论MGR的改进，包括操作跟踪器、统计周期和依赖性。 关键细节： 已在Squid中引入了操作跟踪器，用于跟踪操作和请求。 需要进一步研究提供更细粒度跟踪的需求。 需要改进MGR统计周期的文档，以便在MGR不可用时获取数据。 后续行动计划： 继续推进MGR的改进工作。 8. NVMe-oF网关： 主要议题： 讨论NVMe-oF网关的改进，包括可选服务选择和移除。 关键细节： 可以在运行时选择启用或禁用某些服务。 可以将NVMe-oF网关服务从监控器中移除。 后续行动计划： 继续推进NVMe-oF网关的改进工作。 9. Upmap平衡器： 主要议题： 讨论Upmap平衡器的改进，以提高可伸缩性。 关键细节： 可以使用多线程来提高Upmap平衡器的性能。 后续行动计划： 继续推进Upmap平衡器的改进工作。 10. 监控器配置配置文件： 主要议题： 讨论监控器配置配置文件的实现。 关键细节： 可以实现监控器配置配置文件，以简化配置管理。 后续行动计划： 继续推进监控器配置配置文件的实现工作。 11. 随机化： 主要议题： 讨论监控器随机化的问题。 关键细节： 监控器重新部署时可能会遇到连接问题。 可以通过引入非通配符地址来解决这个问题。 后续行动计划： 继续推进监控器随机化的改进工作。 12. 需要兼容的客户端： 主要议题： 讨论需要兼容的客户端的机制。 关键细节： 需要考虑如何强制执行客户端兼容性。 可以使用特征位而不是代码名称来强制执行客户端兼容性。 后续行动计划： 继续推进需要兼容的客户端的改进工作。 13. 发布： 主要议题： 讨论Tentacle版本的发布。 关键细节： 需要确定负责发布Tentacle版本的人员。 后续行动计划： 确定负责发布Tentacle版本的人员。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - Dashboard","slug":"CDS_Tentacle_-_Dashboard","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_Dashboard/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_Dashboard/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 会议地点： 线上会议 参会人员： 全体开发者 会议主题： Dashboard 开发者峰会 会议内容： 一、Scripx 和 Squid 改进 Scripx： 改进了导航布局。 正在撰写博客文章介绍改进内容，目前处于审核阶段。 增加了 SFS 相关功能，包括快照和克隆管理、快照调度、文件系统管理助手等。 修复了一些 bug。 Squid： 增加了 RGW 存储桶策略管理。 支持添加和删除存储桶标签。 改进了 UI/UX。 实现了 RGW 分析功能，可视化存储桶和用户分析数据。 二、Tentacle 计划 多集群功能： Tentacle 将是第一个支持多集群功能的版本。 可以将多个集群连接到一个中心集群，实现单集群管理。 已经完成了大部分实现，包括安全性和 UX 改进。 需要进行性能测试，目标是支持 50 到 100 个集群。 将在测试阶段进行多集群测试。 SE 管理网关： 为 SE 集群上的所有监控堆栈提供单一入口点，提高安全性。 即使节点故障，也能保证仪表板和 RESTful API 的正常运行。 目前大部分功能已经实现，将继续迭代和改进。 NVMe 改进： 将 NVMe 管理功能从 UI 中提供。 计划引入网关组和相关功能。 支持 MTL。 工作流程： 讨论了多个工作流程，包括多站点自动化、NVMe 部署、FS 工作流程和 RBD 镜像。 将根据用户反馈和设计进行优先级排序。 Carbon 迁移： 计划将所有页面迁移到 Carbon，提高性能和可维护性。 将进行性能测试，确保不损失性能。 依赖项升级： 升级 Angular 到最新版本，以提高安全性和可维护性。 将升级其他依赖项。 监控： 计划添加多集群视图、改进 RGW 分析仪表板、支持集群 ID 过滤和改进警报。 将升级 Grafana 到最新版本。 RGW： 实现了细粒度的存储桶复制策略管理。 计划在 UI 中实现 S3 管理。 测试覆盖率： 提高 API 测试覆盖率。 改进测试覆盖率和测试自动化。 三、后续行动计划 继续开发 Tentacle 功能。 完成多集群测试。 发布博客文章。 召开 UX 设计会议。 升级 Grafana。 与其他开发者合作，改进测试和监控。 四、其他事项 讨论了 RBD 镜像工作流程和测试覆盖率的改进。 讨论了 Landing 页面改进和 Carbon 迁移。 五、会议总结 本次会议讨论了 Dashboard 的多个改进和计划，包括 Tentacle 功能、多集群、SE 管理网关、NVMe、工作流程、Carbon 迁移、依赖项升级、监控、RGW 和测试覆盖率。会议明确了后续行动计划，并鼓励开发者积极参与。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - Documentation","slug":"CDS_Tentacle_-_Documentation","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_Documentation/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_Documentation/","excerpt":"","text":"会议纪要 会议时间： 2024年8月19日，美国东部时间上午9:30，伦敦时间下午1:30，加州时间上午6:30 参会人员： Zack（Seth基金会文档负责人）、Ronan、Josh、Zach、Laur、Ernesto等 会议主题： 讨论Seth项目文档的现状、改进计划及社区协作。 会议内容： Zack自我介绍及工作概述： Zack是Seth基金会文档负责人，主要负责维护和改进Seth项目文档。 他使用reStructuredText和Markdown进行文档编写，并负责将主分支的提交回滚到功能分支。 他还负责编译和发布Seth季度报告，并与其他社区成员合作改进文档。 Seth项目文档现状： Seth项目文档主要维护在docs.com，并定期更新。 文档内容涵盖Seth项目的各个方面，包括安装、配置、使用、开发等。 然而，部分文档内容存在过时、不完整或组织混乱等问题。 Seth项目文档改进计划： Seth季度报告： 继续更新Seth季度报告，总结过去三个月的Seth项目进展。 新手指南： 编写新手指南，帮助新用户了解Seth项目的基本概念和功能。 测试驱动指南： 编写测试驱动指南，引导新用户通过一系列命令体验Seth项目。 冰镐计划： 改进在线帮助，使其更具体、更易于使用。 硬件推荐： 建立硬件推荐列表，帮助用户选择合适的硬件。 Python问题： 加强对文档基础设施的管理和运维。 社区协作： 鼓励社区成员参与文档编写和改进，包括报告错误、提交pull request、提供硬件推荐等。 鼓励社区成员提出改进建议，共同提升Seth项目文档的质量。 会议决定： Zack将根据会议讨论的内容，进一步推进Seth项目文档的改进计划。 社区成员将积极参与文档编写和改进，并提供反馈和建议。 后续行动计划： Zack将更新Seth季度报告。 编写新手指南和测试驱动指南。 改进在线帮助。 建立硬件推荐列表。 加强对文档基础设施的管理和运维。 其他事项： 会议中，Ronan提到Seth项目内部文档组织混乱，Zack表示将改进文档的组织方式。 会议结束时，Zack提供了联系方式，方便社区成员提出文档请求和建议。 关键词： Seth、文档、改进、社区、协作、新手指南、测试驱动指南、冰镐计划、硬件推荐","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - NVMe","slug":"CDS_Tentacle_-_NVMe","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_NVMe/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_NVMe/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Patrick, Sam, Ilia, Chris Krishna, Val, Krishna 等 会议主题： 讨论Ceph Gateway的优化、功能增强和后续行动计划 会议内容： 一、编码优化与升级 讨论了编码优化工作，包括修复编码问题、指针清理等。 计划将优化后的代码合并到上游。 讨论了升级问题，特别是升级时的兼容性。 二、Spdk相关功能 讨论了Spdk社区的新功能，如新的EnV me council命令。 讨论了xcopy支持，需要进一步研究其性能和实现方式。 讨论了使用shed FR pool进行优化的方案。 讨论了Spdk的动态调度器，这是一个新的研究项目。 三、安全增强 讨论了用户认证和访问控制，包括namespace mask scheme。 讨论了性能提升，包括CPU利用率优化和网络性能提升。 讨论了使用offloading加密技术。 四、可用性改进 讨论了将Ceph Gateway CLI迁移到SEF CLI的方案。 讨论了改进命令行界面，使其更易于使用。 讨论了提高文档质量，包括最小硬件推荐和故障排除指南。 五、快照和复制 讨论了快照和复制的功能，包括将快照和配置复制到其他集群。 讨论了复制的复杂性，包括访问控制、IP地址和initiators。 讨论了使用RBD snapshot和clone进行复制的方案。 六、其他 讨论了TLS PSK的使用。 讨论了API支持VALL的需求。 后续行动计划： 完成编码优化并合并到上游。 研究xcopy支持的性能和实现方式。 优化Spdk功能，包括动态调度器。 增强安全性和可用性。 完善文档。 研究快照和复制功能。 备注： 会议中提到了许多计算机科学/ceph相关领域英文关键词，如编码、优化、升级、Spdk、安全、可用性、快照、复制等。 会议内容涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - Crimson","slug":"CDS_Tentacle_-_Crimson","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_Crimson/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_Crimson/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： Google Meet 参会人员： Squid 项目成员，包括 Squid 项目负责人、Intel 团队成员等。 会议主题： Squid 项目进展、Crimson 存储引擎优化以及未来计划。 会议内容： 一、Squid 项目当前状态 Squid 项目已实现多核支持，包括 Reactor 和 Messenger。 支持在复制的存储池中使用 Blue Store、C Store 和 CN Store 作为后端，主要处理 RBD 工作负载。 支持通过 saadm 或重启快速部署集群。 提供初始的 Scrub 支持，可通过 SEF tell 命令启动 Scrub 或 Deep Scrub。 在恢复和备份方面进行了大量工作，提高了稳定性。 测试覆盖范围良好，拥有稳定的测试套件，并添加了恢复垃圾模式测试。 引入 SE Store 作为后端，大部分 API 测试和基本测试均通过。 引入协程，提高了代码友好性和开发效率。 二、Crimson 存储引擎优化 评估了 RBD 4K 随机读写性能，这是衡量 Crimson OSD 基本性能的关键指标。 分析了 Crimson 的扩展性，结果表明其性能随着核心数的增加而提高。 对 Crimson 进行了优化，包括计算效率、I/O 效率和减少饥饿和内部竞争。 优化了 C Store，提高了随机读写的性能。 C Store 的核心功能已实现，包括数据读写、元数据索引、事务支持和背景任务等。 优化了性能，包括 FGC 缓存和 128 位逻辑块地址支持。 三、未来计划 推进性能改进，特别是多核支持下的性能。 优化异步消息传递，提高其可扩展性。 优化 C Store，提高其性能和可用性。 支持更复杂的 Scrub 功能。 支持动态 CPU 核心分配。 扩展测试套件，包括 RBD 镜像测试。 四、行动计划 Squid 项目成员将继续优化 Squid 和 Crimson，并推进未来计划。 Intel 团队将继续优化 C Store，并提高其性能和可用性。 Squid 项目成员将积极参与社区贡献，并推动 Squid 的发展。 五、其他事项 会议讨论了异步消息传递的性能问题，并探讨了可能的解决方案。 会议讨论了 C Store 的扩展性，并探讨了如何提高其性能。 总结： 本次会议回顾了 Squid 和 Crimson 的进展，并讨论了未来的计划。会议强调了性能优化和扩展性改进的重要性，并制定了具体的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - RGW","slug":"CDS_Tentacle_-_RGW","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_RGW/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： Casey, Adam Emerson, Daniel, Caleb, Mark Hogan, Shila, Val, CH, Bloomberg 等 会议主题： 讨论Ceph分布式存储项目的进展和未来计划 主要议题： 1. 扩展接口 d4n缓存： 讨论了d4n缓存的使用和优化，包括完成读写缓存和缓存分配，以及考虑将非持久性数据缓存起来。 S3 Select增强： 讨论了S3 Select的进一步增强，但目前Gal不在场，因此暂时保留此议题。 Arrow flight： 讨论了Arrow flight的进一步优化，包括处理flight SQL请求并通过S3 Select进行增强。 2. 调整和优化 Resharding： 讨论了Resharding的优化，包括非阻塞Resharding和Shard并发性。 多站点： 讨论了多站点的优化，包括Bucket索引日志卸载到FIFO、复制清理和修复多站点测试。 3. Zipper Zipper可加载模块： 讨论了Zipper可加载模块的进展，目前Caleb正在开发中。 灵活的配置： 讨论了灵活的配置，允许运行时配置Zipper的过滤器和存储。 4. 其他 S3桶日志： 讨论了S3桶日志的实现，这是一个类似于AWS S3功能的特性，用于记录桶的所有修改和访问。 大对象： 讨论了大对象的优化，包括使用相同的概念进行服务器端复制，并考虑将对象与数据分离。 S3 put bucket所有权控制： 讨论了S3 put bucket所有权控制，允许禁用桶对象的ACL。 跟踪： 讨论了跟踪的实现和优化，包括在rgw和OSD之间实现端到端跟踪，并讨论了如何使用跟踪来测量性能和定位问题。 Lua强化： 讨论了Lua强化，包括防止Lua脚本消耗过多内存和CPU，以及防止Lua脚本修改操作系统或文件系统。 C++ 20协程原型： 讨论了C++ 20协程原型，用于元数据同步，这将使多站点功能更容易实现。 行动计划： 完成d4n缓存的优化和集成。 实现S3 Select的进一步增强。 优化Resharding和Shard并发性。 实现Bucket索引日志卸载到FIFO、复制清理和修复多站点测试。 开发Zipper可加载模块和灵活的配置。 实现S3桶日志和大对象优化。 禁用S3 put bucket所有权控制。 优化跟踪功能。 强化Lua功能。 开发C++ 20协程原型。 后续行动： 将会议纪要中的讨论内容转化为Redmine跟踪问题。 继续推进各个议题的进展。 定期召开会议，讨论项目的进展和问题。 总结： 本次会议讨论了Ceph分布式存储项目的多个重要议题，并制定了详细的行动计划。会议气氛积极，参会人员积极参与讨论，为项目的进展做出了贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Tentacle - Telemetry","slug":"CDS_Tentacle_-_Telemetry","date":"2024-08-21T16:00:00.000Z","updated":"2024-08-22T16:00:00.000Z","comments":true,"path":"2024/08/22/CDS_Tentacle_-_Telemetry/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/22/CDS_Tentacle_-_Telemetry/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储系统 Telemetry 功能讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Ceph 团队成员，包括研发人员、测试人员、用户代表等 会议内容： 一、Stretch 模式指标收集 讨论背景： 为了了解 Stretch 模式的实际使用情况，需要收集相关指标。 解决方案： 通过 OSD 映射中的标志位收集 Stretch 模式状态信息。 使用 Telemetry 模块收集相关数据，甚至可以追溯到几代版本。 讨论了 Stretch 模式和 Stretch 集群的区别，以及进入 Stretch 模式所需的准备工作和配置。 行动计划： Junior 将研究是否需要收集其他相关信息。 在 Stretch 集群上进行测试，验证指标收集是否正确。 二、其他指标收集 讨论背景： 讨论了其他需要收集的指标，例如： 用户对其他功能的使用情况。 其他未收集的指标，例如 RBD、RGW 和 FFS 的应用层指标。 RGW 多站点集群的统计信息。 蓝存储分配器性能指标。 解决方案： 讨论了如何收集和分析这些指标，例如： 使用 Grafana 进行可视化。 开发新的 Telemetry 模块。 从性能计数器中推断信息。 行动计划： 将讨论结果提交给用户开发会议，进一步讨论和确定具体的指标收集方案。 三、Telemetry 分析报告 讨论背景： 讨论了如何向用户提供 Telemetry 分析报告，帮助用户了解其部署状态和潜在问题。 解决方案： 讨论了两种方案： 在 Telemetry 网页或 Grafana 上提供更个性化的分析报告。 开发一个 Telemetry 命令，生成分析报告。 行动计划： 研究现有的 AI 工具，例如 SE Report，以获取灵感。 研究如何将敏感信息匿名化。 讨论如何将分析报告集成到现有的工具中。 四、其他事项 讨论了如何改进升级路径的数据库，以便更好地了解不同版本之间的兼容性。 讨论了如何使用 Telemetry 数据来评估版本稳定性，并帮助用户做出升级决策。 会议总结： 本次会议讨论了 Ceph 存储系统 Telemetry 功能的多个方面，包括指标收集、分析报告和用户体验等。会议达成了多项共识，并制定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User + Dev Monthly Meeting 2024-08-21","slug":"Ceph_User_+_Dev_Monthly_Meeting_2024-08-21","date":"2024-08-20T16:00:00.000Z","updated":"2024-08-21T16:00:00.000Z","comments":true,"path":"2024/08/21/Ceph_User_+_Dev_Monthly_Meeting_2024-08-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/21/Ceph_User_+_Dev_Monthly_Meeting_2024-08-21/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： Ceph分布式存储用户开发会议，主要讨论了用户体验（Usability）和Ceph功能改进。 参会人员： Laura、Zach、Joel、Alex等Ceph社区成员。 会议内容： 1. 用户体验（Usability） 议题： 如何改进Ceph的用户体验，特别是针对非技术用户。 讨论： Joel： 提出在Crush Map中添加网络交换机信息，以帮助管理员更好地了解集群结构，但担心这会导致数据迁移。 Alex： 建议使用PG Remapper或upmap remapped工具来避免数据迁移，并建议Joel创建一个跟踪器来记录问题。 Zach： 提出冰镐倡议（Ice Pick Initiative），旨在改进Ceph命令的帮助输出，使其更易于理解和使用。 Garv： 讨论Ceph仪表板的用户体验改进，特别是针对非技术用户，并计划进行社区调查以获取反馈。 决定事项： Joel将创建一个跟踪器，记录添加网络交换机信息的问题，并尝试使用PG Remapper或upmap remapped工具来解决。 Zach将开始实施冰镐倡议，并创建一个跟踪器来跟踪所有需要改进的命令。 Garv将进行社区调查，以获取对Ceph仪表板用户体验的反馈。 2. Ceph功能改进 议题： 讨论Ceph功能的改进，特别是与用户体验相关的改进。 讨论： Joel： 提出使用upmap来避免在添加网络交换机信息时进行数据迁移。 Alex： 讨论了upmap和upmap balancer的工作原理，并建议Joel尝试使用这些工具来解决他的问题。 Zach： 讨论了Ceph命令的帮助输出，并提出了改进建议。 Garv： 讨论了Ceph仪表板的用户体验改进，并计划进行社区调查以获取反馈。 决定事项： 无 后续行动计划： Joel将创建一个跟踪器，记录添加网络交换机信息的问题，并尝试使用PG Remapper或upmap remapped工具来解决。 Zach将开始实施冰镐倡议，并创建一个跟踪器来跟踪所有需要改进的命令。 Garv将进行社区调查，以获取对Ceph仪表板用户体验的反馈。 社区成员将提供反馈，以帮助改进Ceph的用户体验。 关键词： usability、Crush Map、upmap、upmap balancer、Ice Pick Initiative、Ceph仪表板、用户体验","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly | 2024-08-07","slug":"Ceph_Developer_Monthly_2024-08-07","date":"2024-08-14T16:00:00.000Z","updated":"2024-08-15T16:00:00.000Z","comments":true,"path":"2024/08/15/Ceph_Developer_Monthly_2024-08-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/08/15/Ceph_Developer_Monthly_2024-08-07/","excerpt":"","text":"会议时间： 2023年11月（具体日期未提及） 参会人员： Jose Perez（英国SE开发者团队） Patrick（Samba开发者） Milan Chang（CFS团队） Lee Sanders（英国团队） Bill（开发者） Ken Drer（基础设施和构建团队） Laura（开发者） 其他参与者 会议主题： Crimson性能建议： Jose Perez分享了Crimson性能建议的研究，比较了基本配置和手动配置的性能差异，并提出了推荐配置。 SEFS不区分大小写的目录树： Patrick讨论了SEFS中不区分大小写的目录树，该功能将提高Samba等网关的性能。 Pine Manager允许禁用始终开启的模块： 提议为Pine Manager添加禁用始终开启模块的功能，以解决某些模块性能问题。 CBT的未来愿景： Lee Sanders介绍了CBT的未来愿景，包括改进自动化、数据后处理和性能评估标准。 Erasure Coding性能工作： Bill讨论了Erasure Coding性能优化，以提高小读写I/O和随机读写性能。 Manager模块加载： Milan Chang提出了Manager模块加载的问题，并讨论了解决方案。 CentOS Stream的生命周期： Laura和Ken Drer讨论了CentOS Stream的生命周期和Ceph的发布计划，并探讨了使用其他发行版的可能性。 关键决定： 将继续研究Crimson性能建议，并制定推荐配置。 将在SEFS中实现不区分大小写的目录树。 将为Pine Manager添加禁用始终开启模块的功能，并考虑将其推广到其他模块。 将改进CBT，以提供更自动化和标准化的性能评估。 将优化Erasure Coding性能。 将解决Manager模块加载问题。 将继续评估CentOS Stream的生命周期，并考虑使用其他发行版。 后续行动计划： Jose Perez将分享Crimson性能建议的幻灯片。 Patrick将更新SEFS不区分大小写的目录树的跟踪器。 将对Pine Manager禁用始终开启模块的功能进行审查。 Lee Sanders将继续改进CBT。 Bill将继续进行Erasure Coding性能优化。 Milan Chang将解决Manager模块加载问题。 Laura和Ken Drer将评估CentOS Stream的生命周期，并与其他团队成员讨论使用其他发行版的可能性。 会议总结： 本次会议讨论了Ceph社区的多个重要议题，并制定了后续行动计划。会议强调了性能优化、功能改进和标准化的重要性，并讨论了如何应对CentOS Stream生命周期结束带来的挑战。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Attempting to Improve Discard Performance | Ceph Days NYC 2024","slug":"Attempting_to_Improve_Discard_Performance_Ceph_Days_NYC_2024","date":"2024-06-17T16:00:00.000Z","updated":"2024-06-18T16:00:00.000Z","comments":true,"path":"2024/06/18/Attempting_to_Improve_Discard_Performance_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/06/18/Attempting_to_Improve_Discard_Performance_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了分布式存储系统Ceph中遇到的一个性能问题，特别是与RBD（RADOS Block Device）工作负载相关的问题。会议详细探讨了问题的发现、分析过程、解决方案以及未来的改进方向。 关键细节 问题发现： 在特定的驱动模型中，当驱动器被大量写入并开始覆盖旧数据时，性能突然下降。 该问题在驱动器满载且未发送丢弃命令（discards）时尤为明显。 初步解决方案： 在部分驱动模型上启用异步丢弃命令，发现对某些模型的性能有显著提升，但对其他模型影响不大。 与驱动器供应商合作，获取新的固件更新以解决性能问题。 固件更新效果： 新固件使丢弃命令的执行速度提升近一倍，但仍远低于参考模型。 内部改进尝试： 尝试通过增加丢弃线程池来提高丢弃命令的并行处理能力，但效果不明显。 发现驱动器固件可能以单线程方式处理丢弃命令，限制了并行处理的潜力。 其他潜在改进： 研究不同的分配器（allocator）对性能的影响，特别是针对混合分配器和AVL分配器的比较。 需要进一步测试以确定不同分配器对不同类型驱动器的影响。 决定事项 继续与供应商合作，优化固件以进一步提升性能。 进一步研究并测试不同的分配器，以找到最适合当前存储环境的配置。 继续在社区中分享和讨论改进方案，以获取更多反馈和建议。 后续行动计划 继续监控和分析启用丢弃命令后的性能数据。 与社区合作，推动并优化丢弃命令的多线程支持。 定期回顾和评估分配器的性能，确保最佳配置。 总结与反思 本次问题的解决过程中，团队通过深入挖掘和与社区的紧密合作，成功找到了初步解决方案。 使用开源产品Ceph的优势在于能够快速响应问题，并与社区共同进步。 对社区的贡献不仅帮助了自身，也促进了整个社区的发展和成熟。 致谢 对Ceph社区的支持和帮助表示感谢，并鼓励团队成员继续积极参与社区贡献。 本次会议记录涵盖了问题的发现、分析、解决方案及未来展望，为后续的工作提供了明确的方向和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Data Security and Storage Hardening in Rook and Ceph | Ceph Days NYC 2024","slug":"Data_Security_and_Storage_Hardening_in_Rook_and_Ceph_Ceph_Days_NYC_2024","date":"2024-06-17T16:00:00.000Z","updated":"2024-06-18T16:00:00.000Z","comments":true,"path":"2024/06/18/Data_Security_and_Storage_Hardening_in_Rook_and_Ceph_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/06/18/Data_Security_and_Storage_Hardening_in_Rook_and_Ceph_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议概述 本次会议是在多次虚拟会议后首次面对面进行的，与会者包括来自IBM的SEF平台总监、网络安全专家等。会议主要讨论了SEF（软件定义存储）的市场规模、安全实践、IBM的产品安全策略以及未来的行动计划。 会议关键细节 市场规模估计： SEF的市场规模估计在4.2到6.5 exabytes之间，这使得SEF成为最大的开源软件定义存储产品之一。 安全实践： 安全实践需要基于威胁模型来选择，不同的威胁场景需要不同的安全策略。 SEF定义了多个网络区域（如公共安全区、存储访问区等），每个区域的安全需求不同，需要仔细配置。 IBM产品安全策略： IBM在产品安全方面进行了多项活动，包括安全开发、生命周期管理、漏洞测试等。 IBM正在努力自动化依赖项的更新，以减少漏洞暴露。 IBM将继续支持SEF的多个版本，并与开源社区进行更多合作。 加密和密钥管理： SEF支持数据静态加密和传输加密，使用DM cry配置和Messenger版本2.1协议。 Rook使用CRD（自定义资源定义）来配置安全设置，支持数据静态加密和密钥管理系统。 未来行动计划： 继续改进SEF的安全性，包括仪表盘安全、远程功能安全等。 与IBM研究部门合作，探讨量子计算和机密计算的安全性。 继续支持SEF作为AI和政府客户的存储后端。 讨论的主要议题 SEF的市场规模和其在软件定义存储领域的地位。 如何基于威胁模型来选择和实施安全实践。 IBM如何通过自动化和开源合作来提高产品安全性。 加密和密钥管理在SEF和Rook中的应用。 决定的事项 继续支持SEF的多个版本，并与开源社区进行更多合作。 自动化依赖项的更新，以减少漏洞暴露。 改进SEF的安全性，包括仪表盘安全、远程功能安全等。 后续行动计划 继续进行安全开发和生命周期管理活动。 自动化代码扫描，检测新漏洞，并将修复措施应用到IBM SEF和上游SEF。 与IBM研究部门合作，探讨量子计算和机密计算的安全性。 继续支持SEF作为AI和政府客户的存储后端。 其他资源 Aqua Security提供的关于Kubernetes Secrets的教程。 Michael Hosenblat的《Hacking Kubernetes》一书中关于存储的章节。 IBM和Red Hat的产品安全和加固指南。 会议结束 会议结束时，与会者表示将继续合作，共同提高SEF的安全性，并鼓励社区成员提出建议和关注点。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"How we Operate Ceph at Scale | Ceph Days NYC 2024","slug":"How_we_Operate_Ceph_at_Scale_Ceph_Days_NYC_2024","date":"2024-06-17T16:00:00.000Z","updated":"2024-06-18T16:00:00.000Z","comments":true,"path":"2024/06/18/How_we_Operate_Ceph_at_Scale_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/06/18/How_we_Operate_Ceph_at_Scale_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题：DigitalOcean 大规模运营 Ceph 的实践 会议时间：[具体日期] 会议地点：[具体地点] 主讲人：Matt（DigitalOcean 存储系统团队，加拿大东部） 会议内容总结： DigitalOcean 简介 DigitalOcean 是一家成立于2012年的云服务提供商，以简单性为核心理念。 最初提供5美元的SSD后端虚拟机（Droplet），后续产品线扩展至包括Spaces（Ceph支持的S3兼容对象存储）、DBaaS、App Platform、LBaaS等。 拥有9个不同区域的数据中心，为客户提供多样化的资源部署选择。 Ceph 在 DigitalOcean 的应用 DigitalOcean 持续扩展Ceph的使用，主要用于块存储和对象存储，支持Volumes和Spaces等服务。 统计数据：58个集群，其中47个生产集群运行Pacific版本，8个测试集群，超过200PB的原始存储，最大集群超过12PB，28,000个OSDs，1,600台服务器运行Ceph。 自动化与配置管理 使用Chef进行核心操作系统配置管理，Ansible用于Ceph特定任务，如集群部署和节点扩充。 AWX作为开源的自托管解决方案，用于运行Ansible playbooks，确保团队共享故障模式、保密信息并记录运行历史。 集群操作与维护 自动化工具支持新集群部署、节点扩充、节点预检、安全重启、配置管理和Ceph升级。 集群扩容通过PG Remapper进行，优化了对象存储的恢复过程，减少了块存储的并发控制以适应工作负载的延迟敏感性。 性能监控与优化 使用自研工具Marigraph进行集群延迟测量，优化了OSD启动和PG peering过程，减少了延迟敏感应用的影响。 针对对象存储，优化了RGW与RocksDB的交互，通过设置OSD异步恢复最小成本和启用TTL压缩，显著提高了性能和稳定性。 监控与告警 使用Ceph Exporter和Store Exporter收集集群和硬件状态数据，监控网络可达性和硬件健康状况。 Marigraph工具持续运行合成负载，提供关键的延迟和IO性能指标，帮助识别和解决性能问题。 反思与未来展望 早期块存储和对象存储团队的分离导致集群管理和自动化配置的差异，增加了复杂性和维护难度。 建议未来更多地整合自动化工具，减少配置分散，提升集群的一致性和可管理性。 后续行动计划： 继续优化自动化工具，特别是Ansible playbooks，以提升集群操作的效率和一致性。 加强监控系统的集成和告警策略，确保及时发现并解决潜在的性能和稳定性问题。 探索更多自动化服务的可能性，减少手动操作，提升团队的整体工作效率。 会议结束： 招聘插件和Q&amp;A环节，讨论了团队扩张和技术细节问题。 备注： 会议内容涉及大量技术细节和特定工具的使用，建议团队成员根据自身职责深入研究相关部分，确保技术实施的准确性和效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Making RBD Snapshot-based Mirroring Robust for Disaster Recovery | Ceph Days NYC 2024","slug":"Making_RBD_Snapshot-based_Mirroring_Robust_for_Disaster_Recovery_Ceph_Days_NYC_2024","date":"2024-06-17T16:00:00.000Z","updated":"2024-06-17T16:00:00.000Z","comments":true,"path":"2024/06/18/Making_RBD_Snapshot-based_Mirroring_Robust_for_Disaster_Recovery_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/06/18/Making_RBD_Snapshot-based_Mirroring_Robust_for_Disaster_Recovery_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题：RBD快照基础镜像功能的改进与灾难恢复解决方案 主讲人：Raman Raja，IBM软件工程师 会议内容概述： Raman Raja介绍了RBD（RADOS Block Device）快照基础镜像功能的最新改进，旨在使其更加健壮，适用于灾难恢复场景。他首先概述了RBD镜像功能，然后详细讨论了如何设置、整体架构、以及在严格测试中发现的快照基础镜像功能的缺陷和解决方案。 主要讨论点： RBD镜像功能概述： RBD镜像功能包括异步复制图像，由RBD镜像守护进程执行。 支持两种模式：日志基础镜像和快照基础镜像。 快照基础镜像模式下，在主图像上拍摄崩溃一致的镜像快照，镜像守护进程识别数据和元数据变化，并复制快照增量到非主图像。 架构与配置： 支持单向和双向复制配置，便于故障切换和故障恢复协调。 使用SEF orchestrator（如SEF ADM或Rook）启动RBD镜像守护进程，配置RBD池和图像进行镜像。 故障切换与恢复： 计划故障切换时，先降级主图像，创建降级快照，同步到非主图像，然后提升非主图像。 非计划故障切换时，强制提升非主图像，如果数据未完全同步，图像回滚到完全同步的快照。 灾难恢复解决方案： 针对Kubernetes工作负载，使用RBD作为存储后端，实现跨区域的数据恢复，确保业务需求在几分钟内恢复。 解决方案涉及三个Kubernetes集群，包括一个Hub集群和两个管理集群，通过ramen Hub操作符自动化管理。 测试中发现的问题与修复： 发现并修复了快照对象映射不正确导致的数据损坏问题。 解决了镜像快照调度器客户端被krbd客户端错误阻止的问题。 改进了在高延迟环境下镜像守护进程的行为。 未来工作： 支持镜像组和RBD克隆的镜像。 优化强制提升时的数据同步效率。 决定事项： RBD快照基础镜像功能已进行多项改进，提高了灾难恢复场景下的健壮性。 继续开发镜像组和RBD克隆的镜像支持。 后续行动计划： 继续测试和优化RBD快照基础镜像功能。 完成镜像组和RBD克隆的镜像支持开发。 致谢： 感谢Ilia和Sham作为RBD和ramen操作符的维护者。 结束语： Raman Raja感谢大家的参与和贡献，并期待未来的进一步合作和改进。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User + Dev Monthly Meeting 2024-05-23","slug":"Ceph_User_+_Dev_Monthly_Meeting_2024-05-23","date":"2024-05-30T16:00:00.000Z","updated":"2024-05-30T16:00:00.000Z","comments":true,"path":"2024/05/31/Ceph_User_+_Dev_Monthly_Meeting_2024-05-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/31/Ceph_User_+_Dev_Monthly_Meeting_2024-05-23/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph社区的调查反馈，特别是关于Orchestration和Performance的调查结果。会议旨在通过互动讨论，收集社区成员的实时反馈，以便更好地理解用户需求并改进Ceph的功能和性能。 关键讨论点 Orchestration反馈 部署目标：大多数用户使用裸机（bare metal）进行部署，较少使用容器。 Orchestration系统：SEF ADM是最受欢迎的Orchestration系统，其次是自制的Orchestration系统。 用户反馈：SEF ADM被认为简单可靠，但存在某些命令过于复杂和日志难以调试的问题。自制Orchestration系统则被赞赏为提供了更多的控制和信任。 Performance反馈 集群事件影响：监控同步、OSD不可用等事件对性能有显著影响。 EC插件使用：大多数用户使用默认的EC插件，如jerasure和reed_sol_van。 Op调度器：mclock是常用的Op调度器，但存在文档不足和需要手动调优的问题。 Telemetry模块：约50%的用户未启用Telemetry模块，主要原因是缺乏对功能的了解和对隐私安全的担忧。 用户建议和反馈 改进建议：用户提出了对SEF ADM的自动化程度、日志调试、OSD创建过程的具体改进建议。 技术讨论：涉及SEF ADM是否应支持非容器化部署的讨论，以及Telemetry模块的数据安全和隐私问题。 决定事项 改进方向：社区将根据调查反馈，特别是在Orchestration和Performance方面的具体问题，进行针对性的改进。 文档更新：将更新和改进相关文档，特别是关于mclock和SEF ADM的使用指南。 后续行动计划 跟踪问题：社区成员被鼓励提出具体的问题和反馈，通过创建Tracker来跟踪和解决这些问题。 社区参与：鼓励更多的社区成员参与到用户委员会中，特别是那些对特定主题（如stretch clusters）有兴趣的成员。 持续反馈：会议结束后，调查问卷将继续开放一段时间，以便收集更多的反馈。 结论 会议强调了社区反馈的重要性，并承诺将根据这些反馈进行改进，以提高Ceph的性能和用户体验。同时，鼓励社区成员积极参与，共同推动Ceph的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Data Placement with Upmap / Introducing Chorus | Ceph Days NYC 2024","slug":"Ceph_Data_Placement_with_Upmap_Introducing_Chorus_Ceph_Days_NYC_2024","date":"2024-05-23T16:00:00.000Z","updated":"2024-05-23T16:00:00.000Z","comments":true,"path":"2024/05/24/Ceph_Data_Placement_with_Upmap_Introducing_Chorus_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/24/Ceph_Data_Placement_with_Upmap_Introducing_Chorus_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议概述 本次会议由一位曾在Ceph Day Berlin 2018发表过演讲的CTO主持，他目前是Ceph基金会执行委员会成员，曾长期在CERN担任Ceph相关职务。会议主要讨论了Ceph的内部机制，特别是关于数据分布和管理的复杂性。 讨论的主要议题 Ceph的历史与现状： 讨论了Ceph早期面临的挑战，特别是运维人员的压力和复杂性。 强调了社区在过去几年中选择不公开讨论Ceph的复杂性，导致了一些知识的缺失。 Ceph的核心机制： Placement Groups (PGs)：解释了PGs的作用，它们如何帮助管理大量数据，并通过统计学原理减少数据丢失的风险。 CRUSH算法：介绍了CRUSH算法的基本功能，包括如何描述基础设施和实现快速数据分布。 upmap工具：讨论了upmap工具如何作为数据分布的最后校正步骤，帮助平衡集群中的数据分布。 自动化与优化： 介绍了Ceph内部的平衡器（balancer），它利用upmap工具自动调整PGs的位置，以优化数据分布和存储效率。 讨论了如何通过脚本和工具（如upmap remap）来进一步优化和管理Ceph集群。 未来展望： 提到了正在开发的Ceph co-pilot，这是一个结合AI和分析工具的辅助系统，旨在帮助运维人员更有效地管理Ceph集群。 介绍了chorus工具，这是一个用于S3集群数据迁移的开源前端工具。 决定的事项 强调了upmap工具的重要性，并建议将其作为默认设置，以提高集群的性能和容量利用率。 确认了Ceph co-pilot和chorus工具的开发进展，并计划将这些工具整合到Ceph的运维实践中。 后续行动计划 继续推广和优化upmap工具的使用，确保所有Ceph集群都能从中受益。 推动Ceph co-pilot的开发，使其成为一个实用的AI辅助工具。 发布chorus工具，帮助用户更高效地管理S3集群间的数据迁移。 结论 会议强调了Ceph技术的复杂性和运维挑战，同时也展示了通过工具和自动化来优化和管理这些挑战的可能性。通过不断的技术创新和社区合作，Ceph的未来发展值得期待。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"NVMe-Over-Fabrics Support for Ceph | Ceph Days NYC 2024","slug":"NVMe-Over-Fabrics_Support_for_Ceph_Ceph_Days_NYC_2024","date":"2024-05-23T16:00:00.000Z","updated":"2024-05-23T16:00:00.000Z","comments":true,"path":"2024/05/24/NVMe-Over-Fabrics_Support_for_Ceph_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/24/NVMe-Over-Fabrics_Support_for_Ceph_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题：NVMe over TCP 和 NVMe-oF Gateway 的集成与性能优化 会议时间：[具体时间] 会议地点：[具体地点] 参会人员： Mike Burkhart - IBM 产品经理，负责 NVMe over TCP 和 VMware 集成 会议内容概要： NVMe 驱动介绍 NVMe 驱动具有高耐用性、并行处理能力和高度可扩展性。 NVM fabric 规范自2018-2019年成熟，支持通过不同传输介质（如光纤通道、RDMA 和 NVMe over TCP）访问 NVMe 磁盘。 NVMe over TCP 的优势 通过网络传输实现 NVMe 驱动的高容量、可扩展性和耐用性。 利用 SEF（Scalable Ethernet Fabric）的扩展能力，增强 NVMe 的耐用性和并行处理能力。 TCP 连接模型 每个 TCP 连接实例使用用户空间驱动，每个连接对应一个独立的会话和 NVMe 命名空间控制器。 这种一对一的连接模型支持高度的可扩展性和控制灵活性。 性能优化与传统技术对比 与传统的 iSCSI 技术相比，NVMe over TCP 提供了更高的吞吐量、更好的 IOPS 和更低的延迟。 RBD（RADOS Block Device）作为底层实现，已经过充分测试和验证。 架构与集成 NVMe-oF Gateway 采用用户空间驱动，基于 SPDK（Storage Performance Development Kit）开发。 支持多路径和负载均衡，每个 Gateway 可以加载所有可用的子系统，实现环境隔离。 控制器与子系统管理 控制器是临时性的，客户端断开连接后，控制器可以被回收利用。 子系统用于协调命名空间，支持多子系统和多 Gateway 的扩展。 配置与安全性 Gateway 的配置存储在 omap 中，支持配置在实例间的迁移。 使用 SPDK 和 TLS PSK 实现加密通信，未来计划支持 inband o。 性能测试结果 与 iSCSI 相比，NVMe over TCP 在多个性能指标上显示出显著优势，特别是在多节点和多反应器配置下。 VMware 集成 支持通过 VMware vSphere APIs for Storage Awareness (VASA) 进行存储加速和卸载。 决定事项： 确认 NVMe over TCP 作为下一代存储解决方案的技术优势和性能表现。 继续推进与 VMware 的集成工作，优化存储性能和效率。 后续行动计划： 完成 NVMe over TCP 与现有 RBD 接口的完全映射。 继续进行性能测试和优化，确保在不同工作负载下的稳定性和高效性。 推进与 VMware 的深度集成，实现更高效的存储管理和优化。 会议结束时间：[具体时间] 以上为本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Community Initiatives and Improving Ceph through User Feedback | Ceph Days NYC 2024","slug":"Community_Initiatives_and_Improving_Ceph_through_User_Feedback_Ceph_Days_NYC_2024","date":"2024-05-22T16:00:00.000Z","updated":"2024-05-23T16:00:00.000Z","comments":true,"path":"2024/05/23/Community_Initiatives_and_Improving_Ceph_through_User_Feedback_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/23/Community_Initiatives_and_Improving_Ceph_through_User_Feedback_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题： SEF用户委员会的启动 会议时间： [具体日期] 会议地点： 线上会议 主持人： Laura Flores 参会人员： SEF项目团队成员、社区成员 会议目标： 介绍SEF用户委员会的成立目的、工作流程、初步调查反馈及后续行动计划。 会议内容总结： 目标介绍： SEF用户委员会旨在收集更多用户反馈，改进SEF项目。 历史活动包括SEF Days、SEF Lons、虚拟论坛和用户开发者会议。 新倡议希望通过用户委员会集中反馈，转化为具体行动项。 工作流程： 用户委员会将聚焦于性能和编排部署两大支柱。 设立冠军（Champions）角色，负责引导讨论和组织相关议题。 通过调查问卷收集用户反馈，冠军将协助设计问卷问题。 调查结果将通过数据可视化处理，并与遥测数据关联分析。 初步调查反馈： 调查集中在性能和编排部署方面，收集了27份反馈。 性能方面，用户普遍满意，但也提出了如mclock控制、长时间回填性能下降等问题。 编排部署方面，用户对自动化和易用性满意，但也指出了日志和错误处理、文档不足等问题。 后续行动计划： 根据初步反馈调整问卷，扩大调查范围，增加社交媒体和口口相传的宣传。 计划在下次用户开发者会议上讨论具体行动项。 鼓励社区成员成为冠军，负责其他支柱如质量、可扩展性等。 下次会议安排： 下次用户开发者会议定于每月第三个周四的14:00 UTC，下次会议日期为5月16日。 感兴趣成为冠军的成员可通过电子邮件联系Laura或N。 行动项： - 调整并发布新的调查问卷。 - 在社交媒体和社区中扩大宣传，吸引更多用户参与。 - 在下次用户开发者会议上讨论并确定具体行动项。 - 招募更多冠军，负责其他SEF支柱的改进工作。 会议结束语： 感谢所有参与者的贡献，期待社区的积极参与和反馈，共同推动SEF项目的改进和发展。 备注： - 会议记录和相关资料将通过邮件列表和社区平台共享。 - 如有关于会议的任何疑问或建议，请及时联系会议组织者。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Designing a Multitenancy File System for Cloud Environment | Ceph Days NYC 2024","slug":"Designing_a_Multitenancy_File_System_for_Cloud_Environment_Ceph_Days_NYC_2024","date":"2024-05-22T16:00:00.000Z","updated":"2024-05-22T16:00:00.000Z","comments":true,"path":"2024/05/23/Designing_a_Multitenancy_File_System_for_Cloud_Environment_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/23/Designing_a_Multitenancy_File_System_for_Cloud_Environment_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题： 利用开源分布式存储系统Ceph为云环境构建多租户文件系统 主讲人： Mitch Hall（45 Drives首席架构师）、Brett KY（45 Drives技术总监） 会议内容总结： 项目背景与需求： 一家《财富》100强公司寻求新的云解决方案，用于远程编辑和存储媒体娱乐内容。 需求包括多租户支持、存储分层（HDD和SSD）、弹性扩展、数据加密、自动化管理以及支持NFS、SMB、快照和配额等功能。 主要挑战： 可扩展性： 需要支持数百至数千个多租户工作站。 多租户支持： 文件系统本身不天然支持多租户。 数据加密： 需要实现数据静态加密。 自动化： 需要从零开始开发自动化工具。 文件系统支持： 需要支持多种文件系统功能。 硬件与软件选择： 硬件：45 Drives提供的存储节点和计算节点，每个存储节点配备30个硬盘槽和22个SSD槽。 软件：Rocky Linux作为操作系统，Ceph Octopus作为分布式存储系统，Proxmox v7.1用于虚拟化。 数据隔离与安全： 使用Ceph的RADOS命名空间实现数据隔离，确保每个租户只能访问自己的数据。 通过配置密钥环限制租户访问权限，确保数据安全。 加密与自动化： 使用DM-Crypt和自加密驱动器实现数据加密。 开发自动化脚本和udev规则，确保驱动器在系统启动时正确解锁。 性能测试： 构建了测试环境，使用Filebench进行多种性能测试，包括随机读写、顺序读写和小文件操作。 测试结果显示，虚拟化网关在处理随机IO时性能稳定，且延迟保持在较低水平。 部署与挑战： 在英国的数据中心实际部署时，发现网络配置与预期不符，通过现场调整代码解决了问题。 未来计划： 考虑将虚拟化层替换为容器化，以提高灵活性和效率。 改进多MDS管理，实现更自动化的MDS分配和扩展。 后续行动计划： - 继续优化自动化工具和配置管理。 - 探索容器化解决方案，提高系统灵活性和可管理性。 - 完善MDS管理策略，确保高性能和稳定性。 备注： - 会议中提到的技术细节和工具包括Ceph、Rocky Linux、Proxmox、Samba、Ansible、Terraform等，这些关键词在总结中保留以供参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Practical Business Ceph Examples | Ceph Days NYC 2024","slug":"Practical_Business_Ceph_Examples_Ceph_Days_NYC_2024","date":"2024-05-22T16:00:00.000Z","updated":"2024-05-23T16:00:00.000Z","comments":true,"path":"2024/05/23/Practical_Business_Ceph_Examples_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/23/Practical_Business_Ceph_Examples_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题：SEF在中小型数据中心业务应用的探讨 参会人员：[发言人姓名] 会议时间：[具体日期] 会议地点：[具体地点] 主要议题： SEF的应用误解：发言人指出，SEF（可能是指Ceph）常被误解为仅适用于大型复杂项目，如CERN、Bloomberg或Digital Ocean。实际上，SEF同样适用于中小型数据中心。 中小型数据中心的挑战与需求：讨论了中小型数据中心不需要过多的存储节点和高性能，但低延迟仍然非常重要。 实际应用案例分享： A5亿客户案例：客户使用SEF在OpenVMS集群上运行，对延迟非常敏感，24/7无停机容忍。 Proxmox与SEF结合：在医疗组织中广泛应用，提供稳定的虚拟化环境。 SEF与VMware集成：通过IceKazi和NFS实现SEF与VMware的集成，提供高可用性。 ZFS on SEF：在某些场景下，ZFS与SEF结合使用，提供高效的存储解决方案。 Borg项目：一个数据去重项目，通过SEF实现高效的数据存储。 Kubernetes与SEF集成：通过CSI和Helm Chart实现Kubernetes的持久卷管理。 RGW应用：通过pfSense和HAProxy实现S3兼容的存储解决方案。 决定事项： SEF的广泛适用性：确认SEF不仅适用于大型项目，同样适用于中小型数据中心。 实际应用的验证：通过多个实际案例，验证了SEF在不同业务场景下的有效性和稳定性。 后续行动计划： 进一步推广SEF的应用：通过更多的案例研究和实际部署，推广SEF在中小型数据中心的使用。 技术支持与社区合作：继续加强SEF社区的合作，提供更多的技术支持和资源。 其他备注： 社区合作的重要性：强调了SEF社区在技术支持和资源共享方面的重要性。 技术细节的深入探讨：鼓励对SEF的技术细节进行更深入的探讨和研究。 会议结束语： 发言人感谢大家的参与，并鼓励大家在SEF社区中继续合作和交流，共同推动SEF技术的发展和应用。 注： 本会议纪要基于会议内容总结，保留了部分计算机科学/Ceph相关领域英文原文的关键词，以确保信息的准确性和专业性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph: A Journey to 1 TiB/s | Ceph Days NYC 2024","slug":"Ceph_-_A_Journey_to_1_TiB_s_Ceph_Days_NYC_2024","date":"2024-05-15T16:00:00.000Z","updated":"2024-05-15T16:00:00.000Z","comments":true,"path":"2024/05/16/Ceph_-_A_Journey_to_1_TiB_s_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/16/Ceph_-_A_Journey_to_1_TiB_s_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题： 实现每秒一万亿字节的存储性能之旅 会议时间： 2024年某月某日 参会人员： Seth，以及其他相关技术人员和客户代表 会议内容总结： 项目背景与客户需求： 客户提出一个具有挑战性的使用案例，已初步设计架构，希望得到专业建议。 客户要求硬件必须是Dell品牌，且每个机架最多部署四个节点，共七个机架，以确保故障域隔离。 客户原有集群基于HDD，希望迁移到基于NVMe的集群，且要求零停机时间。 硬件与网络配置： 客户已具备高速网络基础设施，具体细节未透露，但参考了Bloomberg的网络配置。 硬件设计采用了100 GigE网络，测试环境使用的是focal auntu系统。 性能优化与挑战： 通过Numa调优和BIOS设置，以及使用单处理器节点，提高了性能。 发现并解决了多个性能瓶颈，包括C States和IMU的禁用，以及Upstream davan auntu构建问题。 通过单个OSD和节点的测试，逐步排查并解决了性能下降的问题。 测试与结果： 在优化设置后，集群性能显著提升，特别是在320个OSD的配置下实现了线性扩展。 最终在3x复制模式下实现了每秒一万亿字节的读取性能，写入性能虽稍逊，但仍达到了预期目标。 使用Eraser编码时，读取性能受到网络影响较大，但写入性能有所提升。 后续行动计划： 客户将继续优化其应用以充分利用新集群的性能。 社区合作将继续推进，目标是超越现有行业标准，如Vast和DDN W。 决定事项： 确认了硬件配置和网络设置的最佳实践。 确定了性能优化的关键步骤和解决方案。 客户集群成功迁移并开始运行在新的NVMe集群上。 后续行动计划： 继续监控和优化集群性能。 探索进一步的性能提升方法，如改进TCP堆栈。 加强社区合作，共同推动存储技术的进步。 备注： 会议中提到的具体技术和配置细节，如C States、IMU、Eraser编码等，是优化性能的关键技术点，需在后续工作中重点关注和应用。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Designing and Tuning for All-Flash Ceph RBD Storage | Ceph Days NYC 2024","slug":"Designing_and_Tuning_for_All-Flash_Ceph_RBD_Storage_Ceph_Days_NYC_2024","date":"2024-05-14T16:00:00.000Z","updated":"2024-05-14T16:00:00.000Z","comments":true,"path":"2024/05/15/Designing_and_Tuning_for_All-Flash_Ceph_RBD_Storage_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/15/Designing_and_Tuning_for_All-Flash_Ceph_RBD_Storage_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议主题：设计与调优全闪存Ceph RBD存储 主讲人：Tyler 会议概要： 主讲人背景：Tyler来自Bloomberg的计算基础设施团队，负责领导计算基础设施团队，专注于Ceph RBD存储的设计与调优。 公司背景：Bloomberg自2013年开始使用OpenStack和Ceph，设计目标是高密度计算和深度存储。 网络架构：重新设计网络架构，采用基于L3的网络，以解决大规模VM部署中的网络挑战。 性能优化： 内存管理：发现并解决了内存交换问题，通过调整内存目标和深入分析，最终发现是NUMA架构下的内存分配问题。 网络与存储：利用L3网络架构和全闪存存储，实现了无客户影响的升级和维护。 NUMA优化：通过优化NUMA设置，显著降低了上下文切换，提高了性能稳定性。 性能挑战与解决方案： 交换问题：最初通过降低内存目标暂时解决，但最终发现是NUMA配置问题，通过优化NUMA设置解决了问题。 性能波动：通过禁用scrubs和优化网络带宽使用，减少了性能波动。 内核与驱动优化：调整NIC驱动设置，优化了RSS处理，减少了CPU核心的热运行。 CRC32性能：发现并优化了CRC32计算，通过使用更高效的CRC函数，提高了性能。 决定事项： NUMA优化：继续深入研究和优化NUMA设置，以进一步提高性能和稳定性。 CRC32优化：考虑在Ceph中默认使用更高效的CRC32实现。 网络与存储协同：继续利用L3网络架构和全闪存存储的优势，优化维护和升级流程。 后续行动计划： 性能监控：加强性能监控，确保及时发现并解决潜在的性能问题。 社区贡献：将优化经验和发现分享给Ceph社区，特别是关于NUMA和CRC32的优化。 持续优化：持续关注和优化Ceph RBD存储的性能，确保满足高密度计算和深度存储的需求。 关键词： OpenStack Ceph (RBD, OSD, RGW) L3 Networking NUMA CRC32 All-Flash Storage Performance Tuning 结论： 通过深入的性能分析和优化，Bloomberg成功解决了全闪存Ceph RBD存储的性能问题，特别是在内存管理和网络优化方面取得了显著成果。这些经验将为未来的存储优化和社区贡献提供宝贵的参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Diving Deep with Squid | Ceph Days NYC 2024","slug":"Diving_Deep_with_Squid_Ceph_Days_NYC_2024","date":"2024-05-13T16:00:00.000Z","updated":"2024-05-14T16:00:00.000Z","comments":true,"path":"2024/05/14/Diving_Deep_with_Squid_Ceph_Days_NYC_2024/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/14/Diving_Deep_with_Squid_Ceph_Days_NYC_2024/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于分布式存储系统Ceph的更新和未来发展方向的讨论。会议由Josh Durgin和Niha Oja主持，他们在IBM担任管理职务，并长期参与Ceph项目。会议地点在Bloomberg办公室，回顾了2023年的重要成就，并展望了即将发布的Squid版本的新特性。 2023年重要成就 社区活动恢复：在疫情后，Ceph社区成功举办了SEON会议，吸引了约300人参加，并计划在2023年12月在CERN举办下一次会议。 存储规模增长：Ceph管理的存储量达到了一个exabyte，并预计今年将达到1.5 exabytes。 社区参与：社区成员广泛参与Telemetry项目，使得数据收集和分析更加全面。 技术采用：Reef版本成为最受欢迎和广泛使用的版本。 沟通平台：社区迁移到Slack，加强了成员间的沟通和协作。 基金会更新：Ceph基金会引入了新的会员级别，并接管了部分社区管理职责。 Squid版本亮点 性能优化： 引入Elastic Shared Blob，显著降低快照工作负载的延迟和CPU需求。 Blue Store现在默认使用RocksDB LZ4压缩，提高性能并减少空间使用。 效率提升： 改进CRUSH算法，允许更灵活的EC配置。 增加新的CRUSH规则，提高存储系统的可用性和灵活性。 可用性改进： 引入Manager OP Tracker，简化生产环境中Ceph管理的调试。 增强Balancer功能，提供在线平衡能力。 客户端优化： Crimson的读取性能得到显著提升，稳定性增强。 Sea Store获得多项改进，包括多核扩展优化和性能提升。 Telemetry更新： 增加对Crimson运行的识别，收集更多性能指标。 管理工具改进： 增强Ceph Dashboard，提供更直观的管理界面。 改进Ceph Admin (Ceph-ADM)和Rook，简化部署和管理流程。 后续行动计划 发布计划：预计在未来几周内发布Squid版本的候选版本（RC），并邀请社区成员进行测试。 社区参与：鼓励社区成员参与测试和反馈，确保版本的稳定性和质量。 未来活动：计划在CERN举办SEFON会议，期待社区成员的广泛参与。 结论 会议强调了Ceph社区的活跃发展和即将发布的Squid版本的重大改进。通过持续的技术优化和社区合作，Ceph项目将继续推动分布式存储技术的前沿。感谢所有参与者的贡献和支持，期待在未来的活动中再次相聚。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2024-04-17","slug":"Ceph_Developer_Monthly_2024-04-17","date":"2024-05-12T16:00:00.000Z","updated":"2024-05-13T16:00:00.000Z","comments":true,"path":"2024/05/13/Ceph_Developer_Monthly_2024-04-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/05/13/Ceph_Developer_Monthly_2024-04-17/","excerpt":"","text":"会议纪要 会议背景 SEF基金会发起了一项用户调查，旨在收集关于Ceph（SEF）改进的集中反馈。 调查主要关注性能和可用性（包括可消费性）两个领域。 未来可能会根据社区需求增加更多关注领域和相应的调查。 会议目的 讨论并分析从用户调查中收集到的数据。 确定短期和长期内可以采取的行动项。 调查结果概览 调查分为两个主要部分：性能和可用性。 共收到27份回复，涉及多种工作负载和配置。 主要发现包括： 最常见的工作负载是备份和归档、持久容器和Kubernetes。 大多数用户使用复制而非纠删码（EC）。 网络配置和性能要求多样化。 用户对Ceph在非错误状态下的性能评价不一，有的满意，有的提出改进建议。 在错误状态下，用户反馈Ceph在重平衡和恢复方面有所改进，但仍存在一些问题，如RBD镜像速度慢、mclock配置等。 行动计划 将在即将举行的Ceph Day New York上展示调查结果和收集流程。 计划增加更多关注领域和相应的调查，鼓励更多用户参与。 考虑在未来的调查中增加关于SSD、NVMe、HDD使用情况的问题。 探索如何通过社交媒体和活动提高调查的参与度。 计划改进文档和日志记录，以更好地支持用户进行性能调优和故障排查。 后续行动 继续优化调查问卷，确保问题准确无误。 通过各种渠道扩大调查的覆盖范围，包括社交媒体和Ceph社区活动。 与开发团队合作，根据用户反馈优先处理和改进相关功能。 结论 会议强调了用户反馈的重要性，并计划通过持续的调查和改进措施来增强Ceph的用户体验和性能。 鼓励所有与会者在未来的调查中积极参与，并提供反馈，以帮助Ceph社区更好地满足用户需求。 以上是根据会议内容总结的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: Crimson","slug":"Ceph_Code_Walkthroughs_-_Crimson","date":"2024-03-05T16:00:00.000Z","updated":"2024-03-06T16:00:00.000Z","comments":true,"path":"2024/03/06/Ceph_Code_Walkthroughs_-_Crimson/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/03/06/Ceph_Code_Walkthroughs_-_Crimson/","excerpt":"","text":"会议纪要 关键细节 主题: 讨论 Crimson 代码与经典代码的差异，特别是使用 seastar 框架的情况。 参与者: 分布式存储 Ceph 研发人员。 时间: 会议具体时间未提供。 地点: 线上视频会议。 讨论的主要议题 经典代码与 Crimson 代码的比较： 经典代码是同步的，处理请求简单直接。 Crimson 代码使用 seastar 框架，主要使用 Futures 和 Continuation。 Continuation 是 C++ Lambda 表达式，用于在 Future 就绪或被赋值时调用。 Lambda 表达式中的指针对象捕获： 讨论了在 Lambda 表达式中捕获 this 指针的安全性，建议避免捕获 con 和 request 以防止生命周期问题。 消息处理机制： 介绍了 messenger 组件，它是 Ceph 中的通信层，处理不同类型的消息如 mosd_op。 mosd_op 代表 OSD 操作，是实际的 RADOS 操作，包含对象 ID 和一系列操作（如删除、写入等）。 对象上下文 (Object Context)： 对象上下文是一个缓存数据结构，用于跟踪对象的修改状态。 讨论了获取对象上下文的逻辑，包括从缓存中获取或从后端加载。 Crimson 代码的目录结构： Crimson 代码主要位于 Crimson 目录中，是经典 OSD 的替代品。 讨论了在 Crimson 代码中使用的一些特殊宏和适配问题。 客户端请求管道 (Client Request Pipeline)： 介绍了 Crimson 中的客户端请求管道，包括等待地图阶段、活动等待阶段等。 强调了在处理请求时需要满足的依赖条件，如 OSD 地图版本匹配。 错误处理： 讨论了使用 erator 处理非严重错误的情况，确保程序在遇到错误时不会崩溃，而是继续运行并知道如何处理这些错误。 决定的事项 确认了在 Crimson 代码中使用 seastar 框架的必要性和优势。 确定了在处理请求时需要满足的依赖条件，并讨论了如何处理这些条件不满足的情况。 讨论了错误处理的策略，特别是使用 erator 来处理非严重错误。 后续的行动计划 继续优化 Crimson 代码，特别是在错误处理和依赖条件满足方面的逻辑。 深入研究 seastar 框架的使用，确保代码的高效和稳定。 定期审查和更新代码，以保持其与 Ceph 其他部分的兼容性和一致性。 备注 会议中提到了一些技术细节和代码示例，这些内容对于深入理解 Crimson 代码的实现非常重要。 会议强调了代码的可维护性和错误处理的策略，这些都是确保系统稳定运行的关键因素。 以上是根据会议内容总结的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-03-06","slug":"Ceph_RGW_Refactoring_Meeting_2024-03-06","date":"2024-03-05T16:00:00.000Z","updated":"2024-03-06T16:00:00.000Z","comments":true,"path":"2024/03/06/Ceph_RGW_Refactoring_Meeting_2024-03-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/03/06/Ceph_RGW_Refactoring_Meeting_2024-03-06/","excerpt":"","text":"会议纪要 关键细节 会议日期与时间: [具体日期] 参会人员: [列出参会人员] 会议主持: [主持人姓名] 讨论的主要议题 TC 崩溃问题 讨论了关于TC（Transport Client）版本2.8.1的崩溃问题，该问题在三年前被记录，但最近重新出现。 讨论了是否在SEF spec文件中直接处理此问题，而不是依赖于外部repo。 决定在SEF spec文件中拒绝版本2.8及其所有次要版本，以避免潜在的崩溃问题。 Zipper 相关 GCK 想法 Ali提出了关于zipper相关的GCK（Google Summer of Code）项目想法。 讨论了可能的zipper相关项目，并鼓励社区成员如果有任何想法，可以与Ali联系。 Redis 作为消息队列 讨论了使用Redis作为消息队列来替换现有的持久化通知系统。 提出了一些技术挑战和可能的解决方案，包括使用Boost Redis客户端。 DDoP 问题 讨论了在S3对象级别的数据重复问题（DDoP），并介绍了Gabriel编写的一个工具来检测这种重复。 发现某些集群中存在高达25%的重复率，鼓励社区成员使用该工具来评估他们的数据。 通知事件的可见性 讨论了如何提高通知事件的可见性，特别是在事件成功交付时的日志记录。 提出了将日志记录分为子系统的建议，以便更好地管理和监控。 决定的事项 在SEF spec文件中拒绝版本2.8及其所有次要版本，以避免TC崩溃问题。 鼓励社区成员使用Gabriel的工具来检测S3对象级别的重复数据。 将日志记录分为子系统，以提高通知事件的可见性和管理。 后续行动计划 由相关人员提交PR，拒绝SEF spec文件中的版本2.8及其所有次要版本。 社区成员测试Gabriel的工具，并提供反馈。 实施日志子系统分割，以改善通知事件的日志记录。 其他事项 提醒社区成员在即将到来的SEF用户和开发者会议上讨论DDoP工具。 鼓励社区成员思考GCK项目的想法，并与Ali联系。 会议结束 会议在讨论完所有议题后结束，主持人感谢所有参与者的贡献，并期待下次会议。 备注: 本次会议记录涵盖了关键的技术讨论和决策，为后续的行动提供了明确的指导。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-02-21","slug":"Ceph_RGW_Refactoring_Meeting_2023-02-21","date":"2024-02-22T16:00:00.000Z","updated":"2024-02-23T16:00:00.000Z","comments":true,"path":"2024/02/23/Ceph_RGW_Refactoring_Meeting_2023-02-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/02/23/Ceph_RGW_Refactoring_Meeting_2023-02-21/","excerpt":"","text":"会议纪要 议题一：IAM账户功能进展报告 主讲人：Casey 内容概述： 介绍了AWS的IAM服务及其REST API的实现目标。 解释了账户的重要性，以及在SEF中引入账户功能的目的，包括提升服务提供商的扩展性和终端用户的控制能力。 讨论了账户功能与现有租户机制的兼容性，以及如何通过账户功能实现用户和策略的管理。 详细说明了账户功能的技术实现细节，包括资源所有权、权限和策略的管理，以及与现有租户功能的交互。 讨论要点： 账户功能如何与现有租户机制协同工作。 账户功能对现有用户和策略的影响。 账户功能的技术实现细节和潜在的改进点。 决定事项： 需要进一步的代码审查和测试，特别是关于账户功能的实现细节。 确定了账户功能与现有租户机制的兼容性。 后续行动计划： Casey将提供详细的代码审查链接，并寻求团队成员的帮助进行代码审查。 需要进一步讨论和实现关于账户功能的技术细节，特别是与租户机制的交互。 议题二：复制状态头设计讨论 主讲人：Alex 内容概述： 讨论了AWS复制状态头（x-amz-replication-status）的设计和实现。 提出了基于日志修剪（bi-log trimming）的方法来确定对象的复制状态。 讨论了复制状态的四种可能状态：已复制、待处理、失败和完成。 讨论要点： 复制状态头的性能影响和实现细节。 复制状态头与现有复制机制的兼容性。 决定事项： 初步决定采用基于日志修剪的方法来确定复制状态。 需要进一步讨论和测试复制状态头的性能和实现细节。 后续行动计划： 需要进一步的技术讨论和实现细节的确定。 需要进行性能测试，以评估复制状态头的实际影响。 议题三：Kafka客户端库变更解释 主讲人：（未提及） 内容概述： 解释了Kafka客户端库的变更，特别是关于连接错误处理和重试机制的改进。 讨论了变更对非持久性通知的影响。 讨论要点： Kafka客户端库变更的技术细节和影响。 决定事项： 需要进一步的技术讨论和代码审查。 后续行动计划： 需要团队成员在代码审查中提供反馈和建议。 总结 本次会议主要讨论了IAM账户功能的进展、复制状态头的设计以及Kafka客户端库的变更。团队成员对这些议题进行了深入的技术讨论，并确定了后续的行动计划，包括代码审查、性能测试和技术细节的进一步讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-02-14","slug":"Ceph_RGW_Refactoring_Meeting_2024-02-14","date":"2024-02-13T16:00:00.000Z","updated":"2024-02-14T16:00:00.000Z","comments":true,"path":"2024/02/14/Ceph_RGW_Refactoring_Meeting_2024-02-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/02/14/Ceph_RGW_Refactoring_Meeting_2024-02-14/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统IAM策略限制讨论及项目进展更新 与会人员：Ozan、Nicholas（产品团队）、Matt等 会议时间：[具体时间] 会议地点：视频会议 主要议题及讨论内容： IAM策略限制讨论 议题引入：Ozan和Nicholas（产品团队）讨论了将IAM和STS产品化的过程中遇到的IAM策略限制问题。他们注意到AWS对IAM策略有一些限制，如策略长度、角色关联的策略数量等。 当前状况：目前Ceph（SEF）在这些方面没有明确的限制，但考虑到未来可能引入限制，可能会导致兼容性问题。 讨论结果：建议对所有IAM相关元数据设置限制，以避免未来出现问题。决定由Ozan创建一个跟踪器（Tracker）来监控和处理这个问题。 账户实现进展 当前状态：账户功能的实现已基本完成，但尚未进行代码审查和测试。 后续行动：计划进行代码审查和测试，并可能进行代码走查（code walkthrough）以加速审查过程。 对象完整性功能更新 当前工作：Matt正在开发对象完整性功能，重点关注多部分上传（multipart uploads）的API覆盖。 讨论结果：决定继续完善该功能，特别是解决多部分上传的相关问题。 Squid版本代码冻结通知 冻结时间：代码冻结将于本周五进行，之后所有新功能和修复需要通过主干（Main）合并并进行回溯（backport）。 重要事项：包括校验和功能和主题元数据迁移等关键功能需要在冻结前完成。 多站点测试和复制头更新 当前工作：正在进行Squid版本的负载测试，并引入新的复制头（X-Replicated-At）以满足特定需求。 讨论结果：该功能将作为Squid版本的一部分，并可能在未来版本中进一步讨论和完善。 决定事项： 创建一个跟踪器来监控和处理IAM策略限制问题。 进行账户功能的代码审查和测试，并可能进行代码走查。 继续完善对象完整性功能，特别是多部分上传的API覆盖。 确保关键功能在Squid版本代码冻结前完成。 引入新的复制头（X-Replicated-At）并计划在Squid版本中使用。 后续行动计划： Ozan将创建一个跟踪器来监控IAM策略限制问题。 进行账户功能的代码审查和测试，并准备代码走查。 Matt将继续与团队合作，完善对象完整性功能。 确保所有关键功能在Squid版本代码冻结前完成。 进一步讨论和完善多站点测试和复制头功能。 会议结束： 感谢所有与会者的参与，下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2024-02-07","slug":"Ceph_Developer_Monthly_2024-02-07","date":"2024-02-12T16:00:00.000Z","updated":"2024-02-13T16:00:00.000Z","comments":true,"path":"2024/02/13/Ceph_Developer_Monthly_2024-02-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/02/13/Ceph_Developer_Monthly_2024-02-07/","excerpt":"","text":"会议纪要 会议主题：S Dev 月度会议 日期：[具体日期] 参会人员：[具体人员名单] 会议议程： PR审查请求 - Pon的链接PR，关于monit monitor manager不输出Network ping stats。 NVMe TCP Gateway - 介绍NVMe-oF（非易失性内存快速）及其高可用性解决方案。 PR审查请求 - Pon的PR，关于monit monitor manager不输出Network ping stats的后续讨论。 端到端追踪 - Yal的PR，关于端到端追踪功能的实现和测试。 讨论内容： PR审查请求 - monit monitor manager不输出Network ping stats Pon提出了一个PR，请求审查关于monit monitor manager不输出Network ping stats的改动。 讨论了该PR的动机和潜在影响，特别是对现有脚本和API的兼容性问题。 决定在下一个主要版本中进行此改动，并更新发布说明。 NVMe TCP Gateway 介绍了NVMe-oF的基本概念和其在Ceph中的应用。 讨论了NVMe-oF的高可用性解决方案，包括Gateway Group和自动故障转移机制。 展示了如何在Ceph中实现NVMe-oF的高可用性，并讨论了未来的发展方向。 PR审查请求 - monit monitor manager不输出Network ping stats（后续讨论） 进一步讨论了该PR的影响和是否需要添加配置选项以保留网络ping统计信息。 决定先解决主要问题，后续再考虑添加配置选项。 端到端追踪 Yal介绍了端到端追踪功能的PR，并请求帮助审查测试结果。 讨论了该功能的测试情况和未来的推广计划。 决定将此功能作为Squid版本的阻塞项，并确保测试结果的审查。 决定事项： 批准Pon的PR，关于monit monitor manager不输出Network ping stats的改动，并更新发布说明。 确认NVMe-oF的高可用性解决方案，并计划在未来版本中实现生产就绪。 将端到端追踪功能作为Squid版本的阻塞项，并确保测试结果的审查。 后续行动计划： Pon将发送邮件通知社区关于monit monitor manager改动的情况。 Yal将更新PR，添加性能测试结果的链接，并确保测试结果的审查。 继续推进NVMe-oF的高可用性解决方案的开发和测试。 会议总结： 本次会议讨论了多个关键的技术议题，包括NVMe-oF的高可用性解决方案和端到端追踪功能的实现。通过详细的讨论和审查，确定了各个议题的后续行动计划，并确保了技术决策的透明性和社区的参与度。感谢所有参会人员的积极参与和贡献。 下一步： 继续推进各个议题的开发和测试工作。 确保所有改动和功能符合社区的需求和期望。 定期更新社区关于项目进展和决策的情况。 会议结束：感谢大家的参与，祝大家有美好的一天！","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-01-31","slug":"Ceph_RGW_Refactoring_Meeting_2024-01-31","date":"2024-01-31T16:00:00.000Z","updated":"2024-02-01T16:00:00.000Z","comments":true,"path":"2024/02/01/Ceph_RGW_Refactoring_Meeting_2024-01-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/02/01/Ceph_RGW_Refactoring_Meeting_2024-01-31/","excerpt":"","text":"会议纪要 会议主题：分布式存储系统中的持久化通知问题讨论 参会人员：Ceph研发团队成员 会议时间：[具体时间] 会议地点：视频会议 会议议程： 持久化通知问题的讨论 代码冻结计划的调整 其他议题 会议内容： 1. 持久化通知问题的讨论 问题背景：在非持久化通知的实现中，存在一个问题，即当消息代理（broker）宕机或用户错误配置代理地址时，持久化通知队列会不断增长，事件永久保留。 现有解决方案：引入了两个变量——生存时间（Time to Live, TTL）和最大重试次数（Max Retry），默认设置为零，意味着事件将永久保留。同时，允许在创建主题（create topic）时设置这些值。 讨论焦点：是否应该允许用户在创建主题时设置这些值，以及如何处理用户设置与管理员设置之间的优先级关系。 提议：建议通过配置标志（con flag）来控制这些属性的可见性和优先级，以便管理员设置的值具有更高优先级。 共识：支持通过配置选项来支持两种模式，即允许用户配置或由存储管理员决定。 后续行动：将撰写详细设计文档，并在Tracker中记录相关信息。 2. 代码冻结计划的调整 原计划：原计划在1月底进行代码冻结，创建squid分支。 调整：经过讨论，决定将代码冻结推迟一周，以便其他组件有更多时间准备。 后续行动：将继续关注Matt、kol、yal和Ali的工作进展，确保相关功能在代码冻结前准备就绪。 3. 其他议题 PR合并：讨论了多个分支上的PR合并问题，计划在squid分支创建后，开始将内容合并到主分支（Main），并在准备就绪后进行回溯合并（backport）。 依赖项：提及了等待Neo rados chain的更新，以便在gate admin级别使用站点配置（site config）。 决定事项： 持久化通知问题的解决方案将通过配置选项来实现，允许用户或存储管理员决定TTL和Max Retry的值。 代码冻结计划推迟一周，以确保所有组件准备就绪。 后续行动计划： 撰写详细设计文档，并在Tracker中记录持久化通知问题的解决方案。 继续关注并整合各个PR，确保在代码冻结前所有功能准备就绪。 在squid分支创建后，开始将内容合并到主分支，并在准备就绪后进行回溯合并。 会议结束： 感谢所有参会人员，会议结束。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-01-24","slug":"Ceph_RGW_Refactoring_Meeting_2024-01-24","date":"2024-01-23T16:00:00.000Z","updated":"2024-01-24T16:00:00.000Z","comments":true,"path":"2024/01/24/Ceph_RGW_Refactoring_Meeting_2024-01-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/01/24/Ceph_RGW_Refactoring_Meeting_2024-01-24/","excerpt":"","text":"会议纪要 会议主题： 用户对Topic的授权问题 Topic迁移问题 讨论内容： 1. 用户对Topic的授权问题 问题描述：当前系统中，任何用户都可以覆盖其他用户的Topic，没有进行用户身份验证。 解决方案： 引入全局配置参数，当没有设置策略时，不进行任何策略检查。 建议保持向后兼容性，通过文档说明用户需要设置策略以防止这种情况。 对于新系统，可以设置全局标志为true，强制执行正确的授权行为。 对于Topic的创建，无论全局标志如何，只要用户存在，就进行策略检查。 对于发布权限，依赖全局参数，默认允许发布，但管理员可以更改标志以强制执行发布策略。 决定事项： 对于Topic的创建和覆盖，进行严格的策略检查。 发布权限依赖全局参数，默认允许发布。 需要编写详细的发布说明，以通知用户这一变更。 2. Topic迁移问题 问题描述：讨论是否在rgw启动或领域重载时进行迁移，还是作为外部工具进行。 解决方案： 建议在启动时进行迁移，以减少对用户的影响。 对于通知迁移，建议懒惰迁移，即在访问时进行迁移。 需要处理多站点配置中的元数据一致性问题。 决定事项： 在启动时进行Topic迁移。 对于通知迁移，采用懒惰迁移策略，并在元数据主站点进行。 需要构建迁移逻辑以容忍现有的元数据，避免冲突。 后续行动计划： 编写详细的发布说明，通知用户关于Topic授权和迁移的变更。 更新现有Tracker问题，根据讨论结果调整PR。 考虑构建一个外部工具，帮助用户在升级前手动同步非主站点的Topic和通知配置。 会议总结： 会议讨论了关于Topic授权和迁移的两个主要问题，并就如何保持向后兼容性、如何进行迁移以及如何处理多站点配置中的元数据一致性问题达成了共识。后续将根据会议决定编写发布说明，并考虑构建外部工具以帮助用户进行迁移。 参会人员：[参会人员名单] 会议时间：[会议日期和时间] 会议记录人：[记录人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User + Dev Monthly 2023-11-16","slug":"Ceph_User_+_Dev_Monthly_2023-11-16","date":"2024-01-22T16:00:00.000Z","updated":"2024-01-23T16:00:00.000Z","comments":true,"path":"2024/01/23/Ceph_User_+_Dev_Monthly_2023-11-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/01/23/Ceph_User_+_Dev_Monthly_2023-11-16/","excerpt":"","text":"会议纪要 会议概要 本次用户开发会议由Zach Dober主持，原计划由Christian TOA主持的议题因故推迟。Zach Dober作为Upstream SEF文档负责人，介绍了即将完成的《Ceph入门指南》及其相关工作。 讨论主要议题 《Ceph入门指南》概述： Zach Dober介绍了该指南的目标，旨在为完全不了解Ceph的新手提供一个不超过五分钟阅读时间的简介。 指南将包含Ceph的基本概念，但不深入技术细节，旨在提供准确的基础信息，并引导读者进一步深入学习。 文档编辑与反馈： Zach分享了指南的初步文本，并邀请与会者在Etherpad上提供反馈和建议。 讨论了文档中应包含的关键内容，如存储池、放置组、仲裁等概念的明确解释。 Ceph组件与架构： 讨论了Ceph的不同存储类型（对象存储、块存储、文件存储）及其适用场景。 强调了Ceph集群中各组件（如OSD、Monitor、RGW、Dashboard等）的角色和重要性。 硬件要求与推荐： 讨论了Ceph部署的硬件规格，包括RAM、存储设备等，以及如何在不推荐特定硬件的情况下提供硬件配置的指导。 社区反馈与建议： 与会者提出了关于文档内容的具体建议，包括增加对Ceph不同组件的描述、提供高层次的架构图等。 Zach鼓励社区成员提供反馈，以便不断改进文档。 决定事项 《Ceph入门指南》将继续接受社区的反馈和建议，以确保内容的准确性和实用性。 将考虑增加一个高层次的架构图，以帮助新手更好地理解Ceph的组件和它们之间的关系。 后续行动计划 Zach Dober将继续收集和整合社区的反馈，对《Ceph入门指南》进行修订。 计划在未来增加一个“试驾文档”，详细介绍如何在实际运行中的Ceph集群上进行操作。 将持续更新和完善Ceph的硬件推荐文档，以提供更具体的硬件配置建议。 其他备注 会议记录将被保存，供未能参加会议的成员回顾。 Zach Dober鼓励社区成员继续通过Etherpad提供反馈，以帮助改进Ceph的文档和社区支持。 本次会议为Ceph社区提供了一个交流和改进文档的平台，确保Ceph的入门和使用更加顺畅和高效。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User + Dev Monthly 2024-01-18","slug":"Ceph_User_+_Dev_Monthly_2024-01-18","date":"2024-01-21T16:00:00.000Z","updated":"2024-01-22T16:00:00.000Z","comments":true,"path":"2024/01/22/Ceph_User_+_Dev_Monthly_2024-01-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/01/22/Ceph_User_+_Dev_Monthly_2024-01-18/","excerpt":"","text":"会议纪要 会议概要 本次用户开发会议邀请了来自国家太阳能天文台的SEF操作员Joel Davido，他提出了一项关于在对象存储中使用磁带作为存储类的功能请求。会议中，Joel详细介绍了该请求的背景、优势、潜在用途以及当前的技术选项，并讨论了可能的实施方案和面临的挑战。 主要议题 背景介绍： Joel介绍了DEIS项目，特别是Daniel K. Inouye太阳望远镜，这是一个位于夏威夷的4米口径太阳望远镜，收集的数据通过Globus传输到位于Boulder的数据中心，存储在S3桶中，并最终存档在AWS Glacier。 功能请求： 请求在Ceph中添加一个由磁带支持的服务，类似于AWS Glacier，以实现长期数据存储和降低成本。 优势与用途： 磁带存储可以减少存储成本、空间利用、电力消耗和冷却负荷，主要用于长期存档和防止勒索软件攻击。 当前技术选项： 讨论了几种第三方应用程序和方法，如Spectra Logic的Black Pearl和StoreCycle，以及Nodiam的产品，但各有优缺点。 期望的功能： 需要原生集成、透明媒体转换、避免单点故障、程序化管理S3请求等功能。 实施方案讨论： 提出了使用S3生命周期管理、Glacier API等方法，以及可能的实施步骤和挑战。 决定事项 会议决定创建一个跟踪器票证，以跟踪该功能的进展和未来开发。 后续行动计划 创建一个跟踪器票证，详细记录功能请求和相关讨论。 分解票证为更小的任务，以便逐步实现。 继续讨论和探索实施细节，特别是关于S3生命周期管理和Glacier API的集成。 其他备注 会议记录将被上传到档案，并与跟踪器票证链接，以便后续参考和跟进。 本次会议为Ceph社区提供了一个讨论和探索磁带存储在对象存储中应用的平台，有助于推动相关技术的进步和应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2024-01-03","slug":"Ceph_RGW_Refactoring_Meeting_2024-01-03","date":"2024-01-04T16:00:00.000Z","updated":"2024-01-05T16:00:00.000Z","comments":true,"path":"2024/01/05/Ceph_RGW_Refactoring_Meeting_2024-01-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2024/01/05/Ceph_RGW_Refactoring_Meeting_2024-01-03/","excerpt":"","text":"会议纪要 会议概要 日期: 新年伊始 参与者: 团队成员 议题: 讨论关于同步主题和通知的工作，以及非持久性通知的问题 讨论主要议题 同步主题和通知的工作 负责人: Kunal 问题描述: 讨论了关于如何更新和管理使用特定主题的桶列表（OMap）的问题。具体涉及如何确保在多个区域同步更新时的原子性和一致性。 讨论点: 如何处理OMap的更新，特别是在多个区域可能同时尝试更新同一个OMap对象时。 讨论了元数据同步的机制，以及如何在主区域和次区域之间保持一致性。 提出了关于级联删除和更新的功能需求，以及如何在不影响系统性能的情况下实现这些功能。 非持久性通知的问题 问题描述: 讨论了非持久性通知的使用场景和当前实现中存在的问题，特别是在消息代理不可用时的处理方式。 讨论点: 如何改进非持久性通知的实现，以确保在消息代理不可用时能够及时返回错误给客户端。 讨论了在同步通知模式下，如何处理超时和错误传播的问题。 决定事项 OMap更新问题: 需要进一步讨论和明确如何在多个区域同步更新OMap时的原子性和一致性问题。 非持久性通知改进: 决定改进非持久性通知的实现，以更好地处理消息代理不可用的情况，并确保及时返回错误给客户端。 后续行动计划 OMap更新问题: 继续讨论和明确OMap更新的原子性和一致性问题。 跟进Kunal的工作，确保相关功能的实现符合预期。 非持久性通知改进: 实施改进措施，确保非持久性通知在消息代理不可用时能够及时返回错误。 进行代码审查和测试，确保改进后的功能稳定可靠。 其他事项 会议中还讨论了关于级联删除和更新的功能需求，以及如何在不影响系统性能的情况下实现这些功能。 需要进一步讨论和明确这些功能的实现细节，并在后续的PR讨论中继续跟进。 会议结束 会议在讨论完所有议题后结束，团队成员将在下次会议中继续跟进相关问题。 以上是对会议内容的总结，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2023-12-06","slug":"Ceph_Developer_Monthly_2023-12-06","date":"2023-12-12T16:00:00.000Z","updated":"2023-12-13T16:00:00.000Z","comments":true,"path":"2023/12/13/Ceph_Developer_Monthly_2023-12-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/12/13/Ceph_Developer_Monthly_2023-12-06/","excerpt":"","text":"会议纪要 会议主题： Ceph Manager模块加载问题讨论 参会人员： Ilia, Gas, Ramina, Radic, Patrick, Travis 会议时间： [未提供具体时间] 会议地点： 视频会议 会议内容总结： 问题描述： 当Ceph Manager启动时，所有Manager模块类会被加载，命令会被发现。命令的发现和命令注册的过程是分开的，从加载模块到启动解释器的过程是异步的。 当Manager接收到一个命令时，虽然知道命令存在，但模块可能尚未加载完成，导致错误。 讨论议题： 错误处理： 讨论了客户端在Manager模块未完全加载时接收到的错误信息，以及如何处理这些错误。 模块加载同步性： 讨论了是否应该让模块加载过程同步，并在模块完全加载后再执行相关命令。 可用性标志（available flag）： 讨论了Manager Map中的可用性标志的实际意义和如何改进其使用。 决定事项： 模块加载策略： 决定重新审视Mola的修复方案，考虑在Manager响应后异步加载Python模块，并延迟设置可用性标志，直到所有模块加载完成。 客户端等待机制： 决定客户端在执行命令前应检查模块是否真正可用，并在Manager Map中等待可用状态。 后续行动计划： 实施细节讨论： 需要进一步讨论具体的实施细节，包括是否修复现有的可用性标志或添加新的标志。 征求反馈： 需要将讨论结果总结并征求Patrick和Travis的反馈，特别是关于Manager Map的使用和外部用户的兼容性问题。 文档更新： 需要更新文档，明确Manager模块启用命令的异步性质，并指导用户如何正确等待模块可用。 会议结束： 会议在讨论完所有议题后结束，未有新的议题提出。 备注： 由于部分关键人员（如Patrick和n）未参会，会议决定在后续的PR评论中征求他们的意见，并确保所有相关方都了解并同意最终的实施方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-12-13","slug":"Ceph_RGW_Refactoring_Meeting_2023-12-13","date":"2023-12-12T16:00:00.000Z","updated":"2023-12-13T16:00:00.000Z","comments":true,"path":"2023/12/13/Ceph_RGW_Refactoring_Meeting_2023-12-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/12/13/Ceph_RGW_Refactoring_Meeting_2023-12-13/","excerpt":"","text":"会议纪要 会议议题 Bucket Notification 和 Multi-Site 支持 主要讨论：关于 Bucket Notification V2 的实现和 Multi-Site 功能的支持。 决定事项： 将功能标志从“notification syncing”重命名为“notification V2”，以避免混淆。 确认功能标志为全局标志，而不是每个区域的标志。 后续行动： 修改功能标志名称。 继续测试和合并当前的 PR，以便开始迁移路径的实现。 生命周期过期和删除标记 主要讨论：在多站点设置中，生命周期过期操作在版本控制桶中的问题。 决定事项： 确认问题源于多站点之间的删除标记版本ID不一致。 后续行动： 研究并实现一种策略，确保在多站点环境中删除标记的一致性。 多站点测试失败 主要讨论：多站点测试中的崩溃问题。 决定事项： 确认问题与 PR 中的更改有关，具体是关于 RGW RADOS 处理程序的使用。 后续行动： 团队成员将共同研究问题，考虑是否需要回退 PR 或寻找其他解决方案。 角色所有权和账户工作进展 主要讨论：角色所有权与账户概念的关系，以及权限模型的设计。 决定事项： 确认角色应由账户拥有，而不是单个用户。 讨论了权限模型的设计，特别是关于 admin caps 的使用。 后续行动： 重新审视和修订角色权限的使用流程。 测试账户功能的进展，并考虑如何整合到现有工作流程中。 总结 本次会议主要讨论了关于 Ceph 存储系统中 Bucket Notification、生命周期管理、多站点测试以及角色所有权和账户功能的设计和实现问题。通过详细的讨论，团队对每个议题都有了明确的行动计划和后续步骤。会议强调了代码和功能的清晰性和一致性，以及在设计和实现过程中考虑迁移和兼容性的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-11-29","slug":"Ceph_RGW_Refactoring_Meeting_2023-11-29","date":"2023-11-28T16:00:00.000Z","updated":"2023-11-29T16:00:00.000Z","comments":true,"path":"2023/11/29/Ceph_RGW_Refactoring_Meeting_2023-11-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/11/29/Ceph_RGW_Refactoring_Meeting_2023-11-29/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统中的HTTP通信优化与Lua集成 参会人员：Matt, Casey, Jane, 以及其他相关研发人员 会议日期：[具体日期] 会议地点：视频会议 会议内容总结： HTTP通信优化讨论 议题介绍：Matt介绍了如何优化HTTP通信以使其更加健壮的议题。讨论了Mark的测试工作，但强调了需要更全面的审查和测试覆盖。 主要讨论点： Casey提出了对Mark的PR（Pull Request）进行重试的测试覆盖不足的担忧。 讨论了多站点功能测试的不稳定性，建议通过改进测试基础设施来解决。 提出了在本地和toothylogy环境中运行测试的策略，以验证PR的功能。 决定事项： Jane将添加评论到PR中，指导测试文件的位置和一般策略。 计划在本地测试环境中使用Mstart进行初步测试，并在toothylogy环境中进行后续验证。 Lua集成讨论 议题介绍：讨论了如何更好地集成Lua脚本与HTTP头信息的暴露问题。 主要讨论点： 讨论了当前Lua绑定中HTTP头信息的暴露方式存在的问题，如命名混乱和安全性问题。 提出了重新组织Lua API的建议，以提供更清晰和安全的访问方式。 决定事项： 决定采用统一的接口来访问所有HTTP头信息，同时考虑安全性和稳定性。 计划对现有的Lua绑定进行清理和优化，以提供更稳定的API。 LDAP的弃用讨论 议题介绍：讨论了弃用LDAP作为独立认证机制的可能性，建议使用STS（Security Token Service）来替代。 主要讨论点： 讨论了如何通知用户并提供迁移指南。 决定事项： 计划在下一个主要版本（如Squid）中宣布LDAP的弃用，并提供详细的迁移指南。 后续行动计划： HTTP通信优化： Jane将添加测试指导到PR中，并开始在本地环境中进行测试。 继续改进多站点测试基础设施，以提高测试的稳定性和可靠性。 Lua集成： 对现有的Lua绑定进行清理和优化，确保API的稳定性和安全性。 提供统一的接口来访问HTTP头信息。 LDAP弃用： 创建跟踪问题以准备LDAP弃用的文档和迁移指南。 在下一次主要版本发布时宣布LDAP的弃用。 会议结束： 会议在讨论完所有议题后结束，感谢所有参与者的贡献和讨论。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-11-22","slug":"Ceph_RGW_Refactoring_Meeting_2023-11-22","date":"2023-11-27T16:00:00.000Z","updated":"2023-11-28T16:00:00.000Z","comments":true,"path":"2023/11/28/Ceph_RGW_Refactoring_Meeting_2023-11-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/11/28/Ceph_RGW_Refactoring_Meeting_2023-11-22/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： Jane的多站点重试PR讨论 由于Jane在感恩节假期期间不在，会议决定将此议题推迟至下周讨论。 用户账户PR进展 会议中提供了用户账户PR的链接，并分解了一个详细的待办事项列表。欢迎团队成员参与工作分配、测试或代码审查。 Ceph对象加密测试 Marcus正在准备测试Ceph对象加密。会议中讨论了关于AIO Completion Pusher的测试想法，特别是如何在不阻塞的情况下处理AO Completion和可选的yield。 数据日志推送的异步处理 讨论了如何实现数据日志推送的异步处理，包括批处理机制和如何将单个条目转换为异步处理。建议在数据日志内部处理批处理逻辑，并通过数据日志接口传递向量。 决定事项： Jane的多站点重试PR将在下周进行详细讨论。 用户账户PR的工作分配和测试将继续进行，欢迎团队成员参与。 数据日志推送的异步处理将在PR中提出初步设计想法，后续进行改进。 后续行动计划： 下周会议将重新讨论Jane的多站点重试PR。 团队成员应查看用户账户PR的待办事项列表，并参与相关工作。 Marcus将继续准备Ceph对象加密的测试，并探索AIO Completion Pusher的测试方法。 数据日志推送的异步处理将在PR中提出初步设计，并进行后续讨论和改进。 其他事项： 对于庆祝感恩节的团队成员，会议结束时表达了节日的祝福。 会议结束时间：[具体时间] 以上是本次会议的详细纪要，涵盖了会议的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-10-25","slug":"Ceph_RGW_Refactoring_Meeting_2023-10-25","date":"2023-11-19T16:00:00.000Z","updated":"2023-11-20T16:00:00.000Z","comments":true,"path":"2023/11/20/Ceph_RGW_Refactoring_Meeting_2023-10-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/11/20/Ceph_RGW_Refactoring_Meeting_2023-10-25/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储中IAM的未来方向讨论 与会人员：Kyle等 会议时间：具体日期未提及 主要议题： IAM的未来方向：Kyle介绍了IAM的未来发展方向，特别是在账户设计方面。他提到了一些现有的IAM系统中的差距，并提出了改进的建议。 账户所有权和使用会计：讨论了如何处理IAM设置中的OIDC提供者和策略，以及如何归属使用情况。提出了根账户的概念，其中根账户是唯一具有所有权概念的主体。 账户和用户的统计数据：讨论了账户级别的统计数据和配额管理，以及如何处理多用户共享资源的情况。 账户层次结构：探讨了账户之间的层次关系，以及如何通过组织单位（OU）来管理账户和配额。 配额管理：讨论了配额的设置和管理，包括如何在账户级别和用户级别进行配额管理。 决定事项： 账户所有权：决定所有权的归属将归于根账户，而不是用户。 使用会计和配额：决定在账户级别进行使用会计和配额管理，而不是在用户级别。 账户层次结构：初步探讨了账户层次结构的可能性，但尚未形成具体决策。 后续行动计划： 更新设计文档：Kyle将根据会议讨论的结果更新设计文档。 进一步探讨配额管理：需要进一步探讨如何在账户和用户级别进行更细粒度的配额管理。 研究账户层次结构：需要研究AWS中账户层次结构的实现，以及如何在Ceph中应用。 其他讨论点： 用户名和密码：讨论了与账户恢复相关的用户名和密码概念。 账户和用户的关系：解释了账户如何将Swift用户和S3用户整合在一起，以及账户如何管理配额和IAM策略。 结论： 会议对IAM的未来方向、账户所有权、使用会计、配额管理和账户层次结构进行了深入讨论，并形成了初步的决策和后续行动计划。需要进一步的工作来细化这些决策并实现它们。 以上是根据会议内容总结的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-11-08","slug":"Ceph_RGW_Refactoring_Meeting_2023-11-08","date":"2023-11-19T16:00:00.000Z","updated":"2023-11-20T16:00:00.000Z","comments":true,"path":"2023/11/20/Ceph_RGW_Refactoring_Meeting_2023-11-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/11/20/Ceph_RGW_Refactoring_Meeting_2023-11-08/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统中librdkafka库的问题讨论与解决方案 参会人员：Ceph研发团队成员 会议时间：[具体日期] 会议地点：视频会议 主要议题： librdkafka库存在的问题 当前使用的librdkafka库版本较旧，存在多个问题，包括崩溃问题和功能缺失。 崩溃问题与librdkafka库中的定义不匹配有关，该问题已在较新版本中修复。 功能缺失包括无法将证书颁发机构（CA）作为字符串传递，以及客户端无法绕过服务器证书检查。 解决方案讨论 讨论了将librdkafka作为子模块（submodule）引入Ceph项目的可行性。 决定采用静态链接方式解决动态链接可能带来的问题。 需要确保子模块的使用是临时的，并计划向CentOS和Ubuntu提交bug报告，要求更新librdkafka版本。 后续行动计划 添加librdkafka作为子模块，并确保提交消息中包含子模块名称以获得批准。 向CentOS和Ubuntu提交bug报告，请求更新librdkafka版本。 监控子模块的使用情况，评估是否需要长期保留。 其他讨论： Kraken的提问：关于在单个RADOS对象中存储所有主题（topics）的问题，讨论了数据模型改进的必要性和潜在的迁移成本。 Ali的工作：关于配置管理和部署的讨论，计划在下次会议中进一步讨论。 Kraken的另一个问题：关于使用Web Identity进行STS（Security Token Service）角色假设时遇到的问题，建议创建Tracker bug并寻求专家帮助。 会议总结： 会议主要解决了Ceph项目中librdkafka库的版本问题和功能缺失，决定采用子模块方式并静态链接解决现有问题。同时，讨论了数据模型改进的必要性和潜在的迁移成本，并计划在后续工作中进一步处理。对于Web Identity的问题，建议创建Tracker bug并寻求专家帮助。 后续行动： 实施librdkafka子模块的添加和静态链接。 提交bug报告，请求更新librdkafka版本。 监控子模块使用情况，评估长期保留的必要性。 创建Tracker bug，解决Web Identity问题。 下次会议预告： 讨论Standalone部署的编排问题和配置管理。 会议结束： 感谢所有参会人员的积极参与和贡献，会议于[具体时间]结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-11-15","slug":"Ceph_RGW_Refactoring_Meeting_2023-11-15","date":"2023-11-19T16:00:00.000Z","updated":"2023-11-20T16:00:00.000Z","comments":true,"path":"2023/11/20/Ceph_RGW_Refactoring_Meeting_2023-11-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/11/20/Ceph_RGW_Refactoring_Meeting_2023-11-15/","excerpt":"","text":"会议纪要 会议概览 本次会议主要讨论了Ceph分布式存储系统中的多个技术议题，包括通知数据模型的更新、生命周期与复制、动态重分片以及配置初始化等问题。会议涉及了技术细节的讨论、解决方案的提出以及后续行动计划的制定。 主要议题与讨论 通知数据模型的更新 讨论内容：讨论了多站点通知数据模型的更新，特别是从旧数据模型迁移到新数据模型的策略。提出了多种迁移方案，包括支持两种数据模型的代码路径、迁移过程的自动化等。 决定事项：建议在升级完成后进行迁移，使用新的区域组特性来全局启用新格式，并在迁移过程中发出警告以确保管理员注意到旧配置的使用。 后续行动：将详细讨论和更新记录在Gist中，并考虑在Slack频道中进一步讨论。 生命周期与复制 讨论内容：探讨了生命周期事件日志记录的问题，特别是对象版本化带来的挑战。讨论了是否应停止对非版本化桶的日志记录。 决定事项：建议首先停止对非版本化桶的日志记录，并考虑增加智能生命周期规则以根据版本化状态进行不同的日志记录。 后续行动：Jan将接手此问题，并进一步探讨解决方案。 动态重分片 讨论内容：讨论了动态重分片中减少分片数量的需求，提出了在重分片队列中添加时间戳以延迟执行的方案。 决定事项：建议通过配置选项来控制时间延迟和分片因子，并考虑在桶创建API中添加分片计数字段。 后续行动：Eric将继续探讨此方案，并在后续会议中进一步讨论。 配置初始化 讨论内容：讨论了如何在区域创建时初始化存储过滤器的配置，以及JSON配置的具体格式。 决定事项：建议使用标准JSON字段“type”来加载相应的驱动程序，并递归解析JSON块。 后续行动：Ali将继续进行相关开发工作，并考虑在后续PR中进行合并。 后续行动计划 更新和记录通知数据模型的讨论细节，并在Slack频道中进一步讨论。 Jan接手生命周期与复制问题的解决方案探讨。 Eric继续探讨动态重分片方案，并在后续会议中讨论。 Ali继续进行配置初始化的开发工作，并考虑在后续PR中进行合并。 其他事项 提醒与会者加入Slack频道，以便更好地讨论开发相关事宜。 下次会议时间：下周。 本次会议记录涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的完整性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User + Dev Monthly 2022-06-01","slug":"Ceph_User_+_Dev_Monthly_2022-06-01","date":"2023-10-22T16:00:00.000Z","updated":"2023-10-23T16:00:00.000Z","comments":true,"path":"2023/10/23/Ceph_User_+_Dev_Monthly_2022-06-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/23/Ceph_User_+_Dev_Monthly_2022-06-01/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统的优化与管理 主讲人：Joshua Bergen &amp; Pedro 会议时间：[具体日期] 会议地点：在线会议 主要内容： Joshua Bergen的演讲：PG Remapper工具介绍 背景介绍：Joshua Bergen是DigitalOcean的Fleet Storage团队的技术负责人，介绍了他们开发的PG Remapper工具，该工具旨在解决Ceph内部与回填（backfill）相关的问题。 问题描述：详细讨论了在Ceph集群中添加新主机时遇到的回填并发问题，包括回填源过载、等待恢复、降级回填等问题。 解决方案：PG Remapper通过控制upmap异常表来管理回填，提供了诸如drain、cancel backfill、undo upmaps等命令，以优化回填过程，避免降级状态。 未来展望：提出了一些改进Ceph代码库的建议，如改进回填并发管理、增加回填源的预订机制等。 Pedro的演讲：Ceph Dashboard的新功能 功能介绍：Pedro展示了Ceph Dashboard中新增的文件系统、卷组和子卷管理功能，包括创建、编辑和删除操作。 操作演示：详细演示了如何在Dashboard中进行文件系统、子卷和子卷组的管理，以及如何处理快照。 未来计划：计划增加快照的创建、编辑和删除功能，以及改进快照的列表显示，同时考虑实现镜像管理功能。 讨论与反馈： PG Remapper的使用与集成：讨论了PG Remapper与Ceph内部平衡器（balancer）的集成问题，以及如何避免在回填过程中出现OSD过载的情况。 Ceph版本更新与支持：提到了Ceph的版本更新计划，包括即将发布的17.2.7版本和后续的18.2.1及16.2.15版本，并呼吁社区成员对Pacific版本的PR进行关注和测试。 后续行动计划： 社区参与：鼓励社区成员在Ceph的Upstream Slack频道和用户邮件列表中提供反馈和讨论。 版本更新跟踪：建议社区成员关注并参与即将发布的Ceph版本的测试和PR审核。 会议总结： 本次会议通过两位专家的详细介绍和演示，展示了Ceph在存储管理和优化方面的新工具和新功能，同时也强调了社区参与和版本更新的重要性。感谢所有参与者的积极讨论和反馈，期待未来更多的技术分享和社区合作。 备注：以上内容为会议纪要，详细的技术细节和操作步骤请参考会议录像和相关文档。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-10-18","slug":"Ceph_RGW_Refactoring_Meeting_2023-10-18","date":"2023-10-17T16:00:00.000Z","updated":"2023-10-18T16:00:00.000Z","comments":true,"path":"2023/10/18/Ceph_RGW_Refactoring_Meeting_2023-10-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/18/Ceph_RGW_Refactoring_Meeting_2023-10-18/","excerpt":"","text":"会议纪要 会议主题：Ceph数据日志设计讨论 与会人员：Adam、Casey、Matt等 会议时间：具体时间未提及 会议地点：未提及 会议内容总结： 设计讨论： Adam介绍了关于数据日志的替代设计方案，主要思路是通过时间戳直接跟踪工作集，确保没有竞态条件，避免数据日志无限增长。 Casey指出该设计可能存在多目标区域的问题。建议将区域信息存储在数据同步映射中，由trim提供，而不是让目标区域相互查询。 主要议题： 数据日志的替代方案：讨论了使用omap来跟踪未同步的桶分片，而不是使用数据日志。 多目标区域的处理：讨论了如何处理多个目标区域，提出了两种方案：为每个目标区域跟踪一个独立的工作集，或者使用一个工作集来跟踪每个桶分片的未修剪区域。 优先级和排序问题：讨论了如何在目标区域中优先处理旧的变更，提出了在源区域进行排序的方案。 决定事项： 倾向于使用omap来跟踪未同步的桶分片，避免数据日志的无限增长问题。 讨论了如何在源区域进行排序，以便目标区域可以优先处理旧的变更。 后续行动计划： 修改CLS条目以增加时间优先级排序。 完成REST接口的其余部分。 考虑数据增量同步的复杂性，以及如何避免向后兼容性问题。 其他议题： 讨论了rgw账户的设计，提出了一个设计方案，并邀请大家进行评审。 会议结论： 会议对数据日志的替代设计方案进行了深入讨论，并提出了具体的实施步骤和后续行动计划。 对于rgw账户的设计，提出了一个初步的设计方案，并邀请大家进行评审。 下次会议预告： 未提及具体的下次会议时间，但预计将继续讨论相关设计细节和实施方案。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-10-11","slug":"Ceph_RGW_Refactoring_Meeting_2023-10-11","date":"2023-10-10T16:00:00.000Z","updated":"2023-10-11T16:00:00.000Z","comments":true,"path":"2023/10/11/Ceph_RGW_Refactoring_Meeting_2023-10-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/11/Ceph_RGW_Refactoring_Meeting_2023-10-11/","excerpt":"","text":"会议纪要 会议时间 日期：具体日期未提供 时间：具体时间未提供 参会人员 Tom Okusan 其他相关人员 会议议题 生命周期处理（Life Cycle Processing）问题讨论 问题描述：生命周期处理在UTC午夜启动时，会导致多站点复制（multisite replication）看起来像是暂停了。原因是生命周期处理的删除操作被添加到复制数据日志和桶索引日志中，导致同一时间戳下大量操作堆积，从而看起来像是数据同步暂停。 讨论内容： 生命周期处理的删除操作是否应该被记录在日志中。 是否可以通过调整生命周期处理的时间来避免高峰期的操作堆积。 是否可以通过引入Rados QoS（Quality of Service）来控制生命周期处理的速率。 决定事项： 决定不记录生命周期处理的删除操作，而是依赖于生命周期在所有区域（zones）上运行并进行本地删除。 计划利用Rados QoS来控制生命周期处理的速率，以避免对客户端性能的影响。 后续行动： Tom将负责创建一个Tracker问题，并在后续添加更多细节。 SEF日志记录问题 问题描述：讨论关于使用-1作为错误日志记录的问题，以及是否需要强制显示这些日志。 决定事项： 决定-1主要用于需要管理员注意的致命错误，而对于客户端请求处理中的错误，通常不需要在日志中显示。 后续行动： 没有具体的后续行动，但建议在处理日志级别时进行进一步的讨论。 其他讨论 提及Adam Emerson关于数据日志的思考，计划在下一次会议中进行讨论。 会议结束 会议在无其他议题的情况下结束。 备注 会议中提到的技术术语如“multisite replication”、“Rados QoS”等保持英文原文。 后续行动计划 Tom负责创建并更新Tracker问题，详细记录生命周期处理问题的解决方案和后续行动。 继续关注并讨论日志级别和错误日志记录的相关问题。 下一次会议将讨论Adam Emerson关于数据日志的思考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2023-10-04","slug":"Ceph_Developer_Monthly_2023-10-04","date":"2023-10-03T16:00:00.000Z","updated":"2023-10-04T16:00:00.000Z","comments":true,"path":"2023/10/04/Ceph_Developer_Monthly_2023-10-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/04/Ceph_Developer_Monthly_2023-10-04/","excerpt":"","text":"会议纪要 会议基本信息 日期与时间: [具体日期] 参会人员: CDM团队成员 会议平台: Google Meet 记录人员: [记录人员姓名] 主要议题 审计模块的创建请求（RFE） 背景: CFS团队提出的需求，希望在RADOS中持久化存储审计日志。 当前问题: 现有的审计日志主要包含监控命令，可能被删除或丢失。 提议解决方案: 开发一个新的RADOS管理模块，用于持久化存储审计日志条目。 讨论点: 用户如何选择需要保存的审计日志。 权限和API设计问题。 保留策略的配置。 共识: 团队普遍认为该功能有其价值，但需要进一步明确细节和实施方案。 去重功能的改进 当前状态: 已有初步的去重实现，但存在效率问题。 主要问题: 小数据块的存储效率低下，无法有效处理大量重复数据块。 提议解决方案: 设计一个新的去重机制，通过打包小数据块到大对象中来提高效率。 讨论点: 如何设计有效的索引机制。 去重过程的性能和资源消耗。 如何平衡在线和离线工具的需求。 共识: 需要进一步研究和测试，以确定最佳实施方案。 决定事项 审计模块: 继续推进审计模块的开发，明确用户需求和实施细节。 去重功能: 开发新的去重机制，进行详细的性能测试和资源评估。 后续行动计划 审计模块: 明确用户选择审计日志的机制。 设计API和权限检查。 配置保留策略。 去重功能: 开发和测试新的去重机制。 评估性能和资源消耗。 发布测试工具和结果，收集社区反馈。 其他事项 会议记录和讨论结果将分享给未能参加会议的团队成员。 下一次会议将在下个月举行。 会议结束语 感谢所有参与者的贡献和讨论，期待在下一次会议中看到更多的进展和成果。再见！","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-09-06","slug":"Ceph_RGW_Refactoring_Meeting_2023-09-06","date":"2023-10-03T16:00:00.000Z","updated":"2023-10-03T16:00:00.000Z","comments":true,"path":"2023/10/04/Ceph_RGW_Refactoring_Meeting_2023-09-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/04/Ceph_RGW_Refactoring_Meeting_2023-09-06/","excerpt":"","text":"会议纪要 会议时间 日期：具体日期未提供 时间：具体时间未提供 参会人员 主持人：未明确 记录人：未明确 参会人员：AWS用户、Matt、Corell等 会议议题 AWS SNS主题管理权限问题 多站点环境下的通知复制问题 AWS CLI工具的改进 主题与桶的关联及权限管理 讨论内容 AWS SNS主题管理权限问题 当前AWS SNS允许任何用户创建、更新或删除主题，这与SNS文档中提到的主题属于创建者的描述不符。 讨论了是否应该将主题与创建者用户关联，以确保只有创建者可以管理该主题。 提出了技术困难，如用户Matt在加入会议时遇到问题。 讨论了现有部署的兼容性问题，以及如何在不破坏现有部署的情况下实现这一改变。 多站点环境下的通知复制问题 讨论了在多站点环境中，通知未被复制到次要站点的问题，这是一个已知的bug，并已有一个跟踪器。 提出了将通知配置作为桶属性的可能性，以便通过现有的同步机制进行同步。 AWS CLI工具的改进 讨论了AWS CLI工具在获取和列出主题时应仅显示用户拥有的主题，而不是所有主题。 提出了匿名主题的概念，即未与特定用户关联的主题，这些主题可以被任何用户访问或删除。 主题与桶的关联及权限管理 讨论了用户B是否可以订阅用户A创建的主题的问题。 提出了使用策略（policies）来管理主题的访问权限，类似于AWS SNS主题策略。 讨论了在创建主题时是否应该包含策略参数，以及如何处理SDK的兼容性问题。 决定事项 主题与用户关联 决定将主题与创建者用户关联，以确保只有创建者可以管理该主题。 对于现有部署，将考虑兼容性问题，并可能允许匿名主题的存在。 多站点环境下的通知复制 确认了通知未被复制到次要站点的问题，并将继续跟踪和解决该问题。 AWS CLI工具改进 决定改进AWS CLI工具，使其仅显示用户拥有的主题。 主题与桶的关联及权限管理 决定探索使用策略来管理主题的访问权限，并考虑在创建主题时包含策略参数。 后续行动计划 主题与用户关联 创建一个新的跟踪器，以继续讨论和实现主题与用户关联的功能。 考虑现有部署的兼容性问题，并制定相应的解决方案。 多站点环境下的通知复制 继续跟踪和解决通知未被复制到次要站点的问题。 探索将通知配置作为桶属性的可能性，以便通过现有的同步机制进行同步。 AWS CLI工具改进 改进AWS CLI工具，使其仅显示用户拥有的主题。 主题与桶的关联及权限管理 探索使用策略来管理主题的访问权限，并考虑在创建主题时包含策略参数。 检查AWS SDK是否支持发送策略作为创建主题的一部分，并确保SDK的兼容性。 会议结束 会议在讨论完所有议题后结束，并约定下次会议时间。 备注 会议中提到的技术困难和用户Matt的连接问题未影响会议的进行。 会议记录中提到的AWS SNS、AWS CLI、SDK等关键词保留英文原文。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-09-20","slug":"Ceph_RGW_Refactoring_Meeting_2023-09-20","date":"2023-10-03T16:00:00.000Z","updated":"2023-10-03T16:00:00.000Z","comments":true,"path":"2023/10/04/Ceph_RGW_Refactoring_Meeting_2023-09-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/04/Ceph_RGW_Refactoring_Meeting_2023-09-20/","excerpt":"","text":"会议纪要 会议主题：每周RGW会议 日期：[具体日期] 参会人员：[参会人员名单] 主要议题： 通知和SNS主题策略 讨论内容： Matt介绍了关于通知和SNS主题策略的讨论，涉及IAM和S3策略，特别是SNS API的使用。 讨论了服务控制策略（Service Control Policy, SCP）和站点控制策略（Site Control Policy），这些策略可能需要通过扩展API或仪表板来支持。 决定事项： 计划实现SNS主题策略，并考虑通过RGW管理命令和API来设置，如果标准IAM或S3 REST API不支持。 后续行动： 继续探讨和实现SNS主题策略，并考虑添加相关API扩展。 持久通知的性能 讨论内容： Yuvall介绍了持久通知性能的PR，讨论了当前使用单个工作线程从队列读取通知并发送至Kafka的机制。 讨论了增加更多工作线程的可能性，以及这可能带来的性能影响。 决定事项： 认为增加更多工作线程可能不会显著提升性能，因为瓶颈可能在写入队列的操作。 后续行动： 考虑添加更多Kafka客户端统计信息，以更好地理解系统性能和潜在瓶颈。 进行测试以验证单线程是否是瓶颈，并评估增加线程的影响。 其他讨论： 讨论了队列填充的两种场景：队列未及时清空和Kafka代理响应慢。 提出了通过增加Kafka客户端统计信息来更好地诊断问题。 结论： 会议决定继续探索和实现SNS主题策略，并通过增加Kafka客户端统计信息来优化持久通知的性能。 将继续进行性能测试，以验证单线程是否是瓶颈，并评估增加线程的影响。 下次会议预告： 下次会议将继续讨论相关议题，并根据测试结果调整优化策略。 会议结束： 感谢所有参会人员，下次会议再见。 注： 以上纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-09-27","slug":"Ceph_RGW_Refactoring_Meeting_2023-09-27","date":"2023-10-03T16:00:00.000Z","updated":"2023-10-04T16:00:00.000Z","comments":true,"path":"2023/10/04/Ceph_RGW_Refactoring_Meeting_2023-09-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/10/04/Ceph_RGW_Refactoring_Meeting_2023-09-27/","excerpt":"","text":"会议纪要 议题一：Coverity 项目更新 汇报人： Vidansh 参与人员： Yuan 等 时间： 过去两个月 内容： - Coverity 工具介绍： Coverity 是一个静态分析工具，用于识别代码中的问题，并将其分类为高、中、低影响。 - 项目成果： 在过去的几个月中，团队成功解决了多个高、中影响的问题，并对工具的有效性进行了数据分析。 - 问题分类： - 关键问题： 40个，几乎与误报数量相等。 - 误报： 约40%的问题被归类为误报。 - 其他分类： 包括实际但不值得立即修复的bug和其他类别。 - 主要bug类型： 除了未处理的异常外，主要问题包括空引用、内存泄漏、未初始化的变量等。 - 项目目标： 提高rgw代码质量，并为社区提供关于Coverity工具有效性的数据，以决定是否将其纳入常规工作流程。 - 后续行动： 需要进一步讨论是否自动化该过程或将其作为CI的一部分，以防止bug再次出现。 议题二：多站点数据日志和bi日志竞态条件 汇报人： Jane 内容： - 问题识别： 在多站点复制过程中发现了数据日志和bi日志的竞态条件问题。 - 具体问题： - 数据日志窗口优化： 当前实现中，数据日志更新在窗口内被缓存，可能导致更新丢失。 - 异步操作问题： 对象更新完成后，异步发送bucket complete操作可能导致数据不一致。 - 解决方案讨论： - 数据日志更新： 建议在bucket index完成处理后进行数据日志更新。 - 性能影响： 讨论了移除数据日志窗口优化可能对性能的影响。 - 后续行动： 需要进一步测试和代码审查，以确定最佳解决方案。 议题三：通知系统更新 汇报人： Krunal 内容： - 问题描述： 在实现IAM策略或通知时，发现当前实现方式可能导致策略被覆盖。 - 当前实现： 使用create topic API来更新主题属性，但未实现set topic attributes API。 - 讨论结果： - 新系统行为： 建议实现set topic attributes API，以允许用户在不覆盖策略的情况下更新主题属性。 - 兼容性问题： 需要确保现有系统不会因升级而中断，同时为新系统提供正确的API使用指南。 - 后续行动： 将文档化新行为，并在PR中进行相应更新。 总结 会议涵盖了Coverity工具的有效性分析、多站点数据日志和bi日志的竞态条件问题以及通知系统的更新。每个议题都有具体的讨论和后续行动计划，旨在提高代码质量和系统稳定性。感谢所有参与者的贡献和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-08-29","slug":"Ceph_Orchestrator_Meeting_2023-08-29","date":"2023-08-29T16:00:00.000Z","updated":"2023-08-30T16:00:00.000Z","comments":true,"path":"2023/08/30/Ceph_Orchestrator_Meeting_2023-08-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/08/30/Ceph_Orchestrator_Meeting_2023-08-29/","excerpt":"","text":"会议纪要 会议主题： 重构工作讨论 参会人员： [未列出具体人员] 会议时间： [未提供具体时间] 主要议题： 1. 重构工作的格式化问题：讨论了重构工作中的一些格式化问题，特别是关于命名和目录结构的讨论。 2. 命名问题：讨论了包名和目录名的命名问题，特别是关于 fadm 和 cephadm 的命名争议。 3. 目录结构：讨论了如何组织文件和目录，以及如何处理源代码树中的主要文件。 4. Python Black 格式化工具：讨论了使用 Python Black 作为代码格式化工具的决策和实施细节。 决定事项： 1. 命名问题：决定暂时保留现有的命名 cephadm，但未来可能会根据更多反馈进行调整。 2. 目录结构：决定将主要文件移动到新的子目录中，以保持代码的组织性和清晰性。 3. Python Black 格式化工具：决定采用 Python Black 作为代码格式化工具，并计划将其纳入 CI 流程。 后续行动计划： 1. 实施命名和目录结构变更：根据会议决定，进行必要的代码和目录结构调整。 2. 集成 Python Black 到 CI：在后续 PR 中将 Python Black 集成到 CI 流程中，确保代码格式的一致性。 3. 文档更新：更新开发者文档，解释新的代码结构和如何在未来进行开发。 其他讨论点： - 代码内容的检查：讨论了如何处理代码中对 Docker IO 的引用，决定将其作为一个单独的规则处理。 - 未来工作：提到了未来可能对服务类型类进行进一步的重构和标准化。 会议总结： 会议主要集中在重构工作的细节上，特别是命名和目录结构的调整。虽然存在一些争议，但最终达成了一致的决定。未来将继续关注代码的组织和格式化问题，并计划进行进一步的文档更新和代码重构工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-08-17","slug":"Ceph_Performance_Meeting_2023-08-17","date":"2023-08-16T16:00:00.000Z","updated":"2023-08-17T16:00:00.000Z","comments":true,"path":"2023/08/17/Ceph_Performance_Meeting_2023-08-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/08/17/Ceph_Performance_Meeting_2023-08-17/","excerpt":"","text":"会议纪要 主要议题与更新 PR审查与更新 讨论了两个更新的Pull Request (PR)： 第一个PR涉及在读取新写入对象时提升对象，目前尚未详细审查，需要进一步评估。 第二个PR由Igor提交，关于不重置预取缓冲区的问题，希望Adam能进行审查。此改动可能改善BlueFS的缓冲I/O使用情况。 Erasure Coding改进 正在进行的PR旨在改进Erasure Coding，目前无更新。计划后续重新审视数据缓存策略，特别是对于EC分片的缓存，以避免网络重传。 测试与性能优化 Gabby分享了关于大量对象创建、快照及克隆的测试结果，涉及300,000个对象和相应墓碑的处理。测试显示，尽管存在性能波动，但整体性能有所提升，特别是减少了在RocksDB中的多次访问。 讨论了可能的自动压缩机制，以及如何通过调整压缩设置来优化性能。 决定事项 需要对Igor的PR进行详细审查，特别是评估其对BlueFS预取机制的影响。 对于Erasure Coding的改进，将继续关注数据缓存策略，特别是远程分片的缓存。 Gabby的测试结果显示性能改进，但需要进一步分析和优化压缩机制。 后续行动计划 分配人员对未审查的PR进行详细评估。 继续关注和优化Erasure Coding的性能，特别是数据缓存策略。 对Gabby的测试结果进行深入分析，探索进一步的性能优化措施。 其他讨论 会议中提到了系统在处理大量数据时的CPU使用率问题，以及如何通过优化减少系统负载。 讨论了实际应用场景中可能遇到的问题，如心跳超时和系统资源占用问题。 会议结束 会议在讨论完所有议题后结束，参与者计划继续各自的开发和测试工作。 备注：会议中涉及的技术细节和具体代码改动需要通过代码审查和进一步测试来确认其效果和可行性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Making Teuthology Friendly","slug":"Ceph_Tech_Talk_-_Making_Teuthology_Friendly","date":"2023-08-15T16:00:00.000Z","updated":"2023-08-16T16:00:00.000Z","comments":true,"path":"2023/08/16/Ceph_Tech_Talk_-_Making_Teuthology_Friendly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/08/16/Ceph_Tech_Talk_-_Making_Teuthology_Friendly/","excerpt":"","text":"会议纪要 会议主题： 病理学（Pathology）项目的改进与实施 主讲人： Devansh，Google Summer of Code实习生，SEF项目成员 会议时间： [具体日期] 会议地点： [具体地点] 参会人员： [列出参会人员] 会议内容： 项目介绍： 病理学（Pathology） 是一个用于安全测试的Python框架，主要用于在远程主机上通过SSH运行测试。 Pulpito 是一个用于监控病理学测试基础设施的Web仪表板，包括测试队列和可用测试节点。 现有问题： 病理学的命令行接口（CLI）复杂，包含大量命令和标志，对新用户不友好。 用户需要手动配置多个参数，如仓库URL、分支名称和套件选项，容易导致错误。 新用户难以发现和理解可用命令、选项及其含义，导致使用困难。 解决方案： 开发下一代Pulpito，提供更直观的用户界面，允许用户通过仪表板直接调度或终止作业。 实现了一个病理学API，并与下一代Pulpito集成，使用户无需SSH进入服务器即可管理作业。 实施细节： 主要功能包括GitHub认证、作业调度和作业终止。 通过仪表板，用户可以轻松配置和监控测试，提高团队生产力。 演示： 展示了如何通过下一代Pulpito界面调度作业和终止作业。 演示了作业调度的实时反馈和错误处理的流程。 未来展望： 考虑将Paddles服务迁移到FastAPI，以利用其社区支持和内置功能。 改进下一代Pulpito的用户体验，增加更多用户中心的功能，如作业历史记录和错误日志展示。 感谢与反馈： 感谢导师Zach、Aishwarya和Junior在整个项目过程中的帮助。 欢迎与会者提供反馈和建议，以进一步改进项目。 后续行动计划： - 继续完善下一代Pulpito的功能。 - 探索将常用命令存储在数据库中的可能性。 - 增强错误日志的展示方式，提供更结构化的错误信息。 会议结束语： - 感谢所有参与者的参与和反馈，期待继续改进和贡献于SEF项目。 附件： - 演示视频链接 - 项目GitHub仓库链接 会议记录人： [记录人姓名] 审核人： [审核人姓名] 日期： [记录日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW Refactoring Meeting 2023-08-16","slug":"RGW_Refactoring_Meeting_2023-08-16","date":"2023-08-15T16:00:00.000Z","updated":"2023-08-16T16:00:00.000Z","comments":true,"path":"2023/08/16/RGW_Refactoring_Meeting_2023-08-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/08/16/RGW_Refactoring_Meeting_2023-08-16/","excerpt":"","text":"会议纪要 会议主题： 讨论Ali的工作关于标记性能计数器（labeled perf counters）和RGW（RADOS Gateway）的集成。 主要讨论内容： Ali的工作进展： Ali已经提交了一个PR，包含了性能计数器的初始草案，并对RGW的前端操作计数器进行了标记。 计划在本周进行更大规模的测试，并欢迎任何反馈。 PR中创建了多个不同的性能计数器实例，用于不同的操作（如put, get, delete等）。 性能计数器实例的合并： Casey提出建议，将所有前端操作计数器合并到一个实例中，以便按桶名或用户名进行缓存。 Ali解释了当前设计的原因，主要是为了未来的灵活性和多站点计数器的集成。 缓存和Prometheus集成： 讨论了缓存驱逐的工作原理和配置。 确认了每个RGW节点需要一个单独的exporter，用于将计数器数据发送到Prometheus。 下一步行动计划： Ali将继续测试并优化性能计数器的实现。 Mark和Ali计划在Folio实验室的机器上进行大规模测试，以验证exporter和Prometheus的集成性能。 其他议题： Tobias分享了关于处理粗选项请求的工作进展，并寻求反馈。 讨论了S3测试的默认认证路径（V2 vs V4），并计划进一步验证和优化。 决定事项： Ali将继续优化性能计数器的实现，并进行大规模测试。 Tobias将寻找更合适的位置来放置认证验证逻辑。 后续行动计划： Ali和Mark将进行大规模测试，以验证性能计数器和Prometheus的集成。 Tobias将继续优化S3测试和认证逻辑的实现。 会议结束： 会议在无其他议题的情况下结束，感谢所有参与者的贡献。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW Refactoring Meeting 2023-07-26","slug":"RGW_Refactoring_Meeting_2023-07-26","date":"2023-08-14T16:00:00.000Z","updated":"2023-08-15T16:00:00.000Z","comments":true,"path":"2023/08/15/RGW_Refactoring_Meeting_2023-07-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/08/15/RGW_Refactoring_Meeting_2023-07-26/","excerpt":"","text":"会议纪要 会议主题：关于Zipper和剩余的casts到Rados驱动的问题 会议时间：[具体时间] 参会人员：[具体人员名单] 会议内容： 主要议题： 讨论了在D3N项目中，验证套件依赖的一些管理API在存在过滤器或其他驱动而非Rados时会崩溃的问题。 确认了Dan之前的工作，但仍有更多需要解决的问题，以确保能够成功测试Preetha的D3N工作。 讨论细节： 会议中提到了一些特定存储的管理API，确认这些API是否已经合并。 发现Zone配置API和元数据获取API存在问题，需要通过存储来解决。 讨论了在管理API中添加过滤器的必要性，以便API能够处理过滤器。 决定事项： 需要进一步检查并修复管理API中剩余的问题。 需要在API中添加过滤器，以确保API能够处理过滤器。 后续行动计划： 在相关PR中添加评论，明确计划和下一步行动。 确认所有问题解决后，继续推进D3N项目的测试工作。 会议结束语： 会议简短，感谢所有参会人员的参与。 会议记录人：[记录人姓名] 会议日期：[具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW Refactoring Meeting 2023-08-09","slug":"RGW_Refactoring_Meeting_2023-08-09","date":"2023-08-14T16:00:00.000Z","updated":"2023-08-15T16:00:00.000Z","comments":true,"path":"2023/08/15/RGW_Refactoring_Meeting_2023-08-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/08/15/RGW_Refactoring_Meeting_2023-08-09/","excerpt":"","text":"会议纪要 会议概要 Reef版本发布：Reef版本已于今日发布，感谢所有人的辛勤工作。 博客文章计划：将开始发布博客文章来宣布新功能。如果有团队成员在Reef版本中开发了新功能并希望与社区分享，请与负责人联系。 主要议题 Yuval关于通知的讨论： 持久化通知改进：目标是提高持久化通知的观察性和可调试性。 当前进展：Ali之前的工作已经使得在RedEscape Admin中可以运行命令查询特定持久化队列的状态或统计信息。 下一步计划： 使用带标签的性能计数器（labeled perf counters）在Redis Gateway Admin上，以便在部署中更方便地收集统计信息并展示在Grafana等工具中。 改进重试机制，包括为每个通知设置TTL和重试次数，以避免无限重试和队列过大问题。 使配置RESTful化，以便不同主题可以指向不同的系统并具有不同的特性。 在迁移过程中，确保重试次数和TTL的持久性，特别是在升级到支持TTL的版本时。 迁移到CLS FIFO： 动机：当前队列的最大大小为128MB，对于长时间的服务器宕机或高更新率的系统可能不够。 挑战： 迁移问题：可能需要同时维护两个队列，直到旧队列中的数据处理完毕。 观察性问题：CLS FIFO可能难以提供准确的队列条目数和大小，可能需要遍历所有节点来获取这些信息。 上限问题：可能需要为FIFO设置一个上限，以防止无限制增长。 讨论要点： 是否需要一个死信队列（dead letter queue）来处理无法发送的通知。 如何处理TTL和重试在CLS FIFO中的实现问题。 迁移策略：建议通过创建新主题并逐步迁移来避免复杂的迁移过程。 决定事项 将继续改进持久化通知的观察性和重试机制。 考虑迁移到CLS FIFO以支持更大的队列大小。 讨论并决定如何处理迁移和死信队列的问题。 后续行动计划 继续开发和测试持久化通知的改进功能。 研究并实施迁移到CLS FIFO的策略。 提供脚本帮助用户迁移到新主题。 讨论并决定是否需要实现死信队列。 其他讨论 关于将S3用户与主题关联的提议，以便更容易管理用户和主题的关系。 会议结束 会议结束，感谢所有参与者的贡献和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: Cephadm","slug":"CDS_Squid_-_Cephadm","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_Cephadm/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_Cephadm/","excerpt":"","text":"会议纪要 会议基本信息 主题: 编排（Orchestration）与鱿鱼（Squid）发布计划会议 日期: [具体日期] 参与者: [参与者名单] 主要议题及讨论内容 SMB支持 讨论内容: 讨论了在Ceph中添加SMB支持的详细计划，包括使用Samba和Samba共享而不是NFS。提到了使用Kubernetes的sidecar容器概念，并计划在Ceph AEM中重用这些工作。 决定事项: 决定为SMB支持创建一个专门的文档，并计划在未来的开发周期中继续推进此功能。 后续行动: 继续开发SMB支持功能，并在下一个开发周期中进行性能测试和优化。 FBM二进制重构 讨论内容: 讨论了FBM二进制文件的重构计划，包括将其分解为更易管理的模块，并引入依赖项。 决定事项: 决定在Reef发布后开始进行二进制文件的重构工作。 后续行动: 开始进行FBM二进制文件的重构，并增加相关的单元测试。 NVMF支持 讨论内容: 讨论了在Ceph中添加NVMF支持的计划，尽管此功能不会包含在初始的Reef发布中。 决定事项: 计划在Squid发布周期中完成NVMF支持的开发和测试。 后续行动: 继续开发NVMF支持，并在Squid发布前进行充分的测试。 升级历史记录 讨论内容: 讨论了添加升级历史记录功能的需求，以便跟踪集群的升级路径和失败记录。 决定事项: 决定在Squid发布中实现升级历史记录功能。 后续行动: 开发并实现升级历史记录功能。 改进测试覆盖率 讨论内容: 讨论了提高测试覆盖率的计划，包括增加IPv6支持和在测试中使用虚拟机。 决定事项: 计划在未来的开发中增加更多的测试覆盖，特别是IPv6和虚拟机测试。 后续行动: 与Toothology团队合作，探讨在测试中使用虚拟机的可能性。 OSD重新部署 讨论内容: 讨论了在需要更改对象存储时自动重新部署OSD的需求。 决定事项: 计划在未来开发中实现OSD的自动重新部署功能。 后续行动: 探讨具体的实现方案，并与社区合作进行开发和测试。 其他讨论点 用户反馈和易用性: 讨论了如何更好地收集用户反馈，并提高Ceph的易用性，包括可能的演示和培训。 社区合作: 提到了与Samba社区的合作，以及如何通过测试基础设施提供相互支持。 结论 会议涵盖了多个关键议题，并为未来的开发工作设定了明确的目标和行动计划。感谢所有参与者的积极参与和贡献。 下一步行动 继续推进SMB和NVMF支持的开发。 开始FBM二进制文件的重构工作。 实现升级历史记录功能。 提高测试覆盖率，特别是IPv6和虚拟机测试。 探讨并实现OSD的自动重新部署功能。 收集用户反馈，提高Ceph的易用性。 会议结束时间: [具体时间] 记录人: [记录人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: Dashboard","slug":"CDS_Squid_-_Dashboard","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_Dashboard/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_Dashboard/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的研发进展，特别是关于Reef版本的新功能和改进。会议涵盖了多个议题，包括新功能的交付、性能优化、用户体验改进以及后续的行动计划。 讨论的主要议题 新功能交付 讨论了Reef版本中已交付的亮点功能，如新的登录页面、博客更新、自动化管理、服务器端加密等。 提到了多站点功能，尽管不会在主要版本中发布，但将在后续的次要版本中进行更多测试和部署。 CephFS管理 讨论了CephFS管理功能的进展，包括卷管理、子卷管理、快照管理等。 确定了PR（Pull Request）的进度，并计划在后续版本中继续开发和测试这些功能。 RGW概览仪表盘 介绍了RGW（RADOS Gateway）概览仪表盘的设计和功能，包括展示RGW实体数量、多站点指标等。 讨论了如何进一步优化和扩展仪表盘的功能。 集群升级管理 讨论了通过Dashboard管理集群升级的功能，包括设计布局、升级状态显示、日志查看等。 确定了升级过程中的一些技术细节和潜在问题，并计划进行更多测试。 性能和用户体验改进 讨论了Dashboard的性能优化，特别是在处理大量OSD（Object Storage Daemon）时的性能问题。 提到了用户体验的改进，如一键创建向导、布局和响应性的优化。 测试覆盖率 强调了提高Dashboard的测试覆盖率的重要性，特别是端到端（E2E）测试和单元测试。 决定的事项 确定了CephFS管理功能的开发和测试计划。 确定了RGW概览仪表盘的设计和功能扩展计划。 确定了集群升级管理功能的设计和测试计划。 确定了性能优化和用户体验改进的具体措施。 确定了提高测试覆盖率的计划。 后续的行动计划 继续开发和测试CephFS管理功能，确保按计划交付。 继续优化RGW概览仪表盘，增加更多功能和指标。 继续测试和优化集群升级管理功能，确保稳定性和可靠性。 继续进行性能优化和用户体验改进的工作。 提高Dashboard的测试覆盖率，确保代码质量和稳定性。 其他讨论点 讨论了RGW多站点功能的改进和测试。 讨论了Dashboard特定遥测数据的收集和分析，以改进用户体验。 会议结束 会议在讨论了所有议题和后续行动计划后结束，与会者对未来的工作充满信心。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: BlueStore","slug":"CDS_Squid_-_BlueStore","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_BlueStore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_BlueStore/","excerpt":"","text":"Ceph Blue Store 会议纪要 会议基本信息 日期与时间: [具体日期] 参会人员: Eager, Adam, Igor 等（Mark 未能参加） 议程: 讨论了Ceph Blue Store的多个关键议题，包括分配器模拟器、碎片化处理、弹性共享Blob、Codel算法、自定义写前锁等。 主要讨论内容 分配器模拟器： 决定解决Booster中定位器问题，启动了GSoC合作项目，目标是创建一个外部工具——分配器模拟器。 模拟器将尽可能接近地重放现有工作负载，并添加一些合成数据，以预测对分配器所做更改在部署后的长期影响。 碎片化处理： 计划在Blue Store中引入一些基本原语，以允许尝试对象碎片整理。 这将涉及在对象存储上创建一些空闲周期队列，作为碎片整理的第一步。 弹性共享Blob： 引入了一个新特性——弹性共享Blob，以优化克隆对象时的效率问题。 该特性已回溯到Quincy和Reef版本，目前正在测试其对Blue Store的影响。 Codel算法： 讨论了Codel算法，该算法旨在在延迟和吞吐量之间做出选择，通过批处理事务来提高整体性能。 另一个相关的PR由Mark Nelson提出，同样基于类似逻辑，但实现层面不同。 自定义写前锁： 讨论了在Blue Store级别实现写前锁，以减少写操作的延迟。 Igor已经开发了一个工程版本，但仍需进一步完善。 政策与回溯： 讨论了代码重构和特性回溯的政策问题，特别是关于如何平衡新特性和稳定性。 提议在开发文档中建立一些高层次的原则，以便未来参考和讨论。 决定事项 将继续推进分配器模拟器的开发，并完善其度量标准。 将尝试在Blue Store中实现碎片整理的基本原语。 弹性共享Blob特性将继续在不同版本中进行测试和部署。 对于Codel算法和自定义写前锁，将继续进行测试和完善。 关于回溯政策，将创建一个文档来记录和讨论相关原则。 后续行动计划 继续开发和测试分配器模拟器。 在Blue Store中实现碎片整理的基本原语。 对弹性共享Blob特性进行进一步测试和部署。 完善Codel算法和自定义写前锁的实现。 创建并维护回溯政策的文档，以便未来参考和讨论。 备注 会议在预定时间内顺利结束，后续的CDS会议将在短时间内开始。 以上是本次Ceph Blue Store会议的详细纪要，涵盖了讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: NVMe-oF-Gateway","slug":"CDS_Squid_-_NVMe-oF-Gateway","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_NVMe-oF-Gateway/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_NVMe-oF-Gateway/","excerpt":"","text":"会议纪要 会议主题：Ceph Gateway 的高可用性和可扩展性讨论 与会人员：Ceph 研发团队成员 会议时间：具体时间未提供 会议地点：线上会议 主要议题： 高可用性和可扩展性 讨论内容：团队讨论了如何通过使用 getter groups 来实现 RBD 卷的高可用性和可扩展性。目标是允许从不同的 gateway 访问相同的 RBD 卷。 关键问题：如何进行负载均衡，即如何决定哪个 gateway 服务于哪个卷。 决定事项：初步决定不自动进行负载均衡，而是通过 Gateway CLI 允许用户指定哪个 gateway 是某个卷的首选。未来可能会考虑自动化。 多路径和 Ana 支持 讨论内容：讨论了当前的多路径和 Ana 支持配置，以及用户如何配置这些设置。 关键问题：如何设置和优化路径状态，以及如何在配置文件中持久化这些设置。 决定事项：决定在未来的版本中允许用户通过 RPC 配置路径状态，但初始版本可能只支持一个优化路径。 故障转移和恢复 讨论内容：讨论了在没有 IP 故障转移的情况下，如何处理故障转移和恢复的问题。 关键问题：如何确保在故障转移时，客户端能够正确地重新连接到新的路径。 决定事项：需要进一步测试和验证，可能需要通过发现服务或类似机制来处理路径的移除和重新添加。 并发 gRPC 处理 讨论内容：由于时间限制，该议题被推迟到下一次会议讨论。 后续行动计划： 负载均衡：继续研究如何实现更智能的负载均衡机制。 多路径和 Ana 支持：完善配置选项，允许用户更灵活地配置路径状态。 故障转移和恢复：进行更多的测试，确保在各种故障情况下客户端能够正确地重新连接。 并发 gRPC 处理：在下一次会议中深入讨论并发 gRPC 处理的细节。 其他备注： 会议中还提到了关于 Gateway groups 的其他问题，如如何报告不可访问的命名空间等，这些问题将在未来讨论。 对于网络流量的问题，会议确认了在 Ceph 架构中，前端和后端的网络流量不需要成倍增加，因为复制发生在后端。 会议结束语： 感谢所有与会者的参与，下一次会议将继续讨论未完成的技术议题。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: RBD","slug":"CDS_Squid_-_RBD","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_RBD/","excerpt":"","text":"会议纪要：RBD 子开发者规划峰会 会议概览 本次会议是关于 RBD（RADOS Block Device）的子开发者规划峰会，主要讨论了关于镜像（mirroring）和快照（snapshot）相关的高优先级问题、新功能提案以及后续行动计划。 主要议题 镜像和快照相关的高优先级问题 数据损坏问题：在同步克隆图像时，如果需要从父图像复制数据到克隆图像，次级集群上的镜像守护进程（mirror daemon）可能不会执行此操作，导致数据损坏。 同步丢弃操作问题：在某些情况下，丢弃操作可能不会正确同步，导致空间未被释放。 块列表错误传播问题：在某些代码路径中，错误被忽略，导致从块列表恢复失败。 强制提升问题：当前的强制提升操作需要等待同步完成，这与其定义不符，可能导致无限期等待。 新功能提案 快照镜像的一致性组：讨论了快照镜像的一致性组功能，但认为当前的RBD一致性组语义可能已经足够。 性能改进：包括从快照克隆、流式快照增量等提案，旨在提高镜像同步的性能和效率。 其他非镜像相关议题 迁移功能改进：包括从非Ceph源进行实时迁移的支持，以及与原生加密交互的改进。 Windows支持改进：讨论了Windows NBD驱动和守护进程的改进，以支持持久保留和多路复用。 决定事项 确认了高优先级问题的修复计划，特别是数据损坏和同步丢弃操作的问题。 对于新功能提案，如快照镜像的一致性组和性能改进，将进行进一步的讨论和评估。 对于非镜像相关议题，如迁移功能和Windows支持，将逐步推进相关改进。 后续行动计划 继续修复高优先级问题，并确保数据完整性和同步的可靠性。 对新功能提案进行详细讨论，评估其实现的可行性和优先级。 推进迁移功能和Windows支持的改进，确保功能的稳定性和性能。 其他备注 会议记录将被保存，供后续参考和审查。 鼓励与会者提出未在列表中的议题，以便在后续会议中讨论。 会议结束时，主持人感谢所有参与者的参与，并期待在后续的沟通渠道中继续讨论和合作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: RADOS","slug":"CDS_Squid_-_RADOS","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_RADOS/","excerpt":"","text":"会议纪要 会议概述 本次会议是Ceph开发者会议的延续，主要讨论了Ceph管理器（MGR）的相关议题，包括性能问题、编码解码的可测试性、客户端之间的QoS（服务质量）、读取均衡器、可用性跟踪、Erasure编码配置文件的简化等。 主要议题及讨论内容 Op Tracker for MGR 讨论了MGR中操作跟踪器（Op Tracker）的重要性，特别是在处理性能问题时。 提出了将Op Tracker集成到MGR中的建议，以便更好地监控和管理操作。 讨论了可能的技术挑战和解决方案，包括Python插件的性能分析工具。 编码解码的可测试性 讨论了编码解码框架的可测试性问题，特别是在处理客户端和服务器版本兼容性时。 提出了改进测试覆盖率的建议，包括强制注册新的可编码类。 讨论了如何扩展测试框架以涵盖更多场景，例如不同的集群模式。 客户端之间的QoS 讨论了在Ceph集群中实现客户端之间QoS的必要性和当前进展。 提出了在不同客户端之间实现公平性的方法，并讨论了相关的技术细节和挑战。 读取均衡器 讨论了将读取均衡器集成到Ceph的平衡器管理模块中的可能性，以减少用户干预。 提出了自动运行读取均衡器的建议，并讨论了可能的触发机制。 可用性跟踪 讨论了如何在Ceph中实现长期的可用性跟踪，包括定义可用性的标准。 提出了基于PG状态的可用性跟踪方法，并讨论了如何优化和扩展这一功能。 Erasure编码配置文件的简化 讨论了简化Erasure编码配置文件的需求，特别是在小型集群中的应用。 提出了创建预定义配置文件的建议，并讨论了如何使这些配置文件更易于用户使用。 决定事项 将继续推进Op Tracker在MGR中的集成工作。 将改进编码解码框架的测试覆盖率，并强制注册新的可编码类。 将继续开发客户端之间的QoS功能，并解决相关的技术挑战。 将开发自动运行的读取均衡器，并探索不同的触发机制。 将开发基于PG状态的可用性跟踪功能，并优化其性能。 将创建预定义的Erasure编码配置文件，以简化用户操作。 后续行动计划 继续推进各项议题的开发和测试工作。 定期召开会议，跟进各项议题的进展，并解决遇到的问题。 与社区成员保持沟通，收集反馈，并根据反馈调整开发计划。 其他事项 会议中提到的其他议题，如多租户统计、端到端跟踪等，将在后续的会议中进一步讨论。 鼓励社区成员积极参与讨论，提出建议和反馈。 会议总结 本次会议成功讨论了Ceph管理器及相关功能的多个关键议题，并制定了相应的行动计划。会议强调了社区合作的重要性，并鼓励所有成员积极参与，共同推动Ceph项目的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: RGW","slug":"CDS_Squid_-_RGW","date":"2023-07-24T16:00:00.000Z","updated":"2023-07-25T16:00:00.000Z","comments":true,"path":"2023/07/25/CDS_Squid_-_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/25/CDS_Squid_-_RGW/","excerpt":"","text":"会议纪要：Ceph RGW 会议 会议目的 本次会议旨在讨论Ceph S版本的规划，分享当前正在进行的一些项目，并将讨论内容更新到Ceph的Trello看板中。 主要议题与讨论内容 D4N数据缓存项目 该项目已进行较长时间，最近开始合并相关内容。 预计在S版本中将包含一些关键能力，如增加灵活性和访问缓存目录的额外功能。 Aeroflight集成 正在探索Aeroflight的前端集成，以实现通过飞行接口查询RGW并进行数据检索。 目标是实现端到端的概念验证，尽管目前存在一些技术限制，如CentOS版本问题。 POSIX文件后端和独立RGW部署 正在开发基于POSIX文件系统的RGW后端，并探索独立RGW部署的可能性。 预计在S版本中将有一个最小可行产品（MVP）。 跟踪（Tracing） 使用Jaeger和OpenTracing库进行集成，已合并初步支持。 计划扩展跟踪覆盖范围，特别是在多站点复制中，并考虑在生产集群中使用。 标记的Prometheus指标 目标是支持按用户或存储桶过滤RGW的计数器，尽管存在一些规模挑战。 Ali正在构建一个原型进行规模测试。 多站点（Multi-site） 计划将存储桶索引日志从omap移出，以简化删除操作。 还有其他多站点相关的计划，如产品化归档区域同步模块。 异步重构 持续进行异步模型的转换，最近在Reef版本中合并了更多可选yield的支持。 目标包括减少RGW线程池的大小，并探索基于C++20协程的多站点原型。 QoS集成与Libreidos 目标是利用OSD中的QoS功能，确保客户端请求和后台工作的公平性。 测试 强调在错误和延迟情况下的改进测试，包括使用Warp工具和其他测试方法。 对性能测试表示兴趣，希望能有可重复的结果以比较不同版本和进行性能优化。 生产检查工具 讨论了实时统计工具的需求，以帮助快速识别和解决性能问题。 决定事项 所有讨论的内容将被整理并更新到Ceph的Trello看板中。 将继续推进各个项目的开发和集成工作。 后续行动计划 继续进行D4N数据缓存项目的开发和集成。 探索和实现Aeroflight的前端集成。 开发和测试基于POSIX文件系统的RGW后端。 扩展跟踪功能，特别是在多站点复制中。 进行标记的Prometheus指标的规模测试。 推进多站点功能的开发和产品化。 完成异步重构和QoS集成工作。 加强错误和性能测试，确保软件质量和性能。 会议结束 会议结束时，主持人确保所有讨论内容将被整理并更新到Trello看板中，并对所有参与者表示感谢。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: Documentation","slug":"CDS_Squid_-_Documentation","date":"2023-07-19T16:00:00.000Z","updated":"2023-07-20T16:00:00.000Z","comments":true,"path":"2023/07/20/CDS_Squid_-_Documentation/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/20/CDS_Squid_-_Documentation/","excerpt":"","text":"会议纪要 会议主题： 2023年Ceph文档会议 日期： 2023年7月20日 主持人： Zach Dover 参会人员： [参会人员名单] 会议议程 Red House文档清理倡议完成情况 经过约三个月的努力，已对RADOS文档的每一行进行了检查和修正，确保其语法正确，符合母语为英语的读者阅读习惯。 目前仅剩约1000行文档待处理，预计将于周二完成所有清理工作。 新手入门指南（Beginner's Guide） 承诺在Squid发布前完成新手入门指南的编写。 该指南将以三栏五卡的形式呈现，旨在向不熟悉Ceph的用户介绍Ceph集群及其组成部分。 预计文档不超过20页，将接受严格的审查。 V-Start文档规范化 目前存在多个关于如何设置开发子集群的不一致文档，需要进行整合和规范化。 该工作将与新手入门指南的编写同时进行，作为上下文帮助改进倡议的前奏。 上下文帮助改进 针对Jana Icepick提出的关于上下文帮助系统的问题，计划在Squid发布前进行改进。 具体改进措施将在V-Start文档规范化后进行。 解决方案指南 由Dan Vanderster提出的解决方案指南将在接近新年时开始，持续到Squid发布前后。 会议决定 确认了文档清理倡议的完成时间表。 确定了新手入门指南和V-Start文档规范化的工作计划。 明确了上下文帮助改进和解决方案指南的实施时间。 后续行动计划 完成RADOS文档清理工作。 开始新手入门指南的编写和V-Start文档的规范化工作。 规划上下文帮助的改进措施。 准备解决方案指南的编写。 其他讨论 社区对文档工作的积极反馈和认可。 讨论了文档错误报告流程的有效性。 确认了Ceph Quarterly（CQ）新闻简报的发布计划和内容。 会议结束时间： 30分钟 会议记录人： [记录人姓名] 备注： 会议中提到的Ceph Quarterly（CQ）新闻简报将每季度发布一次，内容包括过去90天内Ceph的开发进展，欢迎各团队负责人提供内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Squid: Telemetry","slug":"CDS_Squid_-_Telemetry","date":"2023-07-19T16:00:00.000Z","updated":"2023-07-20T16:00:00.000Z","comments":true,"path":"2023/07/20/CDS_Squid_-_Telemetry/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/20/CDS_Squid_-_Telemetry/","excerpt":"","text":"会议纪要 会议概要 日期与时间: [具体日期] 参会人员: CBS团队成员 会议目的: 讨论下一版本的开发计划，进行头脑风暴，收集新功能和改进的建议。 主要议题 集群内容分析与遥测工具 讨论内容: 讨论了如何通过遥测工具收集集群内容的摘要信息，如对象大小分布、BlueStore碎片化信息等，以支持去重和分块等功能的决策。 决定事项: 需要开发一个工具，使用liberators库来爬取目标池或集群，生成内容摘要，并通过遥测系统上报。 后续行动: 开发一个可插拔的框架来生成这些派生参数，并解决爬取过程中可能影响客户端IO的问题。 仪表板功能使用分析 讨论内容: 探讨了在仪表板中收集用户访问数据的可能性，以便优化仪表板的用户体验。 决定事项: 需要设计一个方案来收集和分析用户在仪表板上的行为，同时确保数据的安全性和隐私性。 后续行动: 设计并实现一个系统，用于跟踪用户在仪表板上的活动，并将数据存储在Manager中，以便Telemetry系统使用。 配置分析与用户反馈 讨论内容: 讨论了如何通过Telemetry数据来分析集群配置，提供配置建议，减少配置错误。 决定事项: 需要确定哪些配置数据可以安全地收集和分析，以及如何将分析结果反馈给用户。 后续行动: 设计一个方案来收集必要的配置数据，并开发一个系统来分析这些数据，提供配置建议。 崩溃报告优化 讨论内容: 讨论了如何优化崩溃报告的分组算法，减少重复和噪声。 决定事项: 需要进一步研究和优化崩溃签名的生成算法，特别是对于包含RocksDB帧的崩溃报告。 后续行动: 研究和实现新的崩溃分组算法，减少重复报告，并提高崩溃报告的准确性。 后续行动计划 开发集群内容分析工具，并集成到Telemetry系统中。 设计并实现仪表板使用数据的收集和分析系统。 确定并收集必要的配置数据，开发配置分析和反馈系统。 优化崩溃报告的分组算法，减少重复和噪声。 其他讨论 讨论了定期发布Telemetry项目新闻通讯的可能性，包括集群报告的数量和大小等信息。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的积极参与和宝贵意见。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-07-05","slug":"Ceph_RGW_Refactoring_Meeting_2023-07-05","date":"2023-07-04T16:00:00.000Z","updated":"2023-07-05T16:00:00.000Z","comments":true,"path":"2023/07/05/Ceph_RGW_Refactoring_Meeting_2023-07-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/05/Ceph_RGW_Refactoring_Meeting_2023-07-05/","excerpt":"","text":"会议纪要 会议主题：扩展用户存储桶数量的讨论 主要议题： - 当前用户存储桶列表存储在单个RADOS对象的omap中，随着存储桶数量的增加，可能会导致RADOS的omap过大，影响性能。 - 讨论了omap的最大键数限制（200,000），以及其对RADOS复制和恢复设计的影响。 - 提出了通过分片（sharding）策略来解决存储桶数量增长的问题，但需要考虑排序和分页的需求。 - 讨论了是否需要为存储桶列表API增加排序和分页功能。 决定事项： - 需要进一步研究和实现分片策略，以支持更大数量的存储桶。 - 需要评估和优化存储桶列表API的性能，考虑是否增加排序和分页功能。 后续行动计划： - 继续研究和测试分片策略，确保其能够有效支持大量存储桶。 - 评估存储桶列表API的需求，考虑是否需要增加排序和分页功能。 - 增加文档说明，明确用户存储桶数量的限制和相关性能影响。 会议主题：Lua包重载机制的改进 主要议题： - 当前Lua包重载需要重启RADOS网关（rgw），希望避免这种情况。 - 讨论了使用watch notify机制来实现无需重启的重载。 - 讨论了是否需要抽象出通知机制，以便未来支持其他存储后端。 决定事项： - 需要进一步研究和实现watch notify机制，以支持Lua包的动态重载。 - 需要考虑抽象出通知机制，以便未来支持其他存储后端。 后续行动计划： - 继续研究和测试watch notify机制，确保其能够有效支持Lua包的动态重载。 - 考虑抽象出通知机制，以便未来支持其他存储后端。 其他议题： 讨论了Bloom过滤器的最新进展，但没有新的更新。 会议总结： - 本次会议主要讨论了如何扩展用户存储桶数量和改进Lua包重载机制，确定了后续的研究和开发方向。 - 需要继续关注和研究相关技术细节，确保解决方案的有效性和性能。 下次会议预告： - 下次会议将继续讨论和评估本次会议确定的方案，并根据进展调整后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: SeaStore","slug":"Ceph_Code_Walkthroughs_-_SeaStore","date":"2023-07-02T16:00:00.000Z","updated":"2023-07-03T16:00:00.000Z","comments":true,"path":"2023/07/03/Ceph_Code_Walkthroughs_-_SeaStore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/03/Ceph_Code_Walkthroughs_-_SeaStore/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统中的新对象存储实现 - c-store 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： c-store简介： c-store是一个新的对象存储实现，专为Crimson的线程和回调模型设计。 目标：避免CPU密集型的元数据设计，如roxdb，并提供灵活的架构以支持多种存储配置和工作负载。 设计目标： 支持多种存储配置，包括QLC或ZNS闪存设备、硬盘以及高性能的NVMe设备。 实现内部层级管理（tiering），以减轻集群设置的设计参数压力，并允许更好地结合不同类型的存储池（如RGW和RBD）。 对象存储接口： 对象存储是OSD与其本地存储通信的接口，具有事务性和平面对象命名空间特性。 对象包含键值映射（omap）和数据负载，支持对象克隆和RADOS快照。 内部元数据结构： 包括LBA B树和back ref B树，这些结构通过逻辑偏移量进行管理，允许透明地移动数据块。 日志记录机制： c-store的日志记录机制在块级别上进行一致性处理，记录包括Delta和新的逻辑及物理块的完整记录。 架构组件： 主要组件包括onode manager、omap manager、object data handler、transaction manager等，这些组件处理逻辑地址并管理元数据结构。 缓存管理： c-store包含一个缓存，用于性能优化和确保事务进行中的正确性。 设备管理： 通过extent placement manager管理不同性能级别的设备，支持垃圾收集和层级管理。 未来工作： 继续优化多核支持，测试随机读写工作负载，并改进内部元数据结构。 决定事项： c-store已集成到Crimson实验版本中，未来六个月内将优先考虑其稳定性和性能优化。 后续行动计划： 继续测试c-store在不同工作负载下的表现，特别是RBD的随机读写性能。 收集社区反馈，特别是关于内部元数据结构的改进建议。 完成多核支持的开发，并确保c-store的稳定性和可靠性。 会议结束： 感谢所有参会人员的参与和贡献，期待社区的进一步反馈和支持。 备注：本次会议记录涵盖了c-store的主要设计目标、架构组件、设备管理和未来工作计划，确保了会议的关键细节和讨论成果得到准确记录。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-07-03","slug":"Ceph_Performance_Meeting_2023-07-03","date":"2023-07-02T16:00:00.000Z","updated":"2023-07-03T16:00:00.000Z","comments":true,"path":"2023/07/03/Ceph_Performance_Meeting_2023-07-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/03/Ceph_Performance_Meeting_2023-07-03/","excerpt":"","text":"会议纪要 会议时间 日期：具体未提供 参与者：Igor, Casey, Adam, Corey Snyder, Paul, 以及其他相关人员 主要议题 GCC 13 修复与 RocksDB 更新 讨论了关于 GCC 13 的修复问题，特别是针对 RocksDB 的 FTBFS（无法构建从源）问题。 决定将修复合并到 Reef 分支，并确保未来更新 Main 分支时能同步这些更改。 讨论了 RocksDB 的版本管理和更新策略，建议定期跟进 RocksDB 的主要版本更新。 Snappy 库的问题与替代方案 讨论了 Snappy 库在新的操作系统发行版中导致的编译问题，特别是与 RTTI 支持的缺失有关。 提出了几种解决方案，包括使用自定义的 Snappy 分支、禁用系统 Snappy 库等。 讨论了 Snappy 的性能和替代方案，建议考虑弃用 Snappy，特别是在 RGW 中的使用。 Elastic Shared Blobs PR 的讨论 讨论了关于 Elastic Shared Blobs 的 PR，特别是关于如何处理部分代码的 ifdefs 问题。 决定暂不合并 PR，而是先进行必要的修改以适应新的运行时条件。 RBD 性能测试结果分析 讨论了 RBD 在 Reef 和 Quincy 版本中的性能测试结果，特别是关于 CPU 使用率和 I/O 效率的问题。 提出了一些假设和测试方向，包括调整内存目标大小、不同 I/O 大小的测试等。 决定事项 确认了 RocksDB 的更新策略，建议定期跟进主要版本更新。 对于 Snappy 库的问题，决定先观察其他发行版的处理方式，再决定具体实施方案。 Elastic Shared Blobs PR 将进行必要的修改后再考虑合并。 后续行动计划 继续监控和分析 RBD 性能测试结果，特别是关于 RocksDB 和 I/O 效率的问题。 跟进 Snappy 库的问题，特别是与其他发行版的协调和处理方式。 修改并重新审查 Elastic Shared Blobs PR，确保其符合新的运行时条件后进行合并。 其他讨论 讨论了 Debian 和 Fedora 对于 Snappy 库的处理方式，建议在主问题跟踪器中记录相关问题。 讨论了 RBD 性能测试中的具体细节和可能的优化方向。 会议结束 会议在讨论完所有议题后结束，感谢所有参与者的贡献，并祝愿大家有一个愉快的一周。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-06-07","slug":"Ceph_RGW_Refactoring_Meeting_2023-06-07","date":"2023-07-02T16:00:00.000Z","updated":"2023-07-02T16:00:00.000Z","comments":true,"path":"2023/07/03/Ceph_RGW_Refactoring_Meeting_2023-06-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/03/Ceph_RGW_Refactoring_Meeting_2023-06-07/","excerpt":"","text":"会议纪要 会议时间：[具体时间] 会议地点：[线上/线下] 参会人员：[参会人员名单] 会议议程： 修复版本到对象一致性Bug的工作进展 讨论了由Corey Snyder负责的关于resharding相关的一致性Bug修复工作。 提到了相关Bug的讨论邮件已在用户列表中发布，并分享了一个指向Pull Request的链接，其中包含修复和检查工具。 表达了对Bloomberg等公司参与测试或开发的兴趣。 技术细节和后续行动 确认了Pull Request 51700的相关工作。 讨论了新resharding逻辑中已修复的Bug，并计划将特定修复回溯到Pacific和Quincy版本。 工具的修复将合并到Main中，并进行回溯。 其他讨论事项 提到了即将举行的CPP会议，Bernie Straw Troop将参加。 决定事项： 继续关注和参与Corey Snyder的Bug修复工作，鼓励更多公司和开发者参与测试和开发。 确保修复工具和代码回溯到相关版本。 后续行动计划： 跟踪Pull Request 51700的进展。 准备回溯修复到Pacific和Quincy版本。 关注CPP会议的进展和Bernie Straw Troop的参与情况。 会议结束语： 会议在简短的讨论后结束，感谢所有参与者的贡献和时间。 会议记录人：[记录人姓名] 会议日期：[具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-06-14","slug":"Ceph_RGW_Refactoring_Meeting_2023-06-14","date":"2023-07-02T16:00:00.000Z","updated":"2023-07-02T16:00:00.000Z","comments":true,"path":"2023/07/03/Ceph_RGW_Refactoring_Meeting_2023-06-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/03/Ceph_RGW_Refactoring_Meeting_2023-06-14/","excerpt":"","text":"会议纪要 会议主题：Ceph存储优化与功能讨论 参会人员：Ceph研发团队成员 会议时间：[具体日期] 主要议题及讨论内容： MD5优化与E-Tag计算 讨论内容：会议开始讨论了关于MD5优化以提高E-Tag计算效率的问题。之前有尝试通过后台线程卸载MD5计算，但由于线程同步成本过高而未成功。目前考虑使用XMD和向量化方法，已发现速度提升可达5倍。提出了使用AC+库的AVX2实现进行实验的可能性。 决定事项：希望有兴趣的团队成员尝试这一优化，以减少CPU使用率。 后续行动：将联系Mark进行评估，并进行性能测试。 多重Zipper后端与过滤器 讨论内容：Ali提出了关于多重Zipper后端或过滤器的工作，特别是在D4和d3n缓存工作中需要使用多个过滤器。讨论了如何通过JSON配置实现多重过滤器和后端的嵌套。 决定事项：需要定义每种驱动程序的JSON格式，并创建相应的工厂函数。 后续行动：Ali将开始研究并实现这一功能。 OLH修复 讨论内容：Corey更新了关于OLH修复的PR，解决了并发问题和遗留的索引条目问题。讨论了如何更好地测试这些并发场景。 决定事项：需要进一步讨论如何进行更全面的并发测试，包括可能的随机延迟注入和错误注入。 后续行动：Corey将继续完善PR，并探索更多的测试方法。 通知重试机制 讨论内容：Krunal讨论了通知重试机制的改进，特别是从Rados对象转换到FIFO对象的需求。 决定事项：需要进一步讨论如何限制FIFO的大小，以及是否需要设置重试次数或时间限制。 后续行动：Krunal将开始转换工作，并继续讨论其他设计细节。 其他讨论点： 数据同步公平性的测试问题，目前仍在解决一些崩溃和边缘案例。 会议总结： 会议涵盖了多个技术优化和功能改进的讨论，涉及MD5优化、多重Zipper后端、OLH修复和通知重试机制。团队成员将根据讨论结果进行后续的开发和测试工作。 下一步行动： 联系Mark进行MD5优化评估。 Ali开始多重Zipper后端的研究和实现。 Corey继续完善OLH修复PR并探索更多测试方法。 Krunal开始通知重试机制的转换工作，并继续讨论设计细节。 会议结束： 感谢所有参与者的贡献，期待下一次会议的进展汇报。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-06-28","slug":"Ceph_RGW_Refactoring_Meeting_2023-06-28","date":"2023-07-02T16:00:00.000Z","updated":"2023-07-02T16:00:00.000Z","comments":true,"path":"2023/07/03/Ceph_RGW_Refactoring_Meeting_2023-06-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/07/03/Ceph_RGW_Refactoring_Meeting_2023-06-28/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph Reef版本的更新、异步请求重构、线程池优化以及从librados迁移到Neo-rados的计划。 主要议题 Reef版本更新 目前计划将两个问题作为Reef版本的阻塞项： 版本化对象一致性问题，Corey Snyder正在处理。 多站点中加密对象损坏问题，Marcus已识别压缩为潜在原因。 需要解决这些问题，否则会导致功能退化。 异步请求重构 最近合并了一个大型PR，扩展了可选的异步处理路径。 计划引入回归测试，确保所有阻塞的librados调用都被发现并防止新增。 讨论了如何在编译时和运行时检查阻塞调用，特别是在Ezio线程中。 线程池优化 当前线程池有512个线程，数量过多。 计划在消除所有阻塞调用后，大幅降低线程池大小，可能调整为核心数的一个小倍数。 从librados迁移到Neo-rados Jason Dillerman在RGW团队中发现切换到Neo-rados有显著性能提升。 讨论了逐步转换的可能性，以及如何管理同时使用librados和Neo-rados的过渡期。 决定事项 需要解决版本化对象一致性和加密对象损坏问题，以避免功能退化。 引入回归测试，确保异步请求的正确性和防止新增阻塞调用。 计划降低线程池大小，并进行性能测试以确定最佳大小。 逐步从librados迁移到Neo-rados，可能采用分系统逐步转换的方式。 后续行动计划 继续跟踪和解决版本化对象一致性问题。 与Marcus合作解决加密对象损坏问题。 实施回归测试，确保异步请求的非阻塞性。 进行线程池大小调整的性能测试。 开始逐步从librados迁移到Neo-rados的工作，可能由calpesh负责。 其他讨论点 讨论了如何处理阻塞的后端存储，如SQLite，以及如何在未来可能完全移除null yield时保持系统的可扩展性。 会议结束 会议在讨论完所有议题后结束，感谢所有参与者的贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-05-31","slug":"Ceph_RGW_Refactoring_Meeting_2023-05-31","date":"2023-05-30T16:00:00.000Z","updated":"2023-05-31T16:00:00.000Z","comments":true,"path":"2023/05/31/Ceph_RGW_Refactoring_Meeting_2023-05-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/31/Ceph_RGW_Refactoring_Meeting_2023-05-31/","excerpt":"","text":"会议纪要 会议主题：字符串优化及通知重试清理讨论 参会人员：Gabby, Yuval, Eugene, 及其他相关开发人员 主要议题： 字符串优化（Gabby 和 Yuval） 讨论内容： 针对S3属性名称（如x-amz-meta-等长字符串）的优化。 属性名称存在多个地方，包括消息、中间结构（如Redis网关）和对象内部。 提议通过哈希将这些长字符串转换为短整数，以减少动态字符串分配和内存使用。 讨论了两种优化级别：在rgw内部进行转换和向客户端发送转换表。 决定事项： 建议首先在OSD层进行优化，隐藏在内部，不改变现有librados API。 rgw可以管理一个本地缓存，从OSD获取转换表，避免全局同步问题。 后续行动： 继续讨论并确定最佳实施方案。 开发一个测试工具来验证实际使用的属性名称数量。 通知重试和清理（Grinnell） 讨论内容： 讨论了通知重试机制，特别是在Kafka broker不可用时的行为。 当前设计是无限重试，直到队列满后向S3客户端发送慢速响应。 提出了几种改进方案，包括设置重试次数上限和清理过期通知。 决定事项： 发起邮件讨论，收集社区意见，确定最佳方案。 后续行动： 发送邮件到用户列表，讨论并收集反馈。 其他事项 Bucket Level Redirect Zone 原型（Eugene） 讨论了相关PR，但未深入细节。 Reef多站点测试更新（Shilpa） Mark成功完成了4亿对象的同步负载测试，未发现回归问题。 下一步行动： 继续讨论字符串优化方案，并开发测试工具。 发送邮件讨论通知重试和清理的最佳方案。 跟进Bucket Level Redirect Zone原型的进一步讨论。 继续Reef的多站点测试，确保无回归问题。 会议结束： 会议超时结束，感谢所有参与者的贡献，期待下次会议。 以上是本次会议的详细纪要，涵盖了关键讨论点、决定事项及后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-05-24","slug":"Ceph_RGW_Refactoring_Meeting_2023-05-24","date":"2023-05-23T16:00:00.000Z","updated":"2023-05-24T16:00:00.000Z","comments":true,"path":"2023/05/24/Ceph_RGW_Refactoring_Meeting_2023-05-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/24/Ceph_RGW_Refactoring_Meeting_2023-05-24/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题及讨论内容 Reef版本候选发布通知 即将发布Reef版本的候选版本，计划下周进行切割。 确保所有已合并到主分支的bug修复都已准备就绪，以便纳入RC版本进行测试。 需要加强多站点（multi-site）的测试，目前缺乏可靠的多站点测试。 计划与Mark安排会议，讨论如何推进多站点测试。 Kafka库的修复 有两个关于Kafka库的修复，这些修复解决了崩溃问题。 这些修复已经在下游QE中验证，但仍需通过Tautology测试。 需要进行代码审查并可能需要QA标签。 Rook中的DBStore集成 讨论了在Rook中集成DBStore的可能性，特别是对于需要轻量级解决方案的用户。 DBStore目前不支持所有S3操作，因此需要用户进行测试以确定其适用性。 需要进一步讨论和文档化如何在Rook中设置DBStore。 Bucket Notifications和Multi-Site支持 讨论了如何支持Bucket Notifications的元数据同步。 需要实现所有元数据接口，参考Prisa在STS中对角色的实现。 决定事项 下周将发布Reef版本的候选版本。 需要安排与Mark的会议，讨论多站点测试的推进。 Kafka库的修复将进行进一步的测试和审查。 将在Rook中探索DBStore的集成，并标记为实验性功能。 需要进一步讨论和实现Bucket Notifications的元数据同步。 后续行动计划 确保所有bug修复都已准备就绪，以便纳入Reef RC版本。 安排与Mark的会议，讨论多站点测试的具体实施。 完成Kafka库修复的测试和审查，并确保其纳入主分支。 在Rook中集成DBStore，并提供清晰的设置文档。 研究并实现Bucket Notifications的元数据同步功能。 其他事项 安排了关于Lewis脚本代码走查的演讲，预计在半小时后进行。 会议结束 感谢所有参会人员的参与和贡献，会议圆满结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: RGW Lua Scripting Code Walkthrough","slug":"Ceph_Tech_Talk_-_RGW_Lua_Scripting_Code_Walkthrough","date":"2023-05-23T16:00:00.000Z","updated":"2023-05-24T16:00:00.000Z","comments":true,"path":"2023/05/24/Ceph_Tech_Talk_-_RGW_Lua_Scripting_Code_Walkthrough/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/24/Ceph_Tech_Talk_-_RGW_Lua_Scripting_Code_Walkthrough/","excerpt":"","text":"会议纪要 会议主题： Seth Tech Talk - Lua脚本在RGW中的应用 会议时间： [具体时间] 会议地点： 线上会议 主讲人： Paul 参会人员： 开发团队成员、技术爱好者 会议内容总结： 介绍与欢迎 会议由Mike主持，欢迎大家参加Seth Tech Talk，并鼓励有兴趣的成员提供技术内容。 Mike提供了联系方式，以便有兴趣分享技术内容的成员与他联系。 主题介绍 Paul将介绍Lua脚本在RGW（Red Hat Ceph Storage Gateway）中的应用，重点是代码走读。 他提到之前在开放源代码峰会上有过详细的解释和演示，本次会议将聚焦于代码层面的细节。 Lua脚本功能概述 Lua脚本功能旨在扩展和增强RGW的功能，主要通过两种方式：增加新的钩子位置和扩展现有钩子的功能。 目前Lua脚本主要在预请求和后请求上下文中使用，未来计划增加更多功能，如支持多个脚本在同一上下文中运行。 代码结构与管理 讨论了Lua脚本和包的管理，包括如何上传、下载和删除脚本，以及如何添加和移除Lua包。 强调了Lua包的管理需要谨慎，因为涉及编译和安装过程，目前这些操作仅在RGW启动时进行。 Lua脚本执行细节 详细解释了Lua脚本的执行过程，包括创建Lua虚拟机、加载标准库、设置包路径等。 讨论了如何在Lua中访问和操作C++结构中的数据，以及如何实现可写和可迭代的数据结构。 数据和背景上下文 介绍了数据上下文，主要用于对象的PUT和GET操作，允许对数据进行过滤和处理。 背景上下文是一个定期运行的线程，可以执行Lua脚本，并有一个全局表用于不同脚本间的通信。 问题与讨论 与会者提出了关于文档、特定用例实现和Lua包存储位置的问题。 讨论了在容器化部署中使用Lua脚本和包管理的一些挑战和可能的解决方案。 后续行动计划： - 继续完善Lua脚本功能的文档和示例代码。 - 考虑增加外部包管理选项，以减少对RGW内部包管理的依赖。 - 解决容器化部署中Lua包管理的具体问题，确保环境的兼容性和稳定性。 会议结束语： - Mike感谢Paul的精彩分享和所有参与者的积极参与。 - 会议记录和视频将被整理并尽快发布。 备注： - 本次会议的技术内容较为深入，涉及Ceph RGW的Lua脚本集成和扩展，适合有一定技术背景的开发人员。 - 对于希望了解更多细节的参会者，建议回顾会议录像和相关文档。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC: An Introduction to MicroCeph","slug":"Ceph_Days_NYC_-_An_Introduction_to_MicroCeph","date":"2023-05-18T16:00:00.000Z","updated":"2023-05-19T16:00:00.000Z","comments":true,"path":"2023/05/19/Ceph_Days_NYC_-_An_Introduction_to_MicroCeph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/19/Ceph_Days_NYC_-_An_Introduction_to_MicroCeph/","excerpt":"","text":"会议纪要 会议主题：Microsoft Snap 在 Ceph 集群管理中的应用 主讲人：Chris 会议内容总结： Snap 介绍： Chris 介绍了 Microsoft Snap，这是一个由 Canonical 开发的集群管理工具。 Snap 使用 Dqlite，一个兼容 SQLite 的数据库，采用 Raft 共识算法。 管理 Daemon 允许构建任意节点的集群，用于管理各种 Ceph 守护进程（如 Monitors、Managers、OSDs、Metadata Servers 等）。 使用场景： 支持单节点 Ceph 部署，适合在笔记本电脑上运行，严格限制权限，类似于手机应用。 支持小型边缘集群部署，快速、可预测，适合非 Ceph 专家的普通部署者。 演示环节： 展示了如何通过 Snap 快速部署 Ceph 集群，包括启动集群、添加节点、配置管理 Daemon 等。 演示了如何添加 OSDs 和设置 Ceph 集群，尽管集群初始化时没有存储。 展示了如何启用和配置 Ceph 的 RGW（Red House Gateway），并进行了简单的 S3 操作演示。 后续计划： 未来工作包括自动化加密、网络配置、升级管理等。 强调了用户反馈的重要性，鼓励用户尝试并提供意见。 技术细节： Snap 不使用 LDM，而是直接使用块设备，以便更好地进行权限限制。 讨论了从单机部署扩展到数据中心部署的可能性。 问题与回答： 回答了关于 Snap 使用的管理 Daemon 和集群状态管理的问题。 讨论了 Snap 在不同环境下的部署和扩展性。 决定事项： 继续开发和完善 Snap 的功能，特别是自动化加密和升级管理。 鼓励用户尝试并提供反馈，以便进一步改进产品。 后续行动计划： 继续进行技术开发和功能完善。 收集和分析用户反馈，优化产品体验。 探索更多部署和扩展场景，提高产品的适应性和灵活性。 会议结束： 会议在感谢和掌声中结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC: State of the Cephalopod","slug":"Ceph_Days_NYC_-_State_of_the_Cephalopod","date":"2023-05-18T16:00:00.000Z","updated":"2023-05-19T16:00:00.000Z","comments":true,"path":"2023/05/19/Ceph_Days_NYC_-_State_of_the_Cephalopod/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/19/Ceph_Days_NYC_-_State_of_the_Cephalopod/","excerpt":"","text":"会议纪要 会议概述 会议主持人对与会者表示欢迎，并强调了自上次面对面会议以来，社区成员的重聚意义重大。会议主要讨论了Ceph项目的最新进展、未来计划以及技术特性的改进。 主要议题 社区治理模型变更： Ceph项目已从单一领导模型转变为理事会模型，由各组件负责人选举产生，负责项目的技术治理和社区管理。 重点发展领域： 质量、性能和可扩展性：加强大规模测试，改进发布流程，引入RC版本供用户测试。 性能优化：特别关注Crimson项目，旨在提高性能和扩展性。 用户反馈：通过Telemetry项目收集匿名数据，了解集群使用情况，优化产品。 版本更新： 原计划于3月发布的Reef版本因实验室故障推迟至6月。 继续每年发布一个主要版本，并逐步淘汰旧版本。 技术特性与改进： 性能与扩展性：在多个大型集群上进行测试，包括澳大利亚超级计算中心。 稳定性与可靠性：引入m-clock调度器，改进QoS（服务质量），优化数据平衡和客户端性能。 Crimson项目：重新实现OSD，采用无共享架构，目前处于实验阶段，未来将支持更多功能。 CephFS和RGW：改进用户界面，增强多站点支持和监控功能。 部署与管理： fadm和Rook：简化部署流程，支持容器化和Kubernetes集成，增强故障诊断能力。 RBD和RGW的进一步优化： RBD：增强多站点镜像功能，支持高性能协议如NVMe-oF。 RGW：优化多站点复制性能，引入OpenTelemetry进行分布式追踪。 测试与质量保证： 改善开发者体验，优化本地测试环境，增强实验室基础设施的韧性。 探索与其他组织合作，共享硬件资源，提高测试效率。 决定事项 Reef版本的发布推迟至6月。 继续推进性能、质量和可用性的改进。 加强社区合作，优化测试和开发环境。 后续行动计划 完成Reef版本的开发和测试，确保按时发布。 持续优化Crimson项目，提升其稳定性和性能。 加强与社区成员的沟通，收集反馈，持续改进产品。 其他 会议中还讨论了QoS的细粒度控制，未来将支持基于图像级别的策略配置。 会议在感谢和掌声中结束，鼓励与会者如有任何问题，可随时提出或会后交流。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Dynamic multi-cluster management with Rook for cloud native IaaS providers for the private clouds","slug":"Dynamic_multi-cluster_management_with_Rook_for_cloud_native_IaaS_providers_for_the_private_clouds","date":"2023-05-18T16:00:00.000Z","updated":"2023-05-19T16:00:00.000Z","comments":true,"path":"2023/05/19/Dynamic_multi-cluster_management_with_Rook_for_cloud_native_IaaS_providers_for_the_private_clouds/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/19/Dynamic_multi-cluster_management_with_Rook_for_cloud_native_IaaS_providers_for_the_private_clouds/","excerpt":"","text":"会议纪要 会议参与者介绍 发言人：一位专注于欧洲市场的企业顾问，曾为Red Hat工作，现为某公司的董事会成员和基金会大使。该公司成立于2010年，总部位于慕尼黑，专注于基础设施和平台即服务（PaaS），是Linux Foundation和Cloud Native Foundation的成员。 产品介绍 产品名称：Dynamic multi-cloud cluster management 开发时间：自2020年开始，预计持续至2024年。 关键特点： 无供应商锁定 开源可扩展性 纯IPv6 Kubernetes驱动 仅使用微服务作为工作负载 从公共云到私有云的迁移 生产中超过200 PB的内存占用 项目动机与需求 需求背景：项目需求多样化，包括独占和共享用例、故障域、可用区域、数据中心、安全隔离等。 解决方案：动态多集群管理，以适应不断变化的用户需求和应用堆栈的需求。 技术实现细节 资源管理：通过Kubernetes管理不同的资源池，动态添加和移除Ceph节点。 数据管理：Rook和Ceph CSI负责数据管理和质量保证。 改进与扩展： 重构Rook 改进Ceph的监控和恢复选项 扩展RBD元数据 改进RBD加密 当前进展与未来计划 当前状态：已部署300个集群，每个集群包含16至35个OSD。 未来方向： 扩展到更大规模的集群 不支持虚拟机，转向标准Kubernetes PV/PVC堆栈 探索NVMe over TCP和SmartNIC的安全隔离 改进Rook和Ceph的日常操作 探索备份策略和数据导出技术 提问与讨论 问题澄清：关于CSI驱动器的使用和未来计划。 技术细节：讨论了NVMe over TCP、SmartNIC支持、BGP的使用、RBD备份等。 结论 总结：项目复杂，涉及多方面的技术改进和扩展，将持续关注和改进以满足不断变化的需求。 感谢与结束：感谢参与者的详细介绍和讨论，会议圆满结束。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Introducing Sibench: A New Open Source Benchmarking Tool Optimized for Ceph","slug":"Introducing_Sibench_-_A_New_Open_Source_Benchmarking_Tool_Optimized_for_Ceph","date":"2023-05-18T16:00:00.000Z","updated":"2023-05-19T16:00:00.000Z","comments":true,"path":"2023/05/19/Introducing_Sibench_-_A_New_Open_Source_Benchmarking_Tool_Optimized_for_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/19/Introducing_Sibench_-_A_New_Open_Source_Benchmarking_Tool_Optimized_for_Ceph/","excerpt":"","text":"会议纪要 会议主题：Ceph 性能基准测试工具 Sidebench 的介绍与讨论 参会人员：Ceph 社区成员及研发人员 会议时间：[具体日期] 会议地点：[具体地点] 主要议题： 基准测试的挑战与痛点 基准测试过程中的复杂性和变量控制问题。 Ceph 的多接口和多工作负载特性增加了基准测试的难度。 工作负载对操作员的不透明性，以及 Ceph 后台任务对性能的影响。 Cosbench 的问题与替代方案 Cosbench 的使用历史和存在的问题，如 Java Native Interface (JNI) 的高开销、维护不足、架构脆弱等。 介绍 Sidebench 作为 Cosbench 的替代方案，强调其简单、轻量、易于调试和线性可扩展性。 Sidebench 的设计目标与功能 设计目标包括低开销、直接调用 C 库、多线程支持、数据格式灵活性等。 功能包括多协议支持（RADOS, RBD, CephFS, S3）、带宽限制、数据切片生成、读写混合测试等。 Sidebench 的架构与使用示例 Sidebench 包含一个守护进程和命令行工具，支持多节点分布式测试。 演示了如何使用 Sidebench 进行 RADOS 和 RBD 的基准测试，以及如何通过 Benchmaster 进行多变量测试。 未来发展方向与社区反馈 讨论了 Sidebench 的未来发展方向，如工作负载生成器、OSD 数量扫描、元操作支持等。 强调社区参与和反馈的重要性，鼓励用户使用并贡献代码。 决定事项： 继续开发和完善 Sidebench，特别是在工作负载生成和多变量测试方面。 鼓励社区成员参与 Sidebench 的测试和开发，提供反馈和建议。 后续行动计划： 发布 Sidebench 的最新版本，并提供详细的安装和使用文档。 组织线上研讨会或工作坊，进一步介绍 Sidebench 的功能和最佳实践。 收集和分析社区反馈，根据需求调整开发计划。 备注： Sidebench 的代码和文档可在 sidebench.io 和 GitHub 上获取。 会议中提到的 Benchmaster 是一个用于管理多基准测试的 Python 工具，支持输出结果到 Google Sheets。 本次会议详细讨论了 Ceph 基准测试工具的发展和优化，特别是 Sidebench 的引入和未来规划，旨在提高 Ceph 性能测试的效率和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"An Initial Look at Deep Learning IO Performance - Mark Nelson, Clyso GmbH","slug":"An_Initial_Look_at_Deep_Learning_IO_Performance_-_Mark_Nelson_Clyso_GmbH","date":"2023-05-17T16:00:00.000Z","updated":"2023-05-18T16:00:00.000Z","comments":true,"path":"2023/05/18/An_Initial_Look_at_Deep_Learning_IO_Performance_-_Mark_Nelson_Clyso_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/18/An_Initial_Look_at_Deep_Learning_IO_Performance_-_Mark_Nelson_Clyso_GmbH/","excerpt":"","text":"会议纪要 会议概述 本次会议是会议的最后一场演讲，演讲者感谢与会者的参与，并表达了在众多选择中大家选择留下来听他演讲的荣幸。演讲主题围绕AI在存储领域的应用，特别是在深度学习训练中的存储需求和优化策略。 讨论主要议题 AI市场的存储需求： 演讲者提到，AI市场去年达到1360亿美元，存储需求正在增长。 引用了IBM某人的话，指出现在至少有数PB的数据需要管理。 深度学习与存储： 讨论了深度学习的基本概念，包括使用人工神经网络分析和学习复杂数据结构。 提到了流行的AI模型如ChatGPT和Stable Diffusion，但主要关注点是图像分类，这是一个360亿美元的市场。 存储优化策略： 强调了使用TF Records的重要性，它可以减少文件读取次数，转换为大顺序读取，从而优化存储性能。 讨论了不同GPU（如V100和H100）对存储性能的影响，以及如何通过调整参数和使用新技术（如Nvidia的Dali框架）来优化性能。 实验与结果： 在Lambda Labs进行的实验显示，使用TF Records可以显著提高图像处理速度，从每秒处理几千张图像提升到上万张。 讨论了不同存储解决方案（如RBD、RADOS Gateway和CephFS）在处理大规模数据集时的表现。 决定的事项 确认了TF Records在优化深度学习训练中的存储性能方面的重要性。 讨论了未来可能的技术发展，如GPU Direct Storage，以进一步优化数据传输效率。 后续行动计划 继续研究和优化存储解决方案，以适应不断增长的AI训练需求。 探索新的技术如GPU Direct Storage和Dali框架，以提高数据处理速度和效率。 鼓励与会者尝试和实验不同的存储和数据处理策略，以找到最适合其应用场景的解决方案。 结论 演讲者鼓励大家继续探索和优化AI训练中的存储问题，并期待未来能有更多创新和高效的解决方案出现。会议在轻松的氛围中结束，与会者被邀请前往酒吧放松。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson Verification on AArch64 - Rixin Luo, Huawei","slug":"Ceph_Crimson_Verification_on_AArch64_-_Rixin_Luo_Huawei","date":"2023-05-17T16:00:00.000Z","updated":"2023-05-18T16:00:00.000Z","comments":true,"path":"2023/05/18/Ceph_Crimson_Verification_on_AArch64_-_Rixin_Luo_Huawei/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/18/Ceph_Crimson_Verification_on_AArch64_-_Rixin_Luo_Huawei/","excerpt":"","text":"会议纪要 会议主题：Crimson验证在Arc 34上的部署与优化 会议时间：[具体日期] 会议地点：[具体地点] 主持人：Lindsay 参会人员：[参会人员名单] 会议内容： 部署与优化 部署方法：通过yum文件添加代码，支持在ARM版本上构建Crimson镜像，并使用Benchmark工具如rados bench和fio进行性能测试。 优化进展：PRS self-adium部分已由Adam King审核，希望有人能帮助审查并合并。 内存泄漏与浪费 问题描述：在内存存储中，大量小写操作会导致缓冲区列表包含许多无效数据，无法重用保留的内存页，可能导致内存不足。 解决计划：将问题贡献给社区，并继续优化。 性能优化 瓶颈分析：发现原子操作在内存端口模块中占用近35%的 overhead，建议禁用lse指令以减少争用。 测试结果：禁用lse后，使用2MB页面大小，对于小包和大包分别获得50%和8%的性能提升。 多节点集群测试 测试环境：使用三台ARM服务器构建测试场景，使用36个OSD和三副本。 测试结果：系统在单次测试中表现良好，但与经典BlueStore相比，性能仍有差距，正在进行优化。 社区贡献与未来计划 贡献内容：将优化代码和协议贡献给社区，包括内存池和缓冲区列表的优化。 未来工作：继续优化Ceph存储系统，特别是C-Store部分，解决读写放大问题，并进行更多测试案例和CI集成。 决定事项： 继续优化Crimson的部署和性能，特别是内存管理和原子操作的优化。 将优化成果和协议贡献给Ceph社区。 后续行动计划： 完成PRS self-adium部分的合并。 继续进行多节点集群的性能测试和优化。 解决内存泄漏和浪费问题，并贡献给社区。 优化C-Store的读写放大问题，并进行更多测试。 会议结束： 会议在提问环节后圆满结束，Lindsay感谢大家的参与和贡献。 备注： 如有进一步问题或需要更多技术细节，请联系Jason Johnson或发送邮件至[相关邮箱]。 [会议纪要结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Tuning: From Bluestore to RBD - Mark Nelson, Clyso GmbH","slug":"Ceph_Performance_Tuning_-_From_Bluestore_to_RBD_-_Mark_Nelson_Clyso_GmbH","date":"2023-05-17T16:00:00.000Z","updated":"2023-05-18T16:00:00.000Z","comments":true,"path":"2023/05/18/Ceph_Performance_Tuning_-_From_Bluestore_to_RBD_-_Mark_Nelson_Clyso_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/18/Ceph_Performance_Tuning_-_From_Bluestore_to_RBD_-_Mark_Nelson_Clyso_GmbH/","excerpt":"","text":"会议纪要 会议主题： Ceph性能调优及工具介绍 主讲人： Mark Nelson 会议时间： 会议最后一天，下午5点 会议内容总结： 开场与自我介绍 Mark Nelson，Ceph性能团队成员，拥有10年相关经验，目前就职于Clyso。 讨论主题：Ceph性能调优及一般性能问题。 Ceph性能概述 讨论了Ceph性能的复杂性，引用Neil Stevenson的话：“性能取决于具体情况”。 介绍了CBT（Ceph Benchmarking Tool），一个用于性能测试的工具，支持多种测试工具如fio, hsbench等。 性能调优工具 介绍了CBT的功能，包括快速部署60 OSD集群，支持多种测试工具，以及详细的测试监控和诊断。 提到了同事正在开发的仪表板，用于更直观地展示测试结果。 性能优化案例 硬件问题： SSD固件升级解决了高Q等待时间问题，但问题后来复发，可能与SSD的写入行为有关。 软件问题： PG计数对性能的影响，低PG计数导致资源争用和性能下降，建议使用足够的PG计数。 RBD快照修剪： 通过优化共享blob的处理，显著减少了CPU使用率。 OSD线程优化： 在资源有限的情况下，减少线程数可以提高效率。 PG日志与RocksDB交互： 通过调整RocksDB参数和实验性日志原型，改善了随机写性能。 结论与建议 强调了理解性能问题背后的行为和原因的重要性，而不仅仅是复制调优参数。 鼓励大家关注Ceph社区的博客和文档，以获取更多性能调优的信息和案例。 后续行动计划： - 继续开发和完善性能调优工具，如CBT和仪表板。 - 探索和实施更多的性能优化措施，特别是在硬件和软件交互方面。 - 加强社区合作，分享和讨论性能调优的最佳实践。 会议结束： 感谢大家的参与，Mark Nelson将继续参与其他会议和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Enabling Near-Data Processing in Ceph - Rixin Luo, Huawei","slug":"Enabling_Near-Data_Processing_in_Ceph_-_Rixin_Luo_Huawei","date":"2023-05-17T16:00:00.000Z","updated":"2023-05-18T16:00:00.000Z","comments":true,"path":"2023/05/18/Enabling_Near-Data_Processing_in_Ceph_-_Rixin_Luo_Huawei/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/18/Enabling_Near-Data_Processing_in_Ceph_-_Rixin_Luo_Huawei/","excerpt":"","text":"会议纪要 会议主题：启用近数据处理（Near Data Processing） 主讲人：Russian Law 会议内容总结： 近数据处理简介： 近数据处理是一种新的计算范式，允许将计算移动到数据所在的位置，或将数据放置在计算附近，以减少数据移动。 Ceph定义了计算存储（Computational Storage），可以在设备上添加计算功能，将主机处理卸载到设备上。 挑战与现有解决方案： 近数据处理面临的主要挑战是数据放置问题。Ceph的数据流模型和擦除码（Erasure Code）会导致数据对象被分割，从而丢失部分信息。 Ceph当前的分布式存储系统设计侧重于高性能和高可靠性，而非近数据处理。 Ceph的存储池类型： Ceph有两种存储池：副本池（Replica Pool）和擦除码池（Erasure Code Pool）。 副本池提供高性能但空间利用率低，而擦除码池提供高空间利用率但性能较低。 解决方案：启用近数据处理： 关键在于保持对象的完整性，不分割存储对象。通过添加聚合模块（Aggregate Module），将相同ID的对象合并为新的聚合对象。 聚合规则包括：聚合对象大小等于擦除码条带大小，不进行分割。 支持元数据： 元数据用于将对象ID映射到聚合对象ID，作为omap项存储。 近数据处理操作： 通过在OST（Object Storage Target）中添加新的数据处理请求和模块，执行数据库查询、正则表达式匹配等操作。 这些操作可以扩展第三方库，通过加载第三方库来执行近数据处理操作。 测试结果： 测试使用6个OST和4+2擦除码数据条带，比较了基本擦除码和聚合擦除码的性能。 结果显示，聚合擦除码在读取中间2MB数据时，减少了集群间的流量，从而减少了数据移动。 后续行动计划： 继续开发和优化近数据处理功能，支持更多数据处理操作。 考虑将计算功能卸载到计算存储设备上，以提高性能。 讨论与问题： 与会者提问关于对象类（Object Classes）和Skyhook项目，主讲人表示这些方案与近数据处理的实现方式不同，但值得进一步研究和考虑。 会议结束： 主讲人感谢大家的参与，并邀请进一步的问题和讨论。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimizing Ceph Object Storage for Analytics and AL/ML Workloads - Overview and Future Plans","slug":"Optimizing_Ceph_Object_Storage_for_Analytics_and_AL_ML_Workloads_-_Overview_and_Future_Plans","date":"2023-05-17T16:00:00.000Z","updated":"2023-05-18T16:00:00.000Z","comments":true,"path":"2023/05/18/Optimizing_Ceph_Object_Storage_for_Analytics_and_AL_ML_Workloads_-_Overview_and_Future_Plans/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/18/Optimizing_Ceph_Object_Storage_for_Analytics_and_AL_ML_Workloads_-_Overview_and_Future_Plans/","excerpt":"","text":"会议纪要 会议主题：优化 Ceph 以支持 AI 和 ML 工作负载 会议时间：[具体日期] 会议地点：[具体地点] 参会人员： Kyle Bader - IBM 首席产品架构师，Ceph 存储工程经理 Matt - [具体职位] 其他参会人员 - [列出其他重要参会人员] 会议内容总结： 背景介绍 Kyle Bader 介绍了 Ceph 在数据湖分析、AI 和 ML 领域的应用历史和现状。 2017 年，Ceph 团队与来自不同行业的四家客户（医疗、金融服务、电信和零售）合作，探讨如何优化 Ceph 作为对象存储以支持大数据环境。 当前挑战与机遇 目前，大多数用户已将存储与数据处理环境解耦，数据湖通常位于对象存储（如 Blob 存储）中。 随着 AI 和 ML 工作负载的增加，需要专门的硬件加速器进行推理和训练，这要求存储与计算资源分离。 Ceph 的优化方向 扩展性：Ceph 已经能够支持数十亿对象的存储，单个集群可达到数十 PB 的容量。 性能：通过测试，Ceph 在 10 节点磁盘集群上实现了 80 GB/s 的吞吐量。 功能增强：引入了版本控制、MFA 删除、对象锁定、桶通知、S3 Select 等功能，以更好地支持 AI 和 ML 工作负载。 与 Massachusetts Open Cloud 的合作 与波士顿大学和东北大学的研究团队合作，开发了 D4N（目录驱动的数据中心交付网络）和 Careers（智能预取器），以加速 S3 上的高价值分析工作负载。 这些技术通过在数据处理之前预取数据，提高了缓存的效率，并减少了延迟。 未来计划 计划将这些研究成果产品化，集成到 Ceph 的主线版本中。 引入 Zipper 重构，允许 Ceph RGW 使用不同的后端存储，如 RADOS、S3 或其他弹性缓存。 探索新的前端接口，如 Apache Arrow 和 Aeroflight，以提高数据处理的效率和灵活性。 决定事项： 继续推进 Ceph 在 AI 和 ML 领域的优化工作，特别是通过与学术界的合作，加速新技术的研发和集成。 确保新功能的引入不会影响现有用户的兼容性和稳定性。 后续行动计划： 持续进行性能测试和优化，确保 Ceph 能够满足不断增长的 AI 和 ML 工作负载需求。 与社区合作，收集用户反馈，不断改进和扩展 Ceph 的功能。 定期更新文档和培训材料，帮助用户更好地理解和使用新功能。 会议结束： 会议在热烈的讨论和掌声中结束，参会人员对 Ceph 的未来发展充满期待。 备注：本会议纪要基于会议内容的概要总结，具体细节和数据可能需要进一步核实。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC: Optimizing RGW Object Storage Mixed Media through Storage Classes and Lua Scripting","slug":"Ceph_Days_NYC_-_Optimizing_RGW_Object_Storage_Mixed_Media_through_Storage_Classes_and_Lua_Scripting","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_-_Optimizing_RGW_Object_Storage_Mixed_Media_through_Storage_Classes_and_Lua_Scripting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_-_Optimizing_RGW_Object_Storage_Mixed_Media_through_Storage_Classes_and_Lua_Scripting/","excerpt":"","text":"会议纪要 会议参与者 Anthony Daughtry：曾任职于Solidine（Intel的NAND部门，后被SK hynix收购），目前就职于Index Exchange。 Kurt Bruns：未参会，负责编码部分。 会议主题 Ceph RGW部署的特性与挑战：讨论了Ceph RGW部署中对象大小多样性对成本和性能的影响。 存储介质的选择与优化：探讨了不同存储介质（如机械硬盘、SSD、QLC SSD）的优缺点及适用场景。 TCO（总拥有成本）分析：介绍了如何使用SNIA的TCO计算器来评估存储解决方案的实际成本。 多存储池与存储类别的配置：讨论了如何在Ceph中配置多存储池以适应不同的工作负载和存储需求。 Lua脚本在Ceph RGW中的应用：展示了如何使用Lua脚本来动态调整存储类别，优化存储管理。 关键讨论点 对象大小对存储设计的影响： 大对象需要高读取吞吐量，但不易缓存。 小对象操作每GB的 overhead 更大，适合低延迟的快速存储。 存储介质的选择： 机械硬盘（HDD）：成本效益高，但接口和寻道延迟是瓶颈。 SSD：性能优越，但密度和成本问题。 QLC SSD：成本较低，密度高，性能介于HDD和TLC SSD之间。 TCO分析： 使用SNIA的TCO计算器考虑驱动器成本、数据中心运营成本、维护成本等。 多存储池配置： 通过混合介质，为不同类型的数据提供不同的存储池。 S3协议的存储类别可用于对象存储，通过请求头指定。 Lua脚本的应用： 使用Lua脚本在对象上传时动态调整存储类别，无需用户手动配置。 通过Lua脚本优化存储分配，减少空间放大问题。 决定事项 采用Lua脚本来自动化存储类别的分配，提高Ceph RGW的灵活性和效率。 使用SNIA的TCO计算器来更准确地评估存储解决方案的成本。 后续行动计划 继续优化Lua脚本，确保其在不同工作负载下的稳定性和效率。 推广使用SNIA的TCO计算器，帮助用户做出更明智的存储投资决策。 探索更多存储介质的组合，以满足不同应用场景的需求。 联系方式 Anthony Daughtry：欢迎对使用Lua脚本优化Ceph RGW存储管理感兴趣的人士联系他。 结束语 会议在感谢和掌声中结束，强调了持续优化和创新在存储管理中的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: 100 Years of Sports on Ceph","slug":"Ceph_Days_NYC_2023_-_100_Years_of_Sports_on_Ceph","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_100_Years_of_Sports_on_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_100_Years_of_Sports_on_Ceph/","excerpt":"","text":"会议纪要 会议主题：基于Ceph的体育数据存储项目介绍 主讲人：Frankie Yank 会议概要： 本次会议主要介绍了基于Ceph的体育数据存储项目，该项目旨在处理和存储大量的体育视频数据，确保数据的安全性、可访问性和长期保存。 讨论的主要议题： 项目背景与动机： 项目起源于对大量体育视频数据的存储需求，这些数据目前存储在磁带上，且数据量不断增长。 数据具有不可替代性，对历史和文化具有重要意义，因此需要确保数据的长期保存和可用性。 除了保存数据，还需要能够对数据进行计算分析和商业化利用。 技术选型与基础设施需求： 选择Ceph作为存储解决方案，因其开源、社区支持强大、可扩展性强。 需要构建一个不仅适用于当前，还能适应未来数据增长和类型变化的存储基础设施。 基础设施需具备高可用性、快速访问、多站点可访问性，并避免供应商锁定。 项目实施细节： 项目分为多个阶段，第一阶段计划构建40PB的Active Archive。 基础设施包括两个位于美国东西海岸的站点，每个站点配备多个生产集群和沙箱环境。 沙箱环境用于测试和验证新功能、升级和配置变更，确保生产环境的稳定性和可靠性。 性能与经济性分析： 通过详细的规划和系统工程设计，确保了基础设施的高性能和低成本。 通过与公共云成本的比较，展示了项目在经济上的优势。 面临的挑战与解决方案： 项目实施过程中遇到的挑战包括硬件选择、网络设计、软件集成和自动化。 通过使用Ceph Ansible等工具和自定义逻辑，解决了数据一致性、性能调优和故障恢复等问题。 决定的事项： 确定了使用Ceph作为核心存储技术，并构建了相应的存储基础设施。 设立了沙箱环境用于测试和验证，确保生产环境的高可用性和可靠性。 后续行动计划： 继续扩展和优化存储基础设施，以适应未来数据的增长和变化。 持续进行性能调优和故障恢复测试，确保系统的长期稳定运行。 探索更多商业化利用数据的可能性，以实现数据的最大价值。 结论： 本次会议详细介绍了基于Ceph的体育数据存储项目的背景、实施细节和面临的挑战，展示了项目在技术选型、经济性和可靠性方面的优势，并明确了后续的行动计划。感谢合作伙伴的支持，并期待项目的进一步发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: Ceph Crossing the Chasm","slug":"Ceph_Days_NYC_2023_-_Ceph_Crossing_the_Chasm","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-16T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_Ceph_Crossing_the_Chasm/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_Ceph_Crossing_the_Chasm/","excerpt":"","text":"会议纪要 会议主题： Ceph存储技术的未来与IBM的战略整合 主讲人： Vincent Shu，IBM Fellow 兼存储部门CTO 会议时间： 日期未明确 会议地点： 未明确 参会人员： 未明确 会议内容总结： 个人介绍与背景： Vincent Shu在存储行业有30年的经验，对存储技术充满热情。 他是IBM的新成员，首次参加Ceph相关活动。 IBM与Ceph的整合： IBM于2023年1月1日正式欢迎Ceph团队加入IBM存储部门。 IBM将继续坚持开源优先的战略，并承诺保持Ceph的100%开源和上游开发。 IBM已成为Ceph基金会的 premium member。 IBM与Ceph的合作历史： IBM与Ceph的合作已持续三年，涉及多个项目，如librbd、native encryption等。 IBM认为Ceph是市场的重要创新工具，有助于推动存储行业的变革。 存储行业的历史与现状： 从早期的专用硬件到现在的软件定义存储，存储技术经历了多次变革。 当前数据中心存在多种存储技术，导致管理复杂，创新速度慢。 未来的存储愿景： 目标是实现一个可编程、统一、API驱动的软件定义存储平台，支持混合云环境。 强调存储的智能化，包括自我监控、自我调整和基于遥测技术的自主管理。 IBM在Ceph社区的贡献与未来计划： 聚焦于可消费性、自动化、云和数据管理、以及网络安全。 计划通过AI Ops等技术加速价值实现时间，简化管理，提高数据管理的灵活性和安全性。 具体技术与项目： 讨论了数据复制、自动化灾难恢复解决方案、加密支持等具体技术。 强调了这些技术如何帮助客户更快地恢复数据，减少网络攻击的影响。 开放性问题与后续行动： Vincent Shu鼓励社区成员提出问题和建议，共同推动Ceph和存储技术的发展。 他承诺将跟进社区的反馈，并继续推动IBM在Ceph社区的领导和贡献。 后续行动计划： - 继续加强IBM与Ceph社区的合作，确保技术路线图与市场需求一致。 - 推动更多自动化和智能化功能，提高存储管理的效率和安全性。 - 加强与客户的沟通，确保产品和服务满足他们的实际需求。 备注： - Vincent Shu强调了他作为Ceph新成员的角色，并承诺将积极参与社区活动。 - 他鼓励与会者不要担心IBM对Ceph的整合会改变其开源性质，IBM将继续支持Ceph的发展。 会议结束： - 会议在掌声中结束，Vincent Shu表示他将在全天内提供进一步的咨询和帮助。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: Ceph Telemetry - Observability in Action","slug":"Ceph_Days_NYC_2023_-_Ceph_Telemetry_-_Observability_in_Action","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_Ceph_Telemetry_-_Observability_in_Action/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_Ceph_Telemetry_-_Observability_in_Action/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph项目的Telemetry模块，包括其项目概述、动机、架构、成功案例以及如何部署自己的Telemetry服务。 讨论的主要议题 Telemetry模块的动机和目标： 了解Ceph集群的分布、版本、存储容量、驱动模型、崩溃情况和使用特性。 通过收集匿名和非识别数据，帮助开发者和用户更好地理解和改进Ceph。 Telemetry模块的架构和功能： Telemetry模块通过拦截器内置于Ceph，默认上报给上游Ceph。 用户可以通过CLI命令或仪表板向导选择加入，并预览Telemetry报告。 报告包括基本信息、崩溃信息、设备健康指标、识别信息和性能计数器等。 隐私保护措施： 数据匿名化处理，不包含敏感或识别信息。 通过分离报告端点增强隐私保护。 成功案例和实际应用： 通过Telemetry数据，开发团队能够及时发现并修复新出现的bug。 用户可以通过Telemetry数据验证自己的安装，并贡献驱动健康指标的开放数据集。 部署自己的Telemetry服务： 需要设置Telemetry服务器和配置Telemetry模块。 提供了详细的安装指南和配置选项。 决定的事项 Telemetry模块的隐私保护措施得到了强调和确认。 确定了Telemetry数据在开发和用户支持中的重要作用。 讨论了未来可能的改进方向，如离线Telemetry能力和更公开的驱动健康报告。 后续行动计划 继续优化Telemetry模块的数据收集和报告机制。 探索和实施离线Telemetry能力。 研究并公开更多关于驱动健康和性能的统计数据。 其他讨论点 讨论了如何区分和过滤硬件故障导致的崩溃。 探讨了设备健康指标的预测效率和改进方向。 讨论了性能通道的启用及其可能的性能开销。 讨论了集群报告的持续性和数据的有效性。 探讨了公开驱动模型可靠性和性能报告的可能性。 结论 Telemetry模块是Ceph项目中一个重要的组成部分，它不仅帮助开发者更好地理解用户的使用情况，还为用户提供了验证和改进自己安装的工具。未来将继续优化和扩展Telemetry的功能，以更好地服务于Ceph社区。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: Ceph at CERN: A Ten-Year Retrospective","slug":"Ceph_Days_NYC_2023_-_Ceph_at_CERN_-_A_Ten-Year_Retrospective","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_Ceph_at_CERN_-_A_Ten-Year_Retrospective/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_Ceph_at_CERN_-_A_Ten-Year_Retrospective/","excerpt":"","text":"会议纪要 会议主题： 10年回顾：在CERN运营Ceph的经验 主讲人： 来自加拿大维多利亚大学的工程师，自2008年起在CERN工作，曾管理Ceph项目，现为CERN的首席IT架构师，同时也是Ceph基金会的董事会成员和执行委员会成员。 会议内容概述： 个人背景介绍： 主讲人自2008年起在CERN工作，管理Ceph项目直至去年，现为CERN的首席IT架构师。 2021年起担任Ceph基金会执行委员会成员。 计划于2023年4月移居温哥华，加入Iwakim公司，帮助在北美建立Klysto。 CERN与Ceph的结合： 展示了CERN的大型强子对撞机（LHC）的照片，解释了CERN的主要研究活动。 讨论了Ceph在CERN的存储解决方案中的重要性，特别是在处理大量物理数据时的应用。 Ceph在CERN的10年回顾： 从2013年开始，Ceph在CERN的使用从300TB的试点项目发展到2016年的6PB集群。 2016年后，Ceph集群规模持续扩大，目前拥有约17个集群和100PB的存储容量。 强调了Ceph在CERN基础设施中的关键作用，特别是在OpenStack和CFS的生产环境中。 挑战与成功故事： 讨论了实施Ceph时面临的挑战，包括硬件兼容性、网络配置和性能优化。 分享了Ceph在CERN的成功案例，如通过改进的Erasure Coding和对象分条技术提高数据处理效率。 未来方向与教训： 强调了持续的监控和维护、测试和社区协作的重要性。 提出了对Ceph未来发展的建议，包括改进的性能优化和更智能的集群管理工具。 决定事项： - 继续支持Ceph的发展，特别是在性能和可扩展性方面的改进。 - 加强与Ceph社区的协作，共享最佳实践和技术更新。 后续行动计划： - 主讲人将在2023年4月加入Iwakim公司，继续在北美推广Ceph技术。 - CERN将继续与Ceph社区合作，参与会议和研讨会，以推动Ceph技术的进一步发展。 总结： 主讲人通过其在CERN的10年经验，分享了Ceph在大型科研环境中的应用和挑战，强调了Ceph作为分布式存储解决方案的强大功能和社区支持的重要性。通过持续的技术改进和社区协作，Ceph有望在未来继续在科研和工业领域发挥关键作用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: Data Security and Storage Hardening in Rook and Ceph","slug":"Ceph_Days_NYC_2023_-_Data_Security_and_Storage_Hardening_in_Rook_and_Ceph","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_Data_Security_and_Storage_Hardening_in_Rook_and_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_Data_Security_and_Storage_Hardening_in_Rook_and_Ceph/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了分布式存储系统Ceph的安全性问题，包括安全实践、威胁模型、加密实现以及产品安全管理等方面。会议由Federico Lucifredi和Sage McTaggart主讲，他们在Ceph和网络安全领域有深入的研究和实践经验。 主要议题 安全实践与威胁模型 强调了安全实践的重要性，特别是针对特定基础设施点的加固。 讨论了在没有攻击者模型的情况下，单纯选择安全实践的不可行性。 提出了绝对安全的不现实性，强调了定义威胁模型的重要性。 网络安全区划分 介绍了四种网络安全区的划分：公共安全区、自客户端区、存储访问区和集群区。 讨论了各区域的安全需求和如何通过加密等手段保护数据传输。 产品安全管理 介绍了IBM的产品安全管理流程，包括安全开发生命周期、定期渗透测试、依赖项清单管理等。 强调了即使在IBM，Ceph的安全修复也会被回溯到上游，确保所有版本的Ceph都保持同等安全。 加密实现 讨论了服务器端和传输中的数据加密，特别是使用LUKS和Ceph协议的安全性。 介绍了对象存储网关的额外加密能力，包括用户密钥管理和AWS SSE-KMS支持。 身份与访问管理 讨论了使用共享密钥和AES加密的安全性，以及如何通过良好的实践来管理密钥和用户权限。 审计与数据保留 讨论了审计日志的重要性，以及如何在数据删除后确保数据不可恢复。 介绍了RBD的垃圾箱功能和rgw的版本控制功能，以及如何通过加密来实现安全删除。 决定事项 继续加强Ceph的安全性，特别是在IBM的新环境下，确保所有安全实践和流程都符合IBM的标准。 持续关注和改进Ceph的加密实现，特别是在数据传输和存储方面。 后续行动计划 继续进行定期的渗透测试和安全审查，确保Ceph的安全性。 与IBM的安全团队合作，进一步完善和扩展Ceph的安全流程。 持续关注和改进Ceph的身份和访问管理，确保用户数据的安全。 备注 会议中提到的所有安全实践和建议都旨在提高Ceph的安全性，特别是在面对不同威胁模型时。 会议还提到了一些外部资源，如Kubernetes Secrets管理、存储安全硬化指南等，供进一步阅读和参考。 本次会议为Ceph的安全性提供了一个全面的视角，并为未来的安全改进工作指明了方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: NVMe-over-Fabrics support for Ceph","slug":"Ceph_Days_NYC_2023_-_NVMe-over-Fabrics_support_for_Ceph","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_NVMe-over-Fabrics_support_for_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_NVMe-over-Fabrics_support_for_Ceph/","excerpt":"","text":"会议纪要 会议主题：Ceph 对 NVMe over Fabrics 的支持 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[列出主要参会人员] 会议内容总结： 背景与动机： 项目始于大约三年前，最初是为了探索在 DPU 硬件上支持 Ceph 的可能性。 由于当时市面上的 DPU 硬件性能较低，决定引入 NVMe over Fabrics 以提高性能和集成度。 NVMe over Fabrics 已成为访问远程块存储的实际标准，广泛应用于各种系统中。 技术实现： 架构概述：Ceph 集群通过 NVMe over Fabrics Gateway 与客户端通信，Gateway 包含多个进程，支持 TCP、RDMA 和 Fiber Channel。 数据路径与控制路径：控制路径使用 Python 进程通过 gRPC 服务进行配置管理，数据路径采用 SPDK（Storage Performance Development Kit）进行高效数据传输。 多路径与故障容忍：引入 Gateway 组概念，通过 Ceph 的 watch-notify 机制和轮询机制保持配置同步，支持多路径优化和负载均衡。 性能测试： 目标是在不使用 Gateway 的情况下尽可能接近原生性能。 在实验室环境中，通过优化和增加并发客户端实例，性能已接近原生性能的 92%。 正在进行更大规模的测试，以验证在更大集群上的性能表现。 未来计划： 计划引入 Discovery Service 和集中式发现功能。 考虑增加身份验证和加密支持，采用插件架构以灵活支持不同的安全方法。 与 Intel 合作，探索 ADNN（Adaptive Data Network）技术，优化数据路径选择。 可用性与支持： 当前版本已可下载试用，但仍需更多测试和优化。 计划在 Reef 版本中发布初始版本，支持单 Gateway 和基本配置管理功能。 决定事项： 确认了 NVMe over Fabrics 在 Ceph 中的实现方案和性能优化方向。 确定了未来版本的功能增强和优化计划。 后续行动计划： 继续进行性能测试和优化，特别是在更大规模集群上的测试。 开发和集成 Discovery Service、身份验证和加密功能。 与社区合作，收集反馈并改进产品。 会议结束： 会议在讨论和解答相关问题后结束，感谢所有参与者的贡献和讨论。 备注：本会议纪要基于会议内容的总结，具体细节和数据可能需要参考原始会议记录或相关技术文档。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: SQL on Ceph","slug":"Ceph_Days_NYC_2023_-_SQL_on_Ceph","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_SQL_on_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_SQL_on_Ceph/","excerpt":"","text":"会议纪要 会议主题： SQL Lite on Ceph 的介绍与应用 主讲人： Patrick Donnelly，IBM 的 Ceph 研发人员 会议内容概述： Patrick Donnelly 介绍了如何在 Ceph 上使用 SQL Lite，特别是通过 libsef sqlite 库将 SQLite 数据库分布式存储在 Ceph 的 RADOS 上。他讨论了 Ceph 管理器（Ceph Manager）如何利用 SQLite 进行持久化存储，并详细说明了实现这一功能的架构和技术细节。 关键讨论点： 1. Ceph 管理器架构： Ceph Manager 通过模块化设计，允许运行 Python 脚本管理集群操作。这些模块包括 orchestration、升级、设备健康监控等，且不依赖于 CFS、RBD 等服务。 2. SQLite 与 Ceph 的结合： 通过 libsef sqlite，SQLite 数据库可以分布式存储在 Ceph 的 RADOS 上，无需修改应用程序代码。这通过 SQLite 的 VFS（Virtual File System）接口实现，允许数据库文件分布在多个 OSD 上。 3. 性能优化： 提供了多个性能优化建议，如增加页面大小、使用更大的缓存、避免删除数据库文件等，以减少对 RADOS 的 IO 操作。 决定事项： - Ceph Manager 已经开始使用 libsef sqlite 进行数据持久化，特别是在设备健康模块中。 - 计划进一步优化 libsef sqlite 库，支持多读者和读取预取性能。 后续行动计划： - 继续优化 libsef sqlite 库，解决存在的 bug 和性能问题。 - 探索在更多 Ceph Manager 模块中使用 SQLite 进行数据持久化。 - 考虑未来可能将其他数据库系统（如 PostgreSQL）集成到 Ceph 中。 其他信息： - 提供了详细的性能优化建议和使用指南。 - 讨论了未来可能的工作方向，包括支持多读者和读取预取性能。 会议结束： Patrick Donnelly 回答了现场提出的问题，并提供了他的联系信息和相关文档链接，以便参与者进一步了解和使用 libsef sqlite。 备注： - 会议中提到的 libsef sqlite 和其他相关技术细节可在提供的文档和博客文章中找到。 - 会议纪要和相关资料将在会议结束后提供给参与者。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: Welcome and Community Update","slug":"Ceph_Days_NYC_2023_-_Welcome_and_Community_Update","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-16T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_Welcome_and_Community_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_Welcome_and_Community_Update/","excerpt":"","text":"会议纪要 会议概述 会议名称：SEF Days New York 地点：Bloomberg办公室，纽约 主持人：Matthew Leonard 会议欢迎与感谢 主持人介绍：Matthew Leonard欢迎与会者，并表达了对能够亲自和虚拟方式参与的荣幸。 感谢团队：感谢Bloomberg的事件、设施、AV、餐饮团队以及SEF董事会成员和其他志愿者，他们的努力使得此次活动得以成功举办。 会议背景与目的 Bloomberg与Ceph的关系：Matthew Leonard解释了为什么一个金融媒体公司的办公室会举办关于Ceph的会议。他提到Bloomberg的存储工程团队管理着公司的存储基础设施，并且他们的下一代云平台和S3平台都利用了Ceph。 Ceph在Bloomberg的应用：Bloomberg的计算和存储平台服务于不同的用例，但都依赖于Ceph。他们已经参与Ceph社区多年，主要通过报告问题和验证代码修复来贡献。 项目与贡献 Bloomberg的Ceph项目：Bloomberg正在开发一些与Ceph生态系统相关的项目，例如实时分布式第7层服务质量（QoS）堆栈和Ceph的大规模遥测收集。 社区参与：尽管Bloomberg尚未直接贡献主要功能，但他们希望在未来更积极地参与社区，确保Ceph作为现代云计算的一个充满活力和可行的组件。 社区与未来展望 社区的重要性：Matthew强调了社区在Ceph项目中的重要性，并希望在未来能够更多地参与和贡献。 未来活动：提到了即将在阿姆斯特丹、印度、温哥华和首尔等地举办的Ceph相关活动，鼓励社区成员参与和提交演讲。 会议结束 再次感谢：Matthew Leonard再次感谢所有参与者和支持者，并期待在未来能够再次见到大家。 后续行动计划 社区参与：鼓励社区成员积极参与即将到来的Ceph活动，并考虑提交演讲。 持续贡献：Bloomberg计划在未来更积极地参与Ceph社区，特别是在代码贡献和功能开发方面。 结论 此次SEF Days New York会议不仅展示了Bloomberg在Ceph领域的应用和贡献，也强调了社区合作的重要性，并为未来的合作和活动奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Days NYC 2023: Why We Built A “Message-Driven Telemetry System At Scale” Ceph Cluster","slug":"Ceph_Days_NYC_2023_-_Why_We_Built_A_Message-Driven_Telemetry_System_At_Scale_Ceph_Cluster","date":"2023-05-16T16:00:00.000Z","updated":"2023-05-17T16:00:00.000Z","comments":true,"path":"2023/05/17/Ceph_Days_NYC_2023_-_Why_We_Built_A_Message-Driven_Telemetry_System_At_Scale_Ceph_Cluster/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/17/Ceph_Days_NYC_2023_-_Why_We_Built_A_Message-Driven_Telemetry_System_At_Scale_Ceph_Cluster/","excerpt":"","text":"会议纪要 会议概述 会议由Nathan Howard主持，他是Bloomberg的高级软件工程师，隶属于分布式存储团队。Nathan在Bloomberg工作已有七年，主要负责软件定义存储，特别是对象级存储，即S3 API，内部称为Bloomberg Cloud Storage (BCS)，该存储系统基于Ceph构建。 会议议程 公司介绍：Bloomberg是一家成立于1981年的金融科技公司，以其旗舰产品Bloomberg终端闻名，为全球超过35万订阅者提供数据服务、新闻分析等。 存储工程团队介绍：负责设计和维护所有存储系统，包括文件、块和对象存储，以及数据保护和存储工作流程自动化。 集群信息：介绍了LCF集群的详细信息，包括数据中心分布、租户数量、存储容量和OSD数量。 Ceph默认Telemetry系统的问题：讨论了Ceph默认集成的Prometheus系统的局限性，特别是在大规模集群中的性能问题和缺乏用户级指标。 解决方案要求：提出了实时性、可扩展性、集成Grafana和易于扩展等要求。 解决方案概述：介绍了基于发布-订阅模型的解决方案，使用RabbitMQ作为消息代理，Celery作为任务调度器，Python编写，易于扩展和维护。 技术栈细节：详细介绍了RabbitMQ和Celery的使用，以及如何通过这些技术实现高可扩展性和容错性。 代码示例：展示了如何使用Celery进行任务调度和消息传递。 结果和未来计划：讨论了解决方案的实际效果，包括快速响应、良好资源利用和易于扩展，并提出了未来可能的改进方向，如扩展到RBD和收集元数据指标。 决定事项 确定了解决Ceph Telemetry系统问题的技术方案，使用RabbitMQ和Celery构建分布式任务调度系统。 确认了集成Grafana进行数据可视化和监控。 后续行动计划 继续优化和扩展当前的Telemetry系统，以支持更多的存储类型和更细粒度的指标。 考虑将解决方案贡献给开源社区，以帮助其他Ceph用户。 招聘更多人才，以支持公司内部Ceph和其他技术的开发和维护。 会议结束 Nathan Howard在会议结束时表示，Bloomberg正在招聘，并欢迎对Ceph或其他技术感兴趣的人士与他联系。会议在掌声中结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Secure Token Service in Ceph - Pritha Srivastava, IBM","slug":"Secure_Token_Service_in_Ceph_-_Pritha_Srivastava_IBM","date":"2023-05-14T16:00:00.000Z","updated":"2023-05-15T16:00:00.000Z","comments":true,"path":"2023/05/15/Secure_Token_Service_in_Ceph_-_Pritha_Srivastava_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/15/Secure_Token_Service_in_Ceph_-_Pritha_Srivastava_IBM/","excerpt":"","text":"会议纪要 会议主题： STS在Surf RGW中的应用 主讲人： Pritha 职位： IBM的Safe RGW团队开发人员 会议内容概述： Pritha介绍了STS（Security Token Service）在Surf RGW中的应用，涵盖了STS的基本概念、构建块、支持的API、自定义凭证提供者、ABAC授权策略以及在多站点环境中的实现。 关键细节： 1. STS简介： STS是一组API，返回具有临时性和有限权限的凭证，基于AWS STS。SDS（Security Domain Service）用于跨账户访问和集成外部应用，这些应用拥有大量用户且不希望拥有永久S3凭证。 2. 当前支持： RGW支持STS API的子集，包括AssumeRole、AssumeRoleWithWebIdentity和GetSessionToken。还实现了AWS IAM API的子集，用于对角色、策略和OpenID Connect提供者的CRUD操作。 3. 临时凭证： 临时凭证包括访问密钥ID、秘密访问密钥和会话令牌。会话令牌加密，包含认证和授权信息。 4. 角色与策略： 角色是一个实体，类似于用户但没有永久S3凭证。角色关联两个IAM策略：信任策略（决定谁可以假设角色）和权限策略（决定角色可以做什么）。 5. 支持的API： - AssumeRole： 提供跨账户或跨租户访问。 - AssumeRoleWithWebIdentity： 提供Web身份联合，用户通过OpenID Connect兼容提供者认证后，可以访问S3资源。 6. ABAC授权策略： 基于属性的访问控制（ABAC）使用标签（键值对）来定义权限，简化权限集的定义。 7. STS Lite： 基于GetSessionToken API，主要用于外部认证如Keystone和LDAP，减少对Keystone服务器的延迟和负载。 8. 自定义凭证提供者： 一个Java模块，改进AWS SDK中的Web身份令牌凭证提供者，支持会话持续时间和会话策略，并提供刷新令牌功能。 9. 多站点实现： 角色和策略元数据复制已实现，OpenID Connect提供者元数据复制仍在进行中。 决定事项： - STS在RGW中的实现和功能已基本明确，多站点元数据复制功能已部分实现。 后续行动计划： - 继续完善OpenID Connect提供者元数据复制功能。 - 探索和优化从桶策略到使用角色的性能改进。 参考资料： - STS及其相关主题的文档和GitHub仓库链接。 会议结束： Pritha感谢大家的参与，并邀请提问。会议中讨论了多站点配置、性能改进和与其他IDP的兼容性问题。 [Applause]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-05-10","slug":"Ceph_RGW_Refactoring_Meeting_2023-05-10","date":"2023-05-09T16:00:00.000Z","updated":"2023-05-10T16:00:00.000Z","comments":true,"path":"2023/05/10/Ceph_RGW_Refactoring_Meeting_2023-05-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/10/Ceph_RGW_Refactoring_Meeting_2023-05-10/","excerpt":"","text":"会议纪要 会议主题：Kafka库实现及代码走查讨论 与会人员：Yuval, Daniel, Thomas 等 会议时间：具体日期未提供 主要议题： Kafka库实现问题讨论 问题背景：用户报告在使用Kafka库时遇到回归问题，特别是在设置ACK级别时。用户发现，尽管设置了ACK级别为“none”，但在某些条件下仍会进行重试。 问题分析：Yuval深入分析后发现，问题源于Kafka库内部的重试机制与我们的代码库中实现的重试机制冲突。我们的重试机制需要能够应对崩溃和重启等情况，而Kafka库的重试机制则是内存中的，无法持久化。 解决方案讨论： Yuval建议尝试禁用Kafka库内部的重试机制，以避免设计上的混乱。 讨论了是否应该禁用Kafka库的重试机制，特别是在ACK级别为“none”时。 提出了是否应该允许用户通过配置文件来控制Kafka库的某些行为，以增加灵活性。 最终决定，对于ACK级别为“broker”的情况，可以允许Kafka库进行内部重试，因为这更节省时间；而对于ACK级别为“none”的情况，则应禁用Kafka库的重试机制，以保持一致性和简化文档。 代码走查提议 提议人：Daniel 提议内容：提议进行代码走查，以传播关于rgw代码库的知识。特别提到了对tracing和Lua代码的走查。 反馈：Yuval表示对tracing的代码走查感兴趣，但希望在OSD编码问题解决后再进行。Thomas表示愿意进行Lua代码的走查。 决定事项： 对于Kafka库的重试机制，决定在ACK级别为“broker”时允许内部重试，而在ACK级别为“none”时禁用内部重试。 允许用户通过配置文件来控制Kafka库的某些行为，以增加灵活性。 计划进行代码走查，特别是关于tracing和Lua代码的走查。 后续行动计划： Yuval将根据讨论结果，对Kafka库的重试机制进行调整，并提交相关PR。 Daniel和Thomas将准备进行代码走查，具体时间待定。 需要关注OSD编码问题的解决进展，以便进行tracing的代码走查。 会议结束：感谢所有参与者的贡献，会议圆满结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Making CephFS (Much More) Great! - Patrick Donnelly & Greg Farnum, IBM","slug":"Making_CephFS_Much_More_Great_-_Patrick_Donnelly_Greg_Farnum_IBM","date":"2023-05-08T16:00:00.000Z","updated":"2023-05-08T16:00:00.000Z","comments":true,"path":"2023/05/09/Making_CephFS_Much_More_Great_-_Patrick_Donnelly_Greg_Farnum_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/09/Making_CephFS_Much_More_Great_-_Patrick_Donnelly_Greg_Farnum_IBM/","excerpt":"","text":"会议纪要 会议基本信息 主持人: Patrick（前CFS团队负责人，现参与Sepafest项目） 参与者: Greg（SEF Fest团队经理，前STL长期贡献者）及其他与会者 会议议题 CFS多集群恢复能力 讨论了多集群故障恢复的难度和当前的不完善状态。 提出了改进建议，包括查看相关故障报告、社区讨论以及配置或升级解决方案。 MDS故障恢复 讨论了MDS在某些情况下会放弃的问题，通常在故障转移情况下可以恢复。 强调了Red Hat Ceph团队现在有更多客户，这些问题的出现频率增加，成为业务优先事项。 SMB与CephFS的集成 讨论了使用Samba VFS与CephFS集成的问题，包括Samba的工作方式和潜在的问题。 提出了改进建议，但目前没有具体的开发重点。 升级问题 讨论了从Nautilus升级到Quincy时的多活动MDS问题，特别是升级过程中的挑战。 提出了新的升级选项，如关闭整个CephFS文件系统进行升级，以避免不同版本的MDS相互通信的问题。 性能和稳定性改进 讨论了MDS缓存大小、客户端性能问题以及如何通过配置调整来改善。 提出了关于CephFS top工具的改进，以及如何更好地监控和收集客户端性能数据。 决定事项 需要进一步研究和改进CephFS的多集群恢复能力和MDS故障恢复机制。 需要关注和解决SMB与CephFS集成中的问题。 需要改进升级过程，特别是多活动MDS的升级策略。 需要增强CephFS的监控和性能数据收集能力。 后续行动计划 继续研究和开发多集群恢复和MDS故障恢复的解决方案。 关注和解决SMB与CephFS集成中的具体问题。 改进和优化CephFS的升级流程。 增强CephFS的监控和性能数据收集功能，特别是在客户端性能方面。 其他讨论点 讨论了CephFS的快照和克隆功能的限制和改进建议。 讨论了CephFS的扩展属性和统计功能的实际应用和潜在改进。 会议总结 会议主要围绕CephFS的多个关键问题进行了深入讨论，包括故障恢复、集成问题、升级挑战和性能监控。会议强调了持续改进和用户反馈的重要性，并提出了具体的改进方向和行动计划。感谢所有参与者的积极讨论和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RBD Integration with DPUs - Varada Raja Kumar Kari, AMD India Pvt Limited","slug":"Ceph_RBD_Integration_with_DPUs_-_Varada_Raja_Kumar_Kari_AMD_India_Pvt_Limited","date":"2023-05-06T16:00:00.000Z","updated":"2023-05-07T16:00:00.000Z","comments":true,"path":"2023/05/07/Ceph_RBD_Integration_with_DPUs_-_Varada_Raja_Kumar_Kari_AMD_India_Pvt_Limited/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/07/Ceph_RBD_Integration_with_DPUs_-_Varada_Raja_Kumar_Kari_AMD_India_Pvt_Limited/","excerpt":"","text":"会议纪要 会议主题： 介绍DPU（数据处理单元）及其在Ceph存储系统中的应用 会议内容总结： DPU简介： DPU是一种新兴的数据中心技术，旨在卸载服务器的基础设施任务，使CPU能够专注于应用程序处理。 DPU通过外部智能网卡实现，具备额外的处理能力，如压缩、加密等，以减少CPU的负担。 DPU主要用于网络和安全策略管理，同时也在探索存储能力的增强。 DPU在数据中心的使用： 数据中心正逐步从传统的CPU处理转向软件定义网络（SDN）、软件定义安全（SDS）和软件定义存储（SDS）。 DPU提供灵活性，允许数据中心管理员编程定义其应用环境，从而提高效率和安全性。 DPU与NVMe集成： 通过NVMe over Fabrics（特别是NVMe over TCP），DPU可以提供低延迟和高吞吐量的存储服务。 这种集成方式支持多种网络协议，如以太网、无限带宽和光纤通道，提供高度的可扩展性和灵活性。 当前部署和挑战： 当前部署基于SPDK前端和RBD插件，连接到NVMe over TCP初始化器。 面临的挑战包括单点故障、性能瓶颈和资源管理问题。 未来方向和优化： 计划在DPU上运行最小版本的Ceph和RBD服务，直接处理NVMe请求并转换为RBD请求。 这种架构可以减少对SPDK的依赖，提高性能和可靠性，同时提供更好的资源管理和安全性。 决定事项： 继续探索DPU在Ceph存储系统中的应用，特别是在卸载存储管理任务和提高性能方面。 研究如何在DPU上优化和运行Ceph组件，如CRUSH算法和librbd。 后续行动计划： 进行更多实验，验证DPU与Ceph集成的可行性和性能。 与硬件供应商合作，优化DPU的硬件和软件，以更好地支持Ceph和其他存储应用。 开发和测试新的DPU软件堆栈，包括优化版的Ceph组件，以适应DPU的特殊需求。 会议结束： 会议在讨论了DPU的潜力和挑战后结束，与会者对未来的研究和开发方向表示乐观。感谢所有参与者的积极参与和贡献。 [会议结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"A 10-Year Retrospective Operating Ceph for Particle Physics - Dan van der Ster, Clyso GmbH","slug":"A_10-Year_Retrospective_Operating_Ceph_for_Particle_Physics_-_Dan_van_der_Ster_Clyso_GmbH","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/A_10-Year_Retrospective_Operating_Ceph_for_Particle_Physics_-_Dan_van_der_Ster_Clyso_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/A_10-Year_Retrospective_Operating_Ceph_for_Particle_Physics_-_Dan_van_der_Ster_Clyso_GmbH/","excerpt":"","text":"会议纪要 会议主题： 10年回顾：CERN的Ceph操作经验 主讲人： Dan 会议地点： 纽约 会议内容总结： 个人背景介绍： Dan，加拿大人，拥有荷兰名字，曾在University of Victoria进行Grid computing研究生学习。 自2008年起在CERN担任工程人员，2013年至2022年担任Ceph经理，过去一年担任IT首席架构师，自2023年4月起在Claiso工作。 自2015年起参与Ceph董事会和基金会，近年加入Ceph执行委员会。 CERN简介： CERN拥有世界最大的粒子加速器，位于日内瓦，27公里环形，100米地下。 加速器使用超导磁体在接近绝对零度的温度下加速质子至接近光速，产生高能碰撞，用于物理研究。 Ceph在CERN的应用： CERN自2013年开始使用Ceph，最初是一个300TB的概念验证，随后迅速扩展到3PB生产环境。 2014-2015年进行Erasure coding研究和数据条带化。 2016年首次测试Ceph的硬件透明替换能力，2017年有8个集群在生产中。 2018-2019年开始测试CephFS和S3，近年来扩展到多个数据中心，支持业务连续性和灾难恢复用例。 目前有17个集群，约100PB的原始磁盘容量。 Ceph在CERN的重要性： Ceph支持CERN的实验室基础设施，包括配置管理、操作系统、数据库、监控、分析平台等。 物理存储主要使用EOS，存储了500PB的数据。 Ceph架构和挑战： CERN选择Ceph是因为其有机增长能力和性价比，避免了硬件供应商锁定。 实施挑战包括硬件选择、数据副本策略、SSD使用、网络架构等。 Ceph集群的基本主机架构保持不变，使用服务器四合一机箱，配备SSD和双路Xeon或AMD处理器。 性能和可扩展性： Ceph的性能被总结为“它就是那样”，强调了Ceph在处理复杂问题时的透明性。 性能改进包括使用SSD缓存层、BlueStore的延迟优化等。 可扩展性测试揭示了早期版本在处理大量OSD时的限制，但通过改进管理守护进程和BlueStore，情况得到改善。 操作经验和教训： 操作Ceph集群需要谨慎应用更改，避免触发可能导致长时间恢复的条件。 Ceph需要更好的工具来预览和验证配置更改，类似于Nomad和Terraform的变更预览功能。 数据放置的均匀性是一个挑战，但UpMap平衡器和PG重映射工具提供了帮助。 成功案例和社区贡献： Ceph成功集成到OpenStack、Kubernetes等平台，保护数据可靠性。 Ceph社区的积极参与和知识共享是其成功的关键。 后续行动计划： - 继续参与Ceph社区活动，计划今年举办六次确认的面对面活动。 - 探索和实施Ceph的新功能和改进，如Crimson后端的L2缓存。 结论： - Ceph在CERN的十年操作经验证明了其作为分布式存储解决方案的可靠性和灵活性。通过持续的改进和社区支持，Ceph将继续在CERN及其他机构中发挥重要作用。 会议结束： - 主讲人感谢CERN同事和Ceph社区成员的支持，并鼓励提问和进一步讨论。 [Applause]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"A Welcoming Ceph Experience Improvements for First-Time Users or: How to Make Beginners Love Ceph","slug":"A_Welcoming_Ceph_Experience_Improvements_for_First-Time_Users_or_-_How_to_Make_Beginners_Love_Ceph","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/A_Welcoming_Ceph_Experience_Improvements_for_First-Time_Users_or_-_How_to_Make_Beginners_Love_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/A_Welcoming_Ceph_Experience_Improvements_for_First-Time_Users_or_-_How_to_Make_Beginners_Love_Ceph/","excerpt":"","text":"会议纪要：Ceph新手用户体验改进 会议概述 本次会议由Jonas主讲，主题为“如何让新手爱上Ceph”。Jonas在德国的Thomas Kanagi公司工作，专注于Ceph的部署和优化。他分享了过去两年中，公司如何帮助新手用户轻松上手Ceph，并讨论了相关经验和改进措施。 关键细节 集群规模：Jonas的公司在过去两年中部署了约75个Ceph集群，每个集群包含3到5个节点，总计225个节点，5400个核心，58TB RAM，1.8PB NVMe存储，以及900个OSDs。 初始配置：新手用户通常从3个节点开始，使用直接电缆连接而非交换机以节省成本，并结合Proxmox进行简易设置。 性能表现：使用4个OSDs每节点的配置，实现了7GB/s的性能。 用户挑战：新手用户常对Ceph的复杂性感到不知所措，不了解如Monitor、Manager、MDS等组件的功能，以及OSDs的管理和数据重平衡等操作。 经验教训：Jonas强调了文档的重要性，建议简化文档，使用图表和交互式地图帮助用户理解Ceph的组件和功能。 决定事项 简化入门：Jonas建议社区开发一个新手引导，使用图表和交互式工具，帮助用户理解Ceph的基本概念和操作。 文档优化：强调文档的简化，避免过度技术细节，重点介绍每个组件的基本功能和重要性。 用户支持：提供更多的用户支持和故障排除指南，特别是在PG状态、OSD管理、数据重平衡等方面。 后续行动计划 贡献文档：Jonas表示愿意为新手引导和文档贡献自己的经验和见解。 社区合作：鼓励社区成员参与新手引导的开发，确保内容的准确性和实用性。 用户反馈：收集用户在使用Ceph过程中遇到的问题和挑战，持续改进文档和用户支持。 讨论的主要议题 Ceph组件的理解：如何简化新手对Ceph组件如Monitor、Manager、MDS的理解。 OSD管理：如何正确管理OSDs，包括添加、移除和数据重平衡。 性能优化：如何在有限的资源下优化Ceph集群的性能。 用户支持：如何提供有效的用户支持，帮助新手解决实际问题。 结论 Jonas的分享强调了简化Ceph入门过程的重要性，通过优化文档和提供更多的用户支持，可以帮助新手更好地理解和使用Ceph。社区的积极参与和贡献将是实现这一目标的关键。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Best Practices of Production-Grade Rook/Ceph Cluster - Satoru Takeuchi, Cybozu","slug":"Best_Practices_of_Production-Grade_Rook_Ceph_Cluster_-_Satoru_Takeuchi_Cybozu","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Best_Practices_of_Production-Grade_Rook_Ceph_Cluster_-_Satoru_Takeuchi_Cybozu/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Best_Practices_of_Production-Grade_Rook_Ceph_Cluster_-_Satoru_Takeuchi_Cybozu/","excerpt":"","text":"会议纪要 会议概述 本次会议由Cyborgs公司的研发人员主持，主要介绍了公司在生产环境中使用Kubernetes和Ceph的最佳实践。会议详细讨论了Cyborgs的基础设施、存储系统以及面临的挑战，并展示了如何通过Kubernetes和Rook来管理和优化Ceph集群。 讨论的主要议题 公司介绍与基础设施概述 Cyborgs是一家位于日本的领先云服务提供商，专注于支持企业团队协作的网络服务。 公司目前的基础设施存在可扩展性问题，且维护工作繁重。 Kubernetes与Rook的介绍 Kubernetes是一个复杂的容器编排系统，用于管理和部署应用程序。 Rook是一个开源的云原生存储编排器，特别适用于Ceph存储系统。 Ceph存储系统的架构与管理 介绍了Ceph集群的架构，包括HDD和NVMe SSD的使用。 讨论了如何通过Rook在Kubernetes中管理Ceph集群，包括创建、升级和管理OSD等操作。 面临的挑战与解决方案 提到了数据丢失的潜在风险，以及如何通过更新Ceph版本和限制某些操作来缓解这些问题。 讨论了自动化需求，如自动替换损坏的OSD和实现远程异步复制。 社区贡献与未来工作 Cyborgs积极参与Rook和Ceph社区，提供反馈和代码贡献。 计划实现备份恢复功能和更多的自动化操作。 决定的事项 确认了通过Kubernetes和Rook来优化Ceph集群管理的策略。 决定继续参与Rook和Ceph社区，提供反馈和贡献。 后续行动计划 继续监控Rook和Ceph的更新，及时应用重要的修复和更新。 实现备份恢复功能和远程异步复制。 提高自动化水平，如自动检测和替换损坏的OSD。 会议结束 会议在掌声中结束，主持人感谢大家的参与并邀请大家提出问题。会议结束后，主持人回答了关于替换损坏OSD脚本和远程复制的相关问题。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Best UADK Acceleration Practice on Ceph Storage - Dai Zhiwei, Huawei","slug":"Best_UADK_Acceleration_Practice_on_Ceph_Storage_-_Dai_Zhiwei_Huawei","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Best_UADK_Acceleration_Practice_on_Ceph_Storage_-_Dai_Zhiwei_Huawei/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Best_UADK_Acceleration_Practice_on_Ceph_Storage_-_Dai_Zhiwei_Huawei/","excerpt":"","text":"会议纪要 会议主题： UADK加速实践在安全存储中的应用 主讲人： Julie（华为技术有限公司） 会议内容总结： 介绍与背景 Julie介绍了她在华为技术有限公司的工作背景，专注于安全数据处理已有五年。 本次演讲的主题是关于UADK（User Space Acceleration Development Kit）在安全存储中的加速实践。 数据处理结构概述 讨论了数据处理架构的概况，包括Ceph存储系统中的多种数据处理特性，如客户端加密、S3、HTTPS、RSW压缩、服务器端加密、MD5计算等。 强调了这些特性对系统性能的影响，特别是在Blue Store和RGW中的热点问题。 UADK解决方案 UADK是一个用户空间加速开发工具包，具有统一接口、高效、安全等优点。 UADK支持基于硬件的加密和压缩加速，无需CPU和HCC设备之间的内存复制。 UADK的安全性通过IOMMU限制设备和进程的访问权限来实现。 实践应用 安全处理卸载： 展示了如何使用UADK引擎进行安全处理卸载，包括AES和MD5的硬件加速。 数据压缩： 介绍了在数据压缩方面的实践，包括使用UADK进行Blue Store压缩和网络传输压缩。 展示了测试结果，表明使用UADK可以显著降低CPU使用率并提高性能。 其他优化工作 讨论了在安全处理方面的其他优化工作，如Lab RC优化和RGW对象加密与压缩的支持。 展示了这些优化带来的性能提升，如压缩速度的显著提高。 未来工作 提出了未来的工作方向，包括解决S380 DPS和Cifax安全模式中的热点问题。 计划将UADK支持集成到Ceph主分支中，包括UD corruption插件和UADK压缩加速器。 探讨了硬件加速的未来可能性，如减少内存访问频率的芯片模式加速。 后续行动计划： - 继续优化和扩展UADK在Ceph存储系统中的应用。 - 解决S380 DPS和Cifax安全模式中的性能瓶颈问题。 - 推动UADK支持的开放源代码工作，增强Ceph社区的参与和贡献。 结束语： - Julie感谢大家的参与，并期待未来在安全存储领域的进一步合作和创新。 会议时间： [具体时间] 会议地点： [具体地点] 参会人员： [参会人员名单] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"BlueStore V2 - an Evolutionary Step Forward - Adam Kupczyk, IBM & Mark Nelson, Clyso GmbH","slug":"BlueStore_V2_-_an_Evolutionary_Step_Forward_-_Adam_Kupczyk_IBM_Mark_Nelson_Clyso_GmbH","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/BlueStore_V2_-_an_Evolutionary_Step_Forward_-_Adam_Kupczyk_IBM_Mark_Nelson_Clyso_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/BlueStore_V2_-_an_Evolutionary_Step_Forward_-_Adam_Kupczyk_IBM_Mark_Nelson_Clyso_GmbH/","excerpt":"","text":"会议纪要：Blue Store 维护与进化 会议概述 本次会议由社区成员主持，主要讨论了Ceph存储系统中的Blue Store的维护、进化以及未来发展方向。会议强调了Blue Store在Ceph中的重要性，并探讨了如何进一步优化其性能和稳定性。 主要议题 Blue Store的历史与现状 Blue Store是Ceph中的一个关键组件，负责处理存储数据的底层操作。 过去曾有File Store，但在Pacific和Quincy版本中已被弃用，并在Reef版本中完全移除。 Blue Store目前仍需维护，但预计未来将被Sister取代。 问题与挑战 讨论了Blue Store中存在的一些技术问题，如引用计数错误、数据块损坏等。 强调了需要改进的验证过程，以确保升级和稳定性的兼容性。 维护与改进措施 提出了多种改进措施，包括优化引用计数机制、改进内存管理、增强迭代器性能等。 讨论了如何处理Blue Store的碎片化问题，以及如何通过新的分配策略来减少碎片化。 未来发展方向 探讨了Blue Store的未来发展，包括可能的新特性如懒惰压缩和自定义写前锁。 讨论了如何通过模拟器来测试不同的分配策略和压缩方法，以减少实际部署中的风险。 决定事项 将继续维护Blue Store，同时探索新的技术解决方案以提高其性能和稳定性。 将开发和使用模拟器来测试和验证新的分配策略和压缩方法。 后续行动计划 继续参与每周的Blue Store维护和进化会议，以保持社区成员之间的同步。 开发和测试新的技术解决方案，如改进的引用计数机制、内存管理优化和迭代器性能提升。 使用模拟器进行广泛的测试，以确保新策略和方法的有效性和稳定性。 结论 本次会议强调了Blue Store在Ceph存储系统中的核心作用，并讨论了如何通过持续的维护和创新来提升其性能和可靠性。社区成员将继续致力于Blue Store的改进工作，以确保Ceph存储系统的长期成功和用户满意度。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Bug of the Year: A Memory Leak Reboot Could Not Help with - Radoslaw Zarzynski, IBM","slug":"Bug_of_the_Year_-_A_Memory_Leak_Reboot_Could_Not_Help_with_-_Radoslaw_Zarzynski_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Bug_of_the_Year_-_A_Memory_Leak_Reboot_Could_Not_Help_with_-_Radoslaw_Zarzynski_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Bug_of_the_Year_-_A_Memory_Leak_Reboot_Could_Not_Help_with_-_Radoslaw_Zarzynski_IBM/","excerpt":"","text":"会议纪要 会议参与者 Radek 会议时间 2023年某月某日 会议主题 讨论并解决Ceph存储系统中的一个长期存在的内存泄漏（memory leak）问题 会议内容总结 问题背景与引入 Radek自2015年起从嵌入式设备领域转入Ceph存储系统的开发。 讨论了一个特殊的内存泄漏问题，该问题对重启等常规处理手段具有免疫力。 问题描述 该内存泄漏问题存在于OSD（Object Storage Daemon）启动时从磁盘加载的内存结构中。 问题自2017年起存在于代码中，并在Octopus版本中因自动缩放器（auto scalar）的默认设置更改而加剧。 技术细节 问题根源在于C++标准库（STDC++）中的std::list容器的size方法在某些版本中不是常数时间复杂度。 该问题导致PG锁（PG lock）中的dupes结构在处理重复操作时出现问题。 问题影响与症状 内存泄漏导致OSD在处理恢复和 peering 过程时消耗更多内存和CPU资源。 症状包括增加的延迟、内存使用量上升、TC malloc警告、以及OSD间歇性闪烁。 诊断方法 传统方法包括停止OSD并使用objectstore_tool工具导出PG锁，但这具有侵入性。 非侵入性方法包括使用admin socket命令观察mempools统计信息。 解决方案与修复 修复工作分为多个阶段，首先解决离线工具（CLT）对dupes结构的无知问题。 在线修复涉及在OSD启动时逐步清理膨胀的dupes条目，避免一次性大量删除导致的问题。 后续行动计划 继续监控和优化修复措施，确保集群稳定运行。 开发和部署更多的诊断工具，以便未来能更有效地发现和处理类似问题。 结论 该内存泄漏问题虽然复杂且难以诊断，但通过团队的共同努力，已经找到了有效的修复方法。未来将加强代码审查和测试，以防止类似问题再次发生。 行动项 继续监控修复后的集群性能。 开发和部署新的诊断工具。 加强代码审查和测试流程。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Building and Scaling Data Pipelines for Data Engineering With Ceph Object Storage - Kyle Bader, IBM","slug":"Building_and_Scaling_Data_Pipelines_for_Data_Engineering_With_Ceph_Object_Storage_-_Kyle_Bader_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Building_and_Scaling_Data_Pipelines_for_Data_Engineering_With_Ceph_Object_Storage_-_Kyle_Bader_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Building_and_Scaling_Data_Pipelines_for_Data_Engineering_With_Ceph_Object_Storage_-_Kyle_Bader_IBM/","excerpt":"","text":"会议纪要 会议主题：数据管道与Ceph对象存储的介绍 主讲人：Kyle Bader 职位：IBM首席产品架构师 主题：数据管道与Ceph对象存储的介绍 会议内容概述 数据处理的新常态： 数据分析和处理已经转向使用对象存储作为标准，不再罕见。 对象存储如Ceph的S3 API提供了丰富的数据管理功能，包括桶策略、生命周期管理、IAM等。 对象存储的多功能性： Ceph的RADOS Gateway（RGW）支持S3和Swift API，以及通过Ganesha实现的NFS服务。 对象存储不仅限于简单的文件系统，还支持复杂的数据工程任务。 数据湖的应用多样性： 数据湖中的应用多种多样，包括直接通过S3 API交互的应用、流技术如Kafka，以及各种数据分析和处理工具。 事件驱动架构： Ceph支持桶通知功能，可以将事件发送到Kafka、AMQ或REST API，实现事件驱动的数据处理。 结合无服务器框架如Knative，可以实现自动扩展和资源优化。 实际应用案例： 展示了基于医疗影像分析的实际应用，如肺炎风险分析，利用Ceph的事件通知功能和无服务器计算。 提供了GitHub代码示例，展示了如何设置和运行这些演示。 安全与访问控制： Ceph的STS和IAM实现支持基于属性的访问控制（ABAC），通过OpenID Connect提供者实现更精细的权限管理。 桶库存功能可以作为工作流DAG的清单，用于后处理数据。 未来展望： 强调了持续关注和利用Ceph的S3 API扩展功能，以实现更高级的数据管理任务。 讨论与问答 S3用户与主体令牌的映射： 解释了如何通过IAM API定义角色，并在桶策略中使用角色而不是具体的用户名。 支持通过身份提供者（如OpenID Connect）映射到IAM角色。 数据管道的适用性： 数据管道主要针对对象存储，但理论上可以通过某些功能（如I notify）扩展到其他存储类型。 批处理的挑战： 批处理需要考虑数据处理的分布式和并发问题，Ceph的事件驱动架构可以部分解决这些问题。 后续行动计划 提供详细的文档和示例代码，帮助用户理解和实施Ceph对象存储的高级功能。 探索将事件驱动架构扩展到其他存储类型的可能性。 结束语 Kyle Bader感谢大家的参与，并鼓励大家继续探索Ceph对象存储的潜力。 本次会议详细介绍了Ceph对象存储在数据管道中的应用，展示了其强大的数据管理和处理能力，以及如何在实际场景中实现高效的数据处理和分析。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph: Lessons Learned from Emergency Support - Joachim Kraftmayer, Clyso GmbH","slug":"Ceph_-_Lessons_Learned_from_Emergency_Support_-_Joachim_Kraftmayer_Clyso_GmbH","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_-_Lessons_Learned_from_Emergency_Support_-_Joachim_Kraftmayer_Clyso_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_-_Lessons_Learned_from_Emergency_Support_-_Joachim_Kraftmayer_Clyso_GmbH/","excerpt":"","text":"会议纪要 会议主题：紧急支持中的经验教训 主讲人：[主讲人姓名] 背景介绍： 公司创始人，公司名为Glyzone。 曾担任Red Hat存储的高级顾问。 自2012年开始涉足Ceph，2014年起在生产环境中运行Ceph。 会议内容总结： Ceph的使用案例和经验分享： 过去两三年中，Ceph在各种环境中的应用案例。 强调了Ceph在虚拟环境（如VMware、OpenStack、超大规模环境）中的多样性。 讨论了Ceph在不同硬件和部署工具（如DeepSea、SaltStack、Ansible）中的应用。 具体案例分析： 性能问题：一个只有三个OSD的集群出现性能问题，原因是使用了较旧的Ceph版本（Luminous）。 配置和管理问题：讨论了PG（Placement Groups）的重要性，以及如何在不中断服务的情况下动态调整集群配置。 硬件和网络问题：提到了消费者级SSD和桌面旋转磁盘的不适用性，以及网络接口（如1Gbps）的瓶颈问题。 功能和配置建议： MDS服务：建议根据负载合理配置MDS的数量，避免过度配置。 PG Auto Scaler：建议禁用自动缩放，手动预定义PG数量以确保性能。 缓存层：不建议使用RBD缓存层，因其不稳定且难以管理。 数据恢复和备份策略： 强调了备份策略的重要性，特别是在生产环境中。 讨论了数据恢复的复杂性和潜在风险，特别是在使用大容量磁盘时。 操作和管理建议： 建议定期进行硬件和性能测试，以确保集群的健康运行。 强调了在生产环境中进行彻底测试的重要性，避免盲目信任自动配置。 后续行动计划： 社区和培训：计划在德国组织Ceph日活动，以加强与社区的联系并分享生产经验。 硬件和配置优化：继续研究和优化Ceph在不同硬件和配置下的性能。 备份和恢复策略：为生产环境制定和实施更有效的备份和恢复策略。 会议反馈和讨论： 与会者就MDS数量、PG配置、硬件选择等问题进行了深入讨论。 主讲人强调了Ceph在大型集群中的应用和管理挑战，以及如何通过合理的配置和策略来应对这些挑战。 结束语： 主讲人感谢与会者的参与，并鼓励大家继续关注Ceph的发展和最佳实践。 以上是对会议内容的详细总结，涵盖了关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph CSI Driver: Bridging Containers and Ceph - Rakshith R & Yati Padia, IBM","slug":"Ceph_CSI_Driver_-_Bridging_Containers_and_Ceph_-_Rakshith_R_Yati_Padia_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_CSI_Driver_-_Bridging_Containers_and_Ceph_-_Rakshith_R_Yati_Padia_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_CSI_Driver_-_Bridging_Containers_and_Ceph_-_Rakshith_R_Yati_Padia_IBM/","excerpt":"","text":"会议纪要 会议主题 讨论关于Ceph CSI（Container Storage Interface）的集成和使用，以及其在容器编排中的应用。 与会人员 Rakshita：IBM工程师，有两年半的Ceph CSI、Rook和Ceph开发经验。 Yati：Ceph CSI团队成员，曾任职于Red Hat，现为IBM员工。 会议议程 简介 容器和容器编排 容器存储驱动（CSI）介绍 Ceph CSI及其主要功能 CSI附加功能 Ceph CSI的未来路线图 问答环节 主要讨论内容 容器和容器编排 容器：标准化的软件单元，包含所有依赖和所需资源，可在任何Linux机器上运行，具有便携性、轻量级和安全性。 容器编排：管理容器的部署、扩展、内存调度等，常见平台包括Kubernetes、Docker Swarm、Apache Mesos等。 容器存储接口（CSI） CSI：解决原生存储驱动的问题，提供gRPC协议，定义API供编排器管理存储资源，支持动态配置、挂载、卸载等操作。 Ceph CSI：专门为Ceph存储系统设计的CSI驱动，作为CSI编排器和Ceph集群之间的桥梁。 Ceph CSI驱动 RBD驱动：高性能块设备，支持快照、复制和强一致性。 CephFS驱动：POSIX兼容文件系统，支持多客户端同时访问。 NFS驱动：基于CephFS的NFS导出，支持外部客户端访问。 CSI附加功能 空间回收：执行RBD擦除和文件系统空间释放命令。 网络隔离：在节点丢失或灾难恢复场景中，阻止特定IP范围访问存储资源。 卷复制：支持卷的复制和状态切换，适用于区域灾难恢复。 未来路线图 密钥轮换：支持加密卷的密钥轮换。 浅层NFS卷：实现NFS卷的浅层克隆。 Kerberos认证：为NFS卷提供Kerberos认证。 卷组快照：同时对多个卷进行快照。 卷组复制：支持卷组的复制。 存储容量跟踪：让Kubernetes了解Ceph集群的存储容量。 决定事项 Ceph CSI将继续开发和优化，以支持更多的存储操作和提高性能。 CSI附加功能将进一步扩展，以满足更复杂的存储管理需求。 后续行动计划 继续开发和测试Ceph CSI的新功能。 与Kubernetes社区合作，确保CSI驱动的兼容性和稳定性。 定期更新文档和用户指南，以便用户更好地理解和使用Ceph CSI。 问答环节 RBD卷的挂载和卸载：在文件系统模式下，RBD驱动使用makefs创建文件系统并挂载到工作负载。 外部依赖：Ceph CSI直接与Kubernetes交互，不依赖OpenStack层或类似的中间层。 CSI附加功能的声明性：CSI附加功能通过CRD（Custom Resource Definitions）实现声明性管理。 参考资料 会议中提到的相关链接和文档将在后续提供。 结束语 感谢所有与会者的参与和讨论，期待Ceph CSI的进一步发展和应用。 [掌声]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crash Telemetry - Observability in Action - Yaarit Hatuka, IBM","slug":"Ceph_Crash_Telemetry_-_Observability_in_Action_-_Yaarit_Hatuka_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_Crash_Telemetry_-_Observability_in_Action_-_Yaarit_Hatuka_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_Crash_Telemetry_-_Observability_in_Action_-_Yaarit_Hatuka_IBM/","excerpt":"","text":"会议纪要 会议主题： Telemetry 项目概述与讨论 会议时间： [具体日期] 会议地点： [具体地点] 主讲人： Yarit（Telemetry 技术负责人） 参会人员： [列出主要参会人员] 会议内容总结： Telemetry 项目概述 动机： 了解社区中 Ceph 集群的分布、版本、存储容量、驱动模型以及用户体验等问题。 架构： Telemetry 模块允许集群匿名报告安装和配置数据，数据在后端聚合并通过公共仪表板（telemetry-public.sef.com）展示。 功能： 自 2019 年 Mimic 版本引入以来，已有约 2500 个集群参与，报告了近 1 Exabyte 的存储容量。 数据报告与隐私 默认设置： Telemetry 报告默认关闭，用户需通过 CLI 命令（如 ceph telemetry on）或 Ceph 仪表板向导明确选择加入。 隐私保护： 报告不包含敏感或识别信息，如用户名、主机名、对象名或内容。集群通过随机 UUID 标识，不报告 FSID，并剔除驱动序列 ID 和 IP 地址。 报告渠道与数据处理 渠道： 包括基本信息、崩溃、设备、身份和性能渠道。基本和设备渠道默认开启，身份和性能渠道需用户明确选择。 数据处理： 使用正则表达式处理和标准化崩溃报告，以便于识别和分类。 成功案例与用户反馈 崩溃报告： 自动将崩溃报告同步到 Redmine 问题跟踪系统，帮助开发者识别和修复问题。 用户参与： 用户可以通过 Telemetry 数据验证其安装，并贡献于开放数据集，帮助改进驱动健康指标和故障预测模型。 后续行动计划 增强用户可见性： 考虑在公共仪表板中为用户提供特定视图，显示其集群的崩溃状态和修复信息。 改进数据收集： 继续添加新的数据收集项，并考虑用户的具体需求和反馈。 提高项目可见性： 在 Redmine 跟踪器顶部添加 Telemetry 链接，提高项目在社区中的知名度。 会议结束： [具体时间] 后续行动： - 继续优化 Telemetry 数据收集和处理流程。 - 增强用户界面和报告功能，提高用户参与度。 - 在社区中推广 Telemetry 项目，收集更多用户反馈和建议。 备注： - 会议中提到的具体命令和链接需在实际操作中验证其准确性和可用性。 - 对于新功能的添加和改进，将持续关注用户反馈并进行迭代优化。 会议记录人： [记录人姓名] 审核： [审核人姓名] 日期： [记录日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Messenger Situation and Optimization - Chunsong Feng, Huawei","slug":"Ceph_Messenger_Situation_and_Optimization_-_Chunsong_Feng_Huawei","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_Messenger_Situation_and_Optimization_-_Chunsong_Feng_Huawei/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_Messenger_Situation_and_Optimization_-_Chunsong_Feng_Huawei/","excerpt":"","text":"会议纪要 会议主题：软件自消息传递情况与优化 会议议程： 当前RDMA消息模块的不足 在自消息模块中启用UCX（Unified Communication X）的措施 性能测试结果 讨论内容： 当前RDMA消息模块的问题 流量控制缺失：导致性能波动，特别是在大包读写测试中。 数据复制问题：在发送和接收路径中存在数据复制。 使用限制：客户端和服务器需要使用RDMA连接，但客户端通常没有RDMA设备，只能使用DSP。 日志设计：后续解释。 固定长度消息：使用固定长度发送和接收消息，影响效率。 UCX架构与关键设计 UCX堆栈：在自消息模块中引入UCX堆栈，使用UCX连接客户端和服务器。 中断与轮询模型：处理设备事件。 不同大小的消息处理：使用不同的协议处理小包和大包。 UCX API：选择实际消息API实现零拷贝接收。 自RDMA与UCX堆栈的运行模块 RDMA堆栈：使用RDMA轮询线程和匹配工作者，共享QPL连接。 UCX堆栈优化：优化锁和会话调用，使用连接映射，消除日志需求。 零拷贝接收 实现两个映射：分别处理小包和大包。 预分配内存：提高接收效率。 性能测试 基准测试：使用100 Gigabit技术，4KB包，Q深度为32，UCX堆栈表现出更好的性能和效率。 类性能测试：使用RBDs进行测试，实现了约20%的性能提升。 未来计划： 性能调优：尝试更多协议和发送接收协议。 提问与回答： 性能提升：与TCP相比，性能提升约10%。 延迟问题：尚未进行延迟测试，但UCX可能提供更低的延迟。 RDMA代码问题：RDMA代码集成问题，需要移除中间层以充分利用RDMA。 决定事项： 提出拉取请求：计划在三周内创建拉取请求，将UCX消息传递整合到主分支。 后续行动计划： 创建拉取请求：整合UCX消息传递。 延迟测试：进行延迟测试，特别是尾延迟，以展示UCX的优势。 会议结束： 感谢与结束语：感谢所有参与者的贡献和讨论，会议圆满结束。 [会议纪要结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Multi-Site at Scale: Bloomberg’s Disaster Recovery Journey","slug":"Ceph_Multi-Site_at_Scale_-_Bloomberg_s_Disaster_Recovery_Journey","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_Multi-Site_at_Scale_-_Bloomberg_s_Disaster_Recovery_Journey/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_Multi-Site_at_Scale_-_Bloomberg_s_Disaster_Recovery_Journey/","excerpt":"","text":"会议纪要 会议主题：Bloomberg的分布式存储Ceph灾难恢复之旅 会议时间：[具体时间] 会议地点：[具体地点] 参会人员： Jane Zhu，Bloomberg高级软件工程师 Teda，Bloomberg分布式存储团队成员 会议议程： 介绍：简要介绍Bloomberg及其分布式存储团队的工作。 Ceph集群概览：展示Bloomberg云存储（BCS）中的Ceph集群。 多站点旅程：深入探讨Bloomberg存储团队如何采用Ceph的多站点功能。 未来计划：讨论未来的发展方向。 问答环节：回答与会者的提问。 会议内容总结： 1. 介绍 Bloomberg是一家成立于1981年的金融科技公司，提供新闻、分析和软件服务给全球超过35万订阅者。 每天处理超过3000亿条金融市场数据，峰值达到每秒1000万条消息。 分布式存储团队负责设计和维护Bloomberg的存储产品，支持文件系统、块设备和对象存储。 BCS（Bloomberg云存储）是对象存储产品，目前由Ceph支持。 2. Ceph集群概览 BCS是一个以RGW为中心的对象存储，每天处理超过10亿次请求。 拥有四个集群，分布在四个数据中心，总存储容量约为65PB。 集群分为Legacy PCS产品和新的支持多站点功能的集群。 3. 多站点旅程 Legacy集群存在单点故障问题，缺乏跨数据中心的通信，依赖客户端进行数据复制。 为了解决灾难恢复问题，团队采用了Ceph的多站点功能，实现了跨数据中心的数据复制。 通过大量的测试，包括功能测试和性能压力测试，发现并解决了在重负载下的多站点复制问题。 与社区合作，通过调试和代码审查，最终修复了问题。 4. 未来计划 计划将集群升级到最新的Ceph版本，以利用新功能和修复。 关注监控和复制延迟问题，希望社区能提供更好的解决方案。 决定事项： 继续与Ceph社区合作，优化多站点功能。 考虑开源部分内部工具和CI/CD管道，以帮助其他组织加速测试和部署。 后续行动计划： 升级现有集群到最新Ceph版本。 开发或集成更好的监控工具，以实时跟踪复制状态。 继续参与社区活动，推动Ceph的发展和改进。 问答环节： 讨论了多站点配置的具体细节，包括使用一个领域和两个区域的模式。 确认了在测试环境中使用的硬件配置接近生产环境。 解释了在主动-主动模式下处理数据差异的策略，当前通过代理路由所有请求到一个数据中心。 会议结束语： Jane Zhu和Teda感谢社区的支持，并邀请有兴趣的人才加入Bloomberg。 会议在掌声中结束，参会者期待未来与Bloomberg和Ceph社区的进一步合作。 注： 本会议纪要保留了部分计算机科学/Ceph相关领域英文原文的关键词，以确保专业性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Object Storage Overview, Capabilities and Future Plans - Matt Benjamin, IBM","slug":"Ceph_Object_Storage_Overview_Capabilities_and_Future_Plans_-_Matt_Benjamin_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_Object_Storage_Overview_Capabilities_and_Future_Plans_-_Matt_Benjamin_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_Object_Storage_Overview_Capabilities_and_Future_Plans_-_Matt_Benjamin_IBM/","excerpt":"","text":"会议纪要 会议概述 本次会议由Matt Benjamin主持，他目前担任IBM的Program Director，负责Seth对象存储项目。会议主要讨论了Seth对象存储的能力、路线图和未来计划。 主要议题 Seth对象存储的能力 RGW (RADOS Gateway) 是一个高保真的S3和Swift兼容的HTTP对象存储，构建在Ceph集群之上。 主要能力包括： 单集群容量可达数百PB。 支持数十万个S3桶或容器。 每个桶可存储至少5亿个对象，目标接近10亿。 动态桶索引缩放。 近期开发和改进 过去两年中，对多站点复制能力进行了大规模重构和重写，以提高规模和鲁棒性。 实现了S3 Select，支持结构化数据操作。 对内部API进行了重大重构，称为“Zipper”。 支持所有Amazon兼容的加密API。 将计算密集型操作从索引存储移至RADOS上的队列操作。 未来计划和路线图 计划在2023年及以后更新C++20协程。 增强多站点复制功能，包括并行同步和同步公平性。 开发S3 Inventory，一种预生成的桶列表。 开发D4N缓存层，与麻省开放云合作。 扩展S3 Select功能，支持Parquet和JSON。 实现端到端跟踪，使用Jaeger。 实现索引恢复功能，用于版本和非版本桶。 新前端协议 计划支持HTTP/3和Apache Arrow Flight。 开发动态脚本和安全脚本，允许用户注入脚本进行调试和复杂工作负载管理。 其他增强功能 增强S3过渡能力，支持远程S3的数据恢复。 增强归档区域功能，包括数据去重。 消除单主节点模型，采用共识协议。 决定事项 确认了Seth对象存储的未来发展方向和技术路线图。 确定了即将实施的关键功能和技术改进。 后续行动计划 继续推进C++20协程的更新。 完成多站点复制功能的增强。 开发和测试新前端协议，如HTTP/3和Apache Arrow Flight。 完善文档和社区支持，确保新功能的顺利实施和用户采用。 其他讨论 讨论了文档更新、过滤器编译、动态脚本插入等技术细节。 确认了未来几年的发展目标和预期成果。 结论 会议强调了Seth对象存储在未来的发展方向和技术创新，旨在提供更高效、更灵活的存储解决方案，满足不断变化的市场需求和技术挑战。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph QoS Refinements for Background Operations Using MClock","slug":"Ceph_QoS_Refinements_for_Background_Operations_Using_MClock","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_QoS_Refinements_for_Background_Operations_Using_MClock/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_QoS_Refinements_for_Background_Operations_Using_MClock/","excerpt":"","text":"会议纪要 会议主题：Ceph中M clock算法的QoS优化 参会人员：Ceph研发团队成员 会议时间：[具体时间] 会议地点：[具体地点] 会议内容概述： 本次会议主要讨论了Ceph中使用M clock算法进行后台操作的QoS（服务质量）优化。M clock是一种用于IO资源分配的算法，目前在Ceph中作为SEF的一部分使用。会议详细介绍了M clock的工作原理、与之前使用的WPQ（加权优先队列）的对比、以及M clock的优化和测试结果。 主要议题： M clock算法介绍： M clock是一种用于IO资源分配的算法，主要用于Ceph中的SEF模块。 M clock通过三个参数（reservation、limit、weight）来控制IO资源的分配。 与WPQ的对比： WPQ是之前Ceph OSDs使用的调度器，每个操作都有一个优先级和成本。 WPQ的缺点包括缺乏资源分配能力、无法区分不同类型的操作，以及需要大量配置选项来控制后台操作。 M clock的优化： 调整了M clock的成本模型，使其更加动态，能够反映操作的实际IO大小。 优化了M clock的内置配置文件，使其更加用户友好。 测试结果： 在内部实验室环境中进行了测试，结果显示M clock在恢复操作和客户端操作方面表现优于WPQ。 特别是在恢复操作方面，M clock的性能提升显著，且客户端操作的延迟更低。 决定事项： 继续优化M clock的成本模型和配置文件。 计划在更大规模的环境中进行测试，以验证M clock的性能。 后续行动计划： 在更大规模的环境中测试M clock的性能。 继续优化M clock的配置文件，使其更加用户友好。 准备将M clock的相关优化合并到Ceph的下一次版本更新中。 会议总结： 本次会议详细讨论了Ceph中M clock算法的QoS优化，通过与WPQ的对比，展示了M clock在性能和用户友好性方面的优势。团队将继续进行测试和优化，以确保M clock能够在实际生产环境中稳定高效地运行。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Security BoF - JC Lopez, IBM","slug":"Ceph_Security_BoF_-_JC_Lopez_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_Security_BoF_-_JC_Lopez_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_Security_BoF_-_JC_Lopez_IBM/","excerpt":"","text":"会议纪要 参会人员 JC Lopez：与Seth有长期合作历史，曾被IBM收购后离开，现回归IBM，继续从事Fusion和Seth相关工作。 会议主题 数据安全 存储强化 Rook项目 Ceph存储系统 主要讨论内容 Ceph的未来与现状： Seth（Ceph）被认为是存储的未来，支持块存储和对象存储。 Ceph在Kubernetes和OpenShift环境中显示出极高的灵活性、高可用性和可扩展性。 Rook项目： Rook是由CNCF孵化的项目，旨在通过操作符模型在Kubernetes环境中部署Ceph集群。 Rook已被用于OpenShift Data Foundation和IBM的Fusion Data Foundation。 Ceph与Rook的安全性： IBM在产品生命周期中进行安全活动，旨在减少风险并提高Ceph和Rook的安全性。 使用安全开发生命周期（SDL）进行代码审计和渗透测试。 IBM的PSIRT（产品安全事件响应团队）将文档化所有开源材料，确保使用的库和组件的安全性。 加密与密钥管理： 支持在OSD级别进行数据静态加密，可以使用自管理密钥或外部密钥管理系统。 支持传输层加密，包括在Messenger层和Rados Gateway的加密。 网络卫生与防火墙： 强调防火墙的重要性，最新版本的Ceph提供了防火墙服务文件。 控制平面SSH的安全性也需要加强。 Rook的具体安全措施： Rook通过CRD控制部署，支持数据静态加密和传输层加密。 CSI驱动支持KMS，允许在PV级别进行加密。 安全最佳实践： 强调suffix的重要性，不应在生产环境中禁用。 管理客户端密钥和S3用户访问密钥的安全性。 后续行动计划 继续审查现有安全措施，定期更新安全代码。 遵循IBM的安全标准，修复已知漏洞。 加强与IBM同事的合作，学习新的安全流程。 其他信息 会议中提到的Ceph和Rook的安全特性将通过后续文档和演示材料进行详细说明。 鼓励与会者如有安全相关问题，可随时联系JC Lopez或其他相关人员。 会议结束 会议结束时，JC Lopez感谢大家的参与，并表示会将所有相关材料和幻灯片分享给与会者。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph for Public Cloud Workloads - Philip Williams, Canonical","slug":"Ceph_for_Public_Cloud_Workloads_-_Philip_Williams_Canonical","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_for_Public_Cloud_Workloads_-_Philip_Williams_Canonical/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_for_Public_Cloud_Workloads_-_Philip_Williams_Canonical/","excerpt":"","text":"会议纪要 会议主题：公共云存储成本与私有云解决方案的经济性比较 会议时间：[具体时间] 会议地点：[具体地点] 主讲人：[主讲人姓名] 会议内容总结： 背景介绍： 主讲人分享了关于公共云存储成本与私有云解决方案经济性的比较。他提到，尽管公共云因其灵活性和动态需求而受到欢迎，但对于某些存储密集型工作负载，如数据湖、备份和活跃档案，公共云的成本可能会非常高。 公共云存储成本分析： 主讲人以2.5 PB数据在公共云存储5年的成本为例，估算出接近400万美元的费用。他指出，公共云的定价模型复杂，数据输入免费或成本极低，但数据读取、处理和分发的成本较高。 私有云解决方案介绍： 主讲人介绍了使用Ceph集群的私有云解决方案，该方案在数据中心或合作位置部署，提供更高的控制和更低的成本。他提到了使用的硬件配置，包括Dell R740 xd2服务器、NVMe设备和网络设备等。 成本比较： 通过比较，主讲人展示了私有云解决方案在硬件、网络、数据传输和管理服务等方面的成本，总计约85万美元，远低于公共云的成本。 优势与控制： 主讲人强调了私有云解决方案在成本控制、数据访问速度和业务数据安全方面的优势。他提到，私有云可以作为不同云服务提供商之间的桥梁，提供更好的灵活性和控制。 未来展望与问题： 主讲人讨论了未来可能的数据迁移成本，并回答了观众关于硬件交付时间的问题。他提到，尽管硬件交付可能需要几个月的时间，但提前规划可以避免经济变化带来的影响。 决定事项： 会议决定进一步探索和实施私有云解决方案，以降低存储成本并提高数据管理效率。 后续行动计划： 研究并制定详细的私有云部署计划。 与硬件供应商协商，确保硬件交付时间符合项目需求。 继续监控公共云和私有云的成本变化，以便及时调整策略。 会议结束： 主讲人感谢大家的参与，并鼓励大家就私有云解决方案提出更多问题和建议。 [会议结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph in Scientific Computing and Large Clusters BoF","slug":"Ceph_in_Scientific_Computing_and_Large_Clusters_BoF","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_in_Scientific_Computing_and_Large_Clusters_BoF/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_in_Scientific_Computing_and_Large_Clusters_BoF/","excerpt":"","text":"会议纪要 会议基本信息 主持人: Kevin Herb Chuck 会议类型: 科学研究计算大型集群的非正式讨论会（Birds of a Feather） 目的: 促进对科学研究和计算环境中有相似兴趣的人员之间的交流与讨论。 会议内容概述 参与者介绍: Kevin来自美国威斯康星大学的空间科学与工程中心，负责处理NASA多个任务的卫星数据。 会议形式: 非正式讨论，主要围绕Ceph在大型集群中的应用、升级、问题解决以及用户经验分享。 讨论主题: Ceph版本升级: 讨论了从Red Hat 7到更高版本的升级路径，特别是从Nautilus到Octopus的升级挑战。 集群管理: 涉及如何处理大规模集群的滚动重启和升级，以及如何优化故障域管理。 S3 API应用: 讨论了如何为科学用户提供安全的S3 API访问，包括自定义前端和后端解决方案。 数据管理: 分享了在大型集群中处理数据突增和异常增长的策略。 决定事项 S3 API安全管理: 采用自定义前端和后端工具来管理S3凭证，确保科学用户的安全访问。 集群升级策略: 探讨了通过虚拟机架和逐步升级策略来减少数据迁移的影响。 后续行动计划 持续交流: 定期举行线上Meetup，时间为每两个月的第四个星期三，下午4点（中欧时间）。 信息共享: 通过QR码链接的Seth pad记录和分享每次会议的讨论内容和发现。 其他备注 技术挑战: 讨论中提到了在大型集群中实施滚动重启和升级的技术挑战，以及如何通过改进Crush map和故障域管理来优化这些过程。 社区合作: 鼓励参与者通过共享经验和合作开发开源API来解决共同面临的问题。 结论 会议成功促进了科学研究计算领域中Ceph用户的交流与合作，为解决共同的技术挑战提供了平台和机会。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph on Windows - Alessandro Pilotti, Cloudbase Solutions","slug":"Ceph_on_Windows_-_Alessandro_Pilotti_Cloudbase_Solutions","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Ceph_on_Windows_-_Alessandro_Pilotti_Cloudbase_Solutions/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Ceph_on_Windows_-_Alessandro_Pilotti_Cloudbase_Solutions/","excerpt":"","text":"会议纪要 会议主题： Ceph与Windows集成解决方案介绍 主讲人： Alessandra Pilotti, CEO at Cloud-based Solutions 会议内容总结： 背景介绍： Ceph是最受欢迎的开源存储解决方案之一。 Windows Server在企业市场中占有很大份额。 传统的Ceph iSCSI Gateway在性能上存在问题。 合作伙伴关系： Cloud-based Solutions与Ceph合作，旨在改善Windows环境下的Ceph性能。 合作成果已开源，并集成到Ceph社区中。 技术目标： 提供与Linux环境下相似的用户体验和命令行接口。 确保Ceph在Windows上运行时，Windows管理员也能感到熟悉。 实现高性能，目标是超越传统的iSCSI Gateway，并接近Linux原生性能。 架构与实现： OSD运行在Linux上，Windows上运行一个用户空间进程（RBD Windows）。 开发了一个新的内核驱动（wimbd.sys）来处理磁盘操作。 支持的Windows版本包括Windows Server 2016, 2019, 2022，以及Windows 10和11用于开发。 性能优化： 通过实现Device I/O Control和改进I/O并发性来提升性能。 测试结果显示，性能显著优于iSCSI Gateway。 安全性与认证： 驱动程序已通过Cloud-based Solutions的认证，未来计划通过Microsoft认证。 Microsoft认证版本将支持安全启动功能。 未来工作： 增加对Windows集群的支持，包括集群共享卷和扩展文件服务器。 持续的维护和改进工作，包括错误修复和社区集成。 演示内容： 展示了如何在Windows Server上安装和配置Ceph。 演示了Ceph卷的创建、映射和管理。 展示了Ceph文件系统（CephFS）在Windows上的使用。 演示了Hyper-V与Ceph的集成，以及如何在集群环境中使用Ceph。 后续行动计划： - 继续与Ceph社区合作，推动技术发展和集成。 - 提供持续的技术支持和咨询服务。 - 完成Microsoft认证流程，发布认证驱动程序。 会议结束语： - Alessandra Pilotti感谢大家的参与，并表示愿意进一步讨论项目细节和提供支持。 备注： - 会议中提到的所有技术细节和演示步骤均为Ceph与Windows集成解决方案的关键组成部分。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Client Driven Geo-Redundancy for Ceph Object Storage - Yuval Lifshitz, IBM","slug":"Client_Driven_Geo-Redundancy_for_Ceph_Object_Storage_-_Yuval_Lifshitz_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Client_Driven_Geo-Redundancy_for_Ceph_Object_Storage_-_Yuval_Lifshitz_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Client_Driven_Geo-Redundancy_for_Ceph_Object_Storage_-_Yuval_Lifshitz_IBM/","excerpt":"","text":"会议纪要 会议主题：Redis Gateway在IBM中的应用及多站点复制改进 会议时间：[具体日期] 参会人员： Yuval（IBM，Redis Gateway项目负责人） Liave和Omar（学生，参与项目开发） 其他相关技术人员 会议内容： 项目背景： Yuval介绍了Redis Gateway项目，该项目是由Red Hat和Reichmann University在以色列的合作项目Connect的一部分。 感谢Liave和Omar两位学生在该项目中的贡献。 多站点复制的挑战： 多站点（multi-site）设置在集群中是一个复杂且常有问题的系统。 地理复制（Geo replication）和地理冗余（Geo redundancies）面临网络问题、性能问题、数据日志和集群间通信问题。 动态重分片（dynamic resharding）和其他问题增加了系统的复杂性。 用户控制的需求： 当前系统高度异步，用户难以了解数据何时安全同步。 项目旨在通过增加新的桶通知（bucket notifications）来增强用户对复制系统的控制。 解决方案介绍： 在Redis Gateway中增加新的桶通知类型，通知用户对象何时安全同步到一个区域（Zone）。 通过Kafka或其他通知机制，用户可以订阅这些通知并据此采取行动。 演示和实施细节： 演示了如何在两个站点（Zone A和Zone B）之间设置主题（topic）和通知。 展示了对象上传到主站点（Zone A）后，如何在备份站点（Zone B）同步并发送通知。 后续改进和行动计划： 需要改进多站点间的信息同步，特别是主题和通知的配置。 计划增加更多类型的通知事件，如删除事件和版本桶创建事件。 学生已经开始编写一个围绕Boto3 Python库的包装器，以简化端到端的功能。 鼓励社区成员参与完善和扩展这些功能。 问题与回答： 讨论了通知的具体内容和如何自定义通知数据。 确认了通知机制与AWS S3的兼容性和扩展性。 后续行动： 完善多站点间的信息同步机制。 增加更多类型的通知事件。 完成并发布Boto3 Python库的包装器。 社区成员参与测试和反馈，以进一步优化系统。 会议结束： Yuval感谢大家的参与，并鼓励大家提出问题和建议。 会议在掌声中结束。 备注：本会议纪要基于Yuval的介绍和讨论内容整理，旨在记录会议的关键细节和后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Chasing Bad Checksums: A Journey Through Ceph, TCMalloc, and the Linux Kernel - Dan Hill, Canonical","slug":"Chasing_Bad_Checksums_-_A_Journey_Through_Ceph_TCMalloc_and_the_Linux_Kernel_-_Dan_Hill_Canonical","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Chasing_Bad_Checksums_-_A_Journey_Through_Ceph_TCMalloc_and_the_Linux_Kernel_-_Dan_Hill_Canonical/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Chasing_Bad_Checksums_-_A_Journey_Through_Ceph_TCMalloc_and_the_Linux_Kernel_-_Dan_Hill_Canonical/","excerpt":"","text":"会议纪要 会议主题： Ceph性能问题及解决方案探讨 主讲人： Dan Hill, Canonical 公司持续工程部门 会议日期： [具体日期未提供] 会议地点： [具体地点未提供] 参会人员： Ceph社区成员、Canonical公司代表、技术支持团队等 会议内容总结 背景介绍： - Dan Hill介绍了Canonical公司的持续工程部门职责，包括作为技术支持团队的升级点，处理复杂问题，测试和验证解决方案，确保满足客户需求。 - 提到了Ubuntu Pro的自支持服务，感兴趣的可以通过ubuntu.com/self了解更多。 - 感谢Mauricio Oliviera的贡献，他虽未能参会，但对本次演讲的幻灯片和问题根源识别及补丁提交有重要贡献。 问题描述： - 客户报告了一个Ceph集群的性能问题，集群规模庞大，包含数十个节点，数百个OSDs，存储容量约10PB，运行在Ubuntu Bionic LTS上，使用Ceph的Octopus版本。 - 集群被用作大型环形缓冲区，持续进行数据摄取和探索，读取活动较少且随时间变化。 - 初始问题是多个OSDs随机崩溃，原因是校验和错误（checksum errors）。 问题分析与解决过程： - 初步怀疑是硬件问题，但系统日志、固件级别和SMART数据均未发现异常。 - 发现校验和错误在集群中广泛分布，且仅在内存压力高时发生。 - 通过详细分析校验和错误，发现校验和计算指向了一个零填充的缓冲区。 - 在Blue Store中存在一个已知的缓解措施，即遇到校验和错误时会重试，但在RocksDB中没有这种机制，导致RocksDB在遇到校验和错误时直接崩溃。 实验与验证： - 在实验室环境中模拟了类似的读写负载和高内存压力，成功复现了问题。 - 通过增加删除操作，复现了元数据密集型工作负载，将问题复现时间从几天缩短到几小时。 - 测试了不同内核版本和其他代码级别，发现问题在较新的内核上仍然存在，但在Ubuntu Focal上无法复现。 根本原因分析： - 发现问题与TC malloc库中的madvise free系统调用有关，该调用允许延迟释放内存，可能导致页面在未被标记为脏之前被释放，返回零填充页面。 - 确认问题为内核问题，涉及CPU调度、虚拟内存管理、内存回收和块I/O子系统。 解决方案： - 在RocksDB路径中添加重试机制，以避免崩溃。 - 在Gperftools中修改madvise free为madvise don't need，确保内存立即释放，避免校验和错误。 - 提交了内核补丁，增加了对页面引用计数的检查，确保在内存回收时不会错误地释放页面。 后续行动计划： - 继续跟踪内核补丁的上游合并进度，确保问题在稳定内核版本中得到修复。 - 提供Ubuntu内核的修复版本列表，供用户升级。 - 提醒开发者在项目中使用madvise free时需考虑其潜在影响，特别是在容器环境中。 其他信息： - 提到了madvise free在其他开源项目中的问题，建议开发者在使用时进行充分考虑。 - 会议结束时，Dan Hill回答了观众的问题，并感谢大家的参与。 结论 本次会议详细讨论了一个Ceph集群性能问题的分析与解决过程，涉及内存管理、内核调度等多个技术层面。通过实验验证和根本原因分析，最终确定了问题所在并提出了有效的解决方案。会议强调了持续工程部门在技术支持中的重要作用，并鼓励社区成员在遇到类似问题时参考本次讨论的经验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson Project Update - Samuel Just, IBM","slug":"Crimson_Project_Update_-_Samuel_Just_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Crimson_Project_Update_-_Samuel_Just_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Crimson_Project_Update_-_Samuel_Just_IBM/","excerpt":"","text":"会议纪要 会议主题：Crimson项目介绍及Reef更新 主讲人：Sam 会议内容总结： Crimson项目概述： Crimson项目旨在优化Ceph OSD（Object Storage Daemon）的性能，特别是在高IOPS环境下。 主要目标是减少CPU开销，通过减少跨核心通信、拷贝和上下文切换，以及利用新兴存储技术如NVMe、ZNS和SMR。 技术背景： 存储技术不断进步，IOPS从150（HDD）增长到10,000（SSD），甚至达到百万级别（NVMe）。 CPU性能未能同步提升，导致单个IO的CPU开销大幅增加。 多核心架构虽然提高了整体性能，但增加了延迟和核心间通信开销。 现有架构问题： 传统OSD架构在处理请求时涉及多个线程池和队列，导致大量的锁竞争和非确定性延迟。 特别是在处理请求提交回调和PG（Placement Group）状态时，存在显著的性能瓶颈。 Crimson架构设计： 采用C-star库，这是一个为SilkDB开发的调度器，支持在单个线程上多路复用异步操作。 目标是实现单线程内完成请求处理，减少线程切换和核心间通信。 通过使用future和callback机制，优化请求处理的同步和异步操作。 C-store介绍： C-store是专为Crimson设计的对象存储实现，旨在利用ZNS等新兴存储技术。 避免使用CPU密集型的元数据设计如RocksDB，支持高效的垃圾回收和数据迁移。 通过逻辑地址和物理地址的分离，优化数据管理和垃圾回收过程。 当前进展和未来计划： Crimson项目已支持RBD工作负载和复制池，Blue Store和C-store后端均已实现。 正在进行多核心支持的开发，以及增强稳定性和性能测试。 未来计划包括完善测试套件，实现数据校验（scrub），以及进一步优化多核心架构下的消息路由。 用户参与和反馈： 鼓励用户通过设置实验性功能标志来测试Crimson，但目前不建议用于生产环境。 用户反馈和性能测试数据对项目发展至关重要。 后续行动计划： 完善测试套件，特别是数据校验（scrub）功能的实现。 继续优化多核心支持，改进消息路由和调度机制。 增强C-store的稳定性和性能，特别是针对ZNS和NVMe的优化。 收集用户反馈，持续迭代和优化Crimson项目。 会议结束： 主讲人感谢大家的参与，并邀请提问和讨论。 [会议结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Critical Troubleshooting Tools for Rook Clusters - Subham Kumar Rai & Parth Arora, IBM","slug":"Critical_Troubleshooting_Tools_for_Rook_Clusters_-_Subham_Kumar_Rai_Parth_Arora_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Critical_Troubleshooting_Tools_for_Rook_Clusters_-_Subham_Kumar_Rai_Parth_Arora_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Critical_Troubleshooting_Tools_for_Rook_Clusters_-_Subham_Kumar_Rai_Parth_Arora_IBM/","excerpt":"","text":"会议纪要 会议主题：Rook 集群的故障排除与调试 参会人员： Bharat Lohar (IBM 存储部门，Rook 开发者) 其他 IBM 存储部门成员及社区开发者 会议议程： Rook 简介 Rook Ceph 插件介绍 Rook 支持的命令 安装与基本命令 调试模式 演示与未来工作 讨论内容： Rook 简介 Rook 是一个 Kubernetes 项目，用于简化 Rook 插件的安装和管理。 Rook 可以用于安装、发现和管理集群中的插件。 Rook Ceph 插件介绍 Rook Ceph 插件用于运行基本命令、管理集群、简化运维操作。 该插件有助于开发、故障排除和管理 Rook Ceph 集群。 Rook 支持的命令 讨论了安装步骤和基本命令的使用。 演示了如何使用 kubectl rook-ceph 命令获取集群状态、更新配置映射等。 调试模式 讨论了在集群进入不良状态时如何使用调试模式。 演示了如何使用调试模式进行手动干预，例如移除不工作的 OSD。 调试模式的优势包括不需要关闭操作符，可以通过命令添加标签来避免特定部署的协调。 演示与未来工作 演示了如何使用 kubectl rook-ceph 命令进行集群状态检查、OSD 移除和 Mon 仲裁恢复。 讨论了未来工作，包括将 shell 脚本转换为 Golang、自动收集性能分析信息等。 决定事项： 确认了 Rook Ceph 插件的重要性和实用性，特别是在故障排除和调试方面。 确定了未来工作的方向，包括改进插件的功能和性能。 后续行动计划： 继续开发和完善 Rook Ceph 插件，根据社区反馈添加更多命令和功能。 定期更新文档和演示，确保用户能够轻松理解和使用插件。 考虑在未来的版本中添加更多自动化功能，减少用户的手动操作。 参考资料： Rook 官方文档 Kubernetes 官方文档 Rook Ceph 插件 GitHub 仓库 会议反馈： 参会者对 Rook Ceph 插件的功能和演示表示满意，期待未来的改进和更新。 提出了一些建议，如简化集群启动过程和增加更多自动化功能。 会议结束： 会议在积极的氛围中结束，参会者对 Rook Ceph 插件的未来发展充满期待。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Embracing Ceph: Key Factors Driving Companies to Adopt Ceph Storage Solutions","slug":"Embracing_Ceph_-_Key_Factors_Driving_Companies_to_Adopt_Ceph_Storage_Solutions","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Embracing_Ceph_-_Key_Factors_Driving_Companies_to_Adopt_Ceph_Storage_Solutions/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Embracing_Ceph_-_Key_Factors_Driving_Companies_to_Adopt_Ceph_Storage_Solutions/","excerpt":"","text":"会议纪要 会议概述 本次会议是在Cephlacon上举办的“拥抱Ceph”专题讨论会。会议由Laura Flores和Dan主持，Laura Flores是RADOS工程师，也是用户开发月度会议的主席，Dan是Ceph执行委员会的成员。会议邀请了五位来自不同组织的Ceph用户作为嘉宾，分享他们选择使用Ceph的关键因素、面临的挑战以及对新组织的建议。 嘉宾介绍 Wasil：Workday的高级软件工程师，负责存储团队，Workday是一个用于人力资源应用的云平台。 Andres：Flatiron Institute的高级数据科学家，该机构是Simons基金会的研究机构，专注于计算科学。 Luca：Posey超级计算中心的架构师，该中心支持澳大利亚所有大学，并将成为SKA望远镜的主要操作基地。 Matthew Leonard：Bloomberg工程的存储工程负责人，负责为全球7000名工程师提供存储资产。 Frank Yang：Patina Systems的首席技术官，该公司提供私有云解决方案和软件。 讨论内容 选择Ceph的关键因素 Wasil：从AWS迁移到数据中心时需要块和对象存储，Ceph是OpenStack存储的默认选择，具有成本效益和灵活性。 Andres：Ceph的开源社区、可靠性优先设计、灵活性和活跃的社区支持是关键因素。 Luca：Ceph的可靠性、可扩展性无 downtime 以及社区支持使其成为首选。 Matthew Leonard：Bloomberg早期采用OpenStack和Ceph，社区和开源特性使其持续使用Ceph。 Frank Yang：Ceph的S3支持、TCO优势、开源社区支持以及灵活性使其成为明显选择。 Ceph的开源特性带来的价值 Wasil：能够自主实现安全特性并贡献给社区，Red Hat的支持加速了开源贡献过程。 Andres：技术人员喜欢能够深入代码，调试和实验的自由，无供应商锁定。 Luca：开源避免了与HPC供应商的沟通问题，社区支持快速解决问题。 Matthew Leonard：社区的知识库和活跃的开发者社区提供了强大的支持网络。 Frank Yang：社区支持、文档丰富，软件开发者可以直接访问源代码。 集成Ceph时的挑战 Wasil：自动化工具的集成挑战，安全增强的需求。 Andres：硬件选择的不确定性，大规模系统的问题。 Luca：硬件选择和配置的复杂性，大规模系统的挑战。 Matthew Leonard：硬件和文档的复杂性，应用程序对S3协议的挑战。 Frank Yang：Ceph内部许多可调参数，硬件和环境差异带来的挑战。 吸引新组织的建议 Wasil：Ceph需要更多成熟的基本功能，如RBD设备的复制支持。 Andres：改进文档，特别是入门指南，确保发布版本的数据可靠性。 Luca：改进文档，提供针对不同用户群体的指南，明确硬件建议。 Matthew Leonard：简化Ceph的使用流程，关注用户的工作流程和业务需求。 Frank Yang：使Ceph更易消费，提供基于工作流的文档和指南，增强安全性检查。 对决策者的建议 Wasil：尝试运行POC，了解Ceph的维护和集成需求。 Andres：从小规模开始，理解Ceph的基本原理，考虑支持选项。 Luca：与社区沟通，避免硬件选择的错误，根据经验调整集群规模。 Matthew Leonard：Ceph是生活方式的选择，需要深入理解文档和硬件，社区支持至关重要。 Frank Yang：尝试Ceph，但需意识到生产环境中的长期承诺和投资。 后续行动计划 改进Ceph的文档，特别是入门指南和硬件建议。 简化Ceph的使用流程，关注用户的工作流程和业务需求。 增强Ceph的安全性检查和错误预防机制。 会议总结 会议涵盖了Ceph用户选择、价值、挑战和建议等多个方面，强调了Ceph的开源社区、灵活性和可靠性。同时，也指出了Ceph在文档、硬件选择和使用流程上的改进空间。会议最后，主持人感谢所有嘉宾的参与和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Enhancing Observability in Rook Ceph - Deepika Upadhyay & Gaurav Sitlani, Koor Technologies Inc.","slug":"Enhancing_Observability_in_Rook_Ceph_-_Deepika_Upadhyay_Gaurav_Sitlani_Koor_Technologies_Inc.","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Enhancing_Observability_in_Rook_Ceph_-_Deepika_Upadhyay_Gaurav_Sitlani_Koor_Technologies_Inc./","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Enhancing_Observability_in_Rook_Ceph_-_Deepika_Upadhyay_Gaurav_Sitlani_Koor_Technologies_Inc./","excerpt":"","text":"会议纪要 会议主题 本次会议主要围绕分布式存储系统Ceph的跟踪（tracing）技术展开，特别是使用OpenTelemetry和Jaeger进行跟踪的实践和未来展望。 会议参与者 主讲人：云存储工程师，曾就职于Redos和RBD，现为Code Technologies员工，同时也是Rook项目的贡献者。 同事：Gaurav Sitlani 讨论内容 跟踪技术简介 跟踪技术在Ceph中的应用，特别是在调试复杂场景中的作用。 当前Ceph中跟踪技术的现状及其对Rook的影响。 调试挑战 在Ceph中，如OSD变慢或出现慢操作等问题，可能由多种原因引起，如硬件故障、软件故障、恢复操作等。 传统上，通过日志进行问题定位非常困难，尤其是对于新手或非专家用户。 跟踪技术的优势 跟踪技术可以在生产集群中提供持续的低性能开销的监控。 支持自适应采样策略，减少跟踪数据的处理负担，同时保持系统的概览。 OpenTelemetry与Jaeger的应用 OpenTelemetry提供了一个厂商中立的API，用于在代码中编写跟踪 instrumentation。 Jaeger是一个使用gRPC和Thrift协议收集和展示跟踪数据的CNCF项目。 跟踪技术的实现细节 跟踪数据以span的形式记录，每个span包含操作名称、开始和结束时间以及相关的标签和日志。 通过上下文ID，span之间可以建立父子关系，形成完整的操作流程图。 Rook集群中的跟踪部署 在Rook中，通过Jaeger operator和OpenTelemetry collector实现跟踪数据的收集和处理。 用户可以通过Jaeger UI查询和分析跟踪数据。 未来展望 探索更多的代码 instrumentation，特别是在生产集群中实时监控的关键需求。 考虑在Rook中集成更多的自定义采样策略和CRD（Custom Resource Definitions）。 决定事项 继续推进Ceph和Rook中的跟踪技术集成，特别是在即将发布的Reef版本中。 增强对开发者和贡献者的跟踪技术培训和文档支持。 后续行动计划 完善Rook中的跟踪技术部署文档和教程。 探索更多的代码 instrumentation 和采样策略，以优化生产环境中的跟踪性能。 与社区合作，推广跟踪技术在Ceph和Rook中的应用。 会议总结 本次会议详细讨论了跟踪技术在Ceph和Rook中的应用，特别是在调试复杂场景和优化生产环境中的作用。通过集成OpenTelemetry和Jaeger，可以显著提升问题定位的效率和系统的可观测性。未来的工作将集中在进一步优化跟踪技术的部署和应用，以及增强对开发者的支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"External Rook Ceph Cluster - Parth Arora & Subham Rai, IBM","slug":"External_Rook_Ceph_Cluster_-_Parth_Arora_Subham_Rai_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/External_Rook_Ceph_Cluster_-_Parth_Arora_Subham_Rai_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/External_Rook_Ceph_Cluster_-_Parth_Arora_Subham_Rai_IBM/","excerpt":"","text":"会议纪要 会议参与者 Parth 和 Shubham，IBM 存储部门的研发人员，主要负责 Rook operator 的开发。 会议主题 讨论外部 Ceph 集群（external Ceph cluster）的需求、使用场景、实现方式以及未来的工作计划。 主要讨论内容 外部 Ceph 集群的需求和使用场景 需求背景：在 Kubernetes 集群中运行存储服务，但可能存在已经运行的外部 Ceph 集群，需要将其集成到 Kubernetes 环境中。 使用场景： 大型组织可能需要多个 Kubernetes 集群，通过单一的外部 Ceph 集群来管理这些集群的存储需求。 已经拥有 Ceph 集群，希望将其集成到 Kubernetes 环境中以实现自动化管理。 需要实现存储的完全隔离。 外部 Ceph 集群的实现方式 架构描述：通过 Rook operator 在外部模式下运行，并结合 CSI 层，从外部 Ceph 集群获取信息并提供给 Kubernetes 集群。 安装和配置： 使用 Python 脚本从外部 Ceph 集群获取详细信息。 通过导入 JSON 输出，创建 Kubernetes 资源如 Secrets、ConfigMaps 和 StorageClasses。 部署 Rook operator 并配置外部 Ceph 集群的连接。 验证和监控 验证连接：通过检查集群的健康状态和连接状态来验证配置是否成功。 监控：通过不同的 OpenShift 集群（OCP）的仪表盘来监控不同外部 Ceph 集群的使用情况。 未来工作计划 功能增强：支持 RADOS 命名空间、卷组和 IPv6 端点。 文档改进：提供更清晰的文档，以便用户更容易连接和使用外部 Ceph 集群。 决定事项 确认了外部 Ceph 集群的实现方式和使用场景。 确定了未来工作的重点，包括功能增强和文档改进。 后续行动计划 继续开发和测试外部 Ceph 集群的功能。 更新和改进相关文档，确保用户能够顺利使用外部 Ceph 集群。 监控和收集用户反馈，以便进一步优化和扩展功能。 会议结束 感谢与会者的参与和提问。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"From Classical to the Future - Matan Breizman, IBM","slug":"From_Classical_to_the_Future_-_Matan_Breizman_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/From_Classical_to_the_Future_-_Matan_Breizman_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/From_Classical_to_the_Future_-_Matan_Breizman_IBM/","excerpt":"","text":"会议纪要 会议主题：从经典到未来 - Crimson项目的介绍与进展 主讲人：Matan Brisman 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容总结： 背景介绍： Matan Brisman介绍了他在过去一年多时间里在Crimson项目上的工作。 强调了存储设备速度的显著提升，特别是NVMe与传统HDD之间的性能差异。 技术挑战： 讨论了CPU与存储设备发展速度不匹配的问题。 指出了单核性能增长停滞，而逻辑核心数量增加的趋势。 Crimson项目目标： 目标是减少CPU开销，通过避免上下文切换和跨核心通信来充分利用快速存储设备。 Crimson是对当前OSD（Object Storage Daemon）I/O路径的重新编写，使用C-star框架以提高效率。 C-star框架介绍： C-star是一个开源的C++异步编程框架，适用于现代硬件。 强调了共享无设计、未来与承诺（Future and Promises）以及消息传递等关键概念。 未来与承诺（Future and Promises）： 解释了未来与承诺的编程模型，以及它们在异步编程中的应用。 通过一个汉堡餐厅的类比，形象地说明了未来与承诺的关系。 代码重构示例： 展示了如何将传统的同步代码转换为使用C-star框架的异步代码。 强调了在Crimson中处理I/O请求时，如何通过未来与承诺来避免昂贵的上下文切换。 性能优化： 讨论了在Crimson中如何通过避免上下文切换来减少CPU开销，从而提高性能。 提到了在实际应用中，代码的复杂性可能会增加，但长期来看，这种编程模型可以简化开发。 未来工作与参与方式： 鼓励社区成员参与Crimson项目，提供了加入会议和参与开发的建议。 强调了性能测试的重要性，并提到了未来将会有更多关于性能数据的展示。 决定事项： 继续推进Crimson项目的开发，特别是性能优化方面。 鼓励社区成员参与项目，提供更多的文档和开发指导。 后续行动计划： 定期举行项目会议，讨论进展和待解决的问题。 增加性能测试的覆盖范围，收集更多数据以优化Crimson的性能。 继续优化代码，确保Crimson能够充分利用现代硬件的优势。 会议结束： 会议在Matan Brisman的感谢和掌声中结束。 注意： 以上内容基于会议录音整理，可能需要根据实际情况进行调整和补充。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"How to Make a Positive Impact from Both an Environmental and Financial Perspective","slug":"How_to_Make_a_Positive_Impact_from_Both_an_Environmental_and_Financial_Perspective","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/How_to_Make_a_Positive_Impact_from_Both_an_Environmental_and_Financial_Perspective/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/How_to_Make_a_Positive_Impact_from_Both_an_Environmental_and_Financial_Perspective/","excerpt":"","text":"会议纪要 会议概览 本次会议是在Cephalocon大会上的一次讨论，主题围绕环境影响和财务问题，而非技术细节。会议由两位主要发言人主持，他们分别是Ceph领域的专家和公司高管，讨论了如何在存储领域通过使用Ceph分布式存储系统来减少环境影响和优化财务决策。 主要议题 环境影响与财务决策： 讨论了数据中心和服务器的生命周期对环境的影响，特别是碳足迹的问题。 强调了延长服务器使用寿命（从通常的5年延长到7年）对减少碳排放的重要性。 分析了购买新服务器与使用旧服务器的成本和环境影响，提出了使用翻新硬件的建议。 Ceph的应用与优势： 讨论了Ceph的设计理念，即通过分布式架构来处理组件故障，提高系统的可靠性和可扩展性。 强调了Ceph在处理存储需求时的效率，特别是在使用旧硬件时仍能保持良好的性能。 立法与企业责任： 提到了欧盟的绿色协议和即将实施的企业可持续发展报告指令，要求企业报告其环境影响。 讨论了企业如何通过改进其IT设备的使用和管理来减少环境影响，并符合未来的法规要求。 决定事项 会议强调了企业和个人在采购和使用IT设备时应考虑其长期的环境影响，而不仅仅是短期的财务成本。 提出了使用Ceph等分布式存储系统来优化资源使用，减少新硬件的采购，从而降低碳足迹。 后续行动计划 鼓励开发人员在开发Ceph相关项目时，考虑到旧硬件的兼容性和性能，确保软件的广泛适用性。 建议企业开始准备并实施环境影响报告，以符合即将到来的法规要求。 提倡在企业内部开展关于可持续性和环境影响的讨论，特别是在IT设备采购和使用方面。 结论 会议通过讨论Ceph的应用和企业的环境责任，强调了通过技术创新和负责任的管理来减少环境影响的重要性。鼓励所有参与者将这些讨论带回各自的工作环境，推动更可持续的IT实践。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Implementing a Resilient Ceph RGW Object Storage with Erasure Coded Data Pool as the Foundation...","slug":"Implementing_a_Resilient_Ceph_RGW_Object_Storage_with_Erasure_Coded_Data_Pool_as_the_Foundation...","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Implementing_a_Resilient_Ceph_RGW_Object_Storage_with_Erasure_Coded_Data_Pool_as_the_Foundation.../","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Implementing_a_Resilient_Ceph_RGW_Object_Storage_with_Erasure_Coded_Data_Pool_as_the_Foundation.../","excerpt":"","text":"会议纪要 会议概述 本次会议由Bahid主持，他是Digicolor的云工程师，分享了公司在设计和实施对象存储服务方面的经验。由于主讲人Yavash无法现场出席，他的演讲以预录视频形式播放。 主要议题 Digicolor简介：Digicolor是中东地区最大的电子商务平台，每日页面浏览量超过1800万，促销期间可达2亿。 问题定义：公司面临高流量和高数据存储需求，原有硬件资源共享导致成本上升。 解决方案：设计并实施自有的对象存储服务，以降低成本并提高性能。 技术细节： 架构设计：采用三层架构，包括Nginx作为缓存服务器和负载均衡器，Ceph RGW处理对象存储。 硬件环境：利用公司闲置硬件资源，部署8个节点，使用HP 10G网络设备。 软件环境：测试了Octopus和Pacific版本的Ceph，使用Ubuntu LTS和OpenResty构建模块。 性能优化：通过自定义CRUSH映射、SSD作为后端存储、分离公共和集群网络等措施优化性能。 数据缓存：设计了多层缓存机制，包括CDN、图像大小调整和Nginx缓存。 测试与结果： 负载测试：使用Locust框架和实际图像数据进行测试，设计了两种场景以模拟真实流量。 性能指标：通过基准测试，选择了Azure RBD以提高存储容量和性能。 最终配置：确定了9个RGW实例，每个实例的线程池大小为2008和2048，以优化CPU核心分配。 决定事项 采用Ceph RGW作为对象存储服务。 优化Nginx配置和RGW实例数量。 实施多层缓存策略以提高性能。 后续行动计划 继续监控和优化系统性能。 探索更多性能优化技术，如进一步调整CRUSH映射和网络配置。 分享经验和技术细节，与社区进行交流。 结论 Digicolor通过设计和实施自有的对象存储服务，成功降低了成本并提高了系统性能，满足了公司的高流量和高存储需求。会议最后，Bahid邀请与会者提问，并表示愿意分享更多细节和经验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Improving Business Continuity for an Existing Large Scale Ceph Infrastructure","slug":"Improving_Business_Continuity_for_an_Existing_Large_Scale_Ceph_Infrastructure","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Improving_Business_Continuity_for_an_Existing_Large_Scale_Ceph_Infrastructure/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Improving_Business_Continuity_for_an_Existing_Large_Scale_Ceph_Infrastructure/","excerpt":"","text":"会议纪要 会议主题： CERN的Ceph存储系统业务连续性与灾难恢复改进 会议时间： 日期未提供 会议地点： 未提供 参会人员： Enrico, Abi (CERN IT部门存储组) 会议内容： CERN介绍： CERN位于日内瓦，运营着一个直径27公里的粒子对撞机，该对撞机建于地下100米。 对撞机内部有超导磁体，用于加速粒子至接近光速，并在精确点进行对撞。 CERN拥有两个计算中心，其中一个历史悠久，建于60年代末或70年代初，另一个新中心预计今年年底投入使用。 个人介绍： Enrico：计算机网络博士，2017年加入CERN，2020年开始参与Ceph操作。 Abi：加入CERN两年，负责Ceph的安全操作。 Ceph在CERN的应用： CERN运行16个生产集群，使用Ceph的各种形式（块存储、文件存储和对象存储）。 总存储容量约为65PB，主要使用旋转硬盘，少量全闪存存储用于RocksDB和元数据池。 Ceph与OpenStack集成，为45万个CPU核心提供存储支持。 近年来，Ceph也越来越多地被用于Kubernetes和OpenShift集群。 业务连续性与灾难恢复： 块存储（RBD）： 从单一RBD集群扩展到五个RBD集群，通过OpenStack提供不同性能和可用性的存储选项。 引入了存储可用性区域（Availability Zones），以提高业务的连续性。 使用RBD镜像进行灾难恢复，测试了基于日志和基于快照的镜像方法。 OpenStack Cinder备份驱动支持S3和RBD备份，RBD备份性能更优。 对象存储： 主要使用两个独立的Ceph集群，一个用于主存储，另一个用于备份。 测试了S3多站点配置，发现同步延迟和Bucket索引重分片的问题。 探索了Cloud Sync功能，用于与外部云服务同步特定Bucket。 文件系统（CephFS）： 从单一CephFS集群扩展到多个集群，根据使用场景进行划分。 测试了CephFS快照功能，发现性能影响主要集中在MDS的Finisher线程。 总结与展望： 业务连续性通过分散存储到不同集群实现，需要与用户和上层服务协调。 灾难恢复主要通过备份和恢复实现，Ceph提供了多种备份工具和方法。 未来可能考虑使用磁带备份，并继续优化备份流程。 后续行动计划： - 继续测试和优化RBD、S3和CephFS的灾难恢复功能。 - 探索和实施更高效的备份和恢复策略，包括磁带备份。 - 与用户和其他IT部门协调，制定清晰的灾难恢复流程。 会议结束： - 会议在提问环节后结束，参会者对Ceph在CERN的应用和未来发展表示了兴趣和赞赏。 备注： - 会议中提到的Ceph相关技术和工具包括RBD、CephFS、Rados Gateway、OpenStack、Kubernetes、OpenShift等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"It’s Alive! Image Live Migration, Live Import and Instant Restore with Ceph RBD - Danny Harnik, IBM","slug":"It_s_Alive_Image_Live_Migration_Live_Import_and_Instant_Restore_with_Ceph_RBD_-_Danny_Harnik_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/It_s_Alive_Image_Live_Migration_Live_Import_and_Instant_Restore_with_Ceph_RBD_-_Danny_Harnik_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/It_s_Alive_Image_Live_Migration_Live_Import_and_Instant_Restore_with_Ceph_RBD_-_Danny_Harnik_IBM/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储中的图像实时迁移、导入和即时恢复 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：来自IBM研究（Haifa, Israel）的研发团队成员，包括发言人及其同事Effie。 会议内容总结： 图像实时迁移（Image Live Migration）简介 功能自Nautilus版本开始引入，最初用于同一集群内不同存储池之间的图像迁移。 在Pacific版本中扩展到外部源，支持从外部源实时迁移图像到Ceph集群。 支持的客户端类型 仅支持Librbd，不支持krbd。适用于OpenStack、KVM虚拟化、NBD RBD及NVMe over Fabrics。 图像实时迁移的工作原理 采用后复制迁移（post-copy migration）技术，允许在数据迁移过程中立即在目标端开始工作。 写操作直接指向目标端，读操作初始指向目标端，若数据不存在则从源端获取。 主要应用场景 集群间实时迁移：适用于拥有多个Ceph集群的部署，支持跨集群的实时数据迁移和负载均衡。 即时导入到Ceph：允许从外部源（如NAS设备）快速导入图像到Ceph，实现即时使用。 备份与即时恢复：通过差异备份和即时恢复功能，实现高效的备份和快速的数据恢复。 新功能介绍 外部NBD源的实时迁移：新增NBD格式支持，通过chemo NBD服务器连接，实现更灵活的图像导入。 备份与即时恢复的POC：使用qcow2格式进行差异备份，并通过chemo NBD实现即时恢复。 未来计划与改进方向 推动现有PR上线的进程。 探索对克隆图像的集群间迁移支持。 改进备份与恢复流程，特别是增加对Ceph原生导出格式的索引支持，以实现更高效的即时恢复。 决定事项： 继续推动图像实时迁移功能的开发和优化。 完善文档和教程，确保用户能够充分利用新功能。 后续行动计划： 完成并上线相关PR。 开发和测试对克隆图像的集群间迁移支持。 研究和实施对Ceph原生导出格式的索引支持，以优化备份与恢复流程。 会议结束： 会议在提问和讨论环节后圆满结束，发言人感谢所有参与者的积极参与和反馈。 备注：本次会议详细讨论了Ceph分布式存储中的图像实时迁移、导入和即时恢复功能，强调了其在多集群部署和数据备份恢复中的重要性，并提出了未来的改进方向和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Ceph: The Future of the Storage TODAY","slug":"Keynote_-_Ceph_-_The_Future_of_the_Storage_TODAY","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Keynote_-_Ceph_-_The_Future_of_the_Storage_TODAY/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Keynote_-_Ceph_-_The_Future_of_the_Storage_TODAY/","excerpt":"","text":"会议纪要 会议概述 会议在Cephalicon举行，由IBM的Danny Mace主持。Danny是IBM存储软件业务的工程团队负责人，介绍了IBM与Red Hat在Ceph项目上的合作和未来计划。Kyle加入讨论，分享了IBM对Ceph社区的贡献和未来发展方向。 讨论的主要议题 IBM与Red Hat的合作： IBM从Red Hat接管了Ceph团队的工程师，以加强软件定义存储的能力。 IBM和Red Hat认为这一合作对Ceph和相关开源项目的发展有利。 IBM的存储业务战略： IBM在存储业务中同时拥有硬件和软件，致力于发展软件定义存储业务。 IBM是全球最大的Kubernetes软件供应商，专注于混合云和OpenShift平台。 Ceph的未来发展： IBM计划扩展Ceph的应用场景，包括容器存储、混合云环境和新用例。 IBM承诺Ceph将继续保持100%开源，并优先考虑上游开发。 Ceph的社区和生态系统： Ceph拥有15年的发展历史和活跃的社区，IBM希望通过增加贡献来进一步增强其生态系统。 IBM计划通过提供最佳的S3、NFS和NVMe over TCP接口来扩展Ceph的市场。 决定的事项 IBM和Red Hat已正式将Ceph团队从Red Hat转移到IBM，工程师团队保持完整。 IBM承诺Ceph将继续保持100%开源，并优先考虑上游开发。 后续的行动计划 IBM将扩展对Ceph的贡献，特别是在容器存储、混合云环境和新的存储用例方面。 IBM将加强Ceph的生态系统，提供最佳的S3、NFS和NVMe over TCP接口，以进入新的市场和应用领域。 结论 IBM对Ceph的未来充满信心，并计划通过增强其功能和扩展其应用场景来推动Ceph的发展。IBM承诺将继续支持Ceph的开源性质，并通过其全球销售网络来推广Ceph。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Lead Developers Town Hall","slug":"Keynote_-_Lead_Developers_Town_Hall","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Keynote_-_Lead_Developers_Town_Hall/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Keynote_-_Lead_Developers_Town_Hall/","excerpt":"","text":"Ceph社区会议纪要 参会人员介绍 Radakaim: Raiders car techlete Yarit: Telemetry techlete Matt Benjamin: Senior Engineering Manager for Rails Gateway and NFL Schedule Sam: Lead for Crimson Zach Dover: Docs guy Josh Duggan: Member of the application here Council and long-time staff developer 主要议题及讨论内容 升级问题 问题: 是否可以从Octopus直接升级到Reef，跳过Quincy？ 答案: 不可以，Ceph支持一次升级两个版本。可以从Octopus直接升级到Pacific或Quincy，但不能直接升级到Reef。 认证问题 问题: 如何在不停机的情况下添加认证？ 答案: 可以通过文档添加认证，已有相关页面介绍如何启用认证，但可能缺少不停机的具体步骤。建议联系Zach获取更多细节。 PG资源消耗 问题: 如何获取PG的CPU或内存消耗？ 答案: 目前没有直接的方法，但可以考虑通过收集和聚合相关指标来推断PG的资源消耗。 冻结数据迁移 问题: 是否有计划将冻结数据迁移到磁带存储？ 答案: 目前正在开发两个对象存储系统，Crimson项目可能是未来的解决方案。 性能改进 问题: 新均衡器对读取IOPS和吞吐量的性能改进如何？ 答案: 正在进行测试，具体数据尚未公布。 大桶删除 问题: 如何快速删除包含数百万文件的大桶，同时不 overload 集群？ 答案: 可以通过增加垃圾回收队列和调整相关设置来实现，但可能会影响其他流量。 SSD性能优化 问题: 如何配置OSD以最大化NVMe设备的性能？ 答案: 需要根据具体工作负载进行调整，可以参考Ceph官方博客中的性能优化文章。 文档改进 问题: 如何帮助清理和改进Ceph文档？ 答案: 可以通过访问docs.ceph.com并点击顶部的大黄框链接，按照开发者指南的基本工作流程进行贡献。 决定事项 认证添加: 确认可以通过文档添加认证，建议联系Zach获取更多细节。 文档改进: 社区将致力于改进文档，特别是编写初学者指南和概述段落。 后续行动计划 认证文档: Zach将负责更新认证相关的文档，确保包含不停机的具体步骤。 性能测试: 继续进行新均衡器的性能测试，并及时公布测试结果。 文档贡献: 鼓励社区成员通过docs.ceph.com参与文档的改进工作。 其他讨论 多站点配置: 讨论了Ceph Gateway的多站点配置和重启桶的当前支持情况。 IPv6支持: 强调了IPv6支持的重要性，并讨论了可能的解决方案。 会议结束 会议在感谢和掌声中结束，鼓励社区成员继续参与和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: State of the Cephalopod","slug":"Keynote_-_State_of_the_Cephalopod","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Keynote_-_State_of_the_Cephalopod/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Keynote_-_State_of_the_Cephalopod/","excerpt":"","text":"会议纪要 会议概述 本次会议主要围绕Ceph项目的最新进展和未来规划进行了详细讨论。会议由多位Ceph项目的关键开发者和技术负责人参与，包括Dan Grenowitz、Yarit Tatuka、Sam、Zach Dover等，他们分别介绍了各自负责领域的最新动态和未来计划。 主要议题 项目治理模型更新：Ceph项目引入了一个新的治理模型，包括一个选举产生的执行委员会，负责项目的日常运营和战略决策。 技术焦点：过去几年，Ceph项目主要关注可靠性和性能提升，包括大规模测试、性能退化检测、候选版本发布等。 用户互动：项目团队鼓励用户与开发者之间的直接反馈和互动，特别是在线下活动中。 版本更新：Ceph的Reef版本计划于6月发布，S版本（Squid）的命名已经确定。 技术更新： RADOS：重点改进了QoS（Quality of Service），引入了mClock调度器。 Crimson：高性能的OSD重写项目，支持RBD工作负载，计划在Squid版本中进一步优化。 Telemetry：继续优化后端分析工具，改进数据收集和驱动健康指标。 Dashboard：改进易用性和功能性，新增RBD镜像和高级OSD操作。 RGW：增强S3选择功能，改进多站点性能和稳定性。 RBD：加强安全性，支持不同克隆的独立加密密钥。 CephFS：改进多站点支持，增强镜像和异步复制功能。 决定事项 Reef版本的发布：计划于6月发布，正在进行大规模测试以确保稳定性。 Squid版本的规划：重点在于性能优化、功能增强和易用性提升。 后续行动计划 用户反馈：鼓励用户在即将到来的开发者大会上提供反馈和建议。 技术开发：继续在各个子系统中进行性能和可靠性优化。 文档改进：加强文档的编写和维护，提供更多入门指南和概览文章。 其他 开发者大会：明天的开发者大会上将有一个开发者城镇会议，欢迎所有人提出问题和建议。 赞助商展示：会议结束后，赞助商展示区将开放，欢迎参会者参观。 本次会议全面展示了Ceph项目的最新进展和未来方向，强调了用户与开发者之间的互动和反馈的重要性，以及持续的技术优化和文档改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: The Road to Open Source Ceph: Bloomberg’s Enterprise Ceph Journey","slug":"Keynote_-_The_Road_to_Open_Source_Ceph_-_Bloomberg_s_Enterprise_Ceph_Journey","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Keynote_-_The_Road_to_Open_Source_Ceph_-_Bloomberg_s_Enterprise_Ceph_Journey/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Keynote_-_The_Road_to_Open_Source_Ceph_-_Bloomberg_s_Enterprise_Ceph_Journey/","excerpt":"","text":"会议纪要 会议主题： Bloomberg的开放源代码之旅及其与Ceph的结合 主讲人： Matthew Leonard，Bloomberg存储工程负责人 会议地点： Cephalocon会议 会议时间： 近期 主要内容： 自我介绍与会议开场 Matthew Leonard进行了自我介绍，并分享了与参会者合影的趣事。 强调了再次见到大家的喜悦，特别是在经历了长时间的Zoom会议和电子邮件沟通后。 Bloomberg的开放源代码之旅 Bloomberg是一个金融和媒体公司，拥有7000名工程师，占全球员工总数的30%以上。 公司早期是闭源的，但在2000年左右开始转向开放源代码，成立了开放源代码项目办公室，以促进与开源社区的合作。 Bloomberg赞助了多个技术和基金会，包括Ceph和云原生计算基金会，并在Kubernetes生态系统中发挥重要作用。 开源贡献与项目 Bloomberg开发并贡献了多个开源项目，如Python内存分析工具Memory Profiler，该项目在GitHub上获得了超过10,000颗星。 公司还设立了Bloomberg自由和开源软件基金，以支持开源社区的发展。 基础设施转型 Bloomberg在2016年决定转向云原生基础设施，以解耦计算和存储，并支持以前在裸机上运行的用例。 公司采用了Kubernetes、虚拟化和S3等平台，以支持数以万计的虚拟机和数十亿次的S3请求。 Ceph在Bloomberg的应用 Bloomberg使用Ceph来支持其S3服务，运行着多个集群，管理着数百PB的存储。 公司还利用Ceph的最新功能，如多站点部署，以满足其特定需求。 未来计划与社区参与 Bloomberg计划将其开发的Telemetry收集系统和QoS堆栈开源，并希望在今年第一季度发布。 公司希望更深入地参与Ceph社区，特别是在crimson、Ceph存储和RADOS网关等项目中。 招聘信息 Bloomberg正在招聘，欢迎有兴趣的工程师与他们联系。 后续行动计划： - 开源Telemetry收集系统和QoS堆栈。 - 加强与Ceph社区的互动和合作，特别是在特定项目中。 - 继续招聘工程师，扩大团队。 结束语： - Matthew Leonard感谢大家的参与，并鼓励大家在会议期间或通过公司展位与他们交流。 会议反馈： - 参会者对Matthew Leonard的分享表示感谢，并给予了热烈的掌声。 备注： - 会议中提到的Ceph、Kubernetes、S3等关键词保留了英文原文，以保持技术领域的准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Welcome Back & Remarks","slug":"Keynote_-_Welcome_Back_Remarks","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Keynote_-_Welcome_Back_Remarks/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Keynote_-_Welcome_Back_Remarks/","excerpt":"","text":"会议纪要 会议概述 日期与时间: 第二或第三天上午 地点: Cephalicon 会议 参会人员: 会议组织者、社区成员及嘉宾 第一天回顾 反馈: 第一天会议反响良好，技术内容丰富，社区成员Josh表示非常满意，认为能够看到新老面孔并重新聚集社区非常棒。 文档改进: Zach Dover, 文档负责人，提到昨天一整天都在听取关于如何改进文档的意见，使其对初学者更加友好和易懂。 社交活动 船游活动: 昨晚的42号码头船游活动受到好评，特别提到船只完全封闭，安全无虞。 今日安排 开场提醒: 强调遵守会议行为准则，确保每个人感到受欢迎和包容。 赞助商感谢: 感谢主要赞助商，包括Bloomberg、IBM等。 日程概览: 上午: Bloomberg的 keynote 演讲。 开发者市政厅: 问答环节。 后续: 更多演讲，今天的活动会稍微延长，因为有很多精彩的提交，最后的演讲将在6:30结束。 后续行动 确保所有参会者了解并遵守会议的行为准则。 继续收集并实施关于文档改进的建议，以提升用户体验。 保持社区的活跃和团结，鼓励更多的互动和合作。 本次会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了信息的全面性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Welcome & Opening Remarks","slug":"Keynote_-_Welcome_Opening_Remarks","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Keynote_-_Welcome_Opening_Remarks/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Keynote_-_Welcome_Opening_Remarks/","excerpt":"","text":"会议纪要 会议主题： Cephalocon 会议开幕 会议时间： 具体日期未提供 会议地点： 未明确指出 主持人： Dan 和 Josh 参会人员： Cephalocon 参会者、Ceph 社区成员、赞助商代表（Bloomberg、IBM、42on、Canonical、Clyso、Core） 会议内容摘要： 开场致辞： Dan 和 Josh 欢迎大家参加自2019年巴塞罗那以来的首次线下 Cephalocon 会议。 强调了过去四年的重要发展，包括 Ceph 的五个版本更新（Nautilus, Octopus, Pacific, Quincy, 即将发布的 Reef）。 提到领导层的变动，Josh 和 Dan 代表 Ceph 执行委员会。 会议组织情况： 会议门票已全部售罄，感谢所有参会者的支持。 提醒参会者注意 Linux 基金会活动的共同规则，确保每个人都感到受欢迎和包容。 介绍了会议日程安排，包括每天上午九点的主题演讲和全天三个并行会议。 会议设施与活动： 提供全天茶歇和午餐服务。 介绍了昨天的开发者峰会内容，Josh 和团队将在今早分享相关内容。 强调了赞助商展示和今晚的展位巡游活动。 感谢与支持： 感谢 Ceph 基金会成员、赞助商、演讲者和整个 Ceph 社区的支持。 特别感谢 Platinum 赞助商 Bloomberg 和 IBM，以及 Silver 赞助商 42on、Canonical 和 Clyso。 Ceph 基金会介绍： 基金会成立于2018年，旨在全球范围内组织和推动 Ceph 的发展。 基金会负责组织 Ceph 日和 Cephalocon 等活动，讨论项目方向，提升社区的可靠性和测试硬件。 未来活动预告： 今年已计划在印度、温哥华和首尔举办更多 Ceph 相关活动。 鼓励各地组织更多 Ceph 日活动，并提供了联系基金会的方式。 会议后续安排： 接下来的议程包括 IBM 的“存储的未来”演讲和开发者对当前 Ceph 项目状态的更新。 后续行动计划： - 参会者应关注会议日程，积极参与各项活动。 - 如有兴趣组织 Ceph 日活动，可联系基金会获取更多信息。 - 继续支持 Ceph 社区和基金会的工作，共同推动项目的发展。 备注： - 请参会者注意会议期间的各项安排和规则，确保会议顺利进行。 - 对于 Ceph 项目的具体技术更新和未来发展方向，将在后续的会议中详细讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Kubernetes Stateful Application Disaster Recovery with Zero Data Loss - Daniel Parkes, IBM","slug":"Kubernetes_Stateful_Application_Disaster_Recovery_with_Zero_Data_Loss_-_Daniel_Parkes_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Kubernetes_Stateful_Application_Disaster_Recovery_with_Zero_Data_Loss_-_Daniel_Parkes_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Kubernetes_Stateful_Application_Disaster_Recovery_with_Zero_Data_Loss_-_Daniel_Parkes_IBM/","excerpt":"","text":"会议纪要 会议主题：Kubernetes中状态应用的同步复制策略 主讲人：Daniel Parks（IBM产品管理团队） 会议内容总结： 背景介绍： Daniel Parks介绍了在Kubernetes中运行关键应用的需求日益增长，这些应用需要持久化数据，因此对数据复制（DR）的需求也在增加。 讨论了不同类型的数据复制选项，包括备份与恢复、异步复制和同步复制（Metro DR）。 备份与恢复： 使用Velero API进行备份和恢复，适用于逻辑故障的覆盖，但RPO（恢复点目标）和RTO（恢复时间目标）容忍度较高。 异步复制（Regional DR）： 使用Open Cluster Manager进行应用的故障转移和恢复，RPO在几分钟范围内，RTO依赖于应用启动时间等因素。 同步复制（Metro DR）： 提供了零数据丢失的同步复制解决方案，主要依赖于Ceph的stretch模式。 使用Rook在Kubernetes集群中部署Ceph，并通过RBD镜像进行块卷的同步复制。 需要低延迟（约10毫秒）以保证性能，适用于非常关键的应用。 Ceph Stretch模式： 讨论了Ceph在stretch模式下的部署细节，包括使用Arbiter节点作为仲裁者，确保在网络分区情况下仍能维持高可用性。 强调了在这种模式下，Ceph集群的自动调整和恢复机制。 应用故障转移演示： 展示了如何在Open Cluster Manager中进行应用的故障转移和恢复，确保RPO为零，没有数据丢失。 决定事项： 确认了同步复制（Metro DR）作为关键应用的高可用性解决方案。 讨论了Ceph在stretch模式下的部署和操作细节。 后续行动计划： 继续优化和测试同步复制解决方案，确保其在实际应用中的稳定性和性能。 探索更多自动化选项，以减少手动操作在故障转移过程中的需求。 提供更多文档和资源，帮助用户理解和部署这些高可用性解决方案。 其他讨论点： 讨论了CFS（Ceph File System）在同步复制中的应用潜力和可能的改进。 确认了所有演示和讨论的组件均为开源项目，鼓励社区参与和贡献。 会议结束： 会议在感谢和掌声中结束，Daniel Parks鼓励大家如果有任何问题或需要进一步的信息，可以随时联系。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Maximising Data Storage Efficiency with Ceph as a Caching Layer for Tape Archiving","slug":"Maximising_Data_Storage_Efficiency_with_Ceph_as_a_Caching_Layer_for_Tape_Archiving","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Maximising_Data_Storage_Efficiency_with_Ceph_as_a_Caching_Layer_for_Tape_Archiving/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Maximising_Data_Storage_Efficiency_with_Ceph_as_a_Caching_Layer_for_Tape_Archiving/","excerpt":"","text":"会议纪要 会议基本信息 主讲人: Thomas Bennett 和 Martin Lever 公司: Solo, 位于南非开普敦 会议主题: 使用Ceph作为接口的存储解决方案 会议内容总结 公司背景: Solo公司由南非红天文台的研究人员创立，专注于开发创新的存储解决方案。 项目动机: 通过提交演讲来免除会议费用，同时展示他们在Ceph存储领域的创新应用。 项目目标: 开发类似Amazon Glacier的存储解决方案，名为Solo Blue，该产品不依赖于BlueStore，而是完全独立的新产品。 客户介绍: 主要客户是南非红天文台，该天文台拥有世界上最敏感的射电望远镜——Meerkat。天文台产生的数据量巨大，需要长期存储和维护。 技术挑战: 数据量预计在未来几年内从18PB增长到60-200PB，需要有效的存储和管理策略。 解决方案概念: 使用Ceph作为接口，通过S3协议管理和存档数据。数据在Ceph和磁带之间迁移，确保长期存储的同时保持数据的可访问性。 实施细节: 使用IBM TS 4500磁带库，计划在Ceph集群上部署解决方案，并通过Ansible自动化安装和管理。 未来展望: 计划在年中完成功能性系统，并探索S3版本控制、多池支持等高级功能。同时，考虑将部分管理功能集成到Ceph Gateway中，以便更好地服务于社区。 决定事项 技术选型: 确定使用Ceph作为主要存储平台，结合磁带库进行长期数据存档。 项目进度: 预计年中完成功能性系统的开发，并开始实际部署。 后续行动计划 系统开发: 继续开发和测试Solo Blue系统，确保其稳定性和性能。 社区合作: 探索与Ceph社区的合作机会，特别是在Ceph Gateway的集成和功能扩展方面。 用户反馈: 收集用户和社区的反馈，优化产品设计和功能。 联系方式 公司网站: Solo公司网站 会议反馈 会议中讨论了磁带存储的未来和其在现代存储解决方案中的应用，引起了与会者的广泛兴趣和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"MicroCeph: What, Why and Who Is It for - Peter Sabaini & Utkarsh Bhatt, Canonical","slug":"MicroCeph_-_What_Why_and_Who_Is_It_for_-_Peter_Sabaini_Utkarsh_Bhatt_Canonical","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/MicroCeph_-_What_Why_and_Who_Is_It_for_-_Peter_Sabaini_Utkarsh_Bhatt_Canonical/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/MicroCeph_-_What_Why_and_Who_Is_It_for_-_Peter_Sabaini_Utkarsh_Bhatt_Canonical/","excerpt":"","text":"会议纪要 会议主题： Microsoft - Ceph集群的简化部署与管理 主讲人： Peter Sabini（来自Canonical） 会议内容概述： 产品介绍： Microsoft是一个针对小型用例设计的Ceph集群解决方案，以snap包形式提供，确保隔离性。 该产品专注于特定的小型用例，并非全功能存储解决方案。 动机与问题陈述： Ceph的安装和操作通常复杂，需要专业用户。Microsoft旨在简化这一过程，使其更易于广泛使用。 技术实现： 基于snap包构建，确保软件包自包含，避免依赖冲突（如DLL hell）。 提供沙箱环境，简化部署和管理，增强安全性和可重复性。 引入轻量级管理层，基于分布式SQLite数据库存储配置和管理信息。 示例用例： 适用于边缘存储、实验室环境、个人开发设置等，特别是非专家用户需要简单可靠的存储解决方案的场景。 演示环节： 展示了如何在三台VM上部署Microsoft，设置S3 Gateway，并进行基本的数据存储操作。 未来发展计划： 计划增加自动OSD加密、网络配置的便利层、轻松升级功能、自动伸缩控制等。 考虑自动化S3 Gateway用户的创建等便利功能。 问答环节： 讨论了集群扩展性、网络配置、与现有Ceph功能的潜在重复等问题。 确认当前基于Ceph的Quincy版本，并计划支持即将发布的Reef版本。 决定事项： - 继续开发和完善Microsoft，特别是增强其自动化和便利性功能。 后续行动计划： - 继续推进自动OSD加密、网络配置便利层、轻松升级和自动伸缩控制等功能的开发。 - 保持与Ceph上游版本的同步更新。 联系方式： - 可通过microsoft.com或GitHub获取更多信息和参与开发。 结束语： - 感谢参与，鼓励大家访问展位了解更多信息，并提及Canonical正在招聘。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Monitoring and Centralized Logging in Ceph - Avan Thakkar, IBM","slug":"Monitoring_and_Centralized_Logging_in_Ceph_-_Avan_Thakkar_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Monitoring_and_Centralized_Logging_in_Ceph_-_Avan_Thakkar_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Monitoring_and_Centralized_Logging_in_Ceph_-_Avan_Thakkar_IBM/","excerpt":"","text":"会议纪要 会议概述 本次会议由IBM软件工程师主持，讨论了Chef中的监控和集中式日志系统，以及它们在Ceph Dashboard中的集成。由于一些参会者因签证问题未能出席，会议由主持人独自进行。 关键细节 主持人背景：IBM软件工程师，拥有三年Ceph维护经验，参与过Ceph Dashboard的监控和安全管理模块，近期贡献于Rook项目。 监控的重要性：监控帮助跟踪集群的健康和性能，确保可靠性和可扩展性，便于故障排查。 讨论的主要议题 监控工具： Prometheus：用于收集机器指标，如磁盘占用、CPU和内存利用率等。 Alert Manager：处理来自Prometheus的警报，并发送至接收器，如Ceph Dashboard。 Grafana：提供数据可视化，包括预构建的仪表盘，如集群概览、OSD详情等。 集中式日志： Loki：日志聚合工具，与Prometheus和Grafana紧密集成。 Promtail：轻量级日志收集代理，部署在每个节点上，将日志发送到Loki。 决定的事项 Prometheus模块的改进：为解决大规模集群中的性能问题，计划实施每个节点的Prometheus exporter，直接从socket文件收集数据，减少对管理器的依赖。 Loki和Promtail的集成：决定使用Loki和Promtail作为集中式日志解决方案，因其与现有监控堆栈的紧密集成和高可扩展性。 后续行动计划 实施新的Prometheus exporter：在每个节点部署新的exporter，直接从socket文件收集数据。 升级Loki版本：计划升级到2.8.0版本，以简化日志查询和过滤操作。 监控和日志系统的持续优化：根据用户反馈和需求，不断优化监控和日志系统的功能和性能。 会议总结 本次会议详细讨论了Chef中的监控和集中式日志系统的当前状态和未来改进计划。通过引入新的Prometheus exporter和升级Loki版本，旨在提高系统的性能和易用性。会议最后，主持人准备接受任何问题和反馈，以便进一步优化系统。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"NVMe-Over-Fabrics Support for Ceph - Jonas Pfefferle, IBM","slug":"NVMe-Over-Fabrics_Support_for_Ceph_-_Jonas_Pfefferle_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/NVMe-Over-Fabrics_Support_for_Ceph_-_Jonas_Pfefferle_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/NVMe-Over-Fabrics_Support_for_Ceph_-_Jonas_Pfefferle_IBM/","excerpt":"","text":"会议纪要 会议主题：Ceph中Envy me over Fabrics的概述 主讲人：Jonas, IBM Research 会议时间：[具体日期] 会议地点：[具体地点] 会议内容总结： 背景介绍： Jonas首先介绍了Envy me over Fabrics（NVMe-oF）在Ceph中的应用，强调了其与现有RBD（RADOS Block Device）的区别和优势。 主要原因包括提高与其他系统的互操作性，支持现有生态系统中的远程存储访问，以及利用DPU（Data Processing Unit）的硬件加速能力。 技术细节： 架构设计：NVMe-oF Gateway作为中间层，将NVMe-oF协议转换为RADOS协议，支持TCP和RDMA两种传输方式。 控制路径：使用Python编写的控制守护进程，通过gRPC进行配置管理，支持RBD图像到子系统命名空间的映射。 数据路径：采用SPDK（Storage Performance Development Kit）处理数据路径，支持多种块设备类型。 多路径和故障转移：通过NVMe-oF的多路径规范，实现Gateway Group的概念，支持配置持久化和多Gateway的协同工作。 性能测试： 展示了单客户端和多客户端场景下的性能测试结果，表明NVMe-oF Gateway能够接近直接使用RBD的性能。 测试了不同数量卷的扩展性，表明系统能够处理大量并发IO。 未来计划： 计划实现Discovery服务，支持动态路径发现和更新。 考虑增加身份验证和加密功能，以及全局QoS（Quality of Service）控制。 探索直接在Ceph OSD中使用NVMe-oF的可能性，以优化数据路径。 项目状态： 当前项目处于开发阶段，计划在Reef版本中发布初始版本，支持单Gateway配置。 多Gateway功能已经合并到代码库中，未来将逐步增加更多功能。 参与者和资源： 项目由多个公司和团队共同参与，提供代码库和社区支持。 鼓励社区成员参与测试和反馈，共同推动项目发展。 后续行动计划： 继续优化性能和扩展性，特别是在多客户端和高并发场景下。 实现Discovery服务，增强系统的动态适应能力。 探索和实现身份验证、加密和全局QoS控制。 加强社区合作，通过定期会议和Slack频道收集反馈和建议。 会议结束： 会议在提问和讨论环节后圆满结束，Jonas感谢所有参与者的积极互动和支持。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"New Read Balancer in Ceph - Laura Flores, IBM","slug":"New_Read_Balancer_in_Ceph_-_Laura_Flores_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/New_Read_Balancer_in_Ceph_-_Laura_Flores_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/New_Read_Balancer_in_Ceph_-_Laura_Flores_IBM/","excerpt":"","text":"会议纪要 会议主题： Ceph 新重平衡器介绍 主讲人： Laura Flores, IBM 的 RADOS 工程师 时间： [具体时间] 地点： [具体地点] 参会人员： [参会人员名单] 会议内容总结： 重平衡的重要性： 在分布式存储系统如 Ceph 中，平衡写入和读取请求对于优化性能至关重要。 平衡写入确保数据快速存储和复制，而读取则确保数据快速访问和检索。 现有平衡器的局限： 现有的容量平衡器（fmap 平衡器）主要处理写入请求，不处理读取请求。 新引入的读取平衡器（read balancer）专注于解决读取请求的不平衡问题。 容量平衡与读取平衡的区别： 容量平衡是功能性需求，确保 Ceph 正常运行。 读取平衡是性能需求，虽然不严格要求，但有助于系统整体性能提升。 读取平衡操作成本低，仅涉及元数据操作，不涉及数据移动。 新重平衡器的特点： 仅适用于复制池（replicated pools）。 假设所有设备同质（homogeneous），但未来版本将考虑异质系统（heterogeneous systems）。 新命令和工具： 引入新的 ceph osd pool ls detail 命令，显示读取平衡分数（read balance score）。 新增 ceph osd pg upmap primary 命令，用于重新分配 PG 的主 OSD。 演示和测试： 演示了在 v-start 集群上使用新工具进行读取平衡的过程。 提供了 GitHub 仓库链接，包含演示脚本和相关信息。 未来计划和改进： 计划将读取平衡器集成到 Ceph 的测试套件中。 考虑将读取平衡器作为默认平衡器模块的一部分。 未来版本将考虑设备大小和性能的异质性。 问答环节： 讨论了读取平衡器在不同版本 Ceph 中的适用性。 探讨了读取平衡器与自动缩放器（auto scaler）的潜在冲突。 讨论了网络延迟对读取平衡的影响。 决定事项： - 鼓励社区成员尝试新读取平衡器，并提供反馈。 - 计划将读取平衡器集成到 Ceph 的默认平衡器模块中。 后续行动计划： - 完善文档，详细说明新工具的使用方法和效果。 - 进行性能测试，验证读取平衡器对集群性能的实际影响。 - 持续改进读取平衡器，考虑设备异质性的处理。 联系方式： - Laura Flores 的邮箱：El Flores f-l-o-r-e-s@ibm.com 会议结束： - 感谢所有参与者的提问和讨论，会议圆满结束。 [会议纪要编写人：[你的名字]] [会议纪要审核人：[审核人名字]] [会议纪要日期：[编写日期]]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Multi Cluster Ceph at Scale - Vasyl Purchel, Workday","slug":"Multi_Cluster_Ceph_at_Scale_-_Vasyl_Purchel_Workday","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Multi_Cluster_Ceph_at_Scale_-_Vasyl_Purchel_Workday/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Multi_Cluster_Ceph_at_Scale_-_Vasyl_Purchel_Workday/","excerpt":"","text":"会议纪要 会议参与者 Vasil：Workday的高级软件工程师，隶属于存储平台团队，专注于OSF解决方案在其数据中心的应用。 公司背景 Workday：作为领先的云端企业解决方案提供商，专注于财务和人力资源领域，致力于确保客户满意度。 团队概况 团队规模：由五名工程师和一名Red Hat顾问组成。 项目管理：除了主要项目外，还维护和开发其他三个项目。 数据中心：管理五个数据中心，拥有23个集群，超过1200台服务器，近100PB的原始存储容量。 主要挑战与解决方案 数据存储与恢复： OpenStack镜像存储：确保镜像下载在两分钟内完成，以支持虚拟机快速部署。 MySQL备份：从NFS迁移到Ceph存储，使用日志设备，将备份时间从24小时缩短到7小时。 集群管理： 多集群策略：为每个环境设置独立集群，以便单独更新和管理，减少故障影响范围。 性能与存储分离：根据需求配置不同类型的集群，如性能集群和归档集群。 技术支持与监控： Red Hat商业支持：在遇到内核bug时提供关键帮助。 统一监控系统：将所有集群的指标和日志集中到一个系统中，便于性能比较和问题诊断。 技术细节 集群配置： 标准集群：初始配置为8台服务器，每台32TB，使用三副本策略。 高密度集群：配置为10台服务器，每台80-90TB，使用擦除编码技术，提供1.5倍的存储容量。 自动化与持续交付： 自动化需求：随着集群和服务器数量的增加，手动管理变得不可行，需要自动化工具。 持续交付流程：从OpenStack VM测试到生产环境的逐步验证，确保每个变更的安全性和有效性。 未来规划与挑战 升级与维护： Ceph版本升级：计划从Ceph 4升级到Ceph 5（Pacific），尽管Ceph 6已发布。 自动化与监控：继续加强自动化和监控工具，确保集群的稳定性和性能。 跨站点复制： 灾难恢复：探索Ceph自身的跨站点复制功能，减少用户的数据复制负担。 结论 Vasil强调了自动化、社区贡献和持续改进的重要性，同时提到了面临的挑战和未来的发展方向。 后续行动计划 继续推进Ceph版本的升级。 加强自动化和监控系统的建设。 探索和实施跨站点复制的解决方案。 会议结束 Vasil感谢大家的参与，并表示愿意回答任何问题。 [会议结束，掌声]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimizing CephFS with Combining MDS QoS Scheduling and Static-Dynamic Subtree Partitioning","slug":"Optimizing_CephFS_with_Combining_MDS_QoS_Scheduling_and_Static-Dynamic_Subtree_Partitioning","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Optimizing_CephFS_with_Combining_MDS_QoS_Scheduling_and_Static-Dynamic_Subtree_Partitioning/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Optimizing_CephFS_with_Combining_MDS_QoS_Scheduling_and_Static-Dynamic_Subtree_Partitioning/","excerpt":"","text":"会议纪要 会议概述 本次会议由Young主持，来自Lion公司的专业人员分享了他们在Ceph分布式存储系统上的工作进展和经验。会议主要讨论了Ceph文件系统（CFS）的调度、软件分区以及动态和静态子树分区策略。 主要议题 公司背景与Ceph应用介绍 Lion公司是一家提供消息和通信服务的公司，拥有超过1.5亿日活跃用户。 公司采用OpenStack和Kubernetes作为私有云基础设施，并使用Azure软件定义存储策略。 具体使用了RBD和rgw来提供块和对象存储接口，自2020年起成功采用CFS。 Ceph文件系统（CFS）的应用与挑战 介绍了CFS与OpenStack Manila的集成，用于处理OpenStack项目的共享卷。 面临的主要挑战包括AI和ML工程师存储大量数据（高达50亿条），以及如何有效管理这些数据。 集群管理与性能优化 描述了两个主要集群（A和B）的配置，每个集群有超过30个活动实例。 讨论了从裸金属服务器到虚拟机的转变，以及如何通过小规模虚拟机来优化MDS。 动态与静态子树分区策略 动态子树分区：能够动态调整元数据分布，但可能导致迁移开销和性能波动。 静态子树分区：通过预分配特定链接来减少元数据迁移，但可能导致工作负载分布不均。 结合动态与静态分区的新策略 提出了一种结合两种分区策略的新方法，旨在处理不同类型的工作负载，优化性能和减少迁移开销。 MDS QoS调度器 介绍了基于M Clock算法的QoS调度器，用于控制MDS的请求处理速度，确保稳定性和性能。 决定事项 确定了结合动态与静态分区策略的新架构，以优化CFS的性能和稳定性。 实施了MDS QoS调度器，以更好地管理MDS的请求处理和资源分配。 后续行动计划 继续测试和优化新的分区策略，确保其在多种工作负载下的有效性。 进一步开发和部署MDS QoS调度器，以应对复杂的应用场景和增加的需求。 持续与社区合作，分享经验并获取反馈，以不断改进Ceph的性能和功能。 结论 Lion公司通过结合动态与静态分区策略以及实施MDS QoS调度器，有效地优化了Ceph文件系统的性能和稳定性。未来将继续探索更多优化措施，并积极参与社区贡献。 提问环节 讨论了在多MDS环境下动态分区时的锁争用问题，以及如何通过外部子树分区器来减少元数据迁移。 探讨了MDS缓存大小的优化和MDS数量的最佳配置。 会议结束时，主持人感谢所有参与者的积极参与，并欢迎大家提供进一步的反馈和建议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimizing Ceph IO for High Throughput Particle Physics Workflows","slug":"Optimizing_Ceph_IO_for_High_Throughput_Particle_Physics_Workflows","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Optimizing_Ceph_IO_for_High_Throughput_Particle_Physics_Workflows/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Optimizing_Ceph_IO_for_High_Throughput_Particle_Physics_Workflows/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统在大型科学实验中的应用与优化 会议时间：[具体日期] 会议地点：[具体地点] 主讲人：Tom 参会人员：[参会人员名单] 会议内容总结： 主讲人介绍： Tom来自英国的科学与技术设施委员会（Science and Technologies Facilities Council, STFC），该组织运营大型科学资源，如粒子加速器、硬X射线源和脉冲激光等。 STFC旨在为学术界和商业用户提供免费的使用点访问，并参与UK Research and Innovation组织。 公司背景： STFC的科学计算部门支持大量数据密集型科学研究。 公司拥有近十万核心的OpenStack，用于构建科学分析工作流程，并在其后运行多种Ceph版本以支持这些工作流程。 Ceph集群Echo介绍： Echo是STFC运行的最大的Ceph集群，已投入生产超过五年，从10PB增长到64.65PB。 即将增加60PB的硬件，使其继续增长。 Echo主要为LHC实验提供磁盘存储，是英国对LHC的主要贡献。 LHC和未来计划： LHC目前处于第三次运行阶段，正在进行探测器和磁铁升级。 未来的高亮度LHC将显著增加碰撞记录和数据率。 为准备这一变化，STFC正在进行各种数据挑战，以确保基础设施的各个部分都已准备就绪。 Ceph集群Echo的优化： Echo使用XrootD作为数据传输框架，通过xrdCEPH和librados striper直接与Ceph集群交互。 发现小读取性能问题，并通过缓存和其他优化措施进行缓解。 最终通过优化xrdCEPH和librados striper，特别是移除锁定行为，显著提高了性能。 后续行动计划： 继续探索和利用librados的其他高级功能，如异步操作和原子操作，以进一步优化性能。 考虑在OSD级别实施校验和计算，以提高外部网关的效率。 决定事项： 确认了Ceph集群Echo的性能优化措施，并计划进一步探索librados的高级功能。 决定继续监控和优化LHC实验的数据处理流程，以应对未来高亮度LHC的挑战。 后续行动： 实施xrdCEPH和librados striper的优化版本，并监控其性能。 探索在OSD级别实施校验和计算的可能性。 继续参与LHC实验的数据挑战，确保基础设施的准备就绪。 感谢人员： 感谢Joe Fish, Alexander, James等人在开发和实施优化措施中的关键贡献。 会议结束： 会议在感谢和掌声中结束，准备进入下一个议程。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Over a Billion Requests Served per Day: Ensuring Everyone Is Happy with Our Ceph Clusters’...","slug":"Over_a_Billion_Requests_Served_per_Day_-_Ensuring_Everyone_Is_Happy_with_Our_Ceph_Clusters_...","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Over_a_Billion_Requests_Served_per_Day_-_Ensuring_Everyone_Is_Happy_with_Our_Ceph_Clusters_.../","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Over_a_Billion_Requests_Served_per_Day_-_Ensuring_Everyone_Is_Happy_with_Our_Ceph_Clusters_.../","excerpt":"","text":"会议纪要 会议主题： Bloomberg软件定义分布式QRS系统的介绍与实施细节 会议时间： [具体时间] 会议地点： [具体地点] 参会人员： Nathan, Alex, 以及其他相关技术和业务人员 会议内容： 介绍与背景 Nathan介绍了Bloomberg作为一家金融技术公司，成立于1981年，主要产品为Bloomberg终端，服务于全球数十万用户，每日处理数百亿条数据。 Bloomberg的存储工程团队负责设计和维护所有存储解决方案，包括基于设备和软件定义的存储。 分布式存储团队专注于软件定义存储，主要产品包括通过OpenStack管理的块存储（BCC）和对象存储（BCS），均由Ceph支持。 系统概述 系统目标是确保Bloomberg的存储集群性能满足用户需求，特别是在S3网关上实施QoS平台。 系统设计考虑了多站点设置，采用主动-被动配置，用户与主动集群交互，流量被复制到被动集群。 用户期望与系统目标 用户期望系统提供与Amazon S3类似的体验，包括高可用性、灵活的客户端SDK选择、可接受的带宽和延迟。 系统目标包括提供一致的性能体验、管理整体集群性能、以及提供集群活动的可见性。 QoS设计与实施 QoS系统设计考虑了层7（HTTP层）的操作，支持基于访问密钥和桶级别的流量控制。 实施细节包括使用HAProxy和Redis进行流量解析和聚合，自定义的syslog服务器和策略生成器用于实时监控和限制违规行为。 系统还包括节点级别的QoS，以防止单个节点过载。 挑战与未来计划 面临的挑战包括实时监控集群、理解系统行为、以及分布式系统间的通信问题。 未来计划包括扩展系统的维度、动态调整配额、优先级管理、连接限制以及开源贡献。 决定事项： - 确认了QoS系统的设计和实施细节，以及未来的发展方向。 后续行动计划： - 继续开发和优化QoS系统，包括扩展功能和提高动态性。 - 探索更智能的请求成本分配方法。 - 考虑将系统开源，并寻求社区反馈以改进系统。 会议结束： - 会议在提问环节后结束，Nathan和Alex感谢大家的参与并鼓励大家提供反馈。 备注： - 会议中提到的技术术语和产品名称，如Ceph、HAProxy、Redis等，保留原文以确保准确性。 [会议记录结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rook: Enabling Read Affinity for RBD Workloads - Rakshith R, IBM","slug":"Rook_-_Enabling_Read_Affinity_for_RBD_Workloads_-_Rakshith_R_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Rook_-_Enabling_Read_Affinity_for_RBD_Workloads_-_Rakshith_R_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Rook_-_Enabling_Read_Affinity_for_RBD_Workloads_-_Rakshith_R_IBM/","excerpt":"","text":"会议纪要 会议主题： 启用RBD工作负载的读取亲和性（Read Affinity） 参会人员： Rakshit（曾在Red Hat工作，现就职于IBM） 会议议程： CRUSH算法和CRUSH Maps简介 OSD拓扑结构 OSD拓扑与CRUSH位置的相互关系 客户端读取流程 读取亲和性的优缺点 如何在内部和外部集群中启用读取亲和性 讨论内容： CRUSH算法：CRUSH算法是Ceph的核心，用于确定数据存储的位置。客户端写入数据时，对象ID通过CRUSH算法映射到PG（Placement Group），再映射到一组OSD，其中一个为主OSD。 OSD拓扑结构：Rook利用Kubernetes的节点标签来实现OSD的拓扑分布，确保数据在不同故障域中的复制。 客户端读取流程：默认情况下，客户端读取数据从主OSD进行。为了提高读取速度，可以通过CSI（Container Storage Interface）将客户端位置信息传递给CRUSH算法，从而允许客户端从最近的次级OSD读取数据。 读取亲和性的优缺点： 优点：显著提高读取速度，降低延迟，减少跨区域流量，特别适用于云环境。 缺点：可能导致多个OSD同时服务于同一数据的读取，增加CPU和内存使用。 决定事项： 启用读取亲和性：在Rook部署的内部集群中，通过设置CSI配置项启用读取亲和性。对于外部集群，需要确保节点标签与外部集群的CRUSH Maps匹配。 后续行动计划： 内部集群：在配置文件中设置CSI_ENABLE_READ_AFFINITY为true，并重启已运行的RBD Pods。 外部集群：确保节点标签与外部集群的CRUSH Maps匹配，并执行相同的配置更改。 参考资料： Rook GitHub链接 Ceph CSI驱动链接 会议结束： 会议在讨论和解答疑问后结束，无其他待办事项。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rook: Why Would You Ever Deploy Ceph Inside Kubernetes? - Travis Nielsen, IBM","slug":"Rook_-_Why_Would_You_Ever_Deploy_Ceph_Inside_Kubernetes_-_Travis_Nielsen_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Rook_-_Why_Would_You_Ever_Deploy_Ceph_Inside_Kubernetes_-_Travis_Nielsen_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Rook_-_Why_Would_You_Ever_Deploy_Ceph_Inside_Kubernetes_-_Travis_Nielsen_IBM/","excerpt":"","text":"会议纪要 会议概述 会议由Travis Nielsen主持，他作为Ceph项目的主要维护者和IBM存储团队的一员，分享了关于在Kubernetes环境中部署Ceph的重要性和方法。Travis强调了Ceph在Kubernetes中的部署优势，并介绍了Rook作为管理层的角色。 讨论的主要议题 Kubernetes与存储的需求： Kubernetes本身并非为存储设计，但部署应用时需要存储支持。 传统上，存储通常是外部的，但在私有数据中心中使用云提供商存储存在限制。 Ceph在Kubernetes中的部署： Ceph提供了企业级的存储解决方案，包括三种类型的存储。 Rook作为管理层，专门用于在Kubernetes中部署和管理Ceph。 Rook的功能与优势： Rook使用Operator模式，通过自定义资源定义（CRDs）来实现Ceph的自动化部署和管理。 Rook自2018年12月宣布稳定，并已在多个生产环境中得到验证。 生产环境中的应用案例： Dimitri Mission的案例展示了Rook和Ceph在多个大学系统中的成功应用，管理着数百个节点和多PB级的数据。 Rook的社区与支持： Rook是CNCF毕业项目，拥有近11,000个GitHub星标和2.8亿次Docker Hub下载。 项目遵循社区优先的哲学，定期发布更新，并与Kubernetes的发布周期同步。 决定的事项 Rook和Ceph的结合为Kubernetes提供了强大的存储解决方案，特别适合需要高可配置性和灵活性的企业环境。 社区将继续支持和发展Rook项目，鼓励更多的用户和贡献者参与。 后续行动计划 继续推动Rook和Ceph的集成，优化在Kubernetes中的部署和管理。 加强社区建设，通过Slack、GitHub等平台收集用户反馈，持续改进项目。 在即将到来的KubeCon活动中，将会有更多关于Rook和Ceph的讨论和展示。 其他信息 Travis Nielsen将在KubeCon上有进一步的分享，并欢迎社区成员参与讨论和交流。 结束语 感谢Travis Nielsen的精彩分享，期待社区成员的积极参与和反馈，共同推动Rook和Ceph项目的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Scrubs Scheduling in Reef and Beyond - Ronen Friedman, IBM","slug":"Scrubs_Scheduling_in_Reef_and_Beyond_-_Ronen_Friedman_IBM","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Scrubs_Scheduling_in_Reef_and_Beyond_-_Ronen_Friedman_IBM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Scrubs_Scheduling_in_Reef_and_Beyond_-_Ronen_Friedman_IBM/","excerpt":"","text":"会议纪要 会议基本信息 主讲人: London Friedman 时间: 会议持续约40分钟 主题: Ceph 存储系统中的 scrub 代码维护和改进 会议内容总结 Scrub 代码维护: London Friedman 过去三年一直在维护 Ceph 中的 scrub 代码。 除了他之外，还有其他贡献者，如 Sam 和其他几位人员。 改进成果: 在过去的几年中，他们对 scrubbing 过程进行了一些改进，这些改进在新的代码版本中可见。 例如，改进了 scrub 状态的更新，确保每几秒钟发送一次更新，使用 PG dump 或 query 命令可以获得更新的 scrub 信息。 重要变更: Chunk Size: 调整了 scrub 的 chunk size，以优化 deep scrub 和 shallow scrub 的性能。 M clock Scheduler: 新的调度器使得在执行 scrub 时对客户端 IO 的影响更小，增加了集群管理的灵活性。 未来计划: 继续增加对系统中 timeout 和慢响应部分的自检、警告和可能的修复功能。 设计新的 scrub 调度器，以解决现有系统中的一些问题，如代码维护的复杂性和调度效率。 新调度器设计: 引入新的 scrub 目标（Target）概念，每个 PG 将维护 shallow 和 deep scrub 的独立目标。 使用 urgency 参数来决定 scrub 的优先级，取代旧的基于 flags 的系统。 引入“not before”机制，以避免对暂时无法 scrub 的 PG 进行重复检查。 性能和维护: 讨论了 scrub 代码的性能优化和维护问题，强调了代码的清晰性和可维护性的重要性。 后续行动计划 继续开发和测试新的 scrub 调度器。 监控和调整 scrub 相关的配置参数，特别是与 chunk size 和调度器相关的参数。 收集用户反馈，以进一步优化 scrub 过程的性能和可靠性。 结论 本次会议详细讨论了 Ceph 存储系统中 scrub 代码的维护和改进工作，展示了过去几年的成果，并提出了未来的改进方向和计划。通过引入新的调度器和优化参数设置，目标是提高 scrub 过程的效率和系统的整体性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Sponsored Lightning Talk: Advancing Infrastructure with Ceph Technology","slug":"Sponsored_Lightning_Talk_-_Advancing_Infrastructure_with_Ceph_Technology","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Sponsored_Lightning_Talk_-_Advancing_Infrastructure_with_Ceph_Technology/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Sponsored_Lightning_Talk_-_Advancing_Infrastructure_with_Ceph_Technology/","excerpt":"","text":"会议纪要 会议主题：Ceph技术的发展与Cliso公司的战略 会议时间：[具体时间] 会议地点：[具体地点] 主讲人：Dan 会议内容总结： Ceph技术的优势与挑战 优势：Ceph因其无限灵活性、高可扩展性和最优的总拥有成本（TCO）而备受青睐。它支持块、对象和文件存储，并能处理容器，适用于多种云环境（如公有云、私有云和多云）。 挑战：尽管Ceph功能强大，但其使用复杂性仍然是一个问题。目前，大部分改进集中在简化安装过程，而日常操作（day two operations）的简化更为重要。 Cliso公司的介绍与战略 公司背景：Cliso成立于2010年，专注于为不同用户提供定制解决方案，包括公有云、私有云、多云环境以及容器化和Kubernetes栈。 战略方向： 支持与服务：提供两种类型的支持——低成本的基本支持和面向关键业务的企业支持。同时，提供咨询和开发服务，如性能调试和可扩展架构设计。 产品开发：计划推出Cliso Enterprise Storage，这是一个高度优化的Ceph版本，包含自定义的MGR模块和AI Ops类型的辅助工具（codename Klyso Co-pilot），以简化配置和操作。 未来计划与行动 产品发布：Cliso将推出一个经过精心筛选的Ceph版本，以避免使用上游版本可能带来的问题。 市场扩展：公司正在扩展到北美市场，并继续支持开源社区，成为Ceph基金会的主要成员。 社区参与：计划在德国举办活动，并参与组织即将在温哥华举行的Ceph数据会议。 问答环节 Ceph版本选择：建议等待新版本发布至少一个月后再进行升级，以确保稳定性。Quincy版本目前看来较为稳定，但建议等待更成熟的版本。 社区反馈：主讲人欢迎社区反馈，特别是关于Ceph仪表板的改进建议。 后续行动计划： 产品开发：继续推进Cliso Enterprise Storage的开发，并确保其包含必要的功能和优化。 市场推广：加强在北美市场的推广活动，并继续参与和支持开源社区。 社区互动：通过ces.clisal.com平台与社区保持沟通，收集反馈并提供支持。 联系方式： 邮箱：[具体邮箱] 网站：[具体网站] 会议结束： 感谢参与者的提问和反馈，会议在掌声中结束。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Sponsored Lightning Talk: The Enterprise Ceph Spectrum - Philip Williams, Canonical","slug":"Sponsored_Lightning_Talk_-_The_Enterprise_Ceph_Spectrum_-_Philip_Williams_Canonical","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Sponsored_Lightning_Talk_-_The_Enterprise_Ceph_Spectrum_-_Philip_Williams_Canonical/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Sponsored_Lightning_Talk_-_The_Enterprise_Ceph_Spectrum_-_Philip_Williams_Canonical/","excerpt":"","text":"会议纪要 会议主题： Ceph 在不同规模环境中的应用与部署策略 主讲人： Phil Williams，Canonical 公司 会议内容总结： Ceph 应用的多样性： Phil Williams 介绍了 Ceph 在不同规模环境中的应用，从大型数据中心到单个开发者的工作站，涵盖了从数十到数百 PB 的大型基础设施到小型零售店或分销中心的后端存储需求。 强调了 Canonical 在 Ceph 领域的持续努力和创新，尽管在社区中可能不是非常显眼。 Canonical 的 Ceph 部署工具： 介绍了 Canonical 的 Ceph 部署工具，包括使用 Juju 和 charms 进行大规模数据中心自动配置。 推出了基于 OCI 镜像的 Rocks，这些镜像完全合规，可以直接在容器化环境中使用，以快速部署和更新 Ceph 集群。 微型云和小型部署： 讨论了微型云（MicroCloud）的概念，这些小型环境使用 snap-based 技术，简单、快速且易于重复部署。 这种技术也可以缩小到单个笔记本电脑或开发者工作站上使用。 Ceph 的多场景应用： 描述了 Ceph 在不同规模环境中的应用，从大型数据中心到小型零售店的后端存储，以及在零售和分销中心的实际应用案例。 强调了 Ceph 的灵活性和可扩展性，能够快速适应不同规模和需求的环境。 Ubuntu 和 Ceph 的全球影响力： 强调了 Ubuntu 在全球范围内的广泛应用，并致力于将 Ceph 也推广到全球各个角落，从最小的环境到最大的基础设施。 后续活动和讨论： Phil Williams 提到了团队在本周的一系列技术讲座和演示，包括关于 eBPF 和在公共云中部署 Ceph 以节省成本的详细讨论。 邀请与会者参观展位，了解更多关于 Ceph 部署的工具和方法。 后续行动计划： - 继续推广和优化 Ceph 在不同规模环境中的应用。 - 加强与社区的互动，提高 Canonical 在 Ceph 社区中的可见度和影响力。 - 持续更新和改进部署工具，以适应快速变化的技术环境和用户需求。 会议结束： - Phil Williams 在会议结束时询问是否有任何问题，并鼓励与会者参与后续的技术讲座和演示。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Stretch Clusters in Ceph: Algorithms, Use Cases, and Improvements","slug":"Stretch_Clusters_in_Ceph_-_Algorithms_Use_Cases_and_Improvements","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Stretch_Clusters_in_Ceph_-_Algorithms_Use_Cases_and_Improvements/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Stretch_Clusters_in_Ceph_-_Algorithms_Use_Cases_and_Improvements/","excerpt":"","text":"会议纪要 会议主题：Ceph中对扩展集群（Stretch Clusters）的明确支持 会议时间：会议开始于整点后6分钟 会议参与者：Greg（Ceph资深开发者，现为IBM工程经理） 会议内容总结： Greg的背景介绍： Greg自大学毕业后加入Sage，多年来一直从事Ceph的开发工作。 他曾作为技术负责人和独立贡献者参与了多个Ceph特性，如缓存分层和新的扩展模式。 目前，Greg已从软件开发转型为工程管理，服务于Red Hat和IBM的Ceph团队。 Ceph基本组件介绍： 主要涉及监控器（monitors）和对象存储守护进程（OSDs），这些是今天讨论的重点。 扩展集群（Stretch Clusters）概述： 扩展集群是指服务器在地理上分散部署的集群。 用户通常在两个或三个站点之间运行扩展集群，面临网络分裂和数据中心故障的高风险。 面临的问题： 网络分裂可能导致监控器选举循环。 两站点扩展集群中，如果一个站点的OSD下线，另一个站点无法提供服务，因为数据被认为过时。 解决方案： 引入新的选举算法，监控器之间互相ping并维护连接分数，选择最可靠的监控器作为领导者。 扩展对等和恢复机制，确保在数据中心故障时，集群仍能正常运行。 具体实施： 监控器在每个站点部署两个，限制OSD只与同数据中心的监控器通信。 扩展对等算法，要求在多个数据中心中至少有一个OSD处于活动状态。 测试和挑战： 单元测试证明选举逻辑无问题，但未覆盖的部分如OSD对等和监控器ID映射存在问题。 需要更多的自动化测试来确保系统的稳定性和可靠性。 未来工作： 支持三站点扩展集群和更好的用户体验。 考虑支持纠删码（Erasure Coding）和更复杂的Crush规则。 用户操作： 用户需要设置监控器位置和自定义Crush规则，然后启用扩展模式。 后续行动计划： 继续完善和扩展扩展集群的功能，特别是支持更多的数据中心和纠删码。 增强自动化测试，确保系统的稳定性和可靠性。 改进用户体验，简化配置和管理流程。 会议结束： 会议在提问环节后结束，Greg感谢大家的参与并鼓励大家继续关注Ceph的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Troubleshooting a Cephadm Deployment - Michel Raabe, B1 Systems GmbH","slug":"Troubleshooting_a_Cephadm_Deployment_-_Michel_Raabe_B1_Systems_GmbH","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Troubleshooting_a_Cephadm_Deployment_-_Michel_Raabe_B1_Systems_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Troubleshooting_a_Cephadm_Deployment_-_Michel_Raabe_B1_Systems_GmbH/","excerpt":"","text":"会议纪要 会议主题：Ceph部署与故障排除 会议时间：[具体日期] 会议地点：[具体地点] 主讲人：Michael Michelle 主讲人简介： 职位：云解决方案架构师 公司：B1 Systems（德国公司，位于Ingelstadt，拥有140名员工） 业务范围：提供咨询、培训和支持服务，涉及多个开源产品，如Ceph和OpenStack 会议内容总结： Ceph部署概述 Ceph Idiom是一个自动化部署工具，相比传统手动部署有显著改进。 最新版本的Ceph Idiom支持更多功能，如部署Ceph集群和NFS。 讨论了容器化安装的优缺点，但本次会议主要关注如何从集群中获取日志文件和监控部署。 故障排除挑战 Ceph Idiom的部署过程自动化程度高，但缺乏详细的默认输出，使得故障排除变得困难。 提到了一些用户在遇到无法解决的错误时，选择丢弃整个集群并重新部署的极端做法。 日志和监控方法 介绍了多种从Ceph集群中收集数据的方法，包括使用Ceph工具、Ceph ADM工具和日志文件。 强调了设置适当的日志级别的重要性，建议至少设置为5以获取更多详细信息。 工具和技巧 推荐使用Snoopy和Audit工具来监控和记录命令执行情况，特别是在非交互式shell中。 讨论了如何通过手动拉取和启动容器来验证问题，并检查日志文件。 最佳实践和建议 强调了正确配置Python、容器、网络和DNS的重要性。 建议避免使用Ansible与Ceph ADM冲突，坚持使用Ceph ADM以避免问题。 提到了一个客户从Ceph Storage版本4升级到5的案例，强调了自动化和手动配置的平衡。 决定事项： 确认了Ceph Idiom在自动化部署方面的优势和挑战。 确定了多种故障排除和监控的方法，特别是使用Snoopy和Audit工具。 后续行动计划： 继续优化Ceph Idiom的日志输出和监控功能。 探索更多自动化和手动配置的平衡方法，以提高部署和故障排除的效率。 会议结束语： 主讲人感谢大家的参与，并鼓励大家继续探索和优化Ceph部署和故障排除的方法。 会议反馈： 与会者对Ceph Idiom的讨论表示赞赏，并期待未来更多的优化和改进。 [会议结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Using EBPF to Develop a Powerful Tool for Diagnosing Ceph Performance Issues","slug":"Using_EBPF_to_Develop_a_Powerful_Tool_for_Diagnosing_Ceph_Performance_Issues","date":"2023-05-04T16:00:00.000Z","updated":"2023-05-04T16:00:00.000Z","comments":true,"path":"2023/05/05/Using_EBPF_to_Develop_a_Powerful_Tool_for_Diagnosing_Ceph_Performance_Issues/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/05/Using_EBPF_to_Develop_a_Powerful_Tool_for_Diagnosing_Ceph_Performance_Issues/","excerpt":"","text":"会议纪要 会议主题： 使用 eBPF 开发强大的性能诊断工具 主讲人： 来自 Canonical 的软件工程师 会议内容概述： OSD 操作生命周期介绍 OSD 操作生命周期主要分为三个层次：messenger 层、OSD 层和 Blue Store 层。 每个层次的操作包括接收、处理和提交数据，涉及网络性能、队列管理和磁盘操作。 现有性能分析方法及其局限性 介绍了 perf 工具、调试日志、管理命令和静态追踪（如 lttng 和 blocking）等方法。 指出了这些方法在详细延迟分析、日志处理和跨层次追踪方面的局限性。 eBPF 和 u-plop 技术的介绍 eBPF 是一种内核技术，允许在不修改内核代码或加载额外模块的情况下，将自定义程序添加到内核中。 u-plop 是一种允许动态追踪用户空间代码的机制，通过注入追踪点来实现。 工具演示 演示了如何使用 eBPF 和 u-plop 技术开发的工具来追踪和分析 OSD 操作的详细延迟。 展示了工具在实际集群中的应用，包括网络性能问题和磁盘操作延迟的诊断。 未来工作 讨论了工具的潜在改进，如检测 OSD 后台任务和扩展到更多 Ceph 组件的追踪。 决定事项： - 主讲人计划将开发的工具开源，以便社区使用和进一步开发。 后续行动计划： - 主讲人将整理代码并尽快发布到开源社区。 - 继续优化工具，特别是减少性能开销和扩展功能，以支持更广泛的应用场景。 会议结束： - 会议以问答环节结束，主讲人回答了关于工具性能、开源计划和潜在应用的问题。 备注： - 主讲人强调了 eBPF 和 u-plop 技术在动态追踪和性能分析中的强大能力，但也指出了在实际部署中需要考虑的性能开销问题。 会议反馈： - 与会者对工具的潜力表示了兴趣，并提出了关于工具在大规模集群中应用的性能问题。 会议总结： - 本次会议详细介绍了如何利用 eBPF 和 u-plop 技术开发高性能诊断工具，以帮助 Ceph 存储系统的性能优化和问题诊断。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-04-26","slug":"Ceph_Crimson_SeaStore_Meeting_2023-04-26","date":"2023-05-02T16:00:00.000Z","updated":"2023-05-02T16:00:00.000Z","comments":true,"path":"2023/05/03/Ceph_Crimson_SeaStore_Meeting_2023-04-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/03/Ceph_Crimson_SeaStore_Meeting_2023-04-26/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： Rocky, Isaiah, June, Phil 会议议题： 1. 项目进展汇报 2. 技术问题讨论 3. 后续行动计划 会议内容： 自我介绍： June 加入了 Hari 团队，并参与了 GitHub 命令的相关工作。 项目进展： Rocky 在 Cephalocon 后主要跟进代码审查工作。 Engine 汇报了 mod core system 和 connection reference 的变更，感谢 Sam 的贡献。已审查并合并了 circular Journal space for random block manager，以及 mod core messenger 的多核 socket 接受和连接功能。单元测试已完成，当前挑战是确保内存分配正确。 Engine 还提到了 OSD 操作消息缓冲列表的跨云约束可能未正确执行，但未触发任何故障。 Engine 将跳过下一次会议，因为即将放假。 技术讨论： 讨论了 buffer lists 使用 Atomic reference Counting 的问题，认为虽然可能存在性能问题，但只要不频繁操作引用计数，可能不需要立即修复。建议进行性能分析。 讨论了 c-star allocator 的工作原理，指出在释放其他核心分配的内存时需要发送消息回其他核心，但确实有效。 讨论了 PR 中的 lva point 修改，建议在测试通过后尽快合并，以避免重构困难。 讨论了 debug 构建中的 get connection pipeline 问题，认为 debug 模式下的行为是正确的，应修复。 讨论了 SMP 设置为三的测试结果，建议通过 debug 输出检查核心运行情况。 后续行动计划： - 继续进行性能分析和代码审查。 - 修复 debug 构建中的 get connection pipeline 问题。 - 确保 PR 的测试通过后尽快合并。 - 通过 debug 输出检查 SMP 设置的正确性。 会议结束： - 会议在确认无其他议题后结束，祝大家下周工作顺利。 备注： - 保留了部分计算机科学/ceph 相关领域英文原文的关键词，如 Cephalocon, mod core system, connection reference, Atomic reference Counting 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2023-05-02","slug":"Ceph_Orchestrator_2023-05-02","date":"2023-05-02T16:00:00.000Z","updated":"2023-05-02T16:00:00.000Z","comments":true,"path":"2023/05/03/Ceph_Orchestrator_2023-05-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/03/Ceph_Orchestrator_2023-05-02/","excerpt":"","text":"会议纪要 会议主题： IPv6 相关问题讨论 开发基于包的 Ceph 管理工具（Cephadm）的可能性 关键细节： IPv6 问题： 讨论了 IPv6 地址绑定的问题，特别是由于 IPv6 地址需要额外的字段（如 flow info 和 scope ID）导致的绑定失败。 提出了需要进一步研究如何处理这些额外字段，特别是 scope ID 的确定方法。 决定将此议题留待后续讨论，以便有更多时间进行深入研究。 基于包的 Cephadm 开发： 讨论了开发一个基于包的管理工具（如 RPM 或 Deb 包）的可能性，以满足那些不希望使用容器化 Ceph 的用户需求。 分析了现有 Cephadm 代码库的结构，指出大部分工作将集中在底层功能的实现上，如包的安装、守护进程的部署和设备检测。 提出了可能的开发路径，包括重用现有代码、创建新的管理模块，以及如何处理与现有容器化 Cephadm 的兼容性问题。 讨论了可能的技术挑战，如安全更新和调试工具的集成。 决定事项： 将 IPv6 绑定问题的深入讨论推迟到下一次会议。 对于基于包的 Cephadm 开发，决定由感兴趣的团队成员进行初步的概念验证工作，并计划在未来几周内进行更详细的讨论和规划。 后续行动计划： 对 IPv6 绑定问题进行更多的研究和测试，以确定最佳的解决方案。 开发基于包的 Cephadm 的初步原型，重点关注底层功能的实现。 安排下一次会议，以讨论基于包的 Cephadm 开发的进展和遇到的任何问题。 其他讨论点： 讨论了容器化 Ceph 的安全性和用户对容器技术的担忧，提出了改进容器工具和文档的建议。 提到了现有 Cephadm 代码库的 refactoring 计划，以及如何与新的开发工作协调。 参会人员： Dan VanderSark Kathy 其他相关开发人员 会议结束： 会议在讨论了所有议题后结束，参会人员对未来的开发工作表示了积极的期待。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-04-26","slug":"Ceph_RGW_Refactoring_Meeting_2023-04-26","date":"2023-05-02T16:00:00.000Z","updated":"2023-05-03T16:00:00.000Z","comments":true,"path":"2023/05/03/Ceph_RGW_Refactoring_Meeting_2023-04-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/03/Ceph_RGW_Refactoring_Meeting_2023-04-26/","excerpt":"","text":"会议纪要 会议主题：多站点删除竞赛问题讨论 会议时间：[具体时间] 参会人员：[具体人员名单] 会议内容： 问题描述： 讨论了多站点环境中的删除竞赛问题，具体表现为在源区域删除对象后，对象被重新创建，导致对象在删除后仍然存在。 该问题已被追踪并更新，主要涉及桶完全同步时的本地Tombstone缓存不可靠问题。 问题根源： 问题根源在于桶完全同步时，本地Tombstone缓存不足以防止对象被重新创建。 开发者已开始进行概念验证，但目前不在会议中。 解决方案讨论： 提出了两种解决方案，但都涉及到需要无限期记住所有对象的问题。 Yehuda建议在特定时间窗口内记住对象，以避免删除竞赛。 讨论了全同步路径中缺乏跟踪信息的问题，建议在桶列表API中包含跟踪信息以解决问题。 后续行动计划： 需要进一步探索解决方案，避免无限期记住所有对象。 会议建议在追踪器中编写设计提案，并由相关人员跟进。 相关PR需要重新测试并分享结果。 其他议题： 讨论了cephalicon会议中的公平性问题，计划在当前问题解决后继续处理。 讨论了数据日志修复的测试结果，发现某些RGW实例的锁未释放问题。 决定事项： 需要编写设计提案并跟进解决方案。 相关PR需要重新测试并分享结果。 后续行动： 编写设计提案并跟进解决方案。 重新测试相关PR并分享结果。 继续处理数据日志修复问题。 会议结束： 感谢所有参与者的贡献，期待下次会议继续讨论。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-05-03","slug":"Ceph_RGW_Refactoring_Meeting_2023-05-03","date":"2023-05-02T16:00:00.000Z","updated":"2023-05-03T16:00:00.000Z","comments":true,"path":"2023/05/03/Ceph_RGW_Refactoring_Meeting_2023-05-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/05/03/Ceph_RGW_Refactoring_Meeting_2023-05-03/","excerpt":"","text":"会议纪要 会议主题：Ceph配置变量重启需求文档化及多站点项目协调 会议时间：[具体日期] 参会人员：Ali, Matt, Casey, Shilpa, Bloomberg团队成员等 主要议题： 配置变量重启需求文档化 Ali介绍了为Red Hat文档团队准备的配置变量重启需求文档化工作。 通过一个电子表格，Ali标记了哪些配置变量需要重启，哪些可以在运行时更改。 讨论了是否应该推荐所有配置变量更改后都需要重启，但多数意见倾向于不采取这种一刀切的做法。 提出了对某些特别重要的配置变量进行优先级排序，以便未来支持运行时更改。 多站点项目协调 Matt提出了关于多站点项目的潜在影响及如何在上游进行协调的问题。 建议使用追踪器问题（tracker issues）来管理这些项目。 讨论了是否需要为多站点项目设立专门的会议或使用现有会议进行讨论。 Bloomberg团队表示愿意参与多站点项目的开发和测试工作，特别是数据同步公平性问题。 决定事项： Ali将分享其完成的配置变量重启需求文档，并邀请团队成员进行审查和提供反馈。 将创建一个包含多站点标签的定制查询，以便更方便地管理和查看相关问题。 Bloomberg团队将参与多站点项目的测试和开发，特别是数据同步公平性问题的测试。 后续行动计划： Ali将发送配置变量重启需求的电子表格给团队成员进行审查。 将创建多站点项目的追踪器问题，并进行标签分类以便管理。 Bloomberg团队将与Shilpa合作，对多站点项目的功能测试进行改进。 将定期在会议上讨论多站点项目的进展和挑战。 其他讨论点： 讨论了功能测试的改进，特别是多站点同步性能问题的识别和解决。 提到了小型单元测试的重要性，以便更好地隔离和测试系统的各个部分。 会议结束： 会议在讨论了所有议题和行动计划后顺利结束，感谢所有参与者的贡献。 注意： 本会议纪要保留了部分计算机科学/Ceph相关领域的英文原文关键词，以确保专业术语的准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStar-OSD 2023-04-12 Meeting","slug":"Ceph_Crimson_SeaStar-OSD_2023-04-12_Meeting","date":"2023-04-11T16:00:00.000Z","updated":"2023-04-11T16:00:00.000Z","comments":true,"path":"2023/04/12/Ceph_Crimson_SeaStar-OSD_2023-04-12_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/04/12/Ceph_Crimson_SeaStar-OSD_2023-04-12_Meeting/","excerpt":"","text":"会议纪要 参会人员 未提及具体姓名，但涉及Ceph开发和质量保证（QE）团队成员。 主要议题 Crimson项目进展 某成员未在Crimson项目上做太多工作，主要关注Classic Q Quality Service，计划将这部分工作移植到Crimson。 讨论了LBA优化和parent-child link优化，提出了后续改进的可能性。 RBD测试结果 QE团队在最近的RBD测试中发现了五个失败案例，其中两个被确认为误报。 需要进一步讨论和调查其余的失败案例，并可能提出新的bug报告。 系统调试与更新 更新了医疗系统，并在垂直OST上进行调试，特别是单个和多个OSD的调试。 会议安排 下一周的会议将照常进行，之后可能会切换到新的会议软件。 决定事项 确认了Classic Q Quality Service的工作将移植到Crimson。 对RBD测试中的失败案例进行了初步分析，并计划进一步讨论和调查。 确认了下一周的会议将继续使用当前的会议软件。 后续行动计划 继续进行LBA优化和parent-child link优化的工作。 QE团队将调查RBD测试中的失败案例，并根据讨论结果决定是否提出新的bug报告。 调试和更新医疗系统，确保其稳定运行。 准备切换到新的会议软件，并提前通知参会人员。 备注 会议中提到了一些技术细节，如LBA优化、parent-child link优化等，这些是Ceph存储系统中的关键技术点。 会议还涉及了RBD（RADOS Block Device）的测试，这是Ceph提供的一种块存储服务。 会议结束 会议在确认了后续行动计划和会议安排后结束。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer  Monthly 2023-04-05","slug":"Ceph_Developer_Monthly_2023-04-05","date":"2023-04-06T16:00:00.000Z","updated":"2023-04-07T16:00:00.000Z","comments":true,"path":"2023/04/07/Ceph_Developer_Monthly_2023-04-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/04/07/Ceph_Developer_Monthly_2023-04-05/","excerpt":"","text":"会议纪要 会议主题： 开发者月度会议 - 友好版 日期： 2023年4月5日 主持人： Radic 出席人员： Kevin, Laura, 以及其他开发者和社区成员 主要议题 介绍 openEuler 到 Upstream Kevin 分享了关于将 openEuler 操作系统引入 Upstream 的想法。 openEuler 是一个开源操作系统，诞生于三年前，现已成为中国最大的开源操作系统社区。 openEuler 社区内有一个 SDS SIG（存储特别兴趣小组），致力于开发和维护存储相关功能。 讨论了如何确保 openEuler 的 LGS 支持能够在 Upstream 中运行，并提交了相关页面到 Upstream。 技术讨论 讨论了在 Upstream 中支持新操作系统的技术细节，包括构建规范、自动化测试、资源需求等。 提到了 openEuler 的存储 SIG 已经有一些自动构建，但需要更多的硬件资源来执行构建。 讨论了如何将 openEuler 的构建集成到 Upstream 的 CI 系统中。 PR（Pull Request）讨论 讨论了提交到 Upstream 的 PR，特别是关于 openEuler 的 spec 文件更改。 确认了 spec 文件在 main 分支上已知可以工作，建议先贡献到 main 分支，然后再回溯到特定分支。 讨论了如何确保 Centos 和 RHEL 的包仍然可以构建。 反馈和后续行动 讨论了从 Upstream 和 openEuler 社区获得的反馈，以及如何继续贡献支持。 确认了 openEuler 社区可以提供硬件资源来帮助 Upstream 设置自动化作业。 讨论了如何在 7.io 网站上提及 openEuler 的存储 SIG 仓库。 其他议题 讨论了在 Reef 版本中切换某些组件从使用旧的未标记计数器到新的标记计数器的问题。 讨论了 perf 计数器是否应被视为公共 API 的一部分，以及如何在社区中形成共识。 决定事项 确认了 openEuler 的 spec 文件在 main 分支上已知可以工作，建议先贡献到 main 分支，然后再回溯到特定分支。 确认了 openEuler 社区可以提供硬件资源来帮助 Upstream 设置自动化作业。 讨论了如何在社区中形成关于 perf 计数器是否应被视为公共 API 的共识。 后续行动计划 继续贡献支持 openEuler 在 Upstream 中的运行。 提供硬件资源帮助 Upstream 设置自动化作业。 在社区中讨论并形成关于 perf 计数器是否应被视为公共 API 的共识。 在 7.io 网站上提及 openEuler 的存储 SIG 仓库。 会议结束： 感谢所有参与者的讨论，期待下个月的会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-04-05","slug":"Ceph_Crimson_SeaStore_Meeting_2023-04-05","date":"2023-04-04T16:00:00.000Z","updated":"2023-04-05T16:00:00.000Z","comments":true,"path":"2023/04/05/Ceph_Crimson_SeaStore_Meeting_2023-04-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/04/05/Ceph_Crimson_SeaStore_Meeting_2023-04-05/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： QE团队更新： OSD日志问题：在启用调试级别20的情况下，OSD日志未包含级别15、10、20的条目，而MGR日志则包含所有这些级别的条目。此问题已在上次测试中被观察到，并在最近一次测试中再次被发现，现已上报。 池压缩问题：启用压缩的池（如Snappy或c-lib）在运行rados bench时，写入的数据量和对象数量与未启用压缩的池相同，而在下游的Red Hat CEPH集群中，这些数据有明显差异。此问题也被上报。 Crimson支持：下游的CI框架现已支持Crimson，所有CI管道中的测试将在未来几周内运行在Crimson构建上。 Crimson日志级别讨论： Crimson的日志系统与传统系统完全不同，只有Trace、Debug和Error三个级别。目前正在调整将传统的调试日志级别映射到Crimson的日志级别。 后续行动计划： 跟进Milton关于设置最大对象的结果分享。 继续调试medusa oski系统，预计很快完成最终修改。 决定事项： 确认Crimson日志级别映射的问题，并将与相关人员进一步沟通解决。 持续关注并解决池压缩问题。 后续行动： 与Milton分享关于最大对象设置的测试结果。 完成medusa oski系统的最终调试和修改。 其他事项： 今天是Pierce的假期，提醒大家享受假期。 会议结束： 会议于[具体时间]结束，感谢大家的参与。 以上是本次会议的详细纪要，涵盖了讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-03-30","slug":"Ceph_Performance_Meeting_2023-03-30","date":"2023-04-04T16:00:00.000Z","updated":"2023-04-05T16:00:00.000Z","comments":true,"path":"2023/04/05/Ceph_Performance_Meeting_2023-03-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/04/05/Ceph_Performance_Meeting_2023-03-30/","excerpt":"","text":"会议纪要 会议主题： 性能会议 日期： 2023年3月30日 主持人： Marcus 关键细节： 新PR介绍： 新增了一个零API到RW Casey，目的是创建一个没有后端存储的REST API，用于隔离HTTP前端的基准测试，优化Boost前端，并对比HTTP/3前端的工作。 性能优化： Mark Kogan进行了一些初步的HS基准测试，显示了较好的改进。 针对Beast前端的SSL连接开销进行了讨论，特别是高负载或多客户端情况下的瓶颈。 其他更新PR： 推进了Mark提出的booster accumulation想法，旨在批量处理键值存储更新，以提高整体吞吐量。 解决了BlueFS的碎片问题，相关方法已批准，等待QA。 新的Crimson性能套件表现良好，可以开始收集数据并与Amazon进行比较。 更新了M clock恢复和backfill成本，特别是在小对象工作负载下的性能改进。 会议工具变更： 从下周开始，会议将切换到Jitsi进行。 讨论的主要议题： 性能优化工具的使用和测量方法。 新的性能改进提案和其潜在影响。 会议工具的变更及其影响。 决定的事项： 确认了新的性能工具的使用和测量方法。 同意了会议工具的变更。 后续的行动计划： 继续对新的性能工具进行测试和优化。 完成Mark的booster accumulation提案的更新和测试。 开始使用新的Crimson性能套件进行数据收集和分析。 切换到Jitsi进行后续的会议。 会议结束： 感谢所有参与者的参与，并期待下周在Jitsi上的再次会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-03-29","slug":"Ceph_Crimson_SeaStore_Meeting_2023-03-29","date":"2023-03-28T16:00:00.000Z","updated":"2023-03-29T16:00:00.000Z","comments":true,"path":"2023/03/29/Ceph_Crimson_SeaStore_Meeting_2023-03-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/29/Ceph_Crimson_SeaStore_Meeting_2023-03-29/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： Crimson项目进展 目前有一个分支使aerator与标准库协同系统兼容。 正在扩展以支持互操作的未来，预计在未来几天内完成。 多核messenger的审查 讨论了连接引用类型可能需要更改为共享外部共享类型。 正在对Crimson OSD中的连接用户进行扫描，以理解潜在影响。 已发送电子邮件描述在Alaska中可能的更改，请求相关人员审查。 医疗助手PR修改 根据反馈修改了医疗助手PR，设备已启动。 未分离接口，因为这会影响系统中的所有产品，如清洁器和外部放置设备。 建议将接口分离作为下一步计划。 Albion指针PR修改 已完成Albion指针PR的修改并已推送。 仍在进行sisters克隆实现的工作。 决定事项： 确认Crimson项目中aerator与标准库协同系统的兼容性工作进展。 对多核messenger的连接引用类型进行进一步分析和可能的更改。 医疗助手PR的接口分离将作为后续步骤进行。 后续行动计划： 继续推进Crimson项目的互操作性扩展工作。 审查并实施多核messenger连接引用类型的更改。 规划并实施医疗助手PR的接口分离。 完成sisters克隆实现的后续工作。 其他事项： 部分成员因假期将缺席下次会议。 会议结束前，提醒相关人员查看电子邮件并处理相关事宜。 会议结束语： 祝大家假期愉快，下周再见。 备注： 本次会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了信息的准确传达和后续工作的顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-03-29","slug":"Ceph_RGW_Refactoring_Meeting_2023-03-29","date":"2023-03-28T16:00:00.000Z","updated":"2023-03-29T16:00:00.000Z","comments":true,"path":"2023/03/29/Ceph_RGW_Refactoring_Meeting_2023-03-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/29/Ceph_RGW_Refactoring_Meeting_2023-03-29/","excerpt":"","text":"会议纪要 议题一：用户配额的标记性能计数器 讨论内容： Ali提出关于用户配额的标记性能计数器的需求，特别是希望在Prometheus中查看每个RGW用户的配额分配和当前使用情况（对象数量和字节数）。 讨论了如何通过创建新的用户标签，更新用户统计信息，并将这些信息发送到与现有计数器相同的收集系统中。 提到了需要一个缓存机制来处理用户配额的频繁更新问题。 讨论了是否应该基于事件（如配额更改或强制执行）来发送数据，而不是连续不断地发送。 讨论了如何处理多网关实例中的数据一致性问题。 决定事项： 首先实现一个缓存机制，然后添加用户标签到前端计数器。 需要进行测试以验证系统的可扩展性。 后续行动计划： Ellie将首先实现缓存机制，然后添加用户标签到前端计数器。 进行测试以验证系统的可扩展性。 议题二：GitHub组织的两因素认证要求 讨论内容： 讨论了GitHub组织即将要求的两因素认证（2FA），以及未启用2FA的成员将被移除的问题。 讨论了如何分步骤实施2FA，以避免一次性移除所有未启用的成员。 决定事项： 提醒所有成员尽快启用2FA，以避免失去对GitHub组织的访问权限。 后续行动计划： 所有成员应尽快启用2FA。 议题三：日志数据与桶策略的交互 讨论内容： Emil讨论了如何禁用区域的日志记录，特别是与桶策略相关的日志记录。 讨论了是否可以使用supports_data_export API实例来替代当前的日志数据标志。 决定事项： 应该使用supports_data_export和supports_data_import来替代区域范围的标志。 后续行动计划： Emil将研究如何调整初始化顺序以解决依赖问题，并更新相关的PR。 其他讨论 会议还讨论了同步模块和多站点配置的一般问题。 会议结束 会议在讨论完所有议题后结束，感谢所有参与者的贡献。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-03-28","slug":"Ceph_Orchestrator_Meeting_2023-03-28","date":"2023-03-27T16:00:00.000Z","updated":"2023-03-28T16:00:00.000Z","comments":true,"path":"2023/03/28/Ceph_Orchestrator_Meeting_2023-03-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/28/Ceph_Orchestrator_Meeting_2023-03-28/","excerpt":"","text":"会议纪要 日期: [具体日期] 参会人员: [具体人员名单] 缺席人员: Brenda (因冲突无法参加) 会议主持人: [主持人姓名] 会议记录人: [记录人姓名] 主要议题 会议目的与议题确认 会议开始时，主持人确认Brenda无法参加，因此会议规模较小。 确认当天没有特定议题，主要讨论昨天已讨论的内容。 技术讨论 讨论了将所有Python内容打包到主RPM的提议，该提议在邮件列表中引起了一些反对意见。 Seth在邮件列表中提出了新的方法，Casey Bodley和Caleb也参与了讨论，提供了技术细节。 讨论了将包推送到Apple的方法，以及为什么某些RPMs和Rel中存在但不在Centos中。 会议工具迁移 确认本周是最后一次使用Blue Jeans进行会议，因为该服务将于4月1日关闭。 主持人将调整社区日历中的会议链接，并提醒参会人员更新个人日历。 记录与版本控制 讨论了如何处理记录和版本控制的问题，特别是关于Python依赖的管理。 提到了使用pip获取最新版本包的优势和潜在问题。 决定事项 确认本周会议结束后将不再使用Blue Jeans，并调整社区日历中的会议链接。 将继续关注邮件列表中关于Python打包方法的讨论，并根据需要调整策略。 后续行动计划 主持人将调整社区日历中的会议链接，并提醒参会人员更新个人日历。 参会人员将阅读邮件列表中关于Python打包方法的讨论，并在必要时参与进一步的讨论。 会议结束时间: [具体时间] 下次会议: [具体日期和时间] 备注: 会议中提到的技术细节和具体人员意见将在后续的邮件列表讨论中进一步明确和处理。 会议记录完毕 [记录人签名] [日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-03-23","slug":"Ceph_Performance_Meeting_2023-03-23","date":"2023-03-23T16:00:00.000Z","updated":"2023-03-24T16:00:00.000Z","comments":true,"path":"2023/03/24/Ceph_Performance_Meeting_2023-03-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/24/Ceph_Performance_Meeting_2023-03-23/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 参与者: [参与者姓名] 主持人: [主持人姓名] 主要议题 硬件需求确认: 讨论内容: 确认Laura是否已经获得进行测试所需的硬件。 决定: Laura仍需获取硬件。 性能测试结果分享: 讨论内容: 分享了在NVMe集群上进行的测试，特别是在RBD池中增加PG数量后，性能显著提升的情况。 决定: 需要进一步分析PG锁争用是否是性能提升的主要原因。 平衡器和自动缩放器的使用: 讨论内容: 讨论了在性能测试中禁用平衡器和自动缩放器的影响。 决定: 需要进一步研究平衡器在不同情况下的效用。 后续行动计划: 行动项: Laura将提供关于如何设置主要重新平衡器的详细指导，以便进行进一步的测试。 预期结果: 通过测试，验证平衡器在不同场景下的效果。 其他讨论 新PRs: 讨论了多个新的和更新的PRs，包括文档更改、性能改进和实验性功能。 硬件测试: 确认将继续为Laura获取硬件，以便进行更深入的测试。 会议平台变更: 下一次会议将尝试使用Jitsi平台。 后续行动 硬件获取: 继续为Laura获取硬件。 性能测试: 根据提供的指导进行主要重新平衡器的测试。 PR审查: 继续审查和更新相关的PRs。 会议结束 时间: [具体结束时间] 下次会议: [下次会议的具体日期和时间] 备注 会议中提到的具体测试数据和性能指标需要进一步验证和分析。 对于平衡器和自动缩放器的深入研究将进一步指导未来的优化方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2023-03-22","slug":"Ceph_Crimson_Seastore_Meeting_2023-03-22","date":"2023-03-21T16:00:00.000Z","updated":"2023-03-22T16:00:00.000Z","comments":true,"path":"2023/03/22/Ceph_Crimson_Seastore_Meeting_2023-03-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/22/Ceph_Crimson_Seastore_Meeting_2023-03-22/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [参会人员名单] 主要议题： 代码审查与开发进展 scrub 和 aerator 代码迁移：会议开始时，提到了正在进行的工作，包括对 scrub 和 aerator 代码的审查，以及将 interruptable future 代码迁移到标准协程（co-routine）的工作。讨论了这种迁移可能带来的便利性和效率提升。 协程与 Future 的使用：讨论了将现有代码中的 Future 实现转换为协程的可能性。强调了这种转换是可选的，主要为了减少内存分配，提高性能。同时，现有代码不需要强制转换，可以自由混合使用两种风格。 Shaded 存储接口定义：讨论了定义 Shaded future store 接口和 Shaded c-store 设备接口的工作。请求对新的 future store 接口从 OSD 角度进行审查。 Marco 系统 PR 修改：根据 AC 的评论，对 Marco 系统的 PR 进行了修改，包括未来写入扭曲和过滤包装短安装的耦合接口定义。讨论了设备接口定义，并计划将其修改为设备类和共享设备类。 LBA point rpr 代码修改：报告了 LBA point rpr 代码修改的调试进展，预计本周可以替换现有代码。同时，审查了由某人提交的正在进行中的缓存 PR。 systore Clone 方法论讨论：与 Ian 讨论了 systore Clone 的方法论，并开始着手开发原型。 决定事项： 对 Shaded future store 接口进行进一步审查。 继续进行 LBA point rpr 代码的调试和替换工作。 开始 systore Clone 的原型开发。 后续行动计划： 完成 Shaded future store 接口的审查并根据反馈进行调整。 完成 LBA point rpr 代码的调试，并替换现有代码。 继续开发 systore Clone 的原型，并根据需要进行调整。 会议结束： 会议简短，大家表示有好的周末。 备注： 保留了部分计算机科学/ceph相关领域英文原文的关键词，如 \"scrub\", \"aerator\", \"co-routine\", \"Future\", \"OSD\", \"PR\", \"LBA point rpr\", \"systore Clone\" 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-03-21","slug":"Ceph_Orchestrator_Meeting_2023-03-21","date":"2023-03-20T16:00:00.000Z","updated":"2023-03-21T16:00:00.000Z","comments":true,"path":"2023/03/21/Ceph_Orchestrator_Meeting_2023-03-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/21/Ceph_Orchestrator_Meeting_2023-03-21/","excerpt":"","text":"会议纪要 会议主题：视频会议平台迁移与技术讨论 会议时间：[具体日期] 参会人员：[参会人员名单] 会议内容总结： 视频会议平台迁移计划 当前问题：Blue Jeans视频会议平台将于4月1日关闭，需要寻找替代方案。 讨论内容：在CLT会议中讨论了Google Meet和Jitsi作为替代方案，但由于Google Meet存在权限问题和需要Google账户，倾向于使用Jitsi。 决定事项：计划迁移到已有的Jitsi会议室，但需要解决录音问题，目前录音需手动触发，不同于Blue Jeans的自动录音。 后续行动：预计会有几周时间没有录音，直到问题解决。下周将继续使用Blue Jeans，之后迁移到Jitsi。 技术讨论：通用超时处理 问题背景：存在多个可能导致命令超时的问题，如卷进程达到极限点、节点根文件系统无空间等。 讨论内容：提出了三种解决方案： 在fdm二进制文件中添加超时标志。 使用线程系统，启动单独线程并设置超时。 使用异步IO，通过内部函数传递超时。 决定事项：倾向于使用异步IO方案，因其实现简单且异常处理更方便。 后续行动：将删除测试用例中的临时代码，编写更正式的单元测试和集成测试。 其他讨论： 对于视频会议平台的迁移，提醒参会人员注意个人日历的更新，确保不会错过会议。 对于技术讨论，鼓励进一步的测试和实施细节的完善。 会议结束： 感谢所有参会人员的参与，下周将继续使用Blue Jeans，之后迁移到Jitsi。 提醒参会人员注意日历更新，确保顺利过渡到新的会议平台。 下次会议预告： 下周会议将继续使用Blue Jeans平台。 之后将迁移到Jitsi平台，并解决录音问题。 会议结束时间：[具体时间] 记录人：[记录人姓名] 审核人：[审核人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-03-16","slug":"Ceph_Performance_Meeting_2023-03-16","date":"2023-03-15T16:00:00.000Z","updated":"2023-03-16T16:00:00.000Z","comments":true,"path":"2023/03/16/Ceph_Performance_Meeting_2023-03-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/16/Ceph_Performance_Meeting_2023-03-16/","excerpt":"","text":"会议纪要 关键细节 参会人员: Casey, Igor, Mark, Joshua, 及其他相关人员。 会议时间: 具体时间未提及，但提到会议开始时有人迟到。 会议平台: 讨论了从Blue Jeans迁移到Jitsu的计划，因为Blue Jeans即将停止服务。 讨论的主要议题 Zero Back End: Casey介绍了Zero Back End的概念，这是一个优化Beast前端和HTTP 3前端性能的工具。团队对此表示兴奋，并讨论了其在Ceph RGW（RADOS Gateway）中的应用潜力。 HTTP 3 Front End: 讨论了HTTP 3前端的性能工作，以及如何通过Zero Back End进行苹果对苹果的比较。 HS Bench: 提到了HS Bench工具的使用，询问是否有改进测试的方法。 Mini IO Work: 讨论了Mini IO工作的进展，确认其对团队有用，并考虑将其集成到CBT（Ceph Build Test）中。 Writable File Allocate PR: Igor介绍了他的PR，该PR旨在减少SSD文件的碎片化，提高性能。讨论了其对RocksDB接口的影响和潜在的性能提升。 RocksDB Store: 讨论了RocksDB Store的多个PR，包括优化删除范围阈值和使用边界迭代器。 D4N Work for RGW: 讨论了一个大型PR，涉及RGW的D4N工作，目前正在进行中。 TC Malek in C-Star: 讨论了在C-Star中启用TC Malek的PR，以解决内存泄漏问题，提高性能和内存使用效率。 决定的事项 确认Zero Back End的潜力，并计划进一步探索其在Ceph中的应用。 确认Mini IO工作的有用性，并考虑将其集成到CBT中。 确认Igor的Writable File Allocate PR的潜在性能提升，并计划进行进一步测试。 确认RocksDB Store的多个PR的进展，并计划进行QA测试。 确认D4N Work for RGW的PR的进展，并计划进行进一步的工作。 确认TC Malek in C-Star的PR的进展，并计划进行进一步的测试和集成。 后续的行动计划 继续探索Zero Back End在Ceph中的应用。 继续测试和集成Mini IO工作到CBT中。 继续测试和集成Igor的Writable File Allocate PR。 继续测试和集成RocksDB Store的多个PR。 继续测试和集成D4N Work for RGW的PR。 继续测试和集成TC Malek in C-Star的PR。 迁移会议平台从Blue Jeans到Jitsu。 其他讨论 讨论了Ceph的性能改进，特别是在Reef版本中，提到了随机写入性能的提升。 讨论了SSD驱动器的固件升级对性能的影响，以及如何处理驱动器碎片化问题。 结论 会议涵盖了多个技术议题，包括性能优化、工具集成和平台迁移。团队对未来的工作充满期待，并计划继续推进各项议题的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2023-03-15","slug":"Ceph_Crimson_Seastore_Meeting_2023-03-15","date":"2023-03-14T16:00:00.000Z","updated":"2023-03-15T16:00:00.000Z","comments":true,"path":"2023/03/15/Ceph_Crimson_Seastore_Meeting_2023-03-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/15/Ceph_Crimson_Seastore_Meeting_2023-03-15/","excerpt":"","text":"会议纪要 会议时间与参与人员 时间: 由于夏令时调整，会议时间提前一小时。 参与人员: 会议中讨论了关于夏令时调整对与会者的影响，确认调整后的时间对所有参与者无影响。 主要议题与讨论内容 Ceph研发进展: Crimson存储引擎: 进行了代码审查，包括优化读取设备分层设计、多核系统调整、Future Store接口调整以及数据覆盖对象的后期读取功能。 LBA 400 PRS验证: 正在进行相关验证工作。 SysStore中的克隆机制设计: 讨论了克隆操作的设计，特别是快照修剪和快照恢复机制。 快照与克隆操作的详细讨论: 快照恢复: 讨论了在恢复过程中如何处理读写操作，特别是如何优先恢复头对象而不是克隆对象。 快照修剪: 强调了支持任意顺序移除快照的重要性，并讨论了避免碎片化的必要性。 设计建议: 提出了通过在对象数据处理程序中建立类似链表的结构来处理克隆引用，而不是在onode中处理，以简化复杂性。 决定事项 快照与克隆操作的设计: 需要进一步考虑和优化，特别是如何处理快照修剪和恢复操作。 Blue Store的研究: 建议深入研究Blue Store的处理方式，以借鉴其有效的交互设计。 后续行动计划 深入研究Blue Store: 进一步了解Blue Store如何处理快照和克隆操作，特别是其交互机制。 继续优化设计: 根据讨论的建议，继续优化快照和克隆操作的设计，确保操作的高效性和避免碎片化。 其他事项 会议中提到了使用中文进行更有效的沟通，建议在必要时使用中文。 结论 会议讨论了Ceph存储引擎的多个关键技术问题，特别是关于快照和克隆操作的设计。后续将重点研究Blue Store的处理方式，并继续优化相关设计，以确保系统的稳定性和高效性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-03-15","slug":"Ceph_RGW_Refactoring_Meeting_2023-03-15","date":"2023-03-14T16:00:00.000Z","updated":"2023-03-15T16:00:00.000Z","comments":true,"path":"2023/03/15/Ceph_RGW_Refactoring_Meeting_2023-03-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/15/Ceph_RGW_Refactoring_Meeting_2023-03-15/","excerpt":"","text":"会议纪要 会议主题：关于多部分重新上传修复的测试覆盖率 主要议题： - 讨论了多部分上传功能中避免数据和索引条目泄露的修复工作，该修复已合并到Reef版本中，但缺少针对孤立对象的测试覆盖。 - 提出了增加测试覆盖的具体形式，包括编写一个工作单元脚本，该脚本将执行多部分上传和重新上传，并扫描RADOS对象和桶索引以检查是否有泄露的对象和索引条目。 决定事项： - Eric自愿负责编写测试脚本，该脚本将模拟多部分上传和重新上传操作，并验证是否存在孤立的RADOS对象和索引条目。 后续行动计划： - Eric将更新跟踪器问题58780，详细说明测试计划，确保不遗漏关键细节。 - 讨论了在每次RGW验证作业后扫描孤立对象的建议，但认为这可能不适用于所有情况，特别是索引条目的问题。 会议主题：关于归档区域的请求 主要议题： - 讨论了一个长期存在的请求，即归档区域在对象元数据更改时生成新版本的问题。 - 提出了一个快速修复方案，即比较新旧对象版本并决定是否丢弃，但认为这可能是一个成本高昂的操作。 决定事项： - 决定不采用快速修复方案，而是考虑更长期的解决方案，如内容可寻址的对象表示方法，这可能会提高RADOS对象名称的信息密度，并增加系统的灵活性。 后续行动计划： - 将在周一的会议上进一步讨论此问题，并考虑在Upstream邮件列表中启动关于设计想法的讨论。 其他事项 讨论了其他可能的改进方向，如基于块的内容可寻址块，这可能对大型对象特别有用。 会议总结： - 本次会议主要集中在多部分上传修复的测试覆盖和归档区域的长期解决方案上，确定了具体的行动计划和后续讨论的方向。 会议结束： - 会议在讨论完所有议题后结束，感谢所有参与者的贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-03-14","slug":"Ceph_Orchestrator_Meeting_2023-03-14","date":"2023-03-13T16:00:00.000Z","updated":"2023-03-14T16:00:00.000Z","comments":true,"path":"2023/03/14/Ceph_Orchestrator_Meeting_2023-03-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/14/Ceph_Orchestrator_Meeting_2023-03-14/","excerpt":"","text":"会议纪要 主要议题 OSD Flags 处理机制讨论 背景：会议中讨论了如何处理OSD Flags的设置，特别是在升级过程中。 当前方案：目前方案是通过配置选项设置一个逗号分隔的列表，默认情况下进行升级并设置这些标志。 讨论点： 默认行为：是否应该默认设置这些标志，以及如何处理用户已经设置的标志。 配置方式：使用逗号分隔列表作为配置选项的优缺点，以及是否有更好的配置方式。 用户需求：评估用户修改这些标志的频率，以决定配置的复杂度和灵活性。 升级过程中的标志处理 问题：如果用户已经设置了某些标志，升级过程中是否应该保留这些设置。 建议：在升级前保存当前标志状态，并在升级后恢复，以避免意外更改用户设置。 新功能引入与默认行为 讨论：是否应该在旧版本中引入新功能但不改变默认行为，以避免用户感到意外。 建议：在旧版本中引入机制但不启用默认行为，在主要版本更新时再启用新默认行为。 决定事项 OSD Flags 处理：同意在升级前保存标志状态并在升级后恢复，以避免用户设置被意外更改。 新功能引入：决定在旧版本中引入新功能但不改变默认行为，在主要版本更新时再启用新默认行为。 后续行动计划 实施标志状态保存与恢复：开发团队将实现升级前保存标志状态并在升级后恢复的功能。 配置选项优化：评估并优化配置选项的设计，以提高用户友好性和灵活性。 文档更新：更新相关文档，明确说明升级过程中的标志处理机制和用户操作指南。 其他议题 OpenStack Manila与Ceph NFS服务集成：讨论了与OpenStack Manila集成的相关问题和解决方案，特别是关于Ingress服务的配置和NFS Ganesha的代理协议实现。 会议结束 会议在讨论完所有议题后结束，预计下次会议将继续跟进相关议题的进展。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-03-09","slug":"Ceph_Performance_Meeting_2023-03-09","date":"2023-03-13T16:00:00.000Z","updated":"2023-03-14T16:00:00.000Z","comments":true,"path":"2023/03/14/Ceph_Performance_Meeting_2023-03-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/14/Ceph_Performance_Meeting_2023-03-09/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [参会人员列表] 会议主持： [主持人姓名] 关键细节 会议开始时，主持人因与Josh讨论碎片整理而迟到。 讨论了本周的两个新PR，均与Crimson Suite相关。 讨论了更新PR，包括qat batch PR、Corey的PR（roxdb iterator bounds for collection list）和Igor的PR（pr4 not resetting the pre-fetched buffer while doing multi-chunk reads）。 讨论了关于Blue Store buffered IO的性能问题，特别是与roxdb的交互和预取缓冲区的使用。 讨论了CBT的一个PR，关于禁用现有结果目录检查的问题。 讨论的主要议题 新PR讨论 Matan的PR：修复了Crimson性能测试中的collect all安装问题。 Intel开发者的PR：增加了细粒度缓存，并提供了基准测试结果。 更新PR讨论 qat batch PR：来自Intel，有一些额外的审查。 Corey的PR：关于roxdb迭代器边界，有一些新的修复。 Igor的PR：关于预取缓冲区的重置问题，可能有助于改善roxdb的预取行为。 Blue Store Buffered IO问题 讨论了是否可以在禁用Blue Store buffered IO的同时，通过BlueFS层进行预取缓存。 讨论了roxdb的块缓存问题，以及是否可以通过改进BlueFS层来解决。 CBT PR讨论 讨论了一个关于禁用现有结果目录检查的PR，目的是防止重复运行测试。 决定的事项 对于新PR和更新PR，将继续进行审查和测试。 对于Blue Store buffered IO问题，将继续探索在BlueFS层进行预取缓存的可能性。 对于CBT PR，将寻找更细致的解决方案，而不是完全禁用现有目录检查。 后续行动计划 继续审查和测试本周的新PR和更新PR。 进一步研究和测试Blue Store buffered IO的性能问题。 与Nissan跟进CBT PR的问题，寻找更细致的解决方案。 会议结束时间： [具体时间] 下次会议预告： [具体日期] 会议记录人： [记录人姓名] 审核人： [审核人姓名] 备注： 会议中提到的技术细节和讨论点需要进一步的技术验证和代码审查。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-03-08","slug":"Ceph_RGW_Refactoring_Meeting_2023-03-08","date":"2023-03-08T16:00:00.000Z","updated":"2023-03-08T16:00:00.000Z","comments":true,"path":"2023/03/09/Ceph_RGW_Refactoring_Meeting_2023-03-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/09/Ceph_RGW_Refactoring_Meeting_2023-03-08/","excerpt":"","text":"会议纪要 会议主题 讨论关于Ceph分布式存储系统中端到端跟踪（end-to-end tracing）的实现和优化问题。 主要议题 端到端跟踪的通用性和特定实现问题： 端到端跟踪技术本身不特定于某个领域，但其需要在代码中通过不同的API传递，并最终序列化到消息中。 Omri的工作涉及将跟踪信息添加到cell对象中，以便在对象进入rados时可以提取和序列化跟踪信息。 代码重构对跟踪实现的影响： Casey的重构工作移除了一些对cell对象的调用，这使得跟踪信息的传递变得复杂。 讨论了如何在rados实现中访问和传递跟踪信息，特别是在重构后如何处理cell对象和rados对象之间的关系。 具体实施方案的讨论： 提出了几种可能的解决方案，包括将跟踪信息添加到所有API函数定义中，或者将跟踪信息作为对象的一个属性。 讨论了在rados对象中存储跟踪信息的可能性，并探讨了如何通过现有结构传递跟踪信息。 决定事项 决定在rgw rados对象类中添加跟踪信息，以便在读写路径中获得更多的覆盖率。 确认了rgw rados对象类可以从rgw cell构造，因此可以在这些类中传递跟踪信息。 后续行动计划 继续探索和实施在rgw rados对象类中添加跟踪信息的方案。 考虑使用warp等工具进行并行工作负载测试，以增强升级测试的覆盖范围。 对现有Ragweed测试进行审计，并考虑添加新的测试案例，特别是针对新功能的开发。 其他讨论 讨论了删除不再使用的代码部分，特别是与Pub sub相关的代码。 探讨了升级测试的策略，包括使用Ragweed测试和可能的S3测试集成。 会议结论 会议对端到端跟踪的实现和优化进行了深入讨论，并确定了具体的实施方案和后续行动计划。通过这些措施，旨在提高Ceph系统在升级过程中的稳定性和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-03-08","slug":"Ceph_Crimson_SeaStore_Meeting_2023-03-08","date":"2023-03-07T16:00:00.000Z","updated":"2023-03-08T16:00:00.000Z","comments":true,"path":"2023/03/08/Ceph_Crimson_SeaStore_Meeting_2023-03-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/08/Ceph_Crimson_SeaStore_Meeting_2023-03-08/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [列出参会人员] 主要议题： 个人工作更新 Junction: 正在处理 classic scrub 和 Crimson scrub，同时更新了 grain cache 的最终版本，并关注 max application size 的 bug 问题。本周将重点审查 lba3 optimization，并计划在未来几周内投入更多精力到 multiple messenger 项目中。 Harsh: 报告了 Crimson 镜像配置集群时遇到的问题，已与 Nedson 讨论并确认问题不在 Crimson 本身，而是与 reef build 相关。 Kevin: 完成了垂直系统修改和 CN storm 系统的安装测试，请求团队进行审查。 Rocky: 提到上周的 PR 主要关于 self volume 和 surveillance，Adam King 正在审查中。 [其他人员]: 汇报了各自的工作进展和计划。 讨论文档： Joyhound 提出的文档关于在 systore 中实现热数据缓存功能，旨在缓存频繁访问的数据。讨论了设计原则，包括利用应用程序访问模式的局部性，以及数据和元数据的访问模式差异。 决定事项： 关于热数据缓存的讨论： 团队对 Joyhound 的文档进行了深入讨论，涉及缓存策略、数据局部性、以及如何与现有 tiering 系统集成。建议将缓存策略设计为可插拔的，以便未来调整和优化。 后续行动计划： 实施计划： 首先实现读取时的数据提升功能，然后独立考虑不同的驱逐策略。 文档更新： Joyhound 将根据会议反馈更新文档，增加更多细节和设计考虑。 会议结束： 会议在讨论完所有议题后结束，团队成员被鼓励继续推进各自的工作，并期待下一次会议的更新。 备注： 会议中提到了一些技术细节和特定术语，如 LBA tree、tiering implementation、eviction policy 等，这些内容对于理解会议内容和后续行动非常重要。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2023-03-07","slug":"Ceph_Orchestrator_2023-03-07","date":"2023-03-06T16:00:00.000Z","updated":"2023-03-07T16:00:00.000Z","comments":true,"path":"2023/03/07/Ceph_Orchestrator_2023-03-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/07/Ceph_Orchestrator_2023-03-07/","excerpt":"","text":"会议纪要 会议主题：证书管理与安全存储讨论 参会人员：[未列出] 会议时间：[未列出] 主要议题： 证书管理现状分析 当前视频管理着一些证书，如RGB前端证书和Grafana证书。 证书目前存储在不同的位置，如配置资源或RSW规范中。 证书管理需求 需要跟踪和管理所有证书，特别是关注其到期时间。 目标是能够监控证书的到期状态，并在接近到期时发出健康警告。 安全存储方案讨论 提议引入一个统一的Secret store，用于存储所有安全相关的数据，如证书、SSH密钥和密码。 该Secret store将类似于Kubernetes Secrets，提供一个通用的机制来管理敏感数据。 实施计划与挑战 需要进行一次大的迁移，将现有的证书和其他敏感数据迁移到新的Secret store中。 需要考虑向后兼容性，确保迁移过程中不影响现有系统的正常运行。 未来扩展性 统一的Secret store将便于未来与Vault等其他安全工具的集成。 提供了一个结构化的方式来管理和访问敏感数据，增强了系统的安全性和可维护性。 决定事项： 创建一个统一的Secret store，用于集中管理所有安全相关的数据。 进行一次大的迁移，将现有的证书和其他敏感数据迁移到新的Secret store中。 后续行动计划： 创建一个跟踪器来记录和管理证书管理的相关工作。 设计和实施Secret store，确保其安全性和易用性。 完成数据迁移，并更新相关代码以使用新的Secret store。 会议结束： 会议在讨论了TLS证书管理和安全存储方案后结束，计划下周继续讨论相关细节。 备注： 会议中提到的“Secret store”和“Kubernetes Secrets”是计算机科学领域中的专业术语，分别指代一个集中存储敏感数据的地方和Kubernetes系统中用于管理敏感数据的一种机制。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-03-02","slug":"Ceph_Performance_Meeting_2023-03-02","date":"2023-03-05T16:00:00.000Z","updated":"2023-03-06T16:00:00.000Z","comments":true,"path":"2023/03/06/Ceph_Performance_Meeting_2023-03-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/06/Ceph_Performance_Meeting_2023-03-02/","excerpt":"","text":"会议纪要 会议概述 本次会议是在两周后再次召开的，原因是会议主持人之前在纽约度假。会议主要回顾了最近两周的PR（Pull Request）列表，讨论了几个关键的议题，并决定了一些后续行动计划。 主要讨论议题 PR审查进度 主持人接近完成了PR列表的审查，但尚未完全完成。 提到了一个来自Casey的新PR，关于在rgw中切换回多态执行器的问题，Mark Hogan进行了测试，未发现明显的性能提升，但仍计划在Reef之后进行切换。 已关闭的PR 讨论了几个已关闭的PR，包括Igor的一个csq更改，使用更大的读取块在cue列表条目中，预计会有小的性能改进。 另一个重要的PR是关于更新Facebook的RocksDB，将在稍后讨论。 新的和更新的PR 讨论了几个新的和更新的PR，包括替换RBD配置的PR，加密添加qat批处理的PR等。 RocksDB更新 讨论了RocksDB的更新，该更新在现有的Valgrind测试中失败，但通过添加大量新的Valgrind抑制规则使其通过。计划在接下来的几个月中进行大量测试，如果出现问题，可能会回滚。 新的基准测试工具 讨论了一个新的基准测试工具，该工具使用了许多底层库，如librbd等，并自动填充Google表格与基准测试结果。但需要更多的测试和与现有工具如fio的比较。 读取平衡器 讨论了读取平衡器的性能改进，计划在一个小集群上进行测试，以证明性能的实际改进。 QAT加密问题 讨论了QAT加密的性能问题，特别是关于是否需要在插件中进行等待的设计问题。 决定事项 计划在Reef之后切换回多态执行器。 RocksDB的更新将在接下来的几个月中进行大量测试，如果出现问题，可能会回滚。 将进行一个小集群的测试，以证明读取平衡器的性能改进。 将进行QAT加密的性能测试，以评估是否需要进行等待。 后续行动计划 继续完成PR列表的审查。 进行RocksDB的更新测试，并监控内存泄漏和其他问题。 进行新的基准测试工具的测试，并与现有工具进行比较。 在小集群上进行读取平衡器的性能测试。 进行QAT加密的性能测试，以评估是否需要进行等待。 其他讨论 讨论了关于Spinner设置的首次写入问题，建议尝试禁用首次写入以减少开销。 讨论了Blue Store的日志问题，建议尝试使用新的日志实现来减少对RocksDB的依赖。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并期待下一次会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-03-01","slug":"Ceph_RGW_Refactoring_Meeting_2023-03-01","date":"2023-03-05T16:00:00.000Z","updated":"2023-03-06T16:00:00.000Z","comments":true,"path":"2023/03/06/Ceph_RGW_Refactoring_Meeting_2023-03-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/06/Ceph_RGW_Refactoring_Meeting_2023-03-01/","excerpt":"","text":"会议纪要 关键细节 Reef 分支决策: 今天的上游领导会议决定分叉 Reef 发布分支，预计今天完成。任何需要进入 Reef 的改动现在必须合并到 Main 并通过 backboards。 同步策略问题: Katie 报告了在禁用 bucket sink 的情况下测试同步策略时遇到的问题。发现即使只有两个区域配置为同步，第三个区域仍在拉取数据，这似乎是一个回归问题。 日志修剪问题: 与同步策略相关的另一个问题是日志修剪和归档区域的问题，即使某些区域不从其他区域同步数据，同步策略仍指示查询这些区域，这阻止了日志被修剪。 rgwhttp 客户端: 讨论了新的 rgwhttp 客户端类，该类可能在多站点配置中非常有用，尤其是在使用 HTTP/3 前端时。讨论了如何处理 OpenSSL 和 BoringSSL 的链接问题。 主要议题 同步策略的实现和问题: 讨论了同步策略在多区域配置中的具体实现问题，包括数据同步的逻辑和日志修剪的策略。 rgwhttp 客户端的使用和挑战: 探讨了在多站点环境中使用新 HTTP 客户端的潜在好处和面临的挑战，特别是与 SSL 库的兼容性问题。 决定事项 Reef 分支分叉: 决定分叉 Reef 发布分支，所有后续的合并请求需要通过 Main 和 backboards。 同步策略问题: 需要进一步审查和测试同步策略的实现，特别是关于数据同步和日志修剪的逻辑。 rgwhttp 客户端: 虽然新的 rgwhttp 客户端在多站点环境中可能非常有用，但需要解决与 SSL 库的兼容性问题。 后续行动计划 同步策略审查: Yehuda 将审查同步策略的实现，并测试更多案例以确认和解决存在的问题。 rgwhttp 客户端开发: 继续开发和测试 rgwhttp 客户端，特别是在处理 SSL 库兼容性方面的工作。 跟踪问题: 所有相关问题和讨论将被记录在 Tracker 和 Theta pad 中，以便后续跟踪和解决。 结论 会议讨论了关于 Reef 分支分叉、同步策略的实现问题以及 rgwhttp 客户端在多站点环境中的应用。决定分叉 Reef 分支并继续审查和改进同步策略和 rgwhttp 客户端的实现。所有相关问题和讨论将被记录并跟踪，以便后续的开发和改进。感谢所有参与者的贡献和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2023-02-28","slug":"Ceph_Orchestrator_2023-02-28","date":"2023-03-01T16:00:00.000Z","updated":"2023-03-01T16:00:00.000Z","comments":true,"path":"2023/03/02/Ceph_Orchestrator_2023-02-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/03/02/Ceph_Orchestrator_2023-02-28/","excerpt":"","text":"会议纪要 主要议题： 单元测试覆盖率讨论 call函数的问题修复与改进 标签命名的讨论 讨论细节： 1. 单元测试覆盖率讨论： - 讨论内容： John提出了关于单元测试覆盖率的问题，特别是针对一些高级别的命令函数（command functions）。他指出，由于这些函数涉及大量的模拟（mocking），其单元测试的价值值得商榷。 - 决定事项： 会议中决定，对于那些看起来不值得覆盖的函数，可以在代码中添加注释说明，并使用pragma no cover暂时跳过。同时，建议在完成其他必要测试后再回过头来重新评估这些函数的测试需求。 - 后续行动： 团队成员将逐一审查这些函数，标记出哪些是明确不需要单元测试的，并在代码中相应地进行标记。 2. call函数的问题修复与改进： - 讨论内容： John介绍了关于call函数的一个问题，即超时参数不工作的问题。他提出了两个修复方案，一个更简单但性能更好，另一个则增加了额外的日志功能。 - 决定事项： 经过讨论，团队决定采用更简单的修复方案，即使用标准库中的communicate函数，因为它不仅性能更好，而且更安全。 - 后续行动： John将根据这一决定提交相应的PR，并删除中间的测试代码。 3. 标签命名的讨论： - 讨论内容： 会议讨论了关于新引入标签的命名问题，特别是关于主机训练和配置文件管理的标签。 - 决定事项： 会议中对于标签的命名进行了初步讨论，但未最终确定。决定在文档中添加警告，告知用户这些标签是系统内部使用的，不建议用户直接操作。 - 后续行动： 将在文档中添加相关警告，并考虑未来添加更多命令来管理这些标签。 后续行动计划： 完成对高级别命令函数的审查，并标记不需要单元测试的函数。 提交并合并关于call函数修复的PR。 在文档中添加关于标签使用的警告，并考虑后续添加更多管理标签的命令。 会议结束： 会议在超时后结束，团队成员将在下一次会议中继续讨论未决事项。 以上是本次会议的详细纪要，涵盖了会议的主要讨论点、决定事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-02-22","slug":"Ceph_Crimson_SeaStore_Meeting_2023-02-22","date":"2023-02-22T16:00:00.000Z","updated":"2023-02-23T16:00:00.000Z","comments":true,"path":"2023/02/23/Ceph_Crimson_SeaStore_Meeting_2023-02-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/23/Ceph_Crimson_SeaStore_Meeting_2023-02-22/","excerpt":"","text":"会议纪要 日期： [具体日期] 参会人员： [参会人员名单] 1. 研发进展报告 scrub 和 crimson 工作： 目前主要集中在 scrub 工作上，未来将转向 crimson 相关工作。 弱事务问题审查： 正在审查 Johan 发现的弱事务问题，目前有四到五个相关的 PR 待处理。 多信使扩展工作： 正在进行 socket 和 socket 测试的扩展工作，并继续进行清理工作。 2. QE 部门更新 物理节点测试： 由于物理节点设置存在问题，已收到新机器并开始进行基本随机测试。初步测试运行良好，未见重大故障。 RBT 测试问题： 之前提到的 RBT 测试问题因机器崩溃暂时无法追踪，将在完成 rados 测试后重新生成问题并创建 Checkers。 3. 医疗系统接口讨论 当前实现架构： 每个 OSD 和共享服务持有单个强实例引用，通过 store 接口访问。 未来改进建议： 建议将 store 接口分离为两部分，一部分供主 OSD 使用，另一部分供其他 OSD 使用。 讨论焦点： 讨论了是否需要在 OSD 中直接使用 core zero shortstore，以及如何处理未来可能的动态空间分配问题。 决定： 决定保持当前实现，但未来可能需要考虑动态空间分配的实现方式。 4. 后续行动计划 代码修改： 根据讨论结果，进行必要的代码修改以支持新的架构。 测试和验证： 继续进行测试，确保新的实现稳定可靠。 文档更新： 更新相关文档，确保用户和开发者能够理解新的架构和使用方法。 下次会议： [具体日期] 备注： 下次会议将讨论如何使用 ceph-ansible 部署 crimson，并寻求社区的帮助和反馈。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-01-22","slug":"Ceph_RGW_Refactoring_Meeting_2023-01-22","date":"2023-02-22T16:00:00.000Z","updated":"2023-02-23T16:00:00.000Z","comments":true,"path":"2023/02/23/Ceph_RGW_Refactoring_Meeting_2023-01-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/23/Ceph_RGW_Refactoring_Meeting_2023-01-22/","excerpt":"","text":"会议纪要 1. GSAC Coverity 分析项目讨论 议题: 讨论GSAC项目中关于Coverity静态代码分析工具的使用和改进。 主要讨论点: Coverity由Synopsys公司拥有，提供免费的扫描工具和Web UI，用于管理开源项目中的问题。 存在问题：无法控制扫描时间和版本，反馈循环存在问题。 Sepia实验室的Caleb创建了一个设置，每天运行Clarity工具并将结果发布到静态网页。 提出了使用代码注释来忽略问题，以更好地控制和管理假阳性问题。 讨论了是否继续使用Web UI或转向静态网页选项，并结合代码注释。 决定事项: 同意继续使用Coverity工具，尽管存在大量假阳性，但工具仍有助于发现真实问题。 考虑使用代码注释来管理假阳性问题。 后续行动计划: 学生将负责清理和修复Coverity中发现的问题，并使用代码注释标记假阳性。 完成后，评估是否需要建立自动化系统来处理Coverity报告。 2. RGW对象清单(Manifest)隐私性讨论 议题: 讨论RGW对象清单是否应私有化。 主要讨论点: 对象清单曾包含在API中，现已移除，但仍有少量使用案例。 讨论了是否应将对象清单完全隐藏在RADOS后端，以及如何处理加密和解密过滤器。 决定事项: 同意将对象清单类型隐藏在RADOS存储后端，使RGW应用无法解码。 后续行动计划: 继续讨论和实施具体的隐私化措施。 3. 多站点同步状态可视化 议题: 讨论如何将多站点同步状态信息导出并可视化在Prometheus中。 主要讨论点: 需要明确要发送给Prometheus的具体信息。 讨论了现有同步计数器与客户需求之间的差距。 决定事项: 确认这是一个复杂问题，需要进一步研究和讨论。 后续行动计划: 详细阅读相关跟踪问题，并考虑如何改进同步状态的可视化。 4. 可加载模块的变更讨论 议题: 讨论对可加载模块进行大规模变更的可行性。 主要讨论点: 变更涉及将驱动程序改为唯一指针，这将影响多处代码。 决定事项: 同意这是一个大变更，需要谨慎处理。 后续行动计划: 将此变更作为独立任务处理，确保不影响其他开发工作。 5. 其他事项 议题: 讨论了其他可能的改进和问题。 决定事项: 确认需要进一步讨论和研究。 后续行动计划: 继续在开发列表中讨论和跟进。 结论 会议涵盖了多个关键议题，包括Coverity工具的使用改进、RGW对象清单的隐私性、多站点同步状态的可视化以及可加载模块的变更。决定继续使用Coverity工具并改进其管理方式，同意将对象清单隐藏在RADOS后端，确认多站点同步状态可视化是一个复杂问题，并同意对可加载模块进行大规模变更需谨慎处理。后续行动计划包括学生负责清理Coverity问题，详细研究同步状态可视化，以及独立处理模块变更。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-02-21","slug":"Ceph_Orchestrator_Meeting_2023-02-21","date":"2023-02-20T16:00:00.000Z","updated":"2023-02-21T16:00:00.000Z","comments":true,"path":"2023/02/21/Ceph_Orchestrator_Meeting_2023-02-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/21/Ceph_Orchestrator_Meeting_2023-02-21/","excerpt":"","text":"会议纪要 会议主题：Ceph 主机维护模式增强功能讨论 与会人员：Ceph 研发团队成员 会议时间：[具体日期] 会议地点：视频会议 主要议题： 主机维护模式（Host Maintenance Mode）的强制执行问题 当前主机维护模式的强制标志（force flag）仅能强制停止其下的功能，但在某些情况下，即使使用强制标志，主机仍无法进入维护模式。 提出了增加一个新的标志，以便在必要时能够强制进入维护模式，即使存在可能导致PG（Placement Groups）降级的条件。 讨论细节： 当前问题描述： 强制标志（force flag）在主机维护模式中仅能强制停止其下的功能，但在某些情况下，即使使用强制标志，主机仍无法进入维护模式。 存在一些情况，例如PG降级，导致无法将主机置于维护模式。 提出的解决方案： 建议增加一个新的标志，例如“紧急”（emergency）或“我确实真的需要这个”（yes I really really mean it），以允许在必要时强制进入维护模式。 该标志将允许用户在即使存在可能导致PG降级的条件下，也能强制停止所有守护进程（demons），以便进行必要的维护工作。 标志命名讨论： 讨论了多个标志名称，包括“紧急”（emergency）和“我确实真的需要这个”（yes I really really mean it）。 最终倾向于使用“我确实真的需要这个”（yes I really really mean it），因为它在Ceph社区中更为常见，且能更好地传达操作的危险性。 操作细节： 该标志将允许用户在不考虑安全检查的情况下，强制停止所有守护进程，以便进行维护。 该操作不会移除任何东西，只是停止守护进程，使其暂时不参与集群活动。 决定事项： 增加一个新的标志，用于在必要时强制进入主机维护模式，即使存在可能导致PG降级的条件。 标志名称倾向于使用“我确实真的需要这个”（yes I really really mean it）。 后续行动计划： 实现新的标志功能，并在代码中添加相应的警告和提示信息。 更新文档，明确新标志的使用场景和潜在风险。 其他讨论： 讨论了其他可能的标志名称和使用场景，但最终决定采用“我确实真的需要这个”（yes I really really mean it）。 会议结束： 会议在讨论完所有议题后结束，没有其他待讨论的新议题。 下次会议预告： 下次会议将根据项目进度和新的开发需求进行安排。 会议记录人：[记录人姓名] 审核人：[审核人姓名] 日期：[具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-02-15","slug":"Ceph_RGW_Refactoring_Meeting_2023-02-15","date":"2023-02-15T16:00:00.000Z","updated":"2023-02-16T16:00:00.000Z","comments":true,"path":"2023/02/16/Ceph_RGW_Refactoring_Meeting_2023-02-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/16/Ceph_RGW_Refactoring_Meeting_2023-02-15/","excerpt":"","text":"会议纪要 主要议题 S3代理过滤器和Zipper的讨论：会议开始时，讨论了如何实现S3代理过滤器和Zipper的问题，这是为了在d4n之下进行集成。昨天的d4n会议中对此有大量讨论，但未解决，因此希望在今天的会议中继续讨论。 Reef项目的进展：询问了Reef项目的现状，包括需要完成的功能和未合并的重要修复。 Ragweed问题的修复：提到了Ragweed问题的修复进展，已经解决了Ragweed的失败问题。 讨论细节 S3代理过滤器的问题：讨论了S3代理过滤器在Zipper API中的不适用性，因为Zipper API将S3操作分解为许多小API调用。理想的S3处理方式是在操作层进行代理，但这与Zipper的设计冲突。 权限验证问题：讨论了如何在无法访问桶元数据和策略的情况下进行权限验证。 新的抽象层提议：提出了为d4n和其他可能的应用构建一个新的抽象层，这个层更面向应用，更容易进行代理。 决定事项 重新安排讨论：由于关键成员Matt不在场，决定重新安排关于S3代理过滤器的讨论。 Reef项目的关注点：确认了Reef项目的进展和需要关注的功能和修复。 后续行动计划 继续讨论S3代理过滤器：待所有关键成员到齐后，继续讨论S3代理过滤器的实现细节。 Reef项目的跟进：继续关注Reef项目的进展，确保所有重要功能和修复得到及时合并。 新抽象层的开发：开始规划和设计一个新的抽象层，以更好地支持d4n和其他应用的需求。 其他讨论点 缓存层的设计：讨论了缓存层的设计，特别是如何处理元数据和数据的问题。 权限验证的实现：讨论了在不同存储后端中如何实现权限验证的问题。 会议总结 会议持续了近一个小时，讨论了多个关键的技术问题，并提出了一些解决方案和后续行动计划。感谢所有参与者的积极参与和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-02-08","slug":"Ceph_Crimson_SeaStore_Meeting_2023-02-08","date":"2023-02-13T16:00:00.000Z","updated":"2023-02-14T16:00:00.000Z","comments":true,"path":"2023/02/14/Ceph_Crimson_SeaStore_Meeting_2023-02-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/14/Ceph_Crimson_SeaStore_Meeting_2023-02-08/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： Ceph项目更新 代码合并与修复 技术讨论与问题解决 Cephalicon会议准备 讨论内容： 代码合并与修复 已合并修复一些非主要Bug。 Ying Jen需要重新基于当前的Main分支进行PR（Pull Request），因为一些故障可能是由于之前的Bug导致的。 当前的Main分支已合并，应该可以正常工作。 技术讨论与问题解决 关于Snap blog的讨论，目前关于Dreams的Snap blog已经可用。 对于SeaStar，正在进行关于启用IBM的Out of Line Physical Extents的讨论，并持续审查相关代码实现。 修复了Messenger的构建问题，并将继续替换相关部分。 Tommy正在完成代码修改，包括对ping功能的修改和连接指针的调整，计划今天进行调试。 上周主要尝试寻找Io hongbug的根本原因，但由于其他工作占用时间，进展不大，本周将继续处理。 Cephalicon会议准备 Cephalicon会议将于四月举行，目前行业内旅行限制普遍，但参会人员计划出席。 鼓励参会人员提交演讲，CFP（Call for Papers）截止日期在本周末。 关于参会预算，需要进一步确认。 决定事项： Ying Jen需要重新基于当前的Main分支进行PR。 Tommy将继续完成代码修改并进行调试。 参会人员将关注Cephalicon会议的进展，并准备可能的演讲提交。 后续行动计划： Ying Jen将重新基于Main分支进行PR，并通知相关人员进行测试。 Tommy将完成代码修改并进行调试。 参会人员将关注Cephalicon会议的进展，并准备可能的演讲提交。 其他事项： 无其他特别事项。 会议结束语： 祝大家本周工作顺利，期待在Cephalicon会议上见到大家。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2023-02-14","slug":"Ceph_Orchestrator_2023-02-14","date":"2023-02-13T16:00:00.000Z","updated":"2023-02-14T16:00:00.000Z","comments":true,"path":"2023/02/14/Ceph_Orchestrator_2023-02-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/14/Ceph_Orchestrator_2023-02-14/","excerpt":"","text":"会议纪要 关键细节 Redo Stuff: 讨论了关于重新部署RGW的问题，确认第一个问题已经修复。 性能问题: 关注了第二个问题下的两个具体问题，特别是非自动重新部署的问题。 图像更新: 讨论了People ID图像的更新问题，发现该图像长时间未更新，存在安全漏洞。 自动化构建: 提议设置自动构建以保持图像的更新，避免未来再次出现类似问题。 IPv6支持: 讨论了IPv6的支持问题，由于缺乏测试环境，目前难以确保IPv6的完全支持。 讨论的主要议题 图像管理: 如何更有效地管理和更新容器图像，特别是通过自动化工具如GitHub或Quay Auto Build。 IPv6测试: 如何建立IPv6的测试环境，以便更好地支持IPv6功能。 文档更新: 更新关于Podman版本兼容性的文档，确保信息的准确性和实用性。 决定的事项 图像更新: 决定手动更新一些关键图像，并探索设置自动构建的可能性。 文档更新: 更新Podman版本兼容性文档，删除过时的信息，添加关于稳定性的说明。 IPv6测试: 计划在未来实验室环境稳定后，重新提出IPv6支持的请求。 后续行动计划 图像更新: 与相关人员讨论如何更新和自动化图像构建过程。 文档更新: 修改并更新Podman版本兼容性文档。 IPv6支持: 在实验室环境稳定后，重新评估和提出IPv6支持的需求。 其他事项 会议时间管理: 由于部分参与者时间限制，会议进行了时间上的调整和优先级排序。 技术细节讨论: 对具体的技术问题进行了深入讨论，包括容器图像的版本管理、自动化构建的设置以及IPv6的支持问题。 会议结束时，所有参与者确认了后续行动计划，并期待在未来的工作中看到这些改进的实施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-02-09","slug":"Ceph_Performance_Meeting_2023-02-09","date":"2023-02-13T16:00:00.000Z","updated":"2023-02-14T16:00:00.000Z","comments":true,"path":"2023/02/14/Ceph_Performance_Meeting_2023-02-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/14/Ceph_Performance_Meeting_2023-02-09/","excerpt":"","text":"会议纪要 主要议题 Ceph存储系统的更新与优化 讨论了新的PR（Pull Request），包括分配器格式版本2（allocator format version 2）的实现和性能改进。 探讨了混合分配器（Hybrid allocator）的工作原理和可能的改进方向。 性能优化与测试 讨论了如何通过改进分配器格式来减少磁盘空间的使用和提高性能。 提到了单元测试的结果，显示在特定条件下新方法比旧方法快。 代码审查与合并 讨论了几个PR的审查状态和合并计划，包括一个关于避免使用整个空间迭代器的PR。 提到了一个关于禁用QAT（Quick Assist Technology）忙轮询的简单PR，考虑了其合并的可能性。 集群性能和配置更新 分享了Corey和David Orman的集群在应用了一些优化后的良好表现。 讨论了RocksDB调优和BlueFS增量日志更新的效果。 决定事项 计划合并几个PR，特别是那些已经通过审查并显示出性能改进的PR。 决定继续测试和评估RocksDB的新调优设置，以确定其在生产环境中的效果。 后续行动计划 继续进行代码审查和测试，确保所有PR都符合性能和稳定性的要求。 进一步探索和评估RocksDB调优和BlueFS更新的长期影响。 计划在未来的会议中继续讨论和更新这些议题的进展。 其他讨论 讨论了QAT技术的测试和集成问题，以及可能的解决方案。 提到了关于集群升级和配置更新的策略，特别是在即将到来的Reef版本中。 会议结束时，所有参与者对当前的进展表示满意，并期待在下一会议中继续讨论和解决问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-02-08","slug":"Ceph_RGW_Refactoring_Meeting_2023-02-08","date":"2023-02-13T16:00:00.000Z","updated":"2023-02-14T16:00:00.000Z","comments":true,"path":"2023/02/14/Ceph_RGW_Refactoring_Meeting_2023-02-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/14/Ceph_RGW_Refactoring_Meeting_2023-02-08/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统开发讨论会 日期：[具体日期] 参会人员：[具体人员名单] 会议内容总结： 预取功能（Prefetching）讨论 讨论了之前关于范围请求预取功能的拉取请求（Pull Request），该功能因OSD无法从EC池进行远程读取而受阻，但此问题已解决。 建议有人重新审视并尝试该功能，因为网络压缩和加密问题已得到解决。 云过渡问题讨论 讨论了从Noba MCG过渡到Azure时的问题，主要是因为对象名称中的连字符（hyphen）导致过渡失败。 提出了一种解决方案，即通过添加特定的HTTP头来决定是否进行属性映射，以便Noba能够适应该问题。 讨论了是否应该为所有从RGW客户端传来的对象默认应用此行为，并探讨了可能的技术实现细节。 RGW套件故障排查 报告了RGW套件在Ragweed上失败的状况，具体是由于Python导入问题导致的测试失败。 讨论了可能的故障原因，包括Python库路径问题，并建议进一步调查和解决。 Google Summer of Code和Outreachy项目征集 提醒团队成员关于Google Summer of Code和Outreachy项目的征集，鼓励大家提出与Ceph相关的项目想法。 决定事项： 需要有人重新审视并尝试预取功能。 对于云过渡问题，建议通过添加特定的HTTP头来解决，并探讨具体的技术实现。 对于RGW套件故障，需要进一步调查并解决Python导入问题。 后续行动计划： 重新审视预取功能的拉取请求，并尝试实施。 设计和实现通过HTTP头来控制属性映射的解决方案。 调查并解决RGW套件的Python导入问题。 收集和提交与Ceph相关的Google Summer of Code和Outreachy项目想法。 会议结束： 会议在讨论了所有议题后结束，感谢所有参与者的贡献。 以上为本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-02-07","slug":"Ceph_Orchestrator_Meeting_2023-02-07","date":"2023-02-07T16:00:00.000Z","updated":"2023-02-07T16:00:00.000Z","comments":true,"path":"2023/02/08/Ceph_Orchestrator_Meeting_2023-02-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/08/Ceph_Orchestrator_Meeting_2023-02-07/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph存储系统中关于管理器（manager）的高可用性（HA）实现，特别是通过使用keepalived来管理虚拟IP的问题。会议中涉及了多个技术细节和潜在的解决方案，以及后续的行动计划。 主要议题 Keepalived与管理器集成： 讨论了如何使用keepalived为管理器提供一个稳定的虚拟IP，以便外部Prometheus实例可以稳定地抓取数据。 探讨了管理器是否需要绑定到特定的IP地址，以及如何处理管理器故障转移时IP的变化。 构建错误问题： 提到了一些构建错误尚未解决，特别是在Sepia Slack上有相关的讨论和拉取请求（pull request），但问题仍未完全解决。 动态绑定问题： 讨论了是否可以在运行时动态绑定到新的虚拟IP，以及如何处理绑定失败的情况。 健康检查： 讨论了如何实现管理器的健康检查，以便keepalived可以正确地识别和管理管理器的状态。 与Dashboard和Prometheus的集成： 讨论了如何将虚拟IP的信息传递给Dashboard和Prometheus，并确保它们能够正确地使用这个IP。 决定的事项 研究与验证： 需要进一步研究管理器的绑定机制，以及是否可以动态绑定到新的虚拟IP。 需要验证keepalived的健康检查脚本是否可以正确地识别管理器的状态。 行动计划： 下周将再次讨论这些问题，届时将会有更多的研究和验证结果。 需要编写文档，指导用户在升级时如何处理keepalived机制。 后续行动计划 研究与验证： 验证管理器是否可以动态绑定到新的虚拟IP。 验证keepalived的健康检查脚本是否可以正确地识别管理器的状态。 编写文档： 编写详细的文档，指导用户在升级时如何处理keepalived机制。 下周会议： 下周将再次讨论这些问题，届时将会有更多的研究和验证结果。 结论 本次会议主要集中在Ceph管理器的高可用性实现上，特别是通过keepalived管理虚拟IP的问题。会议中提出了多个技术挑战和潜在的解决方案，并制定了后续的研究和验证计划。下周将再次讨论这些问题，届时将会有更多的研究和验证结果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-02-02","slug":"Ceph_Performance_Meeting_2023-02-02","date":"2023-02-07T16:00:00.000Z","updated":"2023-02-07T16:00:00.000Z","comments":true,"path":"2023/02/08/Ceph_Performance_Meeting_2023-02-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/08/Ceph_Performance_Meeting_2023-02-02/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统的多个技术问题和改进措施，包括新提交的PR（Pull Request）、已关闭的PR、更新中的PR以及一些实验性的改进。会议还涉及了Ceph在实际生产环境中的性能问题和解决方案。 主要议题 新提交的PR Igor提出的PR关于在带前缀的访问中不使用真实的整个空间迭代器。Igor解释了该PR的背景和实验结果，强调了在特定情况下使用默认列族可以显著提高性能。 Adam K提交的PR关于改进发酵方块度量，主要涉及碎片化分数计算的修正。 已关闭的PR 由机器人关闭的三个PR，包括从日志中移除子树映射、跳过空目录的inode cap迭代以及不进行缓冲写入。这些PR因各种原因被关闭，但会议中讨论了可能的重新开启和审查。 更新中的PR RocksDB升级PR，作者需要额外帮助以解决与Seth RocksDB仓库相关的问题。 添加主平衡分数的PR，主要等待实验室环境的修复以进行测试。 实验性改进 David和Corey团队分享了他们在实际生产环境中对Ceph集群的改进和优化，包括使用压缩、调整RocksDB设置以及处理NVMe和旋转磁盘的混合使用问题。 讨论了Ceph在处理大量删除操作时的性能问题，并提出了一些有效的解决方案。 其他讨论 讨论了Ceph在不同版本（如Pacific和Quincy）中的性能表现和可能的改进。 涉及了Ceph在处理大文件时的性能问题，特别是BlueFS的日志更新问题。 决定事项 需要进一步审查和可能重新开启某些已关闭的PR。 RocksDB升级和相关设置的调整需要尽快完成以改善性能。 对于Ceph在实际生产环境中的性能问题，需要继续进行实验和优化。 后续行动计划 继续审查和测试新的PR，确保它们符合性能和稳定性的要求。 对已关闭的PR进行重新评估，考虑是否需要重新开启和进一步开发。 继续与David和Corey团队合作，收集更多关于Ceph在实际生产环境中的性能数据和反馈。 考虑将某些实验性的改进（如压缩和RocksDB设置调整）作为默认配置，以提高Ceph的整体性能。 结论 会议强调了Ceph在实际应用中的性能优化和问题解决的重要性，并提出了具体的改进措施和后续行动计划。通过持续的测试和优化，Ceph的性能和稳定性有望得到显著提升。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2023-02-01","slug":"Ceph_Developer_Monthly_2023-02-01","date":"2023-02-01T16:00:00.000Z","updated":"2023-02-01T16:00:00.000Z","comments":true,"path":"2023/02/02/Ceph_Developer_Monthly_2023-02-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/02/Ceph_Developer_Monthly_2023-02-01/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统中的多个关键议题，包括测试失败、性能警告处理、S3选择功能、逻辑大规模套件开发、以及性能计数器JSON输出的格式调整。会议涵盖了问题的识别、解决方案的探讨、以及后续行动计划的制定。 主要议题与讨论 测试失败与健康警告 问题描述：测试失败由健康警告引起，涉及一个相关的PR。 讨论内容：Chris提供了问题的简要总结，指出在QA任务中，忽略列表或Badness检查未正确执行两项操作：未检查标准错误，以及指向错误的日志位置。 解决方案：创建了一个草稿PR来考虑并检查标准错误和正确的日志位置。计划在实际的RBD API上进行测试。 S3选择功能更新 功能介绍：S3选择功能允许客户端将SQL语句推送到存储层，从而只提取所需的数据子集，显著提高性能和降低成本。 讨论内容：详细介绍了S3选择功能的工作原理、优势以及面临的挑战，特别是与Spark和Trino等分析应用的集成。 后续行动：继续开发和优化S3选择功能，考虑与更多分析应用的集成。 逻辑大规模套件开发 目标：开发一个逻辑大规模套件，以便在Ceph上运行更多OSD的测试。 进展：已经完成了零块检测功能的开发，并正在进一步设置逻辑大规模套件。 后续行动：继续进行套件的设置和测试，以验证其在多OSD环境下的性能和稳定性。 性能计数器JSON输出格式调整 问题描述：讨论了是否以及如何调整性能计数器的JSON输出格式。 讨论内容：涉及是否保持现有命令不变，添加新命令，或调整现有命令的输出格式。 决定：决定添加一个新命令dump_counters，同时保持现有命令不变，逐步将计数器迁移到新命令中。 后续行动计划 测试失败与健康警告 继续在实际的RBD API上测试草稿PR，确保其正确处理标准错误和日志位置。 S3选择功能 继续开发和优化S3选择功能，特别是与Spark和Trino等分析应用的集成。 逻辑大规模套件 完成逻辑大规模套件的设置，并在多OSD环境下进行全面测试。 性能计数器JSON输出 实现新命令dump_counters，并逐步将计数器迁移到新命令中，同时发布相关更新和迁移指南。 结论 会议成功地识别了多个关键问题，并制定了相应的解决方案和后续行动计划。所有参与者都积极参与讨论，确保了决策的全面性和可行性。下一步将按照会议决议执行相关行动，并持续监控进展情况。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2023-01-31","slug":"Ceph_Science_Working_Group_2023-01-31","date":"2023-01-31T16:00:00.000Z","updated":"2023-01-31T16:00:00.000Z","comments":true,"path":"2023/02/01/Ceph_Science_Working_Group_2023-01-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/02/01/Ceph_Science_Working_Group_2023-01-31/","excerpt":"","text":"会议纪要 会议概述 本次会议是本年度的首次会议，旨在为来自不同背景的存储领域专业人士提供一个交流平台，讨论包括Ceph在内的分布式存储系统的各种议题，如升级、问题解决等。会议由一名组织者主持，参与者包括来自大学、研究机构和企业的人员。 主要议题与讨论 Ceph集群介绍与经验分享 Garen Atterbury（University of Nebraska Lincoln）分享了他们在Ceph集群上的经验，包括从HDFS迁移到Ceph，以及管理多个Ceph集群的情况。 Jeremy（South African Radio Astronomy Observatory）介绍了他们使用Ceph作为Meerkat射电望远镜数据产品的对象存储的案例。 Pieter（CSC）讨论了他们在Ceph集群上实施的S3认证和密钥管理策略，以及遇到的挑战和解决方案。 Ceph集群升级经验 Bruno Cannings（Sanger Institute）分享了他们从Ubuntu 18.04升级到20.04的经验，以及在升级过程中遇到的挑战和解决方案。 组织者和Jeremy讨论了从CentOS 7和8升级到Rocky 8的经验，以及如何进行In-Place转换。 Ceph集群管理和优化 讨论了Ceph集群的平衡器使用情况，包括内置算法和其他第三方平衡器的比较。 Pieter提到了他们在大型Ceph集群中遇到的管理和扩展性问题，特别是在使用Ceph Orchestrator时。 Ceph集群的硬件和操作系统选择 讨论了在不同操作系统版本上运行Ceph的情况，包括CentOS、Rocky Linux和Ubuntu。 Pieter提到了他们在使用NVMe存储设备时遇到的写放大问题。 决定事项 会议决定不举行下一次虚拟会议，而是计划在即将到来的Cephalocon 2023会议上举行面对面的Birds of a Feather session。 后续行动计划 组织者将考虑在Cephalocon 2023上组织一个Birds of a Feather session，以便参与者可以更深入地讨论Ceph相关的话题。 参与者将继续关注Ceph的开发和社区动态，以便及时了解和应用新的功能和改进。 其他备注 会议中提到了一些具体的Ceph版本和配置问题，如Ceph 16、Ceph 17、Erasure Coding等，这些信息对于理解和解决特定问题非常有帮助。 会议强调了社区交流的重要性，鼓励参与者在Cephalocon等活动中进行更多的面对面交流。 本次会议为Ceph社区成员提供了一个宝贵的交流机会，促进了知识和经验的共享，有助于提升Ceph集群的管理和性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-01-26","slug":"Ceph_Performance_Meeting_2023-01-26","date":"2023-01-30T16:00:00.000Z","updated":"2023-01-31T16:00:00.000Z","comments":true,"path":"2023/01/31/Ceph_Performance_Meeting_2023-01-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/31/Ceph_Performance_Meeting_2023-01-26/","excerpt":"","text":"会议纪要 主要议题 Etherpad 归档问题： 每年都会将Etherpad内容归档到前一年的文档中并重新开始。 发现一个配置问题导致复制粘贴操作在服务器端 silently fails，导致2021年的记录丢失。 2022年的记录已通过本地保存的副本恢复。 已调整服务器缓冲区大小，以防止未来再次发生类似问题。 新Pull Request讨论： 来自Igor的两个新PR： 第一个PR涉及在多块读取时不重置预取缓冲区，讨论了其在性能统计上的改进，但实际性能提升不明显。 第二个PR关于在飞行中启用RocksDB删除操作，讨论了其在实验中的应用和潜在的改进。 其他PR包括启用4K分配单元、用户边界迭代器等，讨论了其对性能的影响和后续的QA需求。 延迟峰值问题： 讨论了在升级到Pacific版本后出现的延迟峰值问题，最终确定是由于消息传递层的throttle机制导致的。 该throttle机制在Nautilus版本中被禁用，但在Pacific版本中被重新启用，导致了一些性能问题。 通过调整throttle设置和禁用该机制，延迟问题得到了改善。 写放大问题： 讨论了写放大问题，通过perf dump数据分析，发现升级到Pacific后，写操作的平均大小有所增加。 讨论了可能的原因，包括碎片化和元数据增加等，但尚未找到确切的原因。 提出了进一步分析RocksDB日志和监控数据的建议。 决定事项 调整Etherpad归档流程，确保未来不再丢失记录。 继续审查和测试新的Pull Request，特别是涉及性能改进的PR。 解决延迟峰值问题，通过调整或禁用throttle机制来优化性能。 进一步分析写放大问题，通过详细的日志分析和监控数据来寻找根本原因。 后续行动计划 完成对新PR的审查和测试，确保其对性能的影响得到充分评估。 继续监控和分析延迟峰值问题，确保所有相关设置和配置都已优化。 深入分析写放大问题，包括RocksDB日志和性能统计数据，以确定问题的根本原因并提出解决方案。 定期回顾和更新Etherpad归档流程，确保数据的安全性和完整性。 结论 本次会议讨论了多个关键议题，包括Etherpad归档问题、新Pull Request的审查、延迟峰值问题和写放大问题。通过详细的讨论和分析，团队确定了后续的行动计划，并将继续监控和优化系统性能。感谢所有参与者的贡献和努力。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2022-11-09","slug":"Ceph_RGW_Refactoring_Meeting_2022-11-09","date":"2023-01-29T16:00:00.000Z","updated":"2023-01-30T16:00:00.000Z","comments":true,"path":"2023/01/30/Ceph_RGW_Refactoring_Meeting_2022-11-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/30/Ceph_RGW_Refactoring_Meeting_2022-11-09/","excerpt":"","text":"Ceph 开发会议纪要 会议概要 本次会议主要讨论了关于Ceph存储系统中Sal（存储抽象层）的依赖管理和组织结构问题，特别是如何处理外部树（out-of-tree）驱动程序的依赖关系。会议还涉及了代码清理、模块化以及版本控制等议题。 主要议题 依赖管理与组织结构 讨论了如何组织Sal的依赖，特别是外部树驱动程序的依赖问题。 探讨了是否应该让外部树驱动程序依赖于self common库，以及如何避免这种依赖。 讨论了如何处理编码解码（encode/decode）和配置（config）相关的依赖。 模块化与版本控制 讨论了如何通过模块化减少依赖，特别是如何处理rgw common库的复杂性。 探讨了版本控制的重要性，特别是如何确保第三方驱动程序能够兼容不同版本的Ceph。 代码清理与优化 讨论了如何清理不必要的头文件包含，以提高编译速度和代码质量。 探讨了如何通过分离文件和模块来优化代码结构，特别是如何处理DB store与rgw的循环依赖问题。 决定事项 依赖管理 决定避免外部树驱动程序直接依赖于self common库，考虑通过分离和标准化部分功能来减少依赖。 模块化与版本控制 决定逐步将rgw common库中的功能分离出来，形成更小的模块，以便更好地管理和控制依赖。 强调了版本控制的重要性，特别是如何确保第三方驱动程序的兼容性。 代码清理 决定通过分离文件和模块来优化代码结构，特别是将rados specific的代码移动到store rados目录下。 决定通过分离文件和模块来优化代码结构，特别是将rados specific的代码移动到store rados目录下。 后续行动计划 依赖管理 继续研究和实施如何避免外部树驱动程序依赖于self common库。 考虑将部分功能从self common库中分离出来，形成独立的模块。 模块化与版本控制 继续推进rgw common库的模块化工作，形成更小的、独立的模块。 研究和实施版本控制策略，确保第三方驱动程序的兼容性。 代码清理 继续清理不必要的头文件包含，提高编译速度和代码质量。 通过分离文件和模块来优化代码结构，特别是处理DB store与rgw的循环依赖问题。 关键词 Ceph Sal 外部树驱动程序（out-of-tree drivers） self common库 编码解码（encode/decode） 配置（config） 模块化 版本控制 代码清理 结论 本次会议明确了Ceph存储系统中Sal层的依赖管理和组织结构问题，特别是如何处理外部树驱动程序的依赖关系。通过模块化和版本控制策略，以及代码清理工作，将有助于提高系统的稳定性和可维护性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2022-11-02","slug":"Ceph_RGW_Refactoring_Meeting_2022-11-02","date":"2023-01-26T16:00:00.000Z","updated":"2023-01-26T16:00:00.000Z","comments":true,"path":"2023/01/27/Ceph_RGW_Refactoring_Meeting_2022-11-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/27/Ceph_RGW_Refactoring_Meeting_2022-11-02/","excerpt":"","text":"会议纪要 会议主题： 讨论关于Ceph的多对象删除（multi-delete PR）的实现细节和性能优化。 参会人员： Jason Corey Casey Rick 其他相关开发人员 主要讨论内容： 多对象删除并发限制 Corey提出在多对象删除操作中，当前实现会为每个对象启动一个新的协程进行并发删除，但需要设置一个上限来限制同时启动的协程数量。 建议引入一个新的配置参数来控制并发协程的数量，以避免对集群造成过大的IOPS压力。 Casey建议是否需要单独的配置变量，或可以考虑其他现有的配置方式。 性能问题与优化 Corey提到当前的生产集群使用的是旋转磁盘，且使用了Erasure Coding（8+3），多对象删除操作会导致大量的IOPS，影响集群性能。 提出另一个配置对象的设想，即不让RGW在head对象中存储任何数据，仅存储元数据，以便删除操作可以在NVMe上进行，提高删除操作的性能。 讨论了是否可以通过配置Zone placement来实现这一功能，而不是通过cephconfig变量。 存储类别的交互 讨论了存储类别（storage classes）的配置，以及如何通过配置不同的存储类别来影响head对象的数据存储。 提到可以通过Bucket级别的配置来设置默认的存储类别，从而影响head对象的数据存储方式。 数据与元数据的存储策略 讨论了为什么数据需要与head对象一起存储，主要是为了减少或避免额外的RADOS操作，特别是对于小对象。 提出在特定情况下，如使用快速存储（如NVMe）时，可以考虑分离数据和元数据的存储，以提高性能。 决定事项： Corey将开启一个新的PR，涉及上述讨论的配置变更，并在现有的PR中添加QoS相关的提交。 将继续在GitHub上讨论这些变更的细节。 后续行动计划： Corey将提交新的PR并添加相关提交。 开发团队将在GitHub上进一步讨论和审查这些变更。 其他事项： 提醒开发者注意即将到来的开发者月度会议和虚拟Cephalicon会议。 会议结束： 会议在讨论完所有议题后结束，未有其他紧急讨论事项。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2022-11-23","slug":"Ceph_RGW_Refactoring_Meeting_2022-11-23","date":"2023-01-26T16:00:00.000Z","updated":"2023-01-26T16:00:00.000Z","comments":true,"path":"2023/01/27/Ceph_RGW_Refactoring_Meeting_2022-11-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/27/Ceph_RGW_Refactoring_Meeting_2022-11-23/","excerpt":"","text":"会议纪要 会议主题：对象 Lambda (Object Lambda) 的讨论 与会人员：Ceph 研发团队成员 会议时间：[具体时间] 会议地点：[具体地点] 主要议题： 对象 Lambda 与 AWS 对象 Lambda 的比较 讨论了对象 Lambda 与 AWS 对象 Lambda 的差异，特别是 AWS 对象 Lambda 支持多种语言，并且通过不同的 URL 来处理对象的获取。 强调了在处理大型对象时的性能和资源分配问题，建议考虑外部处理以避免对 RGW（RADOS Gateway）的性能影响。 处理方式的选择 探讨了内联处理与离线处理的优劣，特别是内联处理在某些场景下的必要性，如数据匿名化等。 讨论了使用不同 URL 来区分处理请求的可能性，以及如何实现这一机制。 技术方案的探索 提到了使用多站点（multi-site）方案的不可行性，以及考虑使用外部服务来处理对象 Lambda 的可能性。 讨论了与 IBM Fabric 技术的结合，以及如何利用现有的服务器less函数套件来增强功能。 后续行动计划 继续探索和评估外部处理方案，特别是那些可以与 S3 接口兼容的方案。 考虑在 RGW 之外建立一个弹性计算设施，以实现更好的资源管理和扩展性。 讨论了与 Spark 和其他大数据生态系统的集成，特别是如何优化数据处理和查询推送。 决定事项： 需要进一步研究和测试外部处理方案，以确定最佳实践。 计划与相关团队（如 Ronancott 团队）进行更深入的讨论，以探索技术整合的可能性。 将持续关注和评估与 Spark 和其他大数据工具的集成，以提高数据处理的效率和灵活性。 后续行动： 安排与 Eric 的会议，讨论 aeroflight 技术的进一步开发和集成。 继续与 Ali 合作，探索 Spark 连接器的开发和优化。 评估和优化 S3 select 的功能，特别是在 Spark Catalyst 中的应用。 会议总结： 本次会议主要围绕对象 Lambda 的功能和实现进行了深入讨论，特别是在如何平衡性能和资源管理方面。团队决定探索外部处理方案，并继续优化与大数据生态系统的集成。会议强调了持续研究和测试的重要性，以确保技术方案的有效性和可行性。 下次会议预告： 讨论 aeroflight 技术的进展和 Spark 集成方案。 评估 S3 select 在 Spark 中的应用和优化。 感谢所有与会者的积极参与和宝贵意见，期待下次会议的进一步讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-01-25","slug":"Ceph_Crimson_SeaStore_Meeting_2023-01-25","date":"2023-01-24T16:00:00.000Z","updated":"2023-01-24T16:00:00.000Z","comments":true,"path":"2023/01/25/Ceph_Crimson_SeaStore_Meeting_2023-01-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/25/Ceph_Crimson_SeaStore_Meeting_2023-01-25/","excerpt":"","text":"会议纪要 会议时间: 春节假期期间 参会人员: 团队成员 会议主持: 未知 会议记录: 未知 主要议题与讨论内容 上周工作回顾 集群维护与构建: 主要工作集中在确保长期运行的集群能够支持K仓库的运作，以便进行8次构建，从而再次构建Crimson。目前Crimson已经能够成功构建，这是一个积极的进展。 故障排查: 正在调查一个无序操作（out of order op）的bug，该bug在几乎所有的Crimson运行中都会出现。 个人假期安排 有成员计划在春节期间休息两天。 当前工作重点 讨论了关于多OSD（Object Storage Daemon）的更新问题，但具体细节未详细展开。 决定事项 会议决定保持简短，未进行深入的技术讨论或决策。 后续行动计划 继续监控和解决Crimson构建中的无序操作bug。 团队成员根据个人计划进行假期安排。 会议结束 会议在简短的交流后结束，参会人员互相祝福假期愉快。 备注: 由于会议时间较短且内容较为零散，具体的行动计划和技术细节需要后续进一步明确和跟进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2023-01-24","slug":"Ceph_Orchestrator_2023-01-24","date":"2023-01-24T16:00:00.000Z","updated":"2023-01-25T16:00:00.000Z","comments":true,"path":"2023/01/25/Ceph_Orchestrator_2023-01-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/25/Ceph_Orchestrator_2023-01-24/","excerpt":"","text":"会议纪要 主要议题 systemd 服务启动超时问题 问题描述：在 systemd 服务启动超时时，由于 kill mode 设置为 none，容器进程不会被终止，导致服务处于失败状态但进程仍在运行。 解决方案：通过 PR 修改，确保在服务启动失败时执行 post-stop 操作，以确保容器进程被正确终止。 决定：该 PR 已经过测试并被接受，计划合并到主分支。 iSCSI 问题与 host.containers.internal 条目 问题描述：host.containers.internal 条目导致 iSCSI 问题。 临时解决方案：通过挂载主机版本的 seos 来解决，但需要进一步研究和测试。 后续行动：计划进行更多实验和讨论，以确定最佳长期解决方案。 SSH 密钥验证问题 问题描述：当前存在 SSH 密钥验证不足的问题，可能导致错误密钥被接受。 解决方案：建议使用现有库进行密钥验证，并更新相关文档。 后续行动：检查并更新文档，确保用户使用正确的密钥设置方法。 决定事项 合并 systemd 服务启动超时问题的 PR。 临时使用挂载主机 seos 的解决方案，同时进行更多研究和测试以确定长期解决方案。 更新 SSH 密钥设置的文档，确保用户使用正确的验证方法。 后续行动计划 完成 systemd 服务启动超时问题 PR 的合并。 进行更多实验和测试，以确定 host.containers.internal 条目的最佳解决方案。 更新并验证 SSH 密钥设置的文档，确保用户使用正确的密钥验证方法。 其他讨论 讨论了关于容器网络设置和 podman 的潜在问题，但未形成具体决议。 会议结束 会议在讨论完所有议题后结束，下次会议将继续跟进上述议题的进展。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2022-11-30","slug":"Ceph_RGW_Refactoring_Meeting_2022-11-30","date":"2023-01-23T16:00:00.000Z","updated":"2023-01-24T16:00:00.000Z","comments":true,"path":"2023/01/24/Ceph_RGW_Refactoring_Meeting_2022-11-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/24/Ceph_RGW_Refactoring_Meeting_2022-11-30/","excerpt":"","text":"会议纪要 主要议题 文档配置变量标签化 Ali正在为文档中的所有配置变量添加标签，以确定它们是否可以在运行时设置或更改。 已经创建了一个PR并渲染了文档，下一步计划是通过审计所有配置变量来进一步完善。 建议使用Pad而不是Google Sheet来共享和更新这些变量的信息。 RADOS中的竞价持久化问题 讨论了在RADOS中持久化竞价信息的问题，特别是如何在不违反现有规则的情况下处理这些信息。 提出了使用CLS锁和XAttr来存储竞价信息，但遇到了持久化和错误返回的复杂性。 计划与RADOS团队进一步讨论，寻找解决方案。 RGW开发入门文档 讨论了为新开发者提供的入门文档，建议参考upstream.com上的资源。 强调了RGW作为S3层的重要性，并欢迎新贡献者加入。 测试和代码重构 讨论了多个PR的测试和重构问题，包括Caleb和Matt的PR。 计划合并相关PR，以减少未来的重构工作量。 Neorados的合并问题 讨论了Neorados的合并问题，计划重新运行测试并联系RBD团队以获取反馈。 决定事项 使用Pad来管理配置变量的审计和更新。 继续与RADOS团队讨论竞价信息的持久化问题。 合并Caleb和Matt的PR，以减少未来的重构工作量。 重新运行Neorados的测试，并联系RBD团队以获取反馈。 后续行动计划 Ali将继续完善配置变量的审计工作，并使用Pad进行信息共享。 与RADOS团队进一步讨论竞价信息的持久化问题，并寻找解决方案。 Caleb和Matt将合并他们的PR，并进行必要的重构和测试。 重新运行Neorados的测试，并联系RBD团队以获取反馈。 其他 欢迎新开发者加入，并提供了入门文档和开发环境的设置建议。 鼓励新贡献者通过bug tracker中的“low hanging fruit”标签寻找简单任务开始贡献。 会议结束 会议在讨论完所有议题后结束，感谢所有参与者的贡献。 下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-01-04","slug":"Ceph_RGW_Refactoring_Meeting_2023-01-04","date":"2023-01-22T16:00:00.000Z","updated":"2023-01-23T16:00:00.000Z","comments":true,"path":"2023/01/23/Ceph_RGW_Refactoring_Meeting_2023-01-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/23/Ceph_RGW_Refactoring_Meeting_2023-01-04/","excerpt":"","text":"会议纪要 会议主题： 讨论应用程序一致性保证中的复制可靠性问题 参会人员： 发言人（未提及姓名） Casey 其他未提及姓名的参与者 主要议题： 复制可靠性与一致性保证 讨论了当前Ceph系统中复制的可靠性问题，特别是数据日志条目的更新问题。 确认了当前系统在操作日志方面是事务性的，但在数据日志条目更新方面存在潜在问题。 潜在问题分析 数据日志条目的更新是尽力而为的，如果未能更新，可能导致复制停滞。 这种停滞可能由多种原因引起，包括集群分区或环境错误等。 解决方案讨论 提出了两种可能的解决方案： 使数据日志条目的更新变得事务性，但这可能会增加成本。 定期检查并处理停滞的复制，例如通过定期扫描所有桶并触发同步。 讨论了定期扫描策略的可行性和效率。 后续行动计划 需要进一步研究如何实现数据日志条目的事务性更新或定期扫描策略。 需要检查和处理可能导致数据日志更新失败的潜在错误或配置问题。 决定事项： 确认了当前系统在复制可靠性方面存在的问题，并同意需要进一步研究和改进。 决定探索实现数据日志条目事务性更新的可能性，以及定期扫描策略的实施细节。 后续行动： 研究并实现数据日志条目的事务性更新或定期扫描策略。 检查和处理可能导致数据日志更新失败的潜在错误或配置问题。 其他讨论： 讨论了Ceph系统中的一些其他技术细节，如RADOS的使用和数据日志的存储位置。 确认了需要进一步关注和解决的问题，特别是在系统崩溃后的恢复机制。 会议结束： 会议在讨论了其他潜在议题后结束，参与者互相祝福新年快乐并期待下次会议。 备注： 会议中提到的具体技术细节和代码问题需要进一步的技术文档或代码审查来详细了解和处理。 会议总结人： [您的姓名] 日期： [会议日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-01-08","slug":"Ceph_RGW_Refactoring_Meeting_2023-01-08","date":"2023-01-22T16:00:00.000Z","updated":"2023-01-23T16:00:00.000Z","comments":true,"path":"2023/01/23/Ceph_RGW_Refactoring_Meeting_2023-01-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/23/Ceph_RGW_Refactoring_Meeting_2023-01-08/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统的工作流程重构和异步编程改进 与会人员：Matt等 会议日期：[具体日期未提供] 会议地点：[具体地点未提供] 主要议题： 工作计划和团队重组：讨论了当前团队的工作流程重构和异步编程改进计划。 异步编程和线程池优化：探讨了如何通过异步编程和线程池优化来提高系统效率，特别是在前端线程池的管理上。 C++20协程和异步重构：讨论了C++20协程的使用和异步编程的重构工作，包括如何处理阻塞调用和优化并发控制。 Zipper接口和模块化：讨论了Zipper接口的改进和模块化的进展，以及如何处理遗留的阻塞调用。 新功能和代码冻结：讨论了即将到来的代码冻结和需要合并的新功能，特别是S3选择功能的JSON格式。 决定事项： 异步编程改进：决定继续推进异步编程的改进，特别是在前端线程池的管理和阻塞调用的处理上。 C++20协程应用：将继续推进C++20协程的应用，特别是在多站点和元数据同步方面。 Zipper接口改进：将改进Zipper接口，确保其支持异步编程，并处理遗留的阻塞调用。 代码冻结和新功能：即将进行代码冻结，将优先处理已合并功能的稳定化，新功能如S3选择功能的JSON格式将在冻结前尽可能合并。 后续行动计划： 异步编程和线程池优化：继续推进异步编程的改进，特别是在前端线程池的管理和阻塞调用的处理上。 C++20协程应用：继续推进C++20协程的应用，特别是在多站点和元数据同步方面。 Zipper接口改进：改进Zipper接口，确保其支持异步编程，并处理遗留的阻塞调用。 代码冻结和新功能：进行代码冻结，优先处理已合并功能的稳定化，新功能如S3选择功能的JSON格式将在冻结前尽可能合并。 其他事项： Shaman构建问题：Shaman构建的Java问题已解决，构建流程已恢复正常。 FIFO分支合并：FIFO分支已准备好进行测试和合并，以推进多站点稳定化工作。 下次会议： 下次会议时间：[未提供具体时间] 下次会议议题：[未提供具体议题] 会议结束语： 感谢所有参与者的贡献，期待下次会议再见。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023--01-19","slug":"Ceph_Performance_Meeting_2023--01-19","date":"2023-01-19T16:00:00.000Z","updated":"2023-01-19T16:00:00.000Z","comments":true,"path":"2023/01/20/Ceph_Performance_Meeting_2023--01-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/20/Ceph_Performance_Meeting_2023--01-19/","excerpt":"","text":"会议纪要 关键细节与讨论主题 构建问题修复： 会议开始时，提到了一个与性能无关的构建问题已经修复，这是一个长期存在的问题，之前一直在使用Luster系统。 Pull Requests (PRs) 讨论： 有界迭代器 (Bounded Iterators)：Igor提出了一个关于ARM范围键的有界迭代器的PR，涉及RocksDB性能下降问题，特别是与map clear函数和多个列族的迭代有关。 Arrow Flight功能：讨论了添加Arrow Flight功能的初始提交，这是一个RPC框架，用于低延迟数据传输，尽管当前实现方式有些粗糙，但提供了实验的基础。 硬件文档重写：一个关于重写硬件文档的旧PR被关闭，可能已被新文档取代。 性能与优化讨论： RBD镜像快照性能：Adam的工作显著提高了RBD镜像和快照的速度，可能使得之前的工作变得不必要。 写放大问题：Josh提到了在从Nautilus升级到Pacific时观察到的写放大问题，特别是在RBD方面，尽管在RGW方面没有观察到类似问题。 决定事项 对于有界迭代器的PR，决定继续测试并可能进行后向移植。 对于Arrow Flight功能的PR，决定继续实验并寻找更好的实现模型。 对于硬件文档重写的PR，决定关闭，因为可能已被新文档取代。 后续行动计划 继续测试和优化有界迭代器的PR，确保其性能和稳定性。 进一步实验Arrow Flight功能，探索其在RGW和OSD集成中的潜力。 调查和解决写放大问题，特别是通过分析RBD和RGW的性能数据，以及可能的配置调整。 继续监控和优化RBD镜像和快照的性能，确保Adam的工作在生产环境中稳定运行。 其他备注 会议超时，决定将未讨论完的话题推迟到下一次会议。 对于写放大问题，Josh计划在staging环境中进行更多测试，特别是关于小块写操作的影响。 参会人员 会议由Josh主持，Igor、Adam、Corey等参与讨论。 结论 会议涵盖了多个技术议题，包括构建问题的解决、新功能的讨论和性能问题的深入分析。团队将继续在这些领域进行工作，以确保Ceph系统的稳定性和性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-01-18","slug":"Ceph_Crimson_SeaStore_Meeting_2023-01-18","date":"2023-01-18T16:00:00.000Z","updated":"2023-01-19T16:00:00.000Z","comments":true,"path":"2023/01/19/Ceph_Crimson_SeaStore_Meeting_2023-01-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/19/Ceph_Crimson_SeaStore_Meeting_2023-01-18/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 会议议题： 实验室状态更新 代码审查与问题修复 技术讨论：多调用信使（multiple call messenger）实现 关键细节： 实验室状态： 实验室再次出现问题，具体影响Centos 8构建，特别是Crimson需要的关键仓库。 正在积极调试，与rgw实例在实验室中的工作有关。 预计问题将在明天解决。 代码审查与问题修复： 本周主要工作包括帮助实验室事务和代码审查。 修复了Sistar Upstream代码中的内存泄漏问题，并提交了PR以更新子模块版本。 技术讨论： 讨论了多调用信使的实现，特别是OSD和PG共享管理器的策略。 提出了模拟多调用信使的方案，以便在实际实现前进行测试。 讨论了OSD和PG共享管理器的具体实现细节，包括请求分发和处理逻辑。 决定事项： 实验室问题： 继续监控实验室状态，等待问题解决。 代码审查与问题修复： 继续进行代码审查和问题修复工作。 技术实现： 确定了多调用信使的模拟方案，以便在实际实现前进行测试。 讨论并初步确定了OSD和PG共享管理器的实现策略，包括请求分发和处理逻辑。 后续行动计划： 实验室问题： 继续监控实验室状态，及时更新团队成员。 代码审查与问题修复： 继续进行代码审查和问题修复工作，确保代码质量和稳定性。 技术实现： 实施多调用信使的模拟方案，进行测试和验证。 根据讨论结果，进一步细化OSD和PG共享管理器的实现方案，并开始编码实现。 其他事项： 假期安排： 考虑到即将到来的中国春节，部分成员将休假两周。 会议结束： 会议在讨论完所有议题后结束，团队成员互相道别，期待下周再见。 备注：本会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了信息的完整性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2023-01-18","slug":"Ceph_RGW_Refactoring_Meeting_2023-01-18","date":"2023-01-18T16:00:00.000Z","updated":"2023-01-19T16:00:00.000Z","comments":true,"path":"2023/01/19/Ceph_RGW_Refactoring_Meeting_2023-01-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/19/Ceph_RGW_Refactoring_Meeting_2023-01-18/","excerpt":"","text":"会议纪要 关键细节 参与者: Maui, Yehuda, Adam, Matt, Mia, 以及其他未明确提及的团队成员。 日期: 未明确提及，但从讨论内容推断为近期。 主要议题: 可选yield的更新。 多站点和墓碑缓存的使用。 多站点和zipper工作的协同。 同步策略的更新。 讨论的主要议题 可选yield的更新: Maui报告了一个关于create bucket的PR，讨论了两种方法：文件逐个处理和整体处理。 讨论了在服务中增加可选yield的好处，特别是对于rgw和rados的改进。 决定将工作分配给其他团队成员，并计划进行性能基准测试。 多站点和墓碑缓存的使用: 讨论了多站点中使用墓碑缓存来解决删除对象的时间戳问题。 提出了缓存不完整的问题，特别是在多个网关的情况下。 讨论了可能的解决方案，包括将缓存移至rados，以及对同步操作的序列化问题。 多站点和zipper工作的协同: 讨论了将多站点工作与zipper结合的可能性，以实现存储无关的复制。 提出了对现有代码的修改和潜在的时间压力问题。 同步策略的更新: 讨论了同步策略的需求，包括在桶级别启用或禁用同步，以及跟踪同步状态的问题。 提出了对现有同步策略的修改和潜在的复杂性问题。 决定的事项 将可选yield的工作分配给其他团队成员，并计划进行性能基准测试。 对多站点的墓碑缓存问题进行进一步的研究和讨论，以寻找解决方案。 对同步策略的需求进行进一步的研究和讨论，以寻找解决方案。 后续的行动计划 Maui将联系calpash并帮助其加速上手相关工作。 对多站点的墓碑缓存问题进行进一步的研究和讨论，以寻找解决方案。 对同步策略的需求进行进一步的研究和讨论，以寻找解决方案。 对新的Centos 9和Ubuntu 22的兼容性问题进行进一步的研究和讨论，以寻找解决方案。 其他事项 由于基础设施问题，Reef版本的冻结和发布将推迟最多三个月。 讨论了rgw套件在新版本Centos和Ubuntu上的兼容性问题，并计划组织相关跟踪问题。 结论 会议涵盖了多个技术议题，包括性能优化、缓存策略、同步策略和兼容性问题。团队决定采取一系列行动来解决这些问题，并计划进行进一步的研究和讨论。此外，由于基础设施问题，Reef版本的发布将推迟，为团队提供了额外的时间来稳定和优化相关功能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2023-01-11","slug":"Ceph_Crimson_SeaStore_Meeting_2023-01-11","date":"2023-01-11T16:00:00.000Z","updated":"2023-01-12T16:00:00.000Z","comments":true,"path":"2023/01/12/Ceph_Crimson_SeaStore_Meeting_2023-01-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/12/Ceph_Crimson_SeaStore_Meeting_2023-01-11/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： OS 8 构建问题 上周发送的 OS 8 构建未成功，导致 Crimson 构建也未能工作。 问题根源与去年十月份出现的问题相同，Gluster 集群底层基础设施损坏了部分 VM 磁盘。 目前正在进行将基础设施从 Gluster 迁移的工作，但尚未完成。 Ceph Java 绑定问题 构建失败的唯一用户是 Ceph JNI 绑定，但这些绑定并不十分重要。 如果未来24小时内无法修复，计划完全禁用 Ceph 的 Java 相关功能。 Dan 认为他有一个修复方案，可能已经解决了问题。 Crimson 测试更新 由于构建问题，Crimson 的测试工作受到阻碍。 正在设置一个四节点的 Twister 集群进行测试。 目前没有 Crimson 的 Reef 构建镜像，因此使用 Quincy 进行测试。 正在更新上游跟踪器，并与 Nixon 沟通获取更多信息。 Kevin 的加入与工作更新 Kevin 首次参加 Crimson 会议，希望了解当前开发情况并提供帮助。 Kevin 正在处理一些 Ceph 64 的 bug 修复。 内存泄漏问题 发现了内存泄漏的根源，与 CPU 核心间的内存管理有关。 正在测试修复方案，并计划提交给社区。 决定事项： 如果 Ceph Java 绑定在24小时内无法修复，将禁用相关功能。 继续进行 Crimson 的测试和文档工作。 解决内存泄漏问题，并提交修复方案给社区。 后续行动计划： 继续监控和解决 OS 8 构建问题。 完成 Crimson 的测试和文档工作。 测试并提交内存泄漏的修复方案。 其他事项： 会议结束时，希望在接下来的24小时内解决构建问题。 会议总结： 会议讨论了多个技术问题，包括 OS 8 构建失败、Ceph Java 绑定问题、Crimson 测试更新以及内存泄漏问题。团队成员正在积极寻找解决方案，并计划在短期内完成相关工作。希望在接下来的24小时内解决构建问题，以便继续推进其他工作。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-01-12","slug":"Ceph_Performance_Meeting_2023-01-12","date":"2023-01-11T16:00:00.000Z","updated":"2023-01-12T16:00:00.000Z","comments":true,"path":"2023/01/12/Ceph_Performance_Meeting_2023-01-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/12/Ceph_Performance_Meeting_2023-01-12/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了关于Ceph存储系统的多个Pull Request（PR），包括优先操作、RocksDB迭代器平衡、删除范围操作的改进等。同时，会议还涉及了未来的研究方向和计划。 主要议题 Pull Request讨论 优先操作PR：讨论了新的PR，涉及优先操作和插件。 RocksDB迭代器平衡PR：来自Corey的PR，关于设置RocksDB迭代器的平衡或集合列表。 删除范围操作改进：讨论了升级到最新版本的RocksDB，以改进删除范围操作，特别是针对memtable的刷新。 RocksDB迭代器行为 讨论了使用无界迭代器导致的性能问题，并提出了添加边界迭代器的解决方案。 讨论了在特定情况下（如PG移动）使用单个删除操作的必要性。 研究方向和计划 讨论了恢复研究讨论的计划，包括定期讨论相关研究论文和想法。 提出了使用性能调用或其他会议时间来讨论研究主题的建议。 决定事项 将继续审查和测试涉及RocksDB迭代器和删除范围操作的PR。 确定了恢复研究讨论的计划，并计划定期讨论相关研究论文。 后续行动计划 对涉及RocksDB迭代器和删除范围操作的PR进行进一步的测试和审查。 组织定期的研究讨论会议，收集和讨论相关的研究论文和想法。 继续推进快照和对象克隆在Blue Store中的优化工作。 其他事项 讨论了Blue Store中快照和对象克隆的优化进展，包括减少共享blob的数量和优化克隆操作。 提到了Adam Kupchak的工作，他在改进快照和对象克隆的性能方面取得了进展。 会议结束时，大家对未来的研究讨论表示期待，并计划在下次会议中继续跟进相关进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-10-05","slug":"Ceph_Developer_Monthly_2022-10-05","date":"2023-01-10T16:00:00.000Z","updated":"2023-01-11T16:00:00.000Z","comments":true,"path":"2023/01/11/Ceph_Developer_Monthly_2022-10-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/11/Ceph_Developer_Monthly_2022-10-05/","excerpt":"","text":"会议纪要 - Ceph 开发者月度会议 (October CDM) 会议概览 日期: October 主持人: Laura 参会人员: Ceph 开发团队成员及相关领域专家 主要议题 用户体验增强 议题: 改进 Ceph 容器的挂载机制 讨论内容: 当前 Ceph 容器（包括实际容器和 safadm shell 容器）对整个根文件系统进行绑定挂载，导致某些行为难以调试。特别是用户遇到内核 RBD 设备取消映射的问题，由于设备被运行中的容器固定。 决定事项: 需要改进挂载机制，建议采用更小范围的目标挂载或仅传递所需的个别文件。 后续行动: Adam 和 Elmer 将进一步讨论和实施这一改进。 仪表板可访问性改进 发言人: Cedric 讨论内容: 介绍了 Ceph 仪表板在可访问性方面的改进，特别是针对视障用户的优化。通过遵循 W3C 的可访问性标准，确保 Blind 和 Visually Impaired 用户也能舒适使用。 展示: 展示了登录页面、仪表板主页和数据表的改进，包括颜色对比度调整和屏幕阅读器兼容性增强。 后续行动: 继续优化可访问性，包括实现暗模式主题和完善开发指南中的可访问性部分。 仪表板主页更新 发言人: Pedro Gonzalez 讨论内容: 介绍了仪表板主页的更新计划，旨在展示更有意义的数据，并提高用户访问的便捷性。 展示: 展示了新设计的仪表板主页草图，包括详细信息卡、集群状态、容量卡、库存卡和集群利用率图表。 后续行动: 继续开发和优化新主页的样式和功能，计划在未来的版本中发布。 性能提升 议题: 管理器架构提案 发言人: Perry 讨论内容: 提出了一个新的管理器架构，旨在消除 Python 解释器的全局解释器锁（GIL），通过 gRPC 服务器将模块移至不同的进程中，以提高性能和并发处理能力。 后续行动: 开发团队将根据反馈继续完善这一架构，并进行性能测试。 性能提升 议题: 新的 Ceph 导出器 发言人: Evan 讨论内容: 介绍了新的 Ceph 导出器，这是一个每节点设计的导出器，用于从每个守护进程获取性能计数器，并通过 HTTP 暴露给 Prometheus。 展示: 展示了导出器的实现和如何在实际集群中运行。 后续行动: 继续测试和优化导出器，特别是在大规模集群中的性能。 RBD-like 虚拟磁盘 发言人: Peter 讨论内容: 介绍了基于对象翻译层的虚拟磁盘设计，通过批量写入和垃圾回收机制减少对后端设备的 I/O 负载。 后续行动: 继续开发和测试这一设计，目标是将其从学术代码转化为实际可用的库。 结论 本次会议涵盖了多个关键议题，从用户体验的改进到性能的提升，以及新技术的探索。各议题的讨论和展示为 Ceph 的未来发展提供了宝贵的见解和方向。感谢所有参与者的贡献，期待在未来的会议中继续推进这些重要的开发工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-01-10","slug":"Ceph_Orchestrator_Meeting_2023-01-10","date":"2023-01-09T16:00:00.000Z","updated":"2023-01-10T16:00:00.000Z","comments":true,"path":"2023/01/10/Ceph_Orchestrator_Meeting_2023-01-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/10/Ceph_Orchestrator_Meeting_2023-01-10/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了关于Ceph项目的一些技术问题和开发进展，特别是关于文档恢复、编译工作、依赖管理以及测试和构建流程的优化。 主要议题 文档恢复 发现部分文档（特别是“orchestration weekly”）信息丢失，其他文档已恢复。 计划重新设置主文档，并从2021年的存档中移除不需要的信息。 编译工作与依赖管理 讨论了在Ceph二进制文件中包含其他依赖包的可能性，之前由于技术限制未能实现。 计划在分支中进行实验，测试添加依赖项的可行性，并评估其在主分支中的实施时机。 测试与构建流程 讨论了容器化构建的进展和需要解决的问题，特别是Java构建问题。 强调了继续进行单元测试和代码覆盖率检查的重要性。 决定事项 重新设置主文档，移除过时信息，并从2021年的存档中恢复必要内容。 在分支中进行依赖管理的实验，以评估其对主分支的影响。 继续推进容器化构建和单元测试，确保代码质量和构建流程的稳定性。 后续行动计划 完成主文档的重新设置工作。 在实验分支中测试依赖管理的可行性，并根据测试结果决定是否合并到主分支。 继续解决Java构建问题，并推进容器化构建的实施。 加强单元测试和代码覆盖率检查，确保代码质量。 其他讨论 讨论了未来可能的开发方向和功能扩展，但目前不作为紧急任务。 强调了与团队成员的沟通和协作，特别是在处理基础设施问题时。 会议结束 会议在讨论完所有议题后结束，计划下周再次召开会议。 备注 会议中提到的“Reef release”和“Quincy release”是Ceph项目的未来版本计划。 强调了团队成员之间的积极沟通和协作，特别是在处理复杂技术问题时。 以上是对本次会议内容的详细总结，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-12-07","slug":"Ceph_Developer_Monthly_2022-12-07","date":"2023-01-05T16:00:00.000Z","updated":"2023-01-06T16:00:00.000Z","comments":true,"path":"2023/01/06/Ceph_Developer_Monthly_2022-12-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/06/Ceph_Developer_Monthly_2022-12-07/","excerpt":"","text":"会议纪要 会议时间 会议开始时间：可能比预定时间晚了几分钟。 会议议题 Depend About 介绍 演讲者：Northeastern University 的研究生，研究信息系统。 内容概述： Depend About 是一个帮助项目管理依赖更新的工具，确保项目依赖安全。 当前项目中，开发者可能会因为依赖版本未更新而浪费大量时间。 Depend About 通过自动化依赖更新，减少开发者的工作量。 功能包括版本更新和安全警报，支持多种编程语言和包管理器。 实现细节包括获取当前依赖列表及其版本，自动创建 PR 等。 Ceph 的 Scrub 调度改进 演讲者：Ronin。 内容概述： 介绍了当前 Ceph 中 Scrub 调度的实现和存在的问题。 提出了改进方案，包括引入 Scrub Target 和 Urgency 字段，优化调度逻辑。 讨论了改进后的调度逻辑如何提高可见性和效率，减少资源浪费。 强调了代码的可维护性和用户可见性的重要性。 Ceph 中的假设和问题 演讲者：Sridhar、Radic 和 Adam。 内容概述： 讨论了在容器化环境中，多个 OSD 使用同一设备导致的问题。 提出了使用 exclusive 标志来确保设备独占使用的解决方案。 讨论了不同操作系统的兼容性和未来的改进方向。 决定事项 Depend About 工具的介绍和其在项目中的应用。 Ceph 的 Scrub 调度改进方案，包括引入新的数据结构和优化调度逻辑。 针对容器化环境中 OSD 设备独占使用的解决方案。 后续行动计划 继续开发和测试 Depend About 工具，确保其稳定性和效率。 实施并测试 Ceph 的 Scrub 调度改进方案，关注其对用户可见性和系统性能的影响。 进一步研究和测试 exclusive 标志在不同操作系统和环境中的表现，确保解决方案的通用性和可靠性。 更新相关文档和发布说明，确保用户和开发者了解新的变化和改进。 其他备注 会议中提到的改进和解决方案需要在实际环境中进行充分测试，确保其有效性和稳定性。 需要关注用户反馈，及时调整和优化方案，确保满足用户需求。 结束语 感谢所有参与者的积极参与和贡献，期待下一次会议的进一步讨论和成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2023-01-03","slug":"Ceph_Orchestrator_Meeting_2023-01-03","date":"2023-01-05T16:00:00.000Z","updated":"2023-01-06T16:00:00.000Z","comments":true,"path":"2023/01/06/Ceph_Orchestrator_Meeting_2023-01-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/06/Ceph_Orchestrator_Meeting_2023-01-03/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 会议议题： Ceph项目更新 讨论了Ceph项目的最新进展，包括PR（Pull Request）的审核和测试运行情况。 提到了Ceph基础设施的问题，如Seth dot IO网页宕机和自动化测试中大量作业失败的情况。 文档团队活动 讨论了文档团队在假期期间的活动，特别是关于文档更新的问题，如Quincy分支的文档变更未被正确发布。 项目管理和基础设施 讨论了项目管理和基础设施的稳定性问题，包括旧PR的清理和Ghostf项目的活跃度。 决定事项： 需要重新检查和重新运行之前的测试，以确保Ceph基础设施的稳定性。 需要关注并解决文档更新未被正确发布的问题。 对于旧PR的清理工作表示肯定，认为这是一个积极的进展。 后续行动计划： 重新激活并跟进之前的工作，特别是与Ceph相关的PR和测试。 检查并修复文档更新的问题，确保所有分支的文档变更都能正确发布。 继续监控Ceph基础设施的稳定性，并及时解决出现的问题。 备注： 会议中提到的具体技术细节和内部讨论内容未在会议记录中详细展开，以保护项目内部信息的安全性。 会议结束时间：[具体时间] 下次会议预告：[具体日期和时间] 会议记录人：[记录人姓名] 审核人：[审核人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-12-08","slug":"Ceph_Performance_Meeting_2022-12-08","date":"2023-01-05T16:00:00.000Z","updated":"2023-01-06T16:00:00.000Z","comments":true,"path":"2023/01/06/Ceph_Performance_Meeting_2022-12-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/06/Ceph_Performance_Meeting_2022-12-08/","excerpt":"","text":"会议纪要 关键细节 Pull Request 审查: 会议开始时，主持人提到他已经完成了所有 Pull Request 的审查，并更新了列表。 RGW 更新: 讨论了一个关于 RGW 的更新 PR，特别是与 d4n 相关的部分。 RocksDB 更新: 讨论了是否应该尝试更新 RocksDB 到最新版本，以支持新的压缩选项。 BlueFS 4K 分配单元: 提到了一个关于 BlueFS 启用 4K 分配单元的 PR，但因相关人员不在场而未深入讨论。 BlueStore 分配器优化: 讨论了一个关于 BlueStore 中 AVL 和混合分配器加速的 PR，需要进一步审查。 主要议题 性能优化: Luke 讨论了他们尝试优化 Ceph 集群性能的策略，包括使用 RAID 配置和不同存储配置的测试。 网络和存储配置: 讨论了网络配置、RAID 级别选择、Erasure Coding 与复制的性能影响，以及如何诊断和优化 RGW 的性能问题。 硬件和软件配置: 讨论了硬件 RAID 控制器缓存、网络带宽、OSD 内存目标设置等对性能的影响。 决定事项 RocksDB 更新: 决定考虑更新 RocksDB 到最新版本，但需要先看到测试结果。 性能测试: 决定进行一系列性能测试，包括不同 RAID 配置、Erasure Coding 与复制的比较，以及单个磁盘与 RAID 配置的性能对比。 后续行动计划 性能测试: 进行详细的性能测试，包括不同 RAID 配置和存储策略的测试。 RGW 优化: 继续优化 RGW 的配置和性能，特别是在处理大量数据读取时的情况。 CRC32 优化: 针对 ARM V8 平台的 CRC32 性能问题，计划创建一个跟踪器并进行进一步的调查和优化。 其他讨论 大型集群管理: 讨论了管理大型 Ceph 集群时可能遇到的问题，特别是与管理器和监视器相关的性能问题。 硬件支持: 讨论了硬件 RAID 控制器缓存和 SSD 元数据驱动器对性能的影响。 结论 会议涵盖了多个关于 Ceph 性能优化和配置的话题，特别是在处理大量数据和高并发读取时的性能问题。后续将进行一系列详细的性能测试和优化工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2023-01-05","slug":"Ceph_Performance_Meeting_2023-01-05","date":"2023-01-05T16:00:00.000Z","updated":"2023-01-06T16:00:00.000Z","comments":true,"path":"2023/01/06/Ceph_Performance_Meeting_2023-01-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/06/Ceph_Performance_Meeting_2023-01-05/","excerpt":"","text":"会议纪要 参会人员 会议主持人：Mark 参会人员：Corey 会议主要议题 Pull Requests (PRs) 更新 由于Ether pad暂时无法使用，会议中没有详细审查新的PRs。 提到了一个关于m-clock工作的更新PR，旨在增加一个高优先级队列用于操作。 Corey的PR收到了一些评论，需要进一步跟进。 有两个PR已经关闭，包括一个修复race condition的PR。 Corey的工作更新 Corey报告了他们在假期前通过取消所有backfills和手动压缩数据来稳定系统的经验。 目前正在考虑升级和测试一些新的调整设置，特别是关于删除操作的优化。 正在测试RocksDB版本7.8.3，特别是关于range delete的新特性，这可能对性能有显著提升。 RocksDB更新 讨论了RocksDB 7.8.3的新特性，特别是range delete的迭代优化，这可能对Ceph的性能有重大影响。 计划尽快将新版本的RocksDB纳入测试。 数据库性能问题 讨论了数据库溢出到硬盘的问题，这导致compaction过程耗时过长。 计划继续研究短期解决方案，同时关注RocksDB升级的长远影响。 其他议题 讨论了Adam正在进行的工作，包括优化RBD mirroring的共享blob管理。 决定事项 尽快测试RocksDB 7.8.3的新特性，并评估其在Ceph中的应用效果。 继续研究数据库溢出到硬盘的问题，并寻找短期解决方案。 后续行动计划 Corey将继续测试RocksDB 7.8.3，并评估其对memtable和SSD文件的影响。 一旦实验室的VPN恢复，将尽快进行RocksDB的升级测试。 继续跟进Adam的工作进展，特别是关于优化blob管理的改进。 会议结束 会议在感谢和告别中结束，计划下周再次会议。 备注：会议中提到的技术术语和产品名称如“m-clock”、“RocksDB”、“PR”等，保留原文以确保专业性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2022-12-07","slug":"Ceph_Crimson_SeaStore_Meeting_2022-12-07","date":"2023-01-04T16:00:00.000Z","updated":"2023-01-05T16:00:00.000Z","comments":true,"path":"2023/01/05/Ceph_Crimson_SeaStore_Meeting_2022-12-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/05/Ceph_Crimson_SeaStore_Meeting_2022-12-07/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [参会人员名单] 会议主持： [主持人姓名] 主要议题： 1. 系统审查与IO Handler类实现 - 正在进行系统审查，并实现IO Handler类以封装输入输出消息和进行事件分发。 - 当前步骤是明确消息握手与信使之间的交互，并将其从同步转为异步，以支持跨核心通信。 - 计划本周发送相关PR（Pull Request）。 对象存储性能验证 已验证在客户端负载较重的情况下，分布式对象存储相较于单节点对象存储性能提升超过10%。 请求团队成员审查相关PR。 跨核心反应器使用情况分析 目前仅能监控核心零的反应器使用情况，计划进行跨核心反应器使用情况的全面分析。 目标是使每个核心都能处理消息并将其分发到相应的PT核心。 解决大规模脏范围修剪导致的长时间延迟问题 正在尝试解决因大规模脏范围修剪导致的长时间延迟问题，但由于其他工作任务，进展有限。 计划本周继续处理此问题。 新成员介绍与PR审查请求 新成员加入会议，以更好地了解项目进展并为测试做准备。 有两个PR即将合并，请求团队成员在合并后进行审查。 决定事项： - 确认了分布式对象存储在重负载下的性能优势。 - 明确了跨核心通信的优化方向和当前的局限性。 - 新成员将参与后续的测试工作。 后续行动计划： - 发送IO Handler类实现的PR，并请求快速审查。 - 继续分析和优化跨核心反应器的使用情况。 - 解决大规模脏范围修剪导致的延迟问题。 - 审查并合并相关PR，确保新功能稳定运行。 会议结束： 会议在确认无其他议题后结束，祝大家本周工作顺利。 备注： 会议中提到的技术细节和术语如“IO Handler类”、“PR”、“跨核心通信”等，是ceph分布式存储领域的关键概念，保留原文有助于理解会议内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2022-12-06","slug":"Ceph_Orchestrator_2022-12-06","date":"2023-01-04T16:00:00.000Z","updated":"2023-01-05T16:00:00.000Z","comments":true,"path":"2023/01/05/Ceph_Orchestrator_2022-12-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2023/01/05/Ceph_Orchestrator_2022-12-06/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： OpenStack Tracker 更新 NFS 相关问题讨论 讨论内容： 1. OpenStack Tracker 更新 背景：讨论了关于在Ceph中定制每个OSD的crash设备类的问题。目前，SafeTangible使用批处理模式，通过传递OSD列表来准备和激活设备。 当前问题：需要在CI环境中为SSD创建crash层次结构并应用规则，但由于缺乏对不同crash设备类的支持，无法完全复制过去的功能。 解决方案： 创建了一个新的tracker来比较过去和现在的实现。 讨论了是否需要为设备类引入不同的语法，或者使现有的路径处理更智能以支持每个OSD的设备类。 建议使用字典格式在spec中定义设备类，并优化批处理模式以减少OSD部署时间。 决定通过分组设备类来优化set volume命令的执行，最多可能需要三个批处理命令。 2. NFS 相关问题讨论 背景：会议中提到了NFS相关的调试问题，特别是关于一个可能导致回归的新配置部分。 当前问题：RC Frank可能引入了一个回归问题，导致无法在IRC中发送消息。 解决方案： 尝试通过修改配置来解决问题。 计划在会议后进行进一步的调试和实验。 讨论了如何处理旧版本的兼容性问题。 决定事项： 对于OpenStack Tracker问题，决定使用字典格式在spec中定义设备类，并通过分组优化set volume命令的执行。 对于NFS问题，计划在会议后进行进一步的调试和实验，并考虑旧版本的兼容性问题。 后续行动计划： 更新tracker，记录会议中的讨论和决定。 进行NFS相关的调试和实验，以确定问题的根本原因并寻找解决方案。 考虑旧版本的兼容性问题，并与相关团队合作解决。 其他事项： 会议中还讨论了团队的过渡问题，以及如何更好地支持新成员和处理项目中的问题。 提到了测试套件的更新和优化，以及如何处理剩余的小问题。 会议结束： 会议在讨论了所有议题后结束，计划下周再次开会。 备注： 会议中提到的具体技术细节和代码修改将在后续的开发和调试中进一步明确和实施。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2022-11-30","slug":"Ceph_Crimson_Seastore_Meeting_2022-11-30","date":"2022-12-01T16:00:00.000Z","updated":"2022-12-02T16:00:00.000Z","comments":true,"path":"2022/12/02/Ceph_Crimson_Seastore_Meeting_2022-11-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/12/02/Ceph_Crimson_Seastore_Meeting_2022-11-30/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph存储系统的开发进展和相关技术问题，包括性能优化、代码审查、功能实现等方面。 主要议题 代码审查和功能迁移 上周主要进行了代码审查工作。 计划迁移Oh Map功能，并推进Split Protocol V2 Messenger和Handshake的开发。 性能回归问题 发现共享存储支持下的性能有所下降，目前正在解决这一问题。 通过添加Mall客户端进行测试，以验证性能改进。 代码调试和单元测试 正在调试Picture Remove代码，已接近完成，计划添加单元测试并准备PR（Pull Request）进行审查。 缓存数据提升功能 讨论了实现缓存数据提升功能的必要性和可行性。 该功能旨在将频繁访问的数据从冷存储提升到热存储，以优化内存使用效率。 讨论了该功能对最终性能的贡献和引入的复杂性。 决定事项 继续推进Split Protocol V2 Messenger和Handshake的开发。 解决共享存储支持下的性能回归问题。 完成Picture Remove代码的调试和单元测试，并提交PR进行审查。 探讨并实现缓存数据提升功能，评估其对性能的影响和重要性。 后续行动计划 完成Oh Map功能的迁移工作。 继续解决性能回归问题，并进行相关测试。 完成Picture Remove代码的单元测试，并提交PR。 进一步讨论和实现缓存数据提升功能，评估其对性能的影响，并考虑架构上的调整。 其他事项 会议结束时，与会者互相祝愿一周愉快。 关键词 Ceph Split Protocol V2 Oh Map Performance Regression Blue Store Object Store Interface Cache Data Promote Memory Constrained Devices 结束语 会议顺利结束，各项议题和后续行动计划已明确，期待各团队成员的进一步进展和合作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-12-01","slug":"Ceph_Performance_Meeting_2022-12-01","date":"2022-12-01T16:00:00.000Z","updated":"2022-12-02T16:00:00.000Z","comments":true,"path":"2022/12/02/Ceph_Performance_Meeting_2022-12-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/12/02/Ceph_Performance_Meeting_2022-12-01/","excerpt":"","text":"会议纪要 关键细节 依赖版本固定问题: 会议讨论了由于上游库的版本升级导致测试中断的问题。主要关注点是版本固定（version pinning）的长期影响和潜在风险。 版本固定策略: 提出了一个策略，建议仅固定主要版本（major versions），以减少长期维护的复杂性。 自动化工具: 讨论了开发一个自动化工具来管理和更新依赖版本，以减少手动更新的负担。 文档和追踪: 强调了需要一个集中的位置来记录和管理所有固定版本的信息，以及定期审查和更新这些依赖的必要性。 讨论的主要议题 版本固定与更新: 讨论了如何处理依赖库的版本固定，以及如何定期更新这些依赖以避免技术债务。 自动化与文档: 探讨了通过自动化工具来管理依赖版本的可行性，并强调了文档的重要性，以便团队成员能够追踪和管理这些信息。 决定的事项 版本固定策略: 决定尝试实施一个策略，即仅固定主要版本，除非次要版本存在问题。 自动化工具开发: 同意开发一个自动化工具来帮助管理和更新依赖版本。 文档更新: 决定在文档中创建一个专门的页面来记录所有固定的依赖版本，并定期更新。 后续行动计划 开发自动化工具: 开始开发一个自动化工具来扫描和管理所有依赖版本。 更新文档: 在开发文档中创建一个新页面，用于记录和管理所有依赖版本的固定信息。 定期审查: 设定每三个月或六个月的时间表，团队成员将审查和尝试更新这些依赖版本。 其他讨论 测试实验室问题: 讨论了当前测试实验室中遇到的一些具体问题，特别是与NFS相关的测试失败，并计划通过冻结节点和手动检查来进一步诊断问题。 合并请求: 讨论了合并一些长期待定的拉取请求（pull requests），尽管存在一些测试失败的风险，但认为这些请求已经过充分审查和测试。 会议结束时，团队成员同意按照上述行动计划推进工作，并期待在下一次会议中看到进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-12-01","slug":"Ceph_Orchestrator_Meeting_2022-12-01","date":"2022-11-30T16:00:00.000Z","updated":"2022-12-01T16:00:00.000Z","comments":true,"path":"2022/12/01/Ceph_Orchestrator_Meeting_2022-12-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/12/01/Ceph_Orchestrator_Meeting_2022-12-01/","excerpt":"","text":"会议纪要 关键细节 会议主题: 讨论测试中的依赖版本问题和测试实验室的故障 参与者: 团队成员（具体姓名未提及） 日期: 未明确提及 讨论的主要议题 依赖版本管理: 团队成员注意到测试中断的原因之一是上游依赖库的版本号大幅更新，导致某些功能变更。 讨论了是否应该制定一个通用策略，建议仅在必要时固定依赖版本，并尝试定期更新到最新的主版本。 提出了一个自动化脚本的想法，用于检查和管理所有依赖项的版本，并定期进行依赖更新。 测试实验室故障: 分析了测试实验室中出现的多个故障，特别是NFS测试的挂载问题。 讨论了可能的故障原因，包括基础设施问题、镜像问题或配置错误。 计划通过冻结节点和手动检查来进一步诊断和解决这些问题。 决定的事项 创建一个清理跟踪器（cleanup tracker）以记录和管理依赖版本问题。 计划实施一个自动化脚本，用于定期检查和更新依赖项。 决定在接下来的会议中继续讨论和解决NFS测试的挂载问题。 后续行动计划 由某成员负责创建清理跟踪器，并开始自动化脚本的开发。 团队成员将在下次会议中继续讨论NFS测试的具体问题，并尝试通过冻结节点和手动检查来诊断问题。 预计在未来一周内开始合并积压的拉取请求（pull requests），并在假期前整理好项目状态。 其他备注 会议中还提到了其他一些测试相关的故障，但这些被认为是较为零星或已知的问题，不会立即影响项目的进展。 团队成员表达了对尽快解决这些问题并恢复项目正常进度的迫切需求。 结论 会议主要集中在解决依赖版本管理和测试实验室故障的问题上，团队成员提出了具体的解决方案和行动计划，以确保项目能够顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-11-02","slug":"Ceph_Developer_Monthly_2022-11-02","date":"2022-11-22T16:00:00.000Z","updated":"2022-11-23T16:00:00.000Z","comments":true,"path":"2022/11/23/Ceph_Developer_Monthly_2022-11-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/23/Ceph_Developer_Monthly_2022-11-02/","excerpt":"","text":"会议纪要 主要议题 Crimson OSD 的用户界面保护措施 讨论了为防止用户意外启动 Crimson OSD 而导致生产集群复杂化的问题。 介绍了两种保护措施： 编辑 Crimson 实验性功能标志。 设置允许 Crimson OSD 映射标志。 这些措施旨在防止用户在不完全支持 Crimson OSD 的功能时意外使用它们。 Crimson 池的设计和功能限制 讨论了未来可能需要在同一集群中混合使用 Crimson OSD 和常规 OSD 的情况。 介绍了基于每个池的设置，而不是整个集群的设置。 限制了 Crimson 池的一些功能，如更改 PG 数量或使用 tiers。 文档和未来支持 讨论了当前文档中对 Crimson 支持功能的描述不足，计划在未来的 Reef 文档中详细说明支持的功能。 强调了 Crimson OSD 在支持某些功能时的变化，以及如何处理这些变化。 条件调试和智能日志记录 讨论了条件调试和智能日志记录的概念，旨在提高故障排除的效率。 探讨了在特定条件下自动启用调试日志的可能性，以及如何实现这一功能。 决定事项 实施了 Crimson OSD 的用户界面保护措施，以防止意外启动和使用不完全支持的功能。 更新了文档，计划在 Reef 文档中详细说明 Crimson 的支持功能。 讨论了条件调试和智能日志记录的实现可能性，但尚未确定具体实施方案。 后续行动计划 继续更新和完善 Reef 文档，确保用户能够清楚了解 Crimson 的支持功能。 进一步探讨和研究条件调试和智能日志记录的实现方法，以提高系统的故障排除能力。 计划在未来的 S 版本中，让有经验的用户在实际使用场景中测试 Crimson 的功能。 其他讨论 讨论了系统调试和日志记录的平衡问题，如何在不影响性能的情况下提供足够的调试信息。 探讨了使用系统工具如 SystemTap 和 DTrace 来增强调试功能的可能性。 结论 会议主要围绕 Crimson OSD 的功能保护、文档更新以及条件调试和智能日志记录的讨论展开。团队将继续致力于提高系统的稳定性和用户的使用体验。 以上是对会议内容的详细总结，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Introduction to Container Object Storage Interface aka COSI for ceph RGW","slug":"Introduction_to_Container_Object_Storage_Interface_aka_COSI_for_ceph_RGW","date":"2022-11-22T16:00:00.000Z","updated":"2022-11-23T16:00:00.000Z","comments":true,"path":"2022/11/23/Introduction_to_Container_Object_Storage_Interface_aka_COSI_for_ceph_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/23/Introduction_to_Container_Object_Storage_Interface_aka_COSI_for_ceph_RGW/","excerpt":"","text":"会议纪要 会议参与者 主讲人: 高级软件工程师，专注于Ceph存储与Kubernetes的集成。 会议主题 介绍CSI（Container Storage Interface）和Cosi项目。 讨论Cosi项目的当前状态、架构、工作流程及未来计划。 介绍Cosi驱动程序的开发进展。 讨论内容 CSI简介 CSI是一个广泛使用的存储插件，已有超过五年的历史。 主要用于暴露块和文件存储，提供灵活性和安全性。 Cosi项目概述 Cosi项目旨在为对象存储提供支持，特别是针对动态存储分配和应用程序直接访问存储桶的场景。 项目目前处于alpha阶段，目标是自动化存储桶的创建、删除和管理。 Cosi架构与术语 介绍了与CSI类似的术语，如Bucket Class和Bucket Claim。 讨论了Cosi如何处理存储桶的访问管理，包括Bucket Access Class和Bucket Access。 Cosi工作流程 详细描述了Cosi的架构设计，包括Cosi控制器、供应器和驱动程序的角色。 解释了Green Field和Brown Field两种场景下的工作流程。 Cosi驱动程序开发 讨论了Cosi驱动程序的当前状态和未来计划，包括支持的协议和功能。 提到了需要合并到上游代码库的工作和未来的改进计划。 决定事项 Cosi项目将继续开发，重点是增加功能和提高稳定性。 Cosi驱动程序的开发将继续，目标是支持更多协议和提高集成度。 后续行动计划 继续开发Cosi项目，解决现有问题并实现新功能。 推动Cosi驱动程序的开发，确保其与Kubernetes和其他系统的兼容性。 定期在社区会议上更新项目进展，并收集用户反馈。 会议结束 主讲人感谢大家的参与，并邀请大家在社区Slack频道上提出问题和建议。 会议在无进一步问题的情况下结束。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"NVMe-over-Fabrics support for Ceph","slug":"NVMe-over-Fabrics_support_for_Ceph","date":"2022-11-22T16:00:00.000Z","updated":"2022-11-23T16:00:00.000Z","comments":true,"path":"2022/11/23/NVMe-over-Fabrics_support_for_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/23/NVMe-over-Fabrics_support_for_Ceph/","excerpt":"","text":"会议纪要 会议主题： NVMe over Fabrics 支持在 Ceph 中的实现 主讲人： Jonas Pfefferle 和 Scott Bauer 会议时间： [具体时间] 参会人员： [参会人员名单] 会议内容总结： 背景介绍： Jonas Pfefferle 和 Scott Bauer 介绍了他们在 Ceph 中实现 NVMe over Fabrics 支持的工作。 强调了这是一个社区合作项目，多家公司参与其中。 NVMe over Fabrics 的重要性： 解释了为什么需要在 Ceph 中支持 NVMe over Fabrics，包括行业标准的使用、生态系统的兼容性以及利用 DPUs 等硬件优势。 架构概述： 展示了从 NVMe initiators 到 Ceph 集群的高层次架构图，介绍了 Ceph NVMe over Fabrics Gateway 组件。 讨论了 Gateway 的部署方式，可以是独立节点或与 OSDs 共存。 技术细节： 详细介绍了 Gateway 的工作原理，包括使用 SPDK（Storage Performance Development Kit）处理数据路径。 讨论了控制路径的配置，包括使用 gRPC API 进行配置管理和持久化配置。 演示环节： 展示了如何配置和启动 Ceph NVMe over Fabrics Gateway，并通过实际操作演示了从 NVMe initiator 到 Ceph 集群的数据路径。 未来工作： 讨论了未来的开发计划，包括 Gateway 组（Gateway groups）、多路径支持（multipathing support）、发现服务（Discovery service）、认证和加密（authentication and encryption）以及 ADNN（Asymmetric Distributed Namespace）支持。 强调了这些功能的重要性，并提到了当前的开发进度和未来的目标。 性能讨论： 讨论了性能问题，包括使用多个 SPDK 线程处理 RBD 图像以避免性能瓶颈。 提到了当前的性能测试结果，显示了良好的性能表现。 社区互动： 回答了与会者提出的问题，包括关于 Discovery 服务、WireGuard 支持和 ADNN 的具体问题。 决定事项： - 确定了 Ceph NVMe over Fabrics Gateway 的初步实现和未来开发方向。 - 确认了社区会议的时间和地点，以便进一步讨论和开发。 后续行动计划： - 继续开发和完善 Ceph NVMe over Fabrics Gateway 的功能。 - 进行更多的性能测试和集成测试，以确保稳定性和可靠性。 - 定期召开社区会议，跟进项目进度并解决遇到的问题。 会议结束： - 会议按时结束，感谢所有参与者的贡献和讨论。 附件： - 会议演示文稿和相关链接已上传至 Etherpad。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Troubleshooting and Debugging in the rook-ceph cluster","slug":"Troubleshooting_and_Debugging_in_the_rook-ceph_cluster","date":"2022-11-22T16:00:00.000Z","updated":"2022-11-23T16:00:00.000Z","comments":true,"path":"2022/11/23/Troubleshooting_and_Debugging_in_the_rook-ceph_cluster/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/23/Troubleshooting_and_Debugging_in_the_rook-ceph_cluster/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Rook项目中的故障排查和调试方法，特别是如何处理Rook Ceph集群中的常见问题，并介绍了Crew插件的使用及其在故障排查中的应用。 参会人员 Deepika Upadhyay：Kotak的云存储工程师，Rook项目的核心贡献者。 Shubham Doshi：Red Hat的软件工程师，Rook项目的核心贡献者。 主要议题 Rook Ceph集群中的常见故障： 监控器（monitors）失去Quorum，导致无法执行Ceph操作。 网络故障或中断导致的卷报告“仍在使用”错误。 高CPU利用率的Ceph组件问题。 故障排查方法： 使用Rook操作日志和Kubernetes层进行初步故障排查。 利用Crew插件进行更深入的调试，特别是在监控器失去Quorum的情况下。 Crew插件介绍： Crew是一个基于Kubectl命令的工具，帮助用户管理和故障排查其Ceph集群。 提供了自动化命令，如恢复Quorum和调试模式，简化了故障排查过程。 未来工作计划： 计划增加在所有监控器都失效时恢复集群的功能。 考虑增加备份和恢复支持，以防止Ceph集群CRD意外删除。 自动化核心转储（core dump）的收集。 决定事项 确认了Crew插件在Rook Ceph集群故障排查中的有效性。 确定了未来工作的方向，包括增强Crew插件的功能和自动化核心转储收集。 后续行动计划 继续开发和完善Crew插件，以支持更多的故障排查场景。 与Telemetry团队合作，探讨如何集成核心转储收集到现有基础设施中。 鼓励社区成员提供反馈和建议，以改进Rook项目的故障排查工具和文档。 其他信息 提供了Crew插件的安装和使用文档链接，方便用户自行安装和学习使用。 强调了社区合作的重要性，并欢迎任何形式的贡献和反馈。 会议结束 感谢所有参与者的参与和贡献，期待在未来的社区活动中再次相聚。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Operating Ceph from the Ceph Dashboard: past, present and future","slug":"Operating_Ceph_from_the_Ceph_Dashboard_-_past_present_and_future","date":"2022-11-21T16:00:00.000Z","updated":"2022-11-22T16:00:00.000Z","comments":true,"path":"2022/11/22/Operating_Ceph_from_the_Ceph_Dashboard_-_past_present_and_future/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/22/Operating_Ceph_from_the_Ceph_Dashboard_-_past_present_and_future/","excerpt":"","text":"会议纪要 会议主题：Ceph Dashboard 的功能介绍与历史回顾 会议时间：待定 主讲人：Nizamudi 会议内容总结： Ceph Dashboard 简介 Nizamudi 目前是 Red Hat 的软件工程师，自2020年起加入 Ceph Dashboard 团队。 Ceph Dashboard 不仅仅是一个监控工具，而是一个全功能的分布式存储管理系统。 Ceph Dashboard 的历史可以追溯到2013年，经历了多个版本的发展，目前是 Ceph Manager 模块的一部分。 Ceph Dashboard 的主要功能 管理与监控：提供高级的 Ceph 管理操作，包括集群配置、日志查看、性能监控等。 集成与优化：直接消费 Ceph Manager 模块的 API，实现高效的数据交互。 用户界面：提供直观的用户界面，简化复杂操作，如集群扩展、OSD 管理、RBD 镜像等。 Ceph Dashboard 的架构与技术细节 架构：Ceph Dashboard 的前端通过 REST API 与后端的 Python 模块交互，获取集群数据。 技术栈：使用 Angular 和 Bootstrap 框架，未来将升级到 Angular 13 和 Bootstrap 5。 Ceph Dashboard 的发展路线图 Reef 版本：将重点改进 RBD 和 OSD 的管理功能，引入多站点等新特性。 长期目标：计划替换 Grafana 为内置的监控组件，增强 CephFS 的集成。 用户反馈与社区贡献 用户调查：2022年的用户调查显示，约50%的用户使用 Ceph Dashboard 进行监控。 社区贡献：鼓励用户、文档编写者和开发者参与贡献，提供多种参与方式。 后续行动计划 技术优化：继续改进用户界面和交互体验，增强系统的可维护性和可访问性。 社区互动：通过邮件列表、IRC 和开发者指南等方式，加强与社区的沟通和协作。 决定事项： 确认 Ceph Dashboard 在 Reef 版本中的开发重点和目标。 继续推动社区参与和贡献，特别是通过低代码倡议吸引更多开发者。 后续行动： 完成 Reef 版本的开发和测试，确保新功能的稳定性和性能。 持续收集用户反馈，优化 Ceph Dashboard 的功能和用户体验。 会议结束语： Nizamudi 感谢大家的参与，并邀请大家在会议后提出问题和建议。 以上是本次会议的详细纪要，涵盖了 Ceph Dashboard 的功能、历史、架构、发展路线图以及社区贡献等方面的重要信息。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-11-17","slug":"Ceph_Performance_Meeting_2022-11-17","date":"2022-11-16T16:00:00.000Z","updated":"2022-11-17T16:00:00.000Z","comments":true,"path":"2022/11/17/Ceph_Performance_Meeting_2022-11-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/17/Ceph_Performance_Meeting_2022-11-17/","excerpt":"","text":"会议纪要 与会人员 主持人：Mark 其他参与者：Casey 会议主要议题 Adam的工作进展 Adam近期致力于改进BlueStore中共享blob的工作方式，特别是在快照处理方面。 初始测试显示性能提升，但后续发现CPU使用率增加，性能并未显著提升。 目前考虑新的方法，即在创建新extent时，将其添加到现有的共享blob中，而不是创建新的共享blob。 这种方法可能不需要改变磁盘格式，但仍需进一步测试和评估。 性能问题讨论 讨论了删除范围（delete range）在RGW日志修剪中的使用问题。 发现下游（Downstream）和上游（Upstream）在处理删除范围时的行为不一致。 讨论了可能的解决方案，包括调整RocksDB的配置以更好地处理删除范围。 后续行动计划 Mark将跟进Adam的工作进展，并尝试理解删除范围问题的具体细节。 Casey将跟进邮件讨论，确保上下游行为一致，并寻找可能的解决方案。 决定事项 继续监控和评估Adam的新方法，以解决快照处理中的性能问题。 确保上下游在处理删除范围时的一致性，并寻找优化方案。 后续行动 Mark将更新拉取请求（pull requests）并跟进Adam的工作。 Casey将通过邮件继续讨论删除范围问题，并寻找解决方案。 其他事项 Mark因健康问题未能详细审查拉取请求，将在下周进行更新。 会议结束时，Mark提醒大家注意健康，并祝愿大家下周顺利。 会议结束时间 会议在讨论完所有议题后结束，无其他紧急事项。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Data Security and Storage Hardening In Rook and Ceph","slug":"Data_Security_and_Storage_Hardening_In_Rook_and_Ceph","date":"2022-11-14T16:00:00.000Z","updated":"2022-11-15T16:00:00.000Z","comments":true,"path":"2022/11/15/Data_Security_and_Storage_Hardening_In_Rook_and_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/15/Data_Security_and_Storage_Hardening_In_Rook_and_Ceph/","excerpt":"","text":"会议纪要 参会人员介绍 Federico Lucifredi: 产品管理总监，负责Obsession平台，曾在Red Hat和即将加入IBM。之前在Canonical担任Ubuntu Server产品经理，参与过14.04版本的开发。曾维护Mount，著有O'Reilly出版的书籍。 Anna Hacker: 使用they/them代词，Red Hat安全团队成员，即将加入IBM。目前负责Red Hat的应急响应，未来将负责存储产品如Ceph ODF和SAP的安全。曾在UCSC攻读形式方法和存储安全，本科毕业于UMass Amherst。 Mike Hackett: 因工作繁忙未能参加，但对本次工作有重要贡献。 会议主要议题 网络安全分区 讨论了四个网络安全分区：公共安全区、存储访问区、SAS客户端区和集群区。强调了根据威胁模型选择合适的加密和安全实践的重要性。 产品安全实践 Red Hat采用安全开发生命周期，包括渗透测试、依赖项清单、漏洞审查等。介绍了Red Hat在安全架构和应急响应方面的具体做法。 加密和密钥管理 讨论了数据在静态和传输中的加密方法，以及密钥管理的重要性。提到了使用LUKS进行数据加密，以及RGW的额外加密能力。 身份和访问管理 讨论了Ceph和RGW的身份验证和授权机制，支持多种身份验证方法如LDAP、Active Directory和OpenStack Keystone。 审计和数据保留 强调了审计日志的重要性，建议将日志集中管理并定期清理。讨论了数据保留策略和安全删除方法。 二进制文件加固 讨论了通过操作系统环境和内核提供的加固选项，如ASLR、限制系统调用等，以增强二进制文件的安全性。 决定事项 确认了Red Hat在产品安全和加密方面的当前实践和未来方向。 强调了根据具体威胁模型选择合适的安全措施的重要性。 后续行动计划 继续优化和加强Red Hat存储产品的安全特性。 探索和实施更全面的应用层日志记录，以更好地跟踪和审计高层次的操作。 资源链接 提供了多个与安全相关的资源链接，包括Kubernetes秘密管理、数据安全和加固文档等。 问答环节 回答了关于拒绝服务攻击、加密对性能的影响以及审计日志的详细问题。 本次会议详细讨论了Red Hat在存储安全方面的实践和未来方向，强调了安全措施的实施需要根据具体的威胁模型进行定制。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"DisTRaC: Accelerating High-Performance Compute Processing for Temporary Data Storage","slug":"DisTRaC_-_Accelerating_High-Performance_Compute_Processing_for_Temporary_Data_Storage","date":"2022-11-14T16:00:00.000Z","updated":"2022-11-15T16:00:00.000Z","comments":true,"path":"2022/11/15/DisTRaC_-_Accelerating_High-Performance_Compute_Processing_for_Temporary_Data_Storage/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/15/DisTRaC_-_Accelerating_High-Performance_Compute_Processing_for_Temporary_Data_Storage/","excerpt":"","text":"会议纪要 会议主题：介绍Distract - 用于加速高性能计算处理的分布式瞬态存储 主讲人：Gabriel Mason Williams 背景介绍： 机构背景：Gabriel Mason Williams介绍了罗斯和弗兰克研究所（Rose and Frank Institute），这是一个位于英国的研究机构，专注于开发新技术以解决重要的健康研究挑战。该机构位于哈威尔（Harwell）校区和迪德科特（Didcot），并由英国EPSRC（Engineering and Physical Sciences Research Council）资助。 个人背景：Gabriel目前是伦敦女王玛丽大学的人工智能硕士学生，并在罗斯和弗兰克研究所担任研究软件助理，同时正在寻找博士机会。 项目背景： 项目起源：Distract项目起源于钻石光源（Diamond Light Source），由Mark Basham和Dave Bond发起，并与布里斯托大学（University of Bristol）合作进行。 会议内容概述： 问题背景：传统的HPC集群设置存在I/O瓶颈问题，主要是因为网络连接到高性能存储集群的限制，以及共享资源的竞争问题。 解决方案：Gabriel提出了Distract作为解决方案，这是一个用于在HPC基础设施上部署瞬态存储集群的程序，利用RAM进行可扩展和高效的管理。 Distract的特点： 快速部署：Distract利用MPI和网络文件系统（NFS）进行快速部署，部署时间大约为22秒。 快速移除：同样利用MPI进行快速移除，移除时间大约为1.5分钟。 隔离资源：Distract创建了一个作业辅助和隔离的内存文件或对象存储，确保作业间的资源隔离。 案例研究： 案例一：Relyon：通过使用Distract，处理时间减少了5.51倍，总时间减少了4.37倍。 案例二：Cyber：通过使用Distract，处理时间减少了8.32%，I/O开销减少了81.04%。 结论： Distract的优势：Distract通过利用集群的RAM创建了一个超融合的HPC集群，减少了网络文件系统的I/O开销，并提供了数据处理性能的潜在提升。 灵活性：Distract支持使用对象存储或文件系统，提供了更多的灵活性。 后续行动计划： 进一步开发：考虑在每个节点上扩展MDS服务，并探索在本地NVMe上部署的可能性。 参考文献： Gabriel提供了相关的参考文献，并对会议进行了总结。 会议结束： Gabriel感谢大家的参与，并邀请大家提问。 提问环节： Stefan提问：是否使用Ceph进行开发？Gabriel回答说，他们使用Ceph的原生功能，如Rados和FFS，并解释了为什么对象存储在处理图像数据时更有效。 本次会议详细介绍了Distract项目的目标、实施方法和实际应用效果，展示了其在高性能计算领域的潜在价值和优势。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"New workload balancer in Ceph","slug":"New_workload_balancer_in_Ceph","date":"2022-11-14T16:00:00.000Z","updated":"2022-11-15T16:00:00.000Z","comments":true,"path":"2022/11/15/New_workload_balancer_in_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/15/New_workload_balancer_in_Ceph/","excerpt":"","text":"会议纪要 会议参与者 Joe Solomon: 前架构师，现为Red Hat的CTO办公室新兴技术团队成员。 Laura Flores: Red Hat的RADOS核心团队成员，曾参与Telemetry管理模块、BlueStore等工作，目前专注于上游测试。 会议主题 介绍即将在Reef版本中引入的新rebalancer。 讨论内容 动机与背景 在分布式存储系统中，高负载下性能受限于最弱环节。 现有容量平衡器确保OSD间容量均匀分布，但未解决读取平衡问题。 CRUSH算法在大型集群中平衡读取，但在小型集群中表现不佳。 现有问题与改进 收集了多种系统的OSD Mark文件进行测试。 重构了现有平衡器代码，使其更易于理解和修改。 创建了新的工作负载平衡器，考虑读取操作。 新rebalancer设计 新rebalancer将在Reef版本中引入，主要针对小型集群。 设计基于池的读取平衡，考虑读写工作负载的差异。 未来版本计划考虑设备大小和动态响应性能波动。 功能与实现 引入新的命令来改变PG的主OSD，不涉及数据移动。 实现两个主要函数：calc desired primary distribution和balanced primaries。 这些函数位于OSD map代码中，便于未来贡献和优化。 演示与测试 展示了如何在不同场景下使用新rebalancer改善读取平衡。 强调了未来将进行更多的上游测试和性能测试。 决定事项 新rebalancer将在Reef版本中作为离线工具提供，未来计划集成到自动平衡模块中。 未来版本将考虑设备大小和动态性能调整。 后续行动计划 继续进行上游测试和性能测试。 考虑将新rebalancer集成到自动平衡模块中。 探索更复杂的平衡策略，如基于设备大小和动态性能调整。 其他讨论点 讨论了primary affinity的潜在改进和客户端读取策略的复杂性。 强调了未来版本中可能考虑的更高级平衡策略。 会议结束 感谢所有参与者的提问和讨论。 分享了相关GitHub仓库链接，以便进一步交流和反馈。 此会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了信息的完整性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimize Ceph messenger Performance","slug":"Optimize_Ceph_messenger_Performance","date":"2022-11-14T16:00:00.000Z","updated":"2022-11-14T16:00:00.000Z","comments":true,"path":"2022/11/15/Optimize_Ceph_messenger_Performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/15/Optimize_Ceph_messenger_Performance/","excerpt":"","text":"会议纪要 关键细节与讨论议题 APK vs TCP 性能优化 讨论了APK与TCP在性能优化方面的比较。 进行了压缩测试，使用了Snappy压缩算法。 结果显示，RDMA在某些测试中并未显示出比TCP明显的优势。 Crimson与Seastar集成问题 讨论了启用Crimson与Seastar时遇到的一些问题。 测试了经典OSD消息的处理，使用了RDMA作为公共网络，TCP作为集群网络。 发现了一些网络配置和性能问题，特别是在高并发情况下。 LSE（Large System Extensions）优化 介绍了LSE在8.1版本中的新特性，如何在L1缓存中加载和修改原子变量以减少缓存一致性成本。 测试结果显示，启用LSE可以显著提高高并发环境下的性能。 多工作负载平衡器 实现了一个新的多工作负载平衡器，用于优化工作负载的分配。 通过迁移最优连接，重新平衡工作负载，提高了序列写入的性能。 内核中的零拷贝技术 在内核中实现了动态零拷贝技术，减少了内存拷贝的开销。 通过动态选择数据大小，优化了性能。 Ceph消息处理优化 讨论了Ceph消息处理的一些优化措施，包括使用RDMA和TCP的比较。 发现了一些网络配置和性能问题，特别是在高并发情况下。 决定事项 决定继续优化APK与TCP的性能，特别是在压缩和网络配置方面。 决定继续改进Crimson与Seastar的集成，解决已知的问题。 决定继续优化LSE的使用，以提高高并发环境下的性能。 决定继续改进多工作负载平衡器，以优化工作负载的分配。 决定继续优化内核中的零拷贝技术，减少内存拷贝的开销。 后续行动计划 继续进行APK与TCP的性能测试，优化网络配置和压缩算法。 继续解决Crimson与Seastar集成中的问题，优化高并发环境下的性能。 继续优化LSE的使用，提高高并发环境下的性能。 继续改进多工作负载平衡器，优化工作负载的分配。 继续优化内核中的零拷贝技术，减少内存拷贝的开销。 其他讨论 讨论了Ceph消息处理的一些优化措施，包括使用RDMA和TCP的比较。 发现了一些网络配置和性能问题，特别是在高并发情况下。 结论 RDMA在某些测试中并未显示出比TCP明显的优势。 启用LSE可以显著提高高并发环境下的性能。 多工作负载平衡器和零拷贝技术的优化可以显著提高性能。 问题与建议 需要继续优化网络配置和压缩算法，以提高性能。 需要继续解决Crimson与Seastar集成中的问题，优化高并发环境下的性能。 需要继续优化LSE的使用，提高高并发环境下的性能。 需要继续改进多工作负载平衡器，优化工作负载的分配。 需要继续优化内核中的零拷贝技术，减少内存拷贝的开销。 会议结束 会议结束前，讨论了后续的工作计划和需要解决的问题。 需要继续与社区合作，改进Ceph的性能和功能。 提问环节 会议结束前，进行了提问环节，讨论了一些具体的技术问题和建议。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW Zipper","slug":"RGW_Zipper","date":"2022-11-14T16:00:00.000Z","updated":"2022-11-15T16:00:00.000Z","comments":true,"path":"2022/11/15/RGW_Zipper/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/15/RGW_Zipper/","excerpt":"","text":"会议纪要：项目 Zipper 讨论 关键细节： 项目名称：Zipper 目的：将 Ceph 的 RGW（RADOS Gateway）中的 S3 实现与其他存储系统（如 ISP 存储源或云存储）集成，提供一个灵活的 API 框架，支持堆叠过滤器以实现如分层或缓存等功能。 技术方法：通过解耦 RGW 的协议层与存储层，开发一个横跨 RGW 的 API（称为 Zipper API），以便在协议层和存储层之间插入其他存储插件。 讨论的主要议题： 架构设计： 顶部为协议层。 中间为核心层，提供所有对象协议通用的操作。 底部为存储层，实现完整的 Zipper API，提供数据和元数据的存储。 插件和过滤器： 存储插件（如 Rados Store）和过滤器（如 D4N Filter）通过 Zipper API 实现功能。 过滤器不需实现整个 API，未覆盖的部分将通过默认实现传递。 决定的事项： API 实现：提供一组纯虚拟基类，涵盖对象存储操作所需的各种概念。 插件管理：插件可以是内建或外建的，只需在运行时提供可加载的库。 配置管理：使用 JSON 文档进行配置，确保集群中的每个 RGW 实例都能访问相同的配置信息。 后续行动计划： 完成插件工作：预计在一个月内完成可加载插件的工作。 开发 Lua 过滤器：计划开发一个 Lua 过滤器，允许通过脚本快速开发过滤器功能。 其他信息： 当前状态：Zipper 已被 Seagate、Intel 和 SUSE 等公司采用，并已成功集成到他们的系统中。 技术限制：目前没有计划将 Zipper 从 C++ 解耦，但未来可能会有变化。 会议结束： 会议主持人感谢大家的参与，并邀请大家在会后通过电子邮件或 Google Chat 提出任何问题。 以上是关于项目 Zipper 的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Revealing BlueStore Corruption Bugs in Containerized Ceph Clusters","slug":"Revealing_BlueStore_Corruption_Bugs_in_Containerized_Ceph_Clusters","date":"2022-11-14T16:00:00.000Z","updated":"2022-11-15T16:00:00.000Z","comments":true,"path":"2022/11/15/Revealing_BlueStore_Corruption_Bugs_in_Containerized_Ceph_Clusters/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/15/Revealing_BlueStore_Corruption_Bugs_in_Containerized_Ceph_Clusters/","excerpt":"","text":"会议纪要 会议主题：Cyborgs公司容器化Ceph存储系统开发中的数据损坏问题及改进建议 会议参与者：Cyborgs公司Ceph存储系统维护团队 会议日期：[具体日期] 会议地点：[具体地点] 会议内容总结： 公司及基础设施介绍 Cyborgs是一家日本公司，提供软件支持团队协作。 公司目前使用基于传统虚拟机的系统，已有10-20年的历史，存在存储容量和性能的限制。 正在开发新的基于Kubernetes的现代化容器化基础设施，使用Rook Ceph作为存储解决方案。 开发中遇到的问题 在容器化Ceph存储系统的开发过程中，发现了多种数据损坏相关的bug，包括OSD创建失败和重启后数据请求损坏等问题。 这些问题主要在HDD上被检测到，推测是因为HDD的慢速特性更容易引发某些条件下的错误。 开发策略 开发策略包括三个步骤：每次更改通过PR提交，触发基于虚拟机的集成测试，测试通过后应用到预生产系统，最终部署到生产系统。 在开发过程中，频繁创建和重启OSD，每天进行多次集成测试，每周重启预生产环境的所有节点以验证基础设施的可用性和更新节点固件。 问题分析与改进建议 分析发现，这些问题在传统的非容器化Ceph集群中较少出现，推测与容器化环境中频繁的OSD创建和重启有关。 提出的改进建议包括增加对OSD重启的应力测试，以及在QA过程中使用HDD以更好地检测潜在问题。 后续行动计划 将继续与Ceph社区合作，验证和修复已报告的bug。 考虑在QA流程中增加更多的应力测试和使用HDD，以提高系统的稳定性和可靠性。 会议结束语 会议结束时，发言人感谢大家的参与，并表示希望这些信息对大家有所帮助。 后续行动： 与Ceph社区的QA工程师联系，讨论并实施改进建议。 持续监控和更新Ceph存储系统的性能和稳定性。 注： 以上内容基于会议发言人的介绍和讨论，具体实施细节和时间表将根据后续讨论和决策确定。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Accelerating PMEM Device operations in bluestore with hardware based memory offloading technique","slug":"Accelerating_PMEM_Device_operations_in_bluestore_with_hardware_based_memory_offloading_technique","date":"2022-11-13T16:00:00.000Z","updated":"2022-11-14T16:00:00.000Z","comments":true,"path":"2022/11/14/Accelerating_PMEM_Device_operations_in_bluestore_with_hardware_based_memory_offloading_technique/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/14/Accelerating_PMEM_Device_operations_in_bluestore_with_hardware_based_memory_offloading_technique/","excerpt":"","text":"会议纪要 会议主题：利用硬件卸载技术缓解持久内存设备操作中的CPU瓶颈 会议时间：[具体时间] 会议地点：Self-Outcome虚拟会议 主讲人：[姓名] 会议内容总结： 背景与问题介绍 随着非易失性内存设备的普及，如Intel Optane内存，数据中心中CPU资源在操作这些持久内存设备时成为瓶颈。 特别是当使用应用程序直接模式时，CPU需要处理更多的读写操作，导致资源紧张。 提出的解决方案 利用硬件卸载技术，如Intel的io80、iox和DSA（Data Streaming Accelerator），来减轻CPU的负担。 DSA是一种高性能的数据复制和转换加速器，将在Intel的下一代处理器中可用，可用于优化数据移动和其他操作。 DSA的深度启用 介绍了如何在系统中启用DSA，包括使用同步API和异步API来卸载CPU操作。 目前已在Brewster中实现了同步模式的DSA支持，并计划在未来扩展到异步模式。 结论与未来工作 总结了通过硬件卸载技术，特别是利用DSA和DML库，可以有效减轻CPU在持久内存操作中的压力。 未来的工作包括继续优化Ceph存储系统中的持久内存操作，并探索其他卸载设备如FPGA的应用。 决定事项： 确认了硬件卸载技术在缓解持久内存设备操作中CPU瓶颈的有效性。 确定了下一步在Ceph存储系统中实施和优化DSA技术的具体步骤。 后续行动计划： 继续在Brewster中完善DSA的异步模式支持。 在Ceph存储系统中实施DSA技术，并评估其性能改进。 探索其他硬件卸载设备如FPGA在持久内存操作中的应用潜力。 备注： 详细的性能报告将在SPI发布后提供。 参会人员： [参会人员名单] 会议记录人： [记录人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"S3select: Computational Storage in S3","slug":"S3select_-_Computational_Storage_in_S3","date":"2022-11-13T16:00:00.000Z","updated":"2022-11-14T16:00:00.000Z","comments":true,"path":"2022/11/14/S3select_-_Computational_Storage_in_S3/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/14/S3select_-_Computational_Storage_in_S3/","excerpt":"","text":"会议纪要 会议主题：S3 Select 介绍 主讲人：Gar Salomon 职位：Dorado 的 Gateway 团队成员 经验：过去三年致力于 S3 Select 的开发 会议内容概述 Gar Salomon 介绍了 S3 Select 的概念、工作原理、优势以及未来的发展方向。S3 Select 是一种新的 S3 能力，允许客户端将 SQL 语句推送到存储层，从而只提取所需的数据，显著提高性能并降低成本。 关键讨论点 S3 Select 简介 引入时间：2020年7月 功能：允许客户端推送 SQL 语句到存储层 优势：提高性能，减少成本 为什么需要 S3 Select 传统方法：数据移动到操作地点 S3 Select 方法：操作推送到数据附近 优势：减少内存消耗，优化大数据生态系统 S3 Select 的工作原理 嵌入式系统：集成到 GET 对象模型中 处理流程：对象被获取并由 S3 Select 模型处理每个片段 支持格式：CSV, JSON, Parquet SQL 在机器学习中的作用 数据处理：SQL 是处理数据的主要语言 数据格式：数据必须格式化以供机器学习算法使用 S3 Select 的软件设计特点 引擎设计：头文件代码，单文件函数，内存高效使用 数据类型处理：不同数据类型的读取器与 SQL 引擎解耦 数据类型处理流程 CSV：简单格式，不支持数据类型 JSON：支持数据类型和模式 Parquet：高级对象，包含元数据，支持直接访问特定数据 并行处理和优化 并行查询：通过分割数据范围并行处理查询 优化器：未来可能集成到 Spark, Presto 等分析应用中 验证和测试 表达式生成器：生成复杂表达式以验证引擎 SQL 生成器：生成复杂 SQL 语句以测试系统 决定事项 未来工作：集成 S3 Select 到 Spark, Presto 等分析应用中 优化方向：作为优化器，提高查询性能 后续行动计划 开发和测试：继续开发和测试 S3 Select 的功能 集成工作：探索与现有分析应用的集成可能性 会议结束 Gar Salomon 欢迎任何问题和反馈，并鼓励大家查看 GitHub 仓库以获取更多信息。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Understanding SeaStore through profiling","slug":"Understanding_SeaStore_through_profiling","date":"2022-11-13T16:00:00.000Z","updated":"2022-11-14T16:00:00.000Z","comments":true,"path":"2022/11/14/Understanding_SeaStore_through_profiling/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/14/Understanding_SeaStore_through_profiling/","excerpt":"","text":"会议纪要 会议主题：理解系统性能分析（System Profiling） 主讲人：Inching 背景介绍： Inching 在 Crimson 项目工作多年，主要熟悉 Crimson Messenger 及其姊妹项目。Crimson 项目旨在有效利用多核 CPU 驱动现代硬件的快速 I/O，采用共享内存设计以减少跨核心的互斥和共享资源，设计为租约完成以最小化跨核心跳转和接触开销，目标是使性能随核心数量可扩展。实现基于 C-star 框架，该框架桥接操作系统和硬件与 Crimson 软件，以实现设计目标。所有 Crimson 代码都在系统框架上实现。 主要议题： Crimson 和 Sister 项目的目标：有效利用多核 CPU 驱动快速 I/O，使用共享内存设计减少跨核心资源共享，设计为租约完成以最小化跨核心跳转和接触开销。 C-star 框架：桥接操作系统和硬件与 Crimson 软件，实现设计目标。 C-store 目标：支持多种设备（如 SSD、NVMe），具有不同的性能特征。 性能分析步骤： 生成工作负载：来自实验室 RPD 客户端或存储 MBD 直接生成。 收集指标：从 C-star 框架收集，需要在软件层实现。 数据可视化：理解收集数据的关系和性能趋势。 决定事项： 性能分析的重要性：诊断多重问题、预测性能趋势、识别不同实现的潜力、识别性能回归、验证不同特性和修复。 性能分析分为四个部分：存储背景、五个不同的性能分析部分、实际优化示例、关键要点。 后续行动计划： 继续开发和完善性能分析工具和方法。 根据性能分析结果进行优化和改进。 保持代码和工具的更新，以适应不断变化的需求。 关键要点： 性能分析是优化的大部分工作，已引入超过1000个指标和28个PR用于性能分析和工具开发，15个PR用于实际优化。 优化需要以性能分析为导向，确保方向正确，避免不必要的复杂性。 性能分析迭代需要在所有步骤中进行，包括识别问题、测试场景、重现问题、根本原因分析、提出解决方案和验证解决方案的有效性。 性能分析需要在引入的开销和代码复杂性之间取得平衡，以获得必要的分析步骤。 参考资料： C-star 框架介绍 收集指标数据的脚本 系统代码和日志结构化设计论文链接 问答环节： 问题：Crimson OST 和 C-store 能否根据实际工作负载性能特征自动优化，例如自动内存分配？ 回答：目前尚未考虑，当前优化主要针对严重问题。如果原始实现稳定后，这可能是一个好的方向。 问题：是否可以基于设置的标签追踪客户端 I/O，例如可开发设备引起的问题？ 回答：可能，但需要找到连接操作和问题的方法，因为它们通常在不同层次。 结论： Inching 详细介绍了 Crimson 项目的性能分析和优化过程，强调了性能分析在系统优化中的重要性，并提出了未来的优化方向和可能的改进措施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"How we operate Ceph at scale","slug":"How_we_operate_Ceph_at_scale","date":"2022-11-09T16:00:00.000Z","updated":"2022-11-10T16:00:00.000Z","comments":true,"path":"2022/11/10/How_we_operate_Ceph_at_scale/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/10/How_we_operate_Ceph_at_scale/","excerpt":"","text":"会议纪要 会议主题：DigitalOcean的Ceph存储系统运营实践 主讲人：Matt（DigitalOcean存储系统团队） 会议内容总结： 公司简介： DigitalOcean是一家成立于2012年的云服务提供商，以简单性为核心理念。 初期产品包括五美元的SSD支持的虚拟机（Droplet），后续推出了Volumes（可拆卸的Droplet存储）和Spaces（S3兼容的对象存储）等产品。 公司于2021年上市，目前在全球拥有八个数据中心。 团队介绍： 存储系统团队由六名工程师组成，目标是实现团队规模与部署规模解耦。 团队致力于自动化所有可能的操作，目标是无需通过SSH进行数据库操作。 Ceph在DigitalOcean的应用： Ceph在DigitalOcean用于块存储和对象存储，支持Volumes和Spaces产品。 目前运营着46个Ceph集群，其中38个为生产集群，总存储容量超过140PB。 自动化与运营： 自动化工具包括Chef、Ansible和AWX，用于配置管理和集群部署。 自动化流程涵盖从硬件采购到集群部署和维护的全过程。 自动化有助于减少人为错误，提高效率，特别是在大规模集群管理中。 挑战与解决方案： 面对大规模集群的运营挑战，DigitalOcean通过自动化和优化配置来应对。 针对Ceph集群中的性能问题，如PG peering延迟和RGW索引层性能，团队通过调整参数和优化流程来改善性能。 未来展望与招聘： 团队将继续优化自动化流程，探索新的技术解决方案，如Rook。 DigitalOcean正在招聘，欢迎有志之士加入。 决定事项： 继续推进自动化和优化Ceph集群的运营流程。 探索和评估新的技术解决方案，如Rook，以提高效率和性能。 后续行动计划： 持续监控和优化Ceph集群的性能。 加强团队建设，吸引和培养新的技术人才。 定期回顾和更新自动化流程，确保其适应不断变化的技术和业务需求。 会议结束语： 感谢Matt的精彩分享和团队的辛勤工作。 期待DigitalOcean在存储领域的进一步发展和创新。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimizing RGW Object Storage Mixed Media through Storage Classes and Lua Scripting","slug":"Optimizing_RGW_Object_Storage_Mixed_Media_through_Storage_Classes_and_Lua_Scripting","date":"2022-11-09T16:00:00.000Z","updated":"2022-11-10T16:00:00.000Z","comments":true,"path":"2022/11/10/Optimizing_RGW_Object_Storage_Mixed_Media_through_Storage_Classes_and_Lua_Scripting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/10/Optimizing_RGW_Object_Storage_Mixed_Media_through_Storage_Classes_and_Lua_Scripting/","excerpt":"","text":"会议纪要 会议主题 优化 RADOS Gateway 对象存储在混合媒体上的存储类和 Lua 脚本 主讲人 Kurt Bruns：Solidime 的软件工程师，同时也是 SPDK 项目的贡献者。 Anthony diatri：Index Exchange 的首席工程师，著有《Seth Learning Seth》第二版，并对 stuff 项目和文档部分有所贡献。 会议内容 背景介绍 RADOS Gateway (RGW) 部署的特点：对象大小多样，读取密集型工作负载（80% 读取，20% 写入），特别是在 AI 工作负载中，读取比例更高。 小对象操作需要高 IOPS 和低延迟，而大对象操作需要高读取吞吐量和带宽。 存储挑战 传统硬盘（HDD）虽然成本效益高，但 IOPS 和带宽有限，导致集群瓶颈。 SSD 成本较高，但性能优越，如何有效使用 SSD 是一个关键问题。 优化策略 使用存储类和 Lua 脚本在 RADOS Gateway 中实现对象存储的优化。 通过 S3 协议的存储类功能，将不同类型的对象引导到不同的存储池（例如，大对象到 HDD 或高容量 SSD 池，小对象到 SSD 池）。 技术细节 Blue Store 的 Min Alloc 大小为 4K，即使写入 1 字节也会分配 4K。 QLC SSD 的 Indirection Unit 为 64K，可能导致空间放大问题，特别是对于小对象。 通过 Lua 脚本在对象上传时检查存储类，并根据对象大小自动分配到合适的存储池。 实施细节 在 Quincy 版本中，引入了自动调整 OSD 的 Min Alloc 大小为 SSD 的最佳 I/O 大小。 RADOS Gateway 的 Lua 脚本修改了存储类头部的可写性，以便在对象上传时动态调整存储类。 结果展示 通过 Lua 脚本，成功简化了对象存储到正确池的路由，避免了用户手动选择存储类可能带来的问题。 示例展示了如何通过 Lua 脚本自动将 4K 对象和 64K 对象分别存储到 TLC 和 QLC 池中，从而优化存储效率。 后续行动计划 继续优化和扩展 Lua 脚本功能，以支持更多自定义的存储策略。 监控和评估优化后的存储性能，确保满足不同工作负载的需求。 参考资料 相关论文和演示文稿的链接。 RADOS Gateway Lua 脚本的相关文档和示例。 空间放大表和 TCO 计算器。 联系方式 Kurt Bruns 的电子邮件：kurt@solidime.com 会议总结 本次会议详细讨论了如何通过存储类和 Lua 脚本优化 RADOS Gateway 对象存储，特别是在混合媒体环境下的存储效率。通过自动化的存储类分配和 Lua 脚本，成功简化了对象存储的管理，并提高了存储效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"What's new with Crimson and Seastore?","slug":"What_s_new_with_Crimson_and_Seastore","date":"2022-11-09T16:00:00.000Z","updated":"2022-11-10T16:00:00.000Z","comments":true,"path":"2022/11/10/What_s_new_with_Crimson_and_Seastore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/10/What_s_new_with_Crimson_and_Seastore/","excerpt":"","text":"会议纪要 会议主题：Crimson项目介绍及近期开发工作 主讲人：Sam 会议内容总结： Crimson项目概述： Crimson项目的主要驱动因素是存储技术正朝着更高的IOP密度和更低的延迟发展，但CPU吞吐量并未同步提升。 项目目标：最小化每I/O的CPU开销，包括跨核心通信、拷贝和上下文切换，并利用新兴存储技术如NVMe。 Crimson项目目标： 重写OSD守护进程，以解决CPU开销和利用新兴存储技术的问题。 关键指标是每核心的IOPs，而非原始IOPs。 Crimson架构设计： 避免传统OSD线程模型中的核心切换，通过预分配每个核心的单个线程和分区数据结构来减少锁的使用。 使用C-star用户空间调度库来处理异步I/O结果，减少回调的使用。 C-store组件： C-store是一个新的对象存储实现，旨在避免CPU密集型的元数据设计，并利用新兴技术如NVMe和Zone Namespace Storage。 ZNS是一种新的NVMe规范，旨在解决传统FTL闪存设计中的垃圾收集问题，减少写放大和尾延迟。 近期开发工作： 稳定化Blue Store RBD RADOS测试，分割病理学套件为Crimson RADOS和Crimson RADOS实验版。 多核心支持：初始阶段专注于单核心实现，现已开始多核心数据结构分区和消息路由架构的开发。 快照支持：基本I/O路径组件已实现，修剪和恢复组件正在进行中。 用户保护措施：添加了实验性功能标志，防止用户意外创建Crimson OSDs。 下一步计划： 继续扩展测试覆盖范围，实现scrub功能以增强正确性验证。 多核心支持的进一步改进，包括多反应器支持和性能测试。 C-store的稳定性提升，包括多核心反应器支持和快照功能的实现。 问答环节： 对于想要尝试Crimson的开发者，建议使用vstart命令和Crimson标志进行部署。 Crimson未来将支持EC（Erasure Coding），但具体时间取决于后续工作进展。 后续行动计划： 继续推进Crimson和C-store的开发，特别是在多核心支持和性能优化方面。 完善文档和测试，确保Crimson能够安全地用于特定生产环境中。 定期发布性能测试数据，以便社区了解Crimson的进展和性能表现。 会议结束语： Sam感谢大家的参与，并期待在Reef版本中进一步测试和使用Crimson。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crash Telemetry - Observability in Action","slug":"Ceph_Crash_Telemetry_-_Observability_in_Action","date":"2022-11-08T16:00:00.000Z","updated":"2022-11-09T16:00:00.000Z","comments":true,"path":"2022/11/09/Ceph_Crash_Telemetry_-_Observability_in_Action/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/09/Ceph_Crash_Telemetry_-_Observability_in_Action/","excerpt":"","text":"会议纪要 会议主题：Telemetry项目更新，重点讨论Crash Telemetry 会议时间：[会议日期] 参会人员：[参会人员名单] 会议内容总结： Telemetry项目概述 Telemetry服务允许集群报告匿名和非识别数据，包括安装和配置信息。 数据汇总后在公共仪表板上展示，网址为Telemetry Dash public.sef.com。 用户可以通过CLI命令self telemetry on或在Ceph管理仪表板中选择加入。 Telemetry通道介绍 Basic Channel：包含集群的基本信息，如内核版本、集群大小、守护进程数量等，默认开启。 Crash Channel：提供集群中所有崩溃的信息，包括崩溃的回溯和在Ceph代码中发生的位置，默认开启。 Device Channel：收集集群中所有驱动器的健康指标，主要是SMART数据和NVMe指标，默认开启。 Ident Channel：允许用户选择性地识别自己，默认关闭。 Perf Channel：在Quincy版本中新增，包含集群性能计数器的信息，默认关闭。 隐私和数据安全 用户需要明确选择加入Telemetry报告，同意CDLA共享许可。 报告不包含敏感或识别数据，如池或主机名、对象名或内容。 集群被分配一个随机的UID，不报告FSID，不存储IP地址。 Telemetry的动机和好处 对开发者：了解功能使用情况，升级节奏，版本采用率，硬件部署情况，设备健康指标数据集，崩溃数据帮助优先处理常见问题。 对用户：验证安装，预先防范设备故障，减少停机时间，自动化处理崩溃报告节省时间。 Telemetry架构和流程 崩溃时，守护进程生成崩溃转储并写入本地磁盘，然后重启。 每个节点上的crash daemon定期检查并将新崩溃报告给Ceph集群的crash manager模块。 用户选择加入Telemetry和Crash Channel后，Telemetry每天查询数据库并编译报告发送至后端。 后端处理和分析 后端使用crash processor处理崩溃报告，去除偏移和地址，应用搜索和替换模式，计算签名，并更新数据库。 Redmine bot查询数据库，将崩溃签名映射到Redmine问题，更新或创建新问题，并识别回归问题。 用户交互和反馈 用户可以通过Redmine跟踪崩溃报告，未来将有工具提供集群崩溃的总体视图。 对于非bug崩溃，建议参考Redmine和博客文章中的故障排除分析。 仪表板演示和成功案例 内部仪表板允许搜索整个数据库，查看崩溃趋势，受影响的集群信息等。 成功案例包括Telemetry bot自动发现并报告问题，开发团队据此修复并回溯到旧版本。 后续行动计划： 继续优化Telemetry报告和后端处理流程。 开发更多用户友好的工具，帮助用户跟踪和管理集群崩溃。 鼓励用户选择加入Telemetry服务，提供更多支持和反馈。 会议结束语： 感谢所有参与者的积极参与和贡献，Telemetry项目已经取得显著成效，期待未来更多的合作和改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-11-03","slug":"Ceph_Performance_Meeting_2022-11-03","date":"2022-11-08T16:00:00.000Z","updated":"2022-11-09T16:00:00.000Z","comments":true,"path":"2022/11/09/Ceph_Performance_Meeting_2022-11-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/09/Ceph_Performance_Meeting_2022-11-03/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph分布式存储系统的性能问题，特别是关于librbd与qemu-kvm的性能差距、RBD镜像的性能问题以及Blue Store的优化方向。会议中涉及了多个技术议题，包括性能调优、加密对性能的影响、快照和快照修剪的性能问题，以及Blue Store的未来发展方向。 主要议题 librbd与qemu-kvm性能差距 讨论了一篇关于librbd与qemu-kvm性能差距的博客文章。 实验结果显示，在启用加密的情况下，16K随机读取的IOPS可以达到123,000，而随机写入的IOPS约为65,000。 加密导致性能下降约30%，主要原因是加密处理占用了messenger线程的大量时间。 RBD镜像性能问题 讨论了RBD镜像性能下降的问题，主要原因是快照和快照修剪导致的OSD使用率上升。 分析了对象碎片化和共享blob的问题，提出了两种解决方案：一种是减少共享blob，另一种是对象去碎片化。 目前这两种方案都有各自的优缺点，正在进行进一步的测试和优化。 Blue Store的优化方向 讨论了Blue Store的未来发展方向，包括可能的Blue Store 2版本。 提出了一些大的改变，如改进写路径、处理分层存储等。 讨论了是否值得进行这些大的架构改变，以及如何平衡性能和稳定性。 决定事项 将继续测试和优化RBD镜像的性能问题，特别是快照和快照修剪的影响。 对于Blue Store的优化，将考虑是否需要进行大的架构改变，以及如何实现这些改变。 将进行更多的实验和测试，以确定最佳的性能调优方案。 后续行动计划 继续跟踪和优化RBD镜像的性能问题，特别是快照和快照修剪的影响。 对于Blue Store的优化，将进行更多的讨论和实验，以确定最佳的发展方向。 将进行更多的性能测试，以确定最佳的性能调优方案。 其他事项 讨论了关于Blue Store的写路径优化，特别是如何处理小写入和大写入的问题。 讨论了如何更好地利用不同的存储设备，如NVMe和HDD。 会议总结 本次会议深入讨论了Ceph存储系统的多个性能问题，并提出了相应的解决方案和优化方向。后续将继续进行更多的测试和优化工作，以提高系统的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"State of the Cephalopod 2022","slug":"State_of_the_Cephalopod_2022","date":"2022-11-08T16:00:00.000Z","updated":"2022-11-09T16:00:00.000Z","comments":true,"path":"2022/11/09/State_of_the_Cephalopod_2022/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/11/09/State_of_the_Cephalopod_2022/","excerpt":"","text":"会议纪要 会议概述 本次会议旨在更新Ceph项目的最新进展，包括技术层面和项目管理层面。会议首先回顾了项目层面的动态，随后深入讨论了Quincy和Reef版本的更新内容。 项目管理更新 领导结构变更：Ceph项目创始人Sage Weil已逐渐退出日常管理，项目采用新的治理模式，由Ceph领导团队和选举产生的执行委员会共同领导。 开放性和协作：Ceph领导团队会议对所有人开放，会议笔记通过邮件列表共享，技术讨论和项目影响决策也在此进行。 重点领域：过去几年重点改善了内部发布流程，增强了稳定性，引入了发布候选版本，加强了性能和可扩展性测试。 技术更新 性能与可扩展性：Quincy版本在大型测试集群中进行了大量测试，包括在澳大利亚的Pawsey超级计算中心测试了4000个OSD，以及在逻辑规模上模拟大型集群测试。 关键功能更新： RADOS：Quincy版本中引入了默认启用的QoS功能，改进了Blue Store的性能，包括移除RocksDB的分配元数据，改进了BlueFS，实现了更细粒度的锁定机制。 Reef版本展望：将引入客户端间QoS的初步实现，改进M clock调度器以支持高优先级操作，Blue Store将支持自定义WAL，改进4K分配单元等。 Crimson项目：作为高性能的RADOS读取器，Crimson在Reef版本中将增加多反应器支持，改进可用性，并计划在S版本中完成 scrub 实现。 Telemetry：Quincy版本增强了数据收集流程，新增了Both Channel收集性能指标，改进了崩溃报告分析，Reef版本将继续优化数据分析和设备故障预测模型。 社区和基金会动态 Ceph基金会：维护了健康的会员结构，包括10个主要成员，13个普通成员和11个关联成员，负责协调活动和资助上游测试实验室。 用户和开发者活动：推出了每月虚拟事件，鼓励新开发者参与，如Google Summer of Code和Outreachy，以及定期的技术讲座。 后续行动计划 版本更新：当前专注于Reef版本的开发，即将开始S版本的命名讨论和开发。 社区参与：鼓励社区成员参与技术讨论和测试新功能，特别是对Telemetry的参与和反馈。 结论 会议强调了Ceph项目在技术和管理层面上的持续进步，呼吁社区成员积极参与和支持即将到来的版本更新和技术发展。会议资料将通过邮件列表分享，欢迎后续交流和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2022-08-16","slug":"Ceph_Crimson_SeaStore_Meeting_2022-08-16","date":"2022-10-19T16:00:00.000Z","updated":"2022-10-20T16:00:00.000Z","comments":true,"path":"2022/10/20/Ceph_Crimson_SeaStore_Meeting_2022-08-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/20/Ceph_Crimson_SeaStore_Meeting_2022-08-16/","excerpt":"","text":"会议纪要 日期： [具体日期] 参会人员： [具体人员名单] 会议主要内容： OSD Map 共享优化 讨论了创建一个外部指针模拟，以高效共享 OSD Maps 的解决方案。目前已有初步方案，正在进行多核处理优化。 GNS 补丁更新 Aaron 提交了 GNS 补丁的第二版，根据评审意见进行了修改。讨论了关于新函数 advance 的使用和命名问题，决定将其分为两个调用：advance 和 write。 针对 CI 中 ZNS 构建失败的问题，建议 Aaron 发送邮件给 Seth 和 David Galloway，请求更新 CI 机器上的内核版本以支持 ZNS。 ZNS 测试进展 Aaron 报告了在物理 ZNS 驱动上进行的测试情况，计划进行更长时间的测试，并保持更新。 事务管理器优化 讨论了事务管理器中的一些特定机制，特别是与随机块管理器实现相关的部分。目前正在准备设备清除的更改，并优化异步清理接口。 Key Range Remove 和 Omap 合并策略 讨论了 Key Range Remove 的复杂性，并找到了更好的 Omap 合并策略，以确保 B+ 树结构的稳定性。 测试环境更新 报告了测试环境中的进展，目前 60% 的测试已通过，正在解决系统挂起的问题。 其他更新 讨论了 Fish Bay Tree 代码的优化，以及提交的两个 PR 以修复发现的次要问题。 决定事项： Aaron 将发送邮件给 Seth 和 David Galloway，请求更新 CI 机器上的内核版本以支持 ZNS。 确定 advance 函数的使用和命名问题，将其分为两个调用：advance 和 write。 后续行动计划： Aaron 将继续进行 ZNS 的长时间测试，并保持更新。 继续优化事务管理器和异步清理接口。 完成 Key Range Remove 和 Omap 合并策略的改进。 解决测试环境中的系统挂起问题，并完成剩余的测试。 会议结束： 会议在讨论了所有议题后结束，所有参会人员祝大家一周愉快。 备注： - 请相关人员按照会议决定和行动计划推进工作。 - 如有任何问题或需要进一步讨论的事项，请及时沟通。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2022-10-19","slug":"Ceph_Crimson_Seastore_Meeting_2022-10-19","date":"2022-10-19T16:00:00.000Z","updated":"2022-10-20T16:00:00.000Z","comments":true,"path":"2022/10/20/Ceph_Crimson_Seastore_Meeting_2022-10-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/20/Ceph_Crimson_Seastore_Meeting_2022-10-19/","excerpt":"","text":"会议纪要 主要议题与讨论内容 Crimson Suite 重组 本周已合并一个 PR，将 c-store 相关内容移至 Crimson rados experimental Suite。 目前 RBD 测试尚未通过，主要涉及额外快照支持问题，Erratic 正在处理。 安全特性增强 提交了一个 PR，增加了 Crimson 和非 Corpson 用户的安全特性。 添加了 OSD map 标志和 pool 标志，以防止 Crimson osds 在未设置标志的情况下创建 pgs。 正在研究添加配置选项，以便在不传递命令行参数的情况下更改 --s p 选项。 Scrub 工作进展 计划继续推进 scrub 工作。 Messenger V2 协议实现 King John 正在审查随机块管理器和 Messenger V2 协议实现。 需要将协议握手阶段和协议就绪阶段分离，以支持 mod core。 Crimson Loop 优化 Junior 发现 Crimson Loop 可能导致栈溢出，正在研究 Sister Loop 的实现并尝试应用到 Crimson。 Open SSO 和 Segmentation 问题 Jensen 发现重复的 Humanity 问题，怀疑是配置差异导致，询问是否有关于 Open SSO 或 Segmentation 的更新。 内存管理问题 讨论了关于内存存储的 PR，涉及使用分区或多设备的问题，存在一些 bug 需要调试。 LBA 树指针问题 完成了 LBA 树指针的调试，正在尝试添加 LBA 叶子节点和逻辑扩展之间的指针。 决定事项 确保 Crimson rados 测试套件稳定。 完成快照实现，确保 ADM 安装和文档完善。 推进 scrub 工作。 后续行动计划 继续优化和稳定 Crimson rados 测试套件。 完成快照实现，确保 Crimson 的功能稳定。 推进 scrub 工作，确保 Reef 代码冻结前的准备工作。 在明年一月，重点将转向性能优化和 c-store 相关工作。 其他 会议中还讨论了关于 Open SSO 和 Segmentation 的问题，以及内存管理和 LBA 树指针的优化工作。 强调了确保 Crimson 功能稳定的重要性，以便进行性能测试。 会议结束 会议结束时，鼓励团队成员继续关注并贡献于上述目标，确保 Crimson 在 Reef 代码冻结前达到稳定状态。 会议最后提醒大家有一个愉快的一周，并结束了会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-08-18","slug":"Ceph_Performance_Meeting_2022-08-18","date":"2022-10-19T16:00:00.000Z","updated":"2022-10-20T16:00:00.000Z","comments":true,"path":"2022/10/20/Ceph_Performance_Meeting_2022-08-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/20/Ceph_Performance_Meeting_2022-08-18/","excerpt":"","text":"会议纪要 PRS (Pull Requests) 更新 新提交与关闭的PR： 在Crimson的c-store日志代码中，通过将缓冲区列表移动来减少内存复制的新PR，由Shoihan提交并已立即合并。 在rgw中，关于deos后端blue代码的PR，作者已关闭，可能会有使用更优库或新版本库的新PR提交。 更新中的PR： 由Josh Solomon添加的主要平衡评分到平衡器的PR，正在审查中。 关于boost Valgrind的cmake更改，讨论较多，但已基本准备就绪。 Igor的PR，关于在每个事务中移除状态更新，已添加到whipTheory测试中，有望很快合并。 讨论议题 RocksDB Tombstone 移除项目： Adam建议尝试修改RocksDB本身，在迭代过程中看到一定数量的tombstones时发出memtable刷新。 经过代码审查，发现实现这一功能可能不简单，且现有代码主要针对elite tombstones而非elite range tombstones。 建议在KV层自行跟踪删除和删除范围，手动触发压缩或刷新，这样代码会更简单易处理。 后续行动计划 继续关注和审查现有PR的进展。 与Adam进一步讨论RocksDB Tombstone移除项目的实施方案。 其他事项 会议中未提及其他重要事项，会议简短结束。 会议结束 感谢所有参与者的出席，并祝大家本周愉快。 会议主持人：[未提及] 记录人：[未提及] 日期：[未提及] 参会人员：[未提及]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-10-13","slug":"Ceph_Performance_Meeting_2022-10-13","date":"2022-10-19T16:00:00.000Z","updated":"2022-10-20T16:00:00.000Z","comments":true,"path":"2022/10/20/Ceph_Performance_Meeting_2022-10-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/20/Ceph_Performance_Meeting_2022-10-13/","excerpt":"","text":"会议纪要 会议主题： 性能测试工具CBT（Ceph Benchmarking Tool）在不同存储后端（如Motor和Deos）的比较。 讨论内容： CBT的使用： 计划使用CBT来比较不同的存储后端，特别是Motor和Deos。 讨论了这些后端的当前状态和是否能够通过CBT的测试。 Motor和Deos的状态： Motor和Deos都是开源项目，但可能需要特定的硬件支持。 Deos由Intel开发，而Motor由Seagate开发。 CBT的抽象和扩展： 讨论了如何改进CBT，使其不仅限于Ceph，还能支持其他存储系统如Deos。 提出了在CBT中增加对Deos集群的支持，并扩展客户端端点的功能。 性能和功能实现： 讨论了Deos的性能，特别是在未启用复制模式下的高速表现。 提到了Deos的一些功能还未完全实现，如多部分上传。 合作与联系： 建议与Seagate合作，共同推进CBT的发展。 确定了与Seagate团队的联系人Gregory Taretsky。 后续行动计划： Mark计划首先尝试安装和运行这些存储系统，并记录部署过程。 计划逐步自动化这些过程，并探索如何将这些系统集成到CBT中。 决定事项： 确定与Seagate的合作，特别是关于Motor和Deos的集成。 Mark将负责初步的安装和测试工作，并与Seagate团队联系。 后续行动： Mark将联系Gregory Taretsky，获取更多关于Motor和Deos的信息。 继续改进CBT，使其支持更多的存储后端和性能测试。 其他讨论： 讨论了RBD的性能改进，特别是与Seagate的合作和CBT的扩展。 提到了Deos的高性能表现和潜在的应用场景。 会议结束： 会议在讨论了所有议题后结束，感谢所有参与者的贡献。 本次会议主要聚焦于Ceph生态系统中不同存储后端的性能测试和集成，特别是通过CBT工具来实现这一目标。通过与Seagate的合作，预计将能够更好地理解和优化这些存储系统的性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-10-20","slug":"Ceph_Performance_Meeting_2022-10-20","date":"2022-10-19T16:00:00.000Z","updated":"2022-10-20T16:00:00.000Z","comments":true,"path":"2022/10/20/Ceph_Performance_Meeting_2022-10-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/20/Ceph_Performance_Meeting_2022-10-20/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph项目的两个新的Pull Request（PR），以及一些关于性能优化和数据恢复的讨论。 主要议题 PR讨论 PR1: 来自Canonical的贡献者发现了一个与Unknown Cash相关的竞态条件（race condition），由Igor提交。这个修复看似简单，但可能存在一些潜在的问题。已将Igor添加为审阅者。 PR2: Adam提交的关于改进Deferred决策的PR。会议中讨论了可能的改进方向，包括完全移除Deferred路径的可能性。 性能问题 讨论了使用Secure Mode时客户端性能显著下降的问题，可能与Adam Emerson的SEO优化有关。这是一个需要进一步调查的假设。 数据恢复 讨论了一个新的数据恢复方法，该方法涉及使用RocksDB的快照进行数据恢复。虽然这种方法可能有助于快速恢复，但也存在数据不一致的风险。需要进一步讨论和测试。 Deferred Writes优化 讨论了完全移除Deferred Writes的可能性，并探讨了如何通过改进内核设备和块设备接口来优化写入过程。 RocksDB的碎片化和Tombstones问题 讨论了RocksDB在处理大量删除操作时的性能问题，特别是与SST文件和Memtable中的Tombstones相关的问题。提出了一些可能的解决方案，包括改进RocksDB的设置和自定义删除跟踪。 决定事项 需要对PR1和PR2进行进一步的审查和测试。 对于Secure Mode性能下降的问题，需要进行详细的性能分析。 数据恢复方法需要更多的讨论和测试，以确保其安全性和有效性。 对于Deferred Writes的优化，需要进一步的研究和实验。 RocksDB的碎片化和Tombstones问题需要更多的诊断工具和可能的改进措施。 后续行动计划 对PR1和PR2进行代码审查和测试。 对Secure Mode的性能进行详细分析。 进一步讨论和测试数据恢复方法。 研究和实验Deferred Writes的优化方案。 开发和测试RocksDB的碎片化和Tombstones问题的解决方案。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并祝愿大家有一个愉快的一周。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph RGW Refactoring Meeting 2022-10-19","slug":"Ceph_RGW_Refactoring_Meeting_2022-10-19","date":"2022-10-19T16:00:00.000Z","updated":"2022-10-20T16:00:00.000Z","comments":true,"path":"2022/10/20/Ceph_RGW_Refactoring_Meeting_2022-10-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/20/Ceph_RGW_Refactoring_Meeting_2022-10-19/","excerpt":"","text":"会议纪要 会议概要 日期与时间: [具体日期] 参与人员: 会议邀请了新面孔，所有参与者欢迎并鼓励提出议程话题。 主要议题: 讨论了一个关于MQTT消息转换为S3对象的小型项目，以及关于多部分上传对象的问题和解决方案。 主要讨论内容 MQTT消息转换项目介绍 项目背景: 由Yuval介绍，该项目针对工业物联网空间，使用MQTT作为主要协议，部分信息需要短期管理，而其他信息需要长期存储供数据科学家或机器学习训练使用。 项目目标: 解决直接将MQTT消息作为S3对象存储的效率问题，提出通过转换器将MQTT消息聚合为S3对象。 技术细节: 转换器配置包括MQTT代理、S3端点、聚合逻辑和桶与主题的映射。项目还包括一个Python代码用于从聚合对象中提取原始消息。 多部分上传对象问题讨论 问题描述: 讨论了多部分上传对象中重复上传导致的孤立数据问题，特别是在计费方面的影响。 解决方案: 探讨了使用多部分上传API进行结构化数据上传的可能性，以及如何通过改进上传流程来避免问题。 合作与进展: 提到了与Matt的合作，以及如何通过代码审查和测试来推进解决方案。 决定事项 项目推进: Yuval的项目将继续进行，包括容器化和在Kubernetes环境中的部署。 问题解决: 对于多部分上传对象的问题，将通过与Matt的合作，共同探讨和实现可行的解决方案。 后续行动计划 技术实施: 继续完善MQTT消息转换项目，确保其在实际环境中的有效性和稳定性。 问题解决: 与Matt合作，详细了解其解决方案的设计，并进行必要的代码审查和测试。 沟通与协作: 保持团队间的沟通，确保所有参与者对项目进展和问题解决有清晰的了解。 其他事项 会议记录: 鼓励所有参与者在有新议题时更新会议文档。 技术支持: 提供了关于使用Jaeger进行多部分上传跟踪的建议，以帮助更好地管理和调试相关问题。 会议结束 下次会议: 提醒所有参与者下次会议的时间，并鼓励继续提出新的议题和建议。 备注: 本次会议记录涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的全面性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-10-18","slug":"Ceph_Orchestrator_Meeting_2022-10-18","date":"2022-10-17T16:00:00.000Z","updated":"2022-10-18T16:00:00.000Z","comments":true,"path":"2022/10/18/Ceph_Orchestrator_Meeting_2022-10-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/18/Ceph_Orchestrator_Meeting_2022-10-18/","excerpt":"","text":"会议纪要 会议主题：Ceph基准测试与不同后端的比较 主要讨论内容： CBT工具的使用： 讨论了使用Ceph Benchmarking Tools (CBT)来比较不同的存储后端，特别是针对不同的zipper后端。 提到了DB store可能是一个可以运行的后端，但对于其他后端的状态不确定是否能够通过这些工作负载。 后端状态与兼容性： 讨论了Motor和Deos后端的状态，特别是它们是否已经合并到上游以及是否需要特殊硬件。 确认Motor是开源的，但不确定是否需要Seagate硬件。Deos是Intel的产品。 CBT集群抽象： 讨论了改进CBT集群抽象的必要性，使其不仅仅支持Ceph。 提到了可能首先支持Deos，然后扩展CBT的客户端端点以支持不同的操作。 功能实现与性能： 讨论了Deos的一些基本功能如put、delete、bucket listing已经实现，但multipart upload等功能尚未实现。 提到了Deos在Lenovo的IO-500测试中表现出色，尤其是在未启用复制模式时。 后续行动计划： Mark计划首先尝试安装和运行Deos，并记录部署过程，以便后续自动化。 计划与Seagate合作，特别是与Gregory Tarletsky联系，以获取更多技术支持和合作。 决定事项： 确定使用CBT工具进行不同后端的基准测试。 确认与Seagate的合作，特别是关于Motor和Deos后端的测试和集成。 后续行动： Mark将尝试安装和运行Deos，并记录部署过程。 将与Seagate的Gregory Tarletsky联系，以获取更多技术支持和合作。 继续改进CBT集群抽象，使其支持更多类型的存储后端。 其他讨论点： 讨论了RBD和RGW的性能改进，特别是与SEO的集成可能带来的性能提升。 提到了多站点重启问题的复杂性，以及客户端性能优化的潜力。 会议结束： 会议在讨论了所有议程后结束，感谢所有参与者的贡献和讨论。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW Refactoring Meeting 2022-10-12","slug":"RGW_Refactoring_Meeting_2022-10-12","date":"2022-10-17T16:00:00.000Z","updated":"2022-10-18T16:00:00.000Z","comments":true,"path":"2022/10/18/RGW_Refactoring_Meeting_2022-10-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/18/RGW_Refactoring_Meeting_2022-10-12/","excerpt":"","text":"会议纪要 会议主题： 使用CBT（Ceph Benchmarking Tool）进行不同zipper后端（如DB store、Motor、Deos）的性能比较。 主要讨论内容： CBT的使用和目标： 讨论了使用CBT进行不同后端的性能比较，特别是DB store和Deos。 提到了Deos和Motor的开发状态，以及它们是否能够通过这些工作负载。 Deos和Motor的状态： Deos和Motor都是开源项目，但可能需要特定的硬件支持。 Deos和Motor的后端由Seagate贡献，Intel也在其中有所参与。 CBT的抽象和扩展： 讨论了如何改进CBT，使其不仅仅支持Ceph，还能支持其他存储系统如Deos。 提到了可能的下一步行动，包括设置Deos并构建CBT中的客户端端点。 性能测试和比较： 讨论了如何进行性能测试，包括使用IO 500和RGW。 提到了Deos在Lenovo的IO-500测试中表现出色，尤其是在未启用复制模式下。 后续行动计划： 计划与Seagate合作，进一步测试和集成Motor和Deos到CBT中。 计划探索如何自动化安装和部署这些存储系统。 计划与Seagate的Gregory Taretsky联系，以获取更多技术支持和合作。 决定事项： 确认了与Seagate的合作意向，并将与Gregory Taretsky联系以推进合作。 确定了初步的行动计划，包括手动安装和测试Deos和Motor，以及后续的自动化和集成工作。 后续行动： Mark将尝试手动安装Deos和Motor，并记录过程，以便后续自动化。 将与Seagate的Gregory Taretsky联系，以获取更多技术支持和合作。 将继续探索和改进CBT，使其支持更多类型的存储系统。 会议结束： 会议在讨论了所有议题后结束，感谢所有参与者的贡献和讨论。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-09-13","slug":"Ceph_Orchestrator_Meeting_2022-09-13","date":"2022-10-11T16:00:00.000Z","updated":"2022-10-12T16:00:00.000Z","comments":true,"path":"2022/10/12/Ceph_Orchestrator_Meeting_2022-09-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/10/12/Ceph_Orchestrator_Meeting_2022-09-13/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题及讨论内容 1. Open Source Day 活动准备 日期确认：Open Source Day 将于16日（周五）举行。 活动内容：活动中将邀请参与者解决一些低难度的技术问题（low hanging fruit issues）。 问题管理：会议中提到需要确保这些问题列表中的任务确实属于低难度，以便参与者能够在一日内完成。建议移除不适合的任务，并考虑添加新的、易于解决的问题。 后续行动：需要团队成员在接下来的几天内关注并参与，以避免因快速修复复杂问题而导致的后续问题。 2. 编译相关工作（Compile Stuff Idiom） 进展更新：自上次邮件通知以来，反馈较少。团队已准备好进行测试和合并相关代码。 具体操作：虽然John今天不在，但团队计划继续推进，解决当前开放的pull requests，并修复合并冲突。 测试与合并：计划在解决所有技术问题后，进行测试并合并代码。 后续步骤：讨论了增加单元测试和重构的必要性，计划在合并后进行。 3. RGW（RADOS Gateway）相关工作 当前状态：正在进行中，主要关注于如何支持区域组和区域的创建及管理。 技术细节：讨论了区域组和区域的端点问题，决定提供给用户手动设置的选项，如果没有提供，则自动从Ceph管理端获取。 后续计划：计划先实现基本功能，后续再逐步增加更复杂的功能。 决定事项 确认Open Source Day的具体任务列表，并进行适当的调整。 继续推进编译相关工作的测试和合并。 逐步实现RGW的基本功能，并考虑未来的扩展。 后续行动计划 团队成员需在接下来的几天内关注Open Source Day的活动，并准备相应的任务。 继续处理编译相关工作的pull requests，并准备测试和合并。 开始实现RGW的基本功能，并逐步完善。 会议结束 会议在讨论完所有议题后结束，未提出新的议题。 计划在下次站立会议中继续讨论未尽事宜。 会议记录人：[记录人姓名] 审核人：[审核人姓名]会议纪要： Open Source Day 计划： 日期确认为X月X日（周五）。 将有随机贡献者出现，处理低挂果问题。提供了一个链接，列出了所有相关的问题。 会议中提出对列表中的七到八个问题进行审查，确保它们是实际可管理的问题。 决定可能移除一些不应包含在列表中的问题，并添加新的追踪器，标记相关的加载组，以便处理。 Ceph Compile Stuff Idiom： 自从上次向用户列表发送邮件已过去两周，反馈有限，仅一个新评论和对PR的一般性反馈。 CLT调用未遇到任何阻碍，除了希望最终签名包。 John不在场，他最近负责处理这个问题。询问了他的进展。 讨论了当前在我的测试标签下打开的拉请求，想合并它们。认为至少有几个影响二进制文件，任何触及二进制文件的操作都会引起合并冲突，但应该容易解决。 一旦这些问题得到解决并且合并完成，就准备测试然后移动实施。没有外部阻碍我们进行这项操作。 Ceph RGW功能更新： 工作正在进行中，由于支持和命令实现的不确定性，计划一直在变动。 正在与Guillaume以及RSW团队沟通确定要做什么。 目前正试图搞清楚如何同时支持创建轮次和添加Zone组及区域。 正在尝试提供基本的命令和灵活的设置，使RGW环境配置尽可能少的用户干预。 目标是从最基本的自动化开始，慢慢增加更复杂的特性。 行动计划： 对于Open Source Day的问题列表进行清理，确保只有正确和可管理的问题被标记。 继续监测Ceph Compile Stuff Idiom的合并和测试过程，并在有问题时协调解决。 对于RGW功能，计划在接下来的一周内至少开始一些基础的工作，并继续与RSW团队合作明确需求和解决方案。 其他事项： 没有其他议题需要讨论。 会议结束，下一步行动将在周四的站立会议上继续讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-09-27","slug":"Ceph_Orchestrator_Meeting_2022-09-27","date":"2022-09-28T16:00:00.000Z","updated":"2022-09-29T16:00:00.000Z","comments":true,"path":"2022/09/29/Ceph_Orchestrator_Meeting_2022-09-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/29/Ceph_Orchestrator_Meeting_2022-09-27/","excerpt":"","text":"会议主题1：关于RW spec格式 会议主题2：新支持的包装Café ADM 会议主题3：版本信息问题 会议主题4：部署Stefidium的方式 会议主题5：二进制中的版本信息 会议主题6：获取Cepharium的方式 会议主题7：发布过程中的链接和签名问题","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW Refactoring Meeting 2022-09-28","slug":"RGW_Refactoring_Meeting_2022-09-28","date":"2022-09-28T16:00:00.000Z","updated":"2022-09-29T16:00:00.000Z","comments":true,"path":"2022/09/29/RGW_Refactoring_Meeting_2022-09-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/29/RGW_Refactoring_Meeting_2022-09-28/","excerpt":"","text":"会议纪要： 讨论主题：Ceph分布式存储系统的性能指标优化和模块化进程。 主要关注点：如何管理和优化大量的性能计数器，并处理模块化过程中遇到的问题。 参与者： Yvonne（Ceph导出器开发者） Ilya（RBD领导） Casey（参与讨论并提出问题和建议） 关键议题： 性能计数器的管理和优化：Yvonne提到她有支持标签化性能计数器的工具，而Ilya表示不需要太多标记的性能计数器。Casey询问了关于性能计数器爆炸性增长的问题以及如何进行过滤。 自动化策略的探讨：Casey提出一个自动化的方法来识别“热用户”和“热存储桶”，从而只启用那些被认定为“热”的标记性能计数器。 模块化进程：Ilya谈到了他在管理admin APIs时进行的模块化进程，并提出了在S3层操作中分离pub/sub操作的问题。 决定事项： 短期内，将重点放在优化现有的性能计数器管理上，不立即实施复杂的自动化策略。 长期解决方案可能需要构建一个新的系统，该系统能够根据用户的需求动态地启用或禁用特定的性能计数器。 需要进一步讨论如何处理Prometheus无法处理大量性能计数器的问题。 后续行动计划： Yvonne将继续完善她的标签化性能计数器工具，并在下一周展示新版接口。 Ilya和团队将继续进行模块化进程，特别是解决pub/sub操作的分离问题。 Casey将探索自动化策略，以更有效地管理性能计数器。 其他讨论： 讨论了HTTP 3前端原型的开发和测试，欢迎感兴趣的成员参与。 结论： 会议围绕Ceph的性能优化和模块化进程进行了深入讨论，确定了短期和长期的行动计划，并鼓励团队成员继续在这些领域进行探索和开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Making Teuthology a Better Detective","slug":"Ceph_Tech_Talk_-_Making_Teuthology_a_Better_Detective","date":"2022-09-27T16:00:00.000Z","updated":"2022-09-28T16:00:00.000Z","comments":true,"path":"2022/09/28/Ceph_Tech_Talk_-_Making_Teuthology_a_Better_Detective/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/28/Ceph_Tech_Talk_-_Making_Teuthology_a_Better_Detective/","excerpt":"","text":"会议纪要： 实习生介绍了她在夏季实习期间参与的项目，该项目涉及改进存储领域分布式存储Ceph的测试流程。 项目的目标是优化测试流程，提高错误检测的准确性和效率。 实习生与导师合作，解决了在测试中遇到的一个问题：当单元测试失败时，系统仅抛出一个模糊的错误信息，导致难以确定具体哪个单元测试未通过。 提出的解决方案是自动化地扫描日志文件，找出并记录具体的单元测试错误，而不是通用的错误代码。 该解决方案以可选方式实现，允许团队选择是否启用此功能。 实习生展示了如何实施这一方案，并讨论了其对工程师节省时间、改善错误追踪和记录的具体益处。 她还提出了未来可以采纳此功能的更多测试类型，并分享了用于实施该解决方案的代码。 最后，她强调了在采用新功能时进行彻底的检查的重要性，以确保其准确性，并鼓励通过跟踪器报告任何问题或遗漏的测试用例。 参会人员对实习生的工作表示赞赏，并就如何进一步改进和扩展该功能提出了建议。 行动事项： - 继续监测和评估自动化错误检测功能的表现。 - 鼓励用户通过跟踪器报告使用该功能时遇到的问题或遗漏的测试用例。 - 考虑将该功能扩展到其他类型的测试中。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Walkthrough: Ceph Release Process","slug":"Walkthrough_-_Ceph_Release_Process","date":"2022-09-27T16:00:00.000Z","updated":"2022-09-28T16:00:00.000Z","comments":true,"path":"2022/09/28/Walkthrough_-_Ceph_Release_Process/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/28/Walkthrough_-_Ceph_Release_Process/","excerpt":"","text":"会议纪要： 讨论了Ceph的发布流程，包括签名机器从OCTA实验室迁移到sepia实验室、GPG密钥的管理和使用、以及构建和发布Ceph包的过程。 提到了新的主版本发布，特别是对于Reef分支的处理，包括创建新的repo文件和通知chakra节点。 描述了Yuri在测试和准备发布新版本时的角色，以及如何将代码推送到相应的Dash发布分支。 讨论了热修复和安全更新的特殊处理方式，包括使用最近的标签进行构建和推送到特定的私有仓库。 介绍了构建过程，包括Jenkins作业的配置、构建失败的处理、以及如何编写和发布发布说明。 强调了在构建完成后，如何使用GPG密钥签名Debian和RPM包，并将构建结果推送到下载服务器。 提到了容器构建的过程，包括x86和arm64容器的构建，并讨论了如何确保构建成功并发布到相关平台。 回答了关于如何处理构建失败、添加新架构或依赖项的问题，并提供了相关的解决方案和建议。 后续行动计划： - 确保所有参与者都理解Ceph发布的每个步骤，并能够按照文档执行。 - 对于新的主版本发布，特别是Reef分支，需要更新chakra节点并重新部署shock。 - 在遇到构建问题时，根据错误类型联系相应的组件负责人或基础设施团队。 - 对于新依赖项，尝试将其包含在Apple中，如果无法实现，则在copper仓库中提供，直到它们在主要分发版中可用。 - 继续监控和维护lab extras仓库，以确保构建和测试过程中所需的依赖项始终可用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-09-22","slug":"Ceph_Performance_Meeting_2022-09-22","date":"2022-09-25T16:00:00.000Z","updated":"2022-09-26T16:00:00.000Z","comments":true,"path":"2022/09/26/Ceph_Performance_Meeting_2022-09-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/26/Ceph_Performance_Meeting_2022-09-22/","excerpt":"","text":"会议纪要： 会议主题：讨论Ceph分布式存储系统中的优化和性能改进。 参会者：Mark、Ronan、Adam等。 主要讨论内容： Mark就上周取消的会议表示歉意，并提到他在准备与Adam讨论一些\"令人兴奋的事情\"。 Ronan询问了关于“Deep scrub”的讨论是否在邮件列表上进行，以及是否有其他私下的邮件交流。 Adam介绍了他最近的工作，包括对对象进行碎片整理以减少写入操作的数量，以及一个用于跟踪所有对象及其克隆的单一跟踪器的实现。 提出了通过将负载从共享块转移到CPU密集型操作来改善性能的方法，并讨论了其潜在的改进效果。 讨论了新的跟踪器方法如何有效地管理快照和克隆，以及如何简化数据结构。 分析了新方法对CPU使用率和IOPS的影响，以及它如何减少空间放大和写入负载。 提到了Jitter的概念，以及如何通过引入Jitter来平滑IO负载。 讨论了在硬盘驱动器上进行快照和碎片整理的潜在影响，以及未来可能需要不同的方法。 提到了rgw的HTTP 3前端的PR，以及它可能带来的性能提升。 最后，讨论了当前Ceph集群部署的CPU使用情况，以及如何进一步降低开销。 行动计划： 继续测试和优化Adam提出的方法。 探讨将新方法集成到现有系统的可能性。 分析新方法在硬盘驱动器上的性能表现。 关注rgw的HTTP 3前端开发的进展，并评估其对性能的影响。 计划下周继续讨论，并鼓励大家度过愉快的一周。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2022-09-23","slug":"Ceph_Crimson_Seastore_Meeting_2022-09-23","date":"2022-09-22T16:00:00.000Z","updated":"2022-09-23T16:00:00.000Z","comments":true,"path":"2022/09/23/Ceph_Crimson_Seastore_Meeting_2022-09-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/23/Ceph_Crimson_Seastore_Meeting_2022-09-23/","excerpt":"","text":"会议主要讨论了Ceph分布式存储系统中的多项技术议题，包括多核分支的进展情况、omap范围移除功能的优化、以及系统内部的一些关键性错误修复和性能提升措施。具体地，讨论集中在如何优化存储节点的负载、内存拷贝效率、树状结构的调整和平衡，以及与系统稳定性和性能相关的问题。此外，还探讨了在高填充率情况下设备的行为，和对Ceph核心代码进行重构的可能性和计划。会议涉及了对当前实现的效率问题和未来可能的改进方向的深入分析。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-09-20","slug":"Ceph_Orchestrator_Meeting_2022-09-20","date":"2022-09-20T16:00:00.000Z","updated":"2022-09-21T16:00:00.000Z","comments":true,"path":"2022/09/21/Ceph_Orchestrator_Meeting_2022-09-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/21/Ceph_Orchestrator_Meeting_2022-09-20/","excerpt":"","text":"会议纪要 会议主题：视频编译相关事宜 主要议题： 测试覆盖率提升： 讨论了如何提高视频相关文件的测试覆盖率，特别是 video.py 文件。 目标是将覆盖率提升至80%，但强调了实际操作中应关注重要功能的测试，而非单纯追求百分比。 测试策略： 确定了通过增加单元测试来提高覆盖率的方法。 计划使用 pytest 生成覆盖率报告，并根据报告识别和优先测试缺失的关键功能。 分工合作： 决定在 Etherpad 上创建一个列表，列出需要测试的功能，并由团队成员自行认领。 强调了避免重复工作，确保每个功能都有人负责测试。 文档更新： 讨论了更新文档以指导用户如何自行编译视频文件。 提出了未来可能需要一个下载链接，但目前主要关注文档的更新。 决定事项： 测试覆盖率目标：不设定硬性百分比目标，而是确保所有关键功能都有测试覆盖。 分工方式：通过 Etherpad 列表进行分工，确保每个功能都有明确的负责人。 文档更新：尽快更新文档，提供编译指导，并标记已知问题。 后续行动计划： 测试工作：团队成员根据 Etherpad 列表认领测试任务，并开始编写单元测试。 文档更新：整理并提交文档更新 PR，确保文档准确反映当前的编译流程。 下载链接：探索并联系相关人员，讨论未来提供下载链接的可能性。 其他讨论点： 代码质量：未来考虑增加代码质量检查，如函数复杂度等。 代码重构：计划在测试覆盖率提升后进行代码重构，以提高代码的可维护性和可读性。 会议结束： 会议在确认所有议题讨论完毕后结束，团队成员将按照会议决定开始后续工作。 以上是本次会议的详细纪要，涵盖了会议的主要讨论点、决定事项及后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-09-15","slug":"Ceph_Performance_Meeting_2022-09-15","date":"2022-09-20T16:00:00.000Z","updated":"2022-09-21T16:00:00.000Z","comments":true,"path":"2022/09/21/Ceph_Performance_Meeting_2022-09-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/09/21/Ceph_Performance_Meeting_2022-09-15/","excerpt":"","text":"会议纪要 关键细节 会议主题: 讨论Ceph BlueStore中共享Blob的工作原理及其性能问题。 主要参与者: Adam, Mark, Igor, 以及其他未具名的参与者。 讨论焦点: 共享Blob在BlueStore中的实现和性能影响。 RBD镜像性能问题，特别是与快照相关的性能问题。 对现有代码的调试和优化尝试。 讨论的主要议题 共享Blob的工作原理: 讨论了共享Blob在BlueStore中的具体实现，包括其引用计数和数据结构。 分析了共享Blob在处理快照时的行为，特别是如何处理对象的修改和快照创建。 性能问题: 针对RBD镜像性能问题，特别是频繁创建快照导致的性能下降进行了深入讨论。 讨论了尝试通过改进迭代遍历范围的性能来优化性能，但遇到了引用计数和其他代码部分的复杂问题。 代码优化和改进: 提出了使用扁平映射替换标准映射的尝试，以及对共享Blob数据结构的简化建议。 讨论了可能的代码重构和新的实现方法，包括对共享Blob的重新设计和简化。 决定的事项 进一步的研究和实验: 决定进行更多的实验和研究，以探索共享Blob的优化和简化方法。 同意尝试新的实现方法，如Adam提出的单一实例跟踪器，以减少共享Blob的实例数量。 性能测试和分析: 计划进行详细的性能测试，以评估不同优化方案的效果。 讨论了可能的性能瓶颈和需要进一步优化的代码部分。 后续的行动计划 代码实验和实现: Adam将尝试实现单一实例跟踪器的概念，并分享初步结果。 继续探索和实验其他可能的优化和改进方法。 性能测试和分析: 进行详细的性能测试，以评估新实现方法的效果。 分析测试结果，确定进一步的优化方向。 持续讨论和反馈: 继续定期讨论和分享进展，确保团队成员之间的信息同步和反馈。 结论 会议聚焦于Ceph BlueStore中共享Blob的性能问题和可能的优化方案。通过深入讨论和实验，团队旨在找到有效的解决方案，以提高RBD镜像和快照处理的性能。后续将继续进行实验和性能测试，以确保优化方案的有效性和可行性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-08-16","slug":"Ceph_Orchestrator_Meeting_2022-08-16","date":"2022-08-16T16:00:00.000Z","updated":"2022-08-16T16:00:00.000Z","comments":true,"path":"2022/08/17/Ceph_Orchestrator_Meeting_2022-08-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/08/17/Ceph_Orchestrator_Meeting_2022-08-16/","excerpt":"","text":"会议纪要 主要议题 RGW Multi-Site 配置支持 背景：当前配置 RGW（RADOS Gateway）多站点需要手动执行多个步骤，使用 RGW 管理二进制文件，过程繁琐。 目标：简化配置过程，通过 Safe ADM 自动完成多站点配置。 提案：Sebastian 提出在 Safe ADM 中引入新的层级结构，通过关键字 kind 区分不同类型的规范（spec）。 技术细节讨论 当前实现：在 Python 通用部署中，有不同的类支持各种规范，如 host_spec 和 service_spec。 提案实现：添加一个通用的 spec 类，如 rgw_spec 或 generic_spec，作为所有不同规范的基类。 关键字 kind：用于指定规范的类型，如服务器、部署等，未来可扩展。 实施策略 原子操作：确保配置过程的原子性，成功则全部成功，失败则回滚。 顺序依赖：确保创建顺序正确，如先创建 realm，再创建 zone group，最后创建 zone。 向后兼容性：确保新实现不会破坏现有功能，特别是对于已有安装的升级。 前端与后端讨论 前端：讨论了如何更好地呈现配置信息，是否需要引入类似 Kubernetes 的 kind 和 version 概念。 后端：讨论了如何实现具体的创建命令，是否可以直接使用现有的 RGW 管理模块。 决定事项 实施方向：初步决定采用 Sebastian 的提案，引入 kind 关键字，并确保向后兼容性。 后续行动： 进一步研究 RGW 管理模块的功能，确定是否可以直接使用。 开发后端逻辑，实现基本的创建命令。 暂缓前端讨论，待后端实现后再确定最佳呈现方式。 后续行动计划 后端开发：开始实现后端逻辑，确保基本的创建命令能够正常工作。 前端讨论：在后端实现基础上，进一步讨论和确定前端的最佳呈现方式。 文档更新：更新相关文档，确保用户能够理解新的配置方式。 其他议题 Podman 版本兼容性问题：讨论了如何处理特定版本 Podman 的兼容性问题，提出了一些临时解决方案和未来可能的改进方向。 结论 会议对 RGW Multi-Site 配置支持的实现进行了深入讨论，确定了初步的实施方向和后续行动计划。同时，对 Podman 版本兼容性问题进行了讨论，提出了一些临时解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2022-08-09","slug":"Ceph_Orchestrator_2022-08-09","date":"2022-08-08T16:00:00.000Z","updated":"2022-08-09T16:00:00.000Z","comments":true,"path":"2022/08/09/Ceph_Orchestrator_2022-08-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/08/09/Ceph_Orchestrator_2022-08-09/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [具体人员名单] 主要议题： 1. PR审查与测试：会议讨论了关于启动由其自身虚拟IP地址支持的NFS守护进程的PR（Pull Request）。该PR由Adam提交，主要涉及对标志（flags）和一些重复代码的修改。尽管有这些改动，但预计功能性和接口的基本工作方式将保持不变。 决定事项： - PR状态：该PR目前被认为是准备进行测试的状态，特别是需要验证在NFS服务器故障转移场景下的功能。 - 后续测试：Adam将请求Manila团队进行进一步的测试，特别是关于故障转移场景的测试。 后续行动计划： - 测试安排：Adam将与Manila团队安排定期会议，以跟进和执行必要的测试。 - 代码审查：在测试过程中，将继续审查和优化代码，特别是标志名称和重复代码的部分。 其他事项： - 由于会议主持人上周缺席，本次会议没有其他重要议题讨论。 - 会议决定提前结束，以便节省时间。 会议结束： - 会议在确认无其他议题后提前结束。 下次会议预告： - 预计在未来的会议中，随着更多测试的进行，相关讨论将继续。 会议结束语： - 会议主持人感谢大家的参与，并期待下次会议再见。 会议记录人： [记录人姓名] 会议结束时间： [具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-07-05","slug":"Ceph_Orchestrator_Meeting_2022-07-05","date":"2022-08-08T16:00:00.000Z","updated":"2022-08-09T16:00:00.000Z","comments":true,"path":"2022/08/09/Ceph_Orchestrator_Meeting_2022-07-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/08/09/Ceph_Orchestrator_Meeting_2022-07-05/","excerpt":"","text":"会议纪要 会议日期： [具体日期] 参会人员： [具体人员名单] 会议主持： [主持人姓名] 会议议题： 1. Eager Tracing 讨论 - 会议开始时提到了关于“Eager Tracing”的话题，但因提出者未参会，未进行深入讨论。 - 目前可以部署Jaeger Tracing demons with Type Idiom。 NFS工作进展 询问了关于NFS工作的进展情况。 Adam提到已阅读了Francesco的POC文档，目前没有具体问题，但尚未完成相关工作。 Ceph相关测试更新 讨论了Ceph测试的最新进展，特别是病理测试的执行情况。 目前有约20个测试失败，其中一些问题已知，其他问题需要进一步排查。 提到了一些持续出现的info failures，如gzip问题，但这些可能不是根本原因。 其他更新 提到了一些正在进行的工作，如compile stuff IDM和新的HA NFS工作，但目前没有需要特别讨论的新内容。 决定事项： - 继续推进NFS工作的进展。 - 对Ceph测试中的失败案例进行逐一排查，并寻求帮助解决。 后续行动计划： - Adam将继续处理NFS相关的工作，并可能会遇到一些问题，届时将寻求帮助。 - 对Ceph测试中的失败案例进行详细分析，并与其他团队成员协作解决。 - 定期更新相关工作的进展情况。 会议结束： - 会议在确认没有其他紧急议题后结束，计划下周再次开会。 备注： - Adam将在下午发送相关测试问题的链接，以便团队成员协助解决。 - 提醒Adam再次审查NFS decorator PR。 下次会议预告： - 预计下周继续讨论NFS工作和Ceph测试的进展。 会议结束时间： [具体时间] 会议记录人： [记录人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-08-03","slug":"Ceph_Developer_Monthly_2022-08-03","date":"2022-08-04T16:00:00.000Z","updated":"2022-08-05T16:00:00.000Z","comments":true,"path":"2022/08/05/Ceph_Developer_Monthly_2022-08-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/08/05/Ceph_Developer_Monthly_2022-08-03/","excerpt":"","text":"会议纪要 会议概览 日期: 8月 参与者: 多名Ceph社区成员 议程: 讨论了四个主要议题，包括用户体验、测试与发布流程改进、性能优化以及社区生态建设。 主要议题与讨论内容 用户体验与Ceph Dashboard的改进 议题: 讨论了Ceph Dashboard的可用性和可访问性改进。 进展: Cedric因网络问题未能参与，但其工作已在Etherpad中详细记录。 决定: 该议题将推迟至下次会议讨论。 质量与测试流程改进 议题: 讨论了Ceph的测试和发布流程的改进。 主要贡献者: Patrick介绍了最近引入的PR，该PR旨在通过脚本动态控制测试矩阵中的片段合并，以提高测试的灵活性和效率。 讨论: 详细讨论了PR的实现细节，包括如何通过Lua脚本进行过滤和控制。 决定: PR已合并，后续将关注其在升级测试中的应用。 性能优化 议题: 讨论了性能计数器（perf counters）的优先级调整及其对管理器（manager）性能的影响。 主要贡献者: Perry提出了通过允许列表（allow list）来控制哪些性能计数器被发送到管理器，以减少不必要的负载。 讨论: 讨论了性能计数器的稳定性和如何通过配置选项来控制其行为。 决定: 将开发一个概念验证（PoC）来验证允许列表方法的可行性，并考虑其对未来版本的影响。 社区生态建设 议题: 讨论了Ceph社区的参与和生态建设，特别是在Grace Hopper Open Source Day活动中的参与。 行动计划: 需要准备30个左右的低难度问题（low hanging fruit issues）供参与者解决，以鼓励新贡献者加入。 决定: 社区成员被鼓励标记或创建新的低难度问题，以便在即将到来的活动中使用。 后续行动计划 用户体验: 等待Cedric的参与，将在下次会议中继续讨论。 测试流程改进: 继续关注Patrick的PR在实际应用中的表现，并探索更多动态测试矩阵的可能性。 性能优化: 开发允许列表的概念验证，并评估其对性能计数器稳定性的影响。 社区参与: 社区成员应标记或创建低难度问题，为即将到来的Grace Hopper Open Source Day活动做准备。 结论 会议涵盖了多个关键议题，特别是在测试流程和性能优化方面取得了显著进展。社区成员的积极参与和贡献对于Ceph项目的持续发展至关重要。下次会议将继续跟进这些议题的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-08-04","slug":"Ceph_Performance_Meeting_2022-08-04","date":"2022-08-04T16:00:00.000Z","updated":"2022-08-05T16:00:00.000Z","comments":true,"path":"2022/08/05/Ceph_Performance_Meeting_2022-08-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/08/05/Ceph_Performance_Meeting_2022-08-04/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 记录人: [记录人姓名] 主要议题 PR讨论 Ronin的PR: 讨论了Ronin提交的一个新的PR，该PR改进了某个字符串计算函数，性能提升了15%。虽然改动较小，但有助于未来可能的性能回归测试。 Rex TV Store的PR: 讨论了关于Rex TV Store的PR，特别是Rock CP设置的重新调整。Adam对大幅度改变现有设置表示担忧，特别是读取放大效应。讨论了可能的改进方向，包括压缩和针对不同列族的默认设置。 其他PR更新 Igor的PR: 关于消除statifes更新的PR，已进行了更多修复。 RGW Bench的PR: 关于原子写入基准测试的PR，Dang进行了审查并进行了进一步讨论。 性能优化讨论 Boost Valgrind默认启用: 讨论了是否默认启用Boost Valgrind，Mark Cogan的测试显示可能有一些性能影响，但影响不大。会议决定进一步测试以验证。 决定事项 继续对Rex TV Store的PR进行深入讨论和测试，特别是关于读取放大和写入放大的平衡问题。 对Boost Valgrind的默认启用进行进一步的性能测试，特别是关注OSD方面的影响。 后续行动计划 Ronin将继续监控其PR的性能影响。 Adam和主持人将继续讨论和优化Rex TV Store的PR。 主持人将进行Boost Valgrind的进一步性能测试。 所有相关人员将继续关注和更新各自的PR进展。 其他事项 会议最后，Mark和主持人讨论了与性能无关的其他事项，并决定在另一个会议中继续讨论。 会议结束 会议在确认无其他议题后结束，主持人祝愿大家有一个愉快的一周，并期待下周的会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2022-07-26","slug":"Ceph_Orchestrator_2022-07-26","date":"2022-07-31T16:00:00.000Z","updated":"2022-07-31T16:00:00.000Z","comments":true,"path":"2022/08/01/Ceph_Orchestrator_2022-07-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/08/01/Ceph_Orchestrator_2022-07-26/","excerpt":"","text":"会议纪要 主要议题 管理标签（admin label）功能讨论 讨论了管理标签的作用，主要涉及在所有主机上部署ceph.conf和admin keyring文件。 讨论了在移除标签时自动移除这些文件的机制，以及可能引发的问题。 提出了使用哈希文件来管理这些文件的方法，以确保只有通过特定流程部署的文件才会被移除。 NFS Keep Alive功能改进 讨论了如何改进NFS Keep Alive功能的命令行参数，提出了使用模式（mode）标志来区分不同的部署策略。 讨论了如何通过模式标志来管理不同的部署场景，如HA代理模式和Keep Alive Only模式。 会议记录归档 讨论了归档会议记录的重要性，特别是对于长期项目，以避免记录过于庞大导致的管理和加载问题。 决定事项 对于管理标签功能，决定进一步研究使用哈希文件的方法来管理ceph.conf和admin keyring文件。 对于NFS Keep Alive功能，决定引入模式标志来简化命令行参数，并支持未来的功能扩展。 决定对会议记录进行定期归档，以保持记录的可管理性和可访问性。 后续行动计划 进一步研究和测试管理标签功能的哈希文件方法。 实施并测试NFS Keep Alive功能的模式标志。 定期归档会议记录，并更新相关文档和链接。 其他事项 讨论了关于编译相关PR的处理，决定等待一周以获取反馈，如果无反馈则考虑创建新的PR。 会议持续了140分钟，涉及了深入的设计和技术讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-07-28","slug":"Ceph_Performance_Meeting_2022-07-28","date":"2022-07-28T16:00:00.000Z","updated":"2022-07-28T16:00:00.000Z","comments":true,"path":"2022/07/29/Ceph_Performance_Meeting_2022-07-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/07/29/Ceph_Performance_Meeting_2022-07-28/","excerpt":"","text":"会议纪要 关键细节 会议开始时间: 会议在部分成员未到齐的情况下开始，预计他们稍后会加入。 主要议题: 讨论了关于优化 RocksDB 设置以减少写放大和改善 Tombstone 行为的工作进展。 决定事项: 决定继续探索在 RocksDB 中自动触发压缩和刷新的方法，特别是在删除操作后。 后续行动计划: 需要进一步研究和测试，以确定最佳的 RocksDB 设置和删除跟踪机制。 讨论的主要议题 RocksDB 设置优化: 讨论了如何调整 RocksDB 设置以减少写放大，特别是在处理大量删除操作时。提出了通过跟踪每个列族的删除操作来手动触发压缩和刷新的想法。 Tombstone 行为: 讨论了 Tombstone 在 RocksDB 中的影响，特别是在迭代删除周期中的性能问题。提出了通过改进 RocksDB 的内部机制来减少 Tombstone 的影响。 性能和资源管理: 讨论了如何在不影响系统整体性能的情况下，有效地管理 RocksDB 的压缩和刷新操作。提出了在 RocksDB 中注册监听器以跟踪压缩和刷新事件的想法。 决定的事项 RocksDB 优化方案: 决定继续探索和实施在 RocksDB 中自动触发压缩和刷新的方法，特别是在删除操作后。 删除跟踪机制: 决定开发一种机制来跟踪每个列族的删除操作，并在达到一定阈值后手动触发压缩和刷新。 后续的行动计划 进一步研究和测试: 需要进一步研究和测试，以确定最佳的 RocksDB 设置和删除跟踪机制。 代码实现和审查: 开发团队将开始实现删除跟踪机制，并邀请其他团队成员进行代码审查和测试。 性能监控和调整: 在实施新的 RocksDB 设置后，需要持续监控系统性能，并根据实际情况进行调整。 其他讨论点 RocksDB 的内部机制: 讨论了 RocksDB 的内部机制，包括压缩和刷新的触发条件，以及如何通过外部代码来控制这些操作。 性能和资源管理: 讨论了如何在不影响系统整体性能的情况下，有效地管理 RocksDB 的压缩和刷新操作。 结论 会议讨论了关于优化 RocksDB 设置以减少写放大和改善 Tombstone 行为的工作进展，并决定继续探索和实施在 RocksDB 中自动触发压缩和刷新的方法。后续需要进一步研究和测试，以确定最佳的 RocksDB 设置和删除跟踪机制。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2022-07-06","slug":"Ceph_Crimson_SeaStore_Meeting_2022-07-06","date":"2022-07-18T16:00:00.000Z","updated":"2022-07-19T16:00:00.000Z","comments":true,"path":"2022/07/19/Ceph_Crimson_SeaStore_Meeting_2022-07-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/07/19/Ceph_Crimson_SeaStore_Meeting_2022-07-06/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Yingjin（C-Store精英），Fair，Marvin，Kingston，Aravind，Jinyu，Juan，Sam等 会议内容： 一、人员变动与项目进展 人员变动： Yingjin 将成为 C-Store 精英，负责 C-Store 项目的领导工作。 项目进展： C-Store 项目： Yingjin 将继续负责 C-Store 项目，并担任 C-Store 的技术领袖。 ZNS 驱动开发： Aravind 正在开发 ZNS 驱动，已提交三个补丁，但遇到 make check 失败问题。 Kingston 提到 ZNS 区的更新问题，由于关闭操作会导致磁盘无法再次打开，需要进行修改。 会议讨论了 ZNS 驱动的关闭操作（finish）与磁盘容量浪费的问题，并决定修改 ZNS 管理器，使其在写入数据时填充空间，以避免浪费。 垃圾回收器改进： Jinyu 提出了关于垃圾回收器改进的想法，建议在 GC 事务中添加判断逻辑，以避免将不满足时间局部性原则的 extent 添加到 Aerial 中。 对象存储改进： Juan 正在调试对象存储相关的 PR，并尝试实现固定 KBB 树优化。 性能测试： Sam 询问如何测试 ZNS 驱动，建议使用 fio 或 rados-bench 等工具进行性能测试。 二、讨论与决策 ZNS 驱动开发： Aravind 将修改 ZNS 管理器，使其在写入数据时填充空间，以避免浪费。 Sam 将审查 Aravind 提交的补丁，并请求代码审查。 垃圾回收器改进： Jinyu 的建议被认可，将考虑将其纳入垃圾回收器改进方案。 对象存储改进： Juan 将继续调试对象存储相关的 PR，并尝试实现固定 KBB 树优化。 三、行动计划 Aravind 修改 ZNS 管理器，并提交补丁。 Sam 审查 Aravind 提交的补丁，并请求代码审查。 Jinyu 将垃圾回收器改进方案提交给相关团队进行讨论。 Juan 继续调试对象存储相关的 PR，并尝试实现固定 KBB 树优化。 四、其他事项 会议讨论了 ZNS 驱动的测试方法，建议使用 fio 或 rados-bench 等工具进行性能测试。 会议讨论了 ZNS 驱动的容量浪费问题，并决定修改 ZNS 管理器，使其在写入数据时填充空间。 五、结束语 本次会议讨论了 C-Store 项目、ZNS 驱动开发、垃圾回收器改进、对象存储改进等议题，并制定了相应的行动计划。会议进展顺利，达到了预期目标。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-07-12","slug":"Ceph_Orchestrator_Meeting_2022-07-12","date":"2022-07-18T16:00:00.000Z","updated":"2022-07-19T16:00:00.000Z","comments":true,"path":"2022/07/19/Ceph_Orchestrator_Meeting_2022-07-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/07/19/Ceph_Orchestrator_Meeting_2022-07-12/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员 会议主题： 讨论Ceph分布式存储系统中fb filtering机制和日志配置的优化问题。 关键细节： 1. fb filtering机制优化： 目前Ceph中fb filtering机制对网络匹配要求严格，需要每个主机配置不同的网络才能通过过滤。 讨论是否可以放宽匹配规则，允许更宽泛的子网匹配。 研究如何使用Python标准库中的ipaddress库进行子网匹配检查。 决定尝试放宽匹配规则，并评估其对系统的影响。 2. 日志配置优化： 目前Ceph中二进制程序的日志级别固定为debug，导致日志文件中包含大量调试信息。 讨论是否可以提供日志级别配置选项，允许用户根据需要调整日志输出。 讨论了使用环境变量、命令行参数和配置文件等方式进行日志级别配置的可行性。 讨论了在不同场景下（如主机级别、命令级别）进行日志级别配置的复杂性。 决定优先考虑全局日志级别配置，并逐步优化。 3. 日志内容优化： 发现Ceph中存在大量冗余的日志信息，例如sc_status命令的输出。 讨论是否可以将这些冗余信息移至silent级别，减少日志文件大小。 讨论了如何处理命令执行过程中的错误信息，确保调试信息对用户有价值。 4. 二进制重构： 讨论了Ceph二进制重构的进展，包括测试和构建过程。 决定继续进行测试，并评估是否需要运行额外的测试用例。 后续行动计划： 尝试放宽fb filtering机制的匹配规则，并评估其对系统的影响。 优先考虑全局日志级别配置，并逐步优化。 优化日志内容，减少冗余信息。 继续进行二进制重构测试，并评估是否需要运行额外的测试用例。 备注： 会议中提到了Ceph的版本控制、构建系统和测试用例等关键词。 会议纪要中保留了部分计算机科学/ceph相关领域英文原文的关键词，例如fb filtering、subnet、log level、binary refactoring等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-07-14","slug":"Ceph_Performance_Meeting_2022-07-14","date":"2022-07-18T16:00:00.000Z","updated":"2022-07-18T16:00:00.000Z","comments":true,"path":"2022/07/19/Ceph_Performance_Meeting_2022-07-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/07/19/Ceph_Performance_Meeting_2022-07-14/","excerpt":"","text":"会议纪要 主要议题 Blue Store Zero Block Detection PR 性能问题 讨论内容：会议讨论了关于Blue Store Zero Block Detection PR在Quincy版本中的性能问题。该功能在17.2.1版本中被默认关闭，导致性能相对于之前的版本有所下降。 决定事项：需要进一步分析和理解性能下降的原因。 后续行动：Laura将与DFG存储团队合作，深入研究17.2.0和17.2.1版本之间的性能差异，特别是Blue Store Zero Block Detection功能的启用和禁用对性能的影响。 内存使用问题与PG Log中的Dupe Ops跟踪 讨论内容：会议讨论了在PG Log中跟踪Dupe Ops时遇到的内存使用问题。当存在损坏的Dupe条目时，会导致停止修剪，从而允许Dupe条目积累。 决定事项：目前提出的解决方案是在OSD重启时，逐步修剪条目（每次10,000条），以恢复稳定状态。 后续行动：将继续进行测试和验证，确保该解决方案的有效性，并考虑在HDDs上进行验证。 Snap Map性能影响 讨论内容：Gabri讨论了Snap Map对性能的影响，特别是在Snapdragon和Clone Object Creation方面的性能问题。 决定事项：需要设计针对性的测试来验证Snap Map的性能影响。 后续行动：Gabri将与团队合作，设计并执行相关测试，以验证Snap Map的性能影响，并分析CPU使用率和写入放大问题。 Smithy节点替换计划 讨论内容：会议讨论了可能的资金支持用于替换Smithy节点，并提出了一个基于高能效的硬件配置方案。 决定事项：需要尽快确定硬件配置，并在短时间内提交报价。 后续行动：David Galloway将与团队合作，尽快确定硬件配置，并提交报价。 后续行动计划 Laura和DFG存储团队将继续研究Blue Store Zero Block Detection PR的性能问题，并寻找解决方案。 团队将继续测试和验证PG Log中Dupe Ops跟踪的内存使用问题解决方案。 Gabri将与团队合作，设计并执行针对Snap Map性能影响的测试。 David Galloway将与团队合作，尽快确定Smithy节点替换的硬件配置，并提交报价。 其他事项 会议中还讨论了其他潜在的性能优化和硬件升级问题，但未形成具体决定或行动计划。 结论 会议涵盖了多个关键议题，包括性能优化、内存管理、硬件升级等，并制定了相应的后续行动计划。团队将继续合作，确保各项议题得到有效解决。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/SeaStore Meeting 2022-07-13","slug":"Crimson_SeaStore_Meeting_2022-07-13","date":"2022-07-18T16:00:00.000Z","updated":"2022-07-19T16:00:00.000Z","comments":true,"path":"2022/07/19/Crimson_SeaStore_Meeting_2022-07-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/07/19/Crimson_SeaStore_Meeting_2022-07-13/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[列出参会人员] 主要议题： Ceph多核PR的进展 发言人：[姓名] 进展：第二个多核PR即将完成，预计明天发布。第三个多核PR的工作即将开始。 OSD启动和ZNS设备测试 发言人：[姓名] 进展：成功在ZNS设备上启动OSD，并进行了RADOS Bench测试。遇到了GC（垃圾回收）问题，GC启动后IO操作停止，需要进一步调试。 对象数据块分割和冲突检测改进 发言人：[姓名] 进展：完成了第一个PR的合并，后续工作包括进一步改进冲突检测和简化随机块管理器的循环日志。 列表对象和枚举对象的调试 发言人：[姓名] 进展：正在根据评论修改PR，并进行调试。 物理B3优化和死亡引用问题 发言人：[姓名] 进展：已分离出第一个PR，第二个PR即将提交。 HDD支持的讨论 发言人：[姓名] 讨论：关于是否在HDD上使用RBM（随机块管理器）进行了深入讨论。建议尽可能避免设备特定代码，并考虑使用段管理器来优化HDD的分配策略。 SMR硬盘支持的可能性 发言人：[姓名] 讨论：提出了在Ceph中支持SMR（叠瓦式磁记录）硬盘的可能性，建议创建SMR实现的段管理器。 决定事项： 继续调试ZNS设备上的GC问题，并考虑创建相关bug报告。 继续改进冲突检测和简化随机块管理器的循环日志。 继续调试列表对象和枚举对象的问题。 继续优化物理B3和解决死亡引用问题。 对于HDD支持，建议尽可能避免设备特定代码，并考虑使用段管理器来优化HDD的分配策略。 考虑在Ceph中支持SMR硬盘，创建SMR实现的段管理器。 后续行动计划： 发布第二个多核PR，并开始第三个多核PR的工作。 继续调试ZNS设备上的GC问题，并创建相关bug报告。 完成冲突检测的改进和随机块管理器的简化。 完成列表对象和枚举对象的调试。 提交物理B3优化的第二个PR。 讨论并实施HDD支持的优化策略。 研究并实施SMR硬盘的支持。 备注： 会议中提到的技术术语包括ZNS（Zone Namespace）、RADOS Bench、GC（垃圾回收）、RBM（随机块管理器）、SMR（叠瓦式磁记录）等。 会议结束时间：[具体时间] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-06-30","slug":"Ceph_Performance_Meeting_2022-06-30","date":"2022-06-29T16:00:00.000Z","updated":"2022-06-30T16:00:00.000Z","comments":true,"path":"2022/06/30/Ceph_Performance_Meeting_2022-06-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/30/Ceph_Performance_Meeting_2022-06-30/","excerpt":"","text":"会议纪要 主要议题 新的Pull Request讨论 会议开始时，讨论了最近的新Pull Request（PR）情况。目前只有一个新的PR，涉及RGW（RADOS Gateway）原子写入器的基准测试组件。这个组件是Zipper工作的一部分，旨在通过针对存储接口的基准测试，比较不同后端之间的性能。 博客文章更新 会议中讨论了关于RocksDB调优的现有博客文章。文章由Kieran Singh和Daniel Parks撰写，发布于2019年，其中包含了一些调优建议，如将OSD PG日志条目和重复跟踪设置为10，声称这减少了写入放大。然而，这些设置并未经过QA测试，且存在一些潜在的问题和副作用。 会议参与者对这些设置的有效性和安全性表示担忧，建议可能需要更新或明确警告这些设置的风险。 后续行动计划 计划编写一篇新的RocksDB调优博客文章，详细解释各种设置及其可能的影响，并明确指出这些设置未经QA测试，使用风险自负。 讨论了是否需要针对现有博客文章发布更正或警告，最终决定可能需要撰写一篇新的博客文章来解释这些设置的后果。 决定事项 确认需要编写一篇新的RocksDB调优博客文章，详细解释设置及其影响，并明确风险。 讨论了是否需要对现有博客文章进行更正或警告，但最终决定可能通过新的博客文章来解决这些问题。 后续行动计划 编写新的RocksDB调优博客文章，并邀请团队成员在发布前进行审阅和反馈。 继续关注OSD线程行为的研究，预计下周继续相关工作。 其他事项 会议结束时，提醒美国团队成员即将到来的假期，并祝愿所有人周末愉快。 结论 会议主要围绕新的PR和现有博客文章的更新进行了讨论，确定了编写新博客文章的计划，并讨论了现有文章的潜在问题和解决方案。会议在确认后续行动计划后结束，祝愿所有人周末愉快。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-06-14","slug":"Ceph_Orchestrator_Meeting_2022-06-14","date":"2022-06-27T16:00:00.000Z","updated":"2022-06-28T16:00:00.000Z","comments":true,"path":"2022/06/28/Ceph_Orchestrator_Meeting_2022-06-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/28/Ceph_Orchestrator_Meeting_2022-06-14/","excerpt":"","text":"会议纪要 主要议题 Paul的磁盘重扫描功能 讨论了Paul的磁盘重扫描功能，该功能可能作为替代现有staff volume inventory的方案。目前有一个相关的Pull Request（PR）已经开放一段时间，但尚未被审查。会议建议团队成员提供直接反馈，并计划下周讨论该议题。 HNFS for OpenStack的概念验证 Ramana更新了关于HNFS for OpenStack的概念验证进展。Francisco主要负责，已经成功手动复制和编辑了现有的NFS Ganesha服务的脚本，并进行了一些代码修改。Ramana请求Francisco分享详细步骤的Google文档，并计划将其链接到跟踪票证。 FADM重构工作 John将开始关注FADM的重构工作。他计划首先本地拉取分支，运行现有代码，以了解PR实施的工作流程。John提到他正在处理GoTheft的发布周期，因此今天没有时间处理此事。 平衡静态放置支持 讨论了关于平衡静态放置支持的请求，该请求由Ernesto提出。目前使用的是基于计数的放置策略，导致所有守护进程都放置在同一主机上，形成热点。会议认为这不是紧急问题，但未来可能需要考虑解决方案。 安全功能更新 讨论了某些守护进程中TLS和SSL功能标记为实验性的问题。开发者表示这些功能已可操作，但未来可能会有变动。会议建议在默认情况下关闭这些功能，并在版本更新时保持谨慎。 决定事项 团队成员应审查并提供关于Paul磁盘重扫描功能PR的反馈。 Francisco将分享HNFS for OpenStack概念验证的详细步骤文档，并链接到跟踪票证。 John将开始FADM重构工作，并计划在本地运行现有代码以了解工作流程。 平衡静态放置支持的问题被标记为未来需要考虑的事项。 对于实验性的TLS和SSL功能，建议在默认情况下关闭，并在版本更新时保持谨慎。 后续行动计划 下周会议将讨论Paul的磁盘重扫描功能PR的反馈和进展。 下周会议将讨论HNFS for OpenStack概念验证的详细步骤文档。 John将继续FADM重构工作，并计划在下周提供更新。 对于平衡静态放置支持的问题，将收集更多信息并评估具体需求。 对于实验性的TLS和SSL功能，将保持关注并在版本更新时进行相应调整。 其他事项 会议提醒团队成员注意安全功能的实验性状态，并在实施时保持谨慎。 下周会议将讨论RDW和多站点相关事宜。 会议结束 会议在确认无其他议题后结束，并计划下周继续讨论相关事宜。 会议时间： [具体日期] 参会人员： [参会人员名单] 记录人： [记录人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-06-28","slug":"Ceph_Orchestrator_Meeting_2022-06-28","date":"2022-06-27T16:00:00.000Z","updated":"2022-06-28T16:00:00.000Z","comments":true,"path":"2022/06/28/Ceph_Orchestrator_Meeting_2022-06-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/28/Ceph_Orchestrator_Meeting_2022-06-28/","excerpt":"","text":"会议纪要 日期： 2023年6月28日 参会人员： [参会人员名单] 主要议题： 1. Ceph编译更新（compiles fdm1） - 问题描述： e2e仪表板测试持续失败，但未发现与当前变更直接相关的联系。 - 当前状态： 新日志行出现在日志输出中，表明Cepheum正在被测试。 - 行动建议： 继续重新运行测试，观察是否为间歇性问题。 NFS相关问题 问题描述： NFS测试失败，可能与最近容器设置的变更有关。 行动建议： 关注NFS相关问题，等待容器问题解决后再次测试。 API测试问题 当前状态： API测试已重启并通过。 后续行动： 继续关注其他潜在的失败测试。 OpenStack团队需求 需求描述： OpenStack团队提出了关于NFS设置的需求。 行动建议： 评估并实施相关需求，重点关注独立部署的维护。 监控和安全更新 当前状态： 监控堆栈的安全特性已准备好，等待其他变更请求（VR）合并后进行测试。 后续行动： 替换并审查相关变更，进行进一步测试。 一致性哈希与随机分布 当前状态： 正在重新启用并测试FDM调度器的随机分布支持。 后续行动： 继续测试并评估其在实际环境中的性能。 决定事项： - 继续监控和重新运行Ceph编译及相关测试，以确定问题的稳定性。 - 关注并解决NFS相关问题，确保其稳定性。 - 实施OpenStack团队的NFS设置需求。 - 完成监控堆栈的安全特性更新，并进行全面测试。 - 测试并优化FDM调度器的随机分布支持。 后续行动计划： - 持续关注测试结果，及时调整和优化相关配置。 - 与OpenStack团队保持沟通，确保需求的准确实施。 - 完成所有安全特性的测试，并准备发布。 - 评估并优化一致性哈希与随机分布的实现。 会议结束： - 会议于[具体时间]结束，无其他重大议题讨论。 备注： - 请相关人员关注并执行上述行动计划，确保项目进度和质量。 下次会议预告： - 下次会议时间：[具体日期和时间] - 主要议题：[预定的讨论内容] 会议记录人： [记录人姓名] 会议结束语： - 感谢大家的参与和贡献，祝大家工作顺利，再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2022-06-22","slug":"Ceph_Crimson_SeaStore_Meeting_2022-06-22","date":"2022-06-26T16:00:00.000Z","updated":"2022-06-27T16:00:00.000Z","comments":true,"path":"2022/06/27/Ceph_Crimson_SeaStore_Meeting_2022-06-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/27/Ceph_Crimson_SeaStore_Meeting_2022-06-22/","excerpt":"","text":"会议重点概括： Ying Jin报告了意外的trim spike问题，并提到改进的GC策略减少了写放大、冲突，并提升了性能。同时，她正在研究SSD内部写放大的评估方法，并计划进一步优化设备分层。 Airmen提到他正在处理一个关于元数据生成的Pull Request (PR)，主要涉及清理工作和计算函数的修正。他还在解决开启Voiced时遇到的写入问题，通过更改代码确保在关闭segment时写入tail信息。 对于ZNS设备的segment管理，讨论了在关闭segment后无法重新打开的情况，因为大多数设备不支持重新打开已关闭的segment。还讨论了在crimson中模拟block segment manager的行为，以及如何根据不同的存储设备选择合适的写入管理器。 Joe May正在处理根据评论修复问题的PR，并研究解决根本原因。他还提到了有关gcc 11的问题影响Ceph的构建，以及与Python绑定相关的问题。 讨论了Ceph CRIMSON OSD的性能分析结果，特别是在垃圾回收(GC)过程中发现的一些关键性能瓶颈，如空间回收过程的时间增加，以及可能的优化点。 后续行动计划： Ying Jin将继续她的PR工作，并对设备分层进行进一步研究。 Airmen将对元数据生成的PR进行最终修改，并继续解决开启Voiced时的写入问题。 团队同意需要添加对象数据块到缓存中以确保在进行GC时的数据一致性。 Joe May将继续处理修复问题并研究与GCC 11和Python绑定相关的构建问题。 根据性能分析结果，团队决定调查和优化cache数据结构及其查找方式，以提高GC过程的效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-06-21","slug":"Ceph_Orchestrator_Meeting_2022-06-21","date":"2022-06-26T16:00:00.000Z","updated":"2022-06-27T16:00:00.000Z","comments":true,"path":"2022/06/27/Ceph_Orchestrator_Meeting_2022-06-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/27/Ceph_Orchestrator_Meeting_2022-06-21/","excerpt":"","text":"本次Cepheiu技术会议讨论了NFS和GANESHA集群的故障转移、部署和管理问题，以及CEPH和Rook项目间的集成。重点包括： 1. GANESHA集群在节点故障时可能无法运作的问题，及解决方法如使用ZAPFIMO实现自动故障转移。 2. 关于NFS服务和客户端配置在同一主机上的位置问题的探讨，以及对最佳实践的影响。 3. 对Cepheiu与Rook项目未来集成方向的探讨，包括更新后的提案和测试计划。 4. 对GANESHA和NFS协议的深入理解，以及它们在实际环境中的行为和预期。 5. 针对特定技术问题的进一步调查，例如在节点故障后如何处理已打开的NFS操作。 6. 对现有解决方案的评估，并寻找改进方法以增强系统的稳定性和可用性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-06-09","slug":"Ceph_Performance_Meeting_2022-06-09","date":"2022-06-26T16:00:00.000Z","updated":"2022-06-27T16:00:00.000Z","comments":true,"path":"2022/06/27/Ceph_Performance_Meeting_2022-06-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/27/Ceph_Performance_Meeting_2022-06-09/","excerpt":"","text":"项目1：不需要ropes保护snap mapper，在系统关闭时将其保存到文件中，这会增加几百毫秒的关闭时间，但在启动时通过从文件中读取可以节省时间。 项目2：处理删除操作，通过批量处理删除请求来减少与roxdb的交互次数，从而减少性能开销。 项目3：将snap marker从一个单一的大型实体更改为每个pg维护自己的snap mapper集合，这可以减少锁冲突并提高性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-06-23","slug":"Ceph_Performance_Meeting_2022-06-23","date":"2022-06-26T16:00:00.000Z","updated":"2022-06-27T16:00:00.000Z","comments":true,"path":"2022/06/27/Ceph_Performance_Meeting_2022-06-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/27/Ceph_Performance_Meeting_2022-06-23/","excerpt":"","text":"会议纪要： 更新情况： 第一个更新是关于移除statifus的，Adam已经审查并通过了该更新，Igor进行了一些额外的修改，目前看起来进展顺利，但仍需要核心团队进行再次审查。 第二个更新是关于将kodell添加到Blue Store中以缓解缓冲区膨胀问题，Sam在上周有机会对其进行了审查并提出了多项更改请求，该更新尚未准备就绪，仍在积极审查中。 讨论主题： 讨论了RocksDB调优问题，发现过去几年中出现的RocksDB调优方法虽然增加了内存缓冲区的数量并减小了其大小，同时允许累积两次写入再刷新到数据库中，但存在一些问题。最近几周的测试显示，这种调优实际上产生了相当稳定的效果，并没有看到预期中的放大增加。进一步的调整表明，通过调整Level 0和Level 1，并使用更多较小的缓冲区累积成较大的刷新，可以在不显著增加写放大的情况下提高RBD性能。 正在研究经典OSD中的分片和线程行为，有证据表明当OSD分片为空时，效率会显著下降。这可能与唤醒所有线程的方式有关。这方面的分析和工作将在其他文章完成后继续进行。 Gabby报告： Gabby正在重写Snapmapper的全部代码。在理解Snapmarker内部的数据结构和操作后，他意识到当前版本仅适用于存储长期数据，而实际中似乎并非如此。新的版本将尝试将所有内容存储在内存中，并按Snap ID和PG确定存储库的使用，优化数据结构从Red-Black树变为哈希表，使用Snap ID和Edge对象而非字符串。这将节省大量内存，并减少编码/解码的需要。Gabby计划在罗马之行回来后继续这项工作，预计不会太久就能进行测试。 行动计划： Gabby将继续他的Snapmapper项目，并在下次会议前提供更新。 其他成员将继续审查和测试现有更新，并在必要时提供反馈。 下一次会议将在一周后召开，届时将进一步讨论这些主题和任何新的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-06-16","slug":"Ceph_Performance_Meeting_2022-06-16","date":"2022-06-26T16:00:00.000Z","updated":"2022-06-27T16:00:00.000Z","comments":true,"path":"2022/06/27/Ceph_Performance_Meeting_2022-06-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/27/Ceph_Performance_Meeting_2022-06-16/","excerpt":"","text":"会议纪要： 概述： 过去一周内，Ceph存储分布式系统的研发工作主要集中在snapmapper性能优化和arbitrary mirror performance研究。 讨论了未决的PR、功能更新和潜在的改进点。 提出了关于snapmapper设计的批评和改进建议。 分享了有关osd（对象存储设备）性能问题的见解。 snapmapper相关讨论： snapmapper的性能问题被关注，特别是其全局对象（pg）设计导致的性能开销。 发现snapmapper在处理大量快照时产生大量的删除请求，这些请求可能不会实际删除任何数据但仍占用资源。 提出将snapmapper的改动分享给更广泛的团队以获得反馈。 讨论了pinning行为和简化逻辑的新PR，但需要更多讨论以决定如何进行。 arbitrary mirror performance： Gabby分享了有关arbitrary mirror性能的文档，该文档详细分析了rbd mirror在snapmapper中产生的额外开销。 讨论了tombstone生成与rocksdb活动之间的关联以及如何减少影响。 OSD性能问题： 当shard queue不能保持满状态时，OSD的性能显著下降。 讨论了使用不同数量的messenger线程、worker线程和shards时的行为差异。 提出了通过循环唤醒单个线程或采用轮询机制来改善性能的潜在方案。 其他讨论： 探讨了避免将pg log更新传递到roxdb的可能性。 讨论了hd starter上pg log读取和条目流的处理。 确定了一些PR的状态，并决定关闭一些过时的PR。 行动计划： 继续调查snapmapper和arbitrary mirror performance的问题。 探索改进OSD性能的方法。 分享更多的发现和文档以促进团队成员间的讨论和协作。 结语： 会议以总结主要讨论点和确定下一步行动计划结束。 鼓励团队成员继续努力，为即将到来的代码提交和功能迭代做准备。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2022-06-07","slug":"Ceph_Crimson_Seastore_Meeting_2022-06-07","date":"2022-06-09T16:00:00.000Z","updated":"2022-06-10T16:00:00.000Z","comments":true,"path":"2022/06/10/Ceph_Crimson_Seastore_Meeting_2022-06-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/10/Ceph_Crimson_Seastore_Meeting_2022-06-07/","excerpt":"","text":"会议纪要 日期： [未指定，但可推断为当前或近期的一周内] 参与者： Carmen, Aravind, [其他参与者名字未提及] 主要讨论议题： 1. ZNS问题识别与解决 2. 日志消息清理 3. 容量报告修正 4. GC测试方法优化 5. 现实工作负载模拟 6. 错误日志修改 7. Crimson在Jenkins上的构建问题 决定事项： - Carmen将对ZNS部分进行问题修复并清理日志消息。 - 发送修正后的容量报告PR请求评审。 - 使用fio的zip f模式来测试GC，更贴近实际的工作负载。 - 对Ceph的matrix进行改进。 - 需要收集真实工作负载数据以优化合成测试。 - 修改错误日志以改善用户体验。 - 解决Crimson在Jenkins上构建的问题，特别是关于系统库和工具集升级后的问题。 后续行动计划： - Carmen将继续处理ZNS相关的问题，并请求其他人评审她的代码。 - Aravind将探索更现实的测试方法，可能包括客户部署测试。 - 继续调查Crimson在Jenkins上的构建问题，特别是与系统库相关的问题。 - 所有参与者应保持关注他们各自任务的进展，并在下次会议前准备好更新。 备注： - 一些技术术语未翻译，如ZNS、GC等，因为这些是专业领域（存储和计算机科学）中的专有名词。 - 会议结束时提到一位参与者下周不在，但会尽量处理邮件；另一位参与者将在之后一周返回。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-03-02","slug":"Ceph_Developer_Monthly_2022-03-02","date":"2022-06-02T16:00:00.000Z","updated":"2022-06-02T16:00:00.000Z","comments":true,"path":"2022/06/03/Ceph_Developer_Monthly_2022-03-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/03/Ceph_Developer_Monthly_2022-03-02/","excerpt":"","text":"Centralized Logging Solutions: Graylog: Has to be configured manually, lacks dynamic log collection. Elasticsearch and Logstash: Offer customization and better visualization, but require running beats daemon on every node. Loki: Simpler integration with native grafana interface. Traceability and Observability: Trace points can help in reducing the overhead of processing logs. Tracing gives the possibility of focusing on specific flows and turning on traces under certain conditions. Dynamic Filtering and Conditional Tracing: The idea of conditional tracing based on observed conditions to reduce the volume of logs. Dynamic filtering capabilities like those seen in dtrace for efficient log management and debugging. Future Work: Explore integrating dynamic code or scripting into logging and tracing to allow for flexible condition injection. Consider the feasibility and safety of such dynamic capabilities in a C++ environment. Community Feedback: Send out emails to both dev list and user list to gather more feedback on centralized logging solutions. Understand different use cases and roles these solutions can serve.","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-05-04","slug":"Ceph_Developer_Monthly_2022-05-04","date":"2022-06-02T16:00:00.000Z","updated":"2022-06-02T16:00:00.000Z","comments":true,"path":"2022/06/03/Ceph_Developer_Monthly_2022-05-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/03/Ceph_Developer_Monthly_2022-05-04/","excerpt":"","text":"会议纪要： 主题：讨论IBM存储设备在Ceph中的部署，以及相关插件系统开发和安全模型。 参会人员：Martin Omar（IBM），会议提前准备充分。 讨论内容： Martin介绍了IBM的NVMe存储设备及其在线压缩功能，该设备提供22TB逻辑块，但只占用9.6TB物理存储空间。使用模式与VDO设备类似，通过侧通道报告实际物理块使用情况以避免磁盘故障。 为支持IBM设备，实验了将代码添加到video组件附近，但发现不合适，因此改为创建插件系统。该系统基于erasure code插件系统，并放置在相邻目录中。新系统称为x block device（axtblkdev），用于加载具有所需接口的插件。 创建了VDO设备的插件作为示例，以展示插件系统如何工作。这允许未来添加更多设备插件，如FCM设备。 当前设备的API仍为供应商特定，未开放。插件方法使得能够向各种客户销售插件或在IBM云中使用。 安全问题讨论包括Linux中的keep caps标志，它保持capability集在set uid系统中不变。提出配置选项来限制保留的capabilities，减少潜在攻击面。 确认/查询每个插件所需的特定权限，而不是默认全部保留或不保留任何权限。 后续行动： Martin将继续测试FCM设备，希望获得对设备接口的访问权限以进行更全面的测试。 需要审查和反馈，特别是关于安全方面的考虑。 讨论了自动化测试的困难，因为插件不在仓库中，测试需要在插件所有者的环境中进行。 会议结论：插件系统开发进展顺利，安全性问题正在积极解决。下一步是继续测试、获取反馈，并可能进行更多安全优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-06-01","slug":"Ceph_Developer_Monthly_2022-06-01","date":"2022-06-02T16:00:00.000Z","updated":"2022-06-02T16:00:00.000Z","comments":true,"path":"2022/06/03/Ceph_Developer_Monthly_2022-06-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/03/Ceph_Developer_Monthly_2022-06-01/","excerpt":"","text":"问题: 对于客户来说，一个对象内部有洞和对象内部有洞但被分配之间的区别是什么？ 答案: 区别在于加密用例。如果一个区域被分配但没有数据（即有洞），在读取时不需要解密，直接返回零；但如果这个区域实际包含了加密后的数据，即使这些数据是全零，也需要先解密再返回给用户。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-06-02","slug":"Ceph_Performance_Meeting_2022-06-02","date":"2022-06-02T16:00:00.000Z","updated":"2022-06-02T16:00:00.000Z","comments":true,"path":"2022/06/03/Ceph_Performance_Meeting_2022-06-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/06/03/Ceph_Performance_Meeting_2022-06-02/","excerpt":"","text":"会议主题：Ceph存储系统相关讨论 主要议题：包括对Ceph文件系统性能的优化、代码审查、测试以及与Ford公司合作等。 会议结论： 优化Ceph文件系统性能，特别是针对小文件和大文件的不同处理方式。 在代码审查中，需要关注线程安全和内存泄漏问题。 测试方面，要重点关注新引入的RPC方法的性能影响。 与Ford公司的合作项目正在等待最终审批，一旦获批将开始实施。 下一次会议安排在下周同一时间。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-05-31","slug":"Ceph_Orchestrator_Meeting_2022-05-31","date":"2022-05-30T16:00:00.000Z","updated":"2022-05-31T16:00:00.000Z","comments":true,"path":"2022/05/31/Ceph_Orchestrator_Meeting_2022-05-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/31/Ceph_Orchestrator_Meeting_2022-05-31/","excerpt":"","text":"会议纪要： 磁盘扫描改进：Paul正在致力于改进磁盘扫描（rescan pr）功能，特别是针对外部存储设备。目标是通过gather facts工具提高扫描效率。目前尚未决定是否采用此方法，但初步反馈是积极的，计划进行概念验证。 磁盘库存同步问题：讨论了如何保持主机信息与Ceph集群信息的同步问题。提出使用gather facts工具收集磁盘信息，并确保其与当前库存数据同步。强调了代码同步的重要性，以避免信息不一致。 Prometheus服务发现：提出了一个PR，准备用于代码审查。该变更涉及代码移动和重构，以简化审查过程。讨论了服务发现端点的使用，以及如何确保Prometheus实例能够像外部工具一样利用这一新功能。 证书管理：讨论了如何处理外部监控工具部署时所需的证书问题。建议提供一种命令生成证书，以便用户手动设置在其Prometheus实例上。还考虑了在Ceph中设置一个使用安全证书的Cherry Pie服务器的可能性。 NFS和Ganesha配置：讨论了关于OpenStack环境中NFS服务的部署，特别是关于Ganesha配置和虚拟IP管理的PoC。目标是不使用HA代理，而是依赖Keeper FD来管理活动Ganesha服务器的浮动IP。 功能跟踪和API设计：确认了创建一个功能跟踪票据，记录Francesco的想法和PoC细节，以便Sephirium核心团队可以开始工作。讨论了如何设计API以减少用户混淆，特别是在部署时是否使用HA代理的情况下。 后续行动：约定在下次会议前更新PoC的进展，并在特征跟踪器票据中添加更多细节。确认了继续推进这些项目的计划，并在下次会议中回顾进度。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2022-05-24","slug":"Ceph_Science_Working_Group_2022-05-24","date":"2022-05-25T16:00:00.000Z","updated":"2022-05-25T16:00:00.000Z","comments":true,"path":"2022/05/26/Ceph_Science_Working_Group_2022-05-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/26/Ceph_Science_Working_Group_2022-05-24/","excerpt":"","text":"会议纪要： 讨论了Ceph分布式存储系统在大型集群中遇到的scrubbing问题，特别是与HP Apollos硬件相关的问题。探讨了磁盘类型（旋转磁盘、闪存或NVMe）、对象大小（小对象或大对象）以及测试数据量（约25PB）。 分析了默认的scrubbing和deep scrubbing参数是否适合当前的工作负载和硬件配置。提出可能需要调整这些参数以适应更大的文件和磁盘容量。 提到了由于硬件限制（如磁盘容量和I/O性能）导致的scrubbing警告，并讨论了如何通过调整监控阈值来减少这些警告。 讨论了RAID控制器的影响，特别是它们可能对整个磁盘的一致性检查（如Dell的patrol reads）产生的影响。 提出了基于OSD的大小和工作负载自动调整默认scrubbing参数的想法，并考虑了实现这一功能的可能性。 分享了有关Ceph版本更新的信息，特别是Octopus版本将支持CentOS 7，并讨论了升级到Pacific版本的计划。 提到了Cephalocon活动，包括虚拟参与的可能性和相关的技术展示。 讨论了集中式日志记录的使用情况，特别是Elasticsearch和Loki的使用，以及它们在Ceph环境中的潜在应用。 最后，讨论了一个特定的性能问题，涉及Power9节点上的性能下降，这可能是由于网络接口问题或内核客户端与OSD之间的连接中断所致。 行动计划： - 研究并调整scrubbing参数以适应大型磁盘和工作负载。 - 检查RAID控制器设置，以确定其是否影响scrubbing性能。 - 探索自动调整scrubbing参数的方法，可能通过开发脚本或工具来实现。 - 计划升级到Ceph的Pacific版本，并关注Octopus版本对CentOS 7的支持。 - 准备参与Cephalocon活动，包括技术展示和虚拟参与的安排。 - 评估集中式日志记录解决方案，如Elasticsearch和Loki，以提高Ceph环境的可管理性。 - 调查Power9节点性能问题的根本原因，并寻找解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore Meeting 2022-05-25","slug":"Ceph_Crimson_SeaStore_Meeting_2022-05-25","date":"2022-05-24T16:00:00.000Z","updated":"2022-05-24T16:00:00.000Z","comments":true,"path":"2022/05/25/Ceph_Crimson_SeaStore_Meeting_2022-05-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/25/Ceph_Crimson_SeaStore_Meeting_2022-05-25/","excerpt":"","text":"会议纪要： 更新状态： 参会者正在致力于错误日志机制，目前专注于处理两个丢失的日志操作。 代码审查和合并准备： 接近完成Scrub调度的清理工作，预计还需要几天时间，之后将请求代码审查。 GC（垃圾回收）开发： 目前正在进行C*代的GC开发，仍在进行Red Pass阶段。 小型PR（Pull Request）和测试： 本周完成了两个小型PR，并进行了进一步的验证测试，以探究空间回收事务与IO事务之间的冲突原因。 通过预填充数据的10GB RBD镜像进行随机写入测试，发现几乎不存在空间回收与事务之间的冲突。 使用未预填充数据Orbit镜像的测试显示，冲突从每个周期一个减少到几乎没有。 根据测试结果，可以确定之前观察到的冲突主要由LBA（逻辑块地址）处理不足引起。 优化工作： 正在对In-Cash后台缓冲区进行一些优化工作。 结论： 确认空间回收事务与IO事务间的冲突不再是主要问题，这是一个好消息。 行动计划： 继续完善错误日志机制。 完成Scrub调度的清理工作并提交代码审查。 继续进行C*代GC的开发。 关注空间回收事务与IO事务间冲突的优化。 继续优化In-Cash后台缓冲区。 下次会议： 本次会议内容已全部讨论完毕，期待下次会面。 请各参与者根据上述纪要推进各自负责的工作事项，并准备下一次会议的内容更新。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-05-17","slug":"Ceph_Orchestrator_Meeting_2022-05-17","date":"2022-05-24T16:00:00.000Z","updated":"2022-05-25T16:00:00.000Z","comments":true,"path":"2022/05/25/Ceph_Orchestrator_Meeting_2022-05-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/25/Ceph_Orchestrator_Meeting_2022-05-17/","excerpt":"","text":"会议纪要： 主题：讨论关于Ceph Rook与NFS操作的问题及后续行动计划 问题描述： 当Rook Orchestrator模块启用时，NFS操作失败。John Mulligan的工作允许NFS CLI在没有Orchestrator模块的情况下工作，但用户如果启用了Orchestrator模块，NFS命令将失败。 当前状况和回归分析： 在Pacific版本中，无论是否启用Orchestrator模块，NFS均可正常工作。但在Quincy版本中，只有在Orchestrator模块未启用时才能正常工作。 可能是由于Quincy版本的回退(backport)未能完全实现，导致部分逻辑或异常处理代码缺失。 讨论内容： 提出可能的解决方案，包括从模块中移除某些逻辑并引发合适的异常，或者尝试修复问题。 确认问题可能与Rook模块相关，需要检查该模块在Pacific和Quincy两个版本中的差异。 讨论OpenStack使用情况下对稳定虚拟IP的需求，以及可能的解决方案。 后续行动计划： 检查并确认Rook NFS的回退情况，确保没有遗漏。 验证不同版本的Rook模块中是否存在差异，特别是与NFS操作相关的代码块。 考虑OpenStack环境下对NFS服务器的要求，评估是否需要采取特殊措施来处理客户端IP限制的情况。 确定OpenStack发布时间线，以便相应地调整项目的优先级和计划。 其他事项： 讨论了功能请求，涉及为Ganesha提供非HA Proxy解决方案以提供稳定的虚拟IPs。 强调了对OpenStack发布时间的了解对于项目计划的重要性。 会议结论： - 团队需要调查和解决Rook NFS操作中存在的问题，同时考虑OpenStack环境中的特殊需求。 - 下一步行动包括检查代码差异、验证回退情况，并与OpenStack团队合作明确时间线和需求。 - 下一次会议将在一周后举行，届时将继续讨论这些问题和进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: Kernel Client Overview","slug":"CephFS_Code_Walkthrough_-_Kernel_Client_Overview","date":"2022-05-23T16:00:00.000Z","updated":"2022-05-24T16:00:00.000Z","comments":true,"path":"2022/05/24/CephFS_Code_Walkthrough_-_Kernel_Client_Overview/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/24/CephFS_Code_Walkthrough_-_Kernel_Client_Overview/","excerpt":"","text":"The question was about the comment in the function self atomic open which said \"if the file or sim link is non-existent, the vfs3 tries\". The questioner wanted to know if VFS keeps retrying and what's the idea behind that. Answer: The comment appears to be outdated and may not be correct. When a file is non-existent, VFS doesn't really retry; it just returns at that point. The calling convention for atomic open has changed, and this comment is likely no longer accurate. If an atomic open is called under very specific circumstances (like not having a cached entry for something or having a negative entry), it allows instantiating an entry if needed. It also handles situations where there might have been changes on the MDS that the client wasn't aware of. In such cases, if it turns out the file does exist and no create operation is being performed, an open call will be issued to the NBS, and the entry can be instantiated accordingly.","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore Meeting 2022-05-11","slug":"Ceph_Crimson_Seastore_Meeting_2022-05-11","date":"2022-05-23T16:00:00.000Z","updated":"2022-05-24T16:00:00.000Z","comments":true,"path":"2022/05/24/Ceph_Crimson_Seastore_Meeting_2022-05-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/24/Ceph_Crimson_Seastore_Meeting_2022-05-11/","excerpt":"","text":"会议纪要 会议主题: Ceph分布式存储开发团队周会 参会人员: [未明确指出] 会议内容概述 功能合并与代码审查 本周有人合并了一个包含多项修复的Pull Request (PR)，目前看来运作良好。 初步操作管道已重新基础并正在等待审查。 存储清理与分析 讨论了后台树的审查和分析。 提出了关于垃圾回收和空间计算调整的问题，需要确保逻辑上对其他参与者有意义。 问题诊断与解决 上周发现一个竞态条件的测试问题，导致客户端请求可能会重试。 建议写入错误日志以帮助检查是否已完成。 确认了对于复制操作的支持缺失，并讨论了如何发送日志条目给复制副本。 性能测试与优化 进行了性能测试，结果表明仅设置一定数量的具体IO可以显著减少冲突。 还讨论了如何控制并发IO的数量，以避免不必要的资源使用。 技术深入与改进 详细探讨了经典OSD的复制事务方式，以及如何将其应用于当前系统。 讨论了对象状态缓存的潜在bug以及如何解决。 后续行动计划 继续审查和合并代码。 对提出的解决方案进行进一步的测试和调试。 在下周的会议中安排时间深入讨论复杂的技术问题。 添加新的日志记录策略，帮助更有效地追踪和解决问题。 考虑实施新的IO并发控制策略，以优化性能和资源使用。 备注: 会议涉及到多个技术性议题，包括代码审查、性能优化、问题解决等，具体执行计划需在相关技术验证后确定。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting: 2022-05-24","slug":"Ceph_Orchestrator_Meeting_-_2022-05-24","date":"2022-05-23T16:00:00.000Z","updated":"2022-05-24T16:00:00.000Z","comments":true,"path":"2022/05/24/Ceph_Orchestrator_Meeting_-_2022-05-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/24/Ceph_Orchestrator_Meeting_-_2022-05-24/","excerpt":"","text":"在会议中，讨论了以下内容： 关于使用Docker镜像的问题。有提议考虑不再使用Docker镜像，因为可能会遇到速率限制问题。建议将Docker镜像复制到Clay，以避免这些问题。 关于备份和回滚策略的讨论。提出了一种自动化的方法来创建和管理回滚按钮，以简化这个过程。 关于软件包管理和版本控制的讨论。有建议使用特定的脚本或工具来自动化这个过程，并确保版本控制的准确性。 关于硬件和网络问题的讨论。提到了一些与硬件和网络相关的问题，但未给出具体解决方案。 关于会议纪要的讨论。强调了在会议结束后尽快提供详细的会议纪要，以便参会人员了解讨论内容和后续行动。 关于其他未提及议题的讨论。询问是否有其他需要讨论的议题，但未收到回应。 关于后续行动计划的讨论。确定了将在下次会议中继续讨论这些议题，并可能添加新议题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-05-10","slug":"Ceph_Orchestrator_Meeting_2022-05-10","date":"2022-05-23T16:00:00.000Z","updated":"2022-05-24T16:00:00.000Z","comments":true,"path":"2022/05/24/Ceph_Orchestrator_Meeting_2022-05-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/24/Ceph_Orchestrator_Meeting_2022-05-10/","excerpt":"","text":"Telemetry is super useful for us and it helps us make a better product, more robust, and have a higher quality.","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-05-05","slug":"Ceph_Performance_Meeting_2022-05-05","date":"2022-05-05T16:00:00.000Z","updated":"2022-05-06T16:00:00.000Z","comments":true,"path":"2022/05/06/Ceph_Performance_Meeting_2022-05-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/06/Ceph_Performance_Meeting_2022-05-05/","excerpt":"","text":"会议纪要 日期： [未提及具体日期，需补充] 参会人员： [未提及，需补充] 1. 已解决的问题和已完成的PRs Adam的卓越PR：修复了Quarry's PR中出现的问题，主要是通过不做整个空间迭代器的边界检查，现在之前失败的测试已经通过。 Cory的PR：已重新纳入pacific版本，并可能已回退主版本。该PR和atom六都将被纳入1628版本及master版本。目前进展顺利。 参数解析修复：收到了来自Kefu和Radic的良好反馈，代码质量超出原始版本。现在已正确将星号命令行选项传递给c-star，解决了之前的传递问题。 2. 更新的PRs和待解决问题 启用TC Malik的更新：使用CStar时，发现如果编译Ceph支持CStar，则neither Crimson还是Classic OSD将不会使用alec，而是都回退到使用lipsy。对于3GB的bluestore缓存大小，我们使用了约33GB的RAM，情况非常糟糕。此更新更改了条件判断逻辑，以防止在使用CStar时链接TC Malloc。 遇到的问题：目前遇到一些无效指针断言，似乎源自地址消毒器。Matan正在查看此问题，认为追踪到的问题源于TC Malloc的已知行为。此外，在运行的一些测试中发现了sink故障，可能是由此或其他因素引起。在解决这些问题前，相关PR可能会暂时搁置。 3. 未来计划和行动项 基于时间的Near-Fit算法：需要对PR进行重新定位和更新，但目前看来反馈良好，建议使用旧版本的配置选项以减少热路径性能的影响。 RGW Deus Cell实现：可能需要更多审查，并且现在需要重新定位。作者需要进一步操作。 增加测试覆盖率：特别是围绕我们的迭代器工作方式，以提高代码质量和防止未来的回归。 解决Aborts和Sig Faults：这似乎是优先事项，特别是为了能够进行更广泛的性能和压力测试。 Igor的工作评估：开始评估Igor实现的BlueStore Wall的工作，而不是使用RoxDB1。目前看来，新机制尚未在BlueStore中启用，需要进一步调查原因。 下一步行动： - 继续跟踪与TC Malloc相关的问题并解决。 - 提高迭代器工作的测试覆盖率。 - 确定是否继续使用传统选项或转向新的配置方式。 - 关注并帮助解决Crimson的性能瓶颈和挂起问题。 - 深入理解和评估BlueStore Wall的实现和效果。 会议结束：会议提前结束，祝大家有一个美好的一周，并期待下周的会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Telemetry Dashboard","slug":"Ceph_Tech_Talk_-_Telemetry_Dashboard","date":"2022-05-05T16:00:00.000Z","updated":"2022-05-06T16:00:00.000Z","comments":true,"path":"2022/05/06/Ceph_Tech_Talk_-_Telemetry_Dashboard/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/06/Ceph_Tech_Talk_-_Telemetry_Dashboard/","excerpt":"","text":"问题: 如何通过telemetry.front.sepia链接访问开发者专用的crash dashboard？ 答案: 开发者需要通过启用sepia vpn来访问telemetry.front.sepia链接，进而搜索和查看crashes。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User + Dev Meeting 2022-05-04","slug":"Ceph_User_+_Dev_Meeting_2022-05-04","date":"2022-05-04T16:00:00.000Z","updated":"2022-05-05T16:00:00.000Z","comments":true,"path":"2022/05/05/Ceph_User_+_Dev_Meeting_2022-05-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/05/Ceph_User_+_Dev_Meeting_2022-05-04/","excerpt":"","text":"会议纪要 会议主题：介绍和讨论IBM的NVM设备在SETH中的部署，以及相关插件系统的开发。 参会人员：Martin Omar（IBM），会议主持人，及其他参与者。 主要讨论内容： Martin介绍了他在IBM的工作，特别是关于NVMe存储设备（NVM）的项目。这些设备由IBM生产，具有在线压缩功能，逻辑块地址为22TB，但物理存储空间只有9.6TB。 详细解释了存储设备的使用模型，与VDO设备类似，已得到SETH的支持。 讨论了如何通过插件系统支持IBM NVM设备。Martin实验性地添加了一个基于Erasure Code插件系统的插件，并创建了一个新的插件系统“xblock_device”。 介绍了新插件系统的架构，包括内核设备结构、插件注册、全局初始化等。 对于安全问题，讨论了Linux的capability system和\"keep caps\" flag的使用，以确保插件在权限切换时的安全性。 技术细节： 创建了两个commit，一个包含插件系统和VDO设备的插件，另一个是特定于FCM设备的插件和必要的Linux配置调整。 提出了对插件系统进行用户可配置的权限设置，以限制不必要的权限提升。 后续行动： Martin将继续测试FCM设备的插件，并希望未来能开放接口以便部署在其他客户环境中。 下一步是进行代码审查和添加更多的测试细节。 问题和反馈： 讨论中提出对安全模型和插件系统的改进建议，如更精细化的权限控制和自动化测试。 确认了参会者对插件系统结构的理解和接受。 会议结论： 本次会议主要集中在IBM NVM设备的插件系统开发上，Martin提供了详细的技术介绍和演示，得到了积极的反馈。 确定了改进安全性和测试的计划，为未来的开发和部署奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-05-04","slug":"Ceph_Orchestrator_Meeting_2022-05-04","date":"2022-05-03T16:00:00.000Z","updated":"2022-05-04T16:00:00.000Z","comments":true,"path":"2022/05/04/Ceph_Orchestrator_Meeting_2022-05-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/05/04/Ceph_Orchestrator_Meeting_2022-05-04/","excerpt":"","text":"当前问题：如果限制NFS导出到特定IP，尝试从这些特定IP挂载时会遭到拒绝。 原因：后端NFS服务器仅看到HAProxy代理的IP，而非客户端ID。 可能的解决方案：设置HAProxy以透明模式运行，使后端服务器能看到客户端IP，而非H8代理IP。 实施难点：需要后端服务器支持代理协议，但当前的Ganesha服务器不支持，因此需要寻找其他方法。 进一步研究：探索是否有其他方式可以设置HAProxy在透明模式下工作，或者为Ganesha服务提供稳定的IP地址解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-04-26","slug":"Ceph_Orchestrator_Meeting_2022-04-26","date":"2022-04-25T16:00:00.000Z","updated":"2022-04-26T16:00:00.000Z","comments":true,"path":"2022/04/26/Ceph_Orchestrator_Meeting_2022-04-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/26/Ceph_Orchestrator_Meeting_2022-04-26/","excerpt":"","text":"会议纪要： 议题一：关于代码审查和功能开发进度的更新，具体如下： 提及了需要重新审视和可能推迟的议题。 讨论了站立会议的频率，提出可能减少会议次数以提高效率。 对HNFS (Highly Non-homogeneous Storage System) 的更新进行了简要讨论，确认了其基本功能正常，但存在一个与OpenStack团队相关的bug。 讨论了升级顺序的问题，强调了核心组件如OSD和MDS的重要性，并提出了放宽对非核心组件的升级顺序限制。 议题二：关于Rook项目的更新，具体如下： 讨论了通过Orchestrator模块进行工作的策略，并提出在Rook中添加新功能。 强调了为Kubernetes用户提供更有用的功能的目标，以及如何实现这一点。 提到了现有Rook Python客户端库的问题，包括其维护和使用方式，以及可能的改进方向。 决定和行动计划： 同意减少站立会议频率，建议每周一和周四举行。 对HNFS的功能和存在的问题有了初步了解，计划进一步调查。 针对升级顺序问题，决定限制仅到MDS级别，之后的顺序可以更灵活处理。 Rook项目将探索添加新功能，并重新考虑现有的Python客户端库的使用和维护策略。 强调了资源分配和整合测试的重要性，以确保项目的顺利进行。 下一步行动： 将相关提议和决定通过邮件通知所有相关人员，并调整会议频率。 对HNFS的问题进行详细调查，并跟进OpenStack团队的反馈。 继续监控Rook项目的开发进度，并探讨新的接口设计。 查找或指定资源来维护和更新Rook Python客户端库，确保其与主项目的同步和兼容性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Crimson","slug":"CDS_Reef_-_Crimson","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-22T16:00:00.000Z","comments":true,"path":"2022/04/22/CDS_Reef_-_Crimson/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/CDS_Reef_-_Crimson/","excerpt":"","text":"会议主要讨论了Crimson CDF项目2022年的进展，重点关注Quincy版本的稳定性和部署情况，以及Reef版本的开发重点。具体内容如下： Quincy版本： 过去一年的主要工作集中在稳定性和部署上。 Crimson现在支持Rook、SAFE和Seth ADM进行部署。 开发了初步的Crimson RADOS技术套件，并进行了故障注入测试。 对发现的问题进行了大量修复，特别是在排序和watch notify API方面。 改进了Blue Stores的支持。 C-Store： 引入了新的指标框架，以更好地理解C-Store的行为。 对C-Store内部进行了重写，简化了LBA树结构，增加了非日志段存储扩展的能力。 冲突检测机制使用可中断的未来重写。 添加了初始DNS支持，ZNS段管理器已在真实的DNS设备上测试。 在性能方面，对LBA提示和日志合并进行了改进。 Reef版本： 多核快照和清理是Reef的重点，特别是清理功能对于其他组件的信心至关重要。 将针对C-Store进行大量工作，包括多设备和分层的进一步改进，特别是与垃圾回收相关。 支持通过Random Block Manager快速访问NVMe设备。 最初通过在静态磁盘分区上运行多个C-Store实例来处理多核问题。 测试和部署： Quincy应该支持在单Reactor配置中测试RBD工作负载，无需快照，后端可以是Blue Store、Cyan Store或C Store，使用Rook或Seth ADM部署。 需要选择一种病理学测试作为所有PR的门槛测试，以确保Crimson持续有效。 调试子系统： 需要使Crimson的日志记录方式与Classic一致。 应尊重Classic的debug_underscore配置选项。 PG日志消息应保持一致性，便于抓取特定PG的所有日志行。 垃圾回收策略讨论： 介绍了基于代数的垃圾回收策略，目的是将相似特性和年龄的扩展存储在同一段中。 讨论了代数的概念，即扩展可以存储在具有相同特性和类似年龄的段中。 提出了对策略的担忧和可能的改进建议，如直接将冷扩展写入更高代数。 后续行动计划： 继续改进C Store的成熟度，尽管可能会落后于Crimson整体进度。 探索更频繁的发布周期，如每月或每周自动构建快照，以便社区成员下载和运行。 推动与更广泛的社区合作，改善发布流程，并考虑为新贡献者编写指令和修复错误。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Dashboard","slug":"CDS_Reef_-_Dashboard","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-21T16:00:00.000Z","comments":true,"path":"2022/04/22/CDS_Reef_-_Dashboard/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/CDS_Reef_-_Dashboard/","excerpt":"","text":"Ceph Dashboard会议纪要 会议概述 本次会议主要讨论了Ceph Dashboard在Reef版本的开发进展，包括即将到来的里程碑、过去开发新功能时遇到的问题和经验，以及未来的行动计划。 主要议题 里程碑与进度 讨论了接下来一周的里程碑，包括Dashboard的开发进度和与过去版本的连接。 规模测试反馈 分享了在Supercomputer Center进行的规模测试结果，特别是在150节点集群上的测试。 发现了一些特定端点的问题，如Aussie组件的百分比缩放问题，以及警报数量在实例增加时的缩放问题。 讨论了监控指标如何报告和传递给Prometheus的问题。 用户调查反馈 分析了用户对Dashboard的反馈，包括正面评价和改进建议。 用户主要使用Dashboard进行监控，而非主动管理。 提出了改进UI/UX设计、报告功能和增加对象浏览器的建议。 功能与改进 讨论了低级指标（如温度）的显示请求。 提到了改进警报系统的必要性，特别是减少噪音警报。 介绍了集中式日志系统的计划，基于Loki和Promtail。 多集群支持 探讨了多集群监控和管理的必要性，以及如何实现集中式日志记录。 讨论了多集群意识和RBD及CephFS镜像管理的可能性。 开发经验与测试 强调了改进开发体验和自动化测试的重要性。 讨论了后端驱动的UI和使用JSON生成表单的可能性。 决定事项 确认了集中式日志系统的实施计划，使用Loki和Promtail。 确定了多集群监控和管理的初步方向，但需要进一步讨论。 确认了改进警报系统和UI/UX设计的必要性。 后续行动计划 继续开发和优化Dashboard的功能，特别是Wizard和多站点管理。 实施后端分页和过滤，以提高Dashboard的可扩展性。 加强与用户的沟通，收集更多反馈，以指导未来的开发方向。 探索更多自动化测试和开发工具，以提高开发效率和产品质量。 其他讨论 讨论了API的稳定性和版本支持问题。 探讨了与Rook orchestrator的集成可能性。 讨论了Ceph核心功能的UI支持，如mclock配置文件。 结论 会议强调了持续改进Ceph Dashboard的重要性，特别是在用户体验、功能扩展和系统稳定性方面。通过不断的用户反馈和内部开发努力，目标是使Dashboard成为一个更加强大和用户友好的管理工具。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Governance","slug":"CDS_Reef_-_Governance","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-22T16:00:00.000Z","comments":true,"path":"2022/04/22/CDS_Reef_-_Governance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/CDS_Reef_-_Governance/","excerpt":"","text":"治理结构：讨论了Ceph项目的治理结构，包括技术指导委员会（TSC）和项目管理委员会（PMC）。 贡献流程：明确了代码提交、审核及合并的流程。 测试与发布：强调了持续集成的重要性，并提到了使用Jenkins进行构建和测试。 版本控制：指出了git作为版本控制系统的使用，以及GitHub作为代码托管平台。 社区沟通：提及了通过邮件列表、IRC和定期会议等方式进行社区沟通。 文档编写：强调了编写清晰、准确文档的重要性，并提到了使用Sphinx工具。 代码质量：讨论了静态分析工具（如Pylint）的使用，以及确保代码质量和一致性的措施。 项目规划：提到了项目管理和路线图规划的重要性，以及如何适应需求变化。 贡献者激励：探讨了如何吸引和保留贡献者，包括设置里程碑和奖励机制。 决策制定：强调了透明和包容的决策过程，以及如何处理分歧和冲突。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Performance Meeting","slug":"CDS_Reef_-_Performance_Meeting","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-22T16:00:00.000Z","comments":true,"path":"2022/04/22/CDS_Reef_-_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/CDS_Reef_-_Performance_Meeting/","excerpt":"","text":"会议主要讨论了Ceph存储系统的最新更新和问题修复，特别是162h版本的发布情况，以及针对特定性能问题的PR（Pull Request）的更新和审查。会议内容涵盖了以下要点： 版本发布与问题跟踪：团队正在处理来自Quincy及Pacific 162h版本的后续事宜，包括一个由Adam关闭的PR，该PR的内容被转移到其他VR和其他工作中，剩余部分不再必要或已被加入其他项目。 代码审查：Corey的PR经过广泛讨论，Casey和Igor已审查并认为其良好，但建议增加配置参数以在必要时恢复到旧的行为模式。 性能优化：讨论了一个时间基算法的更新，旨在改善ADL分配器的性能，避免重复搜索，简化逻辑，提高可理解性。 文档更新：关于重写硬件文档的PR，进行了一些关于措辞的建议和讨论，特别是关于时钟速度与核心数量的表述。 关键问题解决：Corey详细描述了他们遇到的一项严重性能问题，涉及动态分片操作失败导致集群性能急剧下降的问题，并提出了解决方案。该方案将作为默认行为，但也提供了配置选项以便在出现问题时能够关闭。 内存管理与性能测试：Radik讨论了Crimson项目中的内存管理问题，提出可能的解决方案，并计划进行进一步的测试和优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: RBD","slug":"CDS_Reef_-_RBD","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-22T16:00:00.000Z","comments":true,"path":"2022/04/22/CDS_Reef_-_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/CDS_Reef_-_RBD/","excerpt":"","text":"Mirroring Schedule Stagger：尝试错开快照计划和镜像计划，以在一段时间内产生一致的性能影响。 State Machine Documentation：改善关于rbd mirroring的状态机文档，以便更好地为开发者提供一些部分的文档。 Rbd Suite Movement to Using Sap Area：将rbd套件迁移到使用sap area，目前仍在进行中，但需要完成多集群支持的工作。 Lack of State Machine Diagrams：在rv mirror代码库中缺少状态机图，这是一个相对容易解决的问题，并且对于刚熟悉代码库的人来说也是一个好任务，因为它有助于从高层次了解代码并整合这些高级状态图。 Sfadm Migration for the Qa Suite：关于qa套件的sfadm迁移，有一个pr正在进行中，但启动它的人已经不再参与其中。将来，这也可以作为新手参与topology和rbd套件的一个很好的起点。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: RADOS","slug":"CDS_Reef_-_RADOS","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-22T16:00:00.000Z","comments":true,"path":"2022/04/22/CDS_Reef_-_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/CDS_Reef_-_RADOS/","excerpt":"","text":"Configuration Profiles: PR link provided for implementation of configuration profiles on a pool level, aimed at reef but backportable to quincy. Automatic Key Rotation: Outstanding PR exists, with work done for quincy enabling backporting, close to completion for reef. Balancer Improvements: Work on the workload or primary balancer focusing on balancing read requests based on pool workloads, with refactored capacity balancer code for clarity and future maintainability. Autoscaler Checks and Balances: Addition of \"dash bulk\" flag in quincy to manage pgs effectively, and \"no auto scale global\" flag to turn off the autoscaler globally. Addressing recent issues where autoscaler actions impact cluster performance. OSD Map Trimming: Case identified where millions of OSD maps remain untrimmed due to a trigger in map generation. To be discussed further post understanding the issue. Partial Stripe Breeds: Implementation of partial stripes to efficiently read subsets of data without accessing every OSD, beneficial for CPU load reduction especially for small reads in large objects. Testing Improvements and Board Cleanup: Discussing testing coverage improvement, particularly for stretch mode, netsplit subsuite, and logical skill testing at larger scales. Also, addressing upgrade test coverage, tracking test improvements, reducing raiders suite run time, and cleanup/deprecation tasks including legacy watches and mdr module usage.","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-04-18","slug":"Ceph_Orchestrator_Meeting_2022-04-18","date":"2022-04-21T16:00:00.000Z","updated":"2022-04-21T16:00:00.000Z","comments":true,"path":"2022/04/22/Ceph_Orchestrator_Meeting_2022-04-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/22/Ceph_Orchestrator_Meeting_2022-04-18/","excerpt":"","text":"会议纪要 会议概述 本次会议由于参与人数较少，原计划讨论的问题优先级排序被推迟。会议主要讨论了两个相关议题，并计划在后续会议中继续讨论。 主要议题 配置文件的使用 讨论内容：讨论了当前使用的配置文件（如 etcsef.com）的重要性。由于大多数守护进程（demons）从监视器（monitor）获取配置信息，因此对于配置文件的需求进行了质疑。 主要观点： 配置文件目前主要用于获取监视器的IP地址，以便执行shell命令。 在容器化环境中，配置文件的重要性有所降低，因为容器通常会挂载自己的配置文件。 长期来看，如果集群配置可以在其他地方（如 bar leap）获取，配置文件可能变得不再必要。 决定事项： 短期内不会移除配置文件，因为可能存在一些遗留系统依赖它。 需要进一步调查和测试，以确定是否可以完全移除配置文件。 镜像选择算法 讨论内容：讨论了在升级过程中，如何选择合适的镜像（image）。当前算法仅选择最新镜像，但在混合旧镜像和新镜像的环境中可能不适用。 主要观点： 建议使用守护进程（demons）的信息来选择镜像，如果无法获取则回退到旧算法。 可以通过优先级列表来选择镜像，优先考虑用户指定的镜像，然后是守护进程的配置，最后是默认的最新镜像。 决定事项： 需要实现新的镜像选择算法，并进行充分的测试。 需要添加更多的日志信息，以便用户了解正在使用的镜像。 后续行动计划 配置文件的使用： 继续调查和测试配置文件的使用情况。 考虑长期移除配置文件的可能性，并制定相应的计划。 镜像选择算法： 实现新的镜像选择算法。 添加更多的日志信息，以便用户了解正在使用的镜像。 进行充分的测试，确保新算法在各种情况下都能正常工作。 其他事项： 将未讨论的议题推迟到下一次会议。 与Mike进一步讨论关于二进制文件重构的计划和策略。 会议结束 会议在讨论完所有议题后结束，计划在下次会议中继续讨论未完成的事项。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Performance","slug":"CDS_Reef_-_Performance","date":"2022-04-13T16:00:00.000Z","updated":"2022-04-14T16:00:00.000Z","comments":true,"path":"2022/04/14/CDS_Reef_-_Performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/14/CDS_Reef_-_Performance/","excerpt":"","text":"会议纪要 关键细节 新Pull Requests (PRs): Corey的PR涉及在RocksDB omap迭代器中设置上下限，Casey正在审查并提出了避免拷贝和内存泄漏的建议。 另一个PR允许RGW使用DEOS作为后端存储，DEOS是一个基于Luster的高性能对象存储系统，目前还处于实验阶段。 关闭的PRs: 一个PR是对AVL分配器的最小化修复，解决了之前改变导致的分配问题。 另一个PR是早期尝试修复同一问题，但已被新的PR取代。 更新的PRs: 一个PR改变AVL分配器以基于时间阈值进行搜索，而不是当前的字节和循环计数。 另一个PR涉及跟踪更新，Typica进行了审查。 讨论的主要议题 AVL分配器性能: 讨论了AVL分配器的搜索策略，特别是从近似匹配模式切换到最佳匹配模式的阈值设置。 提出了基于时间的搜索限制，以简化调整过程。 PG日志优化: 讨论了PG日志的写入和存储问题，特别是与RocksDB的集成和性能影响。 提出了使用RocksDB的写前日志机制来优化PG日志的存储和管理。 决定的事项 AVL分配器: 决定继续探索基于时间的搜索限制，并可能支持两种限制方式以确保其有效性。 PG日志: 决定进一步研究和原型化使用RocksDB的写前日志机制来优化PG日志的存储和管理。 后续行动计划 AVL分配器: 继续测试和验证基于时间的搜索限制。 PG日志: 原型化并测试使用RocksDB的写前日志机制来优化PG日志的存储和管理。 会议安排: 下一次会议将首先讨论Corey关于RocksDB迭代器边界的工作，然后继续PG日志的讨论。 其他 会议还涉及了其他一些技术细节和潜在的性能优化点，包括对RocksDB写前日志的深入讨论和可能的改进。 会议结束: 感谢所有参与者的贡献，并祝愿大家有一个愉快的假期周末。下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Rados Gateway","slug":"CDS_Reef_-_Rados_Gateway","date":"2022-04-13T16:00:00.000Z","updated":"2022-04-13T16:00:00.000Z","comments":true,"path":"2022/04/14/CDS_Reef_-_Rados_Gateway/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/14/CDS_Reef_-_Rados_Gateway/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph分布式存储系统中RGW（RADOS Gateway）的多个高层次项目和进展，包括新功能的开发、现有功能的优化以及测试和性能提升等方面。 主要议题 Zipper项目 动态加载存储库：计划允许从共享库中加载存储库，而不是内置在Ftree中，以更好地支持外部项目的集成。 独立模式：探索基于DB存储的独立模式，以便在小规模配置中运行，无需连接到集群。 过滤层：开发一个过滤层，通过包装另一个存储接口并传递所有调用，实现数据缓存和其他中间层策略。 S3 Select JSON支持：正在进行对JSON格式对象的查询支持，计划在Reef版本中完成。 AeroFlight集成：虽然与S3 Select不是直接相关，但AeroFlight作为一个前端，理解列式数据集，并有一个内部接口Flight SQL，可以进行各种限制操作。 异步重构项目 减少线程数：目标是能够以远少于默认的512个线程运行，Adam在Neo-Rados客户端的工作与此紧密相关。 可观测性和追踪 Jaeger集成：已经进行了大量工作将Jaeger集成到Ceph中，构建追踪原语并测试其性能。 条件追踪：正在探索基于Lua的条件追踪，以便在特定条件下动态启用追踪。 多站点（Multi-Site）项目 动态重分片：正在进行动态重分片的工作，以提高多站点配置的可扩展性。 同步公平性：目标是改进多个网关实例之间的协作，优化同步过程。 工作负载测试 测试重写：考虑重写多站点测试，可能使用Golang或其他支持并发性的语言。 性能和规模测试：讨论了使用MinIO Warp工具进行工作负载生成，以及在ToothAlley环境中进行大规模测试的可能性。 HTTP/3支持 长期目标：计划在RGW中添加HTTP/3支持，以实现更低的延迟和更好的性能。 同步信息提供者 抽象同步API：工作包括抽象同步API，以便支持非RGW数据源，如AWS S3。 功能弃用 OMAP日志：讨论了弃用OMAP日志的可能性，特别是在数据日志方面。 决定事项 继续推进Zipper项目中的各项功能开发。 完成S3 Select的JSON支持和AeroFlight集成。 完成异步重构项目，减少线程数。 完善可观测性和追踪功能，特别是条件追踪的实现。 完成多站点项目的动态重分片和同步公平性改进。 探索使用Golang重写多站点测试，并使用MinIO Warp进行工作负载测试。 开始HTTP/3支持的初步研究。 继续推进同步信息提供者的工作，并在动态重分片完成后重新审视。 考虑在Reef版本中弃用OMAP日志。 后续行动计划 继续开发和测试Zipper项目中的功能。 完成S3 Select的JSON支持和AeroFlight集成。 完成异步重构项目，减少线程数。 完善可观测性和追踪功能，特别是条件追踪的实现。 完成多站点项目的动态重分片和同步公平性改进。 探索使用Golang重写多站点测试，并使用MinIO Warp进行工作负载测试。 开始HTTP/3支持的初步研究。 继续推进同步信息提供者的工作，并在动态重分片完成后重新审视。 考虑在Reef版本中弃用OMAP日志。 其他讨论 讨论了在ToothAlley环境中进行大规模测试的可能性。 讨论了在Ceph Messenger中添加QUIC支持的可能性。 讨论了Deprecating features，特别是OMAP日志的支持。 会议结束 会议在讨论了所有议题后结束，Casey计划将新内容添加到Trello的Backlog中，并鼓励大家继续参与后续的讨论和开发工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Reef: Orchestrator","slug":"CDS_Reef_-_Orchestrator","date":"2022-04-12T16:00:00.000Z","updated":"2022-04-12T16:00:00.000Z","comments":true,"path":"2022/04/13/CDS_Reef_-_Orchestrator/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/13/CDS_Reef_-_Orchestrator/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph Orchestrator的规划，包括团队提出的初始议题和后续行动计划。会议涉及多个关键议题，包括代理稳定化、服务循环透明度、升级历史记录、二进制文件重构、工作流程简化以及断开环境的支持等。 主要议题 代理稳定化 现状：代理（agent）是一个非容器化的守护进程，运行在每个主机上，用于加速指标收集。 问题：存在主机离线时的稳定性问题，需要进一步的稳定化和功能增强。 计划：增强代理的稳定性，实现守护进程的部署和信息收集功能，使其能够异步执行，提高效率。 服务循环透明度 现状：当前服务事件和日志信息难以访问，不易于调试。 计划：改进日志和事件的可访问性，提供CLI命令来查看历史操作和当前状态，增强调试功能。 升级历史记录 现状：升级过程中的状态信息在完成后消失，难以追踪。 计划：实现升级历史记录功能，记录升级的时间、版本等信息，便于后续查询和故障排查。 二进制文件重构 现状：当前二进制文件庞大且难以维护。 计划：进行二进制文件的重构，将其模块化，便于未来的维护和开发。 工作流程简化 计划：自动化一些复杂的工作流程，如监控堆栈镜像的设置和多站点部署，提高用户体验。 断开环境支持 现状：当前对断开环境的文档和支持有限。 计划：增强对断开环境的支持，确保在这些环境中的部署和运行更加顺畅。 决定事项 增强代理的稳定性和功能。 改进服务循环的透明度和调试功能。 实现升级历史记录功能。 进行二进制文件的重构。 自动化复杂的工作流程。 增强对断开环境的支持。 后续行动计划 继续推进代理的稳定化和功能增强。 开发和测试服务循环透明度的改进措施。 实现和测试升级历史记录功能。 完成二进制文件的重构工作。 自动化监控堆栈镜像设置和多站点部署流程。 增强断开环境的文档和支持。 其他讨论 讨论了性能和规模的问题，计划在未来进行更多的测试和优化。 提及了资源感知调度的问题，计划在未来进行研究和开发。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并期待未来的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-04-07","slug":"Ceph_Performance_Meeting_2022-04-07","date":"2022-04-06T16:00:00.000Z","updated":"2022-04-07T16:00:00.000Z","comments":true,"path":"2022/04/07/Ceph_Performance_Meeting_2022-04-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/07/Ceph_Performance_Meeting_2022-04-07/","excerpt":"","text":"会议纪要 关键细节 性能问题讨论：会议主要围绕Ceph存储系统中的性能问题展开，特别是关于NVMe驱动器和AVL分配器的行为。 具体问题：Gabriel报告了在快速NVMe测试节点上使用master分支时，性能从过去的70,000到80,000 IOPS下降到现在的20,000到30,000 IOPS。 AVL分配器变更：讨论了AVL分配器中关于何时切换到最佳适配模式的变更，这些变更限制了搜索的字节距离和迭代次数。 讨论的主要议题 性能下降原因：分析了性能下降的可能原因，包括可能的硬件问题或软件配置问题。 分配器行为变更：讨论了分配器行为的变更对性能的影响，特别是在三星驱动器上的表现。 测试结果分析：分享了不同配置下的测试结果，包括在不同驱动器和硬盘上的表现。 决定的事项 进一步测试：决定进行更多的测试，特别是在硬盘上，以评估新代码的影响。 代码审查：决定对新引入的分配器代码进行详细审查，以确保其性能和稳定性。 后续行动计划 性能分析：Gabriel将继续分析性能数据，并与团队成员合作，以确定问题的根本原因。 代码优化：团队将考虑对分配器代码进行优化，以改善其在不同硬件上的性能表现。 硬件兼容性测试：将进行更多的硬件兼容性测试，确保Ceph在各种存储设备上的稳定性和性能。 其他讨论点 分配器状态分析：Mark提议在分配器表现不佳时，捕获其状态以进行详细分析。 长期测试：讨论了进行长期测试的必要性，以更全面地评估系统性能。 结论 会议强调了Ceph存储系统在不同硬件配置下的性能问题，并决定通过进一步测试和代码优化来解决这些问题。团队将继续监控和改进系统性能，确保Ceph在各种应用场景中的高效和稳定运行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-04-05","slug":"Ceph_Orchestrator_Meeting_2022-04-05","date":"2022-04-04T16:00:00.000Z","updated":"2022-04-05T16:00:00.000Z","comments":true,"path":"2022/04/05/Ceph_Orchestrator_Meeting_2022-04-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/04/05/Ceph_Orchestrator_Meeting_2022-04-05/","excerpt":"","text":"会议纪要 主要议题 文档维护与更新 讨论了关于RGW和NFS的文档链接，建议将这些文档整合到一个统一的入口，以便更好地维护和更新。 提议创建一个通用的入口文档，避免重复内容，并考虑是否可以创建一个通用的图表来替代特定服务的图表。 多集群支持 讨论了在同一主机上运行多个Ceph集群的配置和管理问题，特别是关于配置文件和FSID的管理。 提出了一个解决方案，即将配置文件同时保存在默认位置和特定FSID的目录下，以简化多集群环境的管理。 集群命名和系统单元文件 讨论了集群命名的问题，特别是关于集群名称在系统单元文件和路径中的使用。 提出了需要进一步调查和测试，以确保不同名称的集群在采用过程中能够正确工作。 未来计划和行动项 讨论了即将到来的规划会议，提出了一些可能的改进点，如增强服务器循环的透明度、改进错误报告机制、优化升级历史记录等。 讨论了代码重构和二进制文件管理的问题，以及如何更好地支持离线环境。 决定事项 将RGW和NFS的文档整合到一个通用的入口文档中，避免重复内容。 创建一个通用的图表来替代特定服务的图表，以简化文档维护。 对于多集群支持，决定将配置文件同时保存在默认位置和特定FSID的目录下。 对于集群命名问题，需要进一步调查和测试，以确保不同名称的集群在采用过程中能够正确工作。 后续行动计划 由团队成员或技术写手负责整合和更新文档。 创建一个新的跟踪器来记录和跟踪多集群支持的改进工作。 调查和测试集群命名和系统单元文件的问题，并在未来的规划会议中讨论。 准备并参与即将到来的规划会议，提出改进建议和行动计划。 其他讨论点 讨论了容器注册表的管理和离线环境的支持，提出了一些初步的想法和建议。 讨论了代码重构和二进制文件管理的问题，以及如何更好地支持离线环境。 会议结束 会议在讨论了所有议题后结束，团队成员将在下一次规划会议中继续讨论和推进相关工作。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-03-31","slug":"Ceph_Performance_Meeting_2022-03-31","date":"2022-03-30T16:00:00.000Z","updated":"2022-03-31T16:00:00.000Z","comments":true,"path":"2022/03/31/Ceph_Performance_Meeting_2022-03-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/31/Ceph_Performance_Meeting_2022-03-31/","excerpt":"","text":"会议纪要 关键细节 Pull Requests (PRs) 动态: 本周PR活动不多，主要因为团队正忙于在Quincy版本中修复问题。 RGW Multi-Site Resharding PR: 该PR已合并到另一个分支，最终将合并到主分支。 性能相关PR: Gabby的PR主要是代码清理，不影响性能。另一个关于tracer的PR正在进行更多测试，以确保其稳定性。 性能回归问题: 团队正在追踪Quincy版本中的写入性能回归问题，初步怀疑与AVL分配器的更改有关。 讨论的主要议题 性能回归问题分析: 通过二分法定位到特定提交，该提交涉及AVL分配器的更改。团队正在测试回滚该更改后的性能影响。 分配器行为变化: 讨论了分配器在First Fit和Best Fit模式下的行为差异，以及这些模式如何影响性能。 硬件差异对性能的影响: 讨论了不同硬件（如AMD和Intel）上性能表现的差异，以及如何通过测试来验证这些差异。 决定的事项 继续测试和分析: 团队将继续测试回滚AVL分配器更改后的性能，并探索其他可能影响性能的因素。 使用性能直方图: 计划使用性能直方图来分析分配器的输出，以更好地理解其对性能的影响。 后续的行动计划 详细测试计划: 包括使用fio进行更详细的性能测试，特别是在不同硬件上的测试。 性能直方图分析: 收集和分析性能直方图数据，以评估分配器的输出对性能的具体影响。 硬件和软件配置的同步: 确保测试环境和配置的一致性，以便更准确地比较不同硬件和软件配置下的性能表现。 其他事项 会议结束: 会议在讨论完所有议题后结束，团队成员将继续进行各自的测试和分析工作。 关键词 Pull Requests (PRs) RGW Multi-Site Resharding Quincy AVL Allocator First Fit vs Best Fit Performance Regression fio Performance Histogram 本次会议主要围绕Ceph存储系统的性能问题展开深入讨论，团队成员通过详细的测试和分析，逐步定位问题并制定相应的解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2022-03-24 :: Ceph Tech Talk - Running Teuthology Locally","slug":"2022-03-24_-_-_Ceph_Tech_Talk_-_Running_Teuthology_Locally","date":"2022-03-29T16:00:00.000Z","updated":"2022-03-29T16:00:00.000Z","comments":true,"path":"2022/03/30/2022-03-24_-_-_Ceph_Tech_Talk_-_Running_Teuthology_Locally/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/30/2022-03-24_-_-_Ceph_Tech_Talk_-_Running_Teuthology_Locally/","excerpt":"","text":"会议纪要 会议主题：使用GPU Labs在本地运行Tautology的演示 会议时间：[具体时间] 会议地点：视频会议 参会人员：Junior（Red Hat Raidos团队成员）、Zach（Red Hat成员）、其他相关开发人员和贡献者 会议内容总结： 介绍与背景 Junior介绍了他在Red Hat的工作经历，特别是在Raidos团队和Tautology项目的工作。 讨论了Tautology的安装过程复杂性，涉及多个服务（如Postgres, Paddles, Pepito, Beanstalk），以及不同开发环境带来的挑战。 问题与解决方案 面临的问题：Tautology的安装和配置过程复杂，对开发者和贡献者不友好。 解决方案：使用Docker容器自动化安装过程，并提供清晰的文档，特别是无法自动化的部分，如添加测试节点。 使用场景 Tautology开发者希望贡献代码。 外部贡献者（如Ouchi和GSoC的实习生）。 开发者希望在本地快速测试，避免等待CI队列。 演示内容 展示了如何使用Docker容器设置本地Tautology环境。 详细介绍了Docker Compose文件的配置和各个服务的依赖关系。 演示了如何添加测试节点到本地Tautology，并运行一个示例作业。 未来工作与改进 自动化更多手动步骤，特别是添加测试节点到库存的过程。 探索使用容器作为测试节点，减少对物理机器的依赖。 长期目标：允许开发者在本地构建和测试，减少对CI的依赖。 Q&amp;A 讨论了如何在没有VPN访问的情况下获取IP信息。 强调了未来工作的重要性，特别是容器化测试节点的进展。 决定事项： 继续推进Tautology的本地开发环境优化，特别是容器化测试节点的实现。 计划未来再次进行演示，展示容器化测试节点的进展和下一步计划。 后续行动计划： 完成容器化测试节点的开发，并提交PR。 更新文档，确保所有步骤都清晰易懂。 定期更新社区，确保所有贡献者都能了解最新进展。 会议结束语： 感谢Junior和Zach的精彩演示和详细解释。 鼓励所有参会者提供反馈和建议，以便进一步改进Tautology的开发体验。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-03-29","slug":"Ceph_Orchestrator_Meeting_2022-03-29","date":"2022-03-29T16:00:00.000Z","updated":"2022-03-30T16:00:00.000Z","comments":true,"path":"2022/03/30/Ceph_Orchestrator_Meeting_2022-03-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/30/Ceph_Orchestrator_Meeting_2022-03-29/","excerpt":"","text":"会议纪要 主要议题： Ceph vstart 依赖性问题 问题描述：当前vstart在启用self adm时失败，原因是无法加载self adm的依赖项。这些依赖项是运行时依赖，因此在从源代码构建Ceph并尝试启动vstart时会失败。 讨论内容：讨论了是否应将这些依赖项作为构建请求的一部分添加，但Kifu Chai指出这些依赖项并非严格意义上的构建依赖，因此不能直接添加。 解决方案：提出了一个短期解决方案，即在导入时处理异常，如果导入失败则使用模拟（mock）代替。长期解决方案需要进一步研究vstart如何处理运行时依赖。 Ceph开发工具的使用 讨论内容：讨论了开发人员通常使用的工具，如kcli和容器化方法，以及vstart的使用频率较低，导致一些问题未被及时发现。 Ceph NFS相关问题 问题描述：讨论了NFS服务的部署问题，特别是多个NFS守护进程在同一主机上的部署问题，以及NFS服务的高可用性配置。 解决方案：提出了一些改进措施，如改进端口冲突解决机制，以及考虑在Ceph的构建过程中使用Python虚拟环境。 决定事项： vstart依赖性问题：短期内将采用异常处理和模拟方法解决，长期需要找到合适的运行时依赖管理机制。 NFS部署问题：需要进一步研究和测试NFS服务的部署和运行机制，特别是高可用性和端口冲突问题。 后续行动计划： vstart依赖性问题：继续研究vstart的依赖管理，寻找更合适的解决方案。 NFS部署问题：创建跟踪票，进一步研究NFS服务的部署和运行机制，特别是高可用性和端口冲突问题。 开发工具使用：鼓励团队成员更多地使用vstart等开发工具，以便及时发现和解决问题。 其他讨论： Ceph开发工具的使用：讨论了开发人员通常使用的工具，如kcli和容器化方法，以及vstart的使用频率较低，导致一些问题未被及时发现。 Ceph NFS相关问题：讨论了NFS服务的部署问题，特别是多个NFS守护进程在同一主机上的部署问题，以及NFS服务的高可用性配置。 结论： 会议主要解决了Ceph vstart的依赖性问题和NFS服务的部署问题，并提出了相应的短期和长期解决方案。后续将继续研究和测试相关问题，确保Ceph的稳定性和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-03-22","slug":"Ceph_Orchestrator_Meeting_2022-03-22","date":"2022-03-28T16:00:00.000Z","updated":"2022-03-29T16:00:00.000Z","comments":true,"path":"2022/03/29/Ceph_Orchestrator_Meeting_2022-03-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/29/Ceph_Orchestrator_Meeting_2022-03-22/","excerpt":"","text":"会议纪要 会议主题：服务发现与高可用性（HA）讨论 参会人员：Ceph研发团队成员 会议日期：[具体日期] 会议地点：视频会议 主要议题： 服务发现（Service Discovery） 背景：讨论了在Ceph中添加新端点以支持服务发现的需求。 目标：通过HTTP从外部获取当前配置，以便在客户环境中使用。 当前状态：目前端点URL在代码中硬编码，Ernesto建议考虑服务发现层级，以便集群内部客户端更容易发现服务。 挑战：需要集群内的名称解析，目前使用IP和Ceph文件系统（CephFS），存在IP硬编码问题，特别是在管理器（Manager）切换时。 建议：考虑使用虚拟IP（VIP）或高可用性代理（HA Proxy）来简化服务发现。 Rook测试失败更新 问题描述：Rook测试套件中出现的故障问题。 解决方案：决定移除未维护的编排器（Orchestrator）命令测试，以清理测试套件。 后续行动：继续监控和更新该问题。 高可用性NFS（HA NFS） 测试结果：结合三个相关的Pull Request，NFS守护进程在节点离线后能够重新调度，但恢复时间较长（约1-2分钟）。 问题：MDS与NFS共存时，MDS未重新调度，导致客户端连接恢复时间更长。 建议：考虑添加MDS到调度列表，并优化心跳检测机制。 未来工作：探索使用代理（Agent）进行更快速的心跳检测，以及解决端口冲突问题以支持守护进程的共存。 决定事项： 继续使用当前的服务发现方法，同时考虑长期改进方案。 移除Rook测试套件中的未维护编排器命令测试。 优化NFS和MDS的高可用性配置，特别是心跳检测和重新调度机制。 后续行动计划： 继续监控和更新Rook测试失败问题。 与Jeff Leighton讨论NFS和MDS的调度策略。 探索使用代理进行更快速的心跳检测，并解决端口冲突问题。 会议结束： 会议于[具体时间]结束，下次会议预定于下周进行。 以上是本次会议的详细纪要，涵盖了服务发现、Rook测试失败和高可用性NFS的主要讨论内容、决定事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-03-24","slug":"Ceph_Performance_Meeting_2022-03-24","date":"2022-03-28T16:00:00.000Z","updated":"2022-03-29T16:00:00.000Z","comments":true,"path":"2022/03/29/Ceph_Performance_Meeting_2022-03-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/29/Ceph_Performance_Meeting_2022-03-24/","excerpt":"","text":"会议纪要 会议概要 会议主要讨论了Ceph存储系统的性能问题、PG日志优化以及相关的技术细节。与会人员包括核心开发团队成员，讨论了多个Pull Request（PR）的更新和新PR的引入。 主要议题 性能回归问题： 讨论了Gabriel的PR，该PR旨在修复No Column B代码在特定情况下默认使用位图分配器的问题。 进行了Quincy与Pacific版本的性能测试，发现长时间运行下存在显著的性能回归。 讨论了可能的解决方案，包括是否在发布前快速修复No Column B或在后续版本中重新启用。 PG日志优化： 讨论了PG日志和PG信息的优化，特别是减少对RocksDB资源的依赖。 提出了将PG日志写入缓冲区的方案，以减少写放大问题。 讨论了在不同分配器（如AVL、Bitmap、Stupid）下的性能表现，以及如何优化这些分配器的使用。 后续行动计划： 计划重新运行测试，特别是Gabriel的PR，以验证其对性能回归的修复效果。 计划进一步调查OSD和BlueStore的行为，以确定性能问题的根本原因。 计划继续讨论和优化PG日志的存储策略，以减少对RocksDB的依赖并提高性能。 决定事项 确认Gabriel的PR将进行测试，以验证其对性能回归的修复效果。 决定进一步调查和优化PG日志的存储策略，以减少对RocksDB的依赖。 确认将继续讨论和优化PG日志和PG信息的存储策略，以提高整体性能。 后续行动 重新运行性能测试，特别是Gabriel的PR。 进一步调查OSD和BlueStore的行为，以确定性能问题的根本原因。 继续讨论和优化PG日志的存储策略，以减少对RocksDB的依赖并提高性能。 结论 会议涵盖了Ceph存储系统的多个关键性能问题和优化策略，确认了后续的行动计划，并强调了继续讨论和优化PG日志存储策略的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-03-15","slug":"Ceph_Orchestrator_Meeting_2022-03-15","date":"2022-03-17T16:00:00.000Z","updated":"2022-03-17T16:00:00.000Z","comments":true,"path":"2022/03/18/Ceph_Orchestrator_Meeting_2022-03-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/18/Ceph_Orchestrator_Meeting_2022-03-15/","excerpt":"","text":"会议纪要 会议主题：防火墙管理与Ceph配置 讨论内容： - 防火墙管理：会议主要讨论了关于Ceph中防火墙管理的当前状态和未来方向。具体问题围绕一个标记（flag）是否应该被移除，该标记涉及是否在启动时进行防火墙配置。 - 历史背景：该标记和相关代码已被移除，原计划的重构未实施。目前，Ceph不再处理防火墙相关事务。 - 用户需求：讨论中提到，虽然有下游用户询问过此功能，但并未表现出强烈需求。 - 决策：会议决定不重新引入防火墙管理功能，而是选择隐藏该标记，以避免对现有脚本造成影响，并防止新用户误用。 后续行动： - 隐藏防火墙管理相关的标记，确保不破坏现有使用该标记的脚本。 - 继续监控用户对此功能的需求，根据反馈决定是否重新考虑实施防火墙管理。 会议主题：新功能开发 - 外部监控配置报告 讨论内容： - 功能需求：开发一个新功能，允许Ceph Admin (cf-admin) 报告已部署服务的不同配置，如机器颜色管理器、节点导出器、HA代理等。 - 实施计划：通过在代理中添加新的端点，利用Prometheus的新特性动态获取这些配置，而不是使用静态信息。 - 当前进展：已经开始实施，预计在完成初步开发后进行代码审查和分享。 后续行动： - 继续开发并实现新端点，确保与Prometheus的集成。 - 修改监控类以使用这些新端点动态生成配置文件。 其他讨论 代码结构问题：讨论了Ceph管理模块的代码结构问题，特别是Python和C++部分的交互。虽然目前不需要改变，但提出了未来可能需要的技术支持和资源问题。 后续行动： - 继续监控和评估代码结构，必要时寻求社区资源支持。 会议总结 本次会议主要解决了防火墙管理标记的处理问题，并讨论了新功能开发的进展和计划。 对于代码结构和未来可能的技术挑战，提出了关注和准备。 下次会议预告： - 预计在接下来的会议中继续讨论新功能的实施细节和可能遇到的技术难题。 会议结束： - 会议在确认无其他议题后结束，下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-03-17","slug":"Ceph_Performance_Meeting_2022-03-17","date":"2022-03-17T16:00:00.000Z","updated":"2022-03-18T16:00:00.000Z","comments":true,"path":"2022/03/18/Ceph_Performance_Meeting_2022-03-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/18/Ceph_Performance_Meeting_2022-03-17/","excerpt":"","text":"会议纪要 会议概要 日期与时间: 会议于早晨开始，稍有延迟。 参与者: 会议中Adam和Gabby缺席，因为他们正在休假。 议题: 讨论了Ceph存储系统的多个Pull Requests (PRs)，包括性能改进、日志优化、以及一些已关闭的PRs。 讨论的主要议题 PRs更新: Matt Benjamin的PR: 关于RGW性能改进，特别是日志处理方面，但未被合并。 Josh Solomon的PR: 关于平衡器性能的改进，已合并。 线程局部指针的使用: 用于保存分片，已合并。 性能标签的测试: 来自Chris的PR，虽关闭但相关工作仍在进行。 池移除速度的改进: Igor的工作，通过引入集合列表预取，已关闭。 性能问题讨论: Kenneth从SoftIron的更新: 讨论了Nautilus特定性能回归问题，特别是ARM架构上的性能测试和优化。 Crimson和ScienceStore的更新: 讨论了性能测试结果和潜在的优化方向。 RocksDB性能问题: 生产环境中的问题: 讨论了一个生产集群中RocksDB性能问题，特别是与RGW的桶列表相关的问题。 解决方案探讨: 讨论了可能的解决方案，包括RocksDB的TTL压缩和周期性压缩选项，以及是否需要升级RocksDB版本。 决定的事项 需要进一步研究RocksDB的TTL压缩和周期性压缩选项，以解决桶列表性能问题。 考虑是否需要升级RocksDB版本，但需谨慎测试以避免潜在的兼容性问题。 后续行动计划 继续跟踪和研究RocksDB的压缩选项。 如果必要，进行RocksDB版本的升级测试。 下周会议将讨论Gabby和Adam关于PG的提案。 其他备注 会议中提到了多个性能相关的讨论点，显示了团队对持续优化Ceph性能的承诺。 对于容器化部署的性能问题，团队表示需要进一步的研究和测试。 会议结束时，主持人感谢所有参与者的贡献，并预祝大家下周再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-03-08","slug":"Ceph_Orchestrator_Meeting_2022-03-08","date":"2022-03-07T16:00:00.000Z","updated":"2022-03-08T16:00:00.000Z","comments":true,"path":"2022/03/08/Ceph_Orchestrator_Meeting_2022-03-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/08/Ceph_Orchestrator_Meeting_2022-03-08/","excerpt":"","text":"会议纪要 会议主题：Ceph版本降级支持与NFS相关问题讨论 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： 版本降级支持讨论 问题背景：讨论了Ceph版本降级支持的历史和现状，特别是minor版本降级的可行性和存在的问题。 主要问题： 迁移处理问题：添加新迁移后，尝试降级到迁移未存在的版本时，迁移过程会无限循环。 升级状态问题：新添加的字段在旧版本中无法正确加载，导致降级失败。 讨论结果： 是否继续支持minor版本降级存在争议，建议在minor版本发布前进行测试。 提出了一些临时解决方案，如调整迁移当前值以避免无限循环。 建议在新的major版本中尝试支持降级，并考虑引入强制标志以明确风险。 升级状态字段讨论 问题背景：讨论了升级状态字段的持久性和内容，以及如何改进以更好地支持降级。 讨论结果： 建议在升级完成后保留升级状态信息，并提供清除命令。 讨论了哪些信息应该被持久化，以及如何处理升级过程中的字段重置问题。 格式标志问题 问题背景：讨论了命令行中的--format标志存在的问题，即无论指定何种格式，总是返回JSON。 讨论结果： 提出了使用装饰器来处理格式转换，并确保支持的格式类型明确。 建议进行实验性实现，并在后续会议中展示结果。 NFS相关问题 问题背景：讨论了NFS的高可用性和扩展性问题，特别是在Ceph和Rook中的实现差异。 讨论结果： 讨论了NFS demon的故障转移、主机离线检测和处理策略。 提出了NFS服务在主机故障时的处理挑战，特别是在节点数量有限的情况下。 讨论了NFS服务的配置和管理，以及如何在不同环境中保持一致性。 后续行动计划： 版本降级支持： 继续测试和评估minor版本降级的可行性。 在新的major版本中尝试实现降级支持，并引入强制标志。 升级状态字段： 实现升级状态信息的持久化，并提供清除命令。 格式标志问题： 进行实验性实现，并在后续会议中展示结果。 NFS相关问题： 继续研究和测试NFS的高可用性和扩展性解决方案。 确保NFS服务的配置和管理在不同环境中保持一致性。 会议结束： 会议于[具体时间]结束，下次会议预定于[下次会议时间]。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-03-03","slug":"Ceph_Performance_Meeting_2022-03-03","date":"2022-03-03T16:00:00.000Z","updated":"2022-03-03T16:00:00.000Z","comments":true,"path":"2022/03/04/Ceph_Performance_Meeting_2022-03-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/04/Ceph_Performance_Meeting_2022-03-03/","excerpt":"","text":"会议纪要 会议主题： Opencast 分布式存储缓存技术介绍 主讲人： Mikhail Sadinsky, 英特尔云软件架构师 会议时间： [具体时间] 会议地点： 波兰 参会人员： [参会人员名单] 会议内容总结： Opencast 概述： Opencast 是一种用于 Linux 的存储缓存软件，工作在块层。 主要功能是将慢速存储介质上的数据缓存到快速存储介质上，以加速存储操作。 支持多种缓存模式，包括写通（write-through）、写回（write-back）、只写（write-only）和直通（pass-through）。 主要特性： 缓存模式： 提供多种缓存模式以适应不同的应用场景。 清理策略： 包括基于访问时间的清理策略（LRU）和基于脏数据区域的清理策略（ICP）。 提升策略： 支持基于访问次数的数据提升策略。 选择性和优先级缓存： 允许用户根据数据的重要性和访问频率配置缓存策略。 顺序流截断： 避免大顺序流数据污染缓存。 可管理性： 提供命令行工具和配置文件支持，便于管理和监控。 架构和技术细节： Opencast 架构包括一个核心缓存框架和针对不同平台的适配器（如 Linux 内核和 SPDK）。 缓存空间组织：支持从 4K 到 64K 的缓存行大小，优化缓存利用率和性能。 数据管理：通过精细的元数据管理，减少写放大和读放大。 与 Ceph 的集成： Opencast 可以作为 Ceph 存储系统的加速层，通过创建缓存实例来优化 OSD 的性能。 支持一对一和一对多的缓存配置，根据流量分布选择合适的部署方式。 性能和优化： Opencast 通过精细的缓存管理和优化策略，相比其他缓存解决方案（如 dm-cache）在处理小请求时具有更低的读写放大。 正在进行性能基准测试，预计将提供更多详细的性能数据。 后续行动计划： - 继续进行性能基准测试，并计划在未来的会议中分享测试结果。 - 考虑分享之前的性能比较数据（与 dm-cache 的比较），待确认是否受 NDA 限制。 会议结束： - 会议在主讲人感谢与会者的参与和提问后结束，提醒大家下周再见。 备注： - 会议中提到的“Opencast for SPDK”是指将 Opencast 缓存框架集成到 SPDK 环境中。 - 对于缓存行大小的选择，建议根据典型工作负载的平均请求大小进行匹配，以优化缓存利用率和性能。 会议记录人： [记录人姓名] 会议日期： [具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-03-01","slug":"Ceph_Orchestrator_Meeting_2022-03-01","date":"2022-02-28T16:00:00.000Z","updated":"2022-03-01T16:00:00.000Z","comments":true,"path":"2022/03/01/Ceph_Orchestrator_Meeting_2022-03-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/03/01/Ceph_Orchestrator_Meeting_2022-03-01/","excerpt":"","text":"会议纪要 会议主题： 新文档项目 - Cepheidium 开发者文档 会议时间： [具体日期] 参会人员： [参会人员名单] 会议目的： 讨论并决定为 Cepheidium 创建新的开发者文档，旨在帮助开发者理解内部实现细节。 讨论内容： 文档目的和受众： 文档主要面向开发者而非用户。 内容将涵盖 Cepheidium 的实现细节，帮助开发者理解代码结构和运行机制。 文档的详细程度： 讨论了文档应保持的详细程度，避免过于复杂导致维护困难。 建议提供重要数据结构、概念、服务循环的概述以及主要功能的简要说明。 具体内容建议： 重要数据结构和概念。 服务循环的概述和主要功能。 数据在库存储的方式，如 JSON 字符串和 Monkey 存储。 管理器故障转移的持久性数据。 文档的组织和位置： 决定在现有的 Cepheidium 开发者文档中添加新内容。 讨论了是否需要重新组织文档结构，最终决定在现有结构基础上添加新内容。 后续行动计划： 开始制定文档的具体章节和内容。 鼓励团队成员根据自身专长贡献内容。 考虑使用工具自动生成部分文档，如类图等。 决定事项： - 确定文档的主要内容和结构。 - 确定文档的维护和更新策略。 后续行动： - 开始编写和整理文档内容。 - 定期更新和维护文档，确保其与代码同步。 会议结束时间： [具体时间] 下次会议预告： [具体日期] 备注： 会议中提到的具体工具和链接将在后续的文档编写中进一步明确和使用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-02-22","slug":"Ceph_Orchestrator_Meeting_2022-02-22","date":"2022-02-21T16:00:00.000Z","updated":"2022-02-22T16:00:00.000Z","comments":true,"path":"2022/02/22/Ceph_Orchestrator_Meeting_2022-02-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/22/Ceph_Orchestrator_Meeting_2022-02-22/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统中的缓存对象问题及Prometheus监控配置讨论 关键细节： 主机缓存对象问题： 当前存在主机缓存对象过大的问题，这些对象包含了主机的详细信息，如使用的磁盘等。 这些信息被存储在一个大的Python对象中，然后转换为JSON对象存储在Monkey Store中。 Monkey Store的默认最大大小为56KB，某些配置密集的主机可能会超出此限制，导致后台故障。 提出的解决方案包括： 增加Monkey Store的大小限制。 将主机缓存对象分割为多个较小的对象，特别是将设备信息单独存储，以避免单个对象过大。 考虑数据压缩，如使用gzip压缩JSON数据，以减少存储需求。 配置和密钥环存储位置： 讨论了将配置和密钥环从当前的Etsy Stuff存储位置迁移到var/lib/fsid目录下的可能性。 目的是使这些文件与集群ID更紧密地关联，便于管理和推理。 提出了在两个位置同时存储的方案，以避免复杂的迁移过程，并允许用户自定义存储位置。 Prometheus版本升级： 讨论了升级Prometheus版本的需求，特别是为了支持外部Prometheus实例的功能。 建议从当前版本升级到2.28，以利用新功能并简化配置。 支持外部Prometheus实例： 讨论了如何支持用户使用外部的Prometheus实例来监控Ceph集群。 提出的方案是在Ceph中创建一个端点，外部Prometheus实例可以通过该端点获取配置信息。 Prometheus高可用性（HA）配置： 讨论了使用RBD图像来存储Prometheus的配置和数据，以实现高可用性。 提出了多个潜在问题，包括依赖集群本身的可用性、数据写入的复杂性以及存储需求等。 决定事项： 对于主机缓存对象问题，决定探索分割缓存对象和数据压缩的解决方案。 对于配置和密钥环存储位置，决定支持在两个位置同时存储的方案。 对于Prometheus版本升级，决定进一步研究和测试新版本的可行性。 对于支持外部Prometheus实例，决定创建一个端点供外部实例获取配置信息。 对于Prometheus HA配置，决定进一步讨论和评估其可行性和潜在问题。 后续行动计划： 实施主机缓存对象分割和数据压缩的方案，并进行测试。 实现配置和密钥环在两个位置同时存储的功能。 进行Prometheus版本升级的测试和验证。 开发并测试外部Prometheus实例的端点支持。 进一步讨论和评估Prometheus HA配置的可行性，并考虑潜在的改进措施。 会议结束： 会议在讨论完所有议题后结束，无其他待讨论事项。 下次会议预定在下周进行。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-02-15","slug":"Ceph_Orchestrator_Meeting_2022-02-15","date":"2022-02-14T16:00:00.000Z","updated":"2022-02-15T16:00:00.000Z","comments":true,"path":"2022/02/15/Ceph_Orchestrator_Meeting_2022-02-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/15/Ceph_Orchestrator_Meeting_2022-02-15/","excerpt":"","text":"会议纪要 会议主题 本次会议主要讨论了关于Rook管理模块（manager rook）的相关问题，特别是在Kubernetes环境下的应用和与Ceph管理模块（cephadm）的差异。 主要议题 Rook管理模块的历史和设计初衷： Rook管理模块是在三到四年前创建的，旨在提供一个通用的接口来与不同的编排器（orchestrators）协同工作。 目前主要支持fadm和Rook，但在Kubernetes环境下，Rook的操作方式与其他平台（如cephadm）存在显著差异。 面临的挑战： Rook在Kubernetes中的操作与其他平台不同，导致一些编排器API对Rook不适用。 仪表盘（dashboard）可能需要为Kubernetes集群提供不同的用户体验。 Rook管理模块的未来： 讨论了是否应该继续投入资源到Rook管理模块，以及是否有其他更合适的方法。 特别是关于仪表盘集成的问题，以及是否应该正式支持Rook管理模块。 文档和API的调整： 建议修改Ceph文档，不再将Rook与cephadm进行直接比较，或者明确指出哪些功能对Rook不适用。 讨论了是否应该在Ceph文档中记录Rook的方法，或者直接引导用户到Rook文档。 决定事项 需要进一步讨论和明确Rook用户的需求，特别是在Kubernetes环境下的需求。 需要与仪表盘团队进行深入讨论，以确定仪表盘在Kubernetes环境下的功能和体验。 可能需要为Rook设计一个不同于编排器API的新API，以更好地适应Kubernetes环境。 后续行动计划 安排一个专门的会议，邀请仪表盘团队和Rook团队成员，以及相关的产品经理，深入讨论Rook管理模块的未来方向。 继续评估和调整文档，确保信息的准确性和实用性。 考虑长期的产品规划和用户需求，以决定Rook管理模块的最终定位和功能。 备注 会议中提到了一些具体的操作流程和技术细节，但由于涉及敏感信息，未在会议记录中详细展开。 会议强调了用户需求和体验的重要性，以及在不同部署环境（如Kubernetes和裸机）下可能需要不同的解决方案。 结论 本次会议为Rook管理模块的未来发展方向提供了初步的讨论和建议，但具体决策和实施细节需要进一步的讨论和规划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-02-07","slug":"Ceph_Orchestrator_Meeting_2022-02-07","date":"2022-02-11T16:00:00.000Z","updated":"2022-02-11T16:00:00.000Z","comments":true,"path":"2022/02/12/Ceph_Orchestrator_Meeting_2022-02-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/12/Ceph_Orchestrator_Meeting_2022-02-07/","excerpt":"","text":"会议纪要 会议主题：Ceph 升级相关问题讨论 参会人员：Ceph 研发团队成员 主要议题： 升级过程中的OSD依赖问题 升级过程的粒度控制 讨论内容： 1. OSD依赖问题 问题描述：在升级过程中，OSD依赖于CRUSH map，导致在升级监控器后所有OSD需要重新配置，这在大型集群中（如3900个OSD）会显著减慢升级速度，并影响用户体验。 解决方案：考虑延迟OSD的重新配置直到升级完成，以减少不必要的重新配置时间。 潜在风险：需要评估延迟重新配置可能带来的风险，并确保在升级过程中不会对集群稳定性造成影响。 2. 升级过程的粒度控制 问题描述：大型集群的用户可能希望更细粒度地控制升级过程，例如按主机或按守护进程类型进行升级，以便更好地管理升级过程和减少潜在的风险。 解决方案：考虑实现按主机或按守护进程类型的升级选项，同时确保升级顺序的正确性，特别是管理器和监控器必须在其他守护进程之前升级。 用户界面：改进升级状态显示，提供更详细的升级进度信息，包括预计升级的守护进程数量和类型。 决定事项： OSD依赖问题：将探索延迟OSD重新配置的可行性，并评估其潜在风险。 升级粒度控制：将实现按主机和按守护进程类型的升级选项，并确保升级顺序的正确性。 后续行动计划： 技术调研：进一步研究延迟OSD重新配置的技术细节和潜在风险。 功能开发：开发按主机和按守护进程类型的升级选项，并确保升级顺序的正确性。 用户界面改进：改进升级状态显示，提供更详细的升级进度信息。 其他讨论点： 升级过程中的离线主机处理：讨论了在升级过程中如何处理离线主机的问题。 升级状态显示：讨论了如何改进升级状态显示，以便用户更好地了解升级进度。 会议结束： 确认了下一步的行动计划，并安排了下次会议的时间。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2022-02-02","slug":"Ceph_Developer_Monthly_2022-02-02","date":"2022-02-02T16:00:00.000Z","updated":"2022-02-03T16:00:00.000Z","comments":true,"path":"2022/02/03/Ceph_Developer_Monthly_2022-02-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/03/Ceph_Developer_Monthly_2022-02-02/","excerpt":"","text":"会议纪要 会议主题 本次会议主要讨论了Ceph管理器（Manager）和指标收集的扩展性问题，以及如何改进这一过程。 主要议题 指标收集的扩展性问题： Paul在进行扩展性测试时发现，Ceph管理器在处理大量指标时存在性能瓶颈。 目前，Ceph管理器每秒需要处理约50MB的数据，这对于大型集群来说是一个显著的瓶颈。 改进方案讨论： 短期解决方案： 减少需要导出的指标数量，仅导出在Grafana和InfluxDB管理器中实际使用的指标。 长期解决方案： 将指标导出功能从Ceph管理器中分离出来，可能通过每个节点或每个守护进程（demon）的独立导出器来实现。 讨论了将指标直接从收集点发送到Prometheus，绕过Ceph管理器的可行性。 提出了在每个节点部署一个独立的导出器（sidecar exporter）来避免在每个服务中嵌入导出逻辑。 技术细节和挑战： 讨论了如何在不同节点和服务之间设置通信，以及如何确保Prometheus能够发现这些导出器。 提到了使用SQLite作为中间存储，让Prometheus直接从SQLite数据库中抓取数据的可能性。 讨论了Python处理大量数据时的性能问题，以及是否可以通过将更多逻辑移至C++来优化性能。 后续行动计划： 继续进行原型设计和实验，探索不同的架构方案，如每个守护进程的独立导出器或每个节点的导出器。 研究如何优化现有的Prometheus模块，减少数据处理量。 考虑如何支持更细粒度的指标，以满足镜像和复制等新用例的需求。 决定事项 确认了需要将指标收集功能从Ceph管理器中分离出来，以提高系统的扩展性和性能。 同意继续进行原型设计和实验，以确定最佳的长期解决方案。 后续行动 继续进行原型设计和实验，探索不同的架构方案。 研究如何优化现有的Prometheus模块，减少数据处理量。 考虑如何支持更细粒度的指标，以满足镜像和复制等新用例的需求。 备注 会议中提到了一些技术细节和挑战，需要在后续的实验和设计中进一步探讨和解决。 需要定期回顾和评估实验结果，以确保解决方案的有效性和可行性。 本次会议记录涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，旨在为Ceph存储系统的优化和扩展提供清晰的指导和方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-02-03","slug":"Ceph_Performance_Meeting_2022-02-03","date":"2022-02-02T16:00:00.000Z","updated":"2022-02-03T16:00:00.000Z","comments":true,"path":"2022/02/03/Ceph_Performance_Meeting_2022-02-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/03/Ceph_Performance_Meeting_2022-02-03/","excerpt":"","text":"会议纪要 关键细节 PR活动: 本周没有新的或关闭的PR，但有一个关于默认编译跟踪的PR被更新，RBD团队正在审查。 性能回归: 一个可能导致性能回归的PR与跟踪功能相关，需要密切关注即使禁用时可能引起的性能影响。 Quincy工作: 由于大家专注于Quincy，本周PR活动较少。 讨论的主要议题 性能优化: 讨论了如何通过调整配置和优化代码来减少内存使用和提高性能。 MClock配置文件: 讨论了MClock的不同配置文件（高客户端IO、高恢复操作、平衡）及其对不同操作（如恢复和 scrubbing）的影响。 Ceph性能测试: 讨论了在大型集群上使用CBT进行性能测试的计划，特别是关于MClock和scrubbing的测试。 决定的事项 Ceph性能测试: 决定在Giba集群上运行CBT以测试MClock配置文件和scrubbing性能。 内存优化: 决定进一步研究内存使用情况，特别是通过调整tc_malloc线程缓存和优化内存分配策略。 后续行动计划 Ceph性能测试: Mark将设置Giba集群以便进行CBT测试，Ashwarya和Sridhar将使用此集群进行MClock和scrubbing的性能测试。 内存优化: 继续研究并优化内存使用，特别是通过改进内存分配和减少碎片化。 性能回归跟踪: 继续监控和分析可能导致性能回归的PR，确保即使禁用跟踪功能也不会对性能产生负面影响。 本次会议涵盖了Ceph存储系统的多个关键性能和优化议题，明确了后续的测试和优化方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-02-01","slug":"Ceph_Orchestrator_Meeting_2022-02-01","date":"2022-02-01T16:00:00.000Z","updated":"2022-02-01T16:00:00.000Z","comments":true,"path":"2022/02/02/Ceph_Orchestrator_Meeting_2022-02-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/02/Ceph_Orchestrator_Meeting_2022-02-01/","excerpt":"","text":"会议纪要 关键细节 日期: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 讨论的主要议题 文档更新 讨论了在文档中明确提及和记录每个功能的引入时间、版本和贡献者的重要性。 决定开始在新的功能引入时添加文档注释，以便追踪功能的历史和来源。 NFS Manager模块的使用 讨论了如何在不启用Orchestration模块的情况下使用NFS Manager模块。 确定了Rook团队的需求，即他们希望在不依赖Orchestration模块的情况下管理NFS导出。 提出了两种解决方案：添加新的命令（如nfs cluster register和unregister）或使用现有的命令但添加一个选项（如--no-orchestration）。 最终决定简化流程，仅移除导出命令对Orchestration模块的依赖，并处理集群ID验证。 自然排序问题 讨论了在某些命令中使用自然排序（如ceph osd tree）以提高用户体验。 决定在所有相关命令中一致地使用自然排序，以保持命令输出的一致性。 考虑引入外部Python包natsort来实现自然排序。 决定的事项 将在新功能引入时添加文档注释。 简化NFS Manager模块的使用流程，移除对Orchestration模块的依赖。 在所有相关命令中一致地使用自然排序，并考虑引入natsort包。 后续的行动计划 完成NFS Manager模块的代码调整，预计本周内提交PR。 引入natsort包并实现自然排序，为相关命令创建单独的PR和问题跟踪。 确认CentOS容器问题的修复情况。 其他事项 确认CentOS容器问题的修复情况，目前问题已解决。 下次会议 下次会议预定于[具体日期]举行。 注意: 本次会议记录涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的准确性和完整性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-01-27","slug":"Ceph_Performance_Meeting_2022-01-27","date":"2022-02-01T16:00:00.000Z","updated":"2022-02-02T16:00:00.000Z","comments":true,"path":"2022/02/02/Ceph_Performance_Meeting_2022-01-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/02/Ceph_Performance_Meeting_2022-01-27/","excerpt":"","text":"会议纪要 关键细节 Ceph性能前线：本周相较于前几周较为平静，PR（Pull Request）活动在性能方面有所减少。 Ronin的PR：涉及scrub功能的PR，主要改变了一些chunking操作，以优化scrub过程中的chunk大小。 Scrub Chunk Size：讨论了scrub过程中chunk大小的配置参数，建议区分deep scrub和regular scrub的chunk大小，以减少对常规客户端请求的延迟影响。 Tracing功能：讨论了将tracing功能默认编译进Ceph的PR，尽管有轻微的性能开销，但可以方便用户在遇到问题时启用tracing。 RocksDB的TTL和Compaction：讨论了RocksDB中的TTL（Time to Live）和compaction设置，特别是在大量插入和删除操作下的性能问题，建议通过调整TTL来定期清理tombstones，以避免性能退化。 讨论的主要议题 Scrub性能优化：如何通过调整scrub的chunk大小来优化性能，同时不影响客户端请求。 Tracing功能的集成：讨论了将tracing功能默认编译进Ceph的利弊，以及如何平衡性能开销和调试便利性。 RocksDB的性能问题：深入讨论了RocksDB在处理大量数据插入和删除时的性能问题，特别是tombstones导致的性能退化，提出了通过TTL来定期清理tombstones的解决方案。 决定的事项 Scrub Chunk Size调整：决定区分deep scrub和regular scrub的chunk大小，并进行进一步测试以确保不会引入新的延迟问题。 Tracing功能默认编译：尽管存在轻微性能开销，但决定将tracing功能默认编译进Ceph，以便用户在需要时启用。 RocksDB的TTL设置：决定尝试通过调整TTL来定期清理tombstones，以解决性能退化问题，并进行进一步的测试和验证。 后续的行动计划 Scrub Chunk Size测试：进行进一步的测试，确保调整后的chunk大小不会影响客户端请求的性能。 Tracing功能评估：评估tracing功能默认编译后的性能影响，并考虑是否需要进一步优化。 RocksDB的TTL和Compaction测试：在实际生产环境中测试调整TTL后的性能表现，并监控其对系统的影响。 与Spdb合作：考虑与Spdb合作，评估其RocksDB替代方案在Ceph中的性能表现，特别是在处理大量数据插入和删除时的性能优化。 其他事项 性能测试和优化：继续关注和优化Ceph在不同硬件配置下的性能表现，特别是在AMD和Intel节点上的性能对比。 生产环境验证：在实际生产环境中验证各项优化措施的效果，并根据反馈进行调整。 本次会议涵盖了Ceph性能优化的多个方面，从scrub性能到tracing功能的集成，再到RocksDB的性能问题，都进行了深入的讨论和决策。后续将通过一系列的测试和验证，确保各项优化措施能够有效提升Ceph的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-01-25","slug":"Ceph_Orchestrator_Meeting_2022-01-25","date":"2022-01-31T16:00:00.000Z","updated":"2022-02-01T16:00:00.000Z","comments":true,"path":"2022/02/01/Ceph_Orchestrator_Meeting_2022-01-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/01/Ceph_Orchestrator_Meeting_2022-01-25/","excerpt":"","text":"会议纪要 关键细节 议题一：SSH命令超时问题 讨论了在管理模块中，如果SSH命令（如set volume命令）挂起，整个服务器循环会永久挂起的问题。 提出了引入超时机制的必要性，但存在设置全局超时的困难，因为不同命令需要不同的超时时间。 讨论了使用异步SSH库的超时选项，以及cephadm内置的超时参数。 决定尝试使用cephadm的超时参数，并设置一个较高的默认超时时间，同时提供配置选项。 议题二：离线主机检测 讨论了如何检测离线主机，特别是在有代理的情况下，可以通过发送快速消息来确认主机是否在线。 如果代理响应失败，将尝试重置连接并进行常规的主机检查。 决定事项 超时机制实施 使用cephadm的超时参数，设置一个默认的高超时时间（如20分钟），并在超时后发出健康警告。 提供配置选项，以便用户可以根据需要调整超时时间。 离线主机检测 在有代理的情况下，通过发送消息来快速检测主机是否在线。 如果代理响应失败，将重置连接并进行常规的主机检查。 后续行动计划 实施超时机制 测试cephadm的超时参数是否有效，并确保在超时后能发出健康警告。 提供文档和健康警告信息，指导用户如何调整超时时间。 优化离线主机检测 在有代理的情况下，实现通过发送消息来快速检测主机是否在线的机制。 考虑在未来的版本中进一步优化代理的功能，以减少对SSH的依赖。 文档和跟踪 更新相关文档，说明新的超时机制和离线主机检测方法。 在跟踪系统中记录这些改进，以便后续跟踪和维护。 其他讨论 代理功能扩展 讨论了代理功能的扩展，以便未来能够完全替代SSH，特别是在部署和管理节点方面。 提出了创建一个大型跟踪器，列出代理需要实现的所有功能，以实现与SSH的完全功能对等。 告别 Sebastian宣布这是他最后一次参加会议，感谢团队并祝愿大家成功。 结论 会议讨论了超时问题和离线主机检测的解决方案，并决定实施cephadm的超时参数和代理的快速检测机制。同时，提出了未来代理功能扩展的计划，并记录了相关行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2022-01-26","slug":"Ceph_Science_Working_Group_2022-01-26","date":"2022-01-31T16:00:00.000Z","updated":"2022-02-01T16:00:00.000Z","comments":true,"path":"2022/02/01/Ceph_Science_Working_Group_2022-01-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/02/01/Ceph_Science_Working_Group_2022-01-26/","excerpt":"","text":"会议纪要 会议主题： 科学计算与大型集群中的Ceph技术讨论会 日期： [具体日期] 主持人： Kevin 会议概述 本次会议是一个开放式讨论会，旨在为科学计算或大型集群领域的工作人员提供一个交流平台，讨论Ceph相关的话题、问题和经验分享。会议每两个月举行一次，形式为“鸟类同群”风格。 主要议题与讨论 新成员介绍 Kasper Shark, GWDG: 介绍了GWDG作为德国中部数据中心，为马克斯·普朗克学会和哥廷根大学提供数据管理服务、存储服务和其他云服务。GWDG已使用Ceph约六七年，目前管理着五个集群，总存储容量约为7PB，并计划在四月新增18PB的冷存储和1.4PB的NVMe存储。 Andres Pataki, Flatiron Institute: 介绍了Flatiron Institute作为西蒙斯基金会的非营利科学研究组织，拥有约200名科学家，使用Ceph进行大规模存储，每个集群约30PB。 Ceph使用经验分享 GWDG: 分享了他们在使用Ceph过程中遇到的一些问题，如集群网络故障等，并表示总体上对Ceph非常满意，正在进一步投资扩大集群规模。 Flatiron Institute: 讨论了他们在使用Ceph时遇到的元数据问题，特别是大量小文件和随机访问文件的问题。 技术问题与解决方案 BlueStore Corruption Issue: 讨论了在重启OSDs时遇到的BlueStore corruption问题，可能与硬盘的写缓存设置有关。 Multi-site Clusters: 探讨了使用单一领域连接多个集群的挑战和潜在的bug。 Support Providers: 讨论了是否使用外部专业支持服务，如Canonical, SoftIron等，以及这些服务的成本效益。 Ceph升级与维护 CERN的Ceph升级: 分享了CERN在升级Ceph时采用的新方法，减少了系统停机时间。 Snapshot Issues: 讨论了启用快照功能后遇到的性能问题，特别是在处理大量元数据时。 未来计划与建议 Cephalocon 2023: 提及了即将举行的Cephalocon会议，鼓励成员参与。 会议时间调整: 讨论了可能将会议时间调整到周一或周二的可能性。 后续行动计划 技术问题跟进: 继续关注和解决BlueStore corruption问题，以及快照功能带来的性能问题。 会议时间调整: 根据成员反馈调整会议时间，以避免与其他重要会议冲突。 Cephalocon参与: 鼓励成员参与即将举行的Cephalocon会议，并考虑是否组织相关的Birds of a Feather活动。 下次会议预告： 由于Cephalocon会议临近，下一次会议可能会在三月后举行。具体日期和形式将根据成员反馈和实际情况确定。 会议结束： 感谢所有参与者的积极参与和贡献，期待下次会议再见。 备注： 本次会议记录由专业的Ceph研发人员和视频会议字幕总结人员共同完成，旨在提供准确、全面的会议纪要。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-01-20","slug":"Ceph_Performance_Meeting_2022-01-20","date":"2022-01-19T16:00:00.000Z","updated":"2022-01-20T16:00:00.000Z","comments":true,"path":"2022/01/20/Ceph_Performance_Meeting_2022-01-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/01/20/Ceph_Performance_Meeting_2022-01-20/","excerpt":"","text":"会议纪要 关键细节 Ceph Quincy 版本准备：团队正在为 Quincy 版本的发布做准备，重点是完成各项任务和修复 bug。 合并的修复： 解决了 RGW（RADOS Gateway）的 bucket loading 统计问题。 优化了 shared blob fsck 的内存使用，使其更加高效。 PR 更新： 简化了 pinning logic 和 blue store cache 的 PR 更新。 针对 FreeBSD 的 huge page based read buffers 问题进行了修复，等待测试反馈。 优化 PG（Placement Group）移除的 PR 更新。 性能测试： 正在进行 Quincy 版本的性能测试，主要集中在 Pacific 版本的测试上。 决定跳过 iSCSI 测试，因为其重要性不高。 讨论了是否继续在大规模测试中收集性能指标，初步决定可能禁用部分测试的性能指标收集。 讨论的主要议题 性能测试策略：讨论了是否在大规模测试中继续收集性能指标，以及如何进行恢复测试。 iSCSI 测试的重要性：决定暂时跳过 iSCSI 测试，因为其对当前版本的影响不大。 恢复测试方法：计划使用 fio 进行恢复测试，观察集群在 OSD 故障和恢复后的行为。 决定的事项 跳过 iSCSI 测试。 可能在大规模测试中禁用部分性能指标的收集。 使用 fio 进行恢复测试，观察集群在 OSD 故障和恢复后的行为。 后续的行动计划 继续进行 Quincy 版本的性能测试，重点关注 Pacific 版本的测试结果。 完成 fio 恢复测试，观察集群在不同负载下的恢复行为。 如果有任何性能测试需要核心团队参与，应及时通知并讨论。 其他事项 提到了正在进行的大规模测试，使用了一个包含 975 个 OSD 的集群，以覆盖更多的测试场景。 鼓励团队成员如果有任何测试需求或问题，及时与核心团队沟通。 结论 会议主要围绕 Quincy 版本的准备工作和性能测试进行讨论，团队成员正在努力确保版本的稳定性和性能。会议结束时，鼓励大家继续专注于任务，并保持沟通，确保所有问题和需求得到及时处理。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-01-18","slug":"Ceph_Orchestrator_Meeting_2022-01-18","date":"2022-01-17T16:00:00.000Z","updated":"2022-01-18T16:00:00.000Z","comments":true,"path":"2022/01/18/Ceph_Orchestrator_Meeting_2022-01-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/01/18/Ceph_Orchestrator_Meeting_2022-01-18/","excerpt":"","text":"会议纪要 关键细节 Quincy 版本发布: Quincy 版本即将发布，但并非迫在眉睫。团队需要确保对 Quincy 的回溯（backporting）工作得到妥善处理，特别是对于每个 bug 修复和功能更新。 回溯策略: 会议讨论了回溯工作的策略，建议采用批量回溯（batch backports）以减少额外工作量和冲突。团队成员普遍支持这一策略。 Pacific 版本的回溯: 针对 Pacific 版本的回溯工作仍在进行中，特别是需要将 agent 回溯到 Pacific。团队需要尽快解决剩余的两个问题，并加速完成回溯工作。 Surf Loop 中的竞争条件: 讨论了 Surf Loop 中存在的竞争条件，特别是在不同线程中修改数据结构时可能引发的问题。团队成员 Mike 提出了一些初步的调查结果和可能的解决方案。 Agent 和数据一致性: 讨论了如何通过 agent 和 metadata up-to-date flag 来解决数据一致性问题，特别是在处理同步操作时。 线程和超时问题: 讨论了线程管理和超时问题，特别是在执行 SSH 命令时可能出现的挂起问题。提出了引入超时机制和健康警告的建议。 团队变动: Sebastian 宣布他将在一月底离开 Red Hat，这将是他参与的倒数第二次会议。 决定事项 回溯策略: 决定采用批量回溯策略，避免单独回溯带来的额外工作量和冲突。 Pacific 版本的回溯: 确认需要尽快解决剩余的两个问题，并加速完成对 Pacific 版本的回溯工作。 Surf Loop 中的竞争条件: 需要进一步调查和解决 Surf Loop 中的竞争条件，特别是在不同线程中修改数据结构时可能引发的问题。 Agent 和数据一致性: 确认通过 agent 和 metadata up-to-date flag 来解决数据一致性问题，特别是在处理同步操作时。 线程和超时问题: 确认引入超时机制和健康警告，以解决执行 SSH 命令时可能出现的挂起问题。 后续行动计划 Quincy 版本的回溯: 确保对 Quincy 的回溯工作得到妥善处理，特别是对于每个 bug 修复和功能更新。 Pacific 版本的回溯: 尽快解决剩余的两个问题，并加速完成对 Pacific 版本的回溯工作。 Surf Loop 中的竞争条件: 进一步调查和解决 Surf Loop 中的竞争条件，特别是在不同线程中修改数据结构时可能引发的问题。 Agent 和数据一致性: 实施通过 agent 和 metadata up-to-date flag 来解决数据一致性问题的方案。 线程和超时问题: 引入超时机制和健康警告，以解决执行 SSH 命令时可能出现的挂起问题。 团队变动: 确认 Adam 将接手 Orchestrator 每周会议的主持工作。 其他事项 Docker 镜像缓存: 讨论了 Docker 镜像缓存的问题，特别是关于 upstream CI 的镜像缓存和 OpenStack 团队的需求。 会议结束 会议在确认了各项议题的后续行动计划后结束，团队成员预祝大家有一个愉快的周末。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-01-13","slug":"Ceph_Performance_Meeting_2022-01-13","date":"2022-01-16T16:00:00.000Z","updated":"2022-01-17T16:00:00.000Z","comments":true,"path":"2022/01/17/Ceph_Performance_Meeting_2022-01-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/01/17/Ceph_Performance_Meeting_2022-01-13/","excerpt":"","text":"会议纪要 主要议题与讨论内容 PR更新与合并情况 RGW Zipper PR: 这是一个Bug修复PR，解决了在某些Age Bidding测试中RGW和Master运行非常慢的问题。原因是由于一个较旧的PR，虽然主要是外观上的改变，但影响了RGW中每个桶加载时的统计数据加载，导致性能下降。修复后，性能恢复到之前的水平。 TTL Cache Implementation PR: 该PR已合并，未见进一步讨论，主要需要通过一些测试。 Primary Balance PR: 由Josh Solomon提交，主要包含代码重构，简化了计算PG Up Maps的代码。原PR中的文档部分被移至另一个PR，将在Quincy分支后合并。 Fine Grain Locking PR: 由Adam提交，经过长时间讨论和测试后终于合并。初步测试显示有性能优势，但需要更多详细的Quincy测试来验证。 Age Binning PR: 这是一个多年未解决的PR，最终合并。虽然初步测试未显示显著性能提升，但在某些测试中显示了小幅改进，主要好处是提供了更细粒度的缓存控制和更好的缓存项年龄信息。 其他PR更新 Onode Binning Shardstrimming PR: 由Igor提交，涉及Onode的Binning和Shardstrimming处理，以及Adam关于Onode引用计数器和固定的PR，这两个PR因过时被关闭。 Auto Tuning of MDS Cache Memory PR: 基于RSS使用的自动调整MDS缓存内存的PR，因长时间未更新被关闭。讨论中提到可能使用优先级缓存来解决RSS内存使用的问题。 性能测试计划 讨论了即将到来的Quincy版本的性能测试计划，包括使用Mako进行大规模集群测试，涉及RBD、RGW、iSCSI、NBD等不同工作负载和设备。 特别提到了恢复测试的改进，由Sridhar提交的新恢复测试方法，创建了两个独立的池和图像，以更好地模拟实际恢复过程。 决定事项 确认了Quincy版本的性能测试计划，包括使用Mako进行大规模集群测试，涉及多种工作负载和设备。 关闭了多个过时的PR，确保项目向前推进。 后续行动计划 继续进行Quincy版本的性能测试，特别是关注恢复测试的新方法。 确保所有关键PR得到适当的审查和测试，以准备Quincy版本的发布。 参会人员 会议由主持人主持，参会人员包括开发团队成员和其他相关人员。 备注 会议中提到的具体PR编号和详细技术讨论未在此纪要中列出，具体内容可参考会议录音或相关代码仓库。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-01-04","slug":"Ceph_Orchestrator_Meeting_2022-01-04","date":"2022-01-10T16:00:00.000Z","updated":"2022-01-11T16:00:00.000Z","comments":true,"path":"2022/01/11/Ceph_Orchestrator_Meeting_2022-01-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/01/11/Ceph_Orchestrator_Meeting_2022-01-04/","excerpt":"","text":"会议纪要 会议概览 日期: 2022年新年后的某个星期 参与者: 未明确列出，但包括Ceph开发人员和相关领域的专家 目的: 讨论和决定关于Ceph服务CPU限制的实现方式，以及处理NFS服务和OSD内存目标的相关问题。 主要议题 CPU限制的实现 问题背景: 去年末提出的功能请求，希望为每个服务实现CPU限制。 讨论焦点: 是否应全局设置CPU限制，还是针对每个服务设置。 如何实现这一功能，特别是是否允许通过容器参数进行灵活设置。 决策: 决定不采用全局CPU限制，而是针对每个服务设置。 选择实现方式为在服务规范中引入简单的CPU和内存限制属性。 NFS服务测试 问题: 如何确保NFS服务在节点离线时能够正确切换。 讨论: 提出通过模拟连接失败来测试NFS服务的故障转移能力。 决策: 确认这一方法可行，并计划在功能完善后实施。 OSD内存目标设置 问题: 默认的OSD内存自动调整设置可能不适用于超融合基础设施（HCI）环境。 讨论: 讨论了是否应默认启用OSD内存自动调整，以及如何处理HCI环境的特殊需求。 决策: 决定默认启用OSD内存自动调整，但会在文档中明确指出HCI环境可能需要调整设置。 后续行动计划 CPU限制实现: 开发团队将根据会议决定，在服务规范中引入CPU和内存限制属性，并进行相应的实现和测试。 NFS服务测试: 开发团队将实施模拟连接失败的测试方法，确保NFS服务的故障转移功能正常工作。 OSD内存目标设置: 更新文档，明确指出HCI环境可能需要调整OSD内存自动调整设置，并提供参考文档和示例。 其他事项 会议中还讨论了其他可能的技术细节和实现问题，但主要决策和行动计划如上所述。 结束语 会议在积极的氛围中结束，参与者对即将到来的2022年充满期待，并承诺将继续努力推动Ceph项目的发展。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2022-01-11","slug":"Ceph_Orchestrator_Meeting_2022-01-11","date":"2022-01-10T16:00:00.000Z","updated":"2022-01-11T16:00:00.000Z","comments":true,"path":"2022/01/11/Ceph_Orchestrator_Meeting_2022-01-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/01/11/Ceph_Orchestrator_Meeting_2022-01-11/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 会议 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： Quincy 版本特性冻结 讨论了 Quincy 版本的特性冻结时间，原计划是本周结束，但具体时间取决于其他组件如 RBG 和 FFS 是否能按时完成。 需要完成的任务包括对 self-adm 二进制文件的重构，这需要在 Quincy 发布前完成。 Quincy 版本的其他待办事项 讨论了 agent 和特定的 pull request 是否需要合并以满足特性冻结。 强调了文件权限问题和主机缓存大小问题的重要性。 Rook Manager Module 的测试和使用 讨论了 Rook Manager Module 在 Quincy 版本中的测试情况，目前仅在 CI 中测试。 该模块对于 multi-site 配置非常重要，但不会包含在 Quincy 的初始版本中。 Quincy 版本的后续行动计划 确认了从兼容性和稳定性角度出发，所有新特性都可以在未来的版本中轻松回溯。 讨论了不同 Rook 版本的兼容性问题，确认 Rook 的接口是向后兼容的。 ISCSI 的回归问题 讨论了 ISCSI 的回归问题，目前尚未解决，需要进一步调查。 Backporting 问题 讨论了 backporting 的复杂性，特别是由于 Pacific 和 Quincy 版本之间的差异，导致需要单独处理每个 pull request 的 backporting。 确认了一些具体的 pull request 需要进行 backporting，并讨论了分配任务的可能性。 决定事项： 确认了 Quincy 版本的特性冻结时间将取决于其他组件的完成情况。 确认了 self-adm 二进制文件的重构需要在 Quincy 发布前完成。 确认了 Rook Manager Module 的重要性，但不会包含在 Quincy 的初始版本中。 确认了 ISCSI 的回归问题需要进一步调查。 确认了 backporting 的复杂性，并讨论了分配任务的可能性。 后续行动计划： 继续监控其他组件的进度，以确定 Quincy 版本的特性冻结时间。 完成 self-adm 二进制文件的重构工作。 继续测试和验证 Rook Manager Module 的功能。 调查并解决 ISCSI 的回归问题。 分配并完成 backporting 任务。 会议结束： 会议在确认无其他议题后结束，感谢所有参会人员，并约定下周再次开会。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2022-01-06","slug":"Ceph_Performance_Meeting_2022-01-06","date":"2022-01-10T16:00:00.000Z","updated":"2022-01-11T16:00:00.000Z","comments":true,"path":"2022/01/11/Ceph_Performance_Meeting_2022-01-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2022/01/11/Ceph_Performance_Meeting_2022-01-06/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph项目的多个Pull Request (PR)，包括新提交的PR、已关闭的PR以及正在进行中的PR。会议还涉及了一些技术讨论和后续行动计划。 主要议题 新提交的PR PR 4479：使用线程局部指针变量保存shard。目前尚未有详细审查，但Ronan已开始进行初步评论。 PR 4466：重写硬件文档。Dan已批准，但会议中提出了关于文档中关于核心需求的建议，建议更细致地说明在NVMe驱动器上可能需要更多核心以提高性能。 已关闭的PR Igor的PR，主要清理onode代码中的pinning。该PR已由Yuri合并，被认为是良好的清理工作。 一个关于优化对象内存分配的PR，基于收到的反馈，作者决定关闭该PR。 正在进行中的PR 管理器TTL缓存的实现更新。 Josh的主要平衡器工作，正在进行中，计划通过tautology进行测试。 Igor的PR，旨在减少shared blob FSDK的RAM使用。Adam进行了大量审查，会议中讨论了如何更好地控制内存使用。 其他讨论 关于omap benchmark的讨论，提出了是否需要重写以更好地适应现有OSD环境。 Casey汇报了rgw性能相关的PR进展，特别是关于beast前端的变化。 Gabby汇报了关于分配器更改的修复工作进展。 决定事项 对于新提交的PR，鼓励团队成员进行审查。 对于硬件文档的更新，建议更细致地说明核心需求。 对于omap benchmark，建议在下次会议中进一步讨论。 后续行动计划 继续审查和更新PR，确保代码质量和性能优化。 安排下一次会议，讨论omap benchmark和可能的技术改进。 关注并评估新提交的PR，特别是那些可能影响性能和稳定性的PR。 其他备注 会议中提到的一些技术讨论需要Adam和Igor的参与，因此相关议题将推迟到他们参与的下次会议。 会议还提到了一些性能优化和内存管理的潜在改进，这些将在后续的开发和测试中进一步探索。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并期待下周的会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-12-23","slug":"Ceph_Performance_Meeting_2021-12-23","date":"2021-12-23T16:00:00.000Z","updated":"2021-12-23T16:00:00.000Z","comments":true,"path":"2021/12/24/Ceph_Performance_Meeting_2021-12-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/24/Ceph_Performance_Meeting_2021-12-23/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph存储系统中的一些关键问题和改进措施，涉及性能优化、代码重构、内存管理等多个方面。会议由Mark主持，参与人员包括Adam、Igor、Laura等。 主要议题 Pinning逻辑的改进： Adam和Igor提出了新的改进方案，涉及BlueStore中的pinning逻辑，特别是针对O_NOCACHE的操作。 这些改进可能会影响性能，但有助于减少对tracker box的依赖，提高系统的稳定性。 BlueStore日志的增量更新模式： Adam介绍了BlueStore日志的增量更新模式，该模式已经通过严格的测试，目前正在进一步的审查中。 TTL缓存实现和Primary Balancer PR： Laura和Joshua正在合作进行Primary Balancer PR的代码重构，目的是使代码更加模块化和易于维护。 该PR的主要目标是保持Balancer的功能不变，同时提高代码的可读性和可维护性。 内存使用和性能优化： 讨论了BlueStore中的一些内存使用问题，特别是关于blob fsck的内存消耗。 Igor提出了一个内存减少的PR，旨在优化BlueStore的内存使用，减少对系统资源的消耗。 EC2设备性能问题： 讨论了在Amazon EC2上运行Ceph时遇到的一些性能问题，特别是关于IOPS的保证和实际性能之间的差异。 提出了一些可能的解决方案，包括增加IO合并和调整BlueStore的并发IO设置。 决定事项 Pinning逻辑的改进： 同意继续推进Adam和Igor的改进方案，并对其进行进一步的测试和审查。 BlueStore日志的增量更新模式： 确认该模式已经通过测试，将继续进行代码审查和优化。 Primary Balancer PR： 同意Laura和Joshua继续合作进行代码重构，并确保重构后的代码功能不变。 内存使用优化： 同意Igor的内存减少PR，并计划在满足内存边界的前提下进行合并。 EC2性能问题： 计划进一步研究和测试，以确定是否需要调整BlueStore的并发IO设置。 后续行动计划 Pinning逻辑的改进： 继续进行代码审查和测试，确保改进方案的有效性。 BlueStore日志的增量更新模式： 完成代码审查，并进行必要的优化。 Primary Balancer PR： 继续进行代码重构，并确保重构后的代码功能不变。 内存使用优化： 完成Igor的内存减少PR的审查，并进行合并。 EC2性能问题： 进行进一步的测试和研究，以确定是否需要调整BlueStore的并发IO设置。 其他讨论 讨论了Ceph在不同硬件配置下的性能表现，特别是关于内存限制和硬件成本的权衡。 讨论了Ceph在不同环境下的部署策略，包括使用SSD和HDD的混合部署。 会议结束 会议在讨论了所有议题后结束，Mark祝愿大家新年快乐，并期待在新的一年中继续合作。 以上是本次会议的详细纪要，涵盖了会议的主要内容、讨论的议题、决定的事项以及后续的行动计划。希望这份纪要能帮助大家更好地理解和跟进会议的成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: Ceph Manager","slug":"Ceph_Code_Walkthroughs_-_Ceph_Manager","date":"2021-12-13T16:00:00.000Z","updated":"2021-12-13T16:00:00.000Z","comments":true,"path":"2021/12/14/Ceph_Code_Walkthroughs_-_Ceph_Manager/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/14/Ceph_Code_Walkthroughs_-_Ceph_Manager/","excerpt":"","text":"会议纪要 会议主题：Ceph Manager 架构与功能概述 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： Ceph Manager 的创建背景与目的 Ceph Manager 最初是为了减轻 Ceph Monitor 的负担而创建的，特别是在大型集群中，Monitor 需要处理大量的统计数据收集任务，这些任务原本由 OSD 和 MDS 等守护进程处理。 Manager 被设计为一个无状态的服务，不需要通过 Paxos 协议或持久化到磁盘，可以独立运行，并能根据需要将信息持久化到 Monitor 或 Rados 中。 Manager 的核心组件与技术栈 Manager 主要使用 C++ 和 Python 编写，核心组件类似于其他 Ceph 守护进程，使用相同的网络通信基础设施。 Manager 作为一个选择客户端连接到 Monitor，并订阅相关的应用以获取集群信息。 Manager 的运行模式 Manager 设计为活动-备用模式，其中只有一个 Manager 实例是活动的，负责与 Monitor 通信并发送心跳以表明其存活状态。 如果活动 Manager 停止响应，Monitor 会选择另一个备用 Manager 成为活动 Manager。 Manager 的功能扩展 除了处理集群统计数据，Manager 还支持多种模块，包括预测、编排、内部集群任务（如平衡 EGs）以及管理长时间运行的操作（如 RBD 或 CephFS）。 Manager 的代码结构与初始化流程 Manager 的入口点在 src/mgr/Mgr.cc 文件中，遵循典型的守护进程设置流程，包括解析命令行参数、环境变量、初始化网络地址绑定等。 Manager 初始化时会创建一个 Manager Standby 类，该类包含与集群通信所需的基础设施，如 Messenger、Monitor 客户端、Objecter 等。 Python 模块的集成与管理 Manager 使用 Python 模块来扩展功能，这些模块在 Manager 启动时从磁盘加载。 Python 模块运行在自己的主线程中，使用独立的 Python 解释器，避免模块间的状态共享和潜在的冲突。 后续行动计划 继续深入研究 Manager 的各个模块和功能细节。 探索 Manager 在处理集群统计数据和性能指标方面的优化潜力。 定期回顾和更新 Manager 的文档，确保其与代码实现保持一致。 会议结论： 本次会议对 Ceph Manager 的架构、功能和代码结构进行了全面的概述，为后续的深入研究和开发工作奠定了基础。 后续跟进： 参会人员将继续关注 Manager 的开发进展，并根据需要提出进一步的问题和建议。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-12-08","slug":"Ceph_Crimson_SeaStore_2021-12-08","date":"2021-12-12T16:00:00.000Z","updated":"2021-12-13T16:00:00.000Z","comments":true,"path":"2021/12/13/Ceph_Crimson_SeaStore_2021-12-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/13/Ceph_Crimson_SeaStore_2021-12-08/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： 逻辑PIN竞争修复 上周主要进行了代码审查，并发布了一个版本修复逻辑PIN竞争问题。 心跳空白IP问题 解决了心跳中的空白IP问题，原因是测试中self.configure文件未设置为公共IP地址和集群IP地址。 Messenger单元测试进展 正在准备Messenger单元测试，已向团队成员发送邮件征求意见。 Rook集群安装问题 尝试安装Rook集群时遇到问题，已与Radic同步并获取输入，预计下周继续测试。 性能分析与优化 进行了性能分析，发现CPU时间主要被LBA研究占用，实施了一些优化并提交了PR。 观察到OMAP相关操作占用大量CPU时间，但目前不是重点。 GC速度影响性能，建议增加GC速度以提升性能。 日志相关功能测试 进行了日志相关功能的测试，发现清理操作与模拟和读取操作存在冲突。 后续行动计划 继续优化LBA和OMAP查找。 关注GC性能，作为下一步工作重点。 完善日志相关功能的指标，特别是清理、修剪和回收事务的区分。 决定事项： 继续优化LBA和OMAP查找。 关注GC性能，作为下一步工作重点。 完善日志相关功能的指标，特别是清理、修剪和回收事务的区分。 后续行动计划： 完成Messenger单元测试的准备工作。 继续Rook集群的安装和测试。 实施LBA和OMAP查找的优化。 增加GC速度以提升性能。 完善日志相关功能的指标。 其他事项： 会议记录者将在下周至1月3日期间休假，1月4日恢复工作，期间可通过邮件联系。 会议结束时间：[具体时间] 备注： 本次会议涉及的技术细节较多，建议相关技术人员根据会议内容进行具体实施和跟进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-12-09","slug":"Ceph_Performance_Meeting_2021-12-09","date":"2021-12-12T16:00:00.000Z","updated":"2021-12-13T16:00:00.000Z","comments":true,"path":"2021/12/13/Ceph_Performance_Meeting_2021-12-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/13/Ceph_Performance_Meeting_2021-12-09/","excerpt":"","text":"会议纪要 主要议题 Pull Requests (PRs) 更新 新PR: 启动新的MD日志段，以处理高负载情况下的预期段大小问题。Patrick正在审查，需要进行单元测试。 关闭的PRs: Sage实现了管理器中Gill处理的优化，主要是线程争用问题。 设置最小Alex大小为最佳I/O大小，针对具有较大分配大小的设备。 更新PRs: TTL缓存实现，是旧PR的新版本。 Whip主平衡器PR，Josh Solomon提交，Laura审查，需要对文档进行一些调整。 引入基于Huge Page的读缓冲区，Igor审查，需要更多信息。 BlueFS的细粒度锁定，Adam提交，正在进行新测试。 使Bob fsck更少内存消耗，Igor提交，正在进行更多讨论和更新。 OSD优化PG移除，Igor提交，正在进行更多讨论和更新。 Bob fsck内存使用问题 Adam提出了对改进后的Bob fsck过程的担忧，担心在某些特定情况下可能会有共享blob错误通过fsck过程。 Igor解释了改进后的Bob fsck不会提供错误检测，但在某些情况下可能会标记一些仍然良好的blob为潜在损坏。 讨论了在容器环境中运行OSD的内存限制问题，以及如何避免内存不足导致的崩溃。 TC Malloc线程缓存大小配置 Adam提议将TC Malloc线程缓存大小设置为可配置选项，而不是使用环境变量。 讨论了在perf glue代码中直接处理TC Malloc线程缓存大小的可能性，以及如何在全局配置中处理。 内存分配器讨论 讨论了不同内存分配器（如TC Malloc和Libsy Malloc）的内存碎片问题。 提到了Crimson中使用C-star分配器的情况，以及可能的改进方向。 决定事项 需要进一步讨论和测试Bob fsck的内存使用问题，特别是在容器环境中的应用。 确定将TC Malloc线程缓存大小设置为可配置选项，并考虑在perf glue代码中处理。 讨论了在Crimson中使用TC Malloc替代Libsy Malloc的可能性，特别是在BlueStore和AlienStore中。 后续行动计划 继续审查和测试相关PRs。 进一步讨论和优化Bob fsck的内存使用问题。 确定TC Malloc线程缓存大小的配置方式，并在perf glue代码中实现。 探索在Crimson中使用TC Malloc替代Libsy Malloc的可能性。 下次会议议题 讨论OSD同步写性能问题。 讨论更广泛的自性能优化话题。 会议结束时间: 会议持续了一个小时，所有议题均已讨论完毕。下次会议将继续讨论未尽事宜。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting: 2021-12-07","slug":"Ceph_Orchestrator_Meeting_-_2021-12-07","date":"2021-12-10T16:00:00.000Z","updated":"2021-12-10T16:00:00.000Z","comments":true,"path":"2021/12/11/Ceph_Orchestrator_Meeting_-_2021-12-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/11/Ceph_Orchestrator_Meeting_-_2021-12-07/","excerpt":"","text":"会议纪要：Ceph Orchestrator 周会 会议时间：[具体日期] 参会人员：[列出主要参会人员] 会议议程： Rook 团队更新 TopoLVM 新 Operator 开发进展 大规模集群测试反馈 Kubernetes 与 Ceph 的集成问题讨论 维护模式与离线主机处理 Agent 与 Manager 的通信优化 会议内容总结： Rook 团队更新 Rook 团队未参会，无更新内容。 TopoLVM 新 Operator 开发进展 决定开发一个全新的 Operator 以支持 TopoLVM，因为现有 Operator 的发展方向与需求不符。 新 Operator 将从零开始，计划在几周内向 TopoLVM 项目提交设计方案。 目前工作重点是实现基本功能，如单节点部署和设备选择。 大规模集群测试反馈 讨论了在大型集群（如 40 节点集群）中的性能和稳定性问题。 强调了需要对集群进行压力测试，特别是在节点离线情况下的行为。 提到了 Prometheus 监控模块的性能问题，建议进行深入测试和优化。 Kubernetes 与 Ceph 的集成问题讨论 讨论了 Kubernetes 如何处理离线节点以及如何借鉴其方法来改进 Ceph 的故障处理。 提出了在 Ceph 中实现类似 Kubernetes 的节点故障检测和自动重调度机制。 维护模式与离线主机处理 讨论了维护模式与离线状态的处理逻辑，建议简化并统一处理方式。 提出了在维护模式下快速重调度无状态服务的建议。 Agent 与 Manager 的通信优化 讨论了 Agent 如何快速发现新的 Active Manager 的问题。 提出了通过改进 Agent 的配置更新机制来加速这一过程的建议。 决定事项： 开发全新的 TopoLVM Operator，并计划在几周内提交设计方案。 对大型集群进行压力测试，特别是关注节点离线时的系统行为。 研究并借鉴 Kubernetes 的节点故障处理机制，改进 Ceph 的相应功能。 优化 Agent 与 Manager 的通信机制，减少 Manager 切换时的延迟。 后续行动计划： 继续开发 TopoLVM 新 Operator，并定期更新开发进度。 实施并验证大型集群的压力测试方案。 分析 Kubernetes 的节点故障处理机制，提出并实施改进方案。 优化 Agent 的配置更新机制，减少 Manager 切换时的通信延迟。 下次会议预告： 下次会议将在下周同一时间进行，届时将讨论上述行动计划的进展情况。 会议结束语： 会议在参会人员的积极讨论中圆满结束，期待下次会议的进一步成果。 备注： 本次会议记录涵盖了关键的技术讨论和决策，为后续的开发和测试工作提供了明确的方向和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: MDS Locker, Part 2","slug":"CephFS_Code_Walkthrough_-_MDS_Locker_Part_2","date":"2021-12-08T16:00:00.000Z","updated":"2021-12-09T16:00:00.000Z","comments":true,"path":"2021/12/09/CephFS_Code_Walkthrough_-_MDS_Locker_Part_2/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/09/CephFS_Code_Walkthrough_-_MDS_Locker_Part_2/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于Ceph分布式存储系统中MDS（Metadata Server）锁管理器（MDS Locker）内部机制的代码走读系列会议的第二部分。第一部分已于今年7月或8月举行。由于MDS Locker是一个非常庞大的主题，难以在一次会议中完全覆盖，因此预计还会有第三部分会议。 主要议题 文档更新： 会议中提到将编写一份关于MDS Locker内部实现的文档，并计划将其作为Pull Request提交，以便社区成员可以审查和提供反馈。 MDS Locker概述： MDS使用日志（logs）来保护inode和dentry中的各种元数据。 不同于单一的大锁，MDS为不同的元数据片段使用不同类型的锁。 锁类型（log types）和锁类别（log classes）的定义和使用。 锁类型和锁类别： 锁类型：MDS定义了多种锁类型，每种类型保护inode或dentry中的特定元数据片段。 锁类别：定义了不同锁类型的锁定行为，以处理分布式锁的需求。 Local Lock：用于不需要分布式锁的数据。 Simple Lock：用于需要共享读和互斥写的数据。 Scatter Lock：用于需要共享读和共享写的数据。 File Lock：特殊情况，用于需要共享读和互斥写的数据。 锁状态和状态机： MDS定义了多种锁状态，每个状态决定了是否允许某种类型的锁。 状态机（state machine）描述了锁从一种状态到另一种状态的转换过程。 以Simple Lock为例，详细讲解了从初始状态到最终状态的转换过程，包括中间状态的作用和意义。 决定事项 将继续编写和完善关于MDS Locker的文档，并计划将其作为Pull Request提交，以便社区成员可以审查和提供反馈。 后续行动计划 预计将举行第三部分会议，继续深入探讨MDS Locker的内部机制，特别是Scatter Lock和File Lock的细节。 社区成员应关注即将发布的Pull Request，并积极参与文档的审查和讨论。 其他注意事项 会议中提到的代码和文档将在后续通过Pull Request的形式发布，社区成员应关注并参与讨论。 对于锁状态和状态机的理解，建议从Simple Lock开始，逐步深入，以便更好地理解复杂的锁机制。 本次会议为Ceph社区成员提供了一个深入了解MDS Locker内部机制的机会，并为后续的文档编写和代码优化奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: kclient overview","slug":"CephFS_Code_Walkthrough_-_kclient_overview","date":"2021-12-05T16:00:00.000Z","updated":"2021-12-06T16:00:00.000Z","comments":true,"path":"2021/12/06/CephFS_Code_Walkthrough_-_kclient_overview/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/06/CephFS_Code_Walkthrough_-_kclient_overview/","excerpt":"","text":"会议纪要 会议主题：Ceph客户端代码概述 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容总结： Ceph客户端代码概述 演讲者简要介绍了Ceph客户端（k client）的代码结构，强调了其与用户空间客户端（user land client）的区别，主要在于共享的只是一些头文件。 详细介绍了内核中的几个关键组件，包括libsep（内核模块，作为Ceph的底层传输层）、rbd驱动（主要调用libsep实现）和cephfs代码所在的fsf。 内核组件详细介绍 libsep：作为Ceph代码在内核中的传输层，主要代码位于netsef目录下，包含处理认证、加密、消息传递（v1和v2版本）等功能。 rbd驱动：虽然代码量不大，但负责调用libsep实现路由块设备的功能。 cephfs代码：位于fsf目录下，是一个完整的分布式文件系统（DFS）层内核驱动，负责创建块设备驱动并与libsep交互以与各种守护进程通信。 文件系统操作流程 讨论了文件系统的挂载、文件打开和写操作的流程，包括路径遍历、原子打开操作、写请求的处理以及同步写操作的细节。 强调了vfs层和cephfs客户端之间的交互，以及如何处理用户驱动的系统调用事件。 后台自动处理活动 提到了一些后台自动处理的活动，如连接的调度例程、cap消息的处理等，这些活动由mds驱动。 详细解释了cap消息的处理流程，包括cap的授予和撤销，以及如何处理这些操作引发的写回操作。 问题与讨论 会议中涉及了一些技术问题，如页面写回错误处理、reader plus操作的使用等，演讲者对这些问题进行了详细的解答。 讨论了reader plus操作的实际应用场景和潜在的性能提升，以及为何该操作在某些情况下可能不如预期有效。 决定事项： 无具体决定事项，主要是技术分享和讨论。 后续行动计划： 继续优化Ceph客户端代码，特别是libsep中的序列化问题，以提高性能。 探索和实施新的I/O操作方式，如iou ring，以进一步提升性能和效率。 备注： 会议内容主要针对Ceph客户端代码的技术细节，适合对Ceph有深入了解的开发人员。 会议结束语： 演讲者感谢大家的参与，并祝愿大家有一个愉快的一天。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: OSD Read Lease","slug":"Ceph_Code_Walkthroughs_-_OSD_Read_Lease","date":"2021-12-01T16:00:00.000Z","updated":"2021-12-02T16:00:00.000Z","comments":true,"path":"2021/12/02/Ceph_Code_Walkthroughs_-_OSD_Read_Lease/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/02/Ceph_Code_Walkthroughs_-_OSD_Read_Lease/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统中的读写一致性问题及解决方案 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： 问题背景： 在Ceph中，使用RADOS时，写操作需要触及所有副本，确保所有副本一致。 读操作通常只从主副本（Primary）读取，但存在网络分区可能导致主副本未意识到集群状态变化，继续服务旧数据读取请求。 历史问题： 该问题已存在较长时间，最终在Octopus版本中得到修复。 修复方法涉及引入“租约”（leases）机制，通过租约间隔属性确保读写一致性。 解决方案详述： 租约机制：通过租约消息在主副本和副本之间同步状态，确保读操作的一致性。 时间戳处理：使用单调时钟（monotonic clock）处理时间戳，避免时钟偏差问题。 租约间隔设置：租约间隔可通过全局配置选项lease_ratio设置，乘以心跳间隔（heartbeat_grace）来确定。 新引入的PG状态： Laggy状态：当PG活跃但租约未及时更新时，PG进入Laggy状态，暂停读取请求，直到租约更新。 Wait状态：当PG正在进行 peering 且前一个间隔的上限仍在未来时，PG进入Wait状态，暂停写操作，直到前一个间隔的租约过期。 优化措施： 快速关闭通知：OSD可以通过发送“标记我为死亡”消息给Monitor，或者通过连接拒绝回调机制快速标记OSD为死亡，从而加速租约过期处理。 历史记录处理：在 peering 过程中，通过历史记录（pg_history）处理前一个间隔的租约状态，确保不会因为过早清除租约信息导致读写不一致。 测试与验证： 通过单元测试和功能测试验证了修复方案的有效性，确保在各种网络分区情况下读取操作的一致性。 决定事项： 确认Octopus版本中引入的租约机制和相关优化措施有效解决了读写一致性问题。 需要进一步完善快速关闭通知机制，确保OSD能够及时发送死亡消息给Monitor。 后续行动计划： 继续监控集群状态，确保租约机制稳定运行。 完善文档，详细记录租约机制的配置和使用方法。 定期进行性能测试，确保引入的机制不会对系统性能产生负面影响。 会议结束语： 感谢所有参会人员的积极参与和讨论，本次会议对于理解Ceph中的读写一致性问题及其解决方案具有重要意义。期待后续的实施和验证工作能够顺利进行。 备注：本次会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的全面性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-12-01","slug":"Ceph_Crimson_SeaStore_2021-12-01","date":"2021-12-01T16:00:00.000Z","updated":"2021-12-02T16:00:00.000Z","comments":true,"path":"2021/12/02/Ceph_Crimson_SeaStore_2021-12-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/02/Ceph_Crimson_SeaStore_2021-12-01/","excerpt":"","text":"会议纪要 参会人员 会议主持人：未明确提及 参会人员：未明确提及，但有多人参与讨论 会议日期 会议时间：未明确提及 会议议题 分支重构与代码审查 主持人上周休假，本周开始处理代码审查和分支重构工作。 计划明天完成分支重构工作。 背景恢复问题解决 Chennai团队报告了关于背景恢复的问题，已经测试并通过，问题已解决，补丁已合并。 在技术测试中发现了心跳报告的IP地址不匹配问题，正在调查中。 Crimson Messenger单元测试扩展 正在扩展Crimson Messenger的单元测试，尝试注入网络延迟和故障，以模拟不同策略下的OSD行为。 Sephadm集群问题 讨论了Sephadm集群中遇到的问题，建议与Radic联系以获取更多指导。 性能分析与测试 讨论了RBD FIO和Rados Bench的性能测试，提出了增加节点树分割的配置以改善性能。 提出了在同一池中预先创建对象以改善随机IO测试的建议。 日志管理优化 讨论了日志管理的优化，减少了70%的写入操作和7%的填充大小。 提出了优化清理和读取操作的建议。 性能优化与CPU利用率 讨论了CPU利用率的问题，建议进行性能分析以找到优化点。 提出了使用Youtube工具进行分析的建议，并建议编写文档以指导后续的性能分析工作。 性能对比测试 讨论了使用单CPU限制的BlueStore与Systole的性能对比测试，结果显示Crimson RSD在缺乏缓存的情况下仍表现良好。 决定事项 继续进行分支重构和代码审查工作。 调查并解决心跳报告的IP地址不匹配问题。 扩展Crimson Messenger的单元测试，注入网络延迟和故障。 与Radic联系以解决Sephadm集群问题。 实施增加节点树分割的配置以改善性能。 优化日志管理，减少写入操作和填充大小。 进行性能分析以优化CPU利用率。 编写性能分析文档以指导后续工作。 后续行动计划 完成分支重构和代码审查。 解决心跳报告的IP地址不匹配问题。 扩展Crimson Messenger的单元测试。 与Radic联系以获取Sephadm集群的指导。 实施性能优化措施。 进行性能分析并编写相关文档。 完成性能对比测试并分析结果。 其他 会议结束时，主持人提醒参会人员注意后续的工作安排，并祝愿大家一周愉快。 结束语 会议在大家互相道别后结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-11-30","slug":"Ceph_Developer_Monthly_2021-11-30","date":"2021-12-01T16:00:00.000Z","updated":"2021-12-02T16:00:00.000Z","comments":true,"path":"2021/12/02/Ceph_Developer_Monthly_2021-11-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/12/02/Ceph_Developer_Monthly_2021-11-30/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统中的随机跟踪（Tracing）部署 主要议题： - 跟踪系统介绍： Omri介绍了Ceph中使用的跟踪系统，特别是RDW（Rados Gateway Daemon）中的跟踪实现。他们使用Jaeger作为跟踪后端，OpenTelemetry作为客户端发送跟踪数据到后端。 - 跟踪系统的实现： 创建了一个Tracer类，使用OpenTelemetry客户端SDK。从OpenTracing迁移到OpenTelemetry，因为OpenTracing的C++库不再维护，而OpenTelemetry是一个活跃更新的新库，支持Jaeger后端。 - 当前工作进展： 在RDW和OSD中实现了新的跟踪功能，能够在运行时启用或禁用跟踪，默认情况下禁用。还实现了跟踪信息的序列化和反序列化，以便统一跨多个操作的跟踪。 - 未来计划： 条件跟踪（Conditional Tracing），允许在特定情况下（如特定存储桶）启用跟踪；多站点跟踪（Multi-site Tracing），帮助调试多站点环境；以及RGW和OSD的端到端跟踪集成。 决定事项： - 继续开发和测试跟踪功能，确保其在多节点环境中的稳定性和性能。 - 探索和实现条件跟踪和多站点跟踪功能。 后续行动计划： - 完成性能测试，比较不同跟踪配置下的性能影响。 - 部署Jaeger组件与Ceph集成，确保通过SafeADM正确部署Jaeger容器。 - 继续开发条件跟踪和多站点跟踪功能。 会议主题：Ceph开发环境中的Docker背景 主要议题： - 开发环境介绍： 讨论了使用Docker容器作为Ceph开发环境的问题，特别是在多容器和系统级权限下的挑战。 - 当前状态和挑战： 尽管在某些机器上工作良好，但在其他机器上由于cgroup v2和权限问题遇到了困难。 - 可能的解决方案： 考虑使用Podman替代Docker，或手动挂载必要的文件系统以支持systemd在容器中的运行。 决定事项： - 继续探索和测试不同的容器化解决方案，以找到最适合Ceph开发环境的工具。 后续行动计划： - 测试Podman作为Docker的替代方案。 - 进一步研究和实现手动文件系统挂载以支持systemd。 会议总结 本次会议主要讨论了Ceph系统中的跟踪功能部署、开发环境的容器化问题以及相关技术挑战。团队将继续在这些领域进行深入研究和开发，以提高Ceph的性能和开发效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-11-30","slug":"Ceph_Orchestrator_Meeting_2021-11-30","date":"2021-11-29T16:00:00.000Z","updated":"2021-11-30T16:00:00.000Z","comments":true,"path":"2021/11/30/Ceph_Orchestrator_Meeting_2021-11-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/30/Ceph_Orchestrator_Meeting_2021-11-30/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 主持人: [主持人姓名] 参会人员: [参会人员列表] 主要议题: 集群状态更新 Topo LVM 状态更新 放置规范（Placement Spec）的使用问题 长期架构改进讨论 HFNFS 相关问题 讨论内容 集群状态更新 集群目前存在锁定问题，正在尝试修复。 正在进行一些更改以减少代理报告的工作量，并增加日志记录以监控代理与管理器的响应时间。 集群状态良好，计划向其他组件开放访问，但不包括 Rook。 Topo LVM 状态更新 Topo LVM 的设计更改（包括原始设备而不仅仅是 LVs）目前停滞。 正在为 ODF 开发一个独立的解决方案，使用 Topo LVM Operator。 由于长期愿景的分歧，决定创建一个新的 Operator 来驱动 Topo LVM。 该项目正在进行中，目标是将其纳入 Top LVM 项目。 放置规范（Placement Spec）的使用问题 讨论了放置规范在不同场景下的使用问题，特别是混合使用导致的不一致性。 需要决定是否分离数据结构或继续当前的使用方式。 长期架构改进讨论 讨论了在大规模测试和性能验证方面的长期愿景。 需要建立一个长期的工作列表，特别是在大规模集群管理和调度方面。 提出了在 Totality 中增加更多功能以支持大规模测试的建议。 HFNFS 相关问题 讨论了 HFNFS 的使用案例和触发条件。 需要实现主机离线情况的处理，并确保服务在节点离线后能够正确恢复。 需要进一步研究 Kubernetes 中的 NFS 故障转移行为。 决定事项 继续监控和修复集群的锁定问题。 推进 Topo LVM Operator 的开发，并寻求将其纳入 Top LVM 项目。 对放置规范的使用问题进行进一步讨论和决策。 开始制定长期架构改进的工作列表。 研究并实现 HFNFS 的故障转移机制。 后续行动计划 继续监控集群状态并实施必要的修复。 完成 Topo LVM Operator 的开发，并提交给 Top LVM 项目。 安排进一步讨论放置规范的使用问题。 制定并开始实施长期架构改进的工作列表。 研究 HFNFS 的故障转移机制，并与 Sage 进一步讨论相关细节。 其他事项 感谢 Daniel 在 Red Hat 的工作和贡献，Daniel 即将离职。 会议结束 会议在感谢和告别中结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: CoDel for BlueStore","slug":"Ceph_Code_Walkthroughs_-_CoDel_for_BlueStore","date":"2021-11-24T16:00:00.000Z","updated":"2021-11-25T16:00:00.000Z","comments":true,"path":"2021/11/25/Ceph_Code_Walkthroughs_-_CoDel_for_BlueStore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/25/Ceph_Code_Walkthroughs_-_CoDel_for_BlueStore/","excerpt":"","text":"会议纪要 会议概述 本次会议由专业存储领域分布式存储Ceph的研发人员主持，主要内容是对Ceph的BlueStore中的Cuddle算法进行详细讲解。会议涵盖了问题背景、解决方案架构、代码实现、实验结果等多个方面。 关键细节 问题背景： 在大多数存储系统中，前端（如OSD）和后端（如BlueStore）分别处理不同层次的存储任务。 当前端队列（如BlueStore中的队列）过大时，会导致前端调度困难，影响系统的可调度性。 解决方案架构： 引入Cuddle算法，通过智能的准入控制机制，平衡前端可调度性和后端吞吐量。 Cuddle算法包括两个循环：高频循环（快速循环）和低频循环（慢速循环）。 快速循环通过目标延迟参数控制请求进入后端的数量，以最小化延迟。 慢速循环则根据系统的吞吐量和延迟优化目标参数，以维持吞吐量和延迟之间的平衡。 代码实现： 主要代码位于blueStore_slow_fast_cuddle.cc和blueStore_slow_fast_cuddle.h文件中。 在BlueStore的构造函数中初始化Cuddle算法，并通过配置文件控制算法的激活和参数设置。 快速循环和慢速循环通过定时器触发，分别处理请求的准入控制和参数优化。 实验结果： 使用FIO生成工作负载，实验在SSD上进行。 实验结果显示，Cuddle算法能够有效控制目标延迟参数，适应不同的工作负载变化。 通过调整目标斜率参数，可以在不显著影响吞吐量的前提下，降低BlueStore中的延迟。 决定事项 确认Cuddle算法的有效性，并计划将其集成到Ceph的BlueStore中。 计划进一步研究Cuddle算法对前端调度和队列服务质量的影响。 后续行动计划 将会议中的详细内容和实验结果整理成文档，添加到相关的Pull Request中。 继续优化Cuddle算法，特别是对其在混合IO大小等复杂场景下的性能进行深入研究。 定期回顾和讨论Cuddle算法的进展，确保其持续改进和适应新的需求。 其他备注 会议中提到的Cuddle算法的设计和实现细节，特别是对目标延迟参数的控制和优化，为后续的研究和开发提供了重要的参考。 会议还讨论了Cuddle算法在实际应用中的潜在影响，特别是在提高系统可调度性和服务质量方面的潜力。 本次会议为Ceph存储系统的优化提供了新的思路和方法，特别是通过引入Cuddle算法来平衡前端和后端的性能，为未来的存储系统设计提供了宝贵的经验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2021-11-21","slug":"Ceph_Science_Working_Group_2021-11-21","date":"2021-11-23T16:00:00.000Z","updated":"2021-11-24T16:00:00.000Z","comments":true,"path":"2021/11/24/Ceph_Science_Working_Group_2021-11-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/24/Ceph_Science_Working_Group_2021-11-21/","excerpt":"","text":"会议纪要 会议概述 本次会议是一个每两个月举行一次的聚会，旨在让高吞吐量、高性能计算领域的管理员和科研人员交流讨论。与会者包括来自云服务提供商和其他科学领域的人员。 主要议题与讨论 新成员介绍 一位新成员分享了其在新的研究机构的工作情况，该机构正在部署一个新的辐射研究中心，目前处于早期阶段，硬件尚未到位。该集群主要针对CephFS使用，计划使用少量对象存储用例。 性能优化 有成员分享了在集群中禁用RAID缓存的经验，这显著提升了性能。讨论了具体的配置方法和潜在的性能提升。 升级与部署问题 讨论了从旧版本升级到Pacific版本时遇到的omap格式转换问题，以及如何避免数据损坏。 分享了从Nautilus升级到Octopus的经验，过程顺利且无数据损坏。 硬件与部署细节 讨论了硬件采购的困难，特别是全球供应链问题导致的延迟。 讨论了使用SSD和HDD混合存储的性能优势，特别是在元数据存储上的优化。 CephFS问题 讨论了CephFS在处理大量文件和快照时的性能问题，特别是客户端的性能瓶颈。 分享了在特定目录下使用快照时遇到的性能问题，以及可能的解决方案。 新功能与未来计划 讨论了Ceph的最新版本中的一些新功能，如Debian Bullseye的支持和MDS的滚动升级。 讨论了Ceph的未来发展方向，包括可能的FileStore弃用和Crimson项目的进展。 决定事项 确认了CephFS在处理大量文件和快照时的性能问题，需要进一步测试和优化。 确认了硬件采购的困难，需要提前规划和备货。 后续行动计划 继续测试和优化CephFS的性能，特别是在处理大量文件和快照时的性能。 继续关注Ceph的最新版本和功能，以便及时升级和优化集群。 继续关注硬件采购的困难，提前规划和备货。 其他讨论 讨论了Ceph的社区活动，如Cephalocon的举办情况和参与方式。 讨论了操作系统的选择，如CentOS 8的迁移问题和Rocky Linux的使用情况。 会议总结 会议涵盖了Ceph的多个方面，包括性能优化、升级问题、硬件采购和未来发展方向。与会者分享了各自的经验和见解，为未来的工作提供了宝贵的参考。下次会议将在一月份举行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-11-23","slug":"Ceph_Orchestrator_Meeting_2021-11-23","date":"2021-11-22T16:00:00.000Z","updated":"2021-11-23T16:00:00.000Z","comments":true,"path":"2021/11/23/Ceph_Orchestrator_Meeting_2021-11-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/23/Ceph_Orchestrator_Meeting_2021-11-23/","excerpt":"","text":"会议纪要 会议时间： 未明确指出，但提到会议开始时已经过了预定时间五分钟。 参会人员： 未明确列出所有参会人员，但提到了Francesco、John、Nesto、Sage、Ramana等。 主要议题： Topol VM Operator进展： 团队报告了Topol VM Operator的最新进展，表示已经有一个固定版本的Topol VM Operator与原始拓扑项目兼容。 开发者对贡献持开放态度，团队已经开始紧密合作。 计划下周提供CRD设计，以便开始实施智能动态配置，这对于在不同环境中管理ACID OSDs至关重要。 Manager挂起问题： Sage正在调试Manager挂起的问题，已经成功复现并使用GDB进行分析，初步判断是某种锁死锁问题。 需要进一步分析堆栈跟踪以确定具体是哪个锁导致的死锁。 Prometheus模块性能问题： Paul发现Prometheus模块存在严重的性能问题，尤其是在处理大量OSDs数据时。 需要进一步优化和测试，以提高模块的性能。 SNMP进展： SNMP的开发仍在进行中，Paul和Sebastian正在负责此项工作。 这是一个重要的开放问题，需要团队持续关注。 NFS服务与OpenStack Manila集成： Ramana报告了NFS服务在OpenStack Manila集成中的测试情况，发现当主机宕机时，NFS服务未能自动重新部署。 需要进一步测试和解决此问题，以确保服务的HA（高可用性）。 决定事项： 需要创建一个跟踪票（tracker ticket）来解决NFS服务在主机宕机时未能自动重新部署的问题。 需要进一步优化和测试Prometheus模块，以解决性能问题。 需要继续推进SNMP的开发工作。 后续行动计划： Sage将继续调试Manager挂起的问题，并尝试解决锁死锁问题。 Paul将继续优化Prometheus模块的性能。 Ramana将创建一个跟踪票，详细描述NFS服务在主机宕机时的问题，并提供复现步骤。 团队将关注SNMP的开发进展，并确保其稳定性和性能。 其他讨论： 会议中还讨论了其他一些技术细节和潜在问题，但未形成具体的决定或行动计划。 会议结束： 会议在讨论完所有议题后结束，约定下周再次开会。 备注： 会议中提到的具体技术细节和问题需要进一步的技术分析和解决。 需要确保所有开放问题都有明确的跟踪和解决计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-11-18","slug":"Ceph_Performance_Meeting_2021-11-18","date":"2021-11-19T16:00:00.000Z","updated":"2021-11-19T16:00:00.000Z","comments":true,"path":"2021/11/20/Ceph_Performance_Meeting_2021-11-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/20/Ceph_Performance_Meeting_2021-11-18/","excerpt":"","text":"会议纪要 会议概要 日期与时间: 会议在特定日期举行，持续了约1小时。 参与者: 会议包括来自Ceph社区的开发者和用户，主要参与者包括Jonas、Josh、Mark、Patrick等。 会议目的: 讨论Ceph存储系统的最新开发进展，特别是关于分布式存储平衡器的工作。 主要议题 Pull Requests (PRs) 更新: 本周有两个新的PRs，一个是由Josh Solomon提交的文档PR，另一个是由Patrick提交的MDS相关PR。 一个关于请求超时优化的PR被合并。 Ceph Balancer 讨论: Jonas介绍了他的独立Ceph平衡器工作，该平衡器使用外部Python脚本通过Z API进行操作。 讨论了平衡器在处理不均匀设备大小和集群性能优化方面的挑战和解决方案。 Jonas的平衡器专注于通过移动PG（Placement Groups）来优化最满的OSD（Object Storage Daemon），以提高集群的整体平衡。 性能与稳定性问题: 讨论了Ceph在处理大量PG时的性能问题，特别是关于PG分配和OSD的限制。 提到了一些长期存在的bug，如重新映射数据的问题，以及如何更好地处理这些bug。 决定事项 确认了Jonas的平衡器工作的有效性，并讨论了将其集成到Ceph主分支的可能性。 讨论了改进Ceph平衡器的方法，包括增加对实际利用率而不是仅PG数量的考虑。 确定了需要进一步研究和解决的性能和稳定性问题。 后续行动计划 继续开发和测试Jonas的平衡器，探索将其正式集成到Ceph的可能性和方法。 对现有的Ceph平衡器进行代码审查和性能优化，特别是在处理PG分配和OSD限制方面。 社区成员将继续跟踪和解决已知的bug和性能问题，特别是那些影响用户日常操作的问题。 其他备注 会议中提到了Ceph社区对新功能开发和bug修复之间的平衡问题，强调了稳定性优化的重要性。 讨论了Ceph在不同使用场景下的适应性和优化策略，特别是在处理大型和异构集群时。 通过这次会议，Ceph社区进一步明确了未来的开发方向和优化目标，特别是在提高存储系统的平衡性和性能方面。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-11-17","slug":"Ceph_Crimson_SeaStore_2021-11-17","date":"2021-11-16T16:00:00.000Z","updated":"2021-11-17T16:00:00.000Z","comments":true,"path":"2021/11/17/Ceph_Crimson_SeaStore_2021-11-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/17/Ceph_Crimson_SeaStore_2021-11-17/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： LRU代码更新 发言人：[姓名] 内容：已编写LRU代码，并将当前版本的链接添加到文档中。需要评估性能影响，确保没有出现不合理的问题。 PIA/TPR合并状态 发言人：[姓名] 内容：正在努力将Myeong-wan的PIA或TPR调整到可合并状态。计划移除特殊段落内容，因为正在添加更复杂的设备位开始PRT。 延迟机制调整 发言人：[姓名] 内容：讨论了外观事件启动中的延迟机制。建议将延迟时间从1秒调整为1毫秒，以避免不必要的长时间延迟。 OSD启动错误 发言人：[姓名] 内容：报告了OSD启动时的错误，正在进行测试以确定问题原因。 段崩溃问题 发言人：[姓名] 内容：解决了由其他原因引起的崩溃问题，但段崩溃问题仍然存在，将继续处理。 决定事项： 将外观事件启动的延迟时间从1秒调整为1毫秒。 继续测试和调试OSD启动错误。 继续处理段崩溃问题。 后续行动计划： 评估LRU代码的性能影响。 调整PIA/TPR以准备合并。 修改延迟机制并确保其他调用者不受影响。 继续调试OSD启动错误。 继续处理段崩溃问题。 其他事项： [姓名]下周将不在，预计下下周返回。 [姓名]将休假，参加家庭聚会。 会议结束： 会议于[具体时间]结束，祝大家下周愉快。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-11-16","slug":"Ceph_Orchestrator_Meeting_2021-11-16","date":"2021-11-16T16:00:00.000Z","updated":"2021-11-16T16:00:00.000Z","comments":true,"path":"2021/11/17/Ceph_Orchestrator_Meeting_2021-11-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/17/Ceph_Orchestrator_Meeting_2021-11-16/","excerpt":"","text":"会议纪要 会议概要 会议主题: 协调器会议 日期: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 主要议题 Cephalocon 的 CFP（Call for Papers） CFP 截止日期为12月10日。 鼓励团队成员提交演讲提案，特别是关于安全性和NSF ADM文档的内容。 讨论了是否需要为不同的开发领域（如FDM、Flu Culture系统等）设置专门的会议环节。 大型集群部署计划 计划在澳大利亚珀斯的Poise超级计算中心部署大规模的SF ADM集群。 讨论了如何有效组织和利用时间，避免在部署过程中浪费时间。 提出了使用IRC或Matrix作为通信渠道，以确保信息的连续性和可访问性。 集群测试和资源利用 讨论了如何优化集群的测试和资源利用，包括重用现有集群和有效管理NVMe设备。 确认了Patrick已经对self-FFS进行了研究，并期待其他组件也能利用这一集群。 技术细节和改进 讨论了从runC切换到crun以改善上游生育测试中的组错误问题。 确认了Sage已经提交了相关的PR，并期待这一改变能带来更稳定的运行环境。 决定事项 将向Cephalocon组织者提出建议，为不同的开发领域设置专门的会议环节。 确认使用Matrix作为通信渠道，以替代传统的IRC。 确认了集群部署和测试的具体计划，包括重用现有集群和优化资源利用。 确认了技术改进的方向，特别是从runC切换到crun。 后续行动计划 向Cephalocon组织者提出建议，设置专门的会议环节。 确认并实施使用Matrix作为通信渠道。 继续推进大型集群的部署和测试工作，确保资源的有效利用。 实施从runC到crun的技术切换，并更新相关文档。 下次会议 日期: 下周二 地点: [会议链接或地点] 会议结束 时间: [具体结束时间] 备注: 无其他议题 会议记录人: [记录人姓名] 审核人: [审核人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-11-11","slug":"Ceph_Performance_Meeting_2021-11-11","date":"2021-11-10T16:00:00.000Z","updated":"2021-11-11T16:00:00.000Z","comments":true,"path":"2021/11/11/Ceph_Performance_Meeting_2021-11-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/11/Ceph_Performance_Meeting_2021-11-11/","excerpt":"","text":"会议纪要 关键细节 新拉取请求（Pull Request）: Radic提交了一个引入基于Huge Page的读缓冲区的新拉取请求，这看起来很有趣，但尚不确定在何种情况下会带来帮助。 更新拉取请求: Adam的BlueFS细粒度锁定重试通过了本周的QA测试，之前失败的案例现在通过了。 优化请求超时: 对Beast库的优化拉取请求包含大量基准测试数据和讨论，Casey进行了审查，发现自定义分配器部分并不真正有帮助，因此被移除。 性能问题: 一个关于RGB性能的拉取请求被提及，但未详细讨论。 其他拉取请求: 包括设置最小ALEX大小、减少blob fsck的RAM使用、优化PG移除等，这些都在积极讨论和测试中。 讨论的主要议题 构建时间优化: 讨论了如何优化包构建时间，特别是单线程部分，提出了并行化构建和优化DWZ工具的可能性。 快速关闭（Fast Shutdown）: 讨论了快速关闭的必要性和实际效果，提出了可能的改进措施，如限制关闭时间。 客户端请求大小: 讨论了客户端请求大小的优化，提出了限制最大请求大小和优化内存使用的建议。 决定的事项 继续测试和优化: 对于所有提到的拉取请求，决定继续进行测试和优化，以确保性能和稳定性。 关注构建时间: 决定进一步研究和优化包构建时间，特别是单线程部分。 考虑快速关闭的改进: 考虑对快速关闭功能进行改进，以减少关闭时间和提高一致性。 后续行动计划 继续测试和审查拉取请求: 对所有拉取请求进行进一步的测试和审查，确保它们符合性能和稳定性的要求。 优化构建时间: 研究和实施构建时间的优化措施，特别是并行化和单线程部分的优化。 改进快速关闭功能: 考虑实施改进措施，以优化快速关闭功能，减少关闭时间并提高系统一致性。 客户端请求大小优化: 研究和实施客户端请求大小的优化，以减少内存使用并提高系统性能。 本次会议涵盖了多个技术议题，涉及性能优化、构建时间优化和系统关闭策略等多个方面，后续行动计划旨在确保Ceph系统的性能和稳定性得到持续改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-11-10","slug":"Ceph_Crimson_SeaStore_2021-11-10","date":"2021-11-09T16:00:00.000Z","updated":"2021-11-10T16:00:00.000Z","comments":true,"path":"2021/11/10/Ceph_Crimson_SeaStore_2021-11-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/10/Ceph_Crimson_SeaStore_2021-11-10/","excerpt":"","text":"会议纪要 关键细节： Journal PRs 合并：本周团队成功合并了两个 Journal PRs。 PRT 结构泛化：Myeongwon 正在努力泛化 PRT 结构，以便只有段管理器内部关心段管理器部分，从而能够在 Ceph 存储和事务管理器中无缝使用随机访问设备地址。 ZNS 段管理器：Joseph 正在开发 ZNS 段管理器，并已实现大部分功能。实验室中已有几个实际的 ZNS 设备，进展顺利。 Crimson 配置简化：Radik 上周主要在 Crimson 项目中工作，发送了一个 PR 以移除 Rook 中 Crimson 的特定配置需求，简化了 Kubernetes 集群中的客户端配置。 中断条件问题：Barth 发现了一个与中断条件相关的问题，即在可中断未来中，全局中断条件未被清除，导致后续事件无法正确启动。该问题已在测试环境中发现，将在离线讨论中解决。 C-Store 测试：Soonel 尝试在上游主分支中测试 C-Store，但发现部署工具尚未支持 C-Store，建议继续关注 Blue Store 的测试。 段故障问题：上周在测试中遇到了严重的段故障问题，原因是 GC 未启动导致空间未回收。已提交 PR 修复 32 位类型溢出问题，但仍在寻找根本原因。 中断条件状态：在处理 PG 事件时遇到了嵌套中断条件的问题，建议通过实现某种中断条件状态来解决。 讨论的主要议题： PRT 结构的泛化和其在 Ceph 中的应用。 ZNS 段管理器的开发进展和实际设备测试。 Crimson 配置的简化及其在 Kubernetes 集群中的应用。 中断条件问题的诊断和解决方案。 C-Store 的测试现状和未来方向。 决定的事项： 继续推进 PRT 结构的泛化工作。 继续 ZNS 段管理器的开发和测试。 简化 Crimson 配置，移除不必要的特定配置。 解决中断条件问题，确保事件处理的正确性。 关注 Blue Store 的测试，同时探索 C-Store 的部署可能性。 后续的行动计划： Myeongwon 继续泛化 PRT 结构，确保其在 Ceph 中的无缝应用。 Joseph 继续 ZNS 段管理器的开发，并进行实际设备测试。 Radik 继续简化 Crimson 配置，确保其在 Kubernetes 集群中的顺利应用。 Barth 与 Jihad 离线讨论中断条件问题的解决方案。 Soonel 继续关注 Blue Store 的测试，同时探索 C-Store 的部署可能性。 解决段故障问题的根本原因，并确保 GC 的正常运行。 会议结束 会议结束，祝大家本周工作顺利。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-11-09","slug":"Ceph_Orchestrator_Meeting_2021-11-09","date":"2021-11-08T16:00:00.000Z","updated":"2021-11-09T16:00:00.000Z","comments":true,"path":"2021/11/09/Ceph_Orchestrator_Meeting_2021-11-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/09/Ceph_Orchestrator_Meeting_2021-11-09/","excerpt":"","text":"会议纪要 会议概要 会议类型: 每周协调会议 日期: [具体日期] 参会人员: [列出参会人员] 主要议题 Topo LVM 更新 讨论内容: Travis、Seb 和 Joseph 讨论了 Topo LVM 处理原始设备的能力。 结论: Topo LVM 目前无法处理原始设备，需要大量设计和投资。OCS 目前使用 LSO 处理静态卷和原始卷，而 Topo LVM 处理本地存储的动态供应。 后续行动: 继续使用现有解决方案，不急于推动 Topo LVM 更新。 Docker 开发环境 讨论内容: 讨论了添加 Docker 开发环境的 Pull Request。 反馈: 需要找到更清洁的方式在本地回环设备上创建 OSDs。 进展: Docker 开发环境已经可以运行，但需要解决 NFS 服务部署时的错误。 CentOS Stream 和 Podman 讨论内容: 讨论了使用 CentOS Stream 和 Podman 的问题。 进展: 目前使用 CentOS Stream 作为临时解决方案，需要持续跟进 Podman 的修复。 Ceph 配置文件路径变更 讨论内容: 讨论了将 Ceph 配置文件路径从 user 更改为 /etc 的 Pull Request。 结论: 需要处理路径迁移问题，其他方面没有大问题。 使用控制台作为 IGW 前端 讨论内容: 讨论了使用控制台作为 IGW 前端的可行性。 结论: 需要手动部署 HAProxy，控制台可以作为替代方案。 决定事项 Topo LVM: 继续使用现有解决方案，不急于推动更新。 Docker 开发环境: 需要找到更清洁的方式创建 OSDs。 CentOS Stream 和 Podman: 继续使用 CentOS Stream，持续跟进 Podman 的修复。 Ceph 配置文件路径: 处理路径迁移问题。 控制台作为 IGW 前端: 需要手动部署 HAProxy。 后续行动计划 Topo LVM: 继续监控现有解决方案的性能和稳定性。 Docker 开发环境: 解决 NFS 服务部署错误，优化 OSD 创建方式。 CentOS Stream 和 Podman: 持续跟进 Podman 的修复，确保稳定版本可用。 Ceph 配置文件路径: 完成路径迁移，确保配置文件的正确性。 控制台作为 IGW 前端: 测试控制台作为 IGW 前端的可行性，确保部署流程的顺畅。 其他事项 Dashboard 团队的工作: 他们的工作已经合并到 Pacific 分支，需要关注后续的测试和反馈。 会议结束 下次会议: 下周同一时间 结束语: 祝大家周二愉快，下次会议再见。 备注: 会议中提到的具体技术细节和术语，如 Topo LVM、LSO、OSDs 等，是 Ceph 分布式存储系统中的关键组件和技术，保留这些术语有助于专业人员理解会议内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-10-03","slug":"Ceph_Crimson_SeaStore_2021-10-03","date":"2021-11-03T16:00:00.000Z","updated":"2021-11-04T16:00:00.000Z","comments":true,"path":"2021/11/04/Ceph_Crimson_SeaStore_2021-10-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/04/Ceph_Crimson_SeaStore_2021-10-03/","excerpt":"","text":"会议纪要 与会人员 主持人：未明确提及 参与者：未明确提及 会议日期 2023年某月某日 主要议题 Ceph相关工作进展 Journal Badging PR for Young Gem：已完成评审。 C-Star Metadata PR for May：正在进行中。 Cache LRU：工作被其他事务打断。 Build问题：测试受阻，需要进一步调查。 性能测试结果差异：不同构建选项对性能测试结果有影响，需要进一步验证。 Make FS问题：Ceph启动和停止正常，但使用特定命令启动OSD时出现问题。 FSID问题：讨论了FSID的设置和随机化问题。 Spread LFS Strategy Work：计划将工作合并到主分支，但上周因其他工作未能推进。 Journal Committer Management：修复了相关问题，并进行了性能测试。 决定事项 Build问题：需要进一步调查和解决。 性能测试结果差异：需要验证不同构建选项对性能的影响。 Make FS问题：需要进一步调查特定命令启动OSD的问题。 FSID问题：决定在Ceph存储初始化时随机化FSID，避免写入零值。 Journal Committer Management：决定合并相关PR，尽管在特定环境中存在性能问题。 后续行动计划 Build问题：继续调查并解决。 性能测试结果差异：验证并分析不同构建选项的影响。 Make FS问题：调查特定命令启动OSD的问题。 FSID问题：在Ceph存储初始化时随机化FSID。 Spread LFS Strategy Work：继续推进并将工作合并到主分支。 Journal Committer Management：合并相关PR，并后续解决性能问题。 其他 会议中提到了一些技术细节和具体代码问题，需要相关人员进一步跟进和处理。 会议结束 会议在讨论完所有议题后结束，祝大家一周愉快。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-11-03","slug":"Ceph_Developer_Monthly_2021-11-03","date":"2021-11-03T16:00:00.000Z","updated":"2021-11-04T16:00:00.000Z","comments":true,"path":"2021/11/04/Ceph_Developer_Monthly_2021-11-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/04/Ceph_Developer_Monthly_2021-11-03/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于Ceph分布式存储系统的月度会议，主要讨论了Crimson更新、Ceph存储技术（Ceph Store）的进展、遥测数据收集以及关键问题的通知机制。会议在假期期间举行，因此参与人数不多。 主要议题 Crimson更新 稳定性提升：Radic团队一直在努力解决Crimson中的bug，特别是在Crimson的Toothology套件中。已经进行了大量的稳定性工作，包括对watch notify API的更改和操作顺序逻辑的改进。 部署进展：Crimson与Rook的集成存在问题，但Chad May对Crimson的Blue Store集成进行了改进，提高了性能。 下一步计划：将scrub工作转移到Krypson中，正在进行OSD状态机的重构，以便在Crimson中重用大量代码。 Ceph存储技术（Ceph Store） 性能优化：Intel团队增加了大量计数器和直方图，用于跟踪事务冲突率和分配信息，有助于解决性能问题。 稳定性改进：对LBI分配路径进行了重写，解决了逻辑问题，提高了代码的可读性。 新功能开发：Schwehn的extent placement manager已合并，支持在C-Store内进行分层。Joyhead正在实现基于年龄的竞价方案，这将有助于将extent写入非日志设备。 遥测数据收集 重新选择流程：讨论了如何解决用户重新选择的问题，提出了一个新的设计，允许用户重新选择时同步新的数据收集版本。 数据收集策略：强调了数据收集的透明度和用户隐私，建议对收集的每个字段进行详细说明，并提供一个结构化的JSON描述。 关键问题通知 健康警告机制：提出了一个健康警告机制，用于在用户运行存在已知问题的版本时发出警告。讨论了如何通过Redmine标记严重问题，并在集群中生成健康警告。 版本信息管理：建议使用releases.yaml文件来标记有问题的版本，并在集群中提供这些信息，以便用户在升级时做出明智的决策。 决定事项 Crimson稳定性提升：继续进行Crimson的稳定性改进，特别是与Rook的集成和多核支持。 Ceph Store性能优化：继续优化Ceph Store的性能和稳定性，特别是对LBI分配路径和extent placement manager的改进。 遥测数据收集改进：实施新的重新选择流程，并对收集的数据字段进行详细说明，以提高透明度和用户信任。 关键问题通知机制：开发一个健康警告机制，用于通知用户关于已知的关键问题，并使用releases.yaml文件来管理版本信息。 后续行动计划 Crimson开发：继续进行Crimson的开发和测试，确保与Rook的集成和多核支持的稳定性。 Ceph Store改进：继续优化Ceph Store的性能和稳定性，特别是对LBI分配路径和extent placement manager的改进。 遥测数据收集：实施新的重新选择流程，并对收集的数据字段进行详细说明，以提高透明度和用户信任。 关键问题通知机制：开发一个健康警告机制，用于通知用户关于已知的关键问题，并使用releases.yaml文件来管理版本信息。 结论 本次会议讨论了Ceph分布式存储系统的多个关键领域，包括Crimson的稳定性提升、Ceph Store的性能优化、遥测数据收集的改进以及关键问题的通知机制。会议强调了透明度、用户隐私和性能优化的重要性，并制定了相应的后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-11-04","slug":"Ceph_Performance_Meeting_2021-11-04","date":"2021-11-03T16:00:00.000Z","updated":"2021-11-04T16:00:00.000Z","comments":true,"path":"2021/11/04/Ceph_Performance_Meeting_2021-11-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/04/Ceph_Performance_Meeting_2021-11-04/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph项目的最新进展，包括新提交的PR（Pull Request）、已关闭的PR以及性能测试相关的话题。会议由一位稍晚加入的成员主持，讨论了多个技术议题和后续行动计划。 主要议题 新PR讨论 Adam的BlueStore fine grain locking PR：这是一个重新尝试引入的PR，之前的版本存在问题并已回滚。讨论了其复杂性和潜在的性能提升。 优化请求超时问题：Casey提交了一个新的PR，通过引入自定义分配器等方法优化了请求超时问题，显著提升了性能。讨论了CPU使用率的变化和后续的测试计划。 性能测试CI工作 讨论了当前性能测试CI的现状和存在的问题，特别是关于Classic PRs的性能测试未自动运行的问题。 提出了扩展测试工作负载的建议，包括引入FIO测试，并讨论了如何改进和扩展现有的性能测试框架。 讨论了多节点测试的必要性和可行性，以及如何处理非默认配置（如禁用数据CRC）的问题。 其他更新和讨论 讨论了其他几个PR的更新情况，包括优化内存使用、配置调整等。 提到了一些长期未有进展的PR，强调了继续讨论和评估的重要性。 决定事项 确认了需要进一步调查为何带有性能标签的Classic PRs未自动运行性能测试。 决定扩展性能测试框架，首先引入FIO测试，并考虑多节点测试的可行性。 讨论了性能测试中非默认配置的问题，建议根据PR的具体内容决定是否启用某些配置。 后续行动计划 调查并解决Classic PRs性能测试未自动运行的问题。 扩展性能测试框架，引入FIO测试，并考虑多节点测试。 继续讨论和评估长期未有进展的PR，确保项目的持续改进和发展。 其他事项 确认了下一次会议将讨论Crimson相关的内容，再下一次会议将讨论Balancer的包装器。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并期待下一次会议的讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: CRUSH","slug":"Ceph_Code_Walkthroughs_-_CRUSH","date":"2021-11-02T16:00:00.000Z","updated":"2021-11-03T16:00:00.000Z","comments":true,"path":"2021/11/03/Ceph_Code_Walkthroughs_-_CRUSH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/03/Ceph_Code_Walkthroughs_-_CRUSH/","excerpt":"","text":"会议纪要 会议概述 本次会议由Sage Weil主持，主要内容是对Ceph分布式存储系统中的核心组件之一——CRUSH算法进行深入的技术讲解。会议涵盖了CRUSH算法的基本原理、代码实现细节、以及一些高级特性，如影子树（shadow trees）和选择参数（choose args）。 讨论的主要议题 CRUSH算法概述： CRUSH算法是Ceph存储系统的数据放置算法，负责在集群中高效地分布数据。 算法基于分层结构和放置规则，通过一系列步骤来确定数据的最终位置。 代码实现细节： 讨论了CRUSH算法的C语言实现，包括头文件中的数据结构和常量定义。 详细解释了算法中的各个步骤，如take、choose等，以及如何通过递归下降来选择数据放置位置。 高级特性： 影子树（Shadow Trees）：介绍了如何在CRUSH映射中自动管理不同存储类别的设备，如SSD和HDD。 选择参数（Choose Args）：解释了如何通过权重集（weight sets）来优化数据分布，特别是在处理不同大小的设备时。 调试和优化： 提供了一些调试CRUSH算法的技巧，如使用dprintk进行详细日志输出。 讨论了未来可能的改进方向，包括简化算法、改进优化器以及增强工具的易用性。 决定的事项 确认了CRUSH算法中的一些关键参数和配置，如默认使用straw2桶类型，以及如何避免数据迁移的常见错误。 强调了使用CLI命令而非手动编辑CRUSH映射文件的重要性。 后续行动计划 继续优化CRUSH算法，特别是在处理大规模集群和复杂数据分布需求时。 探索更高效的调试和优化工具，以简化CRUSH映射的管理和调整。 考虑增加对JSON格式的支持，以便更方便地导入和导出CRUSH映射。 其他注意事项 提醒与会者注意CRUSH算法中的某些遗留特性和桶类型可能不再推荐使用，建议逐步淘汰这些旧特性。 强调了在修改CRUSH映射时需要特别小心，以避免不必要的数据迁移。 本次会议为Ceph社区的开发者和用户提供了深入了解CRUSH算法的机会，同时也为未来的改进和优化指明了方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-10-27","slug":"Ceph_Crimson_SeaStore_2021-10-27","date":"2021-11-02T16:00:00.000Z","updated":"2021-11-03T16:00:00.000Z","comments":true,"path":"2021/11/03/Ceph_Crimson_SeaStore_2021-10-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/03/Ceph_Crimson_SeaStore_2021-10-27/","excerpt":"","text":"会议纪要 主要议题与讨论内容 Ceph PR审核与合并 已完成多项PR的审核工作。 成功合并了首个Random Block Manager的PR，感谢所有参与审核的人员。 针对lower bound fix的问题，已实施修复，希望解决了相关问题。 Crimson测试与问题反馈 正在进行Crimson的测试，并遇到了一些问题，已在上游报告了一个bug。 在配置Crimson时，按照上游文档操作，但在第三步遇到了问题。 问题可能源于文档中的指令错误，Radik正在努力使Crimson与Rook兼容，之后将对此问题进行进一步检查。 OSD Metadata问题 已修复OSD Metadata相关问题，但仍有其他问题需要调查。 单元测试中存在一些错误，已修复并将更新PR。 Journal Submitter与Metrics问题 正在调试Journal Submitter，特别是与Metrics Matrix注册失败相关的问题，这影响了LBA测试。 目前正在深入调查，怀疑存在更深层次的问题。 EPM Sprel Sprite LFS Strategy测试 上周主要处理了相关问题，下周将继续进行测试。 决定事项 确认了Crimson配置文档中的指令存在错误，需要进一步修正。 将持续跟进OSD Metadata和Journal Submitter的相关问题，并进行深入调查。 后续行动计划 更新并修正Crimson配置文档中的错误指令。 继续进行Crimson与Rook的兼容性测试。 深入调查并解决OSD Metadata和Journal Submitter中的问题。 完成EPM Sprel Sprite LFS Strategy的测试工作。 其他事项 会议结束时，提醒大家注意沟通问题，确保所有参与者都能听到并参与讨论。 会议结束语 - 祝大家本周工作顺利，再见。 以上是本次会议的纪要，涵盖了关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-11-02","slug":"Ceph_Orchestrator_Meeting_2021-11-02","date":"2021-11-02T16:00:00.000Z","updated":"2021-11-03T16:00:00.000Z","comments":true,"path":"2021/11/03/Ceph_Orchestrator_Meeting_2021-11-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/03/Ceph_Orchestrator_Meeting_2021-11-02/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 会议 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： 升级问题讨论 问题描述：Dania 和 Melissa 提出的关于创建健康警告的 Pull Request 揭示了从 Octopus 升级到 Pacific 的问题。具体表现为升级过程中监控堆栈（包括 Alertmanager、Grafana、Prometheus 和 Node Exporter）出现名称冲突错误，提示“alertmanager.vm0 已存在”。 影响范围：此问题不仅影响 Octopus 到 Pacific 的升级，还可能影响 Pacific 到 Master 的升级。 当前状态：目前正在调查具体的操作顺序和原因，尚未找到确切解决方案。 Agent 状态更新 主要进展：讨论了 Agent 的几个关键 Pull Request，包括端点支持和响应性改进。这些 PR 已经通过了 QA 测试，目前需要进一步的审查。 NFS 相关问题：Adam 报告了 NFS 守护进程的故障检测和恢复机制，目前正在测试主机离线时的处理情况。 其他议题 Topo LVM 更新：Blaine 表示没有关于 Topo LVM 的新更新。 Backport 计划：讨论了将某些功能回溯到 Pacific 版本的计划，特别是 Agent 功能，建议在稳定后再进行回溯。 Key Rotation PR：提及了 Key Rotation 的 Pull Request，已准备好进行审查。 Bug 修复：解决了导出功能中的一个路径问题，并计划在测试完成后合并。 决定事项： 继续调查和解决从 Octopus 升级到 Pacific 的监控堆栈名称冲突问题。 完成 Agent 相关 PR 的审查和合并工作。 计划在 Agent 功能稳定后进行回溯到 Pacific 版本的准备工作。 后续行动计划： 对升级问题进行深入分析，找出根本原因并提出解决方案。 完成并合并 Agent 相关的 Pull Request。 在实验室环境中测试 Agent 功能，确保其在生产环境中稳定运行。 审查并合并 Key Rotation 的 Pull Request。 备注： 会议中提到的具体技术细节和错误信息需要进一步的技术分析和验证。 所有决定和行动计划需要相关团队成员的协作和跟进。 下次会议预告： 预计下周继续讨论上述议题的进展和下一步行动。 会议结束： 会议于[具体结束时间]结束，感谢所有参会人员的参与和贡献。 注意：以上纪要基于会议内容总结，具体实施细节和时间表可能需要根据实际情况调整。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-10-28","slug":"Ceph_Performance_Meeting_2021-10-28","date":"2021-11-02T16:00:00.000Z","updated":"2021-11-03T16:00:00.000Z","comments":true,"path":"2021/11/03/Ceph_Performance_Meeting_2021-10-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/11/03/Ceph_Performance_Meeting_2021-10-28/","excerpt":"","text":"会议纪要 关键细节 新拉取请求（Pull Requests, PRs）: 设置最小分配大小为某些设备的最佳I/O大小。讨论了新设备类型可能需要大于4K的分配单元，但不一定必须，涉及性能与空间浪费的权衡。 Igor提出的改进共享Blob fsck过程，使其更节省RAM。从12GB减少到0.5GB，显著改善了内存使用。 Mark Cogan关于db store的工作，增加了配置选项以设置单线程性能调优参数。 更新PRs: 优化PG peering延迟的PR，Neha将重新定位到master分支。 MDS移除子树映射从日志的PR，设计文档已提供，仍在进行中。 优化对象内存分配使用池的旧PR，Gabriel增加了讨论，涉及内存分配的优化。 讨论的主要议题 内存分配优化: 讨论了如何通过预分配区域或重用对象来优化内存分配，减少动态分配的需求。 提到了使用栈分配、固定大小缓冲区（如4K或8K）以及slab分配器的可能性。 讨论了是否应该重新设计协议，以支持更高效的内存使用和减少碎片化。 性能瓶颈: 提到了messenger组件可能存在的性能瓶颈，建议从这里开始优化。 讨论了如何通过减少动态分配和优化数据结构来改善性能。 决定的事项 需要进一步调查和优化内存分配策略，特别是对于高频使用的对象和请求。 选择一个简单的组件（如messenger）开始优化，以验证假设和方法的有效性。 后续行动计划 继续讨论和优化内存分配策略，特别是对于编码/解码过程。 开始对messenger组件进行优化，以减少其性能开销。 收集更多的性能数据和墙钟分析，以帮助确定进一步优化的领域。 会议强调了通过小步骤开始，逐步改进系统性能的重要性，并鼓励团队成员继续探索和实验这些优化策略。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-10-20","slug":"Ceph_Crimson_SeaStore_2021-10-20","date":"2021-10-20T16:00:00.000Z","updated":"2021-10-21T16:00:00.000Z","comments":true,"path":"2021/10/21/Ceph_Crimson_SeaStore_2021-10-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/21/Ceph_Crimson_SeaStore_2021-10-20/","excerpt":"","text":"会议纪要 会议开始 时间: 会议开始于指定时间。 参与者: 确认所有关键成员已加入。 主要议题 多设备功能合并 上周已完成多设备功能的合并。 正在与C-Store合作，特别是与chimney项目合作，处理cash相关工作。 Bug修复 Joyhot发现并修复了lower bound中的一个bug。 该bug通过运行程序在8到9秒后导致崩溃。 计划为此bug创建一个单元测试。 C-Store与Crimson OST的集成 上海团队正在协助建立稳定的测试环境。 正在研究如何为Crimson OST构建beam包。 解决了报告错误，原因是OSD元数据未写入指定目录。 确认需要支持将元数据写入特定目录的功能。 C-Store的文件布局 计划模仿BlueStore的文件布局，特别是使用相同的分区策略。 需要开发工具来检测和挂载C-Store块设备。 PG Reactor接口开发 正在开发足够的接口，以便实现独立的PG Reactor。 需要定义正确的原语接口。 Sprite LFS策略实施 实施了Sprite LFS策略，但发现段清理器清理速度不够快。 增加了段清理器在单个GC周期内可以回收的数据量。 遇到了处理写操作时的另一个问题，已提交PR解决。 决定事项 确认需要支持将OSD元数据写入特定目录的功能。 计划模仿BlueStore的文件布局和分区策略。 需要开发工具来检测和挂载C-Store块设备。 后续行动计划 为新发现的bug创建单元测试。 继续开发和完善PG Reactor接口。 解决Sprite LFS策略实施中的问题，并优化段清理器的性能。 会议结束 会议在确认所有议题讨论完毕后结束。 祝愿所有参与者有一个愉快的一周。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-10-21","slug":"Ceph_Performance_Meeting_2021-10-21","date":"2021-10-20T16:00:00.000Z","updated":"2021-10-21T16:00:00.000Z","comments":true,"path":"2021/10/21/Ceph_Performance_Meeting_2021-10-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/21/Ceph_Performance_Meeting_2021-10-21/","excerpt":"","text":"会议纪要 关键细节 新PR讨论：本周有一个关于backfill和recovery性能的新PR，由用户“gun”提交。该PR针对特定情况，即新OSD需要从主OSD进行完整复制，且主OSD的PG日志条目数小于OSD最小PG日志条目数时，新OSD可以通过PG日志进行恢复。该方法通过backfill处理比recovery更快，因为recovery涉及更多额外工作。Mia将审查该PR。 已关闭的PR：四个PR已关闭，包括TTL缓存、async messenger帧消息头优化、OSD压缩绕过和Adam的BlueFist fine green locking PR。其中，BlueFist PR在测试中导致锁定失败，但Adam正在处理。 更新的PR：三个PR已更新，包括MDS的树移除PR和两个库D优化PR。这些PR需要重新审查。 性能优化：Jeff Layton提交了内核客户端的修复，可能解决之前观察到的3GB/s瓶颈问题。使用自旋锁替代不必要的互斥锁，Ilia将审查并进行测试，目标是达到8GB/s的性能。 GDB PMP问题：GDB PMP在多线程环境下导致经典OSD崩溃，Adam开发了一个使用live unwind的新版本，速度更快但代码复杂。目前正在尝试结合lib unwind和lib dw进行优化。 讨论的主要议题 Backfill与Recovery性能优化：讨论了新PR中提出的backfill与recovery性能优化方法。 PR状态更新：回顾了已关闭和更新的PR，特别是涉及性能优化和锁定的PR。 内核客户端性能瓶颈：讨论了Jeff Layton提交的修复，旨在解决内核客户端的性能瓶颈。 GDB PMP的替代方案：讨论了GDB PMP的问题及其替代方案，包括Adam的新版本和结合lib unwind与lib dw的尝试。 决定的事项 审查新PR：Mia将审查关于backfill和recovery性能的新PR。 测试性能优化：Ilia将审查并测试Jeff Layton提交的内核客户端修复。 继续优化GDB PMP替代方案：继续探索和优化GDB PMP的替代方案，结合lib unwind和lib dw。 后续行动计划 审查和测试PR：继续审查和测试所有相关的PR，确保代码质量和性能。 性能测试：进行详细的性能测试，特别是内核客户端的修复和GDB PMP的替代方案。 代码优化：持续优化代码，特别是涉及锁定的部分和性能瓶颈的解决。 结束语 会议在讨论了各项PR的状态和性能优化措施后结束，团队成员将继续跟进相关工作，确保项目的稳定性和性能提升。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-10-19","slug":"Ceph_Orchestrator_Meeting_2021-10-19","date":"2021-10-18T16:00:00.000Z","updated":"2021-10-19T16:00:00.000Z","comments":true,"path":"2021/10/19/Ceph_Orchestrator_Meeting_2021-10-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/19/Ceph_Orchestrator_Meeting_2021-10-19/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 周会 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： NFS 功能缺失讨论 讨论了 NFS LGW 导出功能在 self-ansible 支持中的缺失，特别是导出单个桶和一组关联到单个用户的桶的能力。 确认当前 Ceph 的 NFS 模块仅支持在桶级别导出，且用户总是桶的所有者。 提议增加功能，允许通过用户名创建导出，以便用户可以导出其所有的桶。 CLI 命令调整 讨论了 NFS 导出创建命令的参数顺序问题，建议调整以提高直观性。 决定即使可能破坏向后兼容性，也要改进 CLI 命令，确保用户使用命名参数而非依赖顺序。 Rook 支持讨论 询问了 Rook 是否支持类似 NFS LGW 用户的导出功能，确认 Rook 支持定义 NFS 服务器，但导出管理不涉及。 ELSO 项目进展 讨论了 ELSO 项目的进展，特别是与 Topol VM 和 Top LVM Operator 的集成。 确认 Top LVM 项目社区活跃，但 Topol VM Operator 社区不理想，可能需要重新设计或创建新的 Operator。 计划与 Topol VM Operator 团队进行会议，讨论可能的贡献和必要的更改。 决定事项： 改进 NFS 导出功能的 CLI 命令，增加通过用户名导出的能力。 确保用户在使用 CLI 时使用命名参数，以适应可能的命令调整。 安排与 Topol VM Operator 团队的会议，讨论项目贡献和设计更改。 后续行动计划： 实施 NFS 导出功能的改进，包括 CLI 命令的调整。 跟进与 Topol VM Operator 团队的会议，确定项目贡献和设计更改的可行性。 监控 Rook 对 NFS 导出功能的支持情况，确保与 Ceph 的集成顺畅。 备注： 会议中提到的技术术语和项目名称（如 Ceph, NFS, Rook, Topol VM, Top LVM）保持英文原文，以确保专业性和准确性。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-10-13","slug":"Ceph_Crimson_SeaStore_2021-10-13","date":"2021-10-17T16:00:00.000Z","updated":"2021-10-18T16:00:00.000Z","comments":true,"path":"2021/10/18/Ceph_Crimson_SeaStore_2021-10-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/18/Ceph_Crimson_SeaStore_2021-10-13/","excerpt":"","text":"会议纪要 关键细节 多设备PR合并：上周主要工作是合并多设备PR，目前已成功合并。 缓存LRU工作：继续进行缓存LRU的工作，并开始审查三星Chennai的大随机写入PR。 技术测试：开始进行技术测试，但由于无法设置OpenVPN，使用团队内部的Tesla测试环境进行测试。 代码构建与系统测试：仍在构建代码并尝试运行系统测试，但尚未完成构建。 DB's Messenger审查：花费时间审查DB's Messenger，未发现重大问题，计划开始研究watch notify机制。 LFS策略测试：尝试测试spreader LFS策略，但尚未成功运行，仍在解决遇到的问题。 性能优化与PR审查：审查多设备PR，并继续工作于合并日志头以减少写入开销，同时关注批处理和自动化压力测试工具。 测试场景准备：准备了测试场景并与团队共享，计划本周继续进行相关测试。 讨论的主要议题 技术测试环境：讨论了技术测试环境的设置问题，决定使用团队内部的Tesla测试环境。 代码构建与测试：讨论了代码构建和系统测试的进展，强调了测试的重要性。 性能优化与PR审查：讨论了性能优化和PR审查的进展，强调了批处理和自动化压力测试工具的重要性。 测试场景准备：讨论了测试场景的准备和共享，强调了测试场景的重要性。 决定的事项 使用团队内部的Tesla测试环境进行技术测试。 继续进行代码构建和系统测试。 开始研究watch notify机制。 继续进行性能优化和PR审查。 继续进行测试场景的准备和共享。 后续的行动计划 继续进行多设备PR的审查和合并。 继续进行缓存LRU的工作。 继续进行技术测试，并解决遇到的问题。 继续进行代码构建和系统测试。 开始研究watch notify机制。 继续进行性能优化和PR审查。 继续进行测试场景的准备和共享。 其他 会议结束时，团队成员互相祝愿有一个愉快的一周。 关键词 Multi-device PR Cache LRU Random Write PR OpenVPN Tesla Testing System Testing DB's Messenger Watch Notify Spreader LFS Performance Optimization PR Review Test Scenarios 会议总结 本次会议主要讨论了多设备PR的合并、缓存LRU的工作、技术测试环境的设置、代码构建与系统测试、性能优化与PR审查以及测试场景的准备。团队成员分享了各自的进展和遇到的问题，并讨论了后续的行动计划。会议结束时，团队成员互相祝愿有一个愉快的一周。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Real-Time Data Anonymization the Serverless Way Demo","slug":"Real-Time_Data_Anonymization_the_Serverless_Way_Demo","date":"2021-10-17T16:00:00.000Z","updated":"2021-10-18T16:00:00.000Z","comments":true,"path":"2021/10/18/Real-Time_Data_Anonymization_the_Serverless_Way_Demo/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/18/Real-Time_Data_Anonymization_the_Serverless_Way_Demo/","excerpt":"","text":"会议纪要 会议主题：CubeCon 2021实时数据项化演示 会议时间：2021年 会议地点：CubeCon 2021 主讲人：[主讲人姓名] 会议内容总结： 演示目的： 展示如何在将图像上传到Ceph存储系统时，自动模糊人脸和车牌。 技术栈与工具： 存储系统：Ceph 配置与部署：使用Rook Operator 服务器less函数：基于KDA Serverless框架 消息通知：通过RabbitMQ消息总线传递，由Private MQ Operator部署 系统配置与部署流程： 从干净的MicroShift节点开始，使用GitHub上的代码进行配置和部署。 安装Rook Operator，包括基础组件和开发者构建的YAML文件。 部署Steph集群，包括OSDs和其他存储后端。 安装Redis网关和对象存储前端，以及必要的工具箱。 创建存储桶： 创建存储桶需要先定义存储类，然后通过对象存储桶声明（Object Bucket Claim）进行配置。 配置特殊标签以关联通知，使用开发者构建以允许明文传输RabbitMQ用户和密码。 配置环境参数： 设置Redis网关服务名称和访问密钥。 安装RabbitMQ Operator并创建RabbitMQ实例。 配置RabbitMQ： 清理并声明交换机，配置队列绑定和路由键。 创建Ceph存储桶主题的CRD，定义通知的端点和参数。 安装和配置KDA： 使用Helm安装KDA，定义服务器less函数以执行模糊处理。 创建必要的秘密文件以提供凭证，确保服务器less函数能够访问Redis网关。 演示上传图像： 上传图像后，系统会发送通知到RabbitMQ，KDA会启动RabbitMQ消费者进行模糊处理。 查看日志确认模糊处理成功，并将处理后的图像上传回Ceph存储桶。 决定事项： 确认演示中使用的所有组件和配置均正常工作，确保系统的稳定性和可靠性。 后续行动计划： 收集反馈并解答与会者的疑问。 根据反馈进一步优化系统配置和部署流程。 会议结束语： 主讲人感谢大家的参与，并欢迎提出任何问题和反馈。 注： 会议中提到的技术术语和工具（如Ceph, Rook, KDA, RabbitMQ等）均为计算机科学和分布式存储领域的专业术语，保留原文以确保准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-10-12","slug":"Ceph_Orchestrator_Meeting_2021-10-12","date":"2021-10-11T16:00:00.000Z","updated":"2021-10-12T16:00:00.000Z","comments":true,"path":"2021/10/12/Ceph_Orchestrator_Meeting_2021-10-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/12/Ceph_Orchestrator_Meeting_2021-10-12/","excerpt":"","text":"会议纪要 会议概览 本次会议主要讨论了Ceph Orchestrator的多个议题，包括Cephadm集成、容器注册表管理、Manila与Ceph及Ganesha的交互等。 主要议题及讨论内容 Cephadm集成 冬季项目已经开始，Cephadm已添加了新的集成功能。 已有两名学生对项目感兴趣，期待更多集成到视频中的可能性。 容器注册表管理 讨论了如何处理容器注册表版本列表，特别是自定义注册表与上游注册表的差异。 探讨了使用Python库与Docker注册表交互的可行性，但存在维护问题。 讨论了是否需要列出所有标签，以及如何处理最新标签的更新。 Manila与Ceph及Ganesha的交互 讨论了Manila如何通过Orchestrator与Ceph及Ganesha交互，特别是通过CLI还是API。 探讨了权限问题，特别是非管理员用户如何执行CLI命令。 讨论了如何更新Ganesha配置文件的部分内容，以及如何获取当前Ganesha demon的状态描述。 决定事项 继续探索Cephadm的新集成功能，并鼓励更多学生参与。 确定使用CLI作为与Orchestrator交互的主要方式，尽管也考虑了API的可能性。 确认了非管理员用户执行CLI命令所需的权限，并计划进一步细化这些权限。 后续行动计划 继续开发和测试Cephadm的新集成功能。 进一步研究如何通过CLI或API与Orchestrator进行更有效的交互。 细化非管理员用户的权限设置，确保Manila能够安全地与Ceph及Ganesha交互。 探索如何更好地管理和更新Ganesha配置文件，以及如何获取和展示Ganesha demon的当前状态。 其他讨论点 讨论了Ingress demon的状态和其在生产环境中的适用性。 探讨了如何处理Orchestrator命令的异步性质，以及如何确保数据路径的连续性。 会议结束 会议在讨论了所有议题后圆满结束，参与者对未来的工作方向有了更清晰的认识。 感谢所有参与者的贡献，并期待下周的进一步讨论和进展。 以上是本次Ceph Orchestrator会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-10-06","slug":"Ceph_Developer_Monthly_2021-10-06","date":"2021-10-07T16:00:00.000Z","updated":"2021-10-08T16:00:00.000Z","comments":true,"path":"2021/10/08/Ceph_Developer_Monthly_2021-10-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/08/Ceph_Developer_Monthly_2021-10-06/","excerpt":"","text":"会议纪要 会议主题：Ceph 十月会议 主要议题： 遥测与性能信息 SMR 驱动器的 Boost 支持 RBD 镜像公主集成 讨论内容： 1. 遥测与性能信息 背景：遥测模块收集用户集群的匿名数据，用于帮助开发者了解集群使用情况和识别问题。 性能通道（Perf Channel）： 收集内容：包括性能计数器、OSD 性能直方图、I/O 速率、每个池的统计总和等。 目的：帮助开发者理解集群整体使用情况，发现操作分布，识别集群使用变化，以及系统是否按预期执行。 客户用途：客户可以使用性能通道来揭示集群整体健康状况的详细上下文，识别工作负载模式，故障排除延迟、限流或内存管理问题，以及监控集群性能。 决定事项： 决定从按池收集改为按单个 PG 级别收集统计总和。 移除池名称以保护匿名性。 后续行动： 添加新的指标如 mempool 和 RocksDB 压缩统计。 讨论数据不可用性的检测和相关指标的收集。 2. SMR 驱动器的 Boost 支持 当前状态：内部元数据跟踪已实现，简单清理器已实现，Boost 可以在 SMR 硬盘上成功运行。 下一步： 确定如何构建，考虑是否添加 libzbd 库依赖。 实现更智能的清理策略。 考虑如何使用常规区域，可能让 BlueFS 使用顺序区域。 解决 fs_check 中的内存使用问题。 为 SMR 驱动器创建不同的 OSD 类别。 3. RBD 镜像公主集成 目标：启用用户监控异步复制的健康状况，检测异常，并提供跨集群复制的统一方式来传递指标和警报。 实现方式：使用 Prometheus 作为消费者，通过 HTTP 端点暴露指标。 挑战与决定： 考虑使用 Prometheus C++ 库或自定义实现。 讨论了高可用性、安全性和服务发现的问题。 决定不引入新的 Web 服务器模块，而是考虑使用 Boost Beast。 后续行动计划： 完成遥测模块的改进，特别是性能通道的指标收集和数据不可用性的检测。 继续 SMR 驱动器支持的工作，包括构建和清理策略的优化。 推进 RBD 镜像集成的工作，特别是 Prometheus 端点的实现和统一指标的制定。 结论： 会议讨论了多个关于 Ceph 的重要议题，包括遥测、性能优化、SMR 驱动器支持和 RBD 镜像集成。每个议题都有明确的下一步行动计划，旨在提高 Ceph 的性能和可用性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-10-07","slug":"Ceph_Performance_Meeting_2021-10-07","date":"2021-10-07T16:00:00.000Z","updated":"2021-10-08T16:00:00.000Z","comments":true,"path":"2021/10/08/Ceph_Performance_Meeting_2021-10-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/08/Ceph_Performance_Meeting_2021-10-07/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于Ceph存储系统的开发进展和讨论。会议开始于两周前的一个拉取请求（Pull Request, PR）总结之后，主要回顾了过去两周内的PR动态和相关讨论。 主要议题和讨论内容 新PR和更新 一个关于优先级现金（priority cash）的缓存年龄分箱（cash age binning）的更新实现。 讨论了LRU缓存实现中的问题，特别是在roxdb块缓存中的一些更改可能导致轻微的损坏。 已关闭的PR 一个关于Prometheus管理器模块的PR，提供了禁用缓存的能力。 一个旧版本的缓存分箱PR被关闭，取而代之的是一个更新和重新基于的版本。 更新中的PR Neha对管理器TTL缓存实现的审查，以及基于她反馈的进一步讨论和更新。 Igor的PG移除优化PR，之前有测试失败的记录，目前仍在计划中。 关于头解码优化的讨论，由Iliad进行审查，有一些额外的讨论和更新。 一个关于从日志中移除子树映射的大PR，由于其复杂性，需要更多的设计文档和讨论。 其他讨论 关于内存使用问题的讨论，特别是在某些节点上发现的大量不可释放内存，可能与创建和销毁大量cgroup时的上游内核bug有关。 缓存年龄分箱的性能影响讨论，虽然有时会有性能提升，但也可能会有损失，主要原因是高估了缓存omap数据的重要性。 决定事项 继续审查和测试缓存年龄分箱的实现，特别是解决可能导致SIG故障的问题。 对于大且复杂的PR，如子树映射移除，需要更多的设计文档和讨论，可能考虑分解为更小的部分。 后续行动计划 继续进行缓存年龄分箱的测试和审查，确保其稳定性和性能。 对于大PR，如子树映射移除，准备设计文档和进一步的讨论，可能分解为更小的可管理部分。 关注内存使用问题，特别是与cgroup相关的内核bug，可能需要进一步的研究和解决。 其他 讨论了关于缓存行为的未来改进和可能的优化方向，包括考虑预分配内存和更静态的内存管理策略。 探讨了应用程序提供缓存提示的可能性，以优化缓存行为。 会议结束 会议在讨论了所有议题后结束，没有其他待讨论的事项。会议参与者将在后续的会议中继续跟进这些议题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: MDS Journal Machinery","slug":"CephFS_Code_Walkthrough_-_MDS_Journal_Machinery","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/CephFS_Code_Walkthrough_-_MDS_Journal_Machinery/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/CephFS_Code_Walkthrough_-_MDS_Journal_Machinery/","excerpt":"","text":"会议纪要 会议主题：Ceph MDS 日志结构与优化讨论 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： MDS 日志概述： MDS 日志（Metadata Journal）是 MDS（Metadata Server）的主要元数据变更持有者。 任何需要持久化的元数据变更都会记录在 MDS 日志中。 日志包含近期元数据变更、客户端会话信息、导出导入状态、清除状态同步等。 客户端会话信息： 新客户端连接时，MDS 会记录会话信息到日志中，这对故障恢复特别重要。 MDS 需要知道所有连接的客户端，以确保客户端重新获取其 caps 并重新建立状态。 日志结构与管理： MDS 日志在逻辑上是一个循环缓冲区，但在物理上只占用有限的对象集。 日志对象的大小通常为 4MB，当一个日志对象满后，MDS 会移动到下一个日志对象。 日志指针： 日志指针是一个双指针结构，用于指示当前 MDS 日志的位置。 日志指针的存在是为了便于进行灾难恢复或日志重置。 日志头部信息： 日志头部包含写入位置、过期位置和修剪位置等信息，这些信息用于管理日志对象的生命周期。 日志事件类型： 日志事件包括子树映射、新会话信息、caps 更新等。 子树映射事件在每个新日志段开始时写入，以简化数据恢复。 日志优化： 近期优化包括将打开文件表移出 MDS 日志，以减少日志大小和提高 MDS 故障转移时间。 未来可能的优化包括将递归 unlink RPC 移出日志，以及重新考虑客户端会话的日志记录方式。 代码实现讨论： 讨论了 osdc 库中的日志管理代码，包括日志指针对象、日志头部对象和日志事件的处理。 强调了日志恢复和重放的逻辑，以及如何处理日志事件的持久化。 决定事项： 需要进一步审查和可能合并 Jung 的 PR，该 PR 旨在将子树映射移出 MDS 日志，以解决性能和可扩展性问题。 后续行动计划： 继续审查和测试 Jung 的 PR，确保其对 MDS 性能的提升。 考虑未来对 MDS 日志的其他潜在优化，如客户端会话管理和递归 unlink RPC 的处理。 会议结束： 会议在讨论了所有议题后结束，感谢所有参与者的参与，并约定下次会议时间。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: Paddles","slug":"Ceph_Code_Walkthroughs_-_Paddles","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Code_Walkthroughs_-_Paddles/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Code_Walkthroughs_-_Paddles/","excerpt":"","text":"会议纪要 会议概要 本次会议是一个代码走查，主要介绍Paddles，这是我们集成测试框架的关键组件。Paddles是一个数据库包装器，用于存储和处理测试节点信息、任务状态更新等。 讨论的主要议题 Paddles简介： Paddles是一个数据库包装器，用于存储Toothology运行和任务信息，以及所有测试节点信息。 使用PostgreSQL作为数据库。 Toothology任务调度流程： Toothology调度器将任务添加到Beanstalk队列，并返回一个唯一的任务ID。 任务ID和任务配置参数存储在PostgreSQL中。 任务状态更新也通过Paddles进行。 Paddles的模块结构： 使用轻量级Web框架Pecan，遵循MVC模式。 主要关注模型和控制器部分。 模型定义数据库操作函数，如启动事务、提交和回滚。 控制器使用对象分派路由策略，将HTTP请求映射到控制器和方法。 Paddles的配置和启动： 配置文件包含服务器特定配置，如主机、端口、Pecan应用配置等。 使用Pecan的transaction hook处理数据库事务。 模型和控制器详细介绍： 模型部分定义了节点、任务和运行的表结构和操作。 控制器部分处理HTTP请求，如获取节点信息、锁定和解锁节点、创建和更新任务等。 Alembic数据迁移框架： 用于在不停止运行的情况下修改数据库模式。 通过创建修订号来管理数据库模式的版本。 测试和部署： 使用Green Unicorn作为生产环境的服务器，启动多个进程处理请求。 编写了多个测试用例，包括模型测试和控制器测试，以及复杂的并发更新测试。 Paddles的持续改进： 正在添加排队机制，以消除对Beanstalk的依赖。 新的排队机制允许在任务排队后更新任务优先级等特性。 决定的事项 确认Paddles的关键功能和结构，以及其在Toothology集成测试框架中的作用。 确认使用Alembic进行数据库模式迁移的方法。 确认使用Green Unicorn进行生产环境部署的方法。 后续行动计划 继续开发和完善Paddles的排队机制。 持续进行代码测试和优化，确保系统的稳定性和性能。 定期进行代码走查和知识分享，以提高团队的技术水平和协作效率。 其他 鼓励团队成员在会议录像中留下问题或评论，以便进一步讨论和澄清。 计划在下个月进行另一个代码走查，具体主题待定。 本次会议详细介绍了Paddles的架构和功能，以及其在Toothology集成测试框架中的应用。通过本次会议，团队成员对Paddles有了更深入的了解，并为后续的开发和优化工作奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-09-29","slug":"Ceph_Crimson_SeaStore_2021-09-29","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Crimson_SeaStore_2021-09-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Crimson_SeaStore_2021-09-29/","excerpt":"","text":"会议纪要 关键细节 修复pin crash问题：上周推送了一个补丁，修复了至少一个pin crash问题，该问题已得到父级处理。 处理weight hard limits crash和segment cleaner问题：即将推送一个PR，解决weight hard limits crash和segment cleaner问题。关键在于在执行out-of-line segment writes之前检查segment cleaner的full status，并允许多个out-of-line segment writes。 缓存LRU优化：计划优化缓存LRU，以实现更有意义的recaching。 日志批处理优化：正在研究日志批处理，已验证可以将写回列表放入队列并合并到更大的缓冲区列表中，然后调用正确的缓冲区。 讨论的主要议题 日志批处理策略：讨论了是否使用定时器或阈值来触发大缓冲区写入磁盘的问题。建议不使用定时器或阈值，而是在没有写入操作时立即写入缓冲区中的数据。 日志批处理实现细节：讨论了如何处理日志批处理中的缓冲区交换和写入操作，以及如何避免在段滚动时写过段末尾的问题。 决定的事项 日志批处理策略：决定不使用定时器或阈值，而是在没有写入操作时立即写入缓冲区中的数据。 日志批处理实现：决定在写入操作完成时，立即将缓冲区中的数据写入磁盘，并在段滚动时确保不写过段末尾。 后续的行动计划 推送PR：即将推送一个PR，解决weight hard limits crash和segment cleaner问题。 优化缓存LRU：继续优化缓存LRU，以实现更有意义的recaching。 日志批处理优化：继续研究日志批处理，确保实现细节符合讨论的策略。 实现集群日志：正在实现集群日志功能，并准备提交一个draft PR。 其他事项 代码审查：承诺尽快完成对其他PR的审查。 多设备支持PR修改：根据建议修改了多设备支持PR，并实现了PC和距离放置策略。 会议结束 会议结束时，大家互相道别，祝愿对方有美好的一天或晚上。 关键词 pin crash weight hard limits crash segment cleaner out-of-line segment writes cache LRU journal batching file store journal segment roll multi-device support PR PC and distance placement strategy cluster log 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-10-07","slug":"Ceph_Crimson_SeaStore_2021-10-07","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Crimson_SeaStore_2021-10-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Crimson_SeaStore_2021-10-07/","excerpt":"","text":"会议纪要 会议时间 日期：具体日期未提供 时间：具体时间未提供 参会人员 主持人：未明确 参会人员：会议中提到的有Schwein、Barth、Greg、Doodle、Chen May等 主要议题及讨论内容 Schwein的设备PR审查 主持人正在审查Schwein的设备PR，并已推送了一些清理代码的提交。 目前还在审查最后的提交，预计在接下来的20到30分钟内重新推送一个实际可运行的版本。 强调了编译器的重要性，例如通过直接暴露段（segment）来简化复合4位28位组合的转换。 Barth的集群问题 Barth尝试使用上游构建版本17.0.0-7998启动集群，但遇到添加OSD的问题。 建议Barth创建一个包含详细步骤的bug报告，以便进一步调查。 讨论了如何从Shaman下载构建版本的问题，建议询问Mark。 三手（Three Hand）的多设备PR和日志批处理PR 讨论了多设备PR和更新日志批处理PR，但发现对延迟没有改善，反而变得更糟。 使用perf工具进行性能分析时遇到问题，建议进一步研究如何使用perf。 讨论了日志批处理代码是否实际进行批处理的问题，建议观察磁盘统计数据以验证。 C-Store在Toothology中的应用 强调了将C-Store OSD引入Toothology的重要性，建议开始进行相关测试。 提供了访问实验室的wiki链接，以便开始相关工作。 Greg的工作进展 Greg正在研究Ciladb如何处理消息传递，以便在多反应器工作中避免潜在问题。 Doodle的工作进展 Doodle在国庆假期期间没有太多进展，计划下周继续推进Sprite LFS GC和范围放置策略的工作。 Chen May的培训资源 提供了一些YouTube视频链接，帮助Chen May熟悉相关技术和环境。 决定事项 Barth需要创建一个详细的bug报告，以便进一步调查集群启动问题。 需要进一步研究perf工具的使用，以解决性能分析中的问题。 开始进行C-Store OSD在Toothology中的测试工作。 后续行动计划 Barth创建bug报告并提供详细步骤。 继续研究perf工具的使用，并观察磁盘统计数据以验证日志批处理代码的效果。 开始C-Store OSD在Toothology中的测试工作，并访问提供的wiki链接以获取实验室访问权限。 其他 会议结束时，主持人祝愿大家有一个愉快的晚上/白天，并期待下周再见。 结束语 会议结束，期待下周的进展和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-10-05","slug":"Ceph_Orchestrator_Meeting_2021-10-05","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Orchestrator_Meeting_2021-10-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Orchestrator_Meeting_2021-10-05/","excerpt":"","text":"会议纪要 会议主题：Ceph 存储系统相关问题讨论 参会人员：Ceph 研发团队 会议日期：[具体日期] 会议内容： Indiana Loopback 配置问题 讨论内容： 发言人分享了关于 Indiana Loopback 配置的最新进展。 在 CentOS 8 内核上，所有功能运行良好，但配置工具 nvme-cli 使用不便，需要安装特定包并处理复杂的 JSON 配置。 在 Ubuntu 系统上，默认内核不支持 NVMe Loopback，存在 bug，需要寻找更好的内核版本。 决定事项： 需要进一步研究并选择合适的内核版本以支持 NVMe Loopback。 后续行动： 编写技术任务文档，指导如何在 LVM LVS 前端添加 NVMe Loopback 配置。 测试相关功能，确保驱动组和设备应用的重装 OSDs 功能正常。 Dashboard 监控堆栈问题 讨论内容： 讨论了在 Rook 项目中，如何手动配置 Dashboard 监控堆栈以支持 Grafana 和其他管理工具。 默认情况下，这些功能在 Rook 启动的 Ceph 集群中未启用。 决定事项： 需要提供详细的文档和步骤，指导用户手动配置监控堆栈。 后续行动： 提供演示视频和文档，帮助用户理解和配置监控堆栈。 其他讨论： 确认了设备在 Linux 系统中的表现正常，不会影响正常操作。 确认了监控堆栈配置的问题，并提出了相应的解决方案。 会议总结： 本次会议主要解决了 Indiana Loopback 配置和 Dashboard 监控堆栈的问题，并制定了相应的后续行动计划。 会议结束时，团队成员确认没有其他紧急议题需要讨论。 会议结束： 会议在确认所有议题讨论完毕后结束，团队成员感谢彼此的参与并祝愿大家工作顺利。 备注： 会议记录由视频会议字幕总结人员整理，保留了部分计算机科学/Ceph 相关领域英文原文的关键词。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-09-28","slug":"Ceph_Orchestrator_Meeting_2021-09-28","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Orchestrator_Meeting_2021-09-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Orchestrator_Meeting_2021-09-28/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 参与者: [参与者名单] 主持人: [主持人姓名] 主要议题 Rook 和存储类（Storage Classes） 讨论内容: 需要创建支持存储类的OSD（Object Storage Daemon）。 当前设备清单不足以满足需求，需要新的Orchestrator API来暴露存储类的名称。 讨论了如何在Rook中实现存储类，包括在CRD（Custom Resource Definition）中的存储部分设置存储类。 决定事项: 需要一个新的Orchestrator API来列出集群中可用的存储类。 需要在驱动组属性中添加存储类。 后续行动: 开发新的Orchestrator API。 与Dashboard团队讨论如何在界面上展示存储类。 Rook与Ceph的兼容性测试 讨论内容: 过去一年中，Ceph的某些更改导致Rook出现问题。 需要确保Ceph发布前能够进行Rook的兼容性测试。 决定事项: 请求在Ceph发布前进行Rook的兼容性测试。 后续行动: 与Ceph团队沟通，确保Rook的兼容性测试纳入Ceph的发布流程。 HAProxy与IPVS 讨论内容: 讨论了使用IPVS作为L4负载均衡器的可行性，以提高读取流量的可扩展性。 讨论了IPVS的直接服务器返回（DSR）功能及其在不同网络环境下的应用。 决定事项: 将IPVS作为L4负载均衡选项纳入考虑。 后续行动: 进一步研究IPVS的实现细节，并在后续版本中考虑实施。 未来规划 讨论内容: 讨论了Ceph的未来版本（如Quincy）的规划和需求。 决定事项: 需要进一步讨论和规划Ceph的未来版本。 后续行动: 在Trello板上添加相关议题，以便后续讨论。 其他事项 会议记录: 会议记录已添加到会议材料中。 下次会议: 下次会议将在下周举行。 行动计划 开发新的Orchestrator API以支持存储类。 与Ceph团队沟通，确保Rook的兼容性测试纳入Ceph的发布流程。 进一步研究IPVS的实现细节，并在后续版本中考虑实施。 在Trello板上添加相关议题，以便后续讨论。 会议结束 时间: [具体结束时间] 下次会议: [下次会议的具体日期和时间] 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-09-23","slug":"Ceph_Performance_Meeting_2021-09-23","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-06T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Performance_Meeting_2021-09-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Performance_Meeting_2021-09-23/","excerpt":"","text":"会议纪要 主要议题与更新 RocksDB LRU缓存更新 问题：自定义的RocksDB LRU缓存实现与新版本的RocksDB不兼容。 解决：Kifu修复了接口问题，并已合并到主分支。 讨论：对于维护者使用最新版本的RocksDB进行编译表示担忧，建议避免用户使用未经测试的版本。 RGW OSD压缩绕过 状态：Casey上周审查通过，已重新基于最新版本，接近合并状态。 BlueStore Fighting Green Locking 更新：Adam更新并由Sage审查，主要是小改动。 讨论：需要进一步审查，特别是与Gabby相关的问题。 BlueStore增量更新模式 状态：正在进行测试，已更新以修复错误。 TTL缓存实现 请求：请求对管理模块的TTL缓存实现进行审查。 状态：已修复make check问题，可能需要再次审查。 PG移除优化 更新：Igor的PR有额外审查和测试，讨论了是否需要为硬盘优化。 状态：测试失败，需要进一步审查。 其他更新 MDS相关的新PR需要重新基于最新版本。 RGW团队的共享对象缓存PR正在等待进一步处理。 MemStore清理PR目前不紧急。 行动计划 RocksDB版本使用 确认Fedora和其他前沿发行版是否使用最新版本的RocksDB，并建议避免使用未经测试的版本。 PR审查与合并 继续审查和测试RGW OSD压缩绕过、BlueStore Fighting Green Locking、BlueStore增量更新模式等PR。 确保Igor的PG移除优化PR通过测试并进行必要的审查。 论文讨论准备 下周将讨论Josh推荐的关于重构Linux存储栈的论文。 建议与会者提前阅读论文，并准备三个关键的讨论点。 后续会议 下周会议将重点讨论关于Linux存储栈重构的论文，建议与会者提前准备并分享三个关键的讨论点。 其他事项 会议中提到的其他PR和项目将继续跟踪和处理，确保及时更新和审查。 会议结束 感谢所有参与者的贡献，期待下周的会议讨论。祝大家一周愉快！ 以上是本次会议的纪要，涵盖了关键的讨论点、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-09-30","slug":"Ceph_Performance_Meeting_2021-09-30","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Performance_Meeting_2021-09-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Performance_Meeting_2021-09-30/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了一篇关于分布式存储系统性能优化的论文。会议参与者包括核心研发人员和相关领域的专家，共同探讨了论文的内容、其在Ceph存储系统中的潜在应用以及后续的行动计划。 讨论的主要议题 论文内容回顾： 论文详细介绍了两种应用程序类别：L-apps（延迟敏感型应用）和T-apps（吞吐量敏感型应用）。 论文提出了一种新的内核块队列实现，通过每个核心拥有自己的入口和出口队列来优化I/O调度。 讨论了SPDK（Storage Performance Development Kit）在测试中的表现，以及其在实际应用中的局限性。 Ceph应用场景： 探讨了论文中的技术如何应用于Ceph的Crimson存储引擎，特别是在处理PG（Placement Group）状态迁移和I/O调度方面。 讨论了在Ceph中如何区分和优先处理不同类型的I/O请求，以及如何通过动态队列管理来优化性能。 性能优化策略： 讨论了在Ceph中如何通过分类池（pool）来优化不同类型应用的性能。 探讨了在Ceph中实施请求调度和应用调度的可行性，以及如何平衡延迟和吞吐量。 决定的事项 论文深入研究： 决定进一步研究论文中的技术细节，特别是关于核心入口和出口队列的实现方式。 Ceph应用探索： 计划探索论文中的技术在Ceph中的具体应用，特别是在Crimson存储引擎中的I/O调度和PG状态管理。 性能优化实验： 计划进行一系列实验，以验证论文中的技术在Ceph中的实际效果，特别是在处理延迟敏感和吞吐量敏感的I/O请求时。 后续行动计划 技术验证： 进行实验以验证论文中的技术在Ceph中的实际应用效果。 分析实验结果，评估技术在Ceph中的可行性和性能提升。 代码实现： 根据实验结果，考虑在Ceph中实现论文中的技术，特别是在Crimson存储引擎中。 开发相应的代码，并进行测试和优化。 文档和分享： 编写详细的文档，记录实验过程、结果和实现细节。 在社区中分享研究成果，收集反馈并进行进一步的优化。 其他讨论点 讨论了当前网络堆栈的工作方式，以及是否可以借鉴论文中的技术进行优化。 提到了一篇关于如何通过TCP实现低延迟的论文，建议进一步研究。 会议总结 会议对论文进行了深入的讨论，并探讨了其在Ceph中的应用前景。决定进行进一步的技术验证和实验，以评估论文中的技术在Ceph中的实际效果。会议强调了持续研究和社区合作的重要性，以推动Ceph存储系统的性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2021-09-22","slug":"Ceph_Science_Working_Group_2021-09-22","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-06T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Science_Working_Group_2021-09-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Science_Working_Group_2021-09-22/","excerpt":"","text":"会议纪要 会议基本信息 时间: 会议开始于整点后几分钟 主持人: 未明确提及 参与者: 一群管理Ceph集群的人员，主要在科学或研究计算环境中工作 会议内容概述 会议目的: 开放讨论，分享Ceph集群管理经验，讨论近期影响Ceph集群的问题和挑战。 会议记录: 会议被录制并上传到YouTube频道。 主要讨论议题 新成员介绍: 新成员Joel来自国家太阳能天文台，正在开始Ceph之旅，目前有6PB的存储在Octopus中，主要用于S3服务。 Ceph集群配置和经验分享: Joel询问关于Ceph集群的经验和建议，特别是关于S3服务的性能优化。 讨论了NVMe SSD的使用，特别是在处理大量小对象时的性能问题。 分享了关于Ceph集群在网络故障后的恢复经验，强调了耐心和系统自我恢复的重要性。 Ceph版本升级和硬件问题: 讨论了从Nautilus到Octopus的升级经验。 提到了硬件问题，特别是硬盘和NVMe的固件更新问题，以及这些更新对集群稳定性的影响。 Ceph集群的可用性和恢复: 分享了在网络故障和电源故障后的集群恢复经验，强调了集群的自我恢复能力和数据完整性的重要性。 Ceph的未来发展: 讨论了Ceph的容器化部署和Rocky Linux的使用，以及这些新技术对现有集群管理的影响。 决定事项 继续关注Ceph的最新版本和硬件更新，确保集群的稳定性和性能。 计划进行Ceph版本的升级，特别是从Nautilus到Octopus或Pacific。 后续行动计划 定期举行会议，每两个月一次，下一次会议计划在11月24日。 继续分享和讨论Ceph集群管理的经验和挑战，特别是在处理大规模数据和复杂环境下的性能优化。 其他备注 会议记录和讨论内容将被上传到YouTube频道供后续参考。 鼓励新成员加入并分享他们的经验，以促进知识共享和技术交流。 本次会议为Ceph集群管理人员提供了一个宝贵的交流平台，通过分享经验和讨论问题，有助于提升集群管理的效率和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Ceph at DigitalOcean","slug":"Ceph_Tech_Talk_-_Ceph_at_DigitalOcean","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-07T16:00:00.000Z","comments":true,"path":"2021/10/07/Ceph_Tech_Talk_-_Ceph_at_DigitalOcean/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/07/Ceph_Tech_Talk_-_Ceph_at_DigitalOcean/","excerpt":"","text":"会议纪要 会议主题：DigitalOcean 的 Ceph 使用案例介绍 会议时间：[具体日期] 会议地点：[线上/线下] 主讲人：Alex Merrigan 职位：Senior Engineer at DigitalOcean 团队：Storage Systems Team 会议内容概述： Alex Merrigan 介绍了 DigitalOcean 在存储系统中使用 Ceph 的情况，包括公司的基本信息、Ceph 的使用案例、操作流程、自动化工具以及遇到的一些问题。 关键细节： DigitalOcean 简介： 成立于 [具体年份]，核心理念是简化云资源的配置。 提供多种产品，包括 Droplets（虚拟机）、Block Storage、Spaces（对象存储平台）等。 全球有八个区域的数据中心，最近的重要事件是六个月前的 IPO。 Ceph 使用情况： 用于 Block 和 Object 存储产品，总计 38 个生产集群，其中 37 个在 Nautilus，1 个在 Luminous。 计划将 Image Backups 产品也迁移到 Ceph。 总存储量超过 54 PB，硬件配置包括全闪存和混合存储（HDD 和 QRC Flash）。 选择 Ceph 的原因： 水平扩展能力、自愈能力、强一致性。 性能可接受，且具有可预测性。 支持多种存储产品，简化运维。 Ceph 操作流程： 高度自动化，使用 Ansible Playbooks 和 AWX。 部署 Ceph 使用自定义的 Playbook，支持容器化部署。 监控使用 Ceph Exporter 和 Node Exporter，开发了 Canary 进程进行性能和可用性检查。 自动化工具： Archimedes：自动处理 CRUSH 权重调整。 PgRemapper：用于管理 PG 映射，支持取消回填、优先恢复权重等。 开发了 OSD 生命周期管理工具，包括诊断、部署、升级、移除等功能。 遇到的问题： Ceph 升级过程中的文档不足和一些未预见的问题。 动态重新分片可能导致 RGW 线程耗尽。 Beast 后端的默认线程设置可能不足。 后续行动计划： 继续优化 Ceph 的自动化和监控工具。 加强对 Ceph 升级和测试流程的改进，计划与社区合作。 考虑将更多产品迁移到 Ceph，并优化现有配置。 其他信息： DigitalOcean 正在招聘，感兴趣的候选人可以查看 DigitalOcean 招聘页面。 如有关于会议内容的疑问，可以联系 Alex Merrigan (amerrigan@digitalocean.com)。 会议结束： 感谢所有参与者的参与，祝大家有一个愉快的一天。 以上是根据会议内容整理的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-09-22","slug":"Ceph_Crimson_SeaStore_2021-09-22","date":"2021-10-05T16:00:00.000Z","updated":"2021-10-06T16:00:00.000Z","comments":true,"path":"2021/10/06/Ceph_Crimson_SeaStore_2021-09-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/06/Ceph_Crimson_SeaStore_2021-09-22/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统中的C-Store模块的性能优化、Bug修复以及未来工作计划。与会人员分享了各自的工作进展，并就遇到的问题进行了深入讨论。 主要议题 性能优化与环境搭建 一位成员正在尝试搭建测量环境，以便更好地理解C-Store的性能数据。 另一位成员关注C-Store的放大效应和垃圾回收机制，并已成功搭建ZNS环境。 Bug修复与代码重构 讨论了事务冲突问题的POC解决方案，确认了某些代码重构的必要性。 提及了C-Store的读写延迟问题，特别是在高并发下的性能表现。 技术细节讨论 深入探讨了C-Store的日志批处理（journal batching）需求，以及如何通过批处理优化写入性能。 讨论了C-Store的缓存策略，建议增加LRU缓存机制以改善读取延迟。 后续行动计划 计划更新指标以正确考虑输出线扩展。 将添加并行板条箱条目以跟踪和解决特定任务。 安排了关于多处理（multiprocessing）的会议。 决定事项 确认了C-Store需要进行日志批处理以优化写入性能。 决定在C-Store中增加LRU缓存机制以改善读取延迟。 确定了需要进一步分析和解决的特定Bug。 后续行动计划 实施日志批处理机制。 在C-Store中实现LRU缓存策略。 继续进行性能测试和代码重构。 安排并参与关于多处理的会议。 其他 会议中还讨论了其他技术细节和潜在的改进点，但未形成具体决议。 结论 本次会议为Ceph的C-Store模块的未来发展指明了方向，特别是在性能优化和Bug修复方面。团队将继续努力，以确保Ceph的高效稳定运行。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-09-21","slug":"Ceph_Orchestrator_Meeting_2021-09-21","date":"2021-10-05T16:00:00.000Z","updated":"2021-10-06T16:00:00.000Z","comments":true,"path":"2021/10/06/Ceph_Orchestrator_Meeting_2021-09-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/10/06/Ceph_Orchestrator_Meeting_2021-09-21/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了两个主要议题：Rook Orchestrator的功能实现和监控堆栈的自动部署问题。会议由一位正在恢复中的主持人主持，他强调了自己不会过多发言，但会确保会议顺利进行。 主要议题及讨论内容 Rook Orchestrator的功能实现 当前状态：讨论了Rook Orchestrator的基本功能，包括网络管理和监控器管理等方面。提出了一些细节问题，如是否值得实现某些功能，因为Rook和Ceph的管理方式存在差异。 ISCSI支持：讨论了在Rook Operator中实现ISCSI支持的问题。虽然有一些功能请求，但由于需求不高，目前尚未有实质性进展。会议中提到了可能需要为Windows节点集成实现ISCSI支持，但目前还没有明确的行动计划。 监控堆栈的自动部署：讨论了是否应在Rook Operator中包含自动部署和配置监控堆栈的功能。虽然Rook Operator目前不负责部署第三方应用，但为了提供更好的用户体验，可能会考虑在文档中提供指导和配置说明。 监控堆栈的自动部署 当前挑战：目前Rook Operator不负责部署Prometheus或Grafana等监控组件，仅提供与这些组件集成的资源。 用户需求：用户可能希望在部署Rook Operator时自动配置监控堆栈，以便更好地使用Dashboard。 建议行动：建议在文档中提供详细的部署指导，并在Dashboard中提供相关链接和说明，以便用户自行部署监控组件。 决定事项 Rook Orchestrator的ISCSI支持：目前没有明确的实施计划，将继续关注用户需求和社区讨论。 监控堆栈的自动部署：Rook Operator不会自动部署监控组件，但会在文档中提供详细的部署指导和配置说明。 后续行动计划 完善Rook Orchestrator的功能：继续完善Rook Orchestrator的基本功能，特别是OSD部署和复杂驱动组的支持。 文档更新：更新文档，提供详细的监控堆栈部署指导，并在Dashboard中增加相关链接和说明。 测试和验证：继续进行Rook Orchestrator的测试和验证工作，确保功能的稳定性和可靠性。 其他讨论点 开发环境的最佳实践：讨论了如何在容器化环境中快速迭代和测试Ceph集群的修改，提出了使用共享文件夹和本地构建环境的方法。 容器化构建流程的简化：建议简化容器化构建流程，将Dockerfile直接放入代码库中，减少复杂性和冗余。 会议总结 会议涵盖了Rook Orchestrator的功能实现和监控堆栈的自动部署等关键议题，明确了后续的行动计划和改进方向。通过文档更新和测试验证，将进一步提升Rook Operator的用户体验和功能完整性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-09-16","slug":"Ceph_Performance_Meeting_2021-09-16","date":"2021-09-15T16:00:00.000Z","updated":"2021-09-16T16:00:00.000Z","comments":true,"path":"2021/09/16/Ceph_Performance_Meeting_2021-09-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/16/Ceph_Performance_Meeting_2021-09-16/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph项目的最新进展，包括代码审查、优化提案以及未来的行动计划。会议强调了代码质量和性能优化的重要性，并对一些关键的Pull Requests（PRs）进行了深入讨论。 主要议题 代码审查与合并 优化carriage handling和bufferless c string的PR：由Radic提交，Ilya进行了审查并批准合并。 OSD压缩绕过PR：Casey进行了审查，Eric在测试中发现了一些错误，目前仍在进行中。 BlueFS inode溢出PR：Adam提交的PR，涉及BlueFS的重大改进，需要进一步审查。 RocksDB更新 讨论了更新RocksDB到新版本的PR，但由于编译问题暂时搁置。建议与RocksDB维护者进行沟通，以更谨慎地处理RocksDB的更新。 性能优化 讨论了多个性能优化的PR，包括缓存管理、线程缓存设置等，强调了这些改进对于提升Ceph性能的重要性。 MDS相关讨论 讨论了MDS的多个PR，包括随机分布dirt frags、子树映射优化等，强调了这些改进对于提高MDS性能的重要性。 QoS和内存管理 讨论了MDS的QoS和内存自动调优的PR，强调了这些改进对于提高Ceph整体性能的重要性。 决定事项 代码审查和合并：继续对关键PR进行审查和测试，确保代码质量和性能优化。 RocksDB更新：与RocksDB维护者进行沟通，谨慎处理RocksDB的更新。 性能优化：继续推进性能优化的PR，特别是缓存管理和线程缓存设置。 MDS改进：对MDS相关的PR进行深入讨论和审查，确保这些改进能够有效提升MDS性能。 QoS和内存管理：对MDS的QoS和内存自动调优的PR进行审查和测试，确保这些改进能够有效提升Ceph整体性能。 后续行动计划 代码审查和测试：继续对关键PR进行审查和测试，确保代码质量和性能优化。 与RocksDB维护者沟通：与RocksDB维护者进行沟通，谨慎处理RocksDB的更新。 性能优化推进：继续推进性能优化的PR，特别是缓存管理和线程缓存设置。 MDS改进审查：对MDS相关的PR进行深入讨论和审查，确保这些改进能够有效提升MDS性能。 QoS和内存管理审查：对MDS的QoS和内存自动调优的PR进行审查和测试，确保这些改进能够有效提升Ceph整体性能。 结论 本次会议强调了代码质量和性能优化的重要性，并对一些关键的PR进行了深入讨论。后续将继续推进这些改进，确保Ceph项目的持续发展和性能提升。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-09-15","slug":"Ceph_Crimson_SeaStore_2021-09-15","date":"2021-09-14T16:00:00.000Z","updated":"2021-09-15T16:00:00.000Z","comments":true,"path":"2021/09/15/Ceph_Crimson_SeaStore_2021-09-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/15/Ceph_Crimson_SeaStore_2021-09-15/","excerpt":"","text":"会议纪要 会议开始 会议开始，回顾了上周的工作进展。 工作进展 EPM简化与修复： 上周提交了一个PR，包含了一些EPM（Erasure Code Profile Manager）的简化与修复。 正在努力使Ceph存储工作，预计会有进一步的修复。 二分搜索优化： 完成了针对LB3和OMAP3的二分搜索优化PR。 正在进行关于alpha extent的magics优化。 性能分析与冲突解决： 发现LBA树分配交换过程中CPU周期浪费较多，原因可能是LBA地址过于集中。 计划生成LBA地址的直方图，以便进一步分析。 I/O测试问题： 在进行I/O测试时，偶尔会遇到add ping a dirt的问题，不是每次都会出现。 认为在发布构建中禁用调试日志可能更容易复现问题。 计划继续尝试复现并调试此问题。 新成员介绍： 新成员Sam来自Surf Cuba团队，对Crimson项目感兴趣，将探索相关工作。 设备支持： 上周主要工作是设备支持，预计在一两天内提交PR。 优化与冲突减少： 正在从指标提供结果的角度进行优化。 实施了一种简单但有效的方法来减少owner manager的写入。 正在研究如何减少Onochie的冲突，认为当前的invariant可能过于强，导致冲突增加。 计划开始进行相关清理工作。 讨论与决策 LBA地址分布问题： 讨论了LBA地址过于集中的问题，计划生成直方图进行分析。 冲突与优化： 讨论了如何减少冲突，特别是关于LBA树的冲突问题。 提到了改变invariant可能需要大量重构，但认为值得努力。 额外讨论： 提到了RADOS Q&amp;A会议，鼓励大家参与提问。 后续行动计划 继续进行EPM的简化与修复工作。 生成LBA地址的直方图，分析地址分布情况。 继续尝试复现并调试I/O测试中的问题。 提交设备支持的PR。 开始进行减少冲突的清理工作。 会议结束 会议结束，提醒大家关注RADOS Q&amp;A会议，并祝大家有美好的一天。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-09-14","slug":"Ceph_Orchestrator_Meeting_2021-09-14","date":"2021-09-13T16:00:00.000Z","updated":"2021-09-14T16:00:00.000Z","comments":true,"path":"2021/09/14/Ceph_Orchestrator_Meeting_2021-09-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/14/Ceph_Orchestrator_Meeting_2021-09-14/","excerpt":"","text":"会议纪要 主要议题与讨论内容 Topo LVM 更新与动态配置 讨论了关于邀请外部团队作为 Rook 存储提供商的进展，对方目前不感兴趣。 计划继续探讨 Topo LVM 的动态配置，特别是针对 raw 设备的动态配置。 团队成员 Ron Joseph 等人正在进行 Topo LVM 的原型设计，以更好地理解其集成方式。 自动缩放与平衡模块 讨论了自动缩放和平衡模块的配置选项，建议在升级过程中可能需要禁用平衡器以避免潜在问题。 提出了将禁用平衡器作为可配置选项的建议，特别是在升级过程中遇到错误时。 健康警告与监控恢复 讨论了在失去所有监控集群时的恢复路径，建议增加健康警告机制。 现有手动步骤包括从 OSDs 重建监控，以及通过复制数据来恢复监控。 KCI 环境中的主机维护问题 讨论了 KCI 环境中主机维护模式的问题，初步判断问题可能与 KCLI 无关，需要进一步在管理器中进行调查。 Prometheus 绑定问题 讨论了 Prometheus 绑定到所有接口的问题，建议调整拉取请求以避免覆盖端口，并探索使用不同命令进行活性探测。 Rook 与 Ceph 版本兼容性 讨论了 Joseph 的 NFS 池更改，计划在 Ceph 7 版本中合并，以确保稳定性和兼容性。 ISCSI 配置工具集成 讨论了将 ISCSI 配置工具集成到 Ceph CLI 中的可能性，以便更方便地进行配置。 决定事项 继续推进 Topo LVM 的动态配置研究和原型设计。 在升级过程中考虑禁用平衡器，并将其作为可配置选项。 增加健康警告机制，并完善监控恢复路径。 调查并解决 KCI 环境中的主机维护问题。 调整 Prometheus 绑定问题的拉取请求，并探索新的活性探测方法。 确保 NFS 池更改与 Ceph 7 版本的兼容性。 探索将 ISCSI 配置工具集成到 Ceph CLI 中的可能性。 后续行动计划 继续 Topo LVM 的原型设计和动态配置研究。 实施并测试禁用平衡器的配置选项。 开发和测试健康警告机制及监控恢复路径。 深入调查 KCI 环境中的主机维护问题。 调整 Prometheus 绑定问题的拉取请求，并实施新的活性探测方法。 确保 NFS 池更改与 Ceph 7 版本的兼容性，并进行相关测试。 与 ISCSI 专家合作，探索并实现 ISCSI 配置工具的集成。 结论 会议涵盖了多个关键议题，包括存储提供商合作、动态配置、健康监控、版本兼容性等。团队将继续推进各项议题的研究和实施，确保 Ceph 和 Rook 的稳定性和功能性。感谢所有参与者的贡献，期待后续的进展和成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-09-08","slug":"Ceph_Crimson_SeaStore_2021-09-08","date":"2021-09-10T16:00:00.000Z","updated":"2021-09-11T16:00:00.000Z","comments":true,"path":"2021/09/11/Ceph_Crimson_SeaStore_2021-09-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/11/Ceph_Crimson_SeaStore_2021-09-08/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： Segment Cleaner 问题审查 讨论了Segment Cleaner可能存在的问题，决定进一步详细审查。 对handle split的修复可能解决了某个assert问题，但仍需进一步验证。 性能分析与优化 使用Curve进行性能分析，发现rb allocate exchange占用了约20%的CPU周期。 讨论了LBA树遍历的优化，建议使用二分查找以提高效率。 计划通过perf counter分析迭代次数，以确定性能瓶颈。 Bug修复与功能开发 讨论了多个Bug的修复情况，包括beetry相关问题和extent placement manager PR。 提到了多设备支持工作的进展，以及对seastar教程的改进。 监控与指标收集 讨论了收集和分析IO性能指标的方法，特别是reactor utilization的独特性。 计划进一步优化写放大问题。 决定事项： 对Segment Cleaner进行更详细的审查。 实施二分查找优化LBA树遍历。 通过perf counter分析迭代次数，以确定性能瓶颈。 继续进行Bug修复和功能开发。 后续行动计划： 详细审查Segment Cleaner，并验证handle split修复的效果。 实施二分查找优化，并分析perf counter数据。 继续进行Bug修复和功能开发，特别是多设备支持工作。 收集和分析更多IO性能指标，优化写放大问题。 其他备注： 会议中提到了使用perf counter进行性能分析的具体方法和预期结果。 讨论了seastar教程的改进和vstart的使用体验。 会议结束： 会议在讨论了所有议题后结束，参会人员计划在下周继续跟进相关工作。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-09-07","slug":"Ceph_Orchestrator_Meeting_2021-09-07","date":"2021-09-10T16:00:00.000Z","updated":"2021-09-11T16:00:00.000Z","comments":true,"path":"2021/09/11/Ceph_Orchestrator_Meeting_2021-09-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/11/Ceph_Orchestrator_Meeting_2021-09-07/","excerpt":"","text":"会议纪要 会议主题：本周的Orchestrator周会 参会人员：全体成员 会议时间：本周 主要议题： Agent介绍 - 由Edin进行 Repaving Oasis - 由Cory进行 测试重启 日志聚合需求 会议内容总结： 1. Agent介绍 目的：提高可扩展性和性能，解决当前使用SSH通信的慢速问题。 架构： 管理器将有一个HTTP端点，使用CherryPy。 主机上的Agent将是一个非容器化的systemd单元，直接在主机上运行命令。 Agent将通过HTTP将收集的所有数据发送到管理器。 管理器和Agent之间通过原始套接字通信。 安全性： 需要确保消息加密和身份验证，防止消息被窃听和伪造。 使用HTTPS和自签名证书来确保通信安全。 使用密钥环进行身份验证。 元数据完整性： 需要确保元数据是最新的，避免重复部署守护进程。 使用计数器来确保元数据的时效性。 离线主机处理： 通过超时机制快速检测离线主机。 重新部署Agent以验证主机状态。 2. Repaving Oasis 目的：自动化OSD的重铺过程，例如更改最小分配大小或使用db wal。 方法： 使用现有的驱动组定义来重新部署OSD。 确保设备在释放后能被正确重新部署。 命令： 设想一个新的命令来启动重铺过程，例如ceph osd repave。 测试： 需要验证在混合OSD（SSD和硬盘）情况下的正确行为。 3. 测试重启 目的：避免在重启过程中出现Monmap问题。 方法： 使用现有的压力测试工具（如Thrasher）来测试重启过程。 4. 日志聚合需求 目的：聚合集群中的日志，可能用于支持案例。 讨论： 对于是否需要在管理器模块中实现日志聚合存在分歧。 建议使用外部工具（如EFK堆栈）来处理日志聚合。 决定事项： Agent的架构和安全性细节已经明确，后续将进行进一步的开发和测试。 Repaving Oasis的初步方案已经提出，Cory将开始进行详细设计和开发。 重启测试将使用现有的压力测试工具进行。 日志聚合可能通过外部工具实现，而不是在管理器模块中。 后续行动计划： Edin将继续开发和完善Agent的功能。 Cory将开始Repaving Oasis的详细设计和开发工作。 使用Thrasher进行重启测试。 考虑使用外部工具进行日志聚合，并可能提供相关文档。 会议结束： 感谢大家的参与，下次会议再见。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-09-11","slug":"Ceph_Performance_Meeting_2021-09-11","date":"2021-09-10T16:00:00.000Z","updated":"2021-09-11T16:00:00.000Z","comments":true,"path":"2021/09/11/Ceph_Performance_Meeting_2021-09-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/11/Ceph_Performance_Meeting_2021-09-11/","excerpt":"","text":"会议纪要 关键细节 会议日期: 未明确提及 参会人员: 未明确提及 会议主持: 未明确提及 讨论的主要议题 已合并的PR: Prometheus VR: 允许禁用缓存，已合并。 Omap命名方案限制: Igor提出的PR，用于解决omap列表过大时的内存消耗问题，已合并。 MDS锁切换: MDS锁切换到公平互斥锁以避免饥饿问题，已合并。 更新中的PR: Adam的PR: 实现写操作的直接I/O和读操作的缓冲I/O。讨论了潜在的一致性问题，需要仔细审查。 BlueStore日志增量更新模式: 未通过QA测试。 OSD压缩绕过RGW压缩: 已进入Eric的测试分支。 TTL缓存实现: 管理模块的TTL缓存实现，正在进行中。 优化PG移除PR: Igor的优化PG移除PR，已重新审查。 Ceph Messenger头2解码优化: 已更新，Ilia之前已审查。 MDS从子树映射移除: 从日志中移除MDS从子树映射，Zhang已更新。 性能回归分析: OSD代码分析: 发现了一些性能回归，主要来源包括mclock QoS更改和BlueStore缓冲I/O的默认启用。 Gabby的PR: 移除RocksDB中的分配数据，显著提升了4K随机写性能。 Adam的PR: 讨论了直接写和缓冲读的混合模式，可能引入一致性问题。 IOU Ring的讨论: IOU Ring的现状: 现有代码可能已过时，需要重新评估其在BlueStore中的应用。 潜在的改进: 考虑使用IOU Ring来改善性能，特别是在缓冲I/O模式下。 决定的事项 性能改进: 确认Gabby的PR显著提升了性能，解决了之前的性能回归问题。 IOU Ring的重新评估: 决定重新评估IOU Ring在Ceph中的应用，特别是在缓冲I/O模式下。 后续行动计划 性能审查: 对Adam的PR进行仔细审查，确保不会引入一致性问题。 IOU Ring的评估: 重新评估和测试IOU Ring的性能和稳定性。 讨论论文: 计划在三周后讨论一篇关于Linux内核低延迟优化的论文。 其他事项 会议时间调整: 由于节假日，下次会议时间调整至30号。 结论 会议讨论了多个PR的进展和性能问题，确认了Gabby的PR对性能的显著提升，并决定重新评估IOU Ring的应用。下次会议将讨论一篇相关论文。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-09-01","slug":"Ceph_Developer_Monthly_2021-09-01","date":"2021-09-01T16:00:00.000Z","updated":"2021-09-02T16:00:00.000Z","comments":true,"path":"2021/09/02/Ceph_Developer_Monthly_2021-09-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/02/Ceph_Developer_Monthly_2021-09-01/","excerpt":"","text":"会议纪要 会议主题：Ceph 配置文件与性能优化 讨论内容： 1. 配置文件（Config Profiles） - 背景：当前Ceph默认配置适用于高性能服务器，但越来越多的用户在资源受限的环境中部署Ceph，如家庭爱好集群、企业边缘部署等。 - 提议：引入性能配置文件，如“边缘资源受限”和“高性能”配置文件，自动调整CPU和内存使用等参数。 - 实现：类似于Pacific中的服务质量配置文件，通过设置一个主配置选项来控制多个子配置参数。 - 讨论：配置文件应如何设计，是否允许用户自定义配置文件，以及如何在Ceph配置系统中实现这些配置文件。 决定事项： - 初步确定至少两个配置文件：“边缘资源受限”和“高性能”。 - 配置文件将通过设置一个主配置选项来控制多个子配置参数，类似于Pacific中的服务质量配置文件。 - 需要进一步讨论和实验来确定具体的配置参数和默认值。 后续行动计划： - 设计并实现配置文件系统。 - 进行实验以确定最佳的配置参数。 - 与社区讨论并收集反馈，特别是关于用户自定义配置文件的需求。 会议主题：处理无复制池的客户端EIO问题 讨论内容： 2. 无复制池的客户端EIO问题 - 背景：在无复制池中，如果底层存储设备失败，客户端（如RBD）可能无法正确处理EIO错误，导致文件系统损坏。 - 提议：引入一个池级别的EIO标志，一旦设置，客户端将立即返回EIO错误，而不是挂起。 - 实现：通过OSD Map中的一个标志来实现，客户端检测到该标志后立即返回EIO错误。 - 讨论：如何确保客户端和服务端的一致性，以及如何处理多客户端情况下的同步问题。 决定事项： - 引入池级别的EIO标志，客户端检测到该标志后立即返回EIO错误。 - 需要确保客户端和服务端的一致性，特别是在多客户端环境下。 - 需要进一步讨论和实验来确定具体的实现细节。 后续行动计划： - 设计并实现池级别的EIO标志。 - 进行实验以验证客户端和服务端的一致性。 - 与社区讨论并收集反馈，特别是关于多客户端环境下的同步问题。 会议主题：大规模集群测试 讨论内容： 3. 大规模集群测试 - 背景：为了测试Ceph在超大规模集群中的性能和稳定性，需要一种方法在不实际部署大量物理硬件的情况下进行测试。 - 提议：使用内存 backed OSDs 和模拟数据存储来模拟大规模集群环境。 - 实现：通过调整OSD的配置和使用模拟数据存储来减少内存和存储需求。 - 讨论：如何平衡模拟环境的准确性和实际测试需求。 决定事项： - 使用内存 backed OSDs 和模拟数据存储来模拟大规模集群环境。 - 需要进一步讨论和实验来确定具体的配置参数和模拟方法。 后续行动计划： - 设计并实现内存 backed OSDs 和模拟数据存储。 - 进行实验以验证模拟环境的准确性和实际测试需求。 - 与社区讨论并收集反馈，特别是关于模拟环境的准确性和实际测试需求。 总结 本次会议主要讨论了Ceph在不同环境下的配置优化、无复制池的客户端EIO问题处理以及大规模集群测试的方法。决定引入性能配置文件、池级别的EIO标志和模拟数据存储来解决这些问题，并计划进行进一步的实验和社区讨论以完善这些方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-08-31","slug":"Ceph_Orchestrator_Meeting_2021-08-31","date":"2021-09-01T16:00:00.000Z","updated":"2021-09-02T16:00:00.000Z","comments":true,"path":"2021/09/02/Ceph_Orchestrator_Meeting_2021-08-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/02/Ceph_Orchestrator_Meeting_2021-08-31/","excerpt":"","text":"会议纪要 会议主题：本地存储解决方案讨论 参会人员：Sage、其他内部OCS团队成员 会议时间：最近几周的定期会议 主要议题： 本地存储的需求和要求： 讨论了本地存储的需求和要求，包括动态和静态资源配置。 提到了一个文档链接，该文档记录了过去几周的会议讨论内容。 动态资源配置的初步方案： 初步认为使用LVM（Logical Volume Manager）进行动态资源配置是一个明显的起点。 LVM提供了已知的有益功能，避免了使用分区。 社区和项目归属问题： 讨论了将项目捐赠给CNCF（Cloud Native Computing Foundation）的可能性。 探讨了是否可以直接将项目纳入Rook项目下，以简化流程。 技术细节讨论： 讨论了LSO（Local Storage Operator）和TopoLVM的结合使用，以及如何处理设备发现和资源分配。 探讨了动态和静态资源配置的优缺点，以及如何在TopoLVM中实现对原始设备的支持。 未来发展和兼容性考虑： 讨论了未来可能需要支持的设备类型，如Crimson和ZNS设备，这些设备可能不支持LVM。 探讨了如何在保持灵活性的同时，确保系统的长期兼容性和扩展性。 决定事项： 将继续与TopoLVM团队沟通，探讨加入Rook项目的可能性，以及如何在TopoLVM中实现对原始设备的支持。 计划安排与TopoLVM团队的进一步会议，以详细讨论技术实现和项目归属问题。 后续行动计划： 与TopoLVM团队进行深入的技术和项目归属讨论。 继续关注和评估LSO和TopoLVM的最新进展，确保项目的动态资源配置功能满足未来的需求。 探索和准备可能的备选方案，以应对TopoLVM团队可能的不同意见或技术挑战。 会议结束： 会议在讨论了所有议题后结束，没有其他紧急议题需要处理。 本次会议记录涵盖了本地存储解决方案的关键讨论点，包括技术实现、社区合作和未来发展方向，为后续的行动计划提供了明确的方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-09-02","slug":"Ceph_Performance_Meeting_2021-09-02","date":"2021-09-01T16:00:00.000Z","updated":"2021-09-02T16:00:00.000Z","comments":true,"path":"2021/09/02/Ceph_Performance_Meeting_2021-09-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/02/Ceph_Performance_Meeting_2021-09-02/","excerpt":"","text":"会议纪要 关键细节 Ceph Crimson测试更新： 通过多个OSD模拟多反应器环境，解决了之前无法实现的问题。 测试显示在随机读取时具有良好的扩展性和较低的CPU使用率。 随机写入的扩展性不如预期，需要进一步优化。 顺序写入在Crimson中表现不如传统OSD，需要调查原因。 数十亿小对象存储方案讨论： 软件遗产基金会提出了一个基于Ceph的架构，用于存储数十亿小对象。 方案涉及使用RBD图像和外部数据库进行对象索引。 讨论了使用Ceph的tiering v2和RADOS manifest功能来简化架构的可能性。 需要评估现有manifest功能的稳定性和性能，以及是否支持这种特定用例。 讨论的主要议题 Crimson性能优化： 随机读取的扩展性和CPU使用率表现良好。 随机写入和顺序写入的性能需要进一步优化。 小对象存储方案： 讨论了使用Ceph现有功能与创建新功能的利弊。 需要评估现有manifest功能的稳定性和性能，以及是否支持这种特定用例。 决定的事项 Crimson优化： 继续优化Crimson的随机写入和顺序写入性能。 小对象存储方案： 需要进一步评估和讨论使用Ceph现有功能与创建新功能的可行性和性能。 计划与软件遗产基金会进一步讨论具体需求和方案。 后续行动计划 Crimson优化： 继续进行性能测试和优化，特别是随机写入和顺序写入。 小对象存储方案： 与软件遗产基金会进行深入讨论，评估现有Ceph功能的适用性。 如果现有功能不满足需求，考虑开发新的存储方案。 会议安排： 安排与软件遗产基金会的后续会议，进一步讨论具体需求和方案。 结论 本次会议主要讨论了Ceph Crimson的性能优化和小对象存储方案的可行性。后续将通过进一步的测试和讨论，确定最佳的解决方案，并与相关方进行深入沟通。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-09-01","slug":"Ceph_Crimson_SeaStore_2021-09-01","date":"2021-08-31T16:00:00.000Z","updated":"2021-09-01T16:00:00.000Z","comments":true,"path":"2021/09/01/Ceph_Crimson_SeaStore_2021-09-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/09/01/Ceph_Crimson_SeaStore_2021-09-01/","excerpt":"","text":"会议纪要 主要议题与讨论内容 LBA重写合并：本周LBA重写已合并，目前正在处理一个断言失败问题，该问题由Yang Zum遇到，Chun Mei和会议主持人也能复现。正在努力找到问题的根源。 多核利用率：会议主持人正在阅读代码和文档，尝试找到可以改进的地方，并已经提交了几个小PR。未来将更多关注多核利用率的优化。 性能分析：Chad May报告了关于文件性能分析的结果，指出在某些情况下，性能比Ceph的BlueStore更差。下一步计划是获取操作的周期数，并进行进一步的优化。 C-Store优化：讨论了C-Store的性能问题，特别是在高负载下。建议使用性能分析工具如OProfile来识别CPU热点，以便进行针对性的优化。 Rook集成：Radik报告了Rook集成的进展，包括添加了Ammon Host Override选项，并解决了序列化器的一些内存管理问题。 新成员介绍：Moreno作为新成员加入会议，表示正在了解会议内容和项目情况。 Crimson项目资源：讨论了Crimson项目的资源和支持，Intel计划在下一季度增加资源。 多设备支持：会议主持人正在开发多设备支持，特别是修改段清理器的行为以适应多设备。 决定事项 使用性能分析工具如OProfile来识别C-Store的CPU热点。 继续优化C-Store的基本存储算法，特别是关于数据写入和垃圾收集的部分。 提交小规模的PR以加速合并过程。 后续行动计划 继续进行性能分析和优化工作。 提交小规模的PR以改进多设备支持。 新成员Moreno将继续了解项目和会议内容。 关注Intel对Crimson项目的资源投入。 其他事项 会议主持人提醒，Beast现在默认不显示损坏信息，如果需要在前台运行，可以使用Crimson Foreground选项。 会议结束时，所有参与者表示感谢并期待下次会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-08-26","slug":"Ceph_Performance_Meeting_2021-08-26","date":"2021-08-25T16:00:00.000Z","updated":"2021-08-26T16:00:00.000Z","comments":true,"path":"2021/08/26/Ceph_Performance_Meeting_2021-08-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/26/Ceph_Performance_Meeting_2021-08-26/","excerpt":"","text":"会议纪要 关键细节 会议时间: 未明确指出 参会人员: 核心团队成员及部分研发人员 会议主持: 未明确指出 讨论的主要议题 新PR审查: Prometheus缓存禁用: 讨论了Prometheus提供禁用缓存的功能，主要针对小型部署，可能涉及内存使用问题。 Direct IO写入方式变更: Adam提出了一个草案PR，旨在改变Direct IO写入方式，以确保安全性并提升性能。 RGW跟踪实现: 讨论了RGW跟踪实现的关闭，以及后续的跟踪扩展和细节添加。 已关闭PR: RGW缓存问题: 讨论了RGW缓存的相关问题，包括缓存的必要性和可能的改进。 BlueStore cap omap命名方案升级: Igor解释了该PR的目的，即解决大型引用写入时的性能问题。 性能调查和未来计划: 性能调查工具: 讨论了性能调查工具的需求，如Kubernetes性能测试工具Storms，以及如何在上游进行测试。 平衡改进: 讨论了平衡改进的必要性，特别是在处理大量小文件时的性能问题。 QoS和缓存策略: 讨论了QoS的一般性问题，以及如何改进缓存策略以更好地平衡资源。 特定组件的性能问题: RGW和CephFS: 讨论了RGW和CephFS中的多个性能问题，包括缓存管理、异步请求处理和多站点性能。 RBD: 讨论了RBD的客户端持久缓存问题，以及NVMe或Fabric网关的潜在性能影响。 其他议题: 自动化性能测试: 讨论了自动化性能测试的需求和挑战，以及如何确保性能不会在代码更新中退化。 决定的事项 需要进一步审查和讨论Prometheus缓存禁用的PR。 Adam将继续审查和改进Direct IO写入方式的PR。 需要进一步讨论和实施RGW跟踪的扩展和细节添加。 需要关注和改进平衡性能，特别是在处理大量小文件时。 需要进一步研究和实施QoS和缓存策略的改进。 需要关注RGW和CephFS中的多个性能问题，并寻找解决方案。 需要关注RBD的客户端持久缓存问题，并评估NVMe或Fabric网关的性能影响。 需要进一步讨论和实施自动化性能测试，以确保性能不会在代码更新中退化。 后续行动计划 继续审查和讨论Prometheus缓存禁用的PR。 继续审查和改进Direct IO写入方式的PR。 继续讨论和实施RGW跟踪的扩展和细节添加。 继续关注和改进平衡性能，特别是在处理大量小文件时。 继续研究和实施QoS和缓存策略的改进。 继续关注RGW和CephFS中的多个性能问题，并寻找解决方案。 继续关注RBD的客户端持久缓存问题，并评估NVMe或Fabric网关的性能影响。 继续讨论和实施自动化性能测试，以确保性能不会在代码更新中退化。 其他备注 会议中提到了多个具体的PR和代码变更，这些需要研发团队的具体成员进行跟进和实施。 会议中提到了多个性能调查工具和方法，这些需要进一步的研究和实施。 会议中提到了多个具体的性能问题，这些需要进一步的讨论和解决方案。 会议中提到了自动化性能测试的需求和挑战，这些需要进一步的讨论和实施。 结束语 会议在讨论了多个关键议题和后续行动计划后结束，参会人员表示将按照会议讨论的内容进行后续的工作。会议主持感谢大家的参与，并期待下一次会议的召开。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Going NATS","slug":"Ceph_Tech_Talk_-_Going_NATS","date":"2021-08-25T16:00:00.000Z","updated":"2021-08-26T16:00:00.000Z","comments":true,"path":"2021/08/26/Ceph_Tech_Talk_-_Going_NATS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/26/Ceph_Tech_Talk_-_Going_NATS/","excerpt":"","text":"会议纪要 会议主题：使用Lua脚本与NATS Blue客户端集成以添加Ceph存储桶通知 会议时间：[具体时间] 参会人员：Martin Brisman、[其他参会人员] 会议内容： 背景介绍： Martin Brisman介绍了如何在Ceph中使用Lua脚本与NATS Blue客户端集成，以添加存储桶通知。 存储桶通知是一种机制，用于在发生特定事件（如向存储桶中添加或删除对象）时向外部系统发送通知。 应用场景： 演示了一个数据管道示例，其中上传的X光照片在Ceph存储桶中触发通知，通过Knative事件组件处理，评估疾病风险，并将结果返回给诊所或发送给研究人员。 技术细节： 目前Ceph支持向Kafka、AMQP和HTTP端点发送通知，但希望通过Lua脚本集成NATS，而无需修改源代码。 Lua脚本允许在Ceph中上传脚本，并在每次收到存储桶请求时执行。 演示环节： Martin展示了如何上传Lua脚本到Ceph，并使用rgw admin命令安装所需的Lua包。 通过s3cmd命令向存储桶发送请求，演示了Lua脚本如何捕获请求并将其发送到NATS服务器。 未来展望： 讨论了Lua脚本的潜在集成机会，如与Elasticsearch和Prometheus的集成。 提到了正在开发中的背景脚本，这将有助于监控和在请求之间保存缓存。 问题与讨论： 讨论了Lua脚本的优势，如无需修改源代码即可集成新系统，以及其简单易用的特点。 也提到了一些限制，如无法在运行之间缓存数据，以及需要改进的地方，如背景数据结构的持久化。 决定事项： 鼓励社区成员尝试使用Lua脚本进行集成和调试，并提供反馈以指导未来功能的开发。 后续行动计划： 继续开发背景脚本和数据结构，以支持更复杂的监控和集成需求。 收集社区反馈，优化Lua脚本功能。 会议结束： 感谢Martin的精彩演示和Google Summer of Code的工作，期待他在Ceph社区的进一步贡献。 备注：会议中提到的技术术语和工具包括Ceph、Lua脚本、NATS、Knative、存储桶通知、数据管道、Elasticsearch、Prometheus等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-07-07","slug":"Ceph_Crimson_SeaStore_2021-07-07","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T16:00:00.000Z","comments":true,"path":"2021/08/24/Ceph_Crimson_SeaStore_2021-07-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/24/Ceph_Crimson_SeaStore_2021-07-07/","excerpt":"","text":"会议纪要 参会人员 Aaron Jeremy Riddick 其他相关研发人员 主要议题 Crimson项目的清理和讨论 Aaron分享了上周在Crimson项目中进行的一些随机清理工作，并讨论了与Jihan关于扩展分配管理器的PR。 IOCTL和控制支持的补丁更新 Aaron提到正在开发Ceph的IOCTL和控制支持的下一个补丁版本，并已提交并接收了一些评审意见。同时，他开始在Ceph的Segment Manager中实现相应的接口。 Extent内容的更新问题 Aaron报告了一个关于Extent内容更新的问题，特别是在并发操作中，Extent内容可能会被其他操作更新，导致最终获取到错误的地址。他提出了一个临时的解决方案，并进行了一些测试。 MLIS案例分析 Riddick分享了关于MLIS（Multi-Level Index Structure）案例的分析，指出问题可能与消息处理有关，特别是在OSD重启时可能发生的竞态条件。 Extent Placement Manager的修改 某位参会者（未明确姓名）讨论了Extent Placement Manager的修改，包括如何处理Extent的写入和日志记录。 C-Store性能分析 另一位参会者（未明确姓名）提到正在进行C-Store的性能分析，并尝试添加矩阵以帮助诊断性能问题。 决定事项 Aaron将继续优化Extent内容的更新问题，并寻找更稳定的解决方案。 Riddick将继续分析MLIS案例，特别是关注消息处理和OSD重启时的竞态条件。 对于Extent Placement Manager的修改，将继续进行多设备支持的实现。 后续行动计划 Aaron将提交更新的补丁版本，并继续在Segment Manager中实现接口。 Riddick将深入研究MLIS案例，并寻找可能的解决方案。 所有参会者将继续关注各自负责的模块，确保Ceph的稳定性和性能优化。 其他讨论 会议中还讨论了关于消息处理的防御性编程，以及如何在集群中处理可能的错误消息。 会议结束 会议在讨论了所有议题后结束，参会者表示将继续跟进各自的任务，并保持沟通。 注： 会议中提到的具体技术细节和代码问题需要进一步的技术文档和代码审查来详细理解和解决。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-06-30","slug":"Ceph_Crimson_SeaStore_2021-06-30","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T16:00:00.000Z","comments":true,"path":"2021/08/24/Ceph_Crimson_SeaStore_2021-06-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/24/Ceph_Crimson_SeaStore_2021-06-30/","excerpt":"","text":"会议纪要 主要议题与讨论内容 代码审查与清理工作 上周主要进行了PR（Pull Request）的审查和代码清理工作。 尝试移除一些不必要的代码，并对PR进行了总结。 提交了一个PR，旨在将无日志的Cue添加到编辑存储中的Shouted Queue。 系统远程集成的控制接口 正在集成IOC TLF控制接口到系统远程设置中。 提交了补丁并进行了初步审查，需要进一步完善版本。 运行时异常修复 修复了两个运行时异常，一个是compare_xattr，另一个是pg_in_rs。 当前的调试构建和发布构建都可以通过FIO和Reader's Bench进行测试。 调试与性能问题 发现调试输出会导致运行缓慢，而禁用输出则会快速遇到问题。 计划提交一个bug报告，以便更好地协调解决这些问题。 Crimson背景问题 发现了Trashing测试中的根本原因，并提交了补丁。 解决了由于错误类型转换导致的core dumps问题。 PR142100审查 鼓励团队审查PR142100，特别关注mutable specifier的使用，以避免性能问题。 实习生招聘 已经开始审查CVs，准备招聘实习生。 PR合并与测试 有一个PR等待测试和审查，建议尽快合并。 中断可处理的Future问题 解决了OSD maps显示和崩溃的问题，修复了C-store不尊重事务顺序的bug。 Extent Placement Manager改进 修改了Extent Placement Manager，以解决Yinshin和Sam的担忧。 重新基于主分支进行了代码重构，并正在修复中断条件泄漏问题。 事务验证与缓存层问题 正在阅读事务验证PRs，并发现了一些缓存层的问题。 正在修复这些问题，并将提交相关补丁。 Lease Message问题 讨论了Lease Message在特定情况下的处理问题，特别是与激活消息的顺序相关。 需要确保消息处理的顺序，以避免潜在的bug。 决定事项 提交bug报告，以便更好地协调解决性能和调试问题。 鼓励团队审查PR142100，关注mutable specifier的使用。 尽快合并等待测试和审查的PR。 后续行动计划 继续完善和提交相关补丁，解决发现的各类问题。 确保消息处理的顺序，特别是在处理Lease Message时。 继续进行代码审查和清理工作，以提高系统稳定性和性能。 备注 下周将不在办公室，将不会进行RADOS QA工作。 需要进一步讨论和解决Lease Message相关的问题。 会议结束，祝大家工作顺利。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-06-29","slug":"Ceph_Orchestrator_Meeting_2021-06-29","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T16:00:00.000Z","comments":true,"path":"2021/08/24/Ceph_Orchestrator_Meeting_2021-06-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/24/Ceph_Orchestrator_Meeting_2021-06-29/","excerpt":"","text":"会议纪要 会议主题：OSD创建在自我编排器中的实现 参会人员： 会议主持人：[主持人姓名] 主要发言人：Chris（OCS操作界面负责人） 其他参会人员：[其他参会人员姓名] 讨论议题： PV（持久卷）的获取与管理 如何将PV引入自我编排器（Self Orchestrator）。 如何使用自我编排器在PV上创建OSD（对象存储守护进程）。 现有问题与挑战 处理本地持久卷（Local Persistent Volumes）与PV及声明（Claims）的关系。 如何在OCS（OpenShift Container Storage）中实现这一流程。 技术细节与演示 Chris演示了如何在OpenShift UI中通过OCS操作符创建PV和OSD。 讨论了LSO（Local Storage Operator）的使用，包括如何发现节点上的磁盘并创建存储类。 后续行动计划 继续探讨LSO作为库的嵌入方式，而不是作为一个独立的操作符部署。 讨论如何使Rook能够支持多种存储类的PV，不仅仅是LSO。 考虑如何通过CSI（Container Storage Interface）标准来管理本地硬件。 决定事项： 需要进一步明确Rook与LSO的集成方式，以及如何处理不同存储类的PV。 计划编写更具体的技术提案，以便更深入地讨论和实施。 后续行动： 继续实验和研究LSO的嵌入方式。 编写具体的技术提案，以便下次会议讨论。 考虑CSI标准在本地存储管理中的应用。 备注： 会议中提到了OpenEBS作为另一个本地存储管理的选项，但目前主要关注LSO。 讨论了如何在Rook中实现对本地硬件的发现和管理，以及如何与现有的存储操作符（如LSO）协同工作。 会议结束： 会议在规定时间内结束，参会人员对后续行动计划达成一致。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-07-06","slug":"Ceph_Orchestrator_Meeting_2021-07-06","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T16:00:00.000Z","comments":true,"path":"2021/08/24/Ceph_Orchestrator_Meeting_2021-07-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/24/Ceph_Orchestrator_Meeting_2021-07-06/","excerpt":"","text":"会议纪要 会议主题： 今天的会议主要讨论了如何改进我们的设计决策和讨论的记录方式，以及如何更好地与上游社区合作。 主要议题： 设计文档的管理： 讨论了是否应该编写设计文档，或者是否可以在会议记录中简单记录设计决策。 提出了是否应该将设计文档公开，以便其他团队和下游用户查看。 讨论了设计文档的复杂性和是否应该根据复杂性来决定是否编写设计文档。 工具和流程的改进： 讨论了使用Redmine、Trello等工具来管理项目和任务的可行性。 讨论了如何改进Redmine的使用，包括标签、过滤和分类问题。 讨论了如何更好地集成不同的工具，如GitHub和Redmine，以便更有效地管理问题和拉取请求。 具体技术问题： 讨论了Ceph集群中的一些具体技术问题，如部署过程中的边缘情况和bug。 讨论了Rook Orchestrator的一些具体问题，如存储类和PV的管理。 决定的事项： 设计文档的管理： 决定根据设计决策的复杂性来决定是否编写设计文档，并考虑将一些重要的设计文档公开。 工具和流程的改进： 决定尝试改进Redmine的使用，包括标签和过滤问题，以便更有效地管理任务。 决定探索如何更好地集成不同的工具，如GitHub和Redmine。 具体技术问题： 决定解决一些具体的部署问题，如边缘情况和bug。 决定测试和改进Rook Orchestrator的存储类和PV管理。 后续行动计划： 设计文档的管理： 根据设计决策的复杂性来决定是否编写设计文档，并考虑将一些重要的设计文档公开。 工具和流程的改进： 尝试改进Redmine的使用，包括标签和过滤问题。 探索如何更好地集成不同的工具，如GitHub和Redmine。 具体技术问题： 解决一些具体的部署问题，如边缘情况和bug。 测试和改进Rook Orchestrator的存储类和PV管理。 其他事项： 讨论了Ceph在特定环境下的兼容性问题，如Python 3和容器管理工具的问题。 讨论了如何更好地管理维护模式下的主机。 会议结束： 会议在讨论了所有议题后结束，大家表示下周再见。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-08-24","slug":"Ceph_Orchestrator_Meeting_2021-08-24","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T16:00:00.000Z","comments":true,"path":"2021/08/24/Ceph_Orchestrator_Meeting_2021-08-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/24/Ceph_Orchestrator_Meeting_2021-08-24/","excerpt":"","text":"会议纪要 会议概述 本次会议为每周一次的Orchestrator会议，主要内容包括两个项目的更新报告。会议由主持人开场，随后分别由Aaron和Melissa进行项目进展的展示。 第一个项目：Aaron的周二项目更新 项目背景：Aaron介绍了他在过去几个月中致力于开发一个新的集成测试框架，使用Jacqueline语言来确保Orchestrator操作的安全性。 技术细节： Jacqueline语言：一种使用常见关键词（如Given、And、Then）定义执行步骤的自然语言，用于创建测试场景。 KCLI工具：用于创建运行特定测试的环境。 项目目标：创建类似执行命令并验证命令输出的场景，无需编程语言知识。 当前进展： 实现了用户定义不同测试实验室配置的功能，使用KCLI创建环境并执行特定测试。 用户可以定义在虚拟机上执行的命令，并指定预期输出中的关键词。 正在进一步定义更多测试场景，并实现命令执行和输出存储的功能。 实施结构： 使用Behave测试框架，定义在.feature文件中，步骤实现则在Python脚本中。 环境配置示例：三个节点，每个节点4GB RAM和4个CPU，使用Fedora 32镜像。 当前问题： 无法使用Talks命令运行Behave测试，因为需要环境变量和适当权限。 正在寻找解决方案以缓解此问题。 第二个项目：Melissa的Outreach实习项目更新 项目背景：Melissa的项目旨在用Python的Async SSH库替换Zeknet和Remoto，以改善Cephadm中的远程命令执行。 技术细节： Async SSH：一个异步实现的SSH协议库，支持OpenSSH配置，提供更好的错误处理和调试日志。 挑战： 选择合适的Python SSH库。 将异步函数集成到现有的同步代码中。 学习和调试容器化环境。 实施结构： 创建一个专用的SSH线程，并在该线程中运行事件循环。 使用同步包装函数来调用异步协程，确保代码的同步执行顺序。 示例代码展示了如何使用Async SSH执行远程命令并处理结果。 未来展望： 确保有一个专用的SSH线程和线程安全的异步函数调用。 开发者可以继续使用同步包装函数，无需过多关注事件循环。 后续行动计划 Aaron的项目： 继续定义和实现更多的测试场景。 寻找并实施解决方案以解决Behave测试的权限问题。 Melissa的项目： 确保Async SSH的稳定集成和维护。 考虑将Async SSH库添加到Ceph的依赖管理中，特别是对于CentOS等系统。 其他讨论 讨论了Async编程在Cephadm中的应用和潜在影响。 提出了关于依赖管理和库选择的未来工作方向。 会议结束 会议在讨论了所有议题后圆满结束，感谢所有参与者的贡献和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-07-01","slug":"Ceph_Performance_Meeting_2021-07-01","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T16:00:00.000Z","comments":true,"path":"2021/08/24/Ceph_Performance_Meeting_2021-07-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/24/Ceph_Performance_Meeting_2021-07-01/","excerpt":"","text":"会议纪要 主要议题 新Pull Request讨论 本周仅有一个新的Pull Request，由Adam提交，涉及在BlueFS中实现细粒度锁定（fine grain locking）。此PR尚未准备好合并，因为存在死锁的可能性，需要进一步审查。 另一个小的PR涉及将long double改为double，对性能有一定提升。 已合并的PR Patrick在MDS中合并了一个PR，用于在请求读锁时刷新MD Log。 Kifu的B树分配器PR已经通过审查并合并。 性能优化和后续行动 正在等待将数据定位器与混合合金和位图分配器结合形成混合模式的继续开发。 讨论了OSD客户端消息容量（OSD client message cap）参数的调整，建议将其默认值设为256。 流控制和CPU分区 讨论了在客户端实现更精细的流控制机制的可能性，以及CPU分区的优化策略。 提到了在ARM架构上的测试结果，显示通过CPU分区可以获得性能提升。 决定事项 确认将OSD客户端消息容量参数的默认值调整为256。 需要进一步研究和测试细粒度锁定PR，以确保不会引入死锁问题。 计划在Intel平台上复现ARM架构上的CPU分区测试，以验证其效果。 后续行动计划 对细粒度锁定PR进行更深入的审查和测试。 在Intel平台上进行CPU分区测试，并与ARM架构上的结果进行对比。 继续推进数据定位器与混合合金和位图分配器的结合工作。 其他讨论 讨论了在容器化环境中如何处理CPU分区的问题。 提到了在AWS上进行Graviton测试的可能性，以获取更多ARM架构的性能数据。 结论 会议涵盖了多个技术议题，包括新PR的审查、性能优化、流控制机制的改进以及CPU分区的策略。决定了一系列后续行动计划，以确保Ceph项目的持续改进和发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: MDS Locker, Part 1","slug":"CephFS_Code_Walkthrough_-_MDS_Locker_Part_1","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/CephFS_Code_Walkthrough_-_MDS_Locker_Part_1/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/CephFS_Code_Walkthrough_-_MDS_Locker_Part_1/","excerpt":"","text":"会议纪要 会议主题：Ceph MDS Locker 代码走读 参会人员：Ceph 研发团队成员 会议时间：具体日期未提供 会议内容总结： 会议目的： 讨论 Ceph 的 MDS（Metadata Server）Locker 机制，由于该主题内容广泛且复杂，决定分为三个系列的视频进行详细讲解。 系列内容规划： 第一部分：介绍为何需要在 MDS 中使用锁，涉及的数据结构，以及文件操作中如何使用锁。 第二部分：详细讲解 Locker 的实际实现，特别是分布式锁的复杂性。 第三部分：探讨不同类型的锁类，包括简单的和复杂的锁类，以及它们如何通过状态机相互关联。 第一部分详细内容： 锁的需求：解释了为何需要在 MDS 中使用锁来保护元数据状态，特别是在处理大容量元数据时。 数据结构与锁：介绍了 MDS 中使用的不同数据结构（如 inode 和 dentry）以及它们如何使用锁来保护不同的元数据字段。 文件操作与锁：通过具体的文件操作（如 mkdir, link 等）展示了如何在操作过程中获取和使用不同类型的锁。 后续行动计划： 继续进行第二和第三部分的讲解，深入探讨锁的实现细节和不同锁类的使用。 改进和文档化现有的代码，特别是 Locker 类的代码，以提高可读性和可维护性。 会议结论： 通过本次会议，团队成员对 MDS Locker 的基本概念和使用有了更深入的理解，为后续的详细实现和优化工作奠定了基础。 下一步行动： 安排第二部分和第三部分的详细讲解和代码走读。 开始对现有代码进行文档化和优化工作。 会议反馈： 参会人员对会议内容表示满意，期待后续的详细讲解和代码实现部分的深入探讨。 本次会议纪要由专业的存储领域分布式存储 Ceph 的研发人员编写，确保了内容的准确性和专业性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: MDS path traversal","slug":"CephFS_Code_Walkthrough_-_MDS_path_traversal","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/CephFS_Code_Walkthrough_-_MDS_path_traversal/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/CephFS_Code_Walkthrough_-_MDS_path_traversal/","excerpt":"","text":"会议纪要 会议主题：Ceph MDS 部分遍历 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： 数据结构介绍： 讨论了MDS部分遍历涉及的三种重要数据结构： CI Node：每个文件对应一个CI Node，包含文件的属性和其他信息。 Seed Entry：目录项的简写，连接inode和文件名或目录名。 CDN Tree：仅存在于目录的数据结构，用于链接目录下的条目。 引入了权威MDS的概念，即特定inode的更改应由权威MDS处理，非权威MDS通常会将请求转发给权威MDS。 代码流程分析： 详细讲解了路径遍历的代码实现，包括路径遍历例程的定义和使用。 讨论了路径遍历中的三种主要用例： 当在特定路径下创建文件时的情况。 路径涉及快照目录时的情况。 路径中某些标识不存在时的情况。 强调了在路径遍历中，客户端通常通过查找操作触发路径遍历，而MDS则通过MD请求结构维护请求的上下文。 实际代码演示： 通过GDB调试工具，展示了单个MDS情况下的路径遍历实际操作。 演示了如何处理路径遍历中的查找操作和创建操作，包括如何处理查找失败的情况。 讨论了涉及快照目录的路径遍历，特别是如何处理快照目录中的文件查找。 问题与讨论： 讨论了Bloom过滤器在路径查找中的应用，作为一种优化手段，用于快速确定路径是否存在。 提及了LRU缓存算法在数据结构中的实现，特别是在inode和CDN树中的应用。 决定事项： 确认了路径遍历的基本流程和关键数据结构。 确定了需要进一步深入研究的边缘案例和复杂情况。 后续行动计划： 继续深入研究路径遍历的复杂用例，特别是涉及多个MDS的情况。 准备下一次会议，讨论更详细的技术实现和优化策略。 会议结束： 会议在提问和讨论环节后顺利结束，感谢所有参与者的积极参与和贡献。 备注：会议中提到的技术细节和代码实现部分，建议参会者会后进一步查阅相关文档和代码库，以加深理解。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-07-28","slug":"Ceph_Crimson_SeaStore_2021-07-28","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Crimson_SeaStore_2021-07-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Crimson_SeaStore_2021-07-28/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph项目的多个技术问题，包括代码审查、性能优化、错误修复以及未来的工作计划。会议参与者包括多位开发人员，他们分享了各自的工作进展和遇到的问题。 主要议题 代码审查与清理 一位开发者完成了对Bronze PR的审查，并进行了一些代码清理工作。 另一位开发者完成了使用可中断未来（interruptable future）的树结构的实现，并即将提交PR。 性能与错误分析 讨论了在容器化环境中配置Messenger时遇到的问题，原因是使用了错误的nonce。 讨论了是否应该引入检查机制来避免nonce冲突，最终决定不引入，而是考虑使用随机nonce来降低冲突概率。 性能比较工具 开发了一个工具用于比较Ceph的不同存储实现（如Ceph和Crimson）的性能，特别是在内存对象处理方面的开销。 该工具主要用于比较memstore和alienstore的性能，发现alienstore在处理4K随机读取时的性能较低。 日志处理与代码优化 讨论了日志处理的改进，特别是在PG状态日志处理方面。 另一位开发者正在重写LBA树，并优化了扩展放置管理器的PR。 性能测试与分析 进行了一些性能测试，包括缓存使用、事务验证和写放大效应的分析。 讨论了如何自动化生成性能图表的过程。 决定事项 不引入nonce冲突检查机制，而是使用随机nonce来降低冲突风险。 继续优化alienstore的性能，特别是在减少内核切换次数方面。 考虑将性能分析脚本集成到CBT工具目录中。 后续行动计划 提交使用可中断未来（interruptable future）的树结构的PR。 继续优化扩展放置管理器的PR，并解决单元测试中的问题。 完成日志处理的改进，并提交相关PR。 继续进行性能测试和分析，特别是关于写放大效应的优化。 探索自动化生成性能图表的方法，并考虑将其集成到CBT工具目录中。 其他备注 会议中提到的“nonce”、“interruptable future”、“alienstore”等术语是Ceph存储系统中的关键技术概念。 会议强调了代码质量和性能优化的重要性，以及持续改进和测试的必要性。 本次会议为Ceph项目的持续发展和优化提供了明确的方向和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-08-04","slug":"Ceph_Crimson_SeaStore_2021-08-04","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Crimson_SeaStore_2021-08-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Crimson_SeaStore_2021-08-04/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了关于Ceph存储系统的性能指标（metrics）实现、系统更新以及设备管理的相关工作进展和后续计划。 讨论的主要议题 性能指标工具的实现： 会议中提到了正在开发一个工具，用于打印出系统的性能指标，特别是与“systole”相关的指标。 该工具的开发由某位成员（可能是“me and aaron”）负责。 系统更新与模块升级： 计划将辅助系统模块更新到最新版本，以便与即将实施的更改兼容。 讨论了启用系统使用最新芯片的计划，特别是关于FC控制和I/O控制命令的实现。 设备管理与扩展放置管理器： 正在实施设备管理的相关工作，并对扩展放置管理器（placement manager）的PR进行了修改。 考虑在段管理器（segment manager）中增加相关功能。 决定的事项 将继续推进性能指标工具的开发和系统模块的更新。 确认了设备管理和扩展放置管理器的工作方向。 后续行动计划 更新辅助系统模块至最新版本。 实施FC控制和I/O控制命令。 在段管理器中增加相关功能。 继续进行设备管理和扩展放置管理器的开发工作。 会议结束 会议在简短的道别中结束，感谢大家的参与，并祝愿大家有一个愉快的一天。 备注：会议中提到的具体技术细节如“systole”、“FC control”和“I/O control commands”等，需要进一步的技术文档或详细讨论来明确其具体含义和应用场景。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-07-21","slug":"Ceph_Crimson_SeaStore_2021-07-21","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Crimson_SeaStore_2021-07-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Crimson_SeaStore_2021-07-21/","excerpt":"","text":"会议纪要 关键细节 上周工作回顾： 审查并调整了与scrub相关的逻辑，将其提取到独立的队列中，以减少crimson的影响并解决由refractory引入的一些回归问题。 提交了sister patch的第三个版本，增加了ceph ctl和控制接口到siege。 审查了一些gears，提供了类似magic的支持，但在测试中遇到了一些不可复现的问题。 本周工作计划： 继续优化buffer list cstr，解决因空carriage buffer指针导致的低效问题。 进行crimson的性能分析，特别是在使用4k随机读取时，观察到每操作的周期数显著增加。 探索使用spin lock替代semaphore的可能性，以提高性能。 讨论的主要议题 性能优化： 讨论了semaphore的使用对性能的影响，特别是在高并发情况下的效率问题。 探讨了使用spin lock替代semaphore的可能性，以减少等待时间。 测试方法： 讨论了使用fio和rbd进行性能测试的有效性，以及如何避免客户端库对测试结果的影响。 决定的事项 性能测试策略： 决定使用fio和rbd进行更深入的性能测试，确保客户端和服务器端在不同的核心上运行，以避免资源争用。 代码优化： 决定进一步探索和实施spin lock替代semaphore的方案，以提高系统的整体性能。 后续行动计划 性能测试： 使用fio和rbd进行更全面的性能测试，特别是在高并发和不同负载条件下的测试。 代码优化： 实施spin lock替代semaphore的方案，并进行性能对比测试，以验证优化效果。 持续监控： 持续监控系统的性能，特别是在引入新优化后的表现，确保没有引入新的性能问题。 通过这些讨论和决策，团队将继续推进ceph的性能优化工作，确保系统在高负载下的稳定性和效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-08-04","slug":"Ceph_Developer_Monthly_2021-08-04","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Developer_Monthly_2021-08-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Developer_Monthly_2021-08-04/","excerpt":"","text":"会议纪要 会议主题：Ceph Dashboard 团队 GSoC 实习生项目汇报 参会人员：Shreya Sharma（GSoC 实习生，Dashboard 团队）、Aryan（GSoC 实习生，Dashboard 团队）、其他团队成员 会议时间：[具体时间] 会议内容总结： Shreya Sharma 的项目汇报 问题陈述：Ceph 用户在遇到问题时，通常通过邮件列表或 Ceph 问题跟踪器报告问题。这种方式存在用户因不便而选择不报告问题，或报告后未得到回复的问题。 解决方案：提供从 Ceph Dashboard 和 Ceph CLI 直接报告问题的选项，以提高用户报告问题的便利性和响应率。 技术挑战：最初尝试使用 Python Redmine 库，但发现其在 CentOS 上不可用，后改用 Thor Requests 库。 实现细节：用户需要提供 Ceph 问题跟踪器的 API 密钥进行身份验证，以避免垃圾邮件。支持通过 CLI 和 Dashboard UI 报告问题。 演示：展示了如何通过 CLI 和 Dashboard UI 创建问题，并验证问题在 Ceph 问题跟踪器中的创建情况。 未来工作：计划支持附加图像、从文件中提供描述等功能，并考虑使用 Python WhatDoYouMean 插件来处理重复问题。 Aryan 的项目汇报 项目背景：Ceph Dashboard 的视觉回归测试，旨在捕捉 CSS 错误和框架升级带来的视觉变化。 现有测试：包括单元测试、集成测试和端到端测试，但这些测试无法捕捉视觉错误。 视觉回归测试：通过比较代码变更前后的屏幕截图来检测视觉变化。 工具选择：评估了多个视觉回归测试工具，最终选择了 Amplitude，因为它支持动态内容处理和 CI/CD 集成。 演示：展示了如何在 Ceph Dashboard 中使用 Amplitude 进行视觉回归测试，并处理动态内容。 未来工作：计划编写更多测试用例，完善 CI/CD 管道集成，并编写文档以帮助贡献者。 其他讨论 安全性和隐私：讨论了如何在不牺牲安全性的前提下简化用户报告问题的流程。 性能测试：讨论了如何自动化性能测试，以及如何通过改进数据格式和缓存策略来提高性能。 跟踪和调试：介绍了使用 Jaeger 进行分布式跟踪的计划，以及如何通过跟踪来改进多站点和复杂操作的调试。 决定事项： 继续推进视觉回归测试和问题报告功能的开发。 探索更高效的性能测试和数据处理方法。 开始实施 Jaeger 跟踪以提高系统的可观察性和调试能力。 后续行动计划： Shreya Sharma 将继续完善问题报告功能，并探索附加图像和文件描述的支持。 Aryan 将继续编写更多视觉回归测试用例，并完善 CI/CD 集成。 团队将开始实施 Jaeger 跟踪，并探索更高效的性能测试方法。 其他备注： 讨论了安全性和隐私问题，特别是如何在不牺牲安全性的前提下简化用户报告问题的流程。 强调了自动化性能测试和数据处理方法的重要性，以及如何通过改进数据格式和缓存策略来提高性能。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator 2021-07-13","slug":"Ceph_Orchestrator_2021-07-13","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Orchestrator_2021-07-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Orchestrator_2021-07-13/","excerpt":"","text":"会议纪要 会议主题： Ceph Orchestrator 会议 日期： [具体日期] 参会人员： [参会人员名单] 会议内容总结： ISCSI 问题讨论： 容器名称问题： 讨论了容器名称中包含点（dot）的问题。建议避免使用不含点的容器名称，因为这会导致 DNS 解析问题。具体来说，Python 的 socket 模块中的 getfqdn 函数在找不到主机名时会扫描 /etc/hosts 文件中的别名，如果容器名称包含点，会导致解析失败。 Cgroups 共享问题： 讨论了容器和系统之间的 cgroups 不共享的问题。这个问题已经有人贡献了解决方案，并且已经合并到 pacific 版本中。 LSO（Local Storage Operator）讨论： 安装和支持问题： 讨论了 LSO 在 vanilla Kubernetes 环境中的安装和支持问题。目前 LSO 的 README 文件不够友好，需要澄清其在上游的支持情况。 LSO 集成到 Rook 组织： 讨论了是否有可能将 LSO 集成到 Rook 的 GitHub 仓库中。目前 LSO 团队对保持所有权感兴趣，因此可能不会接受这个提议。 LSO 功能需求： 讨论了 LSO 的功能需求，包括硬件库存检查、动态 PV 分配、原始设备支持等。目前没有完全满足这些需求的存储运营商。 Rook 本地存储运营商： 提出了创建一个新的 Rook 本地存储运营商的想法，以满足上述需求，并可能从 LSO 和 TopoLVM 中学习。 后续行动计划： 基本支持实现： 计划在 Manager Rook 中实现基本支持，包括使用预创建的 PV 或 LSO，并支持基本的 OSD 创建和销毁。 新运营商开发： 计划在基本支持实现后，开发一个新的、更强大的本地存储运营商。 社区讨论： 将在即将举行的 Rook 社区会议上提出这些讨论点，以获取更多反馈和建议。 决定事项： - 避免使用不含点的容器名称。 - 继续推进 Manager Rook 的基本支持实现。 - 探索开发新的 Rook 本地存储运营商的可能性。 后续行动： - 在 Rook 社区会议上提出讨论点。 - 继续推进 Manager Rook 的基本支持实现。 - 探索新的本地存储运营商的开发。 会议结束时间： [具体时间] 下次会议时间： [具体时间] 会议纪要编写人： [编写人姓名] 会议纪要审核人： [审核人姓名] 备注： 请参会人员确认会议纪要的准确性，并在确认无误后进行分发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-07-20","slug":"Ceph_Orchestrator_Meeting_2021-07-20","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Orchestrator_Meeting_2021-07-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Orchestrator_Meeting_2021-07-20/","excerpt":"","text":"会议纪要 会议基本信息 日期: [具体日期] 时间: [具体时间] 主持人: [主持人姓名] 参会人员: [参会人员名单] 会议记录: 本次会议已通过上游蓝牙账户进行录制，但目前无法访问。通常会议录像会发布到YouTube，但可能会有两周的延迟。 讨论议题 会议录像访问问题 讨论了如何访问和发布会议录像的问题。建议再次联系Mike以获取访问权限。 Ceph Orchestrator模板问题 议题: 用户修改模板后无法受益于新版本默认模板的问题。 讨论: 提出了两种解决方案：将所有开关放入Yammer文件或继续使用Ginger模板。 讨论了两种方案的缺点：Yammer文件可能导致配置复杂，Ginger模板可能导致升级问题。 提出了可能的改进方案，如分离标准和自定义模板，或在Yammer文件中增加spec对象以允许用户自定义。 决定: 暂时不做出决定，将问题推迟到后续讨论，并考虑在升级后提供工具帮助用户比较和更新模板。 Manager循环卡顿问题 议题: Manager在处理离线主机时会卡顿15分钟。 讨论: 分析了问题原因：Ceph在主机离线时尝试通过SSH连接，导致长时间卡顿。 提出了可能的解决方案：减少超时时间或等待新的SSH库和代理的改进。 决定: 暂时不采取行动，等待新SSH库和代理的改进，观察是否能解决问题。 后续行动计划 会议录像: 再次联系Mike以获取会议录像的访问权限。 模板问题: 推迟到后续讨论，考虑提供工具帮助用户在升级后比较和更新模板。 Manager卡顿问题: 等待新SSH库和代理的改进，观察是否能解决问题。 其他事项 会议结束，下次会议再见。 备注: 本次会议讨论了Ceph Orchestrator的模板管理和Manager的性能问题，提出了多种解决方案和改进建议，但决定暂时不采取具体行动，等待后续技术改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-08-03","slug":"Ceph_Orchestrator_Meeting_2021-08-03","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Orchestrator_Meeting_2021-08-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Orchestrator_Meeting_2021-08-03/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 周会 日期：[具体日期] 参会人员：[参会人员名单] 主要议题： 容器镜像问题 问题描述：在使用 OSPCI 部署 CephFS 时，团队原本使用 Ceph-Ansible 角色而非 Cephdm，通过创建 systemd 单元并使用 Ceph 提供的容器启动。在尝试将 Pacific beats 升级到 16.5 版本时，发现 CephFS 无法启动，原因可能是新容器构建基于 demon 基础镜像而非 daemon 镜像，导致 Dockerfile 缺少入口点，start nfs bash 脚本未被调用。 讨论内容： 新容器格式缺少入口点，不适用于 CephFS。 建议继续使用传统的 daemon 镜像，直到新的 Manila 部分准备就绪。 讨论了旧容器镜像的维护问题，以及是否需要继续维护旧容器镜像。 决定事项： 继续使用 6.0.4 版本的容器镜像作为稳定版本。 确认 6.0.x 系列将继续维护，直到完全迁移到 Cepheidm。 后续行动计划： 确认旧容器镜像的维护计划，确保新版本的稳定性和兼容性。 继续监控新容器格式的测试和部署情况，确保无重大问题。 LSO 项目更新 项目概述：讨论了 LSO 项目的需求文档，计划与 LSO 团队合作，明确项目需求和目标。 讨论内容： 创建了一个 Google Doc 用于团队间的协作和讨论。 确认项目需要支持 vanilla Kubernetes，成为一个上游项目。 决定事项： 继续完善需求文档，计划在本周五与 LSO 团队进行详细讨论。 后续行动计划： 确保文档准备就绪，与 LSO 团队进行深入讨论。 跟进与 Duncan 的会议，讨论产品管理相关事宜。 其他议题： Crimson 和 Encephalidium 容器镜像：讨论了 Crimson 的容器镜像问题，确认其为不同的构建，带有特定的构建标志。 会议总结： 会议主要解决了容器镜像的兼容性问题，并讨论了 LSO 项目的进展。团队将继续监控和维护相关容器镜像，确保项目的稳定推进。同时，LSO 项目的需求文档将继续完善，以便与团队进行更深入的讨论和合作。 下一步行动： 确认并维护旧容器镜像的稳定性和兼容性。 完善 LSO 项目需求文档，准备与 LSO 团队进行详细讨论。 跟进与 Duncan 的会议，讨论产品管理相关事宜。 会议结束： 感谢所有参与者的积极参与，期待下周的会议。 注意：以上内容根据会议记录整理，保留了关键的英文术语和技术细节，以确保信息的准确性和专业性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-07-27","slug":"Ceph_Orchestrator_Meeting_2021-07-27","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Orchestrator_Meeting_2021-07-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Orchestrator_Meeting_2021-07-27/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了关于Ceph存储系统的开发进展，特别是与Rook和Local Storage Operator (LSO) 的集成问题。会议涉及了多个议题，包括代码审查、文档更新、用户集成测试以及未来工作计划。 主要议题 代码审查与集成测试 Alfonso确认收到了关于PR（Pull Request）的消息，并讨论了如何处理PR中的评论和权限问题。 讨论了在代码中设置用户“dashboard”的问题，以及需要进行的集成测试。 文档更新与用户反馈 讨论了删除部分文档的问题，特别是关于某些选项如“scheme nivea”的保留价值。 计划本周安排一次简短会议，以解决这些松散的结尾并推进VR（验证请求）。 Rook与LSO的集成 讨论了Rook项目中的一些问题，特别是关于OSD（Object Storage Daemon）的创建和移除。 确认了需要对Rook进行一些修改以支持OSD的移除，并讨论了可能的短期和长期解决方案。 LSO的未来发展 讨论了LSO的当前状态和未来的发展方向，包括与Topol LVM的合作可能性。 确认了需要与OpenShift的产品管理团队进行进一步的沟通，以确定LSO的未来发展路径。 决定事项 Alfonso将继续处理PR中的评论，并进行相关的集成测试。 计划本周内安排一次会议，以解决文档和用户集成的问题。 确认了需要对Rook进行修改以支持OSD的移除，并讨论了可能的短期和长期解决方案。 确认了需要与OpenShift的产品管理团队进行进一步的沟通，以确定LSO的未来发展路径。 后续行动计划 Alfonso将继续处理PR中的评论，并进行相关的集成测试。 计划本周内安排一次会议，以解决文档和用户集成的问题。 确认了需要对Rook进行修改以支持OSD的移除，并讨论了可能的短期和长期解决方案。 确认了需要与OpenShift的产品管理团队进行进一步的沟通，以确定LSO的未来发展路径。 会议结束 会议在讨论了所有议题后结束，参与者计划在下周继续跟进相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-07-22","slug":"Ceph_Performance_Meeting_2021-07-22","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Performance_Meeting_2021-07-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Performance_Meeting_2021-07-22/","excerpt":"","text":"会议纪要 会议概要 会议讨论了本周Ceph项目中的多个Pull Requests (PRs)，包括新提交的和更新的PRs，以及一些关闭的PRs。会议还涉及了Ceph的性能改进、内存分配优化、以及对Ceph存储系统的未来发展方向的讨论。 主要议题 新PR和更新PRs 一个新的PR改变了vlog的工作方式，Kifu已批准并要求Sam进行审查。 Radic提交了一个有趣的PR，允许在Crimson中使用外来的存储（alien store），这可以用来测试mem store和file store。 一个新的PR用于RGW跟踪，Matt已进行审查。 针对c字符串转换的buffer list优化。 一个PR改进了finisher线程的CPU占用，虽然有些争议，但Kifu和Kcr正在审查。 关闭的PRs Ori从IBM提交的PRs中，一些已被合并，一些因问题未解决而关闭。 Adam关于改变Blue Store缓存行为的旧PR被stale bot关闭。 性能和优化 讨论了在Crimson中实现multi-reactor的可能性，Greg Farnham将负责此项工作。 讨论了Randy和Radic在mem store和buffer list优化方面的工作。 RBD和客户端性能 讨论了RBD在kernel和user land客户端的性能问题，特别是与pnfs相关的讨论。 探讨了改进用户空间客户端性能的可能性，包括改进FUSE代码或探索其他技术如Zuf。 决定事项 继续推进multi-reactor的实现，以提高Ceph的性能。 继续审查和优化现有的PRs，特别是那些涉及性能和存储优化的PRs。 继续讨论和探索RBD客户端性能的改进方案。 后续行动计划 Greg Farnham将开始着手multi-reactor的实现工作。 继续审查和优化现有的PRs，确保它们符合项目的需求和标准。 继续讨论RBD客户端性能的改进方案，并寻求社区的反馈和建议。 其他事项 会议还讨论了一些正在进行中的测试和未来的工作计划，包括对bidding code和blue fs的改进。 会议结束 会议在讨论了所有议题后结束，与会者被鼓励继续工作并享受即将到来的周末。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-07-15","slug":"Ceph_Performance_Meeting_2021-07-15","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Performance_Meeting_2021-07-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Performance_Meeting_2021-07-15/","excerpt":"","text":"会议纪要 会议概要 日期: 会议日期未明确提及，但根据内容推测为近期。 参与者: Orlando, Mark, 以及其他未明确提及的开发人员。 主要议题: 讨论了Ceph项目的多个技术问题，包括持久性RBD缓存、CephFS性能优化、IBM研究人员的贡献、以及Crimson存储引擎的性能问题。 讨论的主要议题 持久性RBD缓存: Orlando的同事在测试持久性RBD缓存时遇到了性能问题。 使用GDB和pmp工具进行调试，发现与工作线程池的繁忙状态有关。 测试包括fio、rbd bench和自定义Python程序，结果显示性能不如预期。 CephFS性能优化: Orlando正在与Dennis Nujab合作，优化CephFS的整体性能。 探讨了Octane SSD和持久内存的使用，以及IO 500测试的结果。 IBM研究人员的贡献: 一位IBM研究人员提交了多个关于内存分配优化和避免内存复制的PR。 这些PR主要集中在librbd，但也涉及其他部分。 Crimson存储引擎: 讨论了Crimson的性能问题，特别是与Blue Store的比较。 发现Crimson在某些情况下性能不如预期，主要瓶颈在于reactor线程。 决定的事项 需要进一步分析和优化持久性RBD缓存的性能问题。 继续进行CephFS的性能优化工作，特别是与Octane SSD和持久内存的结合使用。 审查并可能合并IBM研究人员的PR，以提升Ceph的整体性能。 对于Crimson存储引擎，需要进一步的工作来解决reactor线程的瓶颈问题。 后续行动计划 继续进行性能测试和调试，以解决持久性RBD缓存的问题。 完成CephFS的性能优化工作，并考虑在实际环境中进行更多测试。 审查IBM研究人员的PR，并与他们合作以确保代码的质量和性能。 对于Crimson存储引擎，需要进一步的研究和开发，特别是关于多reactor的支持和优化。 其他备注 会议中还提到了一些具体的PR和代码变更，但这些细节主要涉及技术实现，未在此纪要中详细列出。 结束语 会议在讨论了各项议题后结束，参与者计划继续各自的工作，并在未来的会议中更新进展。会议结束时，大家互相道别，并期待下周的再次会面。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-07-29","slug":"Ceph_Performance_Meeting_2021-07-29","date":"2021-08-22T16:00:00.000Z","updated":"2021-08-23T16:00:00.000Z","comments":true,"path":"2021/08/23/Ceph_Performance_Meeting_2021-07-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/23/Ceph_Performance_Meeting_2021-07-29/","excerpt":"","text":"会议纪要 主要议题与讨论内容 PRs本周更新 本周唯一的PR来自会议主持人，主要涉及对memstor的重新架构，包括从几年前的pet store项目中引入的vector object。经过测试，发现buffer list的性能已经与vector object相当，甚至可能略优。 braddock提出了一项智能变更，允许alien store使用任何经典对象存储，不仅仅是blue store，这意味着现在可以运行mem store和alien store。 一个关于设置osd client message cap的PR被合并，该变更在测试中表现合理，预计能解决生产环境中与心跳超时相关的问题。 一个关于AVX 512 erasure coding的实现被作者关闭，原因是他们无法继续测试或更新该PR。 其他技术讨论 讨论了pg log的更新，特别是关于acceptable rollback info的变更，需要更多时间来理解和评估其潜在影响。 rgw tracing的优化正在积极讨论中，bufferless c-string的处理优化也得到了初步的审查。 关于finisher的CPU自动释放优化，目前正在进行详细的讨论，以确定具体的优化策略。 SMR存储技术 讨论了SMR（Shingled Magnetic Recording）存储技术在blue store中的实现状态和未来发展方向。目前，SMR的实现还处于初级阶段，需要进一步的工作来完善功能和性能。 讨论了如何更好地支持SMR硬件，包括可能的硬件测试环境和模拟测试方法。 决定事项 需要进一步研究和优化memstor在写路径上的效率问题。 需要对SMR存储技术的实现进行更深入的代码审查和功能测试。 后续行动计划 会议主持人将重新审视memstor的性能问题，并尝试找出其效率低下的原因。 对于SMR存储技术，将安排一次代码审查会议，以确定下一步的开发方向和具体实施计划。 将探索在现有测试环境中引入SMR硬件的可能性，以便进行更真实的性能测试。 其他信息 会议中还提到了关于crimson性能和效率的比较研究，特别是在小数据集和大数据集上的表现差异，以及memstor和blue store在不同场景下的效率对比。 结论 本次会议主要围绕ceph存储系统的性能优化和SMR存储技术的实现进行了深入讨论，确定了后续的研究和开发方向。会议强调了代码审查和性能测试的重要性，并计划通过实际硬件测试来验证和优化系统性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: BlueStore SMR","slug":"Ceph_Code_Walkthroughs_-_BlueStore_SMR","date":"2021-08-20T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/21/Ceph_Code_Walkthroughs_-_BlueStore_SMR/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/21/Ceph_Code_Walkthroughs_-_BlueStore_SMR/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统中SMR（Shingled Magnetic Recording）智能驱动器的代码更新与讨论 参会人员：Ceph研发团队成员 会议时间：[具体日期] 会议地点：视频会议 主要议题： SMR智能驱动器的代码更新 讨论了针对HSM（Host-Managed SMR）智能驱动器的代码更新，包括内核设备的支持和SMR特定功能的添加。 介绍了如何通过SMART特定调用来获取设备上的区域信息，如区域数量和传统区域数量。 Zoned Allocator和Zone Freelist Manager的更新 详细讨论了Zoned Allocator和Zone Freelist Manager的实现细节，包括新的清理线程的添加和设备参数的处理。 讨论了如何处理对象的区域编号和偏移量，以及如何在数据库中维护这些信息。 代码优化和未来工作 讨论了是否需要继续使用ZBD库以保持对旧内核的兼容性，以及是否需要紧急移除它。 讨论了如何处理多区域同时清理的问题，以及如何简化这一过程。 决定事项： ZBD库的使用：决定不紧急移除ZBD库，以保持对旧内核的兼容性。 多区域清理：决定简化多区域清理过程，每次只清理一个区域，以减少复杂性和潜在的错误。 后续行动计划： 代码审查和优化：对现有代码进行详细审查，特别是Zoned Allocator和Zone Freelist Manager的实现，确保其正确性和效率。 兼容性测试：在不同内核版本上进行兼容性测试，确保代码在各种环境下都能稳定运行。 文档更新：更新相关文档，包括代码注释和用户手册，以便其他开发者更好地理解和维护代码。 备注： 会议中提到的“zone append”命令是一个新的内核命令，用于简化SMR驱动器的写操作。 会议结束时，团队成员表示将通过电子邮件跟进会议中提到的待办事项。 会议总结： 本次会议主要讨论了Ceph存储系统中SMR智能驱动器的代码更新和优化问题，团队成员对现有代码进行了深入的讨论，并制定了后续的行动计划。通过本次会议，团队对SMR驱动器的支持有了更清晰的认识和规划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-08-05","slug":"Ceph_Performance_Meeting_2021-08-05","date":"2021-08-20T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/21/Ceph_Performance_Meeting_2021-08-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/21/Ceph_Performance_Meeting_2021-08-05/","excerpt":"","text":"会议纪要 关键细节 新PR: 本周有一个新的PR，涉及MDS锁的更改，从非公平互斥锁切换到公平互斥锁，目的是改善等待时间较长的请求的处理，避免资源饥饿。 已关闭PR: Kifu合并了一个关于PG日志的更改，具体是关于回滚信息的修剪。 更新PR: 多个PR正在积极审查和开发中，包括RGW跟踪工作、缓冲区列表的PR以及TTL缓存实现的长期工作。 性能问题: Red Hat内部工作组发现基于Pacific的新存储版本在性能上有所提升，但NVMe基础的DB和WAL分区在OSD中出现了显著的写放大问题，导致SSD驱动器的工作负载比之前版本更重。 讨论的主要议题 写放大问题: 讨论了BlueStore中首选延迟大小与Blob大小的关系，以及这对写操作的影响。特别是，当首选延迟大小等于或大于Blob大小时，会导致大量的延迟I/O流量进入RocksDB的写前日志和MemTable缓冲区，从而引发写放大问题。 代码逻辑和行为: 讨论了BlueStore处理大写操作的逻辑，以及如何通过调整参数（如首选延迟大小）来优化性能和减少写放大。 决定的事项 进一步测试和分析: 决定进行更多测试，特别是简化场景的测试，以更好地理解写放大问题的原因和潜在的解决方案。 代码审查和优化: 需要进一步审查和优化BlueStore的代码，特别是在处理大写操作和延迟写入的逻辑上。 后续行动计划 性能测试: 进行更多性能测试，特别是在不同配置下测试写放大问题。 代码审查: 继续审查和优化BlueStore的代码，特别是与写操作和延迟写入相关的部分。 参数调整: 考虑调整BlueStore的首选延迟大小参数，以减少写放大并优化性能。 结论 会议讨论了Ceph存储系统中的多个开发和性能优化问题，特别是关于MDS锁的改进和BlueStore中的写放大问题。决定进行更多测试和代码审查，以解决这些问题并优化系统性能。感谢所有参与者的贡献和讨论，期待下周继续跟进这些问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: rstats","slug":"CephFS_Code_Walkthrough_-_rstats","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/CephFS_Code_Walkthrough_-_rstats/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/CephFS_Code_Walkthrough_-_rstats/","excerpt":"","text":"会议纪要：CephFS R-Stats 实现讨论 会议主题 本次会议主要讨论了Ceph文件系统（CephFS）中递归树统计（R-Stats）的实现细节及其在文件系统检查（File System Check）中的应用。 主要议题 R-Stats 的定义与用途： R-Stats 用于在递归前向 scrubbing 过程中检查统计数据的一致性。 提出了使用快照 R-Stats 来检测两个文件系统树（即两个快照之间）的变更。 Scrubbing 的启动方式： Scrubbing 可以针对常规目录或内部 MDS 目录启动，但不使用递归标志时，仅验证目录的一层。 R-Stats 的维护与结构： R-Stats 的维护依赖于 frag_info 和 nest_info 结构，这些结构嵌入在 fnode_t 容器结构中。 frag_info 维护单个目录片段的信息，而 nest_info 累积深度超过一层的条目统计。 R-Stats 的传播： R-Stats 从叶节点（目录或文件）向文件系统根节点传播。 传播是懒惰的，不即时发生，涉及路径上所有 fnode 对象的更新。 挑战与问题： R-Stats 的传播涉及大量锁定，是一个复杂的并发问题。 快照目录的 RC 时间更新存在 bug，正在调查中。 决定事项 确认了 R-Stats 在文件系统检查和快照变更检测中的重要性。 需要进一步解决 R-Stats 传播中的锁定和并发问题。 后续行动计划 继续调查和修复快照目录的 RC 时间更新 bug。 研究优化 R-Stats 传播过程中的锁定机制，以提高效率和可靠性。 会议结束 会议结束时，主持人询问是否有其他问题，并表示如果没有更多问题将结束分享。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-08-11","slug":"Ceph_Crimson_SeaStore_2021-08-11","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Crimson_SeaStore_2021-08-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Crimson_SeaStore_2021-08-11/","excerpt":"","text":"会议纪要 主要议题与讨论内容 CI系统中的C语言编译器替换 讨论了将当前使用的GCC替换为Clang编译器，以避免Sealant构建失败的问题。 决定未来将不再使用GCC，而是坚持使用Clang，假设如果构建通过Clang，也应该能通过GCC。 FIO构建问题 遇到了FIO在Clang 10或Sealant 11上构建失败的问题，正在尝试解决。 创建了PR来移除在头文件中使用namespace lcd_one的声明，因为这被数百个源文件包含。 针对FIO本身的另一个问题，创建了补丁使用原子操作库来实现顺序锁。 测试与调试 讨论了FIO测试在没有调试信息输出时容易失败的问题，正在尝试解决。 提到了一个回归问题，可能是由最近的集成引入的，需要进一步调查。 其他开发进展 讨论了关于 scrubbing 的问题，正在处理相关问题并计划添加新的PR。 提到了LBA管理器的重写，已经通过了单元测试，正在进行更多的集成工作。 讨论了多设备支持的进展，几乎完成，但仍在调试中。 性能与冲突分析 讨论了从旧节点到LBA的冲突移动，通过图表比较了集成前后的情况。 提到了在CI中集成性能测试工具的可能性，但认为目前还不是优先事项。 编译问题与CI/CD 讨论了编译速度问题，通过启用CCache有所改善。 提到了CI/CD系统的升级和相关问题，包括网络配置和包管理。 决定事项 未来将不再使用GCC，而是使用Clang进行构建。 将继续解决FIO构建问题，并优化测试流程。 将继续推进多设备支持和LBA管理器的开发。 后续行动计划 继续解决FIO构建问题，并优化测试流程。 完成LBA管理器的集成工作，并准备提交PR。 继续调试多设备支持，并准备提交PR。 进一步分析和优化性能测试，考虑在CI中集成相关工具。 解决CI/CD系统升级中的问题，并优化构建流程。 其他 会议中还讨论了具体的编译命令和测试案例，以及如何处理Jenkins任务的取消。 讨论了如何处理特定的编译和集成问题，包括如何处理回归问题和具体的代码修改。 结束语 会议结束时，所有参与者都表示将继续推进各自的工作，并保持沟通以解决遇到的问题。感谢所有人的参与和贡献，期待下次会议的进一步更新。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-08-18","slug":"Ceph_Crimson_SeaStore_2021-08-18","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Crimson_SeaStore_2021-08-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Crimson_SeaStore_2021-08-18/","excerpt":"","text":"会议纪要 关键细节 参与者: 会议涉及多名研发人员，包括但不限于Sam, Sean, Kifu等。 时间: 会议讨论了近期的工作进展和遇到的问题。 项目: 主要围绕Ceph存储系统的开发和测试。 讨论的主要议题 代码修改与测试: 会议开始时，一位开发者讨论了他在启用syllabus和将所有警告视为错误方面的进展，以防止潜在的特定替代品替换组织。 另一位开发者提到了他对allocate x10的PR修改，以及尝试重现一个在cat组件中常见的问题。 版本更新与问题重现: 讨论了更新到当前master分支后遇到的问题，特别是在interruptible future中。 确认了使用的是release build，并且测试了包含最新补丁的master分支。 问题跟踪与解决: 提到了创建跟踪票（tracker ticket）来记录和解决遇到的问题。 讨论了如何重现cache is dirty的问题，该问题虽然不总是发生，但频率较高。 代码审查与项目进展: Sam分享了他对多个PR的审查工作，特别是关于sway hounds和lba tree的进展。 Sean提到了他对extent placement pr的修改，以及对多设备支持的调整。 决定的事项 确认了使用包含最新补丁的release build进行测试。 决定继续跟踪和重现cache is dirty的问题，并尝试找到稳定的重现方法。 确认了代码审查和项目进展的下一步行动。 后续的行动计划 继续测试和验证release build中的问题，并确保所有警告被正确处理。 持续跟踪和解决cache is dirty的问题，并更新跟踪票。 完成对sway hounds和lba tree的审查，并推进相关项目的开发。 对extent placement pr进行进一步的修改和测试。 其他事项 Kifu宣布这将是他在团队的最后一周，团队成员对他的离开表示了感谢和祝福。 结论 会议涵盖了多个技术问题和项目进展，强调了持续测试、问题跟踪和代码审查的重要性。团队成员对Kifu的离开表示了深深的遗憾和祝福。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2021-08-11","slug":"Ceph_Docubetter_Meeting_2021-08-11","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Docubetter_Meeting_2021-08-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Docubetter_Meeting_2021-08-11/","excerpt":"","text":"会议纪要 会议参与者： Laura 其他未明确提及的参与者 会议时间： 会议在Laura所在地的上午11:46开始。 主要议题： 技术文档更新与维护 Laura正在重新运行set idiom文档，等待Sebastian审核两个PR。 计划重写Sephio发现页面，目标是在9月1日前完成。 正在进行RADOS文档的重写，预计将持续到10月中旬。 新倡议与文档改进 Patrick Donnelly提议了一个“self-at-home”倡议，旨在帮助对技术感兴趣但不熟悉如何使用的人。Laura计划撰写相关文档。 Etienne从法国提交的Nomad文档正在等待技术审核，之后Laura将重写以确保英语地道。 性能计数器文档更新 Laura更新了性能计数器文档，解释了其重要性和使用场景，特别是帮助诊断内存管理和延迟问题。 Tautology文档审查 Laura正在审查YouTube频道上的Tautology教程视频，并建议改进相关文档。 文档质量与风格 讨论了文档的语法和风格问题，强调了文档清晰度和专业性的重要性。 实习与招聘 Laura的实习即将结束，她将在9月作为全职员工返回。 讨论了Keifu的离职，以及团队成员的知识转移和文档更新。 决定事项： Laura将继续推进文档的重写和更新工作。 确认了Keifu的离职，并计划通过知识转移确保团队工作的连续性。 后续行动计划： Laura将继续处理RADOS文档的重写，并监控PR的合并进度。 继续审查和改进Tautology文档，确保其准确性和易用性。 实习生Laura将在9月以全职身份回归，继续参与文档和团队工作。 其他备注： 会议中提到了Etherpad的故障，影响了文档的访问。 Laura对团队的氛围和同事的友好态度表示赞赏。 会议结束： 会议在Laura的祝福和其他参与者的感谢中结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-08-17","slug":"Ceph_Orchestrator_Meeting_2021-08-17","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Orchestrator_Meeting_2021-08-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Orchestrator_Meeting_2021-08-17/","excerpt":"","text":"会议纪要 会议基本信息 日期: [具体日期] 时间: [具体时间] 参会人员: Karen, Sebastian, Travis, Arun 等 主持人: [主持人姓名] 会议议题 Podman 问题讨论 问题描述: 大约三分之二的任务因为 Podman 管理问题失败。 原因分析: Podman 的稳定版本存在问题，且 Podman 项目推送了损坏的稳定版本。 讨论内容: 是否使用最新版本的 Podman。 是否禁用 Podman 测试，转而使用 Docker 基础的测试。 决定事项: 需要内部讨论并可能向 Podman 项目反馈问题。 客户端管理需求 需求描述: 需要有效管理客户端主机，如 OpenStack 客户端或挂载 LBD 或 ASF 的客户端。 具体需求: 安装客户端库包。 正确配置 csfsaf.conf 文件。 分发客户端安全密钥。 讨论内容: 如何在没有持续 root 访问权限的情况下分发客户端密钥和配置文件。 讨论了使用 Ceph 管理模块和 Ceph 代理的可能性。 决定事项: 目前 Paul 的 Pull Request 已经提供了部署客户端密钥和配置文件的能力，暂时不需要额外的解决方案。 Rook 相关更新 更新内容: 设备列表问题已由 PR 修复，但状态检查仍有问题。 本地存储功能正在逐步推进。 后续行动: 需要与 LSO 团队合作，确保长期兼容性和正确性。 集成测试新方法 新方法介绍: 使用 Behave 框架进行集成测试，已实现部分测试用例。 后续行动: 下周将向社区展示这一新测试方法的演示。 后续行动计划 Podman 问题: 内部讨论并可能向 Podman 项目反馈问题。 客户端管理: 继续使用 Paul 的 Pull Request 提供的解决方案，观察其效果。 Rook 更新: 与 LSO 团队合作，确保本地存储功能的长期兼容性。 集成测试: 向社区展示 Behave 框架的集成测试方法，并收集反馈。 其他事项 会议中提到了一些技术细节和具体实现问题，需要在会后进一步讨论和明确。 会议结束 下次会议: 下周同一时间 会议总结: 会议讨论了多个关键议题，包括 Podman 问题、客户端管理需求、Rook 更新和集成测试新方法，并制定了相应的后续行动计划。 会议结束时间: [具体时间] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-08-10","slug":"Ceph_Orchestrator_Meeting_2021-08-10","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Orchestrator_Meeting_2021-08-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Orchestrator_Meeting_2021-08-10/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 会议 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： Rook CI 中 Manager Rook 模块的测试 讨论了如何在 Rook CI 中测试 Manager Rook 模块。 介绍了测试框架的使用，包括使用 Kubeadm、Minikube、Kcli 等工具设置固定集群。 强调了集成测试的重要性，特别是在 Rook 项目中自动检测潜在问题。 提出了未来测试的改进方向，特别是关于 OSD 的管理和创建。 重置设计设置 OC Flex 讨论了在重启 OSD 时是否应设置 noout 标志。 确认了当前的做法是在维护模式下设置 noout，并在一定时间后重置。 存储私钥和 YAML 规范 讨论了在 YAML 规范中存储私钥的问题，特别是在使用 GitHub 存储 YAML 文件时。 提出了改进的必要性，但认为这不是最高优先级。 区域和区域组创建 讨论了在 Orchestrator 中创建区域和区域组的问题。 确认了需要引入 YAML 文档来简化这一过程。 本地存储操作符讨论 讨论了本地存储操作符的需求和设计。 提出了关于静态和动态存储供应的讨论，以及是否需要创建新的操作符。 决定事项： 确认了在 Rook 项目中集成测试的重要性，并计划改进 OSD 的管理和创建。 确认了在维护模式下设置 noout 的做法，并在一定时间后重置。 提出了改进存储私钥的方法，但认为这不是最高优先级。 确认了需要引入 YAML 文档来简化区域和区域组的创建。 提出了关于本地存储操作符的需求和设计，以及是否需要创建新的操作符。 后续行动计划： 继续改进 Rook 项目中的集成测试，特别是关于 OSD 的管理和创建。 研究改进存储私钥的方法，并评估其优先级。 引入 YAML 文档来简化区域和区域组的创建。 进一步讨论本地存储操作符的需求和设计，并决定是否需要创建新的操作符。 其他事项： 讨论了 Python 版本兼容性问题，并计划解决相关测试失败的问题。 会议结束： 会议在讨论完所有议题后结束，并安排了下次会议的时间。 以上是本次 Orchestrator 会议的详细纪要，涵盖了会议的主要议题、决定事项和后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-08-19","slug":"Ceph_Performance_Meeting_2021-08-19","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Performance_Meeting_2021-08-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Performance_Meeting_2021-08-19/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统中关于分布式存储的一些关键议题，特别是围绕着如何优化使用不同类型的存储设备（如QLC驱动器）以及如何处理大量小对象的存储问题。会议还涉及了Ceph的开发进度和未来的行动计划。 主要讨论议题 动态增加存储池大小： 讨论了通过添加新的OSDs（Object Storage Daemons）来动态增加存储池大小的可能性，以及这种做法的灵活性和潜在的挑战。 存储池数量的增加请求： 收到了关于需要大幅增加可创建存储池数量的反馈，讨论了可能的解决方案，如为每个存储类别创建两个不同的存储池。 RGW（RADOS Gateway）存储池的使用： 探讨了实际用户或客户是否创建多个RGW存储池，以及这些存储池的常见使用模式。 多站点配置中的区域（Zone）使用： 讨论了在多站点配置中，区域的使用频率和可能遇到的问题，特别是在存储池数量限制方面。 性能优化策略： 讨论了通过分离存储池来提高性能的策略，特别是在处理大量小对象时。 Ceph开发进度和未来计划： 回顾了最近的开发工作，包括对RocksDB缓存的更改、文件元数据更新的处理以及一些性能改进的实施。 讨论了未来的工作计划，如处理RocksDB缓存的变化和准备提交的一些改进。 决定事项 确认了通过增加新的OSDs来动态扩展存储池大小的可行性。 同意需要进一步研究和实验来解决存储池数量限制的问题。 确定了需要继续讨论和优化RGW存储池的使用和管理。 后续行动计划 继续研究和实验，以找到最佳的存储池管理和优化策略。 邀请Intel的专家参与未来的讨论，以获取更多关于QLC驱动器和OpenCSD技术的反馈。 继续推进Ceph的开发工作，特别是关于RocksDB缓存的改进和性能优化。 备注 会议中提到的“OpenCSD”和“QLC驱动器”是讨论中的关键技术术语，这些术语在存储技术领域具有特定的含义和应用。 会议强调了需要持续关注和适应新的硬件技术，以优化Ceph的性能和功能。 本次会议为Ceph存储系统的未来发展提供了重要的方向和决策基础，特别是在处理复杂存储需求和新技术集成方面。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-08-12","slug":"Ceph_Performance_Meeting_2021-08-12","date":"2021-08-19T16:00:00.000Z","updated":"2021-08-20T16:00:00.000Z","comments":true,"path":"2021/08/20/Ceph_Performance_Meeting_2021-08-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/08/20/Ceph_Performance_Meeting_2021-08-12/","excerpt":"","text":"会议纪要 日期： [具体日期] 参会人员： Casey, Mark, Igor, Adam, Niha, Josh, Gabby 等 主要议题 RGW对象缓存PR讨论 Casey提出了一个关于RGW（RADOS Gateway）对象缓存的PR，希望有人能审查。该PR旨在通过包装现有缓存并创建分片来启动对象缓存，作为重构前的临时解决方案。 讨论了该PR的潜在价值，包括消除锁竞争的可能性，但需要更多数据支持。 BlueFS日志增量更新模式 讨论了BlueFS日志的增量更新模式，旨在减少日志增长速度。提出了两个PR，最终将选择一个进行合并。 调试构建变更的回滚 讨论了回滚一个导致始终从源代码构建调试版本的变更，该变更可能对测试造成混淆。 延迟IO路径的改进 讨论了改进延迟IO路径的PR，特别是在硬盘驱动器上运行时减少写放大。提出了多个PR，旨在优化这一过程。 MDS锁切换到公平互斥锁 讨论了将MDS锁切换到公平互斥锁的PR，请求Patrick进行审查。 其他PR和更新 讨论了多个其他PR，包括RGW跟踪、Radix优化、BlueFS精细锁定等，以及一些需要重新审查和测试的PR。 决定事项 同意将Igor的PR应用于master和Pacific版本，以改进延迟IO路径。 同意进行更多测试，特别是针对硬盘驱动器的性能测试，以更好地理解写放大问题。 后续行动计划 Casey将继续推动RGW对象缓存PR的审查和测试。 团队将继续审查和测试BlueFS日志增量更新模式的PR。 将进行更多针对硬盘驱动器的性能测试，以验证和优化延迟IO路径的改进。 继续跟踪和审查其他PR，确保所有变更都经过充分的测试和审查。 下次会议： 下周 备注： 会议超时，但所有议题均得到充分讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Ceph Community Ambassador BoF","slug":"Ceph_Month_2021_-_Ceph_Community_Ambassador_BoF","date":"2021-06-24T16:00:00.000Z","updated":"2021-06-24T16:00:00.000Z","comments":true,"path":"2021/06/25/Ceph_Month_2021_-_Ceph_Community_Ambassador_BoF/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/25/Ceph_Month_2021_-_Ceph_Community_Ambassador_BoF/","excerpt":"","text":"会议纪要 会议主题：社区大使计划讨论 会议时间：[具体日期] 参会人员：[列出主要参会人员] 会议内容总结： 社区大使计划的提出 背景：社区管理员在处理日常事务中面临大量工作，特别是在疫情后活动恢复期间。 目的：建立社区大使计划，以协助社区管理员，特别是在不同地区组织活动时提供支持。 社区大使的职责 组织活动：协助或组织Ceph Day活动，包括预算申请、场地安排、餐饮和社交活动。 协调meetup：与各地meetup组织者合作，确保活动的活跃性和更新meetup wiki页面。 支持会议：协助本地会议的组织，包括提供swag和寻找演讲者。 内容协调：参与CFP（Call for Papers）协调，与市场开发工作组合作，更新网站内容。 具体行动计划 更新社区列表：创建或调整社区邮件列表，确保所有相关人员都能收到更新。 联系meetup组织者：根据地区分工，联系各地meetup组织者，了解活动状态并提供支持。 准备活动物资：为即将恢复的线下活动准备swag和其他物资。 后续行动 邮件列表更新：会议结束后，将更新社区邮件列表，并邀请参会人员加入。 活动准备：根据疫情和地区限制，准备即将到来的Ceph Day和其他社区活动。 决定事项： 建立社区大使计划，明确大使的职责和行动计划。 更新和维护社区邮件列表，确保信息流通。 后续行动计划： 更新社区邮件列表，并邀请相关人员加入。 根据地区分工，联系meetup组织者，了解活动状态并提供支持。 准备即将到来的Ceph Day和其他社区活动的物资和计划。 会议结束语： 感谢所有参会人员的参与和贡献，我们将继续在邮件列表中跟进相关事宜。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Ceph Market Development Working Group BoF","slug":"Ceph_Month_2021_-_Ceph_Market_Development_Working_Group_BoF","date":"2021-06-24T16:00:00.000Z","updated":"2021-06-24T16:00:00.000Z","comments":true,"path":"2021/06/25/Ceph_Month_2021_-_Ceph_Market_Development_Working_Group_BoF/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/25/Ceph_Month_2021_-_Ceph_Market_Development_Working_Group_BoF/","excerpt":"","text":"会议纪要 会议概要 会议由Cameron主持，来自Softline的营销总监，讨论了关于Ceph市场发展组（Ceph Market Development Group）的成立和目标。会议涉及了该组织的成立背景、目标、工作方式以及未来的行动计划。 讨论的主要议题 Ceph市场发展组的成立背景： 该组织由多个供应商组成，旨在提高Ceph在软件定义存储市场中的认知度、理解和考虑度。 主要面向企业技术决策者，而非开发者或工程师。 为何需要Ceph市场发展组： 强调Ceph的成功对于所有相关供应商的重要性。 认识到当前技术环境的复杂性和竞争性，希望通过提升Ceph的知名度来帮助其在市场中脱颖而出。 Ceph市场发展组的工作方式： 组成一个跨供应商的工作组，与Canonical、Red Hat等紧密合作。 目标是推动更多的商业导向营销活动，以触及更广泛的受众。 Ceph市场发展组的未来行动计划： 继续每两周举行一次会议，制定长期战略。 计划向Ceph基金会董事会申请预算，以执行一系列营销活动。 邀请社区成员参与，共同推动Ceph的市场推广。 决定的事项 确认了Ceph市场发展组的目标和行动计划。 决定继续使用现有的Ceph用户邮件列表进行沟通，并在主题行中添加特定标签以便识别。 后续的行动计划 继续定期会议，制定和执行营销策略。 更新和优化Ceph官方网站，增加更多教育内容和案例研究。 通过各种渠道，包括社交媒体、搜索引擎营销等，提升Ceph的知名度和市场占有率。 邀请更多社区成员参与，共同推动Ceph的发展和市场推广。 其他讨论点 讨论了如何更好地整合和展示Ceph社区的工作组信息，以便社区成员更容易参与和了解。 提到了Ceph官方网站的更新和改进，以及如何通过网站更好地服务社区和潜在用户。 结论 会议强调了Ceph市场发展组的重要性，并呼吁社区成员积极参与和支持。通过集体努力，目标是提升Ceph的市场地位和认知度，促进其在企业环境中的更广泛应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Evaluating CephFS Performance vs. Cost on High-Density Commodity Disk Servers","slug":"Ceph_Month_2021_-_Evaluating_CephFS_Performance_vs._Cost_on_High-Density_Commodity_Disk_Servers","date":"2021-06-24T16:00:00.000Z","updated":"2021-06-24T16:00:00.000Z","comments":true,"path":"2021/06/25/Ceph_Month_2021_-_Evaluating_CephFS_Performance_vs._Cost_on_High-Density_Commodity_Disk_Servers/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/25/Ceph_Month_2021_-_Evaluating_CephFS_Performance_vs._Cost_on_High-Density_Commodity_Disk_Servers/","excerpt":"","text":"会议纪要 背景信息 CERN的计算环境：CERN使用名为“Worldwide LHC Computing Grid”的全球性计算网格进行数据处理。CERN作为Tier Zero中心，拥有约135PB的磁盘存储（双副本）和近400PB的磁带存储。每年新增数据量约50PB。 全球分布：CERN周边有14个Tier 1中心和160个Tier 2中心（大学和实验室），总计约100万个CPU核心，每天处理约200万个作业。 存储和网络：全球存储总量约1EB，内部总连接速度约1Tbps。去年在全球LHC计算网格上转移了300PB的数据。 存储软件和技术 开源存储软件：CERN使用多种开源存储软件，如DCache, DPM, EOS, Storm, XRootD等，这些软件由高能物理（HEP）社区开发。 协议和服务：使用HTTP, XRootD, GSI-FTP等协议进行站点间传输，通过File Transfer Service (FTS)进行第三方传输，并根据网络约束调度传输。 数据协调器：Rucio作为数据协调器，根据不同策略与FTS交互并放置数据。 未来挑战和解决方案 高亮度LHC数据需求：预计到2028年，每年数据需求将增至500PB。 Ceph的角色：Ceph作为成熟且功能强大的开源存储软件，可能在未来物理存储系统中扮演重要角色。然而，现有的开源软件缺乏某些高级功能。 解决方案：通过在开源存储软件上叠加HEP特定的网关，如CephFS + EOS的组合，来解决这些缺失的功能。 实验和性能测试 硬件配置：使用8台大型新机器进行测试，每台机器配备双Xeon处理器、192GB RAM、100Gbps以太网、60TB硬盘和1TB SSD。 CephFS配置：测试了三种不同的擦除编码布局（4+2, 8+2, 16+2），并使用upmap平衡器确保平衡。 性能结果：在读取性能方面，最多达到20GB/s；在写入性能方面，最多达到34GB/s。发现随着OSD存储空间的增加，写入性能下降。 后续行动计划 生产环境测试：计划在生产环境中进一步测试CephFS + EOS组合，以验证其在实际使用中的性能和操作优势。 优化和改进：考虑统一命名空间和本地化I/O，以便客户端可以直接使用原生Ceph客户端，而不需要通过EOS客户端。 结论 CephFS和EOS的组合：展示了在高密度商品磁盘服务器和100G网络上的出色性能，具有高度可靠性和灵活性，并可通过QoS进行调整。 社区支持：Ceph拥有一个庞大且活跃的用户社区，超越了物理社区。 未来工作：将继续测试和优化这一组合，以满足未来高能物理存储系统的需求。 讨论和问题 读取性能问题：讨论了读取性能在达到一定水平后饱和的原因，可能是由于磁盘寻道延迟。建议调整内核客户端的预读设置以改善性能。 CephFS快照的使用：在特定场景如同步和共享服务中，CephFS快照将得到更有效的使用。 后续行动 继续在生产环境中测试CephFS + EOS组合。 优化命名空间和I/O本地化策略。 调整内核客户端设置以改善读取性能。 探索CephFS快照在同步和共享服务中的应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-06-23","slug":"Ceph_Crimson_SeaStore_2021-06-23","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T16:00:00.000Z","comments":true,"path":"2021/06/24/Ceph_Crimson_SeaStore_2021-06-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/24/Ceph_Crimson_SeaStore_2021-06-23/","excerpt":"","text":"会议纪要 关键细节 PR创建与处理：Aaron创建了一个PR来处理同步问题，以便能够中断正在运行的命令，如HD和MD测试工具中的控制C命令，并使用内置的HPV服务器暴露指标。 Zone设备集成：讨论了集成Zone设备的方法，主要使用zoned和nvme pass-through ioctl，以及即将到来的异步ioctl。 调试与构建问题：讨论了调试构建与发布构建的差异，特别是调试构建中存在的问题，如无效范围的处理和比较x属性的支持。 同步与元数据问题：修复了fretboard中的同步问题，并正在处理PG元数据加载中的分段错误问题。 性能监控：尝试通过系统度量基础设施暴露指标，并改进调试设施以更好地处理核心转储问题。 讨论的主要议题 Zone设备管理：讨论了使用nvme pass-through ioctl处理Zone设备管理的可行性，以及异步ioctl的潜在优势。 构建与调试问题：分析了调试构建中存在的问题，包括无效范围的处理和比较x属性的支持。 元数据与同步问题：讨论了fretboard中的同步问题和PG元数据加载中的分段错误问题。 性能监控与调试设施：探讨了如何通过系统度量基础设施暴露指标，并改进调试设施以更好地处理核心转储问题。 决定的事项 Zone设备管理：决定继续探索nvme pass-through ioctl的使用，并关注异步ioctl的发展。 构建与调试问题：决定继续支持比较x属性，并解决调试构建中的问题。 元数据与同步问题：决定继续修复fretboard中的同步问题，并处理PG元数据加载中的分段错误问题。 性能监控与调试设施：决定改进调试设施，以便更好地处理核心转储问题。 后续的行动计划 Zone设备管理：继续探索nvme pass-through ioctl的使用，并关注异步ioctl的发展。 构建与调试问题：继续支持比较x属性，并解决调试构建中的问题。 元数据与同步问题：继续修复fretboard中的同步问题，并处理PG元数据加载中的分段错误问题。 性能监控与调试设施：改进调试设施，以便更好地处理核心转储问题。 参会人员 Aaron 其他未具名参会者 会议结束 会议在讨论了各项议题和后续行动计划后结束，参会人员表示感谢并期待后续的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: CephFS + fscrypt: filename and content encryption","slug":"Ceph_Month_2021_-_CephFS_+_fscrypt_-_filename_and_content_encryption","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T16:00:00.000Z","comments":true,"path":"2021/06/24/Ceph_Month_2021_-_CephFS_+_fscrypt_-_filename_and_content_encryption/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/24/Ceph_Month_2021_-_CephFS_+_fscrypt_-_filename_and_content_encryption/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统中的透明加密支持 主讲人：Jeff 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容总结： 项目背景与目标： Jeff自一年前开始着手一个项目，旨在为Ceph文件系统提供透明加密支持。 该项目涉及的核心组件是fscrypt，一个内核库，文件系统可以调用它来实现文件名、文件内容和符号链接目标的透明加密。 技术细节： fscrypt在文件系统级别操作，不需要密钥来挂载文件系统，但需要密钥来访问和操作加密的目录树。 目前支持fscrypt的文件系统包括ext4、f2fs和ubifs，Jeff正在努力使其适用于网络文件系统。 加密机制： 每个加密的目录树有一个主密钥，每个加密的inode有一个关联的加密上下文。 fscrypt使用密钥派生函数生成每个inode的密钥，确保即使丢失密钥也能清理目录并回收空间。 用户工具与工作流程： 提供了一个用Golang编写的用户空间工具，用于生成和管理主密钥。 工作流程包括初始化、文件系统设置、加密空目录以及锁定和解锁目录。 inode数据存储： 每个inode关联一个40字节的blob，包含加密模式、主密钥ID和随机数据（nonce）等信息。 为了确保文件名的合法性，使用base64编码，并在必要时对文件名进行截断和哈希处理。 MDS（元数据服务器）支持： 引入了一个新的fs crypt auth属性，挂载在inode上，MDS将其视为不透明的blob。 增加了新的pert entry alternate name字段，用于存储完整的加密文件名。 内容加密挑战： 内容加密仍在进行中，涉及AES加密和处理块数据的问题。 需要处理截断操作，确保不会破坏加密块的完整性。 演示与反馈： Jeff展示了如何在Ceph集群中使用fscrypt加密目录，并演示了加密前后的文件名变化。 讨论了将此功能扩展到其他文件系统（如SMB和NFS）的可能性。 后续行动计划： 继续完善内容加密部分，解决截断操作和数据路径的问题。 探索将加密功能集成到新的库模块netfs中，以支持更广泛的网络文件系统。 决定事项： 继续推进fscrypt在Ceph中的集成，特别是内容加密和数据路径的优化。 考虑将此功能扩展到其他文件系统，如SMB和NFS。 后续行动： Jeff将继续完善fscrypt的实现，并寻求社区的帮助和支持。 社区成员可以关注并参与相关的代码审查和测试工作。 会议结束语： Jeff感谢大家的参与和反馈，并期待在未来的版本中看到这一功能的完整实现。 注： 以上纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，保留了部分计算机科学/Ceph相关领域英文原文的关键词。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Crimson Update","slug":"Ceph_Month_2021_-_Crimson_Update","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-24T16:00:00.000Z","comments":true,"path":"2021/06/24/Ceph_Month_2021_-_Crimson_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/24/Ceph_Month_2021_-_Crimson_Update/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph项目的两个关键进展：Crimson和C-Store。Crimson是一个新的OSD（对象存储守护进程）实现，旨在替换现有的Ceph OSD，以更好地适应下一代存储硬件的需求，减少CPU开销。C-Store则是一个新的对象存储实现，专为Crimson的线程回调模型设计，旨在利用新兴存储技术如ZNS和持久内存。 主要议题 Crimson OSD的进展 Crimson OSD的目标是通过减少每个I/O的CPU开销来提高性能，特别是在多核环境下的性能。 使用C-Star框架来减少上下文切换，通过为每个核心分配单一线程并分区数据结构和任务来实现。 近期工作集中在实现RBD（RADOS块设备）工作负载、数据持久性和可靠性、可见性和调试以及稳定性。 C-Store的详细介绍 C-Store设计避免使用CPU密集型的元数据设计，如RocksDB，并利用快速NVMe设备和持久内存。 ZNS（Zone Namespace）是一种新的NVMe规范，通过将驱动器分为只能顺序写入的区域来减少写放大和垃圾回收。 持久内存因其低延迟和高写入耐久性，适合作为数据和元数据的持久缓存。 C-Store的高级设计 C-Store的逻辑结构包括根块、O节点索引、Omap树和逻辑地址到物理地址的映射。 使用逻辑地址映射来简化垃圾回收和数据重定位，减少写放大。 日志记录使用原子写入和重放机制，支持逻辑和物理块的变更。 决定事项 Crimson OSD和C-Store的开发将继续集中在稳定性和性能优化上。 未来工作将包括多核支持、克隆支持、直接突变支持和持久内存支持。 后续行动计划 继续推进Crimson OSD的稳定性测试和功能移植。 优化C-Store的垃圾回收机制和性能。 探索与NVMe over Fabric网关的潜在集成。 其他讨论 SPDK（Storage Performance Development Kit）将在C-Store之下作为底层I/O细节的插件。 Crimson OSD目前支持BlueStore，未来可能会有更多与NVMe over Fabric网关的协同工作。 结论 会议强调了Crimson和C-Store在Ceph项目中的重要性，并明确了未来的开发方向和目标。感谢Sam的详细介绍和所有参与者的积极参与。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-06-22","slug":"Ceph_Orchestrator_Meeting_2021-06-22","date":"2021-06-23T16:00:00.000Z","updated":"2021-06-23T16:00:00.000Z","comments":true,"path":"2021/06/24/Ceph_Orchestrator_Meeting_2021-06-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/24/Ceph_Orchestrator_Meeting_2021-06-22/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 周例会 会议时间：[具体日期] 参会人员：[参会人员名单] 会议议程： KCLI 项目进展 Paramecio 适用性问题 会议内容： 1. KCLI 项目进展 项目介绍：介绍了使用 KCLI 项目来设置 Kubernetes 集群并通过 Rook 操作符启动 Ceph 集群的新计划。 技术细节：讨论了在个人笔记本上进行测试所需的资源（如足够的内存和硬盘空间），并探讨了如何简化开发和集成测试过程。 工具对比：比较了 KCLI 和 Vagrant 的相似性，讨论了各自的优缺点，以及是否需要安装额外的工具。 团队反馈：欢迎团队成员提出意见和建议。 2. Paramecio 适用性问题 问题描述：讨论了 Paramecio 作为 SSH 的封装层，存在功能限制和错误信息隐藏的问题。 替代方案：探讨了使用 ZincSSH 或其他库的可能性，以及是否需要一个同步库。 技术挑战：讨论了如何处理远程主机上的多命令执行问题，包括使用持久性 SSH 连接或远程 Python 解释器。 团队决策：初步决定尝试使用 AsyncSSH，并考虑移除对 Remoto 的依赖，以简化实现。 决定事项： KCLI 项目：继续推进 KCLI 项目，收集团队反馈以优化工具选择和使用。 Paramecio 问题：尝试使用 AsyncSSH 作为替代方案，评估其适用性和性能。 后续行动计划： KCLI 项目：团队成员需提供关于 KCLI 和 Vagrant 的使用反馈，以便进一步优化开发环境。 Paramecio 问题：进行 AsyncSSH 的实验性测试，评估其是否能满足项目需求，并解决多命令执行的问题。 其他事项： RGW 集成测试：确认 RGW 集成测试的进展，计划进行测试套件的转换工作。 NFS 和 Dashboard 工作：继续推进 NFS 相关工作和 Dashboard 模块的改进。 会议结束： 会议于[具体时间]结束，下次会议定于下周进行。 以上是本次会议的详细纪要，涵盖了会议的主要议题、讨论内容、决定事项及后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: CephFS update","slug":"Ceph_Month_2021_-_CephFS_update","date":"2021-06-22T16:00:00.000Z","updated":"2021-06-23T16:00:00.000Z","comments":true,"path":"2021/06/23/Ceph_Month_2021_-_CephFS_update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/23/Ceph_Month_2021_-_CephFS_update/","excerpt":"","text":"会议纪要 会议主题：Ceph Pacific版本更新及未来计划 主讲人：Patrick Donnelly, Ceph FS技术负责人 会议时间：待定 会议地点：线上 主要内容： Pacific版本成就 多文件系统支持稳定性提升：现在创建文件系统更加简单，自动化程度提高。 MDS自动扩展器：根据文件系统需求自动启动和停止MDS。 Ceph FS Top工具：管理员可以监控文件系统的使用情况，收集性能统计信息。 Ceph FS Shell：一个简单的Python实用程序，允许在文件系统上执行命令，无需使用FUSE或内核。 快照计划管理模块：允许在Ceph FS上按计划创建和保留快照。 NFS网关支持：通过NFS管理器模块，可以创建NFS集群来导出Ceph FS。 内核客户端加密支持：正在进行中，部分功能已实现。 性能和稳定性提升 API设置最小客户端版本：确保客户端连接到集群的兼容性。 多MDS文件系统扫描：现在支持在多个活动MDS的情况下进行扫描。 内核客户端支持Messenger V2：通过内核挂载选项启用。 异步创建和删除支持：提高操作效率。 多站点和生态系统改进 快照镜像工具：支持基于快照的远程集群复制。 Kubernetes CSI环境支持：改进与Kubernetes的集成。 Ceph FS Token Windows客户端：类似于Ceph FUSE，提供Windows系统上的访问。 未来计划（Quincy版本） 异步rmdir、link和rename支持：提高性能。 异步元数据操作支持：正在进行中。 MDS滚动升级支持：简化升级过程。 libcephfs SQLite：一个新的客户端，允许在Ceph FS上使用SQLite数据库。 MDS内存目标：优化MDS的内存使用。 后续行动计划： 继续改进和开发Ceph FS的各项功能。 收集社区反馈，特别是关于Ceph FS Top工具和Ceph FS Shell的反馈。 推动Quincy版本的新功能开发，包括异步操作支持和MDS滚动升级。 会议结束： 感谢所有参与者的参与。 请查看会议链接中的后续活动日历。 备注： 会议中提到的详细内容和博客文章将在稍后分发。 欢迎随时提问和提供反馈。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Cephadm Update","slug":"Ceph_Month_2021_-_Cephadm_Update","date":"2021-06-22T16:00:00.000Z","updated":"2021-06-23T16:00:00.000Z","comments":true,"path":"2021/06/23/Ceph_Month_2021_-_Cephadm_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/23/Ceph_Month_2021_-_Cephadm_Update/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统更新与部署策略 会议时间：[具体日期] 参会人员：Ceph研发团队、系统运维团队、项目管理团队 会议内容总结： Ceph集群部署更新： 讨论了Ceph集群的安装和配置工具，特别是FDP（Flexible Distributed Placement）在西部的应用。 强调了使用Robert Popall的操作工具进行集群管理的重要性。 提到了针对外部管理者的用例，需要高效地分离和处理集群中的问题。 容器化与服务部署： 讨论了容器化技术在Ceph集群中的应用，特别是在私有云和系统区域中的部署。 强调了容器化对于提高系统灵活性和可维护性的重要性。 提到了通过使用单个容器和服务组来优化需求服务。 系统升级与维护： 讨论了Ceph集群的自动升级策略，特别是在使用Octopus版本时的具体操作。 强调了升级过程中的监控和数据展示的重要性。 提到了通过集成和 daycare 中心来优化接口和服务的实施。 安全与性能优化： 讨论了通过优化内存管理和性能提升来增强Ceph集群的性能。 强调了通过避免端口冲突和资源配置来提高系统的稳定性。 提到了通过集成不同的服务和避免冲突来优化系统的整体性能。 文档与支持： 讨论了文档的重要性，特别是在部署和管理Ceph集群时。 强调了通过提供详细的文档和支持来帮助用户更好地理解和使用Ceph系统。 提到了通过提供单一文档来整合所有相关服务和配置信息。 决定事项： 确认了Ceph集群的部署和升级策略。 确定了优化内存管理和性能提升的具体措施。 确认了文档和支持服务的改进计划。 后续行动计划： 继续优化Ceph集群的部署工具和文档。 实施内存管理和性能优化的具体措施。 定期更新和维护Ceph集群的文档和支持服务。 会议结束时间：[具体时间] 备注：本次会议纪要基于会议讨论的内容进行了总结，具体的技术细节和实施方案需要进一步的技术文档和实施计划来支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Improving Cosbench for Ceph Benchmarking","slug":"Ceph_Month_2021_-_Improving_Cosbench_for_Ceph_Benchmarking","date":"2021-06-22T16:00:00.000Z","updated":"2021-06-23T16:00:00.000Z","comments":true,"path":"2021/06/23/Ceph_Month_2021_-_Improving_Cosbench_for_Ceph_Benchmarking/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/23/Ceph_Month_2021_-_Improving_Cosbench_for_Ceph_Benchmarking/","excerpt":"","text":"会议纪要 会议主题：改进Cosbench的成本基准测试 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容总结： Cosbench简介： Cosbench是一个开源项目，由Intel上海研发中心在2013-2015年间开发，主要用于S3对象存储的基准测试。 该项目具有高度的可扩展性和模块化设计，支持多种对象存储系统，包括Amazon S3和Google Cloud。 Cosbench的应用： 在Softline公司，Cosbench主要用于客户特定的基准测试，帮助客户理解和配置适合其工作负载的集群。 尽管存在其他基准测试工具，如fio和hsbench，但由于Cosbench的广泛采用和使用，它已成为比较性能结果的标准。 Cosbench的架构和功能： Cosbench采用控制器-驱动器架构，易于扩展到大集群。 支持多种工作负载，包括混合读写操作，并能自动平衡多个HTTP端点的负载。 Cosbench的挑战和改进： 目前Cosbench缺乏有效的构建系统，且项目维护不足，最新版本存在问题。 会议中提出了一些内部改进措施，包括引入Maven构建系统、打包为Debian软件包、改进工作负载生成和结果处理脚本。 后续行动计划： 计划将内部改进的Cosbench分支公开，以便社区其他用户受益。 探索进一步改进Cosbench的可能性，如增加数据流的随机性，以更好地测试去重功能。 决定事项： 将内部改进的Cosbench分支公开，并提供Debian软件包。 继续探索和改进Cosbench的功能，特别是数据流的随机性。 后续行动： 准备并发布改进后的Cosbench分支。 收集社区反馈，进一步优化和扩展Cosbench的功能。 会议结束时间：[具体时间] 备注： 会议中提到的其他工具和项目，如fio、hsbench、cbt等，也值得进一步研究和评估。 鼓励社区成员参与Cosbench的改进和扩展，共同推动项目的发展。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Optimizing Ceph on Arm64","slug":"Ceph_Month_2021_-_Optimizing_Ceph_on_Arm64","date":"2021-06-22T16:00:00.000Z","updated":"2021-06-23T16:00:00.000Z","comments":true,"path":"2021/06/23/Ceph_Month_2021_-_Optimizing_Ceph_on_Arm64/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/23/Ceph_Month_2021_-_Optimizing_Ceph_on_Arm64/","excerpt":"","text":"会议纪要 会议主题：M64上的安全存储生态系统实践 主讲人：Rachel 会议内容概述： 自我相关工作概述： 在AMP服务器上进行了安全存储生态系统的实践，包括使用特定指令或特性进行通用优化，如UTF-8 DRC ISA。 在M64平台上启用了多个服务器项目，如SPDK系统、Safe CSI等，并进行了优化。 支持使用Safe作为OpenStack和Kubernetes的存储后端。 优化工作： 对UTF-8字符串处理和CRC-33实现进行了优化，分别提升了8倍和3倍的性能。 在ISA库中添加了对CRC IGB、AES GCM等算法的支持，并实现了多缓冲算法。 为M64添加了基于CPU特性集的实用函数，并提供了一个框架来生成基于特性集的最佳函数。 64KB内核页面的启用和基准测试： 在M64平台上支持64KB内核页面，通过移除一级页表，提高了TLB查找速度和TLB命中率。 使用一个包含一个监控器、一个管理器和三个OSD的测试集群进行了基准测试，结果显示使用64KB内核页面可以带来3%到11%的性能提升。 SPDK和DPDK的优化： SPDK通过将所有必要驱动程序移到用户空间并采用轮询模式，避免了内核上下文切换和中断处理开销。 DPDK采用了C11内存模型，优化了内存屏障的使用，并利用GCP的incoming CPU特性进行优化。 Ceph在ARM服务器上的性能状态： 在ARM服务器上进行了Ceph的性能测试，结果显示在某些情况下SPDK并未带来明显的性能提升。 Ceph在C4上的工作： 支持Ceph作为Kubernetes容器云存储后端，并添加了对关键容器镜像的支持。 正在进行的工作包括支持容器存储接口在线C4和Kubernetes存储e2e测试的改进。 后续行动计划： 继续探索新的优化点，如利用可扩展向量扩展（SVE）和非临时性指令进行优化。 进一步研究和优化SPDK和DPDK在ARM架构上的性能。 继续支持Ceph在Kubernetes上的集成和优化。 会议讨论： 讨论了ISA库在非Intel架构上的实现和使用，以及如何在混合CPU集群中安全使用ISA擦除编码。 探讨了在Raspberry Pi上使用ARM架构进行存储的可能性。 会议结束： Rachel感谢大家的参与和提问，并表示将继续进行相关研究和优化工作。 注： 会议中提到的技术术语和项目名称如SPDK、DPDK、Ceph、ISA等，均为计算机科学和存储领域的关键技术，保留原文以确保准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-06-17","slug":"Ceph_Performance_Meeting_2021-06-17","date":"2021-06-22T16:00:00.000Z","updated":"2021-06-22T16:00:00.000Z","comments":true,"path":"2021/06/23/Ceph_Performance_Meeting_2021-06-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/23/Ceph_Performance_Meeting_2021-06-17/","excerpt":"","text":"会议纪要 关键细节 MDS改进提案：本周有一个有趣的pull request针对MDS（元数据服务器），旨在改进在并发客户端访问同一文件时的锁定机制。理论上，这可能减少长时间等待获取读锁的情况，但需要进一步测试验证。 B树分配器提交：ifu提交了一个新的B树分配器，可能在内存使用和某些情况下的性能上有所优势，尽管会增加CPU使用。初步测试显示，与AVL分配器相比，空间改进接近两倍，CPU消耗增加不大。 内存管理讨论：讨论了新的分配器在长时间运行测试中的潜在问题，特别是关于碎片化和内存使用的增长。建议进行更长时间的测试以验证其稳定性。 TC malloc缓存大小调整：Adam提交了一个新的pull request，允许在运行时修改TC malloc缓存的大小，这被认为是改进内存管理的一个正确方向。 讨论的主要议题 性能优化：讨论了多个pull request，旨在优化Ceph的性能，特别是在高并发和高负载情况下的表现。 内存管理：深入讨论了新的B树分配器在实际应用中的表现，包括其对内存使用和CPU消耗的影响。 配置管理：讨论了如何更好地管理Ceph组件的配置，特别是在运行时调整缓存大小的能力。 决定的事项 测试新分配器：决定对新的B树分配器进行更深入的测试，包括长时间运行和高负载条件下的表现。 配置管理改进：支持Adam的pull request，认为这是改进Ceph配置管理的正确方向。 后续行动计划 深入测试：对新的B树分配器进行包括长时间运行和高负载条件下的测试。 性能分析：继续分析和优化Ceph在不同配置下的性能表现，特别是在高并发和高负载情况下的稳定性。 配置管理优化：进一步讨论和实施运行时配置调整的方案，以提高Ceph的灵活性和性能。 本次会议涵盖了Ceph存储系统的多个关键技术领域，包括性能优化、内存管理和配置管理，旨在通过技术改进提升系统的整体稳定性和效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Evaluation of RBD replication options @CERN","slug":"Ceph_Month_2021_-_Evaluation_of_RBD_replication_options_@CERN","date":"2021-06-21T16:00:00.000Z","updated":"2021-06-21T16:00:00.000Z","comments":true,"path":"2021/06/22/Ceph_Month_2021_-_Evaluation_of_RBD_replication_options_@CERN/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/22/Ceph_Month_2021_-_Evaluation_of_RBD_replication_options_@CERN/","excerpt":"","text":"会议纪要 会议主题：CERN SAFE项目中RBD复制选项的评估 主讲人：Archer 会议内容总结： 项目背景与目标： Archer自三月起作为研究员加入CERN的SAFE团队。 SAFE项目涉及四个Ceph集群，为OpenStack Cinder提供服务，管理约七千个卷，总容量达八兆字节。 项目目标是为Cinder卷提供灾难恢复解决方案，允许用户在不同集群（数据中心或数据中心内的不同房间）之间进行复制。 技术细节与挑战： RBD复制模式： 日志模式（Journal Mode）： 客户端在写入RBD镜像的同时写入日志，导致性能问题，尤其是在大块写入时，性能下降约50%。 镜像性能在默认设置下较慢，每镜像约30MB/s，通过调整参数可提升至40-50MB/s，但仍不理想。 快照模式（Snapshot Mode）： 通过定期快照实现数据复制，非连续复制，性能优于日志模式，每镜像可达200MB/s。 目前OpenStack Cinder不支持快照镜像，但已提交补丁，预计未来版本可能支持。 测试环境： 使用SAFE Octopus版本，配置包括6台实验机，60个OSDs（混合场景，数据在HDD，DB在SSD），18个OSDs专用于RBD日志。 客户端运行FIO进行随机写负载测试。 结论与后续行动： 鉴于日志模式的性能问题，团队计划采用快照模式进行进一步测试和优化。 已提交五个补丁以提高RBD复制的可观察性和稳定性，并计划继续与社区合作，贡献代码。 问答环节： 快照频率：初始测试中使用最小频率（1分钟），但实际应用中可能会根据FS3S快照工作的进展调整。 文件系统冻结支持：目前尚未遇到因缺乏文件系统冻结支持导致的问题，但预计未来应用中会有所帮助。 日志模式性能：在较大RBD集群中，客户端性能可能受限于集群带宽，尤其是进行双写操作时。 后续行动计划： 继续测试快照模式，确保其稳定性和性能。 与OpenStack Cinder开发团队合作，推动快照镜像功能的集成。 持续提交补丁，优化RBD复制的性能和稳定性。 会议结束语： 感谢Archer的详细介绍和解答，期待后续的进展和成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Qemu: librbd vs krbd performance","slug":"Ceph_Month_2021_-_Qemu_-_librbd_vs_krbd_performance","date":"2021-06-20T16:00:00.000Z","updated":"2021-06-21T16:00:00.000Z","comments":true,"path":"2021/06/21/Ceph_Month_2021_-_Qemu_-_librbd_vs_krbd_performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/21/Ceph_Month_2021_-_Qemu_-_librbd_vs_krbd_performance/","excerpt":"","text":"会议纪要 会议主题： 讨论和比较Ceph的两种主要客户端（librbd和krbd）的性能表现。 会议目的： 为了解答客户关于librbd和krbd性能差异的疑问，特别是针对特定工作负载（Kimu workloads），会议旨在通过数据收集和比较，展示这两种客户端的性能特点。 主要讨论内容： 测试目标和方法： 定义了四个主要测试场景，包括使用librbd和krbd的虚拟机测试，以及在物理主机上使用librbd和krbd的测试。 测试包括随机读写，块大小为4k、64k和4MB，使用不同的I/O引擎。 每个场景进行了五次非连续运行，以确保结果的可比性。 测试结果： 在虚拟机环境中，librbd和krbd的性能几乎相同，平均性能差异在100%左右。 在物理主机上，krbd的性能显著优于librbd，特别是在高队列深度（q depth）和大块大小的情况下。 发现librbd在特定设置下有一个约20,000 IOPS的性能上限。 后续行动计划： 计划使用Pacific版本进行进一步测试，并重新比较结果。 将公开fio配置，以便其他人可以在自己的系统上进行测试。 决定事项： 确认了librbd在特定环境下的性能上限约为20,000 IOPS。 计划进行进一步的测试以验证和探索性能差异的原因。 后续行动： 使用Pacific版本进行测试，并重新评估性能数据。 公开fio配置，促进社区的进一步测试和验证。 会议总结： 会议成功地定义了测试场景和方法，收集并分析了librbd和krbd的性能数据，为解答客户疑问提供了科学依据。后续将继续进行深入测试和分析，以更好地理解性能差异的原因，并探索可能的优化方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-06-16","slug":"Ceph_Crimson_SeaStore_2021-06-16","date":"2021-06-15T16:00:00.000Z","updated":"2021-06-16T16:00:00.000Z","comments":true,"path":"2021/06/16/Ceph_Crimson_SeaStore_2021-06-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/16/Ceph_Crimson_SeaStore_2021-06-16/","excerpt":"","text":"会议纪要 关键细节 设备管理支持： 需要定义zone space和其他结构以支持设备管理。 参考了FTL库和SPDK中的定义，以获取灵感。 PR审查与更新： 审查了一个成熟的PR，涉及管理多个zones。 更新了PR，修复了单元测试中的bug，并移除了catch extent。 单元测试问题： 发现一个单元测试存在问题，但系统API测试未报告此问题。 讨论了使用计数器等于1的问题，计划后续处理。 构建问题： 在release build中发现parent pointer问题，debug build未触发此问题。 讨论了垃圾收集行为，建议使用mbd测试工具。 Ceph Master分支问题： 在当前master分支中，创建pool时出现问题，但在旧分支中可以正常工作。 建议其他人验证是否存在问题。 接口要求： 讨论了zone设备的接口要求，建议参考c-store中的segment manager.h。 需要创建适配器以暴露设备信息。 fmt库更新： 提议将fmt库从6升级到7.1.3或7.1.4，以解决gcc编译问题。 创建了格式化构造，希望尽快合并。 事务管理器转换： 正在进行事务管理器的interrupted future转换。 计划将所有消费者也转换为使用interrupted future。 调试与测试： 讨论了在调试过程中遇到的问题，如invalid extent和osd map读取问题。 建议增加更多调试输出，以帮助定位问题。 决定事项 设备管理支持： 需要定义zone space和其他结构以支持设备管理。 参考FTL库和SPDK中的定义，以获取灵感。 PR审查与更新： 更新PR，修复单元测试中的bug，并移除catch extent。 构建问题： 在release build中发现parent pointer问题，建议使用mbd测试工具。 Ceph Master分支问题： 建议其他人验证是否存在问题。 接口要求： 需要创建适配器以暴露设备信息。 fmt库更新： 将fmt库从6升级到7.1.3或7.1.4。 事务管理器转换： 正在进行事务管理器的interrupted future转换。 后续行动计划 设备管理支持： 定义zone space和其他结构。 创建适配器以暴露设备信息。 PR审查与更新： 继续审查和更新PR。 构建问题： 使用mbd测试工具调试parent pointer问题。 Ceph Master分支问题： 验证是否存在问题。 接口要求： 创建适配器以暴露设备信息。 fmt库更新： 将fmt库从6升级到7.1.3或7.1.4。 事务管理器转换： 完成事务管理器的interrupted future转换。 将所有消费者也转换为使用interrupted future。 调试与测试： 增加更多调试输出，以帮助定位问题。 验证osd map读取问题。 通过本次会议，团队明确了设备管理支持、PR审查与更新、构建问题、Ceph Master分支问题、接口要求、fmt库更新、事务管理器转换以及调试与测试等方面的关键细节、决定事项和后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Project Aquarium - An easy-to-use storage appliance wrapped around Ceph","slug":"Ceph_Month_2021_-_Project_Aquarium_-_An_easy-to-use_storage_appliance_wrapped_around_Ceph","date":"2021-06-15T16:00:00.000Z","updated":"2021-06-16T16:00:00.000Z","comments":true,"path":"2021/06/16/Ceph_Month_2021_-_Project_Aquarium_-_An_easy-to-use_storage_appliance_wrapped_around_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/16/Ceph_Month_2021_-_Project_Aquarium_-_An_easy-to-use_storage_appliance_wrapped_around_Ceph/","excerpt":"","text":"会议纪要：Project Aquarium 介绍与讨论 会议概述 本次会议由Alex Saddle主持，他作为软件工程经理在Souza公司工作，同时也是Project Aquarium的产品负责人。会议主要介绍了Project Aquarium的目标、架构、演示以及未来的发展计划。 关键细节 项目名称：Project Aquarium 项目目标：简化Ceph的开发、部署和管理，提供一个开源的存储设备解决方案。 项目团队：由Souza公司的存储团队开发，Alex Saddle担任产品负责人，另一位高级工程师担任后端负责人。 项目架构：分为两个主要部分，后端称为“Gravel”，前端称为“Glass”。后端使用Python，前端使用Angular。 技术选择：Aquarium作为系统服务运行，不采用容器化，依赖于fadm等系统工具。使用WebSockets进行节点间通信，并利用fcd来维护集群状态。 用户界面：目标是提供一个简化的、引导式的安装和操作界面，抽象复杂概念，如不直接暴露Ceph的底层配置细节。 演示内容 安装过程：通过Web界面引导用户创建集群，选择存储设备，配置服务等。 集群管理：展示如何在现有集群中添加新节点，以及如何在不同节点间进行数据操作和管理。 后续行动计划 短期目标：改进仪表板，实现对象服务，测试USB启动和实际硬件上的Pixie booting。 中期目标：关注升级过程，开发块服务和资源约束求解器。 长期目标：社区发展和项目扩展，希望实现“世界统治”（幽默提及）。 讨论与问答 经验教训：从Ceph Dashboard的经验中学习，但Aquarium项目有其独特性，不直接竞争，而是提供不同的使用场景。 技术细节：使用Python Librados直接与Ceph通信，而不是依赖Dashboard API。 硬件选择：目前不特定于特定硬件模型，但未来可能会更具体化。 使用fcd的原因：确保Aquarium在Ceph故障时仍能运行，fcd提供必要的集群状态管理。 结论 Project Aquarium是一个新兴的开源项目，旨在简化Ceph的使用和管理。团队欢迎社区的参与和反馈，并计划通过一系列的改进和扩展来推动项目的发展。 联系方式 社区交流：通过Slack和GitHub讨论板进行。 会议安排：每周三次，覆盖不同时区。 入门指南：提供从零开始的入门指南。 感谢所有参与者的关注和提问，期待社区的进一步参与和支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Dashboard Update","slug":"Ceph_Month_2021_-_Dashboard_Update","date":"2021-06-14T16:00:00.000Z","updated":"2021-06-15T16:00:00.000Z","comments":true,"path":"2021/06/15/Ceph_Month_2021_-_Dashboard_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/15/Ceph_Month_2021_-_Dashboard_Update/","excerpt":"","text":"会议纪要 会议主题：Ceph Dashboard 更新与未来规划 参会人员：Ernesto Puerta（Ceph Dashboard 组件负责人） 会议时间：[具体时间] 会议地点：[具体地点] 会议内容总结： Pacific 版本亮点 Cepheum 集成：重点介绍了 Cepheum 集成，特别是与 Orchestrator 的整合，目前主要集中在 Cepheum 上。Rook 的支持仍在开发中，预计将在 Quincy 版本中完成。 RGW 增强：在 RGW 方面投入了大量精力，包括支持高级工作流程，如多站点监控和多站点同步监控。 RESTful API：在 Pacific 版本中，Dashboard 的 API 正式化，并承诺保持 API 的稳定性。 安全性改进：加强了 Dashboard 的安全性，包括账户锁定、使用安全 cookies 存储敏感信息等。 Quincy 版本规划 用户工作流程：计划提供更多高级用户工作流程，如集群安装向导。 多站点与多集群支持：增强对多站点和多集群的支持，包括 RGW 镜像和 CephFS 镜像。 RGW 高级工作流程：计划增加桶策略、生命周期管理、服务器端加密等功能。 可观测性增强：考虑增加日志聚合功能，以改善日志管理。 性能与用户体验改进 性能优化：讨论了关于 RBD 图像列表等性能问题，计划进行内部清理和重构以提高性能。 用户体验：计划改进 Dashboard 的登录页面，使其对所有用户更加友好。 后续行动计划 社区参与：鼓励社区成员通过 IRC 频道和 GitHub 参与到 Dashboard 的开发中。 技术分享：计划举办技术讲座，分享 Dashboard 的开发经验和代码走查。 会议决定事项： 确认了 Pacific 版本的主要更新和 Quincy 版本的发展方向。 确定了性能优化和用户体验改进的具体计划。 后续行动计划： 继续推进 Cepheum 和 Rook 的集成工作。 加强 RGW 功能和多站点支持的开发。 优化 Dashboard 的性能和安全性。 增强社区参与和技术分享活动。 联系方式： IRC 频道：[具体频道] GitHub：[具体链接] 会议结束时间：[具体时间] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: From Open Source  to Open Ended in Ceph with Lua","slug":"Ceph_Month_2021_-_From_Open_Source_to_Open_Ended_in_Ceph_with_Lua","date":"2021-06-14T16:00:00.000Z","updated":"2021-06-15T16:00:00.000Z","comments":true,"path":"2021/06/15/Ceph_Month_2021_-_From_Open_Source_to_Open_Ended_in_Ceph_with_Lua/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/15/Ceph_Month_2021_-_From_Open_Source_to_Open_Ended_in_Ceph_with_Lua/","excerpt":"","text":"会议纪要 会议主题：Ceph中Lua的集成与应用 参会人员：Ceph研发团队及相关领域专家 会议时间：[具体时间] 会议地点：[具体地点] 会议内容总结： Seth简介： Seth是一个开源且免费的工具，旨在提供灵活的存储解决方案。 Ceph作为一个包含2.5百万行C++代码的大型项目，具有复杂的架构和依赖关系。 Ceph的开放性： 尽管Ceph是开源的，但并非所有用户都有能力或意愿对其核心代码进行修改。 为了增强用户的参与度和灵活性，Ceph提供了多种机制，如对象类（CLS）和Lua集成，允许用户在不修改核心代码的情况下进行定制。 Lua在Ceph中的应用： Lua是一种成熟且强大的编程语言，易于学习和使用。 Lua在Ceph中的应用包括注入Lua对象类（CLS），允许在OSD（Object Storage Daemon）中运行Lua代码。 Lua的轻量级特性使其适合处理并发请求，且与C++的集成效率高。 Lua集成的优势： 提供简单易用的API，隐藏内部复杂结构，保持API的一致性。 支持零拷贝和零安装，简化开发和部署过程。 通过Lua集成，用户可以实现特定的业务逻辑和行为，而无需修改Ceph的核心代码。 具体应用案例： 通过Lua脚本解决客户端元数据缺失的问题，增强系统的灵活性和可扩展性。 在RGW（RADOS Gateway）中集成Lua，提供更多的定制选项和集成点。 后续行动计划： 继续探索和扩展Lua在Ceph中的应用，如压缩选项、对象分割等。 考虑在RGW中引入Lua层，以支持更多的逻辑处理和集成需求。 鼓励社区成员提出更多的使用案例和需求，以进一步丰富Lua在Ceph中的应用场景。 决定事项： 确认Lua作为Ceph的扩展语言，提供更多的定制和集成选项。 继续推动Lua在Ceph中的应用，增强系统的灵活性和可扩展性。 后续行动： 研发团队将深入研究Lua在Ceph中的具体应用场景，并制定详细的实施计划。 鼓励社区成员积极参与，提出更多的使用案例和需求，共同推动Ceph的发展。 会议结束时间：[具体时间] 下次会议安排：[具体时间] 以上是对本次会议内容的详细总结，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: RBD latency with QD=1 bs=4k","slug":"Ceph_Month_2021_-_RBD_latency_with_QD=1_bs=4k","date":"2021-06-14T16:00:00.000Z","updated":"2021-06-15T16:00:00.000Z","comments":true,"path":"2021/06/15/Ceph_Month_2021_-_RBD_latency_with_QD=1_bs=4k/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/15/Ceph_Month_2021_-_RBD_latency_with_QD=1_bs=4k/","excerpt":"","text":"会议纪要 会议主题： RBD性能优化与低延迟配置讨论 主讲人： Widow 日期： [具体日期未提供] 参会人员： [具体人员未提供] 主要议题： 1. RBD性能测试配置： 讨论了使用Q Depth（队列深度）为1和块大小为4K的RBD性能测试。 2. 单线程IO延迟的重要性： 强调了单线程IO延迟对于许多应用程序的重要性，特别是在PHP Web服务器、MariaDB数据库和Redis缓存等场景中。 3. Ceph的性能与设计目标： 解释了Ceph的设计目标（冗余性、可扩展性和数据安全）与低延迟之间的权衡。 4. 硬件配置与优化： 分享了使用特定硬件配置（如Super Micro系统、Epic 16核CPU、256GB内存、Samsung PM SSDs和100 Gigabit网络）进行性能测试的经验。 5. Ceph Crimson项目与RBD持久化缓存： 讨论了Ceph Crimson项目和RBD持久化缓存对未来性能提升的潜在影响。 决定事项： 1. 性能测试基准： 确定以Q Depth为1和4K块大小作为性能测试的起点。 2. 硬件优化策略： 强调了CPU C-State pinning和CPU性能配置文件对降低延迟的重要性。 3. 未来性能提升方向： 关注Ceph Crimson项目和RBD持久化缓存的发展，以期待更好的性能表现。 后续行动计划： 1. 持续性能测试： 继续使用Q Depth为1和4K块大小的配置进行性能测试，并根据测试结果调整硬件和软件配置。 2. 关注Ceph Crimson项目进展： 跟踪Ceph Crimson项目的开发进度，评估其对降低延迟的潜在影响。 3. 评估RBD持久化缓存： 在代码更稳定后，重新评估RBD持久化缓存的性能表现。 其他讨论点： - RBD缓存的影响： 讨论了RBD缓存对性能测试结果的影响，并指出在特定配置下RBD缓存可能不会被启用。 - Fio引擎的更新： 提到了Fio引擎的更新可能会影响性能测试结果，特别是在处理缓存和刷新操作方面。 会议结束： - Widow总结了测试单线程IO延迟的重要性，并感谢大家的参与和提问。 备注： - 会议中提到的具体硬件配置、软件版本和性能数据已记录，供后续参考和分析。 - 任何进一步的问题和讨论可以通过用户或开发者邮件列表进行。 会议记录人： [记录人姓名未提供] 会议记录日期： [记录日期未提供]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-06-15","slug":"Ceph_Orchestrator_Meeting_2021-06-15","date":"2021-06-14T16:00:00.000Z","updated":"2021-06-15T16:00:00.000Z","comments":true,"path":"2021/06/15/Ceph_Orchestrator_Meeting_2021-06-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/15/Ceph_Orchestrator_Meeting_2021-06-15/","excerpt":"","text":"会议纪要 会议主题：Ceph Dashboard 配置与 RGW 连接优化 参会人员：Alfonso、Sage、Casey、Jehuda 等 会议时间：[具体日期] 会议地点：视频会议 主要议题： Ceph Dashboard 中 Selfie IDM 网络设置的 Pull Request RGW 连接凭证的配置与优化 NFS 导出创建的 CLI 命令优化 Rook 管理模块的当前状态与后续行动 讨论内容： Selfie IDM 网络设置： 讨论了在 Dashboard 中设置 Selfie IDM 网络的 Pull Request。 确认等待 Sage 加入会议以进一步讨论。 RGW 连接凭证配置： 讨论了当前凭证设置方式，即按网关（gateway）设置。 提出了新的提案，建议按领域（realm）设置凭证，以简化配置。 讨论了凭证设置的具体实现细节，包括是否需要用户升级过程。 确认了凭证设置应基于区域（zone）而非网关，以避免混淆和错误。 NFS 导出创建的 CLI 命令优化： 讨论了当前 CLI 命令的不足，特别是创建命令的幂等性问题。 提出了使用“apply”命令替代“create”和“update”，以简化操作并确保幂等性。 Rook 管理模块： 更新了 Rook 管理模块的当前状态，包括 RGW 的 realm 和 zone 标志的启用情况。 讨论了 Rook 客户端 Python 库的维护和使用问题。 决定事项： RGW 连接凭证配置： 决定采用按领域（realm）设置凭证的方式，简化配置。 确认需要考虑用户升级过程，确保凭证设置的平滑过渡。 NFS 导出创建的 CLI 命令优化： 决定使用“apply”命令替代“create”和“update”，以简化操作并确保幂等性。 Rook 管理模块： 确认 Rook 客户端 Python 库的维护和使用问题，需要进一步测试和验证。 后续行动计划： RGW 连接凭证配置： 更新 Pull Request，确保凭证设置按领域（realm）进行。 准备用户升级指南，确保凭证设置的平滑过渡。 NFS 导出创建的 CLI 命令优化： 更新 CLI 命令，使用“apply”替代“create”和“update”。 确保新命令的幂等性和正确性。 Rook 管理模块： 进一步测试 Rook 客户端 Python 库，确保其稳定性和正确性。 准备 Rook 管理模块的后续开发计划。 会议结束： 确认无其他议题后，会议结束。 感谢所有参会人员，会议圆满结束。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: 5 more ways to break your ceph cluster","slug":"Ceph_Month_2021_-_5_more_ways_to_break_your_ceph_cluster","date":"2021-06-13T16:00:00.000Z","updated":"2021-06-14T16:00:00.000Z","comments":true,"path":"2021/06/14/Ceph_Month_2021_-_5_more_ways_to_break_your_ceph_cluster/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/14/Ceph_Month_2021_-_5_more_ways_to_break_your_ceph_cluster/","excerpt":"","text":"会议纪要 会议概述 本次会议由Vito，421的创始人，主持，主题为“破坏你的Ceph集群的五种新方法及一个额外提示”。会议回顾了Vito几年前关于“破坏Ceph集群的十种方法”的演讲，并分享了新的研究成果和经验教训。 讨论的主要议题 自动化工具的误用： 案例分析：自动化脚本未正确检查监控器数量，导致监控器被错误移除，包括监控数据库，造成严重停机。 教训：自动化工具的使用需谨慎，确保所有必要的检查和配置都已正确设置。 监控器的重要性误解： 案例分析：用户错误地认为监控器可以随意移除和重新创建，导致系统监控功能受损。 教训：监控器在Ceph集群中扮演关键角色，不应随意操作。 配置错误： 案例分析：集群配置中的最小副本数设置不当，导致数据恢复困难或数据丢失。 教训：建议始终使用至少三个副本以确保数据安全。 升级不完全： 案例分析：未完全遵循升级指南进行升级，导致集群在一段时间后出现问题。 教训：升级过程中应严格遵循官方指南，确保所有步骤都已完成。 过早完成升级： 案例分析：在未完全升级所有守护进程的情况下，启用增强安全设置，导致服务连接问题。 教训：升级应确保所有相关组件都已更新到最新状态。 PG自动缩放器的盲目信任： 案例分析：集群在数据量增加后，PG自动缩放器错误地增加了放置组，导致数据错位。 教训：应谨慎使用PG自动缩放器，并监控其行为以避免数据管理问题。 决定的事项 强调了自动化工具、监控器管理、配置设置、升级过程和PG自动缩放器使用的重要性。 提醒用户应持续关注和学习Ceph的最佳实践和更新，以避免潜在的风险。 后续行动计划 用户应重新评估和优化其Ceph集群的管理和配置，确保遵循最佳实践。 定期进行培训和知识更新，以提高对Ceph集群管理的理解和技能。 会议结束 会议在讨论和解答与会者的疑问后结束，强调了持续学习和实践的重要性，以确保Ceph集群的稳定和高效运行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: RBD Update","slug":"Ceph_Month_2021_-_RBD_Update","date":"2021-06-13T16:00:00.000Z","updated":"2021-06-14T16:00:00.000Z","comments":true,"path":"2021/06/14/Ceph_Month_2021_-_RBD_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/14/Ceph_Month_2021_-_RBD_Update/","excerpt":"","text":"会议纪要 会议主题： RBD 更新报告 主讲人： Ilya（RBD 团队技术负责人） 日期： [会议日期] 关键细节： 即时导入（Instant Import）： 在 Nautilus 中引入的图像实时迁移功能已扩展支持外部数据源。 支持通过 HTTP/HTTPS 的本地和远程文件，以及兼容 Amazon S3 的对象存储中的文件。 数据源格式支持 raw、qcow2 等，但不支持高级功能如压缩、加密等。 迁移准备后图像即可使用，读写操作会根据需要从数据源进行深度复制。 内置加密（Built-in Encryption）： 引入基于 LUKS 的加密，使用 AES 加密算法，支持 LUKS1 和 LUKS2 格式。 解决了 CoW 克隆可能使用相同密钥的问题，但目前仅支持非克隆图像的加密格式化。 性能改进： 通过重写 librbd I/O 路径，改进了小 I/O 性能，提升了 I/O 操作的效率。 引入了客户端持久写回缓存，改善了缓存管理和数据一致性。 快照 QS 钩子： 新增 RPC 消息，支持协调快照创建，特别是在集群级别的镜像快照中。 内核客户端支持： 内核 5.11 支持 Ceph Messenger 2.1 协议，改进了客户端与集群的通信。 支持副本读取和压缩操作，优化了跨数据中心的性能。 Windows 支持： 实现了 Windows 下的 librbd 和 librados 支持，通过 wnbd 驱动提供类似 Linux 的块设备接口。 决定事项： 继续完善和扩展 RBD 的功能，特别是在加密、性能优化和跨平台支持方面。 改进用户和管理员体验，特别是在缓存管理和快照操作方面。 后续行动计划： 在 Quincy 版本中完成加密格式化克隆和持久写回缓存的改进。 扩展崩溃恢复测试，优化缓存状态的可观测性和解释性。 增强 RBD 的监控和报警功能，特别是在镜像和快照管理方面。 探索和实施 NVMe-oF 目标网关，提升性能和可扩展性。 改进 QEMU 块驱动，支持写零操作和加密格式化图像的加载。 会议结束语： Ilya 感谢大家的参与，并欢迎会后通过 IRC 或电子邮件提出问题。会议记录和演示文稿将提供给未能参加的人员。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Intel QLC SSD: Cost-Effective Ceph Deployments","slug":"Ceph_Month_2021_-_Intel_QLC_SSD_-_Cost-Effective_Ceph_Deployments","date":"2021-06-10T16:00:00.000Z","updated":"2021-06-11T16:00:00.000Z","comments":true,"path":"2021/06/11/Ceph_Month_2021_-_Intel_QLC_SSD_-_Cost-Effective_Ceph_Deployments/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/11/Ceph_Month_2021_-_Intel_QLC_SSD_-_Cost-Effective_Ceph_Deployments/","excerpt":"","text":"会议纪要 会议主题：Intel QLC SSD在Ceph分布式存储系统中的成本效益分析 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： 主要议题： 讨论了Intel QLC SSD在Ceph存储系统中的应用，特别是在NVMe环境下的性能和成本效益。 对比了SSD与HDD的实际应用情况，包括成本、容量、可靠性和性能。 探讨了QLC技术的优缺点，以及其在实际部署中的潜在优势。 讨论要点： 成本分析：强调了QLC SSD在成本上的竞争力，尤其是在考虑到服务运行效率和维护成本时。 性能与可靠性：讨论了SSD（包括QLC）在IOPS和吞吐量上的优势，以及其在提高服务可用性和减少维护窗口方面的潜力。 技术细节：涉及了SSD的过配置（over-provisioning）、耐久性（endurance）和错误率（error rate）等技术参数，以及如何通过调整这些参数来优化存储系统的性能和可靠性。 决定事项： 确认了QLC SSD在特定应用场景下的成本效益优势，特别是在需要高容量和高性能的环境中。 讨论了未来可能的技术发展，如ZNS（Zoned Namespace）接口的SSD，以及如何进一步优化Ceph存储系统的配置和管理。 后续行动计划： 继续研究和测试QLC SSD在Ceph环境中的最佳实践，包括自动检测和设置最佳的写入单元大小（IU size）。 探索BlueStore的自动配置选项，以简化用户操作并提高系统性能。 考虑在未来的Ceph版本中集成更多针对QLC SSD的优化措施，如调整BlueFS的分配大小。 会议结束语： 感谢所有参与者的贡献和讨论，期待在未来的会议中继续探讨和优化Ceph存储系统的性能和成本效益。 附件： 会议PPT及相关技术文档 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Performance Optimization for All Flash based on aarch64","slug":"Ceph_Month_2021_-_Performance_Optimization_for_All_Flash_based_on_aarch64","date":"2021-06-10T16:00:00.000Z","updated":"2021-06-11T16:00:00.000Z","comments":true,"path":"2021/06/11/Ceph_Month_2021_-_Performance_Optimization_for_All_Flash_based_on_aarch64/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/11/Ceph_Month_2021_-_Performance_Optimization_for_All_Flash_based_on_aarch64/","excerpt":"","text":"会议纪要 会议主题：基于Oculus X46的Wolfram性能优化介绍 主讲人：Chenzon（华为） 会议时间：[具体日期] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容总结： 介绍与背景 Chenzon介绍了基于Oculus X46的Wolfram性能优化方案，该方案基于Queen Pong 920和Common 920平台。 强调了Queen Pong 920的核心配置，包括32、48和64核心，以及Prolink技术（2.6或3 GHz）。 技术架构与硬件 讨论了基于Cranbone芯片的技术架构，包括Tesla硬件的高质量CPU、SSD等。 提到了在Openonline平台上进行的测试，优化了CPU使用和并发槽数量。 性能优化措施 通过中断核心绑定、MTU调整和TCP参数调整优化了网络性能。 进行了IO性能优化，包括使用34页大小和opt message clc 32c。 测试了4k和54k的优化效果，显示了显著的性能提升和延迟降低。 多技术部署与优化 讨论了多技术部署，包括DDR多通道部署和消息加载槽的优化。 强调了数据流在同一NUMA节点内的完整性，以提高数据处理效率。 后续行动计划 计划进一步测试和优化，包括对4k和64k页面大小的进一步测试。 考虑将优化措施自动化，以便在不同配置下自动调整性能。 讨论与问题： CPU分区与线程管理：讨论了CPU分区的概念，以及是否可以自动进行线程管理以优化性能。 页面大小与内存管理：讨论了页面大小对性能的影响，以及如何减少内存浪费。 RocksDB与CRC校验：讨论了RocksDB的CRC校验问题，以及是否应将其包含在未来的版本中。 决定事项： 将继续进行性能测试和优化，特别是在不同页面大小和配置下的测试。 考虑将某些优化措施自动化，以简化配置和管理。 后续行动： 发送详细的CPU分区设置指南给相关团队。 提交页面大小优化的补丁或拉取请求。 考虑将RocksDB的CRC校验修复包含在未来的版本中。 会议结束： 会议在感谢Chenzon和Kevin的贡献后结束，准备进行下一场演讲。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Ceph in Research & Scientific Computing BoF","slug":"Ceph_Month_2021_-_Ceph_in_Research_Scientific_Computing_BoF","date":"2021-06-09T16:00:00.000Z","updated":"2021-06-10T16:00:00.000Z","comments":true,"path":"2021/06/10/Ceph_Month_2021_-_Ceph_in_Research_Scientific_Computing_BoF/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/10/Ceph_Month_2021_-_Ceph_in_Research_Scientific_Computing_BoF/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于Ceph分布式存储系统和科学计算的“鸟类聚会”，由Kevin主持。会议每两个月举行一次，旨在讨论Ceph和科学计算相关的话题，包括有趣的用例、实验和技术挑战。 主要讨论议题 Ceph RBD Mirroring: 下一周将有一位新成员进行关于RBD镜像的演示。 CephFS Snapshots: CERN团队正在测试CephFS的快照功能，发现了一些限制，特别是在Nautilus和Octopus版本中，快照删除操作非常慢。建议升级到Pacific版本以解决这些问题。 Ceph Adm的使用: 讨论了Ceph Adm在管理Ceph集群中的应用，特别是与Puppet的集成问题和容器镜像的管理。 Ceph升级经验分享: 分享了从Luminous升级到Octopus的经验，强调了升级过程中的一些关键步骤和注意事项，如确保所有虚拟机重启以避免安全问题。 CephFS性能问题: 讨论了CephFS在处理大量文件时的性能问题，特别是MDS日志段的管理和清理。 Ceph版本和包管理: 讨论了Ceph版本的升级策略和包管理的最佳实践，包括从FileStore迁移到BlueStore的计划。 决定事项 建议升级到Ceph Pacific版本以解决快照管理的性能问题。 需要进一步测试和验证Ceph Adm在不同环境下的兼容性和功能。 强调了在升级Ceph集群时，特别是涉及安全特性的升级时，需要特别注意文档中的警告和建议操作。 后续行动计划 继续测试Ceph Adm的功能和性能，特别是在集成Puppet和容器镜像管理方面。 计划在下一个会议周期（可能是8月或9月）再次举行“鸟类聚会”，以继续讨论Ceph和科学计算的相关话题。 对于CephFS的性能问题，将继续进行压力测试和优化，以确保在大规模文件系统中的稳定性和性能。 其他注意事项 会议中提到的关于Ceph Adm和Podman的特定问题，需要进一步的技术验证和社区反馈。 对于Ceph版本的升级，特别是从FileStore到BlueStore的迁移，需要详细的计划和测试，以确保数据的安全和服务的连续性。 本次会议为Ceph社区成员提供了一个交流和分享经验的平台，有助于推动Ceph在科学计算领域的应用和发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: RGW Update","slug":"Ceph_Month_2021_-_RGW_Update","date":"2021-06-09T16:00:00.000Z","updated":"2021-06-10T16:00:00.000Z","comments":true,"path":"2021/06/10/Ceph_Month_2021_-_RGW_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/10/Ceph_Month_2021_-_RGW_Update/","excerpt":"","text":"会议纪要 会议主题：Ceph 月度会议 - 第二周 会议时间：[具体日期] 参会人员：Ceph 社区成员、研发人员、相关领域专家 会议内容总结： RGW 更新介绍： S3 Select 功能：在 Pacific 版本中新增，支持对 CSV 格式的对象进行类似 SQL 的查询。Quincy 版本将进一步扩展查询类型和函数支持，并增加对 Parquet 格式的支持，以实现更高效的查询执行。 S3 Bucket Inventory：通过后台进程构建大型桶的索引，以提高列表和搜索的性能。 SSE S3 Bucket 加密：透明、基于策略的对象加密，无需客户端在上传时请求加密。 请求速率限制：已实现概念验证，预计在 Quincy 版本中推出。 数据缓存项目：与 Mass Open Cloud 合作，旨在通过本地数据缓存加速工作负载。 Jaeger 追踪支持：计划在 RGW 中构建 Jaeger 追踪支持，用于性能评估和优化。 Project Zipper：由 Dan Grinowicz 领导的项目，构建了一个抽象层，允许接入非 RADOS 后端或在其上堆叠层。 多站点支持：主要工作包括动态重共享支持、生命周期过渡到云服务、从云同步等。 讨论与提问： S3 Select 和 Bucket Inventory：Flipkart 的 Prasad 对 S3 Select 支持和 Bucket Inventory 感兴趣，询问了速率限制的实现细节。 Project Zipper：讨论了 Project Zipper 对不同后端的支持，以及在多站点环境中的应用。 数据缓存：CERN 的 Enrico 询问了数据缓存是否仍计划使用 Nginx 缓存，以及是否可以直接在 RGW 中实现。 版本支持：询问了新功能是否会回溯支持到 Pacific 版本。 Ganesha 导出支持：讨论了 Ganesha 导出支持在多站点环境中的应用。 索引格式：CERN 的 Dan 询问了索引格式是否会在未来版本中发生变化。 后续行动计划： 继续推进 S3 Select、Bucket Inventory、速率限制等功能的开发和测试。 完善 Project Zipper 的多后端支持，并探索在边缘部署中的应用。 加强数据缓存项目的研究和开发，考虑在 RGW 中直接实现缓存功能。 继续测试和优化多站点支持，特别是动态重共享和生命周期过渡到云服务。 会议结束语： 感谢 Casey 的详细更新和所有参会者的积极参与。期待在后续的开发和测试中取得更多进展。 以上是本次 Ceph 月度会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: The go-ceph get together BoF","slug":"Ceph_Month_2021_-_The_go-ceph_get_together_BoF","date":"2021-06-09T16:00:00.000Z","updated":"2021-06-10T16:00:00.000Z","comments":true,"path":"2021/06/10/Ceph_Month_2021_-_The_go-ceph_get_together_BoF/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/10/Ceph_Month_2021_-_The_go-ceph_get_together_BoF/","excerpt":"","text":"会议纪要 会议基本信息 主持人: John Mulligan 主题: GoCeph项目公开讨论 时间: 具体时间未提及 会议内容总结 项目历史回顾 GoCeph项目始于2014年，由Noah Watkins发起。 John Mulligan和其他维护者于2019年10月加入项目并开始活跃。 2020年2月发布了第一个官方版本0.2，此后每两个月发布一次新版本。 项目现状 主要模块包括FFS、RADOS和RBD，这些模块是对C API的封装。 主要目标是提供与Go函数类似的Ceph API，避免暴露C语言的复杂性。 RBD API是重点开发领域，CSI项目是其主要用户。 近期重要更新包括RBD镜像、快照以及厚/薄图像配置。 未来计划 短期计划包括完成RBD镜像功能和探索CephFS镜像功能。 项目仍有许多未封装的Ceph API，需要评估哪些功能需要优先实现。 技术发展 最近开发了多个管理包，如CephAdmin、RBDAdmin和RGWAdmin，使用JSON API进行管理操作。 Sven Anderson正在研究Go和C之间共享缓冲区的性能增强。 社区和文档 需要提高PR处理速度和改进文档。 正在考虑从v0升级到v1，但需要确保API的兼容性。 用户和项目反馈 讨论了如何更好地了解用户需求和优先级。 提到了一些使用GoCeph的项目，如CSI驱动和Rook。 技术细节讨论 讨论了Admin Socket的实现和GoCeph在Mac上的兼容性。 提到了改进PR处理速度和自动化测试的可能性。 后续行动计划 继续开发RBD镜像和CephFS镜像功能。 评估并决定哪些Ceph API需要优先封装。 改进文档和错误处理，准备从v0升级到v1。 探索提高PR处理速度的方法，如减少审查要求或增加自动化测试。 会议结束 会议在讨论了未来可能的改进和用户反馈后结束。 会议记录将被上传到Ceph YouTube频道。 备注: 会议中提到的具体技术细节和项目名称（如CSI、Rook、Admin Socket等）是Ceph和GoCeph项目中的关键术语，保留原文有助于理解相关领域的专业内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-06-10","slug":"Ceph_Performance_Meeting_2021-06-10","date":"2021-06-09T16:00:00.000Z","updated":"2021-06-10T16:00:00.000Z","comments":true,"path":"2021/06/10/Ceph_Performance_Meeting_2021-06-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/10/Ceph_Performance_Meeting_2021-06-10/","excerpt":"","text":"会议纪要 会议主题：Ceph性能对比分析及问题讨论 参会人员：Mark（缺席）、其他相关人员 会议时间：待定 主要议题： Ceph性能对比分析： 对比了Nautilus和Pacific版本在RGW工作负载下的性能。 使用了两种不同的工作负载：一种是主要针对较小对象（1KB至256KB）的cost bench，另一种是混合了小对象和大对象（最大1GB）的gauss bench。 发现Pacific在处理小对象工作负载时性能优于Nautilus，但在处理混合对象工作负载时性能不如Nautilus。 问题分析与讨论： OSD内存目标设置问题： 在Pacific版本中，OSD内存目标（OSD memory target）未被任何部署方法覆盖，特别是cephadm目前无法覆盖OSD内存目标。 Nautilus版本中，OSD内存目标应根据主机内存自动计算，但实际上实验中使用的内存远低于预期。 TC Malloc环境变量设置问题： 讨论了TC Malloc环境变量（PC Malloc Max Total Thread Cache Bytes）的设置问题，发现即使在Nautilus中，该变量也未正确设置。 提出了两个相关的PR（Pull Request）来解决这个问题，一个是全局设置，另一个是通过优先级缓存管理器设置。 后续行动计划： 重新进行实验以验证结果，特别是Nautilus版本的实验。 确保TC Malloc环境变量正确设置，并考虑是否需要动态调整。 讨论是否将相关更改回溯到Pacific版本。 其他讨论： Mark原计划讨论RBD测试和RGW的MTP使用情况，但由于缺席，推迟到下次会议。 确认了TC Malloc的灵活性，并讨论了动态调整的可能性。 后续会议： 下次会议将继续讨论RBD测试和RGW的MTP使用情况。 确认是否有其他议题需要讨论。 会议结束： 会议在无其他议题讨论的情况下结束，感谢所有参与者的贡献。 备注：会议中提到的关键术语和工具包括： - Ceph：分布式存储系统。 - RGW：Ceph的对象网关。 - OSD：Object Storage Daemon，Ceph的存储守护进程。 - TC Malloc：线程缓存malloc，一种内存分配器。 - cephadm：Ceph的部署和管理工具。 - PR：Pull Request，代码贡献的一种形式。 行动项： - 重新进行Nautilus版本的实验。 - 确保TC Malloc环境变量正确设置。 - 考虑回溯相关更改到Pacific版本。 - 动态调整TC Malloc设置的可能性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-06-09","slug":"Ceph_Crimson_SeaStore_2021-06-09","date":"2021-06-08T16:00:00.000Z","updated":"2021-06-09T16:00:00.000Z","comments":true,"path":"2021/06/09/Ceph_Crimson_SeaStore_2021-06-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/09/Ceph_Crimson_SeaStore_2021-06-09/","excerpt":"","text":"会议纪要 主要议题与讨论内容 SPDK 和 F2FS 的实现研究 上周开始阅读 SPDK 和 F2FS 的实现，特别是首次过期处理。 下一步计划研究 LBA 实现和段清理器，以收集必要信息，提高计算机收集效率。 讨论了添加序列 ID 的可能性，以跟踪每次写入的顺序。 C-Store 的稳定性问题 C-Store 目前存在崩溃问题，仅能完成两次 I/O 操作。 建议先观察崩溃情况，再尝试修复，但目前不建议在此部分工作，因为正在添加可中断的未来部分。 垃圾收集技术研究 讨论了使用模拟（mocks）来模拟系统行为的可能性，但认为这可能不是最有效的方法。 建议先观察 C-Store 的实际行为，再制定段清理器的策略。 中断可处理的未来部分 正在添加中断可处理的未来部分，这是一个重大的重构工作。 建议在完成这部分工作后再进行其他改进。 其他技术细节 讨论了使用 FIO 工具来测试事务管理器的稳定性。 提到了 Zweihan 正在添加的长期段垃圾收集机制。 决定事项 继续观察和研究 C-Store 的崩溃问题，等待中断可处理的未来部分完成后，再进行进一步的改进。 使用 FIO 工具来测试和观察 C-Store 的行为。 等待 Zweihan 完成长期段垃圾收集机制的添加，再进行更有效的段清理策略。 后续行动计划 继续研究 SPDK 和 F2FS 的实现，特别是 LBA 和段清理器的部分。 观察和记录 C-Store 的崩溃行为，尝试找出根本原因。 使用 FIO 工具进行测试，收集 C-Store 的实际行为数据。 等待中断可处理的未来部分完成后，再进行 C-Store 的进一步改进。 与 Zweihan 沟通，了解长期段垃圾收集机制的进展。 其他事项 讨论了编译器版本问题，建议在 GCC 10 上进行测试和调试。 欢迎新成员加入，期待下次会议能有更多贡献。 会议结束 会议在讨论了各项技术细节和后续行动计划后结束，大家表示期待下次会议的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-06-08","slug":"Ceph_Orchestrator_Meeting_2021-06-08","date":"2021-06-07T16:00:00.000Z","updated":"2021-06-08T16:00:00.000Z","comments":true,"path":"2021/06/08/Ceph_Orchestrator_Meeting_2021-06-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/08/Ceph_Orchestrator_Meeting_2021-06-08/","excerpt":"","text":"会议纪要 会议主题：Rook Manager 模块讨论 会议时间：本周的协调会议 参会人员：全体成员 主要议题： Gherkin 语言的实现介绍 Aaron 介绍了 Gherkin 语言，这是一种类似于自然语言的测试场景定义语言，旨在使非技术人员也能轻松定义系统应如何工作。 使用 Given、When 等关键字来运行场景并断言结果。 示例场景包括以 root 身份登录节点并执行特定命令，然后断言输出应与预期版本匹配。 测试框架的集成 讨论了使用 kcli 和虚拟机来快速创建和运行测试环境。 依赖于 Python 的行为驱动开发框架 Behave，使用 Gherkin 语言定义测试场景并通过 Python 实现执行。 讨论了项目文件结构和如何在社区中实施此项目。 Rook Manager 模块的状态和未来方向 讨论了如何在 Jenkins 中集成测试框架，确保测试的自动验证。 讨论了 Rook 在裸机部署中的适用性和如何管理设备。 确定了需要解决的关键问题，包括如何处理特定设备上的 OSD 创建和如何管理块数据库设备。 决定事项： 确定在 Jenkins 中集成测试框架。 确认需要新的接口来处理 Kubernetes 环境中的 PV 和动态供应。 确定需要与 Rook 和 LSO 的相关人员进行进一步讨论，以确定如何在裸机和非裸机环境中使用 Rook。 后续行动计划： Aaron 将继续推进 Gherkin 语言的实现和测试框架的集成。 确定与 Rook 和 LSO 相关人员的会议，以讨论如何在不同环境中使用 Rook。 Joseph 将继续调查 Rook 中的 orange ls 和 rgps 命令的问题，并确保这些命令在沙箱环境中正常工作。 其他讨论点： 讨论了 Rook 在不同环境中的使用，特别是如何在 OpenShift 中使用 Rook。 确认了需要进一步讨论如何在不同环境中管理设备和 OSD。 会议结束： 会议在确认下一步行动计划后结束。 下次会议： 下周继续讨论 Rook Manager 模块的进展和其他相关议题。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-06-02","slug":"Ceph_Crimson_SeaStore_2021-06-02","date":"2021-06-01T16:00:00.000Z","updated":"2021-06-02T16:00:00.000Z","comments":true,"path":"2021/06/02/Ceph_Crimson_SeaStore_2021-06-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/02/Ceph_Crimson_SeaStore_2021-06-02/","excerpt":"","text":"会议纪要 会议时间 日期：[具体日期未提供] 时间：[具体时间未提供] 参会人员 [具体人员未提供] 会议议题 Crimson OSD 启动失败问题 异常处理与错误报告 ZFS 学习与研究 事务管理器读取交换断言问题 OSD 停止异常 新实习生介绍 Scrubbing PR 讨论 Clang 编译问题修复 可中断分配器开发 扩展放置管理器调试 键值大小限制实现 讨论内容 Crimson OSD 启动失败问题 上周尝试复现 Travis 报告的 Crimson 在 Rook 中运行失败的问题。 本周重点解决启动 Crimson 时的错误报告问题。 异常处理与错误报告 提出一个修复方案，使用与 Ceph 数据库相同的清理函数钩子方法。 遇到 ASAN 问题，报告越界访问，后发现是 ASAN 本身的 bug，已创建 PR 解决。 ZFS 学习与研究 研究 ZFS 如何处理垃圾收集和分配器问题。 事务管理器读取交换断言问题 修复了因分段状态跟踪器混乱导致的事务管理器读取交换断言问题。 OSD 停止异常 发现 Crimson OSD 在启动后立即停止，未收到停止指令。 正在调试 LBA 析构函数中的断言问题，该断言表明缓存未清理。 新实习生介绍 Joseph 作为 Red Hat 的新实习生，加入会议了解 Crimson 项目。 Scrubbing PR 讨论 Brennan 讨论了关于 Scrubbing 的 PR，建议重新创建 PR 以包含最新的基础提交。 Clang 编译问题修复 Sam 修复了 Clang 编译问题，计划提交 reproducer 到 Clang 上游。 可中断分配器开发 继续开发可中断分配器，以便在 Ceph 存储中使用。 扩展放置管理器调试 正在调试扩展放置管理器，希望本周能提交 PR。 键值大小限制实现 实现了键值大小的限制，相关 PR 已合并。 决定事项 继续调试 Crimson OSD 启动和停止的异常问题。 重新创建 Scrubbing PR 以包含最新的基础提交。 提交 Clang 编译问题的 reproducer 到上游。 后续行动计划 继续调试和修复 Crimson OSD 相关问题。 完成 Scrubbing PR 的重新创建和测试。 提交 Clang 编译问题的 reproducer。 继续开发和测试可中断分配器。 完成扩展放置管理器的调试并提交 PR。 其他 欢迎新实习生 Joseph，并鼓励其参与 Crimson 项目。 会议结束 会议在无其他议题的情况下结束，感谢大家的参与。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-06-02","slug":"Ceph_Developer_Monthly_2021-06-02","date":"2021-06-01T16:00:00.000Z","updated":"2021-06-02T16:00:00.000Z","comments":true,"path":"2021/06/02/Ceph_Developer_Monthly_2021-06-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/02/Ceph_Developer_Monthly_2021-06-02/","excerpt":"","text":"会议纪要 主题一：Ceph中的故障条件处理 问题描述：在Ceph中，当发现未找到对象时，会进入backfill unfound状态（PG）。在重启primary OSD时，可能会发生异常情况。 已知问题： 在某些情况下，可能会导致崩溃，已有修复措施（移除断言）。 重启primary OSD时，如果另一个OSD成为临时的primary，并且该OSD没有该对象，可能会重新开始backfill过程，但不会找到该对象，导致PG进入clean状态。 讨论内容： 是否应该继续使用旧的行为，即重启OSD后忘记对象的不可读状态。 是否应该在backfill过程中记录缺失的对象，并在replica上强制添加到missing set。 决定事项： 对于旧版本，应加强现有行为，避免崩溃，但不尝试修复。 对于master版本，可以记录缺失集中的对象，并在backfill过程中处理。 后续行动： 进一步讨论和确定具体的修复方案。 增加对这些情况的测试覆盖，包括错误注入测试。 主题二：加密策略设计讨论 目标：讨论Ceph中的加密策略，特别是SSE-S3的支持。 现有支持： 客户端加密 SSE-C（客户端提供密钥） SSE-KMS（使用KMS） 待支持： SSE-S3（服务器管理密钥） 讨论内容： 如何实现SSE-S3，包括密钥管理、密钥轮换等。 如何与现有的KMS基础设施集成。 决定事项： 开始实现SSE-S3，包括支持put bucket encryption API。 考虑使用Vault作为KMS，并讨论其使用细节。 后续行动： 实现SSE-S3功能。 在refactoring会议上进一步讨论具体实现细节。 主题三：Manager模块的性能优化 问题描述：Manager模块在处理依赖关系时可能会遇到性能瓶颈。 讨论内容： 短期解决方案：合并所有模块到一个解释器中，避免多进程通信开销。 长期解决方案：探索使用Python的multi-isolated sub-interpreters。 决定事项： 尝试合并所有模块到一个解释器中，观察是否能解决性能问题。 关注Python新版本中的multi-isolated sub-interpreters的发展。 后续行动： 实施短期解决方案并测试其效果。 持续关注Python新特性的发展。 主题四：OSD Map的缓存策略 问题描述：OSD Map的频繁更新可能导致性能问题。 讨论内容： 使用缓存策略减少重复的序列化和反序列化操作。 考虑使用immutable对象和copy-on-write策略。 决定事项： 尝试使用缓存策略减少性能开销。 探索使用immutable对象和copy-on-write策略。 后续行动： 实施缓存策略并测试其效果。 进一步优化OSD Map的处理逻辑。 总结 本次会议主要讨论了Ceph中的故障条件处理、加密策略设计、Manager模块的性能优化以及OSD Map的缓存策略。会议确定了各个主题的后续行动计划，并强调了增加测试覆盖和持续优化的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Call for Participation: Ceph Stable Releases Team","slug":"Ceph_Month_2021_-_Call_for_Participation_-_Ceph_Stable_Releases_Team","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-01T16:00:00.000Z","comments":true,"path":"2021/06/01/Ceph_Month_2021_-_Call_for_Participation_-_Ceph_Stable_Releases_Team/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/01/Ceph_Month_2021_-_Call_for_Participation_-_Ceph_Stable_Releases_Team/","excerpt":"","text":"会议纪要 会议主题： Ceph 稳定版本发布流程及社区参与 主讲人： Louis Desjardins 会议概要： Louis Desjardins 介绍了 Ceph 稳定版本发布团队的工作流程，强调了社区参与的重要性，并讨论了如何优先处理回溯补丁（backport）。 主要议题： 1. Ceph 版本管理： - 目前最新的稳定版本是 Pacific，用户升级到 Pacific 点发布版本时，期望获得已回溯的 bug 修复和安全修复。 - 回溯补丁的过程涉及在旧版本上应用修复，这可能因代码变化而失败，需要手动调整。 测试流程： 每个回溯补丁在应用到 Pacific 之前，必须通过单元测试和大规模测试实验室的实际集群测试，以确保不会引入回归错误。 同时，还需确保 Octopus 集群可以升级到 Pacific，避免升级过程中的问题。 社区参与： 鼓励社区成员通过加入稳定版本发布团队来参与回溯补丁的工作。 新成员可以通过应用感兴趣的补丁到 Octopus 版本，并创建 Pull Request 来开始参与。 社区提供 IRC 频道（#ceph-backports）来协助新成员解决测试失败等问题。 公司参与： Louis 所在的公司 Easter Eggs 决定每月投入两天时间支持 Ceph 稳定版本发布团队，以回馈社区。 决定事项： - 强调了社区参与对于维护 Ceph 稳定版本的重要性，并鼓励更多公司和个人参与进来。 后续行动计划： - 继续推动社区成员参与 Ceph 稳定版本发布团队，特别是通过回溯补丁的工作。 - 探索和优化回溯补丁的优先级策略，以更好地满足用户需求。 讨论问题： - 如何优先处理回溯补丁？ - 目前没有明确的书面策略，主要依赖于紧急程度和社区的参与度。 - 对于某些复杂的修复，可能需要更多时间来确保其安全性，避免引入新的问题。 会议结束： 感谢 Louis Desjardins 的详细介绍和解答，会议圆满结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Ceph Project Update","slug":"Ceph_Month_2021_-_Ceph_Project_Update","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-01T16:00:00.000Z","comments":true,"path":"2021/06/01/Ceph_Month_2021_-_Ceph_Project_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/01/Ceph_Month_2021_-_Ceph_Project_Update/","excerpt":"","text":"会议纪要 会议概要 会议主题: SethMonth 2021 更新 主讲人: Josh 和 Seth 日期: 2021年6月21日 讨论内容 Seth 简介 Seth 被描述为软件定义存储、统一存储系统、可扩展分布式存储，甚至是存储的未来或存储的Linux。 Seth 是开源软件，不依赖特定硬件，可在各种商品组件上运行，如服务器、网络、硬盘、SSD、VM等。 单一集群可提供对象、块和文件工作负载。 Seth 是免费的，用户有权使用、修改和分享源代码，避免供应商锁定，促进创新。 Seth 的特性 可靠性: 由不可靠组件构建的可靠存储系统，无单点故障，提供数据耐久性（通过复制或纠删码），支持滚动升级和在线扩展或收缩。 可扩展性: 弹性存储基础设施，集群可随需求变化或硬件更新而增长或收缩，支持在线添加或移除硬件。 统一系统: 提供对象、块和文件接口，基于 RADOS 组件处理复制和数据分布。 版本和发布 Seth 每年3月发布稳定版本，提供两个版本的backports（bug修复和安全更新），版本生命周期约为两年。 提供 Debian 和 RPM 包，以及容器镜像。 SethMonth 2021 目标：更互动和碎片化，避免长时间Zoom会议，分散在几周内，每次几小时，包含计划演讲和非结构化讨论时间。 提供 Etherpad 链接，用于提问和讨论。 未来计划 计划在2022年3月举办 Cephalocon，地点未定，可能是首尔或北美。 希望收集社区反馈，考虑混合型活动或传统会议。 Seth 基金会更新 基金会成立以支持 Seth 项目，现有12个职业成员，新加入的有 Bloomberg、Cloudbase 和 Vexos。 基金会项目包括改进文档、网站更新、培训材料开发等。 实验室更新 扩展实验室硬件，改进测试基础设施（如 Teuthology），增加 ARM 架构支持。 遥测数据 Seth 有遥测模块，用户可选择分享数据，帮助开发者理解实际问题。 遥测数据包括基本元数据、崩溃元数据、设备信息等，未来计划增加性能数据。 未来发展方向 重点包括可靠性、用户体验和适应数据中心及硬件的演进。 特别关注 Crimson OSD 的重新设计和 NVMe over Fabrics 的支持。 后续行动计划 继续改进 Seth 的稳定性和用户体验。 扩展测试覆盖和硬件支持，如 ARM 和 NVMe over Fabrics。 收集社区反馈，为未来的 Cephalocon 和 Seth 发展方向做准备。 其他 会议中提到的 Crimson 更新将在后续的 SethMonth 活动中详细讨论。 社区成员可参与命名下一个 Seth 版本的讨论。 以上是本次会议的详细纪要，涵盖了 Seth 的特性、版本管理、社区活动、基金会更新、实验室改进、遥测数据以及未来发展方向等关键内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Ceph On Windows","slug":"Ceph_Month_2021_-_Ceph_On_Windows","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-01T16:00:00.000Z","comments":true,"path":"2021/06/01/Ceph_Month_2021_-_Ceph_On_Windows/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/01/Ceph_Month_2021_-_Ceph_On_Windows/","excerpt":"","text":"会议纪要 会议主题：Ceph与Windows服务器的集成 会议时间：约7分钟 会议参与者：Ceph研发团队、SUSE团队（Lars和Mike）、社区成员 会议背景： Ceph作为最受欢迎的开源分布式存储解决方案之一，与Windows服务器的市场需求相结合，特别是在企业环境中，Windows服务器占有较大市场份额。因此，实现Ceph与Windows服务器的无缝集成，对于满足企业级存储需求至关重要。 讨论的主要议题： 用户需求与市场背景： Windows服务器在企业中占有较大市场份额，需要与Ceph集成以实现存储解决方案的统一。 现有解决方案如Sapphire Sketch Gateway存在性能和可扩展性问题。 技术目标与架构设计： 目标是使Windows上的用户体验尽可能接近Linux，减少学习曲线。 性能上要超越现有的Ice CSI Gateway，并尽可能接近Linux原生性能。 支持Windows Server 2016、2019及即将发布的2022版本，以及Windows 10用于开发目的。 技术实现细节： 用户空间组件包括rbd-wimbd，通过用户空间DLL连接到VMBD内核模块。 内核驱动程序VMBD允许创建由网络存储支持的存储，并显示为操作系统内的磁盘。 配置文件在Windows上的位置与Linux上的/etc相对应，位于Program Data目录下。 性能与稳定性： 性能测试显示，新解决方案在某些情况下甚至超过了Linux原生RBD性能。 稳定性方面，已用于生产环境，未收到稳定性问题的报告。 安装与部署： 提供MSI安装程序，支持自动化部署，如通过Ansible playbook。 持续集成构建可在GitHub上获取，确保始终使用最新版本。 虚拟化支持： 支持Hyper-V和OpenStack，允许在Windows环境中无缝使用Ceph。 决定的事项： 确认了Ceph与Windows服务器集成的技术路线和实现细节。 确定了支持的Windows版本和性能目标。 确定了安装程序和部署流程。 后续行动计划： 继续优化性能和稳定性。 推广新解决方案，收集用户反馈。 准备参加未来的技术会议，如Cephalocon，以进一步推广和获取市场反馈。 会议总结： 本次会议详细讨论了Ceph与Windows服务器的集成方案，包括技术实现、性能优化、安装部署等方面。通过与SUSE的合作，已经取得了显著进展，并准备将解决方案推向市场。感谢所有参与者的贡献，期待未来的进一步合作和成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: Open Discussion","slug":"Ceph_Month_2021_-_Open_Discussion","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-01T16:00:00.000Z","comments":true,"path":"2021/06/01/Ceph_Month_2021_-_Open_Discussion/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/01/Ceph_Month_2021_-_Open_Discussion/","excerpt":"","text":"会议纪要 会议目的 本次会议旨在让与会者听取相关演讲，并进行自由形式的讨论，以便就任何相关议题进行交流。 主要议题 File Store 状态讨论 讨论了何时停止对 File Store 的支持。 通过 Grafana 仪表板上的遥测数据，显示目前仍有约 1500 个 File Store OSDs 在使用，占总数的 4%。 决定是否继续支持 File Store 的讨论，以及可能对代码简化和对象存储接口清理的影响。 Crimson 和 File Store 的未来 Crimson 将不再支持 File Store，这可能导致未来无法继续支持。 提出了对仍在使用 File Store 的 OSDs 发出警告的建议。 Dedupe 更新 讨论了 Dedupe 功能的三个部分：RADOS 类、RADOS 分层代码的更改以及 RADOS 网关直接存储数据的支持。 目前 Dedupe 功能尚未完全稳定，仍在开发中。 Cepheidium 对大型集群的支持 讨论了 Cepheidium 的扩展限制和计划中的重构，以提高其可扩展性。 Ceph 部署和管理方式的未来 讨论了是否继续构建容器和包，以及如何管理通过包安装的 Ceph 集群。 强调了尽管有对容器的抵触，但目前没有具体的技术理由反对使用容器。 其他议题 讨论了 CephFS 和 RBD 在 macOS 上的支持情况，以及可能的改进。 决定事项 决定继续讨论并最终决定是否停止对 File Store 的支持。 计划对仍在使用 File Store 的 OSDs 发出警告。 将继续开发和完善 Dedupe 功能。 将继续支持包和容器的构建，但可能减少对多个发行版的支持。 后续行动计划 发送跟进邮件到 Ceph 用户列表，收集对停止 File Store 支持的反馈。 继续开发和测试 Dedupe 功能，确保其稳定性和可用性。 继续改进 Cepheidium 的可扩展性。 准备一篇博客文章，讨论容器使用的议题，并收集更多反馈。 下次会议安排 下次会议将于 6 月 10 日举行，将包括 RGW 更新和其他相关议题的讨论。 会议结束 感谢所有参与者的参与和贡献，期待下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Month 2021: RADOS Update","slug":"Ceph_Month_2021_-_RADOS_Update","date":"2021-05-31T16:00:00.000Z","updated":"2021-06-01T16:00:00.000Z","comments":true,"path":"2021/06/01/Ceph_Month_2021_-_RADOS_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/06/01/Ceph_Month_2021_-_RADOS_Update/","excerpt":"","text":"会议纪要 会议主题：Ceph Pacific 更新及 Quincy 展望 会议时间：[具体时间] 会议地点：[具体地点] 参会人员： Neha Ocha（技术负责人，Raiders 团队） 会议内容总结： Ceph Pacific 更新 可用性增强： Upmap 平衡器默认开启。 新增健康警告，检测不同版本的守护进程并提醒用户。 支持取消正在进行的数据一致性检查（scrubs）。 改进恢复进度显示，提供更全面的恢复进度信息。 引入分布式追踪框架，使用 Jaeger 工具在 OSD 中添加追踪点。 质量提升： 改进 PG 删除性能，提升 4 倍。 优化 OSD 映射修剪行为，仅保留相关版本。 更新 Messenger 2.1，引入新的安全修复。 改进管理器模块效率，包括进度模块的可关闭性。 优化大型 C++ 结构的使用，减少冗余信息。 性能优化： RocksDB 分片默认开启，减少磁盘空间需求。 引入混合分配器，降低内存使用和磁盘碎片。 SSD 的 4K 分配单元大小，提高空间利用率。 改进缓存效率，引入 mempools 概念，便于内存使用追踪。 生态系统： 支持扩展集群配置，跨数据中心配置带有仲裁器的集群。 Quincy 展望 可用性增强： mClock 调度器将成为默认设置，简化配置。 引入自动基准测试，优化 mClock 参数。 新的 PG 自动扩展器配置文件，支持缩减操作。 改进平衡器算法，考虑 OSD 利用率。 提供更详细的集群降级信息。 质量提升： 动态调整监控器修剪速率，防止积压。 进一步改进 PG 删除性能。 管理器模块的自动调整统计收集频率。 改进慢操作日志记录，简化日志监控代码。 性能优化： 扩展 QoS 支持，包括 HDD 和背景活动优先级。 移除 RocksDB 中的分配元数据，提高写入性能。 简化拆分缓存，避免锁定问题。 引入 omap 性能基准测试工具。 生态系统： 自动生成文档，减少重复工作。 集成 Redmine 追踪器，优化资产标识。 后续行动计划： 继续优化和扩展 QoS 功能，包括客户端和池级别的优先级设置。 完善 Crimson 和 C-Store 的支持，包括多核支持和持久内存支持。 加强生态系统建设，提高文档自动化和用户反馈收集。 会议结束语： 会议在讨论了 Ceph Pacific 的最新进展和 Quincy 的未来规划后结束，Neha Ocha 邀请大家提出问题并进行了简短的问答环节。会议随后转向了 Windows 相关的内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-05-27","slug":"Ceph_Performance_Meeting_2021-05-27","date":"2021-05-26T16:00:00.000Z","updated":"2021-05-27T16:00:00.000Z","comments":true,"path":"2021/05/27/Ceph_Performance_Meeting_2021-05-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/27/Ceph_Performance_Meeting_2021-05-27/","excerpt":"","text":"会议纪要 关键细节 性能相关PR: 本周仅发现一个与性能相关的PR，涉及管理器实现的TTL缓存，包含性能结果和图表。 D3N缓存更改: 对上游和RGW的D3N缓存更改经过多次测试和更新后，已通过测试。 RocksDB优化: Gabby正在移除RocksDB中的分配，遇到笔记本电脑上的bug，但测试集群中未出现。 压缩Blob大小设置: Adam的PR设置新的压缩Blob大小为64KB，已获批准，但需要进一步测试和改进。 ISC 21提交: 讨论是否为国际超级计算机会议提交新的FFS（Fast File System）改进，尽管之前的测试结果不理想，但仍有改进空间。 BlueFS锁优化: Adam正在尝试将BlueFS的大锁分解为更小的锁，以提高性能。 讨论的主要议题 性能改进: 讨论了多个性能相关的PR，包括TTL缓存、D3N缓存更改、RocksDB优化等。 ISC 21提交: 讨论了是否继续提交FFS改进到国际超级计算机会议，尽管之前的测试结果不理想，但认为仍有改进空间。 BlueFS锁优化: 讨论了将BlueFS的大锁分解为更小的锁的可能性，以提高性能。 决定的事项 性能相关PR: 确认了多个性能相关的PR的进展，包括TTL缓存、D3N缓存更改等。 ISC 21提交: 决定继续探索FFS的改进，并可能在未来的会议上提交。 BlueFS锁优化: 决定继续进行BlueFS锁优化的工作，尽管存在风险，但认为值得尝试。 后续的行动计划 性能相关PR: 继续跟踪和测试性能相关的PR，确保它们能够安全地合并到主分支。 ISC 21提交: 继续进行FFS的改进工作，包括性能测试和优化。 BlueFS锁优化: 继续进行BlueFS锁优化的工作，确保更改不会破坏现有功能。 其他事项 纪念日周末: 提醒美国团队成员即将到来的纪念日周末，并祝愿大家有一个愉快的假期。 结论 本周会议主要集中在性能改进和未来的工作计划上，特别是关于FFS的改进和BlueFS的锁优化。团队将继续跟踪和测试相关的PR，并确保所有更改都能够安全地合并到主分支。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-05-26","slug":"Ceph_Crimson_SeaStore_2021-05-26","date":"2021-05-25T16:00:00.000Z","updated":"2021-05-26T16:00:00.000Z","comments":true,"path":"2021/05/26/Ceph_Crimson_SeaStore_2021-05-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/26/Ceph_Crimson_SeaStore_2021-05-26/","excerpt":"","text":"会议纪要 关键细节 代码链接问题： Kifu发现有三段代码如果注释掉，可以解决链接问题，但目前尚不清楚原因。Kifu正在调查这个问题，并承认是他引入了这个回归问题。 这三段代码来自x out of change，Kifu已经通过电子邮件发送了回滚这些更改的提交。 mclock移植： 讨论了将mclock移植到Ceph存储系统的不同组件中，特别是PG和OSD（crimson和systole）。 目前的工作包括将mclock实现移植到OSD调度器，但存在一些争议和复杂性。 讨论了mclock是否应该与线程模型解耦，以及如何处理内部使用的pthread锁。 性能计数器与指标： 讨论了在crimson OSD中使用性能计数器（perf counter）和指标（metrics）的问题。 决定在crimson中使用seastar metrics来暴露perf counter的状态，同时保持与经典OSD的兼容性。 其他更新： 讨论了extent placement manager的工作进展，包括实现parallel for each函数。 提到了ono tree的API已经合并，并测试了重启功能。 讨论了tc malloc属性的复制问题，以及如何区分测试套件中的OSD变体。 决定事项 代码链接问题： 暂时注释掉导致链接问题的三段代码，Kifu将继续调查原因。 mclock移植： 初步决定将mclock移植到crimson和systole中，但需要进一步讨论和调整以避免线程模型的依赖。 性能计数器与指标： 在crimson中使用seastar metrics来暴露perf counter的状态，保持与经典OSD的兼容性。 后续行动计划 代码链接问题： Kifu将继续调查三段代码导致链接问题的原因，并寻找更长期的解决方案。 mclock移植： 开始讨论和实施mclock的移植工作，特别是如何处理线程模型和pthread锁的问题。 性能计数器与指标： 在crimson中实现seastar metrics的包装器，以便暴露perf counter的状态。 其他更新： 继续推进extent placement manager和ono tree的工作，确保功能的稳定性和性能。 tc malloc属性的复制： 讨论并实施区分测试套件中OSD变体的解决方案，确保测试的准确性和覆盖率。 会议总结 本次会议主要讨论了Ceph存储系统中的多个技术问题，包括代码链接问题、mclock移植、性能计数器与指标的使用等。通过详细的讨论和决策，确定了后续的行动计划，以确保系统的稳定性和性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-05-25","slug":"Ceph_Orchestrator_Meeting_2021-05-25","date":"2021-05-25T16:00:00.000Z","updated":"2021-05-25T16:00:00.000Z","comments":true,"path":"2021/05/26/Ceph_Orchestrator_Meeting_2021-05-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/26/Ceph_Orchestrator_Meeting_2021-05-25/","excerpt":"","text":"会议纪要 会议主题：Orchestrator 会议 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： Etsy Hosts 问题 讨论了 Etsy Hosts 文件的回归问题，涉及 DeepSea、Ansible 和 Cephadm Octopus Tana。 确认了两个相关的 Pull Request。 讨论了 Podman 和 Docker 的行为差异，特别是关于 get fqdn 的处理。 发现 Podman 在特定配置下返回回环地址，导致配置文件生成问题。 讨论了如何处理 DNS 和 Etsy Hosts 的依赖问题，建议在添加主机时强制指定 IP 地址。 提出了在文档中明确说明使用 IP 地址的必要性，并更新相关代码以支持这一变化。 Ganesha 模板冲突问题 讨论了 Ganesha 模板中的冲突标志问题，该问题导致 NFS EdgeRW 损坏。 确认了需要移除 dirt chunk equal zero 配置。 讨论了是否应该使用单一 Ganesha 实例同时支持 CephFS 和 RGW 导出。 发现不同后端（CephFS 和 RGW）需要不同的配置选项，建议恢复为使用不同的 Ganesha 集群。 讨论了未来可能的改进方向，包括与 Ganesha 开发者的进一步沟通。 决定事项： Etsy Hosts 问题 关闭第一个 Etsy Hosts 相关的 Pull Request。 更新文档，明确说明在添加主机时必须指定 IP 地址。 确保 cephadm 命令在添加主机时返回使用的 IP 地址。 进行代码审查，确保所有对 resolve ip 的调用都被正确处理。 Ganesha 模板冲突问题 暂时放弃使用单一 Ganesha 实例同时支持 CephFS 和 RGW 导出的方案。 恢复为使用不同的 Ganesha 集群，分别支持 CephFS 和 RGW。 等待与 Ganesha 开发者的进一步沟通，以确定最佳解决方案。 后续行动计划： Etsy Hosts 问题 完成文档更新，明确说明使用 IP 地址的必要性。 更新 cephadm 命令，确保在添加主机时返回使用的 IP 地址。 进行代码审查，确保所有对 resolve ip 的调用都被正确处理。 Ganesha 模板冲突问题 与 Ganesha 开发者沟通，了解 dirt chunk 配置的具体影响。 根据沟通结果，确定是否需要进一步的配置调整或代码修改。 更新相关文档和代码，确保用户明确不同后端需要不同的 Ganesha 配置。 其他讨论： 讨论了 Ingress 服务在底层 RGW 服务被删除时的行为，建议保持当前的异常处理方式，避免自动删除服务。 会议总结： 本次会议主要解决了 Etsy Hosts 文件的回归问题和 Ganesha 模板冲突问题，明确了后续的行动计划和改进方向。通过与 Ganesha 开发者的进一步沟通，将有助于确定最佳的技术方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-05-20","slug":"Ceph_Performance_Meeting_2021-05-20","date":"2021-05-19T16:00:00.000Z","updated":"2021-05-20T16:00:00.000Z","comments":true,"path":"2021/05/20/Ceph_Performance_Meeting_2021-05-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/20/Ceph_Performance_Meeting_2021-05-20/","excerpt":"","text":"会议纪要 关键细节 性能相关PR: 本周没有新的性能相关的PR。 关闭的PR: 本周有两个PR被关闭： 一个针对Crimson的优化，涉及客户端请求处理并行性。 另一个是关于自动调优，让管理器自动设置容器内存限制。 讨论的主要议题 自动调优: 讨论了自动调优的实现细节，特别是关于如何根据某些比例自动设置容器内存限制。 DoWriteSmall PR: 讨论了DoWriteSmall PR的更新，计划通过设置标志来控制何时使用DoWriteSmall或直接IO，并观察其行为。 RGW压缩绕过: 讨论了一个关于RGW压缩后绕过OSD压缩的PR，虽然核心理念被认为是好的，但实现似乎过于复杂。 LRU缓存管理: 讨论了一个关于在BlueStore中使用LRU缓存管理器的PR，该管理器可以跟踪不同LRU缓存中的项目，并将其与年龄段关联，以便更好地管理内存分配。 决定的事项 性能数据收集: 决定开始收集更多关于IO大小和类型的信息，以及OSD和BlueStore内部状态的数据，以便更好地理解工作负载和优化系统。 数据收集频率: 讨论了数据收集的频率，建议可能需要更细粒度的数据收集，例如每小时一次，以便更好地捕捉集群的日常负载周期。 后续的行动计划 确定最小数据集: 开始确定要收集的最小数据集，并创建相应的telemetry报告。 用户反馈: 通过邮件列表与用户沟通，了解他们是否愿意分享性能数据，并解释这将如何帮助优化Ceph。 实验性数据收集: 考虑设置一个实验性的数据收集通道，让愿意参与的用户可以分享更多详细数据，以便进行更深入的分析和优化。 其他讨论点 内存使用: 讨论了关于内存使用的统计数据，如PG日志、缓存和块缓存的使用情况，以及这些数据如何帮助理解集群的行为和性能。 数据隐私和安全性: 讨论了数据收集的隐私和安全问题，特别是如何确保用户数据的安全性和匿名性，以及如何处理用户可能的后悔情况。 结论 会议涵盖了多个关于Ceph性能优化和数据收集的重要议题，确定了后续的行动计划，并强调了用户反馈和数据隐私的重要性。通过这些讨论和决策，Ceph社区将继续推动项目的改进和发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-05-19","slug":"Ceph_Crimson_SeaStore_2021-05-19","date":"2021-05-18T16:00:00.000Z","updated":"2021-05-18T16:00:00.000Z","comments":true,"path":"2021/05/19/Ceph_Crimson_SeaStore_2021-05-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/19/Ceph_Crimson_SeaStore_2021-05-19/","excerpt":"","text":"会议纪要 会议主题：本周的 orchestrator 会议 参会人员：全体成员 会议时间：本周 主要议题： 自我管理代理（self-adm agent）的深入探讨 讨论了自我管理代理的需求、收益以及对架构的影响。 分析了当前 cephadm 中的 reconciliation loop 的扩展性问题，特别是通过 SSH 连接执行任务的效率问题。 模型选择：推模型 vs 拉模型 讨论了使用推模型（push model）和拉模型（pull model）的优劣。 倾向于使用推模型，通过在每个主机上运行的代理（agent）将信息推送到管理模块（manager module），以提高性能和响应速度。 架构和实现细节 讨论了代理（agent）的职责和如何设计架构以最大化收益。 考虑了如何处理潜在的竞争条件和失败模式，特别是在部署新守护进程（daemon）时的同步问题。 安全性和可靠性 讨论了如何确保代理（agent）与管理模块（manager module）之间的通信安全，包括使用 API 端点和客户端认证。 考虑了如何处理主机离线的情况，以及如何确保代理（agent）的可靠运行。 未来扩展和升级路径 讨论了如何设计系统以便未来可以扩展到集群外的客户端。 考虑了从旧版本升级到新版本时的兼容性和升级路径。 决定事项： 倾向于采用推模型（push model）来改善系统的扩展性和响应速度。 需要进一步细化代理（agent）的职责和架构设计，以避免竞争条件和失败模式。 需要设计一个安全可靠的通信机制，确保代理（agent）与管理模块（manager module）之间的信息交换。 后续行动计划： 分配任务给团队成员，进一步细化代理（agent）的设计和实现细节。 开始实施初步的推模型（push model）原型，并进行测试以验证其性能和可靠性。 考虑未来的扩展需求，确保设计具有足够的灵活性和可扩展性。 会议结束： 会议在接近预定时间结束，没有其他议题需要讨论。 全体成员祝大家有一个愉快的一周。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-05-18","slug":"Ceph_Orchestrator_Meeting_2021-05-18","date":"2021-05-17T16:00:00.000Z","updated":"2021-05-18T16:00:00.000Z","comments":true,"path":"2021/05/18/Ceph_Orchestrator_Meeting_2021-05-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/18/Ceph_Orchestrator_Meeting_2021-05-18/","excerpt":"","text":"会议纪要 会议主题：本周的 orchestrator 会议 参会人员：全体成员 会议日期：[具体日期] 会议内容总结： 主要议题： 深入探讨 self-adm agent 的功能和必要性。 讨论 cephadm 中的 reconciliation loop 的扩展性和性能问题。 评估是否需要改进架构以支持更快的故障转移。 讨论细节： self-adm agent：讨论了 self-adm agent 的潜在收益和架构影响。提出了是否需要实施该代理，以及如何实施的问题。 reconciliation loop：指出了当前 cephadm 中的 reconciliation loop 在扩展性上的限制，特别是在创建 SSH 连接和执行远程命令时的性能问题。 架构改进：讨论了如何改进架构以支持更快的故障转移，包括考虑使用 push 模型而不是 pull 模型，以及如何处理潜在的竞争条件和失败模式。 决定事项： 确认改进 reconciliation loop 和引入 self-adm agent 的必要性。 初步决定采用 push 模型，通过 agent 向 manager 推送信息，以提高性能和响应速度。 需要进一步明确 agent 的责任和具体实施细节。 后续行动计划： 分配任务给特定人员以细化 self-adm agent 的实施细节。 开始设计和实现 agent 的 push 模型，确保其与现有系统的兼容性和安全性。 考虑长期目标，减少对 SSH 的依赖，并探索如何简化 manager 的架构。 其他讨论点： 讨论了如何处理升级路径和兼容性问题。 探讨了 manager 模块的架构重构可能性，但认为这是一个长期目标。 会议结束： 会议在接近预定时间结束，未有其他紧急议题需要讨论。 全体成员祝大家有一个愉快的周末。 本次会议重点在于优化 ceph 的 orchestration 功能，特别是通过引入新的 self-adm agent 来解决现有的性能瓶颈问题。会议强调了详细的实施计划和考虑潜在的架构影响的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-05-13","slug":"Ceph_Performance_Meeting_2021-05-13","date":"2021-05-13T16:00:00.000Z","updated":"2021-05-14T16:00:00.000Z","comments":true,"path":"2021/05/14/Ceph_Performance_Meeting_2021-05-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/14/Ceph_Performance_Meeting_2021-05-13/","excerpt":"","text":"会议纪要 与会人员 Josh Corey（预计稍后加入） 主要议题 新项目讨论 Josh提出一个即将开始的面试项目，需要收集大量数据以了解最有用的信息。 讨论了如何使数据收集和模式变更变得容易，以避免系统脆弱性。 数据存储和查询 讨论了使用JSON格式存储数据，并利用数据库（如PostgreSQL）的JSON支持进行查询。 提到了在大量性能数据下，可能需要对JSON数据进行索引以提高查询速度。 Ceph性能优化 讨论了Ceph BlueStore的缓存策略，特别是关于小写操作的直接I/O和缓存使用。 Adam提出了一个PR，旨在改变小写操作的缓存策略，以避免双重缓存问题。 性能测试和分析 分享了关于omapbench测试的更新，特别是在不同Ceph版本间的性能差异。 讨论了RocksDB的缓存命中率和性能问题，特别是在删除操作后的性能下降。 决定事项 需要进一步测试和分析BlueStore的缓存策略，特别是直接I/O和小写操作的缓存使用。 计划引入额外的配置参数来控制页面缓存的使用，以便更好地进行基准测试和性能优化。 后续行动计划 Adam将继续完善PR，以提供更灵活的缓存控制选项。 进行更多的性能测试，特别是关注RocksDB的缓存命中率和删除操作后的性能恢复。 探讨和实验RocksDB的compaction策略，以优化性能。 其他讨论 讨论了旧版本Ceph集群中使用文件存储（FileStore）遇到的问题，特别是inode扫描和目录列表性能问题。 分享了在实际部署中遇到的性能问题和解决方案，特别是在使用缓存和直接I/O时的权衡。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并期待下周的会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-05-12","slug":"Ceph_Crimson_SeaStore_2021-05-12","date":"2021-05-11T16:00:00.000Z","updated":"2021-05-12T16:00:00.000Z","comments":true,"path":"2021/05/12/Ceph_Crimson_SeaStore_2021-05-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/12/Ceph_Crimson_SeaStore_2021-05-12/","excerpt":"","text":"会议纪要 关键细节 代码审查与性能分析：会议开始时，讨论了上周进行的代码审查工作，特别是对电阻指标和内部性能计数器的差异进行了调查。 PR讨论：讨论了与Srihan合作的PR（Pull Request）#39772，并分享了相关链接。 段错误调试：报告了在单元测试中发现的一个段错误，该错误出现在主分支中，目前仍在调试中。 环境差异：讨论了环境差异可能导致的问题，特别是非确定性调度可能引发的bug。 Ceph存储系统改进：详细讨论了Ceph存储系统中的一个关键问题，即ONode Manager处理冲突的方式。计划通过引入新的机制来解决这个问题，该机制将使用可中断的未来类型来检查事务的无效状态。 性能计数器与系统指标：讨论了性能计数器（perf counters）与系统指标（C-star metrics）的优劣，特别是系统指标在标签支持方面的优势。决定继续使用性能计数器，并可能在未来集成系统指标。 决定事项 继续使用性能计数器：尽管系统指标提供了更多的灵活性和标签支持，但决定继续使用性能计数器作为当前的解决方案。 集成系统指标：计划在未来集成系统指标，特别是在性能优化和问题追踪方面。 后续行动计划 解决段错误：继续调试并解决在单元测试中发现的段错误。 改进ONode Manager：实施新的机制来改进ONode Manager的处理冲突方式。 集成系统指标：开始规划和实施系统指标的集成工作，以提供更详细的性能数据和标签支持。 其他讨论 会议结束：会议在讨论了所有议题后顺利结束，没有其他待处理事项。 本次会议主要聚焦于Ceph存储系统的性能优化和问题解决，特别是在事务管理和性能计数器方面的讨论，为未来的开发和优化工作奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-05-11","slug":"Ceph_Orchestrator_Meeting_2021-05-11","date":"2021-05-10T16:00:00.000Z","updated":"2021-05-11T16:00:00.000Z","comments":true,"path":"2021/05/11/Ceph_Orchestrator_Meeting_2021-05-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/11/Ceph_Orchestrator_Meeting_2021-05-11/","excerpt":"","text":"会议纪要 会议主题：OpenStack与Ceph集成中的NFS模块问题讨论 与会人员：OpenStack与Ceph开发团队成员 会议时间：[具体时间] 会议地点：在线会议 主要议题： NFS模块现状与挑战 OpenStack与Ceph集成中的NFS模块问题 短期与长期解决方案讨论 后续行动计划 讨论内容： NFS模块现状与挑战 目前存在多个模块和限制，需要找到解决方案以推动OpenStack的发展。 仪表盘模块功能良好，但需要与新的NFS模块集成，该模块目前尚未完全功能完善。 OpenStack与Ceph集成中的NFS模块问题 需要部署Ganesha和Pacemaker，但存在配置和部署的复杂性。 现有的NFS模块不支持NFSv3，仅支持NFSv4.1及以上版本。 短期与长期解决方案讨论 短期解决方案： 使用TripleO Ansible部署Ganesha和Pacemaker，类似于Stephansible的方式。 确保部署的Ganesha能够与Ceph集群通信，并正确配置。 长期解决方案： 使用Cephadm管理NFS守护进程和入口服务。 Manila直接与Cephadm交互，动态部署和管理Ganesha集群。 后续行动计划 短期行动： 完成TripleO Ansible部署Ganesha和Pacemaker的脚本。 确保迁移过程中现有客户的平稳过渡。 长期行动： 完善Cephadm的NFS模块，确保其支持所有必要的功能。 简化Manila代码，使其能够利用新的NFS模块接口。 开发迁移工具，帮助客户从旧系统迁移到新系统。 决定事项： 确认了短期和长期的解决方案方向。 确定了短期内的具体行动步骤，包括TripleO Ansible的部署脚本编写。 明确了长期目标，包括Cephadm的NFS模块完善和Manila代码的简化。 后续行动： 开发团队将开始编写TripleO Ansible的部署脚本。 Cephadm团队将继续完善NFS模块，确保其满足所有需求。 Manila团队将开始简化代码，以便能够利用新的NFS模块接口。 开发迁移工具，确保客户能够平稳过渡到新系统。 会议总结： 会议明确了OpenStack与Ceph集成中NFS模块的问题，并制定了短期和长期的解决方案。开发团队将按照会议确定的行动计划，逐步推进项目的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-05-05","slug":"Ceph_Developer_Monthly_2021-05-05","date":"2021-05-05T16:00:00.000Z","updated":"2021-05-06T16:00:00.000Z","comments":true,"path":"2021/05/06/Ceph_Developer_Monthly_2021-05-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/06/Ceph_Developer_Monthly_2021-05-05/","excerpt":"","text":"会议纪要 会议主题： 优化OSD Map以提升客户端使用效率 增加通过标签或生成号来阻止实体列表的功能 讨论内容： 1. 优化OSD Map以提升客户端使用效率 问题描述：在高速集群（如全闪存集群）中，重新平衡或恢复操作完成后，集群会留下大量OSD Map。客户端可能无法及时获取这些更新，导致使用过时的OSD Map。 解决方案讨论： 原始方案：添加设置以限制构建增量OSD Map时的版本。 替代方案：使用细粒度锁来提高监控器在服务OSD Map时的并行性。 讨论结果：决定不采用细粒度锁，而是优化客户端请求OSD Map的行为，确保客户端只请求必要的OSD Map版本，减少监控器的负担。 后续行动：更新客户端以优化其请求OSD Map的行为，并可能进一步优化监控器处理OSD Map请求的方式。 2. 增加通过标签或生成号来阻止实体列表的功能 问题描述：在灾难恢复场景中，需要能够阻止整个集群或特定应用程序访问共享存储端点，以实现无缝切换。 解决方案讨论： 原始方案：使用现有的阻止列表功能，但发现其不适用于此场景。 替代方案：通过标签或生成号来阻止实体列表，以更广泛地隔离集群。 讨论结果：决定探索更简单的网络层阻止方案，而不是在存储系统中实现复杂的阻止机制。 后续行动：进一步研究IP范围阻止列表的可行性，并与社区讨论其实现细节和时间框架。 决定事项： 优化客户端请求OSD Map的行为，减少监控器的负担。 探索网络层阻止方案，以简化灾难恢复过程中的集群隔离。 后续行动计划： 更新客户端代码以优化OSD Map请求。 研究并实现IP范围阻止列表功能。 与社区进一步讨论和细化阻止实体列表的方案。 会议总结： 本次会议主要讨论了如何优化Ceph存储系统中的OSD Map使用和灾难恢复过程中的集群隔离问题。通过优化客户端行为和探索网络层阻止方案，旨在提高系统的性能和可靠性。后续将根据讨论结果进行具体实施和社区协作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-05-06","slug":"Ceph_Performance_Meeting_2021-05-06","date":"2021-05-05T16:00:00.000Z","updated":"2021-05-06T16:00:00.000Z","comments":true,"path":"2021/05/06/Ceph_Performance_Meeting_2021-05-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/06/Ceph_Performance_Meeting_2021-05-06/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph存储系统的性能优化、缓存策略以及与Intel的合作等方面的问题。会议中，与会者分享了他们在实际操作中遇到的问题和解决方案，并对未来的工作方向进行了探讨。 主要议题 Ceph性能问题： 讨论了在OpenShift环境下Ceph的性能问题，特别是与IBM Cloud Packs的集成问题。 提到了在RBD设备上运行XCD的复杂用例，以及Gluster和Ceph的集成问题。 缓存策略： 讨论了缓存层的选择，包括Intel的OpenCAS和LVM缓存。 探讨了直接IO（Direct IO）和缓冲IO（Buffered IO）的使用场景和性能影响。 与Intel的合作： 讨论了Intel的OpenCAS项目，以及如何在客户端侧进行本地缓存以提高性能。 探讨了与Intel合作的可能性，以优化Ceph的性能。 代码审查和开发： 讨论了多个Pull Request（PR），包括对缓冲IO的处理、C-Store的初始支持等。 提到了对OMap性能的测试和优化，以及对RocksDB缓存行为的深入分析。 决定事项 缓存策略的优化： 决定进一步测试和优化缓存策略，特别是直接IO和缓冲IO的使用。 计划与Intel合作，探索使用OpenCAS作为客户端缓存解决方案。 代码审查和开发： 对多个PR进行了讨论，包括对缓冲IO的处理和C-Store的支持。 决定继续深入分析RocksDB的缓存行为，以优化OMap性能。 后续行动计划 性能测试： 继续进行性能测试，特别是对缓存策略的优化。 与Intel合作，进行OpenCAS的性能测试和集成。 代码开发和审查： 继续审查和优化相关的Pull Request。 深入分析RocksDB的缓存行为，以解决OMap性能问题。 合作与交流： 与Intel保持沟通，探讨进一步的合作可能性。 定期进行技术交流和问题讨论，以确保项目的顺利进行。 参会人员 Randy Michael Kidd Joe Quinn Adam Gabby 其他核心开发人员 会议结束 会议在讨论了所有议题后结束，与会者同意继续进行相关的测试和开发工作，并保持与Intel的合作沟通。下次会议将继续讨论相关进展和问题。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-05-05","slug":"Ceph_Crimson_SeaStore_2021-05-05","date":"2021-05-04T16:00:00.000Z","updated":"2021-05-05T16:00:00.000Z","comments":true,"path":"2021/05/05/Ceph_Crimson_SeaStore_2021-05-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/05/Ceph_Crimson_SeaStore_2021-05-05/","excerpt":"","text":"会议纪要 参会人员 主持人：[姓名] 参会人员：[姓名列表] 会议日期与时间 日期：[具体日期] 时间：[开始时间]至[结束时间] 主要议题 PR审查与讨论 主持人回顾了上周的PR审查工作，包括来自Redtech的PR以及与Redec的讨论。 讨论了关于未来商店订单的进一步讨论，并提供了PR和防抖动PR的审查。 OSD优化与改进 Greg分享了在经典OSD中关于秘密处理器的改进，特别是在Crimson中进行的优化，旨在通过优化复制消息来减少延迟。 讨论了Crimson后端的改进，特别是在异步存储中的段观察。 Scrub功能的实现与测试 讨论了两个PR，这些PR改变了经典OSD的Scrub功能，以匹配Crimson的实现。 正在进行Scrub功能的测试，特别是对象和快照的比较部分。 C-Store的开发进展 报告了C-Store的开发进展，包括能够启动OSD并完成一些IO操作。 正在进行C-Store的PR审查和其他相关审查。 设备映射器接口设计 讨论了博客设备映射器的接口设计，这是一个代理层，介于系统事务管理器和随机博客管理器之间。 提供了设计文档的链接，并期待团队的反馈。 事务处理与并发优化 讨论了事务处理的顺序和并发性问题，特别是在C-Store中的实现。 强调了不需要额外的回调来确保操作的顺序，而是应该依赖C-Store内部的处理机制。 决定事项 确认了不需要额外的回调来确保操作的顺序，而是应该依赖C-Store内部的处理机制。 确认了C-Store的责任是确保操作的顺序，任何与此不符的行为都应视为bug。 后续行动计划 继续进行PR的审查和测试工作。 完成Scrub功能的测试，并确保其与Crimson的实现相匹配。 继续开发和优化C-Store，确保其能够正确处理操作的顺序。 完成设备映射器接口的设计，并根据团队反馈进行调整。 其他备注 会议中提到的设计文档需要访问权限，相关人员已请求并获得了访问权限。 会议结束 会议在[结束时间]结束，所有参会人员表示感谢并期待下次会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-05-04","slug":"Ceph_Orchestrator_Meeting_2021-05-04","date":"2021-05-03T16:00:00.000Z","updated":"2021-05-04T16:00:00.000Z","comments":true,"path":"2021/05/04/Ceph_Orchestrator_Meeting_2021-05-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/04/Ceph_Orchestrator_Meeting_2021-05-04/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 记录人: [记录人姓名] 主要议题 Quincy项目中的自我管理代理（Self Adm Agent）改进 讨论内容: 讨论了如何使自我管理代理（Self Adm Agent）或Ceph管理守护进程（Ceph Adm Daemon）更加工程化和优化。 决定事项: 需要进一步分析任务细节，制定详细的实施计划。 后续行动: 计划召开专门会议，由Sage和Sebastian主导，定义实施指南，并在后续的下游发布后开始实施。 容器化Ceph部署 讨论内容: 探讨了使用容器化方法部署Ceph，特别是通过Docker in Docker方法，以及可能的改进方向。 决定事项: 同意分享代码，并考虑将其纳入Ceph的代码库中。 后续行动: 继续探索容器化部署的可行性和优化方案。 服务规范中的容器图像属性移除 讨论内容: 讨论了从服务规范中移除容器图像属性的必要性和方法。 决定事项: 决定移除除Ingress和自定义容器服务外的所有容器图像属性。 后续行动: 进行代码修改，确保所有相关部分的一致性。 NFS服务的改进 讨论内容: 讨论了NFS服务的部署和管理，特别是在Kubernetes环境中的使用。 决定事项: 需要简化NFS集群的创建过程，包括是否使用Ingress服务。 后续行动: 进一步明确NFS服务的部署流程，并在Rook模块中实现Ingress支持。 资源限制的自动调整 讨论内容: 讨论了如何自动调整OSD的内存和CPU资源限制。 决定事项: 倾向于使用Ceph的配置选项来管理内存目标，而不是直接在容器级别设置。 后续行动: 继续研究和实现CPU资源的自动调整。 后续行动计划 Quincy项目: 安排专门会议，由Sage和Sebastian主导，制定详细的实施计划。 容器化Ceph部署: 分享代码，探索进一步的优化和集成方案。 服务规范: 完成容器图像属性的移除工作。 NFS服务: 明确NFS服务的部署流程，并在Rook模块中实现Ingress支持。 资源限制: 继续研究和实现CPU资源的自动调整。 其他事项 会议安排: 下次会议定于[具体日期]。 特别感谢: 感谢所有参与者的积极讨论和贡献。 注意: 本会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。具体的日期和人员名单需要根据实际情况填写。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: MDSMonitoring","slug":"CephFS_Code_Walkthrough_-_MDSMonitoring","date":"2021-05-02T16:00:00.000Z","updated":"2021-05-03T16:00:00.000Z","comments":true,"path":"2021/05/03/CephFS_Code_Walkthrough_-_MDSMonitoring/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/05/03/CephFS_Code_Walkthrough_-_MDSMonitoring/","excerpt":"","text":"会议纪要 会议主题：MDS Monitor 的深入探讨 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： MDS Monitor 概述 定义：MDS Monitor 是 Ceph 分布式存储系统中的一个关键组件，属于 Paxos 服务的一部分。 功能：负责管理和监控 MDS（Metadata Server）集群的状态，通过修改 FS Map 或 MDS Map 来驱动集群状态的变化，并将这些变化分发给所有客户端和 MDS。 健康监控：MDS Monitor 还负责监控 MDS 的健康状态，标记延迟的 MDS，并在必要时进行替换。 MDS Monitor 的组件和操作 FS Map 和 MDS Map：MDS Monitor 管理多个 FS Map，每个 FS Map 包含一个或多个 MDS Map。 命令接口：提供命令行接口，如从 Ceph 命令行创建新文件系统或失败 MDS。 消息交互：MDS 定期向 Monitor 发送 MDS Beacon 消息，Monitor 根据这些消息驱动 MDS 状态的变化。 代码实现细节 Paxos FS Map：引入了一个新的类来保护当前和待处理的 FS Map，防止意外修改。 Beacon 处理：MDS 发送的 Beacon 消息驱动状态变化，Monitor 通过预处理 Beacon 消息来确保 MDS 不会因 Monitor 负载过高而被错误标记为延迟。 命令处理：处理如 mds fail 或 fs new 等命令，这些命令会修改 FS Map。 历史和改进 2018年：引入了 Paxos FS Map 和增量控制激活，提高了系统的稳定性和可管理性。 2019年：增加了 standby replay 功能，简化了配置。 2020年：增加了 MDS 亲和性设置，使得 MDS 可以更灵活地服务于特定文件系统。 决定事项： 确认了 MDS Monitor 的主要功能和操作流程。 讨论了 MDS Monitor 的代码实现细节，特别是 Paxos FS Map 和 Beacon 处理机制。 后续行动计划： 继续优化 MDS Monitor 的代码，特别是处理 Beacon 消息的逻辑，以减少潜在的错误标记问题。 探索进一步的功能增强，如改进订阅机制，减少 Monitor 的通信负载。 会议结束语： 感谢所有参会人员的积极参与和 Patrick 的详细讲解。 期待明天的进一步讨论和改进。 备注：本会议纪要基于会议内容的总结，具体的技术细节和代码实现可能需要参考相关的技术文档和代码库。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-04-29","slug":"Ceph_Performance_Meeting_2021-04-29","date":"2021-04-29T16:00:00.000Z","updated":"2021-04-29T16:00:00.000Z","comments":true,"path":"2021/04/30/Ceph_Performance_Meeting_2021-04-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/30/Ceph_Performance_Meeting_2021-04-29/","excerpt":"","text":"会议纪要 会议概要 日期与时间: 会议时间稍晚，但仍按计划进行。 参与者: 会议主要参与者包括Gabby、Kifu、Adam等。 主要议题 死锁问题 近期合并的Blue Store写过程锁优化PR引发了死锁问题。 Kifu尝试解决，但不幸的是出现了死锁问题，决定回滚。 缓存线优化 讨论了缓存线优化和分片行为，特别是与缓存线统计相关的PR。 这些优化对于确定如何进一步优化存储行为非常重要。 RGW压缩PR 讨论了关于RGW压缩的PR，目前尚未合并，但已准备好。 Crimson客户端请求处理并行化PR 该PR正在测试中，已重新基于，但近期无进一步进展。 BlueFS锁优化 讨论了BlueFS锁优化的问题，特别是多线程环境下的性能和安全性。 需要进一步分析和确定锁策略，以确保安全和性能。 性能测试和优化 讨论了性能测试的重要性，特别是如何捕捉和避免潜在的性能下降。 强调了需要有标准化的测试环境和方法，以及实时监控性能指标的必要性。 决定事项 回滚PR: 由于死锁问题，决定回滚最近的Blue Store优化PR。 继续测试和优化: 继续对Crimson客户端请求处理并行化PR进行测试和优化。 性能监控: 需要建立更有效的性能监控和测试机制，以避免未来的性能问题。 后续行动计划 性能分析: 对Luminous和Master的性能进行详细分析，特别是关于OMAP操作的性能。 锁优化: 继续研究和优化BlueFS的锁机制，确保多线程环境下的安全和性能。 标准化测试: 开发和实施标准化的性能测试流程，确保测试结果的可比性和可靠性。 其他讨论 硬件配置: 讨论了不同硬件配置下的性能表现，特别是NVMe和HDD的差异。 未来方向: 讨论了未来可能的技术方向，如Crimson存储引擎的进一步开发和应用。 结论 会议强调了性能优化的重要性，特别是在分布式存储系统中。通过详细的性能分析和标准化的测试流程，可以确保系统的稳定性和高效性。同时，对于锁机制的优化也是提高系统性能的关键。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthrough: RGW Bucket Notifications with AMQA/Kafka","slug":"Ceph_Code_Walkthrough_-_RGW_Bucket_Notifications_with_AMQA_Kafka","date":"2021-04-27T16:00:00.000Z","updated":"2021-04-27T16:00:00.000Z","comments":true,"path":"2021/04/28/Ceph_Code_Walkthrough_-_RGW_Bucket_Notifications_with_AMQA_Kafka/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/28/Ceph_Code_Walkthrough_-_RGW_Bucket_Notifications_with_AMQA_Kafka/","excerpt":"","text":"会议纪要 会议概述 本次会议由Mike Perez主持，Yuval主讲，主题为Reno的Gateway Bucket Notifications，特别是与AMQP和Kafka相关的实现细节。会议主要通过代码走查的方式，详细介绍了如何配置和发送通知。 主要议题 Bucket Notifications概述 功能简介：当对象创建或删除时，发送通知到预配置的端点。 两种模式： Push模式：事件发生时立即发送通知。 Pull模式：所有通知存储在特殊的pub sub zone中，计划未来弃用。 配置流程 主要涉及的文件：rgw_rest_pubsub和rgw_rest_pubsub_common。 配置API：创建、删除、列出主题和通知。 系统对象存储：所有配置信息作为系统对象存储。 数据结构 定义在rgw_pubsub.h中，包括主题、通知、过滤器等。 过滤器类型：前缀、后缀、正则表达式、标签和元数据。 通知发送流程 从rgw_ops开始，涉及publish_reserve和publish_commit函数。 同步和异步通知处理： 同步：直接发送通知。 异步（持久化）：先存储通知，后续再发送。 端点实现 涉及Kafka和AMQP的实现细节。 端点管理：初始化、关闭、发送确认等。 决定事项 确认了Bucket Notifications的基本功能和配置流程。 明确了同步和异步通知的处理方式。 确认了端点（如Kafka和AMQP）的实现细节。 后续行动计划 继续优化和完善Bucket Notifications的功能。 考虑未来可能的新端点类型集成。 如果有进一步的问题或需要详细解释，可以通过邮件联系Yuval。 其他备注 会议中提到的某些API和模式（如非AWS合规API和Pull模式）计划弃用，不建议在新开发中使用。 推荐使用AWS CLI或o3border3工具进行配置，手动编写REST消息较为复杂且不推荐。 会议结束 感谢Yuval的详细讲解和所有参与者的积极参与。希望大家有一个愉快的剩余时间。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: CephFS Follow-up","slug":"Ceph_Developer_Summit_Quincy_-_CephFS_Follow-up","date":"2021-04-27T16:00:00.000Z","updated":"2021-04-28T16:00:00.000Z","comments":true,"path":"2021/04/28/Ceph_Developer_Summit_Quincy_-_CephFS_Follow-up/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/28/Ceph_Developer_Summit_Quincy_-_CephFS_Follow-up/","excerpt":"","text":"会议纪要 会议主题 本次会议主要讨论了Ceph项目的上游Trello backlog board，并计划了即将到来的Quincy版本的工作内容。 会议链接 会议中提供了Trello board和Quincy feature search的链接，确保所有参与者都能访问相关资源。 主要议题及讨论内容 Multi-MDS Export Thrashing PR已准备好，但因MDS相关问题导致测试失败，需先解决该问题。 该PR已被标记为Quincy版本的工作内容。 MDS Check for Mixed Versions 讨论了是否需要对MDS demons版本不匹配的情况发出健康警告。 决定继续跟踪此问题，并计划在Quincy版本中解决。 Threshing Fragments 需要重新基于最新代码进行调整，并进行审查。 该问题也被标记为Quincy版本的工作内容。 MDS Memory Target 由于当前方法不满足需求，正在考虑采用优先级缓存方法。 该问题将在后续讨论中进一步探讨。 Client Complete Support for Lazy IO 讨论了Lazy IO的实际需求和实现难度，最终决定不将其作为Quincy版本的工作内容。 Root Squash via MDS Capability 该功能已在Pacific版本中实现，因此从Quincy版本的工作内容中移除。 HSM Support 由于缺乏下游需求，决定不将其作为Quincy版本的工作内容。 Optimized Rsync 由于CephFS Mirror的存在，决定关闭此优化需求。 Multi-FS Shared Pools 由于技术限制和需求变化，决定关闭此需求。 Snapshots File Level Snapshots 讨论了文件级快照的技术挑战和实际需求，决定暂时不作为Quincy版本的工作内容。 Background Fored Scrub Scheduling 需要创建相关跟踪票并找到负责人，计划在Quincy版本中实现。 FFS Notify Support 讨论了在VFS层实现通知支持的难度，决定暂时不作为Quincy版本的工作内容。 MDS Star 由于需要大规模重写MDS，决定暂时不作为Quincy版本的工作内容。 Libs FFS PP 讨论了将C API与C++ API分离的需求，决定暂时不作为Quincy版本的工作内容。 Ceph Top MultiFS Support 需要改进mgr stats模块以支持多文件系统，计划在Quincy版本中实现。 Recursive Unlink RPC 计划在Quincy版本中实现。 AHA Support 计划在Quincy版本中实现。 SFS Cache 等待内核补丁的进展，计划在Quincy版本中实现。 Client Expose Auth MDS for Fileder 讨论了在客户端暴露权威MDS的需求，决定暂时不作为Quincy版本的工作内容。 后续行动计划 继续跟踪和更新Trello board，确保所有工作内容和进度得到准确反映。 对于标记为Quincy版本的工作内容，需尽快找到负责人并开始实施。 对于暂时不作为Quincy版本的工作内容，将继续在backlog中跟踪，等待合适的时机再进行处理。 会议总结 本次会议对Ceph项目的多个关键议题进行了深入讨论，并制定了相应的行动计划。通过Trello board的持续更新和跟踪，确保项目按计划推进，并为即将到来的Quincy版本做好充分准备。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: Orchestrator Follow-up","slug":"Ceph_Developer_Summit_Quincy_-_Orchestrator_Follow-up","date":"2021-04-27T16:00:00.000Z","updated":"2021-04-27T16:00:00.000Z","comments":true,"path":"2021/04/28/Ceph_Developer_Summit_Quincy_-_Orchestrator_Follow-up/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/28/Ceph_Developer_Summit_Quincy_-_Orchestrator_Follow-up/","excerpt":"","text":"会议纪要 会议主题 跟进EDS（Enterprise Data Services）并制定Quincy的路线图。 参会人员 全体成员 会议内容 路线图制定 会议开始时，主持人确认目标是制定Quincy的路线图。 主持人已经通过Orchestrated Quincy和其他工具整理了CDS（Ceph Development Sprint）列表中的事项，并浏览了Tracker和Trello，总结出高层次的任务列表。 任务优先级划分 建议对任务进行高、中、低优先级的划分，以便后续决策。 讨论了多个任务的优先级，包括： Refractor safe adm into a proper python package：被认为是开发者体验相关，优先级待定。 Managed client curing：已在进行中。 Clarify host maintenance mode：主持人个人关注点，不确定其与调度器的交互是否正确。 NFS-HA：认为重要，但已有进展。 Postspec crash info：认为是一个重要的功能缺口。 Agent exporter：认为非常重要，与NFS-HA同等重要。 后续行动计划 确认使用Trello来跟踪和管理高层次任务。 讨论了如何改进架构，而不是仅仅提高速度，特别是在处理大规模集群时。 确认了一些任务的当前状态和未来计划，如监控服务的IP绑定、RGW多站点规范的制定等。 其他讨论点 讨论了如何从集群内部安全地移除集群，建议使用外部工具来执行此操作。 讨论了监控堆栈的定制化需求，建议通过配置选项来统一管理容器镜像。 决定事项 使用Trello来管理任务优先级和进度。 确认了一些任务的优先级和当前状态。 讨论了如何改进架构和处理大规模集群的问题。 后续行动 继续在Trello上更新和调整任务优先级。 开始实施高优先级任务，如改进架构和处理大规模集群的问题。 确认并实施监控堆栈的定制化需求。 会议结束 会议在讨论了所有议题后结束，全体成员对会议结果表示满意，并期待接下来的工作进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: CephFS Mirroring Part 2","slug":"CephFS_Code_Walkthrough_-_CephFS_Mirroring_Part_2","date":"2021-04-26T16:00:00.000Z","updated":"2021-04-26T16:00:00.000Z","comments":true,"path":"2021/04/27/CephFS_Code_Walkthrough_-_CephFS_Mirroring_Part_2/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/27/CephFS_Code_Walkthrough_-_CephFS_Mirroring_Part_2/","excerpt":"","text":"会议纪要 会议主题：Demurrer Daemon 后续讨论 参会人员：Ceph 分布式存储研发团队 会议时间：[具体时间] 会议地点：[具体地点] 会议内容总结： Demurrer Daemon 概述： Demurrer Daemon 负责在主集群和次集群之间同步快照。 每个集群有一个 Demurrer Daemon，可以处理多个文件系统（multi-fs ready）。 采用推送模型（push model），数据从主集群推送到次集群。 技术细节： Demurrer Daemon 使用 libcephfs 客户端库与本地和远程集群通信。 设计考虑了在主集群和次集群中进行挂载以使用 rsync，但最终选择了使用 libcephfs 客户端库。 支持增量同步，但目前 Pacific 版本仅支持批量复制。 配置和运行： 主集群需要 ceph 配置文件和密钥环。 次集群支持两种添加方式：通过 pr add 接口和通过引导（bootstrapping）。 目前建议每个集群只运行一个 Demurrer Daemon。 代码实现： 从 main.c 开始，进行基本初始化，创建 messenger 和客户端。 使用 Cluster Watcher 订阅 fs map，处理镜像启用和禁用等事件。 通过定时器线程驱动异步操作，处理镜像启用、禁用、添加和移除对等体等操作。 使用 fs mirror 类处理特定文件系统的镜像，支持多对等体。 同步机制： 使用实例观察者和镜像观察者处理通知消息。 通过引导令牌在主集群中导入次集群信息，存储在 mon config store 中。 每个对等体分配多个线程进行快照同步，每个线程处理一个目录。 使用 f-lock 确保多个 Demurrer Daemon 不会同时处理同一目录。 增量同步： 通过比较快照 ID 和元数据来识别删除和重命名操作。 使用 dirty snap id 扩展属性来确定是否可以进行增量同步。 支持基于本地比较和远程比较的增量同步。 后续行动计划： 继续完善 Demurrer Daemon 的增量同步功能。 测试和验证多对等体支持。 优化配置选项和性能。 会议结论： Demurrer Daemon 的设计和实现已经基本完成，但仍需进一步测试和优化。 增量同步功能是当前的重点开发方向。 后续行动： 继续开发和测试增量同步功能。 验证多对等体支持的可行性。 优化配置选项和性能，提升用户体验。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Cephadm","slug":"Ceph_Tech_Talk_-_Cephadm","date":"2021-04-25T16:00:00.000Z","updated":"2021-04-25T16:00:00.000Z","comments":true,"path":"2021/04/26/Ceph_Tech_Talk_-_Cephadm/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/26/Ceph_Tech_Talk_-_Cephadm/","excerpt":"","text":"会议纪要 关键细节： 讨论了关于Ceph存储集群的多个方面，包括软件升级、容器化部署、服务管理等。 提到了与墨西哥城集群的合作，以及在东京的安全邮件系统。 讨论了容器化部署的升级和管理，特别是与Ceph相关的容器化服务。 强调了数据一致性和服务可用性的重要性。 主要议题： 软件升级和容器化部署： 讨论了如何升级和协调容器化部署，特别是在Ceph集群中的应用。 提到了使用容器化技术来提高服务的灵活性和可管理性。 服务管理和数据一致性： 讨论了如何管理服务，包括服务的启动、停止和监控。 强调了数据一致性的重要性，特别是在多节点集群环境中。 安全性和可靠性： 讨论了如何在Ceph集群中实施安全措施，包括邮件系统的安全。 提到了如何确保服务的可靠性和可用性，特别是在高负载情况下。 决定的事项： 决定继续推进容器化部署的升级工作，特别是在Ceph集群中的应用。 决定加强数据一致性的措施，确保在多节点环境中的数据同步。 决定实施更严格的安全措施，特别是在邮件系统和关键服务中。 后续行动计划： 继续推进容器化部署的升级工作，确保所有服务都能顺利迁移到新的容器化平台。 加强数据一致性的监控和维护，确保在多节点环境中的数据同步。 实施更严格的安全措施，特别是在邮件系统和关键服务中，确保系统的安全性和可靠性。 定期进行系统审计和性能评估，确保系统的稳定运行和高效性能。 结束语 本次会议讨论了Ceph存储集群的多个关键议题，包括软件升级、容器化部署、服务管理和数据一致性等。通过本次会议，我们明确了后续的行动计划，并将继续推进相关工作，确保系统的稳定运行和高效性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-04-22","slug":"Ceph_Performance_Meeting_2021-04-22","date":"2021-04-22T16:00:00.000Z","updated":"2021-04-23T16:00:00.000Z","comments":true,"path":"2021/04/23/Ceph_Performance_Meeting_2021-04-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/23/Ceph_Performance_Meeting_2021-04-22/","excerpt":"","text":"会议纪要 会议概要 本次会议是Ceph开发团队的定期会议，主要讨论了近期的工作进展、待处理的Pull Requests（PRs）以及一些技术细节。会议开始时，主持人欢迎大家回归，并简要回顾了过去几周的工作情况。 主要议题 Pull Requests（PRs）讨论 讨论了两个新的PR，均与o-node pinning和trimming相关。一个是Igor提交的，另一个是Adam提交的，但Adam本周不在，因此未能深入讨论。Igor建议对两个方案进行独立审查。 更新了关于RGW压缩和roxdb内存分配的PR，Gabriel的PR需要进一步的审查和测试。 技术细节讨论 Gabriel讨论了在roxdb中进行对象计数的挑战，提出了使用估计大小和节点遍历的方法来改进进度显示。 讨论了如何从PG map中获取对象计数信息，以及如何改进osd的启动过程显示。 Crimson存储优化 介绍了Crimson存储的最新进展，包括与IBM的合作和性能优化。目前Crimson在处理小随机读写方面更高效，但仍需解决多核利用率的问题。 决定事项 对Igor和Adam的PR进行独立审查，计划在下一次性能会议上进一步讨论。 Gabriel将继续测试和改进roxdb中的对象计数和进度显示方法。 继续推进Crimson存储的多核优化工作。 后续行动计划 对Gabriel的PR进行详细审查和性能测试。 继续研究和优化Crimson存储的多核利用率。 下一次会议将讨论PR的进一步审查结果和Crimson存储的进展。 其他事项 确认了关于backfill和recovery reservations的邮件列表讨论的澄清。 会议结束时，主持人提醒大家下周再见，并祝大家一周愉快。 本次会议有效地总结了近期的工作进展，并为接下来的工作指明了方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: Dashboard Follow-up","slug":"Ceph_Developer_Summit_Quincy_-_Dashboard_Follow-up","date":"2021-04-21T16:00:00.000Z","updated":"2021-04-22T16:00:00.000Z","comments":true,"path":"2021/04/22/Ceph_Developer_Summit_Quincy_-_Dashboard_Follow-up/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/22/Ceph_Developer_Summit_Quincy_-_Dashboard_Follow-up/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph Dashboard的功能增强、用户体验改进以及未来的开发计划。会议涉及多个议题，包括嵌入式CLI工具、多集群管理、性能优化等。 主要议题 嵌入式CLI工具（UI Toolbox） 讨论了在Ceph Dashboard中嵌入低级Seth命令的能力，以便用户在不离开UI的情况下执行CLI命令。 强调了这一功能对开发者和用户的潜在价值，特别是在简化节点连接和错误处理方面。 多集群管理 探讨了Ceph Dashboard管理多个Ceph集群的能力，包括RGW多站点和CFS镜像。 讨论了与核心团队的合作，以确保安全性和权限管理的细粒度控制。 性能和可扩展性 讨论了引入缓存到Ceph Manager API的必要性，以及在UI中实现分页、过滤和排序的重要性。 提到了简化开发流程的“Lean Dashboard”计划。 监控和日志管理 讨论了自定义图形仪表板和警报的持久性问题，以及高可用性监控堆栈的需求。 提到了日志聚合的需求，以及可能的集成方式。 用户反馈和分析 讨论了收集和分析用户对Ceph Dashboard使用情况的反馈，以改进功能和用户体验。 决定事项 确认了嵌入式CLI工具（UI Toolbox）的开发优先级。 确定了多集群管理功能的探索性工作。 确认了性能优化和可扩展性改进的必要性。 讨论了监控和日志管理功能的改进方向。 后续行动计划 开始嵌入式CLI工具的开发工作。 与核心团队合作，探讨多集群管理的安全性和权限控制。 继续推进性能优化和可扩展性改进的工作。 收集用户反馈，进一步优化Ceph Dashboard的用户体验。 其他事项 讨论了与Rook团队的合作，以改进Orchestrator的集成和支持。 确认了自测试功能的需求，以便在安装后快速检查组件状态。 会议结束 会议在讨论了所有议题并确定了后续行动计划后结束，与会者感谢大家的参与并期待下次会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-04-21","slug":"Ceph_Crimson_SeaStore_2021-04-21","date":"2021-04-20T16:00:00.000Z","updated":"2021-04-21T16:00:00.000Z","comments":true,"path":"2021/04/21/Ceph_Crimson_SeaStore_2021-04-21/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/21/Ceph_Crimson_SeaStore_2021-04-21/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph项目的多个关键议题，包括代码审查、问题修复、功能实现以及配置优化等方面。会议中涉及的主要议题和决定事项如下： 主要议题与讨论 代码审查与问题修复 Jihan Ritter的PR审查：会议开始时，提到了对Jihan Ritter的PR进行审查，并计划本周继续进行。 Sam的PR验证：正在验证Sam的第二个PR，并修复相关的测试案例和构建错误。 Crimson背景问题：讨论了Crimson背景下的多个失败原因，特别是单个客户端实现中的问题。相关修复已合并，并提供了链接。 Get Info问题：正在处理CRS Lock F-Class实现中的Get Info问题，涉及到损坏的缓冲区列表。 功能实现与优化 可读性回溯：讨论了使回溯更易于人类开发者使用的改进，特别是通过自动化的方式减少手动操作。 信号处理：讨论了信号处理机制，特别是信号处理在实际故障中的可靠性问题。 包管理更新：更新了包管理，包括在商业构建中包含二进制实用程序。 对象范围处理：讨论了对象范围处理的初始合并，并修复了相关问题。 扩展属性支持：正在支持除OI属性外的其他扩展属性。 擦除逻辑实现：完成了擦除逻辑及相关测试，并计划将其集成到旧节点管理器中。 配置与性能优化 配置提取：正在提取与OCD和Crimson相关的配置，以减少内存占用和维护开销。 决定事项 继续进行代码审查和问题修复工作。 优化回溯功能，使其更易于开发者使用。 更新包管理，确保包含必要的二进制实用程序。 完成擦除逻辑的实现，并进行集成测试。 后续行动计划 继续审查Jihan Ritter和Sam的PR。 解决Crimson背景下的问题，并优化相关功能。 完成扩展属性和擦除逻辑的实现，并进行集成。 提取并优化配置，减少内存占用和维护开销。 会议结束 会议最后，各位成员确认了后续的工作计划，并期待下周的进一步进展。会议在互相道别后结束。 参会人员：Jihan Ritter, Sam, 及其他相关开发人员。 会议时间：[具体时间] 会议地点：[具体地点或在线会议平台] 记录人：[记录人姓名] 审核人：[审核人姓名] 附件：相关PR链接、代码修改记录等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-03-03","slug":"Ceph_Developer_Monthly_2021-03-03","date":"2021-04-19T16:00:00.000Z","updated":"2021-04-20T16:00:00.000Z","comments":true,"path":"2021/04/20/Ceph_Developer_Monthly_2021-03-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/20/Ceph_Developer_Monthly_2021-03-03/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统优化与测试改进 日期：2021年3月 参会人员：Kyle Vigor, 以及其他Ceph研发和测试团队成员 主要议题： Ceph RGW性能优化与配置简化 讨论内容： 讨论了通过预设的Erasure Coded（EC）配置文件来简化用户配置，以提高性能和易用性。 探讨了如何在集群启动时自动加载这些预设配置文件，并让用户可以直接使用，无需手动设置。 讨论了如何通过RGW客户端根据不同的EC配置文件动态调整参数，以优化性能。 提出了在BlueStore中为特定池设置提示或属性，以便优化存储分配和管理。 决定事项： 需要进一步讨论和定义具体的EC配置文件参数。 需要研究如何在RGW和BlueStore中实现这些优化策略。 后续行动计划： 创建跟踪问题（tracker issues）和任务分解，以便具体实施这些优化策略。 与开发团队合作，确保这些优化策略的技术可行性和实施细节。 构建与测试优化 讨论内容： 讨论了如何优化测试执行和提高测试覆盖率，包括改进测试的并行执行和减少测试间的重复。 探讨了如何减少测试环境的设置和重置时间，以及如何减少日志收集的开销。 讨论了使用Ninja作为构建工具的可能性，以提高构建速度。 决定事项： 需要进一步分析和优化测试执行流程。 需要评估Ninja作为构建工具的效果和可行性。 后续行动计划： 开展暑期项目，专注于测试优化和构建效率提升。 探索使用Ninja和其他构建工具的可能性，并进行实际测试。 Telemetry意识提升 讨论内容： 讨论了如何在用户界面和命令行接口中提高Telemetry的可见性和用户参与度。 探讨了如何通过教育和宣传来减少用户对Telemetry的疑虑。 决定事项： 需要在主要升级时提醒用户启用Telemetry。 需要通过CLI和文档宣传Telemetry的好处和实际应用案例。 后续行动计划： 在主要升级时通过CLI提醒用户启用Telemetry。 制作宣传材料，展示Telemetry的实际应用和好处。 Windows支持 讨论内容： 讨论了Windows支持的进展，包括构建和测试流程的自动化。 探讨了如何通过CI集成来确保Windows支持的稳定性和可靠性。 决定事项： 需要进一步完善Windows支持的CI流程。 需要确保Windows支持的测试覆盖率和质量。 后续行动计划： 与CI团队合作，完善Windows支持的CI流程。 增加Windows支持的测试用例，确保质量。 总结： 本次会议主要聚焦于Ceph RGW的性能优化、构建与测试流程的改进、Telemetry的推广以及Windows支持的进展。通过讨论，明确了具体的优化方向和实施步骤，并制定了相应的后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: RADOS Follow-up","slug":"Ceph_Developer_Summit_Quincy_-_RADOS_Follow-up","date":"2021-04-19T16:00:00.000Z","updated":"2021-04-20T16:00:00.000Z","comments":true,"path":"2021/04/20/Ceph_Developer_Summit_Quincy_-_RADOS_Follow-up/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/20/Ceph_Developer_Summit_Quincy_-_RADOS_Follow-up/","excerpt":"","text":"会议纪要 会议概述 本次会议是继CDS Raiders会议后的跟进会议，旨在回顾在CDS讨论的项目，并根据优先级将其整理到Trello看板中。会议开始前，主持人欢迎了所有参与者，并简要介绍了会议目的。 主要议题与讨论 Trello看板整理： 会议首先回顾了在Etherpad中列出的项目，并确保这些项目已正确转移到Trello看板上。 讨论了各个项目的具体细节，包括仪表盘改进、崩溃遥测面板、BlueStore或Split Cache改进等。 BlueStore与Split Cache改进： 由于某些BlueStore书籍的可用性问题，上次会议未详细讨论。 计划在性能会议上进一步讨论这些改进，并已将相关文档链接添加到Etherpad。 Manager改进： 讨论了一系列Manager的改进措施，包括短期和长期目标。 特别提到了改进进度模块和Insights，这些已有单独的Trello卡片。 Autoscaler改进： 讨论了Autoscaler的改进，包括创建单独的自动配置文件，用户可以根据工作负载选择合适的配置。 Cluster Log Messages： 决定不存储所有低请求消息在集群日志中，而是将其定向到Manager日志。 讨论了控制监控器中修剪率的更适应性方法。 其他技术细节： 讨论了结构化配置文件、自动认证密钥轮换、Autoscaler改进、QoS（Quality of Service）等。 特别提到了MClock调度器的默认使用，以及自动化基线测量的需求。 决定事项 确认了各个项目的优先级和实施细节。 决定将某些项目的改进细节转移到Trello看板，以便更好地管理和跟踪。 确定了某些项目的短期和长期目标，并计划在后续的性能会议中进一步讨论。 后续行动计划 继续在Trello看板上跟踪和管理各个项目的进展。 对于某些未详细讨论的项目，计划在后续的性能会议或CDM会议上进一步讨论。 确保所有项目的改进措施得到适当的文档记录和用户支持。 其他备注 会议还讨论了一些小的改进项目，这些项目适合新手开发者参与。 对于某些技术细节，如设备错误和OSD崩溃的映射，提出了进一步的集成和改进建议。 会议结束 会议在讨论完所有议题后结束，主持人感谢所有参与者的参与，并祝愿大家有一个愉快的一天。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-04-20","slug":"Ceph_Orchestrator_Meeting_2021-04-20","date":"2021-04-19T16:00:00.000Z","updated":"2021-04-20T16:00:00.000Z","comments":true,"path":"2021/04/20/Ceph_Orchestrator_Meeting_2021-04-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/20/Ceph_Orchestrator_Meeting_2021-04-20/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了与Ceph分布式存储系统相关的多个议题，包括Ceph部署、Ganesha NFS服务配置、以及NVMe over Fabrics的实现细节。会议还涉及了后续行动计划和一些技术决策。 主要议题 Ceph部署与Ganesha NFS服务配置 讨论了如何优化Ganesha NFS服务的部署，特别是在Ceph环境中。 决定使用Ceph的调度机制来管理Ganesha服务的重启和故障转移，而不是依赖于Peoplesoft ID。 提出了通过Ingress服务和HAProxy来管理NFS服务的IP地址和负载均衡，以确保服务的高可用性和性能。 NVMe over Fabrics的实现 讨论了如何在SPDK（Storage Performance Development Kit）中实现NVMe over Fabrics的命名空间掩码功能。 展示了如何在SPDK中通过RPC调用来动态附加和分离控制器到命名空间，以及如何处理活动和非活动命名空间ID。 提出了将SPDK的命名空间掩码功能与Ceph的访问控制机制集成，以便更好地管理权限和安全性。 Ceph部署中的密钥管理 讨论了在Ceph部署中如何管理密钥环，特别是在Ganesha配置中。 决定在短期内继续使用现有的密钥环部署方式，但未来将修改Ganesha以支持在配置中明确指定密钥，从而避免物理部署密钥环文件。 Ceph客户端配置管理 讨论了如何管理Ceph客户端的配置文件（ceph.conf），特别是在集群中的客户端节点上。 提出了通过Ceph的管理工具来动态更新客户端节点的配置文件，以确保客户端能够正确访问Ceph集群。 决定事项 使用Ceph的调度机制来管理Ganesha NFS服务的重启和故障转移。 通过Ingress服务和HAProxy来管理NFS服务的IP地址和负载均衡。 在短期内继续使用现有的密钥环部署方式，未来将修改Ganesha以支持在配置中明确指定密钥。 通过Ceph的管理工具动态更新客户端节点的配置文件。 后续行动计划 继续优化Ganesha NFS服务的部署和管理，确保服务的高可用性和性能。 在SPDK中实现并测试NVMe over Fabrics的命名空间掩码功能，并考虑与Ceph的访问控制机制集成。 修改Ganesha以支持在配置中明确指定密钥，避免物理部署密钥环文件。 开发Ceph管理工具，动态更新客户端节点的配置文件，确保客户端能够正确访问Ceph集群。 其他事项 需要进一步讨论和测试HAProxy的配置，确保在服务故障转移时客户端不会被重定向到错误的节点。 需要与Ganesha开发团队讨论，确保Ganesha服务的配置和管理符合Ceph的最佳实践。 结论 本次会议涵盖了多个与Ceph分布式存储系统相关的重要议题，并制定了具体的行动计划。团队将继续优化Ceph和Ganesha的集成，确保系统的高可用性、性能和安全性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS Code Walkthrough: CephFS Mirroring Part 1","slug":"CephFS_Code_Walkthrough_-_CephFS_Mirroring_Part_1","date":"2021-04-18T16:00:00.000Z","updated":"2021-04-19T16:00:00.000Z","comments":true,"path":"2021/04/19/CephFS_Code_Walkthrough_-_CephFS_Mirroring_Part_1/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/19/CephFS_Code_Walkthrough_-_CephFS_Mirroring_Part_1/","excerpt":"","text":"会议纪要 会议主题：Ceph Pacific版本中新引入的FFS Mirroring功能代码走读 会议时间：[具体时间] 参会人员：[参会人员名单] 会议内容总结： 功能介绍： 本次会议主要讨论了Ceph Pacific版本中新引入的FFS Mirroring（或称为FFS Snapshot Mirroring）功能。 该功能允许集群管理员或操作员选择性地将目录快照同步到远程Ceph文件系统，实现异步数据复制。 功能结构与持久化： 讨论了涉及的数据结构及其在集群中的持久化位置，特别是在Ceph的Object中。 介绍了FS Map（文件系统映射）及其在存储和管理对等信息中的作用。 接口与操作： 详细介绍了从操作员或集群管理员角度如何启用目录的快照同步。 涉及的接口包括启用/禁用文件系统镜像、添加/移除对等点等。 强调了使用fs snapshot mirror前缀的接口，避免与fs mirror接口混淆。 管理模块与数据复制： 管理模块（Manager Module）提供了镜像功能的接口，并负责与镜像守护进程（Mirror Daemons）的交互。 镜像守护进程负责实际的数据复制和快照同步工作。 状态机与目录映射： 介绍了如何通过状态机管理目录与镜像守护进程的映射关系。 讨论了状态机的异步特性及其在目录添加、移除和重新分配中的应用。 后续行动计划： 计划进行第二部分会议，详细讨论镜像守护进程的实际代码实现。 将继续优化和完善FFS Mirroring功能，包括支持多个镜像守护进程的活跃-活跃模式。 会议结论： 本次会议为Ceph Pacific版本中的FFS Mirroring功能提供了深入的技术解读和代码走读，为后续的开发和优化工作奠定了基础。 后续行动： 安排第二部分会议，详细讨论镜像守护进程的代码实现。 继续优化FFS Mirroring功能，确保其稳定性和高效性。 会议感谢： 感谢所有参会人员的积极参与和宝贵意见。 注： 本次会议纪要基于会议内容的详细记录，确保了关键细节、讨论议题、决定事项及后续行动计划的全面覆盖。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-04-14","slug":"Ceph_Crimson_SeaStore_2021-04-14","date":"2021-04-15T16:00:00.000Z","updated":"2021-04-16T16:00:00.000Z","comments":true,"path":"2021/04/16/Ceph_Crimson_SeaStore_2021-04-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/16/Ceph_Crimson_SeaStore_2021-04-14/","excerpt":"","text":"会议纪要 关键细节 PR审查进展: 上周提交了多个PR，涉及watch和notify功能的实现，包括分离watch的超时处理和一些小的修复。 主要议题: 讨论了watch和notify机制在经典OSD和crimson中的实现差异，以及如何优化这些机制以支持端到端映射。 决定事项: 决定是否可以移除经典OSD中watch和session的耦合，以简化实现并提高效率。 后续行动计划: 继续审查和合并PR，优化crimson的包管理，改进调试信息的输出格式，以及探索c-store的性能优化。 讨论的主要议题 PR审查: 上周提交了多个PR，主要涉及watch和notify功能的实现，包括分离watch的超时处理和一些小的修复。计划在本周内完成这些PR的审查。 Watch和Notify机制: 讨论了watch和notify机制在经典OSD和crimson中的实现差异。经典OSD中，watch与session紧密耦合，而在crimson中，watch机制更为独立。讨论了是否可以移除经典OSD中watch和session的耦合，以简化实现并提高效率。 包管理优化: 讨论了crimson的包管理问题，建议创建一个单独的包来区分crimson和经典OSD，以避免混淆和提高用户识别度。 调试信息输出: 讨论了如何改进调试信息的输出格式，以便更方便地进行调试。提出了改进backtrace输出的需求，以便在崩溃时能更清晰地看到调用栈信息。 c-store性能优化: 讨论了c-store的性能优化问题，包括改进缓存数据结构和事务处理的内部机制，以及增加性能计数器以更好地监控和分析性能问题。 决定的事项 继续审查和合并PR，特别是涉及watch和notify功能的PR。 决定是否可以移除经典OSD中watch和session的耦合，以简化实现并提高效率。 优化crimson的包管理，创建一个单独的包来区分crimson和经典OSD。 改进调试信息的输出格式，特别是backtrace的输出，以便更方便地进行调试。 后续的行动计划 完成PR的审查和合并工作。 探索并实施移除经典OSD中watch和session耦合的方案。 优化crimson的包管理，创建单独的包。 改进调试信息的输出格式，特别是backtrace的输出。 探索c-store的性能优化，包括改进缓存数据结构和事务处理的内部机制，以及增加性能计数器。 结论 本次会议主要讨论了ceph存储系统中watch和notify功能的实现细节，以及如何优化这些机制以支持端到端映射。同时，还讨论了包管理、调试信息输出和c-store性能优化等关键问题，并制定了相应的后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2021-04-14","slug":"Ceph_Docubetter_Meeting_2021-04-14","date":"2021-04-14T16:00:00.000Z","updated":"2021-04-14T16:00:00.000Z","comments":true,"path":"2021/04/15/Ceph_Docubetter_Meeting_2021-04-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/15/Ceph_Docubetter_Meeting_2021-04-14/","excerpt":"","text":"会议纪要 关键细节： SEP Idiom Rewrite Project：正在进行中，旨在重写SEP ADM指南中的所有字符串，共19个部分。项目虽落后于计划，但进展顺利。 Google Season of Docs：目前有六名申请者，项目提案为创建一个全面的“用户贡献指南”，解释如何使用Git以及处理各种错误信息。结果将于17日揭晓。 M Clock Documentation：Neha提交的文档已由会议参与者重新编辑，以改善语法和内容表达，这是第三次采用这种模式，效果良好。 讨论的主要议题： 文档重写项目的进展和挑战。 Google Season of Docs的申请情况和预期结果。 文档编辑和开发者贡献流程的优化。 决定的事项： 继续推进SEP Idiom Rewrite Project和Google Season of Docs项目。 维持现有的文档编辑流程，鼓励开发者直接提交初稿，后续由专业人员进行优化。 后续的行动计划： 17日等待Google Season of Docs的申请结果，并根据结果调整后续行动。 继续优化文档编辑流程，特别是对于非英语母语的开发者，简化他们的贡献流程。 探索新的志愿者来源，如即将参加的Right-to-Doc会议。 其他讨论点： 会议参与者分享了个人的工作习惯和时间管理，强调了非传统工作时间对于创造性工作的益处。 讨论了邮件列表的使用和管理，以及如何更有效地处理大量信息。 结论： 会议强调了文档项目的重要性和当前的进展，同时提出了对未来工作流程的改进建议。所有参与者对项目的未来持乐观态度，并期待即将到来的Google Season of Docs的结果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-04-13","slug":"Ceph_Orchestrator_Meeting_2021-04-13","date":"2021-04-13T16:00:00.000Z","updated":"2021-04-14T16:00:00.000Z","comments":true,"path":"2021/04/14/Ceph_Orchestrator_Meeting_2021-04-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/14/Ceph_Orchestrator_Meeting_2021-04-13/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统的开发与测试 参会人员：Ceph研发团队成员 会议时间：[具体日期] 会议地点：线上会议 主要议题： RGW（RADOS Gateway）服务的测试覆盖问题 当前的Pull Request主要集中在RGW服务上，但缺乏测试覆盖。 需要解决虚拟IP分配问题，以避免与其他节点的IP冲突。 讨论了使用bash脚本进行临时解决方案的可能性，但建议寻找更复杂的解决方案。 虚拟IP分配问题 讨论了如何在测试环境中分配虚拟IP，避免冲突。 提出了使用机器锁定机制来分配虚拟IP的建议。 RGW服务的测试案例 计划编写一个测试案例，确保RGW服务能够创建并正确运行。 需要解决虚拟IP问题，以便进行更全面的测试。 单节点部署的测试 讨论了单节点部署的测试需求，建议创建一个单独的测试目录。 需要确保单节点部署的测试能够快速运行，并且覆盖所有必要的功能。 NFS服务的测试覆盖 确认了NFS服务的测试已经在DLI测试中覆盖，但建议增加更多的端到端测试。 讨论了如何改进测试框架，使其更加灵活和自动化。 Grafana服务的持久化问题 讨论了Grafana服务的数据持久化问题，建议暂时使用本地存储，并记录其局限性。 需要进一步研究如何更好地支持Grafana的定制化需求。 NFS服务的CLI参数问题 决定移除NFS服务的CLI参数，以简化接口。 需要更新相关的文档和发布说明。 决定事项： 虚拟IP分配问题的解决方案 将尝试使用机器锁定机制来分配虚拟IP。 RGW服务的测试案例编写 将编写一个全面的测试案例，确保RGW服务的正确性和稳定性。 单节点部署的测试改进 将创建一个单独的测试目录，以确保单节点部署的测试能够快速且全面地运行。 NFS服务的CLI参数移除 将移除NFS服务的CLI参数，并更新相关的文档和发布说明。 后续行动计划： 解决虚拟IP分配问题 研发团队将探索并实现一个稳定的虚拟IP分配机制。 编写并运行RGW服务的测试案例 研发团队将编写并运行RGW服务的测试案例，确保其功能和性能。 改进单节点部署的测试 研发团队将改进单节点部署的测试，确保其快速且全面地覆盖所有功能。 移除并更新NFS服务的CLI参数 研发团队将移除NFS服务的CLI参数，并更新相关的文档和发布说明。 备注： 会议中提到的技术术语和工具，如RGW、Ceph、RADOS、DLI、Grafana等，是Ceph分布式存储系统的关键组件和工具，研发团队将继续深入研究和优化这些组件。 会议强调了测试覆盖的重要性和持续改进的必要性，以确保Ceph系统的稳定性和可靠性。 研发团队将继续关注用户反馈和系统性能，以不断优化和改进Ceph系统。 会议结束时间：[具体时间] 下次会议预定时间：[具体日期和时间] 以上是本次会议的详细纪要，研发团队将根据会议决定和行动计划，继续推进Ceph系统的开发和测试工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: CI","slug":"Ceph_Developer_Summit_Quincy_-_CI","date":"2021-04-11T16:00:00.000Z","updated":"2021-04-12T16:00:00.000Z","comments":true,"path":"2021/04/12/Ceph_Developer_Summit_Quincy_-_CI/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/12/Ceph_Developer_Summit_Quincy_-_CI/","excerpt":"","text":"会议纪要 会议主题：测试基础设施改进讨论 参会人员：David Galloway等 会议时间：[具体时间] 会议地点：[具体地点] 主要议题： Jenkins作业和构建器的可靠性改进 讨论了Jenkins作业中存在的竞争条件问题，建议增加详细日志记录并延长日志存储时间。 提出了设置预生产环境，以便在实际部署前更广泛地测试更改。 测试环境的改进 讨论了如何改进测试节点升级或添加新补丁包时的现有设置。 提出了使用临时Jenkins实例进行更详细的测试。 PR标签和优先级 讨论了如何标记对构建器测试设置修复重要的PR，以便更容易识别和优先审查。 日志和调试改进 讨论了如何改进Jenkins日志，使其更易于调试，特别是在make check测试中。 提出了使用CTest输出机器可读信息，以便更容易识别失败的单个测试。 元数据和机器信息 讨论了在Jenkins作业中包含更多关于运行作业的机器的元数据，以便更好地识别特定发行版或机器类型上的问题。 已知竞争条件的处理 讨论了如何处理已知的难以调试的竞争条件，建议Jenkins能够自动重新运行遇到已知问题的作业。 集成测试和Cephadm的改进 讨论了如何改进集成测试，特别是通过Cephadm部署和管理集群的能力。 提出了增加更多工具和框架，如CBT，以收集更多运行时的资源利用信息。 容器构建过程的改进 讨论了容器构建过程的脆弱性，建议将Dockerfile移到Ceph树中，以简化容器构建过程。 降级测试 讨论了降级测试的重要性，建议创建一个专门的降级测试套件。 决定事项： 增加Jenkins作业的日志详细程度和存储时间。 设置预生产环境以测试基础设施更改。 标记和优先处理对构建器测试设置修复重要的PR。 改进Jenkins日志以更易于调试。 在Jenkins作业中包含更多机器元数据。 自动重新运行遇到已知竞争条件的Jenkins作业。 改进Cephadm以支持更复杂的部署和管理任务。 简化容器构建过程。 创建降级测试套件。 后续行动计划： 实施日志改进措施。 设置和配置预生产环境。 开发和部署PR标签和优先级系统。 改进Jenkins日志和调试工具。 实施机器元数据收集。 开发自动重新运行Jenkins作业的机制。 改进Cephadm以支持更多集成测试。 简化容器构建过程。 创建和实施降级测试套件。 备注： 会议中提到的具体技术和工具，如Jenkins, Cephadm, CTest, CBT等，是Ceph分布式存储系统开发和测试中的关键组件。 会议讨论了多个技术细节和改进措施，旨在提高测试基础设施的可靠性和效率，确保Ceph系统的稳定性和性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: CephFS","slug":"Ceph_Developer_Summit_Quincy_-_CephFS","date":"2021-04-11T16:00:00.000Z","updated":"2021-04-12T16:00:00.000Z","comments":true,"path":"2021/04/12/Ceph_Developer_Summit_Quincy_-_CephFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/12/Ceph_Developer_Summit_Quincy_-_CephFS/","excerpt":"","text":"会议纪要 会议概览 本次会议主要讨论了Ceph分布式存储系统中的多个关键议题，包括Dashboard和NFS的当前状态与后续步骤、MDS内存目标、文件系统加密（fs-crypt）、异步操作、递归删除、MDS滚动升级、文件系统镜像指标以及客户端隔离（fencing）等。 讨论的主要议题 Dashboard和NFS的当前状态与后续步骤 展示了Dashboard中文件系统特定组件的界面，包括默认系统、MDS信息、客户端连接、目录列表和快照创建等功能。 讨论了NFS v3的支持问题，决定未来不再支持NFS v3，并可能在未来版本中移除相关支持。 提到了NFS插件的集成工作，以及与Ganesha的兼容性问题。 MDS内存目标 讨论了动态调整MDS缓存内存限制的PR，目标是根据MDS的总内存使用情况动态修改缓存限制。 文件系统加密（fs-crypt） 讨论了文件名加密的实现进展，以及内容加密中遇到的截断问题。 提到了客户端处理未缓存I/O时的加密需求，以及可能的解决方案。 异步操作 讨论了异步创建和删除操作的实现，以及如何处理递归操作中的同步问题。 递归删除 提出了添加递归删除RPC的建议，以简化管理操作，特别是针对子卷的删除。 讨论了实现细节和潜在的挑战，如硬链接的处理。 MDS滚动升级 讨论了简化MDS升级过程的方案，包括避免MDS在兼容性设置变化时自杀的问题。 提出了支持混合版本MDS的长期目标。 文件系统镜像指标 讨论了与RBD镜像指标对齐的需求，以便更好地监控和管理镜像过程。 客户端隔离（fencing） 讨论了在Kubernetes集群中实现客户端隔离的需求，以便在集群不可用时能够安全地隔离客户端。 提出了基于标签和生成ID的解决方案，但尚未确定最终方案。 决定的事项 未来版本中将不再支持NFS v3。 将探索简化MDS升级过程的方法，并考虑支持混合版本MDS。 将研究递归删除RPC的实现细节和挑战。 后续行动计划 继续推进文件系统加密的开发，解决截断问题。 研究并实现递归删除RPC，考虑硬链接的处理。 完善MDS滚动升级方案，确保升级过程的稳定性和安全性。 跟进文件系统镜像指标的开发，确保与RBD镜像指标的一致性。 进一步讨论和确定客户端隔离的最终方案。 其他备注 会议中提到的多个议题仍处于讨论和开发阶段，需要进一步的工作和测试。 对于每个议题，都需要详细的开发计划和时间表，以确保功能的稳定实现和集成。 本次会议为Ceph的持续改进和发展提供了重要的讨论和决策基础，后续的工作将围绕这些关键议题展开。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: Dashboard","slug":"Ceph_Developer_Summit_Quincy_-_Dashboard","date":"2021-04-11T16:00:00.000Z","updated":"2021-04-12T16:00:00.000Z","comments":true,"path":"2021/04/12/Ceph_Developer_Summit_Quincy_-_Dashboard/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/12/Ceph_Developer_Summit_Quincy_-_Dashboard/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph Dashboard团队在Quincy版本发布前的关键议题，包括团队变动、功能优先级调整、用户界面改进、后端优化等。 关键细节 团队变动：由于近期团队成员变动，特别是来自SUSE的同事流失，团队能力受到一定影响。因此，团队决定重新考虑当前的工作重点。 功能优先级调整：团队计划更多关注用户体验（UX）和易用性，而不是完美地复制Ceph的所有功能。将采用更精简的方法，避免提供所有功能，而是专注于核心流程的优化。 用户界面改进： 引入安装向导和升级向导，以简化用户操作流程。 改变当前模仿Ceph功能的界面，提供更多流程引导的方式。 后端优化： 精简Dashboard代码库，减少重复代码，提高代码复用性。 探索将部分前端逻辑移至后端，以简化开发和维护。 跨组件接口：解决Dashboard与Ceph其他组件（如Ceph Manager）之间的数据同步问题，确保Dashboard始终与Ceph保持同步。 讨论的主要议题 用户体验和易用性：如何通过向导和流程优化提升用户体验。 代码库优化：如何通过代码重构和精简减少维护成本。 跨组件数据同步：如何确保Dashboard与Ceph其他组件的数据一致性。 决定的事项 优先考虑用户体验和易用性，简化功能集。 开始实施安装和升级向导，以引导用户操作。 探索前端逻辑后端化的可能性，以简化开发。 确保Dashboard与Ceph其他组件的数据同步。 后续行动计划 实施安装和升级向导。 开始代码库的精简和重构工作。 与Ceph其他组件团队协作，确保数据同步机制的实施。 持续关注用户体验反馈，不断优化界面和流程。 结论 本次会议明确了Ceph Dashboard团队在Quincy版本发布前的主要工作方向和优先级，为后续的开发和优化工作奠定了基础。团队将继续关注用户体验和代码质量，确保Dashboard的稳定性和易用性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: RBD","slug":"Ceph_Developer_Summit_Quincy_-_RBD","date":"2021-04-11T16:00:00.000Z","updated":"2021-04-12T16:00:00.000Z","comments":true,"path":"2021/04/12/Ceph_Developer_Summit_Quincy_-_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/12/Ceph_Developer_Summit_Quincy_-_RBD/","excerpt":"","text":"会议纪要 会议主题：Ceph Dashboard、NVMe over Fabrics、RBD Mirroring Monitoring、Volume Groups on Snap Mirroring、Prometheus Scale Out、Image Encryption 会议时间：[具体日期] 参会人员：Jeff, Ernesto, Ilias, Michael, Danny, Orr, 以及其他相关人员 会议内容总结： Ceph Dashboard 演示 Ernesto 展示了 Ceph Dashboard 的功能，重点介绍了 RBD 镜像和 RBD 镜像功能。 演示了如何在 Dashboard 中创建 RBD 镜像、启用日志记录、设置条带化选项和 QoS 选项。 讨论了 RBD 镜像的配置和操作，包括镜像保护和克隆。 提到了命名空间支持和对旧版本 RBD 镜像的兼容性。 NVMe over Fabrics 状态和下一步计划 讨论了 NVMe over Fabrics 的工作进展，包括设置网关和使用 SPDK。 提到了需要实现发现服务，以便在集群中找到目标和命名空间。 预计未来几个月会有更多工作进展。 RBD Mirroring Monitoring Ilias 介绍了 RBD 镜像监控的目标，包括改进和统一不同镜像解决方案的指标。 讨论了 Prometheus 指标的暴露和收集，以及如何解决管理器过载的问题。 提到了需要实现每个镜像守护进程的独立 Prometheus 端点。 Volume Groups on Snap Mirroring Michael 讨论了在快照镜像中使用卷组的可能性，以便创建一致性快照组进行镜像。 提到了现有的快照镜像功能和未来的扩展计划。 Prometheus Scale Out 讨论了 Prometheus 的扩展问题，特别是在 Kubernetes 环境中直接从客户端收集指标的可行性。 提到了需要避免管理器过载，并考虑客户端直接发送指标到 Prometheus 的方案。 Image Encryption Danny 和 Orr 介绍了在 librbd 中添加加密功能的工作，特别是基于 Lux 格式的加密。 讨论了加密功能的性能优势和未来的改进方向，包括支持不同密钥的克隆功能。 决定事项： 继续推进 Ceph Dashboard 的功能完善，特别是 RBD 镜像和监控部分。 持续关注 NVMe over Fabrics 的工作进展，并计划实现发现服务。 改进 RBD 镜像监控，实现每个镜像守护进程的独立 Prometheus 端点。 探索在快照镜像中使用卷组的可能性，并考虑 Kubernetes 集成。 解决 Prometheus 扩展问题，特别是在 Kubernetes 环境中的指标收集。 完成图像加密功能的代码审查和测试，特别是支持不同密钥的克隆功能。 后续行动计划： 继续完善 Ceph Dashboard 的功能，特别是 RBD 镜像和监控部分。 推进 NVMe over Fabrics 的工作，实现发现服务和其他必要的增强功能。 实现 RBD 镜像监控的改进，特别是每个镜像守护进程的独立 Prometheus 端点。 探索在快照镜像中使用卷组的可能性，并考虑 Kubernetes 集成。 解决 Prometheus 扩展问题，特别是在 Kubernetes 环境中的指标收集。 完成图像加密功能的代码审查和测试，特别是支持不同密钥的克隆功能。 会议结束： 会议在讨论完所有议题后结束，参会人员感谢彼此的参与，并期待明天的会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: Orchestrator","slug":"Ceph_Developer_Summit_Quincy_-_Orchestrator","date":"2021-04-08T16:00:00.000Z","updated":"2021-04-08T16:00:00.000Z","comments":true,"path":"2021/04/09/Ceph_Developer_Summit_Quincy_-_Orchestrator/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/09/Ceph_Developer_Summit_Quincy_-_Orchestrator/","excerpt":"","text":"会议纪要 会议概述 本次会议主要围绕Ceph分布式存储系统的管理工具Orchestra SDS的仪表盘演示和功能讨论展开。会议由一位研发人员主持，重点介绍了仪表盘的新功能和与Ceph管理工具的集成。 主要议题 仪表盘功能演示： 展示了集群主机列表及其上运行的服务。 演示了如何编辑、删除主机，或将主机置于维护模式。 讨论了添加和删除主机标签的功能。 维护模式： 详细介绍了如何将主机置于维护模式，并处理相关的警告和错误。 讨论了维护模式下的服务迁移和主机状态更新。 服务管理： 讨论了服务的创建、删除和管理。 提到了当前服务对话框过于通用，需要更具体的配置参数。 讨论了服务的高可用性配置，如HAProxy和Keepalived。 开发环境： 讨论了使用Kcli进行虚拟化开发环境的优缺点。 探讨了如何提供更轻量级的开发环境，以便于开发和测试。 功能和改进： 讨论了Ceph管理工具的改进方向，包括简化操作、提高用户体验和增强功能。 提到了资源调度、自动调整OSD和MDS内存等高级功能的需求。 决定事项 维护模式和主机管理： 确认了维护模式的功能和操作流程。 决定进一步简化主机移除流程，包括自动处理OSD和服务的迁移。 服务管理： 确认了服务管理的当前状态和未来改进方向。 决定提供更具体的服务配置参数，并考虑引入服务规范模式。 开发环境： 决定进一步探讨和优化开发环境，以提高开发效率和简化部署流程。 后续行动计划 功能开发： 继续开发和完善仪表盘功能，特别是服务管理和维护模式。 探索和实现更高级的功能，如资源调度和自动调整。 开发环境优化： 研究和实施更轻量级的开发环境解决方案。 提供清晰的开发环境设置文档和步骤。 用户反馈和文档： 收集用户反馈，持续改进用户体验。 更新和完善相关文档，确保用户和开发者能够轻松理解和使用新功能。 本次会议为Ceph分布式存储系统的管理和开发提供了明确的方向和行动计划，有助于推动项目的进一步发展和完善。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: RGW","slug":"Ceph_Developer_Summit_Quincy_-_RGW","date":"2021-04-08T16:00:00.000Z","updated":"2021-04-09T16:00:00.000Z","comments":true,"path":"2021/04/09/Ceph_Developer_Summit_Quincy_-_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/09/Ceph_Developer_Summit_Quincy_-_RGW/","excerpt":"","text":"会议纪要 会议主题：Ceph RGW 议程 会议时间：[具体时间] 参会人员：[列出主要参会人员] 主要议题： Swift API 与 S3 API 的支持情况 Swift API 允许更新桶的元数据，但 S3 API 不支持特定操作。 讨论了是否应该扩展 S3 API 以支持这些操作。 Dashboard 和 RGW 的功能更新 展示了 Dashboard 的最新功能，包括多站点配置下的性能图表、用户容量限制的可视化、桶配额管理等。 讨论了增强桶策略和后端管理的必要性，特别是配额管理和加密通知。 管理模块与 RGW 命令行接口 讨论了将所有 RGW 管理命令集成到 CLI 的可能性。 探讨了管理模块与 RGW 管理 API 的关系，以及如何处理多站点配置的问题。 Bucket 索引方案的改进 讨论了使用 SQLite 作为 Bucket 索引的可行性。 探讨了 Bucket 索引性能的问题，特别是对于大型 Bucket 的索引性能。 RGW 的 CLI 统一 讨论了将 RGW 管理命令统一到 CLI 的必要性和实施方案。 缓存策略 讨论了 D3N 和 D4N 缓存策略的进展和未来方向。 Zipper 项目 讨论了 Zipper 项目的当前状态和下一步计划，包括 API 的稳定性和未来发展。 Bucket 清单 讨论了实现 Bucket 清单功能的必要性和可能的实现策略。 RGW 去重 讨论了 RGW 去重的实现策略和可能的技术方案。 Pool 创建问题 讨论了 RGW 创建 Pool 时可能遇到的问题和解决方案。 Rook 和 Bucket Claims 讨论了 Rook 和 Bucket Claims 的相关问题。 测试策略 讨论了 RGW 测试的现状和未来可能的改进方向，特别是关于 API 覆盖和随机测试的需求。 决定事项： 需要进一步讨论和规划如何扩展 S3 API 以支持更多操作。 确定增强 Dashboard 功能的具体需求，包括配额管理和加密通知。 需要对 RGW 管理命令进行重构，以便更好地集成到 CLI 中。 确定 Zipper 项目的下一步行动计划，包括 API 的稳定性和外部实现的兼容性。 需要进一步讨论 Bucket 清单功能的实现细节和策略。 确定 RGW 去重的实现策略和技术方案。 需要改进 RGW 测试策略，特别是增加随机测试和 API 覆盖。 后续行动计划： 安排专门会议进一步讨论 S3 API 的扩展和 Dashboard 功能的增强。 开始 RGW 管理命令的重构工作，并制定详细的实施计划。 继续推进 Zipper 项目，确保 API 的稳定性和兼容性。 制定 Bucket 清单功能的详细实施方案。 确定 RGW 去重的具体技术方案和实施计划。 改进 RGW 测试策略，增加随机测试和 API 覆盖。 备注： 会议中提到的具体技术细节和实现方案需要在后续的会议或工作中进一步细化和确认。 需要定期回顾和更新这些行动计划，确保项目的顺利进行。 会议结束时间：[具体时间] 下次会议预定：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: Rook","slug":"Ceph_Developer_Summit_Quincy_-_Rook","date":"2021-04-08T16:00:00.000Z","updated":"2021-04-09T16:00:00.000Z","comments":true,"path":"2021/04/09/Ceph_Developer_Summit_Quincy_-_Rook/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/09/Ceph_Developer_Summit_Quincy_-_Rook/","excerpt":"","text":"会议纪要 会议主题：Ceph Rook Manager 模块评估与讨论 参会人员：Rick、Travis、Miguel、Seth 等 会议时间：[具体时间] 会议地点：[具体地点] 主要议题： Rook Manager 模块评估：讨论了 Rook Manager 模块的功能和应用场景，特别是与 Ceph 管理模块的集成。 OSD 部署和管理：探讨了 OSD（Object Storage Daemon）的部署和管理方式，包括使用 PVC（Persistent Volume Claim）和直接设备管理。 维护任务自动化：讨论了如何自动化执行维护任务，如 fs check、reshard 等，以及如何在 Rook 和 Ceph 环境中实现。 服务部署和 HA 配置：讨论了如何在 Kubernetes 和 Ceph 环境中部署服务（如 RGW、NFS）以及配置高可用性（HA）。 Bucket 配置和 Cozy 集成：探讨了 Bucket 配置的自动化以及与 Cozy 的集成，特别是在 Kubernetes 1.21 中的新功能。 决定事项： OSD 部署策略：决定继续探讨使用 PVC 和直接设备管理两种方式部署 OSD，并评估其在 Rook 和 Ceph 环境中的适用性。 维护任务自动化：计划开发一个通用的维护任务框架，允许用户定义和执行特定的维护任务，如 fs check 和 reshard。 服务部署和 HA 配置：决定将 HA 配置作为一个可选的独立模块，允许用户根据需要部署和配置高可用性服务。 Bucket 配置和 Cozy 集成：计划在 Rook 中优先集成 Cozy，并探讨如何在 Ceph 环境中实现类似的 Bucket 配置自动化。 后续行动计划： 技术测试开发：开发一个技术测试，部署 Kubernetes 并使用 Rook 管理 Ceph 集群，以确保 Rook Manager 模块的功能和稳定性。 维护任务框架开发：开始开发一个通用的维护任务框架，允许用户定义和执行特定的维护任务。 HA 配置模块开发：开发一个独立的 HA 配置模块，允许用户根据需要部署和配置高可用性服务。 Cozy 集成：在 Rook 中优先集成 Cozy，并探讨如何在 Ceph 环境中实现类似的 Bucket 配置自动化。 备注： 会议中提到的具体技术细节和实现方式将在后续的技术文档和开发过程中进一步明确。 所有决定的事项和后续行动计划将由相关团队负责执行，并定期进行进度更新和评估。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: Crimson","slug":"Ceph_Developer_Summit_Quincy_-_Crimson","date":"2021-04-07T16:00:00.000Z","updated":"2021-04-07T16:00:00.000Z","comments":true,"path":"2021/04/08/Ceph_Developer_Summit_Quincy_-_Crimson/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/08/Ceph_Developer_Summit_Quincy_-_Crimson/","excerpt":"","text":"会议纪要 主题一：适应Ceph的Boost ASIO代码到C-Star Reactor 讨论内容： 现有代码依赖Boost ASIO，讨论如何将其适配到C-Star Reactor中。 探讨是否可以通过包装和适当的回调函数来直接在Reactor中运行。 初步认为需要进一步调查是否需要进行此项工作，特别是对于实时RBD（Live RBD）。 决定事项： 需要进一步调查和评估将Boost ASIO代码适配到C-Star Reactor的可行性和必要性。 可能需要一个初始原型来验证代码的适配情况。 后续行动计划： 由熟悉Boost ASIO和C-Star的开发人员进行深入调查和原型开发。 主题二：Rapid CAR Diamond和Rapid CAR Monitor设计 讨论内容： 讨论了如何设计Replica Daemon和Rapid CAR Monitor来管理复制信息。 现有设计涉及在Replica Monitor中维护Replica Daemon的信息，包括RDMA的IP地址和端口等。 决定事项： 需要重新考虑是否需要在Monitor中维护这些信息，可能通过RADOS对象和watch/notify机制来实现更为合适。 后续行动计划： 重新评估和设计Replica Daemon和Rapid CAR Monitor的管理机制，避免对Monitor的过度依赖。 向社区征求反馈和建议，进一步优化设计。 主题三：Crimson的多核支持与M2N映射 讨论内容： 讨论了如何在Crimson中实现多核支持，包括处理客户端连接、PG状态和后端存储实现。 探讨了是否需要在Messenger中实现多核支持，以及如何处理跨核通信。 决定事项： 决定先实现PG在多个核心上的分布，再考虑Messenger和C-Store的多核支持。 需要实现一个跨核服务来管理PG到核心的映射。 后续行动计划： 开发跨核服务，实现PG到核心的映射。 逐步实现Messenger和C-Store的多核支持。 主题四：C-Store的当前状态和未来工作 讨论内容： 回顾了C-Store的当前进展，包括事务层、逻辑块映射、OMAP和垃圾回收等。 讨论了如何支持ZNS设备和其他可变存储设备。 决定事项： 需要进一步的工作来优化C-Store的性能和稳定性，包括引入更多的性能指标和调试工具。 后续行动计划： 引入性能指标和调试工具，优化C-Store的性能和稳定性。 探索和支持新的存储设备，如ZNS和持久内存。 总结 本次会议涵盖了多个关键议题，包括Boost ASIO代码的适配、Rapid CAR Monitor的设计、Crimson的多核支持和C-Store的优化。每个议题都有明确的后续行动计划，旨在推动Ceph的进一步发展和优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Summit Quincy: RADOS","slug":"Ceph_Developer_Summit_Quincy_-_RADOS","date":"2021-04-06T16:00:00.000Z","updated":"2021-04-06T16:00:00.000Z","comments":true,"path":"2021/04/07/Ceph_Developer_Summit_Quincy_-_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/07/Ceph_Developer_Summit_Quincy_-_RADOS/","excerpt":"","text":"会议纪要 主要议题 Dashboard 和 RADOS 当前状态及下一步计划 由 Ernesto 和 Alfonso 主导，展示了 Dashboard 的功能和未来改进方向。 讨论了 Dashboard 中特定功能的实现，如 OSD 创建和过滤器的使用。 强调了收集用户反馈和建议的重要性，以提高 Dashboard 的可用性和操作性。 Crash Telemetry 面板审查 讨论了收集和审查集群崩溃数据的机制。 提出了将崩溃数据审查纳入日常 bug 清理流程的建议。 讨论了如何改进每日邮件报告，以便更有效地处理新报告的崩溃。 Immutable Content 优化 讨论了在 Ceph 中处理不可变对象的挑战，如空间放大和枚举问题。 提出了将对象打包成大容量的解决方案，类似于 Facebook 的 Ambry 系统。 探讨了在 RGW 层实现打包支持的可能性，并讨论了相关的技术挑战。 Ceph Manager 改进 讨论了扩展 Manager 的策略，如将模块分离到不同的进程中。 提出了创建一个共享池用于某些模块的建议，以提高效率。 讨论了自动缩放器（Auto Scaler）的新行为和潜在的改进。 避免集群日志消息通过 Paxos 讨论了通过 Paxos 存储集群日志消息的问题，特别是可能导致数据库过载的问题。 提出了将日志信息重定向到 Manager 日志的解决方案，以避免 Paxos 的负担。 简化文档编写 讨论了简化选项文档编写的必要性，提出了使用 YAML 文件和 Python 脚本自动生成文档的方案。 探讨了如何通过标签和方案来区分不同类型的选项，以便在 Dashboard 中以不同方式展示。 自动化认证密钥轮换 讨论了实现自动化密钥轮换的挑战，包括两阶段提交和在不重启守护进程的情况下更新密钥。 提出了两种可能的解决方案：监视器同时持有旧密钥和新密钥，或者客户端尝试使用两个密钥。 强调了需要进一步研究认证代码，以确定如何实现无缝密钥轮换。 决定事项 将继续收集用户对 Dashboard 的反馈，并根据反馈进行改进。 将改进崩溃数据审查流程，并优化每日邮件报告。 将探索在 RGW 层实现对象打包支持的可能性。 将实施 Manager 模块的分离和共享池的创建。 将改进自动缩放器的行为，并引入配置文件机制。 将重定向集群日志消息到 Manager 日志，以减轻 Paxos 的负担。 将使用 YAML 文件和 Python 脚本自动生成选项文档。 将研究并实现自动化密钥轮换的解决方案。 后续行动计划 继续收集和分析用户对 Dashboard 的反馈。 实施崩溃数据审查流程的改进。 探索并实现对象打包支持。 实施 Manager 模块的分离和共享池的创建。 改进自动缩放器并引入配置文件机制。 重定向集群日志消息到 Manager 日志。 使用 YAML 文件和 Python 脚本自动生成选项文档。 研究并实现自动化密钥轮换的解决方案。 参会人员 Ernesto、Alfonso、Yuri、Massimo、Nikola Dondrimo、Josh、Junior、Hry、Igor、Adam、Mark、Luk、Sebastian 等。 会议结束 感谢所有参与者的积极参与和贡献，期待在未来的会议中继续讨论和改进 Ceph 项目。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: RADOS Snapshots","slug":"Ceph_Code_Walkthroughs_-_RADOS_Snapshots","date":"2021-03-31T16:00:00.000Z","updated":"2021-03-31T16:00:00.000Z","comments":true,"path":"2021/04/01/Ceph_Code_Walkthroughs_-_RADOS_Snapshots/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/01/Ceph_Code_Walkthroughs_-_RADOS_Snapshots/","excerpt":"","text":"会议纪要：Ceph Snapshot 技术详解 会议概要 日期与时间：2023年3月23日，17:00 UTC 主讲人：Samuel Just 主题：Ceph Snapshot 技术详解 参与人员：Ceph 社区成员 会议形式：在线视频会议 讨论内容 Snapshot 概述 Ceph 支持三种项目：RGW, RBD, 和 ZFS，其中 RBD 和 CephFS 大量使用快照功能。 RBD 在块设备层面使用快照，而 CephFS 在子树层面使用。 两者都使用 Librados 来管理 I/O，并共享相同的底层快照机制。 快照的工作原理 创建快照：客户端维护快照元数据，CephFS 通过 MDS 和能力系统进行排序，RBD 则在每个 RBD 块设备的头对象上维护快照信息。 读取快照：OSD 维护每个对象的快照状态映射，通过在写操作中附加快照信息来更新。 回滚快照：必须逐对象执行，RBD 快照回滚时间与对象数量成线性关系。 删除快照：空间回收是懒惰的后台操作。 客户端与快照交互 客户端通过 RBD 或 CephFS 的快照机制与快照交互。 RBD 在创建快照时，会请求新的快照 ID，并更新头对象的元数据，然后通知所有用户重新加载快照元数据。 快照的底层接口 Librados 提供了四个基本操作：snap create, snap set snap right context, snap remove, 和 snap rollback。 快照创建和删除主要由监视器操作，OSD 通过接收 OSD 地图更新来处理快照信息。 快照的恢复与优化 恢复过程中，需要先恢复头对象，然后根据快照集信息恢复克隆对象。 通过计算克隆子集，优化恢复过程中的数据共享，减少空间使用。 决定事项 无具体决定事项，主要为技术分享和讨论。 后续行动计划 会议录像将上传至 Ceph 的 YouTube 频道。 社区成员应关注即将到来的技术讲座和用户调查。 其他备注 会议中提到的 RBD 镜像功能，如快照镜像和稀疏克隆，为虚拟化环境提供了高效的存储解决方案。 社区成员对快照功能的深入理解有助于更好地利用 Ceph 的存储能力。 会议结束 感谢 Samuel Just 的详细讲解和社区成员的积极参与。 期待下一次的 Ceph 技术分享会议。 以上为本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson 2021-03-31","slug":"Ceph_Crimson_2021-03-31","date":"2021-03-31T16:00:00.000Z","updated":"2021-03-31T16:00:00.000Z","comments":true,"path":"2021/04/01/Ceph_Crimson_2021-03-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/01/Ceph_Crimson_2021-03-31/","excerpt":"","text":"会议纪要 关键细节 时间: 最近一周 参与者: 团队成员 主要议题: 技术问题讨论、代码测试、文档更新、项目进展 讨论的主要议题 MBD测试问题: 使用Sam的新PR进行MBD测试，但存在间歇性的segmentation fault问题。 尝试复现问题，但条件不明确，仍在追踪中。 阅读Sam的segmentation clear代码和journal代码，发现并修复了一个小问题。 FIO测试问题: 设置较大的offset（例如50GB）时，FIO无法运行。 不确定是FIO问题还是其他代码问题，需要进一步调试和确认。 文档更新: 继续更新上周提到的恢复文档，解决了几个问题，预计下周完成。 讨论了使用unique ptr或foreign ptr进行连接重构的问题，决定继续使用unique ptr，但保留未来切换到foreign ptr的可能性。 状态机更新: 更新了经典SD的状态机，以匹配Queensland中的更改，已准备好提交。 计划阅读Erased在Queensland中的事务处理，以便后续使用。 逻辑扩展: 开发了一种方案，将所有相关分配信息嵌入到LBA层，避免使用extent map。 正在实施中，虽然更复杂，但可以消除第二个映射。 Ceph存储问题: 实现了C store中的get和set地址方法。 正在尝试实现read和write meta方法，并调查可能的Marx问题。 树级别环境不变性: 解决了管理树级别环境不变性的问题，正在进行最后的子节点合并工作。 下一步将推进布局和阶段级别的实现。 C-star原生堆栈改进: 注意到C-star原生堆栈的一些改进，主要涉及零拷贝传递和一些bug修复。 单元测试问题: 解决了Jenkins中单元测试不完整的问题，通过添加步骤在检查作业中止时终止运行中的单元测试。 决定的事项 继续使用unique ptr进行连接重构，但保留未来切换到foreign ptr的可能性。 解决Jenkins中单元测试不完整的问题。 后续行动计划 继续追踪和解决MBD测试中的segmentation fault问题。 进一步调试和确认FIO测试中的问题。 完成恢复文档的更新。 实施逻辑扩展方案，消除extent map的使用。 推进Ceph存储和树级别环境不变性的实现。 阅读Raft论文，准备下周讨论。 其他事项 下周将举行CTS会议，欢迎大家添加感兴趣的话题。 结束语 会议结束，感谢大家的参与，祝大家工作顺利。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Persistent Bucket Notifications","slug":"Ceph_Tech_Talk_-_Persistent_Bucket_Notifications","date":"2021-03-31T16:00:00.000Z","updated":"2021-04-01T16:00:00.000Z","comments":true,"path":"2021/04/01/Ceph_Tech_Talk_-_Persistent_Bucket_Notifications/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/04/01/Ceph_Tech_Talk_-_Persistent_Bucket_Notifications/","excerpt":"","text":"会议纪要：Ceph Tech Talk - 持久化桶通知功能介绍 会议概要 本次Ceph技术讲座由Evolve主讲，主题为“持久化桶通知”（Persistent Bucket Notifications）。该功能将在即将发布的Pacific版本中推出，旨在提供一个额外的发布和订阅模型端点，增强系统的可靠性和灵活性。 讨论的主要议题 持久化桶通知的概述： 桶通知机制允许外部系统了解Ceph Redis网关上的操作，如对象的创建、删除和复制。 当前支持的端点包括HTTP、AMQP、RabbitMQ和Kafka，未来计划增加更多端点。 持久化桶通知的优势： 异步通知机制：不等待回复，立即回复客户端，确保消息稍后到达端点。 两阶段提交队列：确保通知的可靠性和持久性，即使Redis网关崩溃也能恢复。 重试机制：确保消息最终到达端点，通过持久化队列实现。 实现细节： 每个持久化主题关联一个队列，确保消息的顺序和避免重复。 使用对象锁机制确保只有一个Redis网关处理队列中的消息。 队列和锁的定期清理机制，防止积累和过期。 未来发展和改进： 增加更多端点类型，如AWS Lambda和SNS。 改进调试工具，提供更直观的队列所有权信息。 考虑将超时配置变为可配置项，以适应不同集群规模的需求。 决定的事项 持久化桶通知功能将在Pacific版本中发布，提供更可靠的异步通知机制。 未来将增加更多端点类型和改进工具，以增强用户体验和功能性。 后续行动计划 继续开发和完善持久化桶通知功能，包括增加新端点和改进调试工具。 考虑将超时配置变为可配置项，以适应不同用户需求。 鼓励社区参与和反馈，以推动功能的进一步发展和优化。 联系方式 Evolve的邮箱和IRC信息将在视频后续提供，以便社区成员联系和参与讨论。 其他信息 提醒参与者填写用户调查，以帮助Ceph团队了解用户需求和使用情况。 本次讲座为Ceph社区成员提供了关于持久化桶通知功能的详细介绍和未来发展方向，旨在增强Ceph在分布式存储领域的竞争力和用户满意度。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-03-11","slug":"Ceph_Orchestrator_Meeting_2021-03-11","date":"2021-03-29T16:00:00.000Z","updated":"2021-03-29T16:00:00.000Z","comments":true,"path":"2021/03/30/Ceph_Orchestrator_Meeting_2021-03-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/30/Ceph_Orchestrator_Meeting_2021-03-11/","excerpt":"","text":"会议纪要 会议主题： 讨论关于Ceph多站点配置的设置和管理，以及相关的技术实现和用户界面设计。 参会人员： Juan Mi, Alfonso, Ernesto, Daniel等。 主要议题： 多站点配置的用户体验： 讨论了多站点配置的不同设置方式，包括复杂的YAML文件、CLI命令和GUI向导。 决定对于新用户和新的集群，使用CLI命令来设置领域（realm）和区域（zone）配置，然后再部署集群。 技术实现和测试： 确定了对于Ceph开发团队来说，使用YAML规范进行QA测试和CI是最重要的。 讨论了与Rook的兼容性问题，决定采用类似Rook的方法，即仅在初始部署时设置配置，不进行后续的协调。 文档和Ansible支持： 强调了确保文档的准确性和完整性的重要性，以便用户理解如何使用CLI命令设置多站点配置。 讨论了如何确保Ansible能够部署和管理现有的多站点配置，特别是在升级时不会破坏现有配置。 网络配置和端口管理： 讨论了网络配置的复杂性，包括多节点部署时的端口分配和IP绑定问题。 确认这些功能仍在开发中，将在后续版本中实现。 NFS版本3的支持： 讨论了是否应该在Ceph中支持NFS版本3，考虑到其复杂性和较少的使用场景。 决定通过邮件列表征求社区意见，考虑是否完全移除对NFS版本3的支持。 决定事项： 对于新用户和新的集群，推荐使用CLI命令来设置多站点配置。 对于Ceph开发团队，将继续使用YAML规范进行QA测试和CI。 将确保文档的准确性和完整性，以便用户理解如何使用CLI命令设置多站点配置。 将考虑是否完全移除对NFS版本3的支持，并通过邮件列表征求社区意见。 后续行动计划： Daniel将开始测试使用CLI命令部署多站点集群的过程。 继续开发网络配置和端口管理功能。 通过邮件列表征求社区意见，决定是否移除对NFS版本3的支持。 其他讨论点： 讨论了服务收集（collecting services）的相关问题，包括服务类型的命名和服务放置的复杂性。 讨论了如何处理服务的共置（colocation）问题，以及如何在不同服务类型之间平衡资源使用。 会议结束： 会议在讨论完所有议题后结束，参会人员表示将按照会议决定开始后续的工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-03-16","slug":"Ceph_Orchestrator_Meeting_2021-03-16","date":"2021-03-29T16:00:00.000Z","updated":"2021-03-29T16:00:00.000Z","comments":true,"path":"2021/03/30/Ceph_Orchestrator_Meeting_2021-03-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/30/Ceph_Orchestrator_Meeting_2021-03-16/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统的性能优化、升级问题、以及一些具体的技术实现细节。会议中涉及了多个关键议题，包括Ceph集群的规模、监控工具的改进、Google Summer of Code项目、以及一些具体的代码实现问题。 关键讨论点 Ceph集群规模： 讨论了用户实际使用的Ceph集群规模，确认有用户至少使用1000个OSDs。 确认当前的性能和可扩展性优于预期的30个节点配置。 监控工具改进： 讨论了需要进一步完善监控工具（exporter），以提升系统的监控能力。 强调了监控工具对于系统性能和可扩展性的重要性。 Google Summer of Code项目： 讨论了项目参与情况，至少有三个人通过邮件联系表达了参与意愿。 讨论了如何作为共同导师参与项目，以及如何处理通过LinkedIn联系的候选人。 代码实现和升级问题： 讨论了具体的代码实现问题，包括如何处理升级过程中的错误和如何改进升级流程。 讨论了如何处理旧的监控容器和如何改进升级过程中的监控栈。 网络和子网配置： 讨论了如何在Ceph中更好地处理网络和子网配置，以及如何将这些配置集成到服务规范中。 决定事项 监控工具改进： 确认需要进一步完善监控工具，以提升系统的监控能力。 Google Summer of Code项目： 确认至少有三个人表达了参与意愿，并将作为共同导师参与项目。 代码实现和升级问题： 确认需要改进升级流程，特别是处理旧的监控容器和改进监控栈的升级。 网络和子网配置： 确认需要将网络和子网配置集成到服务规范中，并讨论了具体的实现细节。 后续行动计划 监控工具改进： 继续完善监控工具，确保其能够提供必要的监控数据。 Google Summer of Code项目： 作为共同导师参与项目，并处理通过LinkedIn联系的候选人。 代码实现和升级问题： 改进升级流程，确保升级过程中不会遗漏任何重要的配置或容器。 网络和子网配置： 将网络和子网配置集成到服务规范中，并确保其能够在实际部署中正常工作。 其他事项 讨论了Ceph集群的健康警告问题，并计划进一步调查和解决。 讨论了如何处理旧的配置选项，并计划在未来的版本中改进这一问题。 会议结束 会议在确认所有议题讨论完毕后结束，并祝愿所有参与者有一个愉快的假期。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-03-30","slug":"Ceph_Orchestrator_Meeting_2021-03-30","date":"2021-03-29T16:00:00.000Z","updated":"2021-03-30T16:00:00.000Z","comments":true,"path":"2021/03/30/Ceph_Orchestrator_Meeting_2021-03-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/30/Ceph_Orchestrator_Meeting_2021-03-30/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统的几个关键议题，包括网络配置、虚拟IP服务、NFS服务的配置和管理，以及Ceph Dashboard的发展路线图。会议还涉及了Ceph与Rook集成的具体问题，以及如何优化NFS和RGW服务的部署和管理。 主要议题 网络配置与管理 讨论了如何通过修改网络列表来确保子网配置的正确性，并探讨了list networks命令与gather facts命令的功能重叠问题。 决定将这两个功能合并，以简化管理和避免重复。 虚拟IP服务（VIP） 讨论了VIP服务在NFS服务中的应用，特别是在NFS守护进程重启或迁移时的IP地址管理问题。 提出了通过扩展放置规范（placement spec）来简化VIP服务的配置和管理。 NFS服务配置 讨论了NFS服务的配置问题，特别是RGW块在NFS配置中的必要性和如何与Rook集成。 决定将RGW配置提升到 orchestrator 层，以便于统一管理和避免在Rook和Cephadm中的重复配置。 Ceph Dashboard发展 讨论了Ceph Dashboard的发展路线图，特别是在即将到来的CDS会议中的讨论安排。 强调了Dashboard与Orchestrator以及其他组件的同步和集成需求。 决定事项 合并list networks和gather facts命令的功能。 扩展VIP服务的放置规范，以简化其配置和管理。 将RGW配置提升到 orchestrator 层，以统一管理和避免重复。 在即将到来的CDS会议中安排关于Ceph Dashboard的讨论。 后续行动计划 实施list networks和gather facts命令的合并。 开发和测试VIP服务的扩展放置规范。 在 orchestrator 层实现RGW配置的管理。 准备在CDS会议中关于Ceph Dashboard的讨论材料。 其他讨论点 讨论了NVMF（NVMe over Fabrics）的管理层和子系统与命名空间模型的选择。 讨论了Ceph与Rook在NFS服务配置上的差异和集成问题。 本次会议为Ceph存储系统的未来发展方向和具体实施细节提供了明确的指导和决策。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastore 2021-03-23","slug":"Ceph_Crimson_Seastore_2021-03-23","date":"2021-03-25T16:00:00.000Z","updated":"2021-03-25T16:00:00.000Z","comments":true,"path":"2021/03/26/Ceph_Crimson_Seastore_2021-03-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/26/Ceph_Crimson_Seastore_2021-03-23/","excerpt":"","text":"会议纪要 与会人员 主持人：未提及 参与者：未提及具体人员，但提到了“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“我”、“","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-03-25","slug":"Ceph_Performance_Meeting_2021-03-25","date":"2021-03-25T16:00:00.000Z","updated":"2021-03-26T16:00:00.000Z","comments":true,"path":"2021/03/26/Ceph_Performance_Meeting_2021-03-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/26/Ceph_Performance_Meeting_2021-03-25/","excerpt":"","text":"会议纪要 关键细节 PR更新: 过去两周有两个新的PR更新。 一个涉及将o_node_map从unordered_map改为std::map，这是一个有争议的改动，目前作为RFC（征求意见）进行。 另一个是关于RGW的PR，涉及在RGW压缩后不进行OSD压缩的问题。 已关闭的PR: 过去两周有三个PR被关闭。 其中一个涉及将alien store线程分散到指定的CPU核心。 另一个涉及将bluefs的buffered I/O设置为true，这是一个必要的改动，因为之前禁用buffered I/O导致了一些性能问题。 性能优化: 动态pen length PR已经合并，解决了对齐问题，并显示出性能提升。 Gabby的PR移除了roxdb中的分配，性能改进看起来很好。 OMAP性能问题: 讨论了bluefs的buffered I/O和omap性能问题，特别是关于hash collisions和数据结构的优化。 提出了使用std::map或定制的unordered_map来解决hash collisions问题。 缓存管理: 讨论了缓存管理的问题，特别是关于缓存分裂和锁定机制的复杂性。 提出了简化缓存管理的建议，例如永久性地将节点附加到缓存shard。 主要议题 数据结构优化: 讨论了如何优化数据结构以减少hash collisions，特别是o_node_map的使用。 性能问题: 讨论了buffered I/O和omap性能问题，以及如何通过改进缓存管理和数据结构来解决这些问题。 缓存管理: 讨论了缓存分裂和锁定机制的复杂性，提出了简化缓存管理的建议。 决定事项 PR合并: 动态pen length PR已经合并，解决了对齐问题，并显示出性能提升。 数据结构优化: 决定继续讨论和优化o_node_map的数据结构，可能采用std::map或定制的unordered_map。 缓存管理: 决定继续讨论和简化缓存管理的方案，特别是关于缓存分裂和锁定机制的改进。 后续行动计划 数据结构优化: 继续讨论和实施o_node_map的数据结构优化方案。 性能问题: 继续调查和解决buffered I/O和omap性能问题。 缓存管理: 继续讨论和实施简化缓存管理的方案，特别是关于缓存分裂和锁定机制的改进。 PR审查: 继续审查和合并相关的PR，确保代码质量和性能优化。 备注 会议超时，但未有其他重要事项提出。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2021-03-24","slug":"Ceph_Science_Working_Group_2021-03-24","date":"2021-03-25T16:00:00.000Z","updated":"2021-03-26T16:00:00.000Z","comments":true,"path":"2021/03/26/Ceph_Science_Working_Group_2021-03-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/26/Ceph_Science_Working_Group_2021-03-24/","excerpt":"","text":"会议纪要 会议概述 本次会议是一个非正式的讨论会，参与者主要是使用Ceph分布式存储系统的用户，特别是那些管理大型集群的用户。会议内容包括了Ceph的最新问题、升级计划、性能讨论以及未来发展方向。 主要议题 Ceph MDS问题： 讨论了MDS在重新加入集群时可能消耗大量内存的问题，特别是在使用8GB RAM的MDS时，可能会消耗高达60GB的内存。 提到了在Ceph Octopus版本中可能存在的修复。 Ceph版本升级： 讨论了从Ceph Nautilus升级到Ceph Octopus的计划，以及升级过程中可能遇到的问题。 提到了Ceph Pacific版本的一些新特性和潜在问题，如S3对象消失的问题，但已修复。 Ceph管理与部署： 讨论了使用Cephadm进行集群管理的经验，包括容器化部署的优缺点。 提到了Cephadm在处理大规模集群时的性能问题，以及未来可能的改进方向。 Ceph社区活动： 讨论了即将到来的Ceph Month活动，这是一个替代Cephalocon的线上活动，旨在通过分散的线上会议来减少参会者的疲劳。 讨论了如何组织和选择会议内容，以及如何记录和分享这些讨论。 决定事项 确定了Ceph Month活动的初步计划和形式，包括可能的会议频率和内容选择方式。 讨论了Ceph版本升级的具体计划，包括从Nautilus到Octopus的升级路径和潜在风险。 后续行动计划 继续监控和测试Ceph MDS的性能问题，特别是在高负载情况下的表现。 继续推进Ceph版本的升级计划，特别是从Nautilus到Octopus的升级。 准备Ceph Month活动的具体安排，包括会议内容的征集和筛选。 其他讨论点 讨论了Ceph在不同操作系统和环境下的兼容性和性能问题，特别是与Python版本相关的编译问题。 讨论了Ceph在不同使用场景下的最佳实践，包括文件系统的快照管理和Erasure Coding的使用。 会议最后，主持人感谢所有参与者的积极参与，并预告了下一次会议的时间。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2021-03-23","slug":"Ceph_Orchestrator_Meeting_2021-03-23","date":"2021-03-22T16:00:00.000Z","updated":"2021-03-23T16:00:00.000Z","comments":true,"path":"2021/03/23/Ceph_Orchestrator_Meeting_2021-03-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/23/Ceph_Orchestrator_Meeting_2021-03-23/","excerpt":"","text":"会议纪要 主要议题与讨论内容 OC服务拉取请求（Pull Request） 讨论了关于OC服务的拉取请求，决定将所有非托管的OSD（Object Storage Daemon）钻石整合到一个OS服务中。 决定在尝试删除该服务时，显示消息提示用户需要先删除相关的OSD。 讨论了OSD.unmanaged的命名问题，认为这是一个合适的名称。 卷设置（Set Volume）的容器版本问题 讨论了关于卷设置时使用与管理器相同容器版本的问题，询问了Sebastian关于该拉取请求的状态。 确认该拉取请求尚未合并，但认为当前的实现方式是可行的。 HA RGW服务的设计问题 讨论了HA RGW服务的设计，特别是HAProxy和Keepalived部分是否应该分开成两个独立的服务。 提出了将HAProxy和Keepalived分开成两个服务的建议，以便更灵活地使用它们。 讨论了服务的配置和密码管理问题，建议自动生成密码并存储在配置文件中。 OSD内存自动配置 提到了OSD内存自动配置的问题，但目前该议题被暂时搁置。 Rook Orchestrator的状态 讨论了Rook Orchestrator的状态，确认其基本功能可用，但需要进一步的测试和功能完善。 决定事项 将所有非托管的OSD钻石整合到一个OS服务中，并在删除服务时提示用户先删除相关OSD。 考虑将HA RGW服务中的HAProxy和Keepalived分开成两个独立的服务。 自动生成密码并存储在配置文件中，以简化用户配置。 后续行动计划 继续跟进OC服务的拉取请求，确保其顺利合并。 对HA RGW服务进行重构，将其分为HAProxy和Keepalived两个独立的服务。 测试和完善Rook Orchestrator的功能，确保其稳定性和可用性。 关注OSD内存自动配置的问题，适时重启相关工作。 其他事项 确认了Pacific版本的预期发布日期，并讨论了与OpenStack Wallaby版本的集成问题。 感谢OpenStack团队的支持，并讨论了未来可能的合作方向。 会议结束 会议在确认所有议题讨论完毕后结束，感谢所有参与者的贡献，并祝愿大家工作顺利。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore 2021-03-17","slug":"Ceph_Crimson_SeaStore_2021-03-17","date":"2021-03-17T16:00:00.000Z","updated":"2021-03-17T16:00:00.000Z","comments":true,"path":"2021/03/18/Ceph_Crimson_SeaStore_2021-03-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/18/Ceph_Crimson_SeaStore_2021-03-17/","excerpt":"","text":"会议纪要 主要议题与讨论内容 性能优化与代码重构 PR2审查：上周对PR2进行了审查，旨在改进Illinois存储的性能。 客户端请求序列化器单元测试：继续进行客户端请求序列化器的单元测试，特别是异常情况的处理。 智能指针使用问题：在Crimson中，发现使用intrusive_ptr发送消息而不是unique_ptr的问题。讨论了是否可以通过移动语义来避免使用智能指针，最终决定使用unique_ptr作为更安全的解决方案。 代码修改与测试 GC修改与测试：Sam的补丁在应用后，不同配置下的测试出现了多种问题。等待Sam完成GC的修改后重新进行测试。 消息传递接口：讨论了在不同核心间传递消息时，是否应使用foreign pointer作为接口，以及如何定义这一接口。 功能开发与代码理解 Ceph存储源码理解：正在阅读Ceph存储的源码，并尝试理解其详细设计。 未来存储API实现：注意到Ceph存储中某些未来存储API尚未实现，考虑是否可以进行相关工作。 测试结果与问题 恢复与回填修复：Shahan的补丁已合并，修复了恢复和回填问题。希望在下一次常规测试中能看到所有测试通过。 节点管理器单元测试：实现了节点管理器级别的单元测试，并进行了一些修复，目前正在审查中。 决定事项 智能指针使用：决定在消息传递中使用unique_ptr以提高安全性。 GC修改与测试：等待Sam完成GC的修改后重新进行测试。 消息传递接口：需要进一步讨论和定义在不同核心间传递消息的接口。 后续行动计划 继续进行单元测试：完成客户端请求序列化器的单元测试。 重新测试GC：在Sam完成GC修改后，重新进行测试。 讨论消息传递接口：安排离线会议，进一步讨论和定义消息传递接口。 实现未来存储API：评估并开始实现Ceph存储中尚未实现的未来存储API。 其他 测试结果更新：关注并更新恢复与回填修复后的测试结果。 代码理解与学习：继续深入理解Ceph存储的源码和设计。 结束语 会议结束，感谢大家的参与和讨论，期待后续的进展和成果。祝大家工作顺利！","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2021-03-11","slug":"Ceph_Performance_Meeting_2021-03-11","date":"2021-03-17T16:00:00.000Z","updated":"2021-03-17T16:00:00.000Z","comments":true,"path":"2021/03/18/Ceph_Performance_Meeting_2021-03-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/18/Ceph_Performance_Meeting_2021-03-11/","excerpt":"","text":"会议纪要 主要议题 OMAP性能基准测试 会议开始时，讨论了两个新的Pull Request (PR)。第一个PR是由会议主持人提出的，旨在为对象存储测试套件实现一个快速且简单的OMAP基准测试。该测试基于现有的简单OMAP测试，增加了写入多个对象和大量键的能力，并进行时间测试。 第二个PR来自Gabby，目的是从RocksDB中移除分配。Josh和Igor已经进行了审查，并提出了一些改进建议。 其他PR更新 讨论了其他几个PR，包括Shuhan提交的PR，该PR涉及将Alien存储线程分散到不同的CPU核心，以及Adam的PR，用于区分BlueFS中的Buffered和Direct IO。 还讨论了Seth的PR，该PR涉及并发检索设备数据，目前仍在讨论和改进中。 BlueStore性能问题 会议中详细讨论了BlueStore的性能问题，特别是在OMAP迭代和RocksDB代码路径方面。讨论了可能的性能瓶颈，如块缓存争用和RocksDB的迭代性能。 提出了一些理论，如内存使用情况可能影响性能，特别是BlueStore和FileStore之间的差异。 后续行动计划 会议主持人计划继续深入研究BlueStore的性能问题，特别是理解RocksDB代码和块缓存的使用情况。 鼓励团队成员查看基准测试代码，并提供反馈和改进建议。 决定事项 确认了继续深入研究BlueStore性能问题的必要性，特别是OMAP性能和RocksDB的使用。 确定了需要进一步讨论和改进的PR，包括Gabby和Shuhan的PR。 后续行动 会议主持人将继续工作于OMAP性能基准测试，并分享进展。 团队成员被鼓励查看和评论相关的PR，以帮助改进和优化。 其他讨论 讨论了FileStore和BlueStore在内存使用和性能方面的差异，以及可能的解释和解决方案。 提到了RocksDB的块缓存和迭代性能，以及可能的改进方向。 结论 会议结束时，主持人感谢大家的参与，并提醒大家下周再见。会议强调了持续关注和改进Ceph存储系统的性能问题的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Teuthology Internals: Overview and Scheduling","slug":"Teuthology_Internals_-_Overview_and_Scheduling","date":"2021-03-15T16:00:00.000Z","updated":"2021-03-15T16:00:00.000Z","comments":true,"path":"2021/03/16/Teuthology_Internals_-_Overview_and_Scheduling/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/16/Teuthology_Internals_-_Overview_and_Scheduling/","excerpt":"","text":"会议纪要 会议主题：Topology Code 的内部结构与调度机制 参会人员：Topology Code 开发团队及相关人员 会议时间：[具体日期] 会议地点：[具体地点] 会议内容总结： Topology Code 概述 讨论了 Topology Code 的整体结构，包括其由多个子命令组成，主要命令为 topology，负责运行测试和任务。 介绍了 topology 命令行工具的实现，使用 Python 模块 docopt 进行参数解析。 强调了代码主要位于 scripts 目录下，每个脚本文件包含一个简单的 main 函数，调用 docopt 解析选项并执行主函数。 远程机器交互 讨论了通过 orchestra 模块与远程机器交互的概念，包括连接管理、远程节点表示和集群执行命令。 介绍了 orchestra 模块中的 connection、remote 和 cluster 概念，以及如何通过 context 变量在程序中全局访问这些对象。 调度机制改进 介绍了近期对调度机制的改进，特别是由 Google Summer of Code 学生实现的新的调度方式。 详细解释了新的调度流程，包括使用 Beanstalkd 作为优先队列，Topology Dispatcher 负责从队列中取出作业并运行。 强调了新机制如何解决旧机制中的优先级反转问题，确保作业按优先级顺序严格执行。 后续行动计划 确认了未来将继续进行类似的会议，深入探讨 Topology Code 的其他方面。 提醒团队成员可以运行 tox 来执行单元测试和代码风格检查，以确保代码质量。 决定事项： 确认了新的调度机制的有效性，并将继续监控其性能。 计划未来会议将涵盖更多关于 Topology Code 的细节，包括实际运行机制。 后续行动： 团队成员应继续关注调度机制的运行情况，并准备参与未来的技术讨论。 开发人员应定期运行 tox 以确保代码质量和一致性。 会议结束语： 感谢所有参会人员的参与，并期待在未来的会议中继续深入探讨 Topology Code 的技术细节。 会议记录人：[记录人姓名] 会议结束时间：[具体时间] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Teuthology Training: Analyzing Test Results","slug":"Teuthology_Training_-_Analyzing_Test_Results","date":"2021-03-15T16:00:00.000Z","updated":"2021-03-15T16:00:00.000Z","comments":true,"path":"2021/03/16/Teuthology_Training_-_Analyzing_Test_Results/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/16/Teuthology_Training_-_Analyzing_Test_Results/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于病理学培训的第二部分，重点讨论病理学失败分析，特别是测试运行后的处理方法。会议强调了开发者在使用病理学（Pathology）进行测试时需要理解测试结果的意义，包括测试通过或失败的情况。 主要议题 基本指导原则： 每个失败都需要被审查。 区分失败和死亡任务（dead jobs），死亡任务是指未能在规定时间内正确终止的任务。 工具和资源： Sentry：用于收集和展示类似失败的工具，帮助分析历史失败事件。 Scrape.log：在每次运行结束时运行的脚本，用于汇总和分类失败，便于分析。 Redmine Tracker：用于记录和跟踪失败的工具，帮助后续分析和避免重复工作。 分析步骤： 使用Palpito和Sentry进行初步分析。 详细分析每个失败或死亡任务，需要访问病理学日志（Pathology log）。 利用Scrape.log进行进一步的失败分类和分析。 检查是否有相关的Redmine Tracker问题，必要时创建新的跟踪问题。 特定情况分析： 针对不同类型的运行（如whip branch、baseline run、developer centric run），分析方法和重点有所不同。 强调在发现新问题时，需要进一步验证并与现有问题进行对比。 决定事项 确认了使用Sentry、Scrape.log和Redmine Tracker等工具的重要性，以及它们在病理学失败分析中的应用。 确定了针对不同类型病理学运行的分析策略和步骤。 后续行动计划 开发者需要继续使用和熟悉上述工具和资源，以便更有效地进行病理学失败分析。 对于Sentry等工具的改进需求，应记录并考虑在未来的会议中讨论。 鼓励开发者在分析过程中遇到问题时，及时通过IRC、邮件等方式寻求帮助和讨论。 其他 会议中提到的具体技术细节和示例，如特定错误消息和日志分析方法，将在后续的培训和文档中进一步详细说明。 本次会议为病理学失败分析提供了详细的指导和工具介绍，旨在帮助开发者更有效地处理和分析测试中的失败情况。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Teuthology Training: Developing Tests","slug":"Teuthology_Training_-_Developing_Tests","date":"2021-03-15T16:00:00.000Z","updated":"2021-03-15T16:00:00.000Z","comments":true,"path":"2021/03/16/Teuthology_Training_-_Developing_Tests/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/16/Teuthology_Training_-_Developing_Tests/","excerpt":"","text":"会议纪要 会议主题：Ceph测试开发培训 会议时间：2023年某月某日 参会人员：Ceph研发团队成员 会议内容总结： 测试类型介绍： 讨论了不同类型的测试，包括单元测试、集成测试和升级测试等。 强调了单元测试的重要性，因其执行速度快，反馈迅速。 详细介绍了集成测试的编写方式，特别是使用脚本（如Bash和Python）对Ceph集群进行测试。 集成测试的编写与执行： 介绍了如何编写集成测试脚本，这些脚本通常存放在Ceph仓库的特定目录下。 讨论了如何在本地v-start环境或Toothology环境中运行这些脚本。 提到了使用Toothology时，系统会自动克隆指定版本的仓库并运行脚本，确保测试的一致性和正确性。 测试脚本示例： 展示了一个典型的集成测试脚本，该脚本使用Bash编写，通过设置set -e和set -x来确保脚本在命令失败时退出，并记录执行过程以便调试。 讨论了如何在Toothology中运行这些脚本，并如何处理输出和日志。 升级测试的详细介绍： 详细讲解了升级测试的结构和执行流程，包括如何配置集群、运行工作负载以及如何在升级过程中保持集群的稳定性。 讨论了如何在升级过程中运行并行任务，以及如何处理集群的部分升级状态。 其他测试类型： 简要介绍了其他测试类型，如独立测试框架和故障注入测试，这些测试用于更深入地测试集群的特定行为和稳定性。 Toothology任务的编写与使用： 讨论了如何在Toothology中编写和使用任务，包括如何定义任务、配置任务以及如何在测试套件中使用这些任务。 强调了文档的重要性，建议通过查看实际的测试套件和任务实现来学习如何编写和使用任务。 后续行动计划： 继续下一期的培训，深入讨论如何在开发测试时运行Toothology，以及如何编写新的测试和任务。 鼓励团队成员在会议后提出任何疑问或需要进一步解释的内容。 会议结束： 感谢所有参与者的参与，并鼓励大家在后续的工作中积极应用所学知识。 以上是本次Ceph测试开发培训会议的详细纪要，涵盖了会议的主要议题、讨论内容、决定事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Teuthology Training: Introduction","slug":"Teuthology_Training_-_Introduction","date":"2021-03-15T16:00:00.000Z","updated":"2021-03-15T16:00:00.000Z","comments":true,"path":"2021/03/16/Teuthology_Training_-_Introduction/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/16/Teuthology_Training_-_Introduction/","excerpt":"","text":"会议纪要 会议概述 会议主题为“IDEA技术培训系列”，由Greg主持，旨在介绍Ceph测试框架Toothology的使用和相关测试流程。会议强调了互动性，鼓励与会者在任何时候提出问题。 主要议题 Toothology框架介绍 Toothology是一个用于测试Ceph的分布式系统测试框架，已有10年历史。 该框架解决了早期Ceph测试中缺乏系统化测试工具的问题。 Toothology基于Python编写，使用Orchestra模块进行远程机器的SSH操作。 测试流程 测试任务通过YAML文件定义，包括目标节点、角色分配和任务执行。 任务包括启动Ceph集群、挂载客户端、执行工作单元等。 测试结果包括日志文件、配置文件和测试总结。 测试套件和子套件 测试套件由多个YAML片段组成，可以灵活组合以覆盖不同测试场景。 使用子套件和特定选项可以减少测试组合的数量，提高测试效率。 实际操作和结果分析 通过Toothology Suite命令行工具运行测试套件。 测试结果存储在特定的目录中，包括日志和总结文件。 分析测试结果时，可以通过日志文件和总结文件定位问题。 其他测试工具 除了Toothology，还有其他测试工具如CBT（Ceph Benchmark Tool）用于性能测试。 单元测试可以通过make check命令本地运行。 决定事项 确认了Toothology框架的重要性和其在Ceph测试中的核心作用。 讨论了如何通过子套件和特定选项优化测试流程，减少测试组合的数量。 后续行动计划 继续使用和优化Toothology框架，确保Ceph的稳定性和可靠性。 探索和改进代码覆盖率工具，以更好地指导测试工作。 定期回顾和更新测试套件，确保覆盖所有关键功能和场景。 其他讨论 讨论了如何处理特定的测试失败和如何重新运行特定测试。 确认了使用GitHub标签和Jenkins服务器进行持续集成和测试的重要性。 会议结束 会议在感谢与会者的参与和讨论后结束，并预告了下一次会议将讨论如何分析测试结果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthroughs: Librbd Part 2","slug":"Ceph_Code_Walkthroughs_-_Librbd_Part_2","date":"2021-03-09T16:00:00.000Z","updated":"2021-03-09T16:00:00.000Z","comments":true,"path":"2021/03/10/Ceph_Code_Walkthroughs_-_Librbd_Part_2/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/10/Ceph_Code_Walkthroughs_-_Librbd_Part_2/","excerpt":"","text":"会议纪要 会议概述 会议日期：2月23日 会议主题：Ceph RBD（Live RBD）代码走读第二部分 主讲人：Jason 参会人员：Ceph社区成员 主要议题 RBD I/O路径概述 I/O请求处理流程：从API层开始，经过多个可插拔层（如QoS、独占锁、刷新状态机等），最终到达核心层处理对象请求。 librbd.cc文件：作为C和C++ API的入口点，负责将I/O请求重定向到librbd内部更深层次的处理。 I/O请求详细流程 API层：在api/io.cc文件中，读写方法通过图像分发规范（Image Dispatch Spec）描述I/O请求。 分发层：I/O请求通过多个分发层，每个层可以对I/O进行不同的处理（如排队、QoS控制、独占锁检查等）。 核心层：将图像范围（Image Extent）转换为对象范围（Object Extent），因为RBD设备由多个对象组成。 对象请求状态机 读请求：从OSD读取数据，如果对象不存在，则从父图像读取数据。 写请求：包括写、丢弃、写相同、比较写等操作，涉及对象映射（Object Map）的预更新和后更新。 复制上状态机：从父图像复制数据到子图像，支持实时迁移（Live Migration）。 可插拔层（Pluggable Layers） 分发层的作用：每个层可以对I/O请求进行不同的处理，如QoS控制、独占锁检查等。 分发层的实现：通过模板化的分发器（Dispatcher）和访问者模式（Visitor Pattern）实现。 总结与展望 I/O路径的复杂性：通过状态机和分发层处理I/O请求，确保数据的一致性和性能。 未来工作：继续优化和扩展librbd的功能，如加密层（Crypto Layer）和实时迁移（Live Migration）。 决定事项 继续优化librbd的I/O路径，确保高性能和数据一致性。 探索更多可插拔层的功能，以支持新的特性和优化。 后续行动计划 继续进行代码走读和优化工作，特别是在实时迁移和加密层方面。 社区成员可以通过邮件列表和IRC进行交流和反馈。 会议结束 感谢Jason的详细讲解，会议内容将被记录并上传至Ceph YouTube频道。期待下次的代码走读会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStore  2021-03-10","slug":"Ceph_Crimson_SeaStore_2021-03-10","date":"2021-03-09T16:00:00.000Z","updated":"2021-03-09T16:00:00.000Z","comments":true,"path":"2021/03/10/Ceph_Crimson_SeaStore_2021-03-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/10/Ceph_Crimson_SeaStore_2021-03-10/","excerpt":"","text":"会议纪要 关键细节 上周工作回顾： 进行了一些清理工作，并继续处理客户端请求序列化测试。 与Shihan和Redec讨论了启动工作。 通过启动任务队列和线程（by pjid）改进了Alien Store性能，目前仍在审查第二部分PR。 调试了NPD的段错误报告，发现是由垃圾收集引起的RB树混乱，已找到Sum已修复的相关bug。 开发了一种方法来重现Chutney观察到的行为，发现LBA管理器的下界或查找实现中的小bug，并修复了垃圾收集器使用日志游标的方式。 测试了PG流水线并行性PR，修复了几个相关bug，并阅读了关于Sistor的源代码和文档。 解决了Honor 3中的问题，并支持了存储中的多设备。 本周计划： 继续测试PG流水线并行性PR，并阅读Sistor相关文档。 增加对TL管理器的单元测试，特别是对Ethel Tree Node Manager接口的全面支持。 修改单元测试以支持两种后端运行，以更好地理解问题所在。 讨论的主要议题 单元测试的改进： 讨论了增加单元测试的必要性，特别是对Ethel Tree Node Manager接口的全面测试。 讨论了如何修改单元测试以支持两种后端运行，以确保测试的全面性和可靠性。 垃圾收集器和段错误问题： 讨论了垃圾收集器引起的问题，以及如何通过增加单元测试来避免类似问题。 讨论了段错误问题的根本原因，并提出了增加超时机制的解决方案。 决定的事项 增加单元测试： 决定增加对TL管理器和Ethel Tree Node Manager接口的单元测试，以确保代码的稳定性和可靠性。 决定修改单元测试以支持两种后端运行，以更好地理解问题所在。 增加超时机制： 决定在脚本中增加超时机制，以防止单元测试无限期运行。 后续行动计划 实施单元测试改进： 增加对TL管理器和Ethel Tree Node Manager接口的单元测试。 修改单元测试以支持两种后端运行。 增加超时机制： 在脚本中增加超时机制，以防止单元测试无限期运行。 继续调试和修复问题： 继续调试NPD的段错误问题，并修复垃圾收集器引起的问题。 继续测试PG流水线并行性PR，并阅读Sistor相关文档。 其他事项 讨论了Ethel Tree代码的复杂性，并提出了增加单元测试的必要性。 讨论了垃圾收集器和段错误问题的根本原因，并提出了增加超时机制的解决方案。 结束语 会议结束时，所有决定的事项和后续行动计划都已明确，团队成员将继续推进各自的工作，并确保代码的稳定性和可靠性。感谢所有参与者的贡献，期待下次会议的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2021-02-03","slug":"Ceph_Developer_Monthly_2021-02-03","date":"2021-03-08T16:00:00.000Z","updated":"2021-03-09T16:00:00.000Z","comments":true,"path":"2021/03/09/Ceph_Developer_Monthly_2021-02-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/09/Ceph_Developer_Monthly_2021-02-03/","excerpt":"","text":"会议纪要 会议主题：Ceph 镜像指标与跨服务共享 讨论内容： - 目标与挑战： 在 Kubernetes 环境中，如何实现一致的告警机制，特别是针对 RGW 多站点或 Ceph 镜像等场景。 - 实现思路： 讨论了如何跟踪和分类 SLA（服务级别协议），以及如何在工程上实现这些 SLA 的报告和度量，以便于构建 Grafana 仪表板进行监控。 - 技术细节： 探讨了在 Ceph Manager 中暴露这些指标的可能性，并讨论了 Prometheus 作为数据消费方的可行性。同时，讨论了当前 Ceph 镜像守护进程（demons）如何报告状态，以及如何改进这些报告以更好地支持告警和监控。 决定事项： - 需要进一步研究 RBD 镜像和 RGW 当前报告的数据结构和逻辑，以确定是否可以标准化这些报告。 - 考虑在每个守护进程中集成 Prometheus 导出器，以便直接从守护进程收集指标。 后续行动计划： - 指定人员进行深入研究，包括分析现有数据报告和探索集成 Prometheus 导出器的可行性。 - 在社区中发起讨论，收集用户和开发者的反馈，以确定最佳实施方案。 会议主题：满载集群中的删除操作处理 讨论内容： - 问题描述： 当集群满载时，Ceph 会阻止写操作，但删除操作可能仍然受限，特别是在 Ceph Manager 模块中。 - 技术挑战： 讨论了如何在不增加集群负担的情况下，确保删除操作能够顺利进行，特别是在 Manager 模块中。 决定事项： - 需要进一步研究 Manager 模块中的删除操作逻辑，以及如何改进这些操作以避免集群满载时的阻塞问题。 - 考虑引入更多的后台工作线程或改进现有的线程池管理，以提高 Manager 的并发处理能力。 后续行动计划： - 进行性能测试，以确定 Manager 模块的并发处理能力和资源需求。 - 在社区中讨论并确定改进 Manager 模块并发处理的最佳实践。 会议主题：消息传递中的传输压缩 讨论内容： - 技术提案： 讨论了在 Ceph 消息传递层（Messenger）中添加传输压缩的可能性，特别是针对 OSD 之间的通信。 - 潜在问题： 讨论了在消息传递层进行压缩可能带来的性能开销，以及是否应该针对特定类型的消息或数据负载进行优化。 决定事项： - 需要在社区中进行更广泛的讨论，以确定最佳的压缩实施位置和方式。 - 考虑在数据负载层进行压缩，而不是在整个消息层，以减少不必要的重复压缩和解压缩操作。 后续行动计划： - 在社区邮件列表中发起讨论，收集关于传输压缩实施的意见和建议。 - 根据反馈和进一步的技术评估，确定最终的实施方案。 会议总结 本次会议主要讨论了 Ceph 存储系统中的多个关键技术问题，包括镜像指标的共享、满载集群中的删除操作处理，以及消息传递中的传输压缩。会议决定了一系列后续行动计划，以推动这些问题的解决和优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"What's New in Pacific Ceph Release - Sage Weil","slug":"What_s_New_in_Pacific_Ceph_Release_-_Sage_Weil","date":"2021-03-08T16:00:00.000Z","updated":"2021-03-09T16:00:00.000Z","comments":true,"path":"2021/03/09/What_s_New_in_Pacific_Ceph_Release_-_Sage_Weil/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/03/09/What_s_New_in_Pacific_Ceph_Release_-_Sage_Weil/","excerpt":"","text":"会议纪要 会议主题： Ceph最新版本Pacific的功能更新与计划 会议时间： 近期 会议地点： 线上会议 参会人员： Ceph社区成员、研发人员、用户 会议内容总结： Ceph概述： Ceph是软件定义的统一存储系统，支持对象、块和文件存储。 基于开源软件，运行在标准硬件上，避免供应商锁定，支持扩展和创新。 设计强调可靠性和数据耐久性，通过复制和纠删码保护数据。 Pacific版本更新： 发布时间： 预计在三月份发布，几周内即将推出。 主要更新： 可用性提升： 改进了Cephadm工具，支持自动化升级和私有注册表认证。 稳定性增强： 改进了PG删除、OSD映射修剪和网络协议安全性。 性能优化： 引入了新的分配器和内存跟踪机制，改进了QoS和分布式跟踪框架。 新功能： 支持多文件系统、异步链接操作、RGW的S3选择和Lua脚本集成。 后续行动计划： 文档和网站更新： 持续改进文档，进行网站 redesign 项目。 社区和生态系统： 支持arm64架构，改进与Rook、CSI等集成。 未来版本规划： 即将开始的Quincy版本规划，计划在2022年3月发布。 社区互动： 计划举办虚拟活动，包括开发者峰会和面向用户的在线讨论会，以促进社区交流和反馈收集。 会议结束： - 会议结束时，鼓励社区成员参与调查和开启集群的遥测功能，以便更好地了解用户需求和改进方向。 备注： - 会议中提到的具体技术细节和功能更新，建议参考Ceph官方文档和社区更新以获取最新信息。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson 2021-02-23","slug":"Ceph_Crimson_2021-02-23","date":"2021-02-25T16:00:00.000Z","updated":"2021-02-25T16:00:00.000Z","comments":true,"path":"2021/02/26/Ceph_Crimson_2021-02-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/02/26/Ceph_Crimson_2021-02-23/","excerpt":"","text":"会议纪要 关键细节 参会人员: 包括Sherhan在内的团队成员。 时间: 最近一周。 主要议题: 讨论了客户端请求序列器（client request sequencer）的优化、单元测试的添加、3D课堂项目的构建问题、以及Ceph存储系统中的并发优化。 讨论的主要议题 客户端请求序列器优化: Sherhan和团队成员正在优化客户端请求序列器，并尝试添加单元测试。 讨论了在不同构建环境下的性能差异，特别是发布构建（release build）和调试构建（debug build）的性能对比。 3D课堂项目: 项目在调试构建中工作正常，但在发布构建中出现崩溃。 讨论了硬件性能对构建的影响，特别是SSD和NVMe硬盘的读取速度问题。 Ceph存储系统并发优化: 讨论了如何在Ceph存储系统中优化并发处理，特别是在crimson osd中的并发请求管道。 强调了客户端请求在底层磁盘上的持久化顺序的重要性，以及如何在Ceph的不同存储实现中保证这一顺序。 决定的事项 发布构建崩溃问题: 决定暂时不深入调试，因为代码仍在频繁变动中。 建议通过添加更多的断言（asserts）或日志输出（logger dot error）来帮助定位问题。 并发优化: 确认了在Ceph存储系统中，客户端请求的持久化顺序必须与它们到达OSD的顺序一致。 讨论了在alien store中如何保证这一顺序，建议通过哈希集合（hash the collection）到线程集合（set of threads）的方式来保证顺序。 后续行动计划 发布构建崩溃问题: 继续监控和收集更多日志信息，以便更好地理解崩溃原因。 在代码稳定后，重新考虑深入调试。 并发优化: 在alien store中实施保证客户端请求顺序的机制。 探索Ceph中是否已有类似的并发处理工具或库，以便更高效地实现并发优化。 其他讨论 讨论了硬件性能对软件构建的影响，特别是SSD和NVMe硬盘的读取速度问题。 确认了在Ceph存储系统中，多个PG（Placement Groups）的使用是为了实现并行处理，而不是在单个PG内实现并行。 结论 会议强调了在Ceph存储系统中保证客户端请求顺序的重要性，并讨论了如何在不同构建环境和硬件条件下优化性能。后续行动计划包括继续监控和调试发布构建的崩溃问题，以及在alien store中实施并发优化措施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2021-01-26","slug":"Ceph_Crimson_SeaStor_OSD_2021-01-26","date":"2021-01-26T16:00:00.000Z","updated":"2021-01-26T16:00:00.000Z","comments":true,"path":"2021/01/27/Ceph_Crimson_SeaStor_OSD_2021-01-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2021/01/27/Ceph_Crimson_SeaStor_OSD_2021-01-26/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [参会人员名单] 会议主持： [主持人姓名] 会议内容： 上周工作回顾： Ceph相关工作： 修复了Ceph管理工具（ceph-adm）中的问题，该问题被认为是Pacific版本发布的阻塞点。 重新审视了流水线文档，并根据Sam的评论进行了修改。 提供了Collection Manager的代码，以便审查和研究流水线设计文档。 其他工作： 进行了3DS培训和性能测试工作，特别是针对Ceph的OSD（Object Storage Daemon）进行性能测试。 本周工作计划： 继续完成Sam的pian和Evernote提供的代码的审查。 专注于性能测试和3DS培训。 代码更新与问题讨论： 替换了biosequential代码到master分支，并实施了针对非幂等客户端请求重复问题的修复。 发现master分支的恢复代码存在一些bug，正在尝试调试以验证修复是否有效。 讨论了关于master分支的bug问题，可能与某些恢复优化有关，但尚未找到根本原因。 其他讨论： 确认了将继续处理关于no value实现的大部分代码审查。 讨论了关于memphis问题的最后评论，并计划添加初始化接口。 决定事项： - 继续进行性能测试和3DS培训。 - 继续调试master分支的恢复代码bug，并寻找根本原因。 - 添加初始化接口以解决memphis问题。 后续行动计划： - 完成Sam的pian和Evernote提供的代码的审查。 - 确认修复是否有效并解决master分支的bug问题。 - 完成no value实现的代码审查和初始化接口的添加。 会议结束： - 会议于[具体时间]结束，感谢大家的参与。 备注： - 如有任何问题或需要进一步讨论的事项，请及时通知相关人员。 会议记录人： [记录人姓名] 会议审核： [审核人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User Survey Working Group 2020-11-25","slug":"Ceph_User_Survey_Working_Group_2020-11-25","date":"2020-11-25T16:00:00.000Z","updated":"2020-11-25T16:00:00.000Z","comments":true,"path":"2020/11/26/Ceph_User_Survey_Working_Group_2020-11-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/26/Ceph_User_Survey_Working_Group_2020-11-25/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph用户调查问卷的修订和更新。会议参与者包括多位Ceph研发人员和社区成员，共同审查和修改问卷内容，以确保问卷的有效性和实用性。 主要议题 问卷结构和内容审查： 讨论了问卷的各个部分，包括问题的新增、删除和修改。 特别关注了问卷的逻辑性和用户友好性，确保问题不会过于复杂或重复。 技术细节讨论： 讨论了Ceph集群的角色和组件状态的表述方式。 讨论了RGW（RADOS Gateway）的使用案例和相关技术问题。 用户反馈和社区参与： 讨论了如何更好地收集和整合社区成员的反馈。 讨论了如何通过邮件列表和社交媒体推广问卷。 决定事项 问卷修订： 决定对问卷进行多处修改，包括删除不必要的问题、简化复杂问题和增加新的问题。 特别关注了RGW相关问题的修订，以更好地反映用户的使用情况。 社区反馈： 决定通过邮件列表和社交媒体进一步收集社区成员的反馈。 决定在问卷发布前，再次生成PDF版本供社区审查。 后续行动计划 问卷最终修订： 继续根据社区反馈调整问卷内容。 确保所有修改在问卷发布前完成。 问卷发布和推广： 通过邮件列表和社交媒体发布问卷。 监控问卷的填写情况，并根据反馈进行必要的调整。 技术支持和社区参与： 确保社区成员能够顺利访问和填写问卷。 继续鼓励社区成员参与问卷的讨论和反馈。 备注 会议中提到的技术细节和具体问题，如RGW的使用案例和Ceph集群的角色，需要进一步的技术文档支持。 社区成员的积极参与和反馈对于问卷的成功至关重要。 本次会议的讨论和决策将有助于提高Ceph用户调查问卷的质量，更好地服务于Ceph社区和用户。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2020-11-25","slug":"Ceph_Science_Working_Group_2020-11-25","date":"2020-11-24T16:00:00.000Z","updated":"2020-11-25T16:00:00.000Z","comments":true,"path":"2020/11/25/Ceph_Science_Working_Group_2020-11-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/25/Ceph_Science_Working_Group_2020-11-25/","excerpt":"","text":"会议纪要 会议概述 本次会议是一个关于研究计算和Ceph存储系统的成员会议，与会者讨论了近期遇到的问题、技术挑战以及解决方案。会议持续了大约半小时到一个小时，讨论内容较为自由，涉及多个主题。 主要议题 Ceph集群中的问题 讨论了在替换S3集群硬件时遇到的问题，特别是PG（Placement Group）迁移和删除的效率问题。 提到了在Nautilus版本中，需要重新启用BlueFS Buffered IO来稳定集群。 讨论了PG删除过程中的低效率问题，以及Igor正在准备的补丁可能解决这一问题。 Ceph版本更新和升级 讨论了从旧版本升级到Octopus版本的体验，特别是内存泄漏和稳定性问题。 提到了在升级过程中遇到的Beast协议相关的问题，以及对Rados Gateway内存使用的讨论。 Ceph性能和配置 讨论了多MDS（Multi-Master Metadata Server）的使用情况和性能问题。 提到了BlueStore的配置和性能优化，特别是关于BlueFS和BlueStore allocator的改进。 Ceph集群管理和运维 讨论了如何限制Rados Gateway的内存使用，以及在网络架构中使用Rados Gateway的策略。 提到了从直接使用Librados转向使用Rados Gateway的可能性，以及相关的网络升级。 决定事项 需要关注Igor关于PG删除的补丁，以及BlueFS Buffered IO的启用情况。 需要进一步测试和验证Beast协议的问题，并考虑是否需要回退到CivetWeb。 需要继续监控和优化Rados Gateway的内存使用，特别是在高并发IO情况下的表现。 后续行动计划 继续关注Ceph的版本更新和补丁发布，特别是与内存管理和性能优化相关的更新。 计划在下一个版本中测试和部署新的BlueStore配置和优化。 继续监控和调整Rados Gateway的配置，以确保在高负载下的稳定性和性能。 其他讨论 讨论了使用InfiniBand网络的可能性，但目前认为以太网已经足够满足需求。 提到了备份大型Ceph集群的挑战，特别是对于运行Oracle数据库的集群。 会议结束 会议在讨论了未来可能的技术升级和优化方向后结束，下一次会议计划在明年一月的第四个星期三举行。会议组织者感谢大家的参与，并提醒大家注意假期安全。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-11-11","slug":"Ceph_Crimson_SeaStor_OSD_2020-11-11","date":"2020-11-23T16:00:00.000Z","updated":"2020-11-23T16:00:00.000Z","comments":true,"path":"2020/11/24/Ceph_Crimson_SeaStor_OSD_2020-11-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/24/Ceph_Crimson_SeaStor_OSD_2020-11-11/","excerpt":"","text":"会议纪要 关键细节 日期: 不详 参与者: 不详 主要议题: 讨论了Ceph项目的多个方面，包括代码重构、性能优化、并发处理、文档更新等。 讨论的主要议题 代码重构与优化 重构对象上下文锁定（object context locking），使用GridLock，并提供了一个草稿PR供初步审查。 对omap3的补丁进行了更新，并计划进一步优化。 完成了对经典scrubbing的评论回复，并创建了一个squashed分支准备合并。 对crimson的interruptable库进行了审查，并发布了审查意见。 性能与并发处理 讨论了如何通过改进并发处理来提高性能，特别是在处理多个并发I/O请求时。 引入了基于UUID的nonce来改进journal的段管理，以确保在重用段时的正确性。 实施了journal中的校验和（checksum）以增强原子性，并优化了段滚动机制以减少校验和计算的开销。 文档与计划 更新了关于多层设备系统的文档，重点关注原子保证和架构变化。 讨论了事务管理器的计划，该管理器将支持持久内存和基于块的opt-in。 决定的事项 确认了多个PR的合并计划，并对代码进行了初步审查。 确定了改进并发处理和性能优化的具体步骤。 确认了文档更新的计划，并指定了相关人员进行后续工作。 后续行动计划 继续进行代码重构和优化工作，特别是关于并发处理和性能提升的部分。 完成并合并相关的PR，确保代码的质量和稳定性。 继续更新和完善文档，确保所有变更和优化都有详细的记录和说明。 备注 会议中提到了多个技术细节和具体实现，如GridLock、UUID nonce、checksumming、transaction manager等，这些关键词体现了会议的专业性和技术深度。 会议参与者对各自负责的部分进行了详细的汇报和讨论，确保了项目的顺利进行和团队成员之间的有效沟通。 结束语 会议在确认了各项任务的进展和后续计划后结束，确保了项目的持续推进和团队成员之间的协作。感谢所有参与者的努力和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-11-12","slug":"Ceph_Performance_Meeting_2020-11-12","date":"2020-11-23T16:00:00.000Z","updated":"2020-11-24T16:00:00.000Z","comments":true,"path":"2020/11/24/Ceph_Performance_Meeting_2020-11-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/24/Ceph_Performance_Meeting_2020-11-12/","excerpt":"","text":"会议纪要 与会人员 Mark Gary Gabby 其他核心团队成员 缺席人员 Adam（因波兰独立日休假） 主要议题 性能分析进展 Gabby报告了关于正式分析的进展，提到需要更好的系统来记录和命名测试案例。 讨论了从CBT（Ceph Benchmark Tool）创建数据库模式以存储和查询测试结果的想法，但目前无人有时间实现。 Ceph性能优化 讨论了Python压缩对性能的影响，特别是关于PG信息和PG日志分离到不同列族的性能影响。 提到了使用Wall Clock Profiler或Adam的Welcome Profiler来更清晰地展示性能差异。 讨论了添加统计信息（如压缩和闪存事件）的显示方式，建议通过admin socket命令获取。 监控插件的开发 讨论了开发一个监控插件来执行任意admin socket命令的必要性，以便更好地收集和分析数据。 提到了在CBT中实现一个自定义监控类的可能性。 PR（Pull Request）更新 讨论了Intel的librbd客户端侧缓存实现的PR，Jason将继续审查。 更新了关于RocksDB动态级别的PR，Adam将在假期后继续跟进。 讨论了Igor的PG移除优化PR，Adam和Neha对其进行了审查，但还有一些细节需要处理。 内存管理 Adam和Mark正在继续研究减少碎片化的内存管理策略。 MClock调度器测试 Sridhar分享了关于MClock调度器的最新测试结果，展示了在不同配置下的性能数据。 讨论了在单个shard和16个线程配置下的性能问题，需要进一步调查。 资源分配 Mark提到为开发人员提供高性能机器的计划，Gabby和Ronan将成为首批使用者。 RGW文件访问接口 讨论了RGW（RADOS Gateway）的文件访问接口，以及与IO500基准测试的合作可能性。 决定事项 需要开发一个监控插件来执行任意admin socket命令，以便更好地收集和分析数据。 需要进一步调查单个shard和16个线程配置下的性能问题。 需要为开发人员提供高性能机器，以便进行更深入的性能测试。 后续行动计划 Gabby将继续进行性能分析，并尝试使用Wall Clock Profiler或Adam的Welcome Profiler。 需要进一步调查和优化MClock调度器的性能。 需要为开发人员提供高性能机器，并鼓励他们使用这些资源进行性能测试。 其他 讨论了KV-Sync线程的性能瓶颈问题，需要进一步调查。 需要进一步调查和优化RocksDB的性能，特别是关于PG信息和PG日志分离到不同列族的性能影响。 结论 会议讨论了多个关于Ceph性能优化的议题，包括性能分析、监控插件开发、PR更新、内存管理、MClock调度器测试等。团队将继续进行深入调查和优化，以提高Ceph的整体性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User Survey Working Group 2020-11-12","slug":"Ceph_User_Survey_Working_Group_2020-11-12","date":"2020-11-23T16:00:00.000Z","updated":"2020-11-24T16:00:00.000Z","comments":true,"path":"2020/11/24/Ceph_User_Survey_Working_Group_2020-11-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/24/Ceph_User_Survey_Working_Group_2020-11-12/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了关于Ceph用户调查问卷的更新和改进。会议参与者包括多位Ceph研发人员和社区成员，共同审查了现有的调查问卷，并讨论了如何优化问题内容和调查界面。 主要议题 调查问卷链接分享与评论审查： 会议开始时，参与者讨论了如何获取并分享包含调查结果的Google Docs链接。 审查了调查问卷中的评论，特别是关于2019年调查的问题。 问题内容和界面设计的讨论： 讨论了如何改进调查问卷的问题内容，特别是确保某些问题是多选而非单选。 讨论了调查界面的用户体验，如增加进度指示器和问题分类，以便用户更好地理解调查的进度和相关性。 新问题的添加和旧问题的调整： 讨论了是否添加新的问题，如关于CPU架构和存储设备使用情况的问题。 讨论了如何调整现有问题，例如合并相关问题或删除不必要的问题。 后续行动计划： 决定继续在Google Docs上添加和讨论评论，以进一步优化调查问卷。 计划在下一次会议前完成内容部分的准备工作，并在后续讨论界面和导航的优化。 决定事项 确认了调查问卷中某些问题需要调整为多选形式。 决定添加新的问题，如关于AMD CPU和存储设备形式的问题。 决定删除或合并一些重复或不必要的问题。 确定了增加调查进度指示器和问题分类的必要性。 后续行动计划 继续在Google Docs上添加和讨论评论，优化调查问卷内容。 在下一次会议前完成内容部分的准备工作。 讨论和优化调查界面的用户体验，包括导航和问题呈现方式。 计划在假期前完成所有调查问卷的优化工作。 会议结束 会议在讨论了所有议题并确定了后续行动计划后结束，预计在下一周继续进行相关讨论和优化工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph User Survey Working Group 2020-11-05","slug":"Ceph_User_Survey_Working_Group_2020-11-05","date":"2020-11-23T16:00:00.000Z","updated":"2020-11-23T16:00:00.000Z","comments":true,"path":"2020/11/24/Ceph_User_Survey_Working_Group_2020-11-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/24/Ceph_User_Survey_Working_Group_2020-11-05/","excerpt":"","text":"会议纪要 参会人员 本次会议原本预计有五人参加，但Stefan因故无法出席，因此实际参会人员为四人。 会议内容 更新与反馈 会议开始时，参会者对当前的更新情况表示好奇，但并未有具体的新信息。 一位参会者分享了上周的待办事项，并展示了调查问卷给上司和其他人，收到了一些有趣的反馈和问题，例如数据的收集目的和相关性，以及硬件供应商的信息是否对软件功能开发有用。 功能与技术讨论 讨论了缓存功能的使用情况，特别是缓存分层功能，指出Red Hat不支持该功能，只有Suse支持。 探讨了如何改进调查问卷以更好地识别和优化功能，特别是性能相关的功能。 讨论了从Intel的角度如何利用NVMe技术改进Ceph的性能，提到了Crimson项目。 调查问卷的改进 讨论了是否应该深化调查问卷的细节，或者是否现有的用户服务形式已经足够。 提出了获取配置和部署细节的可能性，以帮助改进Ceph的部署和性能。 讨论了调查问卷的格式和内容，是否应该保持现有的格式，或者进行调整以更好地收集有价值的信息。 后续行动计划 决定继续使用现有的调查问卷格式，但会重新审视和优化问题内容。 计划重新启用调查问卷，并允许参会者进行体验和反馈。 讨论了推广调查问卷的方法，包括通过用户组列表和博客进行宣传，以及通过董事会成员在其组织内推广。 下一步行动 参会者将在Google Docs上编辑调查问卷的问题，并提出改进建议。 重新启用调查问卷，并邀请参会者进行体验和反馈。 通过用户组列表和博客进行调查问卷的宣传，并通过董事会成员在其组织内推广。 计划在下一次会议前，对调查问卷的内容和格式进行进一步的讨论和优化。 下次会议 计划在下周或下下周进行下一次会议，具体时间将通过Doodle Poll确定。 备注 会议中提到了一些技术细节，如NVMe技术、Crimson项目、缓存功能等，这些是Ceph分布式存储系统中的关键技术点。 参会者对调查问卷的改进和推广表示了积极的态度，并提出了具体的行动计划。 本次会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的全面记录和后续行动的明确指导。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2020-11-04","slug":"Ceph_Developer_Monthly_2020-11-04","date":"2020-11-16T16:00:00.000Z","updated":"2020-11-17T16:00:00.000Z","comments":true,"path":"2020/11/17/Ceph_Developer_Monthly_2020-11-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/17/Ceph_Developer_Monthly_2020-11-04/","excerpt":"","text":"会议纪要 会议主题：Ceph 开发者月度会议 - 2020年11月 参会人员：Ceph 开发团队成员 会议议程： Manager 可扩展性讨论 Replicated Writeback Cache (RWD) 介绍 Dashboard 设计协作改进 关键细节： 1. Manager 可扩展性讨论 问题识别：Manager 在高负载下出现 CPU 使用率高、处理延迟增加等问题。 性能瓶颈：主要集中在 Manager 模块的某些部分，如 Finisher 队列处理大量完成项时导致延迟。 短期解决方案： 自动调整报告间隔，减少 OSD 报告的频率。 优化模块，提高数据处理效率，例如减少 JSON 转换的开销。 长期解决方案： 考虑将 Manager 模块分解，提高整体系统的可扩展性。 引入更多监控和调试工具，帮助识别和解决性能问题。 后续行动： 收集更多关于 Manager 性能的遥测数据，分析并优化。 探索更有效的数据结构和处理方法，减少 CPU 和内存的使用。 2. Replicated Writeback Cache (RWD) 介绍 项目背景：RWD 是一个基于持久内存的缓存系统，旨在提高数据处理的效率和可靠性。 当前进展：已完成第一阶段，即单副本缓存实现；第二阶段将实现跨设备的数据复制。 技术挑战： 需要管理多个副本的状态和数据一致性。 处理节点故障时的数据恢复和重新分配。 后续行动： 进一步测试和验证 RWD 的性能和可靠性。 考虑简化初始实现，先解决核心的用户故事和基本功能。 3. Dashboard 设计协作改进 问题识别：设计团队和开发团队之间的协作需要改进，特别是在时间区差异较大的情况下。 解决方案：通过设计拉取请求（Design Pull Requests）的方式，将设计文档提交到开发仓库中，以便更好地协作和审查。 后续行动： 继续使用设计拉取请求的方式，收集反馈并优化流程。 探索更有效的协作工具和方法，提高团队间的沟通效率。 决定事项： 确认了 Manager 模块的性能优化方向和短期行动计划。 确定了 RWD 项目的下一步测试和简化实现的策略。 同意继续使用设计拉取请求的方式，改进 Dashboard 的设计协作。 后续行动计划： 收集和分析 Manager 的性能数据，优化代码和配置。 测试 RWD 的性能，简化初始实现，确保基本功能的稳定性和可靠性。 继续使用设计拉取请求，优化 Dashboard 的设计协作流程。 会议结束： 感谢所有参与者的贡献，期待在下一次会议中继续讨论和推进项目的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD Weekly 2020-11-04","slug":"Ceph_Crimson_SeaStor_OSD_Weekly_2020-11-04","date":"2020-11-15T16:00:00.000Z","updated":"2020-11-16T16:00:00.000Z","comments":true,"path":"2020/11/16/Ceph_Crimson_SeaStor_OSD_Weekly_2020-11-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/16/Ceph_Crimson_SeaStor_OSD_Weekly_2020-11-04/","excerpt":"","text":"会议纪要 关键细节 对象上下文锁定恢复问题： 讨论了在PG（Placement Group）活动集更改时解锁对象上下文的问题。 提出了使用with lock原语来确保解锁操作总是被调用的解决方案。 EIO处理： 讨论了在PG后端处理EIO（输入/输出错误）的适当位置。 决定将EIO处理移至pg.cc，并在客户端请求中处理重启逻辑。 PG状态修复： 讨论了在遇到EIO时将PG状态设置为修复的原因和后果。 确认修复状态是为了触发后续的 scrub 和修复操作。 文档编写： 建议编写文档来解释设计目标和计划的上传位置，以帮助评审人员理解。 性能测试： 讨论了将新功能添加到性能测试中的可能性，以确保代码路径的持续优化。 集合树的需求： 讨论了是否需要为Ceph存储节点信息创建单独的树。 提出了使用现有接口和对象存储来处理集合信息的建议。 线程池处理： 讨论了线程池处理和心跳计时器的使用，以防止长时间操作导致的心跳问题。 测试和分布式问题： 讨论了测试的覆盖范围和特定分布的限制。 事务管理器和性能： 讨论了事务管理器的性能测试和需要修复的问题。 Messenger更改： 讨论了Messenger在多核环境下的运行问题和可能的设计变更。 决定事项 EIO处理位置：决定将EIO处理逻辑移至pg.cc。 文档编写：决定编写详细的设计文档来解释EIO处理的设计和实现。 集合树的需求：决定不创建单独的树，而是使用现有接口来处理集合信息。 Messenger更改：决定进一步研究Messenger在多核环境下的运行问题，并考虑设计变更。 后续行动计划 编写设计文档：编写详细的设计文档，包括EIO处理和Messenger更改的设计。 性能测试：将新功能添加到性能测试中，以确保代码路径的持续优化。 集合树的研究：进一步研究集合树的需求和现有接口的使用。 Messenger更改的研究：进一步研究Messenger在多核环境下的运行问题，并考虑设计变更。 结论 本次会议主要讨论了Ceph存储系统中的多个关键问题，包括EIO处理、对象上下文锁定恢复、集合树的需求和Messenger的更改。通过详细的讨论和决策，确定了后续的行动计划，以确保系统的稳定性和性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-10-28","slug":"Ceph_Crimson_SeaStor_OSD_2020-10-28","date":"2020-11-02T16:00:00.000Z","updated":"2020-11-02T16:00:00.000Z","comments":true,"path":"2020/11/03/Ceph_Crimson_SeaStor_OSD_2020-10-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/03/Ceph_Crimson_SeaStor_OSD_2020-10-28/","excerpt":"","text":"会议纪要 关键细节 Johannes Pierre的审查：会议开始时提到，上周对Johannes Pierre的“interpretable future”进行了审查，并希望尽快完成。 修复occluded by unknown问题：讨论了在服务客户端请求时，如何修复因未知原因导致的对象遮挡问题。 PG acting sets的变化：在处理客户端请求时，PG的acting sets发生了变化，需要重新启动客户端请求。 PR的更新：对PR进行了一些更改，目前正在解决编译错误，并计划运行thresh测试。 单元测试的缺失：发现目前没有可用的单元测试来检查恢复过程，可能需要在整个trash测试中运行。 时间区变更：从明天开始，将前往加拿大，时间区会有所变化，但仍会参与会议。 代码清理和PR提交：计划清理代码并提交PR进行审查，同时在测试中发现了一个bug，需要修复并提供测试用例。 扩展map tree的问题：在扩展map tree时遇到了问题，计划发送详细信息给团队成员帮助解决。 NBD服务器实现：为了测试Ceph的不同元素，实现了一个简单的NBD服务器，将I/O操作直接传递给事务管理器。 NVMe over Fabric的讨论：讨论了如何在未来的Rados中适应NVMe over Fabric，以及如何改变Rados协议以允许客户端在没有协调的情况下进行写操作。 Optane内存的使用：讨论了如何利用Optane内存来提高性能，特别是在元数据和日志缓存方面。 多核Crimson的实现：计划实现多核Crimson，以提高性能和覆盖更多的测试场景。 主要议题 Ceph存储系统的性能和稳定性改进：包括修复已知问题、优化代码、增加测试覆盖率以及探索新的硬件加速技术。 分布式存储系统的未来发展方向：讨论了如何适应新的硬件技术（如NVMe over Fabric）和内存技术（如Optane），以及如何改进协议以提高效率。 决定事项 继续审查和完善PR：确保代码质量和功能完整性。 增加单元测试：以确保系统的稳定性和可靠性。 实现NBD服务器：用于更有效地测试Ceph的各个组件。 探索NVMe over Fabric的应用：以提高存储系统的性能。 利用Optane内存：特别是在元数据和日志缓存方面。 实现多核Crimson：以提高系统的并行处理能力。 后续行动计划 完成PR的审查和测试：确保所有更改都经过充分的测试。 设计和实现单元测试：以覆盖所有关键功能。 继续研究和开发NBD服务器：以支持更复杂的测试场景。 深入研究NVMe over Fabric和Optane内存的应用：以确定最佳实践和实施方案。 推进多核Crimson的实现：以提高系统的性能和可靠性。 本次会议涵盖了Ceph存储系统的多个关键技术和未来发展方向，旨在通过技术改进和创新，提高系统的性能、稳定性和可扩展性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-10-29","slug":"Ceph_Performance_Meeting_2020-10-29","date":"2020-11-02T16:00:00.000Z","updated":"2020-11-02T16:00:00.000Z","comments":true,"path":"2020/11/03/Ceph_Performance_Meeting_2020-10-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/03/Ceph_Performance_Meeting_2020-10-29/","excerpt":"","text":"会议纪要 关键细节 PR审查与更新： 性能改进PR：Jason对异步创建镜像快照的性能改进PR进行了审查。 集成AVX擦除编码实现PR：该PR主要涉及构建变更，性能提升效果待定。 关闭的PR：RBD缓存PR已合并，代码量较大，后续需进一步强化。 无缓存重建PR：已被替换，新PR待审查。 BlueStore动态层级PR： 该PR存在一段时间，与Adam的列族分片工作不兼容，需要Adam进行审查。 缓存分桶代码： 大部分代码已合并到主分支，剩余部分正在单独分支中处理。 PG自动缩放讨论： 讨论了改进PG自动缩放算法的必要性，以改善初始安装时的性能。 提出了通过调整PG日志长度来控制内存使用，而不是直接调整PG数量的方法。 讨论了不同类型池（如数据池和索引池）的处理策略。 内存使用和缓存年龄分桶： Adam修复了数据缓存无法正确增长的bug。 讨论了缓存管理和内存碎片化问题，提出了使用Radix工作改进内存分配的建议。 I/O环讨论： 尝试在Kernel 5.9上构建包含liburing支持的Ceph代码，发现构建问题并初步测试未见性能差异。 决定事项 PG自动缩放算法改进： 同意改进PG自动缩放算法，以避免频繁的数据移动和优化并发性能。 内存管理和缓存优化： 确认了内存碎片化问题，并讨论了可能的解决方案，包括改进内存分配策略和缓存管理。 后续行动计划 PG自动缩放算法实现： 继续开发和测试新的PG自动缩放算法，确保其在不同使用场景下的有效性。 内存碎片化问题解决： 进一步研究和测试内存碎片化解决方案，包括Radix工作的应用和缓存管理的优化。 I/O环性能测试： 继续验证liburing在Ceph中的正确使用，并进行更深入的性能测试。 下周议程： 将PG日志相关讨论作为下周会议的首要议题。 会议结束时，团队成员被鼓励在即将到来的一周中继续努力，并期待在下一次会议中分享更多进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthrough: LibRBD I/O Flow Pt. 1 2020-10-27","slug":"Ceph_Code_Walkthrough_-_LibRBD_I_O_Flow_Pt._1_2020-10-27","date":"2020-11-01T16:00:00.000Z","updated":"2020-11-02T16:00:00.000Z","comments":true,"path":"2020/11/02/Ceph_Code_Walkthrough_-_LibRBD_I_O_Flow_Pt._1_2020-10-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/11/02/Ceph_Code_Walkthrough_-_LibRBD_I_O_Flow_Pt._1_2020-10-27/","excerpt":"","text":"会议纪要 会议主题： Ceph 中 RADOS Block Device (RBD) 的 I/O 路径解析 主讲人： Jason Dillman 会议内容总结： 介绍与目标： Jason Dillman 是 Ceph 项目中 RADOS Block Device (RBD) 部分的 Tech Lead。 本次会议的目标是详细解析从 librbd API 到 OSD 的读写请求的转换过程。 数据组织： RBD 将块设备视为一个从字节零开始的扁平文件。 内部通过 librbd 将这些请求分解为更小、更易管理的对象，存储在 Ceph 存储集群中。 每个 RBD 图像默认使用 4MB 大小的固定对象进行存储。 API 接口： librbd 是一个用户空间库，提供 C 和 C++ 以及 Python 绑定。 常见的集成包括 QEMU，它通过 librbd 与 RBD 交互。 API 提供同步和异步的读写、刷新和丢弃操作。 内部实现： API 方法首先在 librbd.cc 文件中定义，负责维护 API 的稳定性和 ABI。 内部将同步调用转换为异步调用，并通过异步完成回调处理。 I/O 请求首先被转换为图像范围的 I/O，然后进一步分解为对象范围的 I/O。 I/O 分发层： I/O 分发层包括多个子组件，如排队层、服务质量层、独占锁层等。 核心层负责将 I/O 请求发送到 Ceph OSD 集群。 对象 I/O 分发： 对象 I/O 分发层处理具体的对象读写请求。 包括缓存层、加密层、日志层等，最终通过核心层将请求发送到 OSD。 测试与未来计划： 有大量的单元测试代码，确保每个组件的正确性。 未来可能会有更多的会议来深入探讨这些细节。 后续行动计划： - 安排更多会议以深入讨论 RBD 的 I/O 路径和其他相关主题。 - 参与者可以通过邮件列表等方式与 Jason Dillman 联系，提出问题或建议。 会议结束： - 感谢 Jason Dillman 的详细讲解和所有参与者的积极参与。 备注： - 本次会议由于时间限制，未能覆盖所有细节，未来会议将继续探讨。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2020-10-29","slug":"Ceph_Docubetter_Meeting_2020-10-29","date":"2020-10-28T16:00:00.000Z","updated":"2020-10-29T16:00:00.000Z","comments":true,"path":"2020/10/29/Ceph_Docubetter_Meeting_2020-10-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/29/Ceph_Docubetter_Meeting_2020-10-29/","excerpt":"","text":"会议纪要 主题：提高文档效率和可扩展性 主要议题： 文档更新与优化： 讨论了文档中的链接问题，特别是顶级链接不工作的问题，原因是使用了混合的目录树和章节。决定关闭相关拉取请求，待进一步了解设置后再重新处理。 提到了对安装指南的改进，包括纠正有序列表的编号错误，并等待Josh、Neha和Keifu的反馈。 文档管理与领导团队沟通： 强调了团队领导需要知道有一个中心位置可以放置他们的发布说明，以便进行编辑，确保专业性。 讨论了自领导团队会议中提到的仪表盘文档链接在Octopus上不工作的问题，目前正在解决中。 RADOS协议文档： Sanford Miller提出了关于RADOS协议的文档需求，强调了RADOS作为一个黑盒的现状，以及对新特性和用例开发的限制。建议专注于文档化RADOS协议方法，而不是整个RADOS系统。 讨论了可能的文档格式，如序列化图表，并征求专家意见。 文档结构与内容管理： 讨论了文档的结构问题，包括是否应该重新组织文档目录，以及如何平衡新旧内容。 提到了对旧文档的更新需求，以及如何在保持新鲜感和不遗漏重要信息之间找到平衡。 决定事项： 关闭相关拉取请求，待进一步了解设置后再重新处理文档链接问题。 继续改进安装指南，并等待关键人员的反馈。 开始着手RADOS协议的文档工作，目标是年底前完成核心部分的文档化。 后续行动计划： 继续与团队领导沟通，确保发布说明的集中管理和专业性。 解决仪表盘文档链接在Octopus上的问题。 开始RADOS协议的文档工作，并定期更新进度。 考虑重新组织文档目录，以更好地服务用户和开发者。 其他事项： 感谢Anthony对文档的大量贡献，并强调了文档更新的重要性。 讨论了如何在文档中平衡新旧内容，以及如何处理不同架构和部署方式的复杂性。 会议结束时，强调了持续沟通和协作的重要性，以确保文档的持续改进和更新。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-10-26","slug":"Ceph_Orchestrator_Meeting_2020-10-26","date":"2020-10-25T16:00:00.000Z","updated":"2020-10-26T16:00:00.000Z","comments":true,"path":"2020/10/26/Ceph_Orchestrator_Meeting_2020-10-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/26/Ceph_Orchestrator_Meeting_2020-10-26/","excerpt":"","text":"会议纪要 会议主题：Ceph高可用性实施与文档更新 关键细节： 1. 高可用性实施：会议开始时，团队讨论了已经开始实施的高可用性（High Availability）方案，特别是针对Ardida Bonjour代理的部署。 2. 文档更新：团队强调了更新和维护相关文档的重要性，包括使用说明和故障排除指南，以确保这些文档易于理解和操作。 3. 技术讨论：讨论了关于Ceph存储系统的具体技术问题，如接口（interface）、参数（argument）和功能实现（functional implementation）。 4. 后续行动计划： - 继续推进高可用性方案的实施，并确保所有相关技术细节得到妥善记录和测试。 - 更新和优化现有文档，确保所有用户和团队成员都能轻松访问和理解。 - 定期召开技术会议，以跟进项目进度并解决任何出现的技术问题。 决定事项： - 确认将继续推进高可用性方案的实施，并优先考虑文档的更新和优化。 - 确定下一次会议将重点讨论具体的实施细节和文档更新的进展。 后续行动计划： - 技术团队将负责继续推进高可用性方案的实施，并确保所有技术文档得到及时更新。 - 安排定期的技术会议，以监控项目进度并确保所有团队成员对项目状态有清晰的了解。 会议结束时，团队成员对即将到来的工作充满信心，并期待在高可用性和文档更新方面取得显著进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2020-10-14","slug":"Ceph_Docubetter_Meeting_2020-10-14","date":"2020-10-13T16:00:00.000Z","updated":"2020-10-14T16:00:00.000Z","comments":true,"path":"2020/10/14/Ceph_Docubetter_Meeting_2020-10-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/14/Ceph_Docubetter_Meeting_2020-10-14/","excerpt":"","text":"会议纪要 会议时间： 某日，时间略晚于预定开始时间 参会人员： 会议主持人及其他相关人员 主要议题及讨论内容： Pull Request 374-51 (FADM) 讨论了FADM（Faster and More Scalable Document）的Pull Request，这是一个未来文档变更的重要来源。目前无需立即行动，但需保持关注。 GitHub行为变更 决定不再要求在doc目录内的提交必须有“Signed-off-by”标签，以避免通过GitHub Web界面进行的更改被阻止。 CFDF细节PR更新 主持人正在处理一个CFDF相关的Pull Request，预计将在接下来几小时内或最迟明天完成。 文档系统（FFS）的改进 针对Josh Cullen提出的关于侧边栏顶级链接无法正常工作的bug，主持人已通过将链接集合到restructuredText文档中的toctree来解决。同时，移除了之前注释掉的HTML代码，并添加了:hidden:选项以避免toctree在文档中显示。 主持人请求Patrick检查这些更改是否影响了他们的需求。 RADOS文档更新 Anthony Diatri对RADOS文档进行了大量更新，主持人与其进行了深入的合作，更新已成功整合到文档中。 defio与docs.ceph.com同步问题 讨论了defio与docs.ceph.com不同步的问题，提出了可能通过自动化工具来解决这一问题。 旧Pull Request的处理 讨论了如何处理因“Signed-off-by”检查而阻塞的旧Pull Request，建议重新运行测试或创建新的Pull Request来清理积压。 文档更新与维护 主持人计划对开发指南进行全面检查和更新，并确保在即将发布的Pacific版本中，文档集是全面、准确且易于导航的。 决定事项： 不再要求doc目录内的提交必须有“Signed-off-by”标签。 将处理旧Pull Request的积压问题，通过重新运行测试或创建新PR来解决。 后续行动计划： 完成CFDF细节PR。 继续更新和维护文档，特别是FFS和开发指南。 探索自动化工具以解决defio与docs.ceph.com的同步问题。 确保Pacific版本发布时，文档集是全面、准确且易于导航的。 会议结束时间： 20分钟后 下一次会议： 待定 备注： 会议中提到的具体技术细节和代码更改需要进一步的技术审查和验证。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2020-10-07","slug":"Ceph_Developer_Monthly_2020-10-07","date":"2020-10-09T16:00:00.000Z","updated":"2020-10-09T16:00:00.000Z","comments":true,"path":"2020/10/10/Ceph_Developer_Monthly_2020-10-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/10/Ceph_Developer_Monthly_2020-10-07/","excerpt":"","text":"会议纪要 会议主题：高效追踪与分布式存储系统优化 关键细节： 高效追踪（Tracing）的重要性： 追踪系统用于解决系统中未知的性能问题。 传统的调试工具如GDB在处理高并发系统时效率低下，需要用户干预，影响系统性能。 在线追踪（Online Tracing）允许系统在不等待用户输入的情况下继续运行，收集和保存变量变化，用户可以在事后分析数据。 现有追踪系统的局限性： 简单的日志系统（如syslog）产生大量数据，可能导致系统过载。 动态添加事件追踪点需要重新编译和构建，不灵活。 基于字符串的操作开销大，追踪数据难以管理。 高效追踪系统的设计要求： 简单易用，无锁操作，不影响正常执行。 数据应高效收集并以二进制格式存储，同时保持人类可读性。 支持在线事件收集过滤，允许用户根据事件类型、对象类型等进行过滤。 实施细节： 使用全局变量简化事件添加过程。 支持在线添加和移除过滤器，使用GUI界面进行管理。 每个CPU核心独立处理事件日志，使用双缓冲技术减少同步需求。 未来工作： 集成到现有工具如Wireshark，避免重复工作。 考虑与现有追踪系统（如Jaeger）的兼容性和替代性。 讨论的主要议题： 如何设计一个既高效又易于使用的追踪系统。 如何在不增加系统负担的情况下收集和分析追踪数据。 如何与现有工具和系统（如Jaeger）集成或替代。 决定的事项： 开发一个原型来测试和验证高效追踪系统的概念。 考虑使用现有开源项目（如SPDK的ADM参考实现）作为基础，避免从零开始。 后续行动计划： 开发和测试高效追踪系统的原型。 探索与现有追踪工具的集成或替代方案。 根据反馈和测试结果调整和优化系统设计。 其他讨论点： 分布式NVMe命名空间（ADN）的概念和实现，旨在优化存储系统的连接性和性能。 如何将ADN集成到Ceph中，以及可能的技术挑战和解决方案。 通过这次会议，团队对高效追踪系统的需求和设计有了更清晰的认识，并制定了初步的实施计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson / SeaStor OSD  2020-10-06","slug":"Ceph_Crimson_SeaStor_OSD_2020-10-06","date":"2020-10-06T16:00:00.000Z","updated":"2020-10-07T16:00:00.000Z","comments":true,"path":"2020/10/07/Ceph_Crimson_SeaStor_OSD_2020-10-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/07/Ceph_Crimson_SeaStor_OSD_2020-10-06/","excerpt":"","text":"会议纪要 与会人员 主持人：未明确提及 参与者：Sam, Johan, 以及其他未明确提及的成员 会议时间 日期：未明确提及 时间：未明确提及 会议议题 个人工作汇报 Sam：上周在PTO期间，创建了一些清理PR，并开始审查Stem Care以添加捕获集合。同时，关注Amnon的PI和Runes，并计划分配时间审查一些hands interrupt。 未明确提及的成员：计划回顾VR，并开始改进测试，特别是独立测试，如scrubbing测试。 Stem：阅读了Greyhounds相关内容，提交了一个PR，并正在为e-store编写磁盘后端，以便进行基本性能测试。 未明确提及的成员：提交了interruptible future PR，并正在修改代码和添加单元测试。 技术讨论 Stem：讨论了使用iou ring支持的问题，目前后端并未使用该功能。 Sam：对interruptible future的设计进行了深入讨论，提出了一些改进建议，包括确保在调用safe then时中断条件已经设置，以及可能的命名问题。 决定事项 Stem：将继续关注iou ring的支持情况，并考虑使用最基本的内置于c-star的方法进行磁盘写入。 Sam：建议在interruptible future的设计中，确保中断条件在调用safe then时已经设置，并考虑命名问题以提高代码的可读性。 后续行动计划 Stem：继续关注iou ring的支持进展，并考虑使用最基本的内置方法进行磁盘写入。 Sam：与Johan讨论interruptible future的设计，确保中断条件在调用safe then时已经设置，并考虑命名问题。 所有成员：继续各自的工作，并关注相关技术进展。 其他备注 会议中提到了一些具体的技术细节和代码实现问题，需要进一步的技术讨论和代码审查。 会议结束 会议在讨论完所有议题后结束，感谢大家的参与。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-10-05","slug":"Ceph_Orchestrator_Meeting_2020-10-05","date":"2020-10-05T16:00:00.000Z","updated":"2020-10-06T16:00:00.000Z","comments":true,"path":"2020/10/06/Ceph_Orchestrator_Meeting_2020-10-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/06/Ceph_Orchestrator_Meeting_2020-10-05/","excerpt":"","text":"会议纪要 会议主题：Rook Manager Module 的状态和未来 参会人员：未明确列出，但提到了Patrick、Travis、Joshua等人。 会议时间：未明确列出，但提到了几天前发送的邮件。 会议地点：未明确列出，通过视频会议进行。 主要议题： Rook Manager Module 的现状和需求 该模块两年前创建，但未得到充分维护和使用。 讨论了该模块的优先级和是否仍需保留。 确认了Dashboard对Rook Manager Module的兴趣。 Rook Manager Module 的启用状态和社区反馈 该模块未默认启用，上游社区未注意到或询问为何不默认启用。 发现了该模块的多个bug，但缺乏测试。 资源和优先级问题 讨论了资源有限，当前主要优先级是FDM（Federated Deployment Manager）。 Red Hat和SUSE的资源分配问题，特别是Red Hat目前主要集中在FDM上。 Rook Manager Module 的功能和测试需求 需要确定Rook Manager Module的具体使用场景和功能需求。 强调了测试的重要性，特别是与Rook和Cephadm的集成测试。 Rook Manager Module 的未来方向 讨论了是否应该继续支持Rook Manager Module，以及如何分配资源。 提出了可能的解决方案，如使用外部资源或调整资源分配。 决定事项： 需要进一步明确Rook Manager Module的使用场景和功能需求。 需要加强测试，特别是与Rook和Cephadm的集成测试。 需要讨论资源分配问题，特别是如何平衡FDM和Rook Manager Module的开发资源。 后续行动计划： 继续讨论Rook Manager Module的未来方向和资源分配。 加强测试，特别是与Rook和Cephadm的集成测试。 需要明确Dashboard对Rook Manager Module的需求和使用场景。 其他讨论： 讨论了SSH和HTTPS在获取主机信息方面的性能和安全性问题。 需要进一步在真实硬件上测试SSH的性能，以决定是否继续使用或切换到HTTPS。 会议总结： 会议主要讨论了Rook Manager Module的现状、需求、资源分配和未来方向。强调了测试的重要性，并提出了需要进一步明确的使用场景和功能需求。同时，讨论了SSH和HTTPS在获取主机信息方面的性能和安全性问题，并提出了需要在真实硬件上进行进一步测试的建议。 以上是根据会议内容总结的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: Karan Singh - Scale Testing Ceph with 10Billion+ Objects 2020-10-01","slug":"Ceph_Tech_Talk_-_Karan_Singh_-_Scale_Testing_Ceph_with_10Billion+_Objects_2020-10-01","date":"2020-10-01T16:00:00.000Z","updated":"2020-10-02T16:00:00.000Z","comments":true,"path":"2020/10/02/Ceph_Tech_Talk_-_Karan_Singh_-_Scale_Testing_Ceph_with_10Billion+_Objects_2020-10-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/02/Ceph_Tech_Talk_-_Karan_Singh_-_Scale_Testing_Ceph_with_10Billion+_Objects_2020-10-01/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于Red Hat的Ceph对象存储在规模测试中的表现，特别是在处理超过10亿个对象时的性能评估。会议由Karan Singh主持，他是Red Hat云存储和数据服务业务单元的高级解决方案架构师。 讨论的主要议题 规模测试的目的和背景： 本次测试旨在验证Ceph对象存储在处理大规模数据（10亿个对象）时的性能。 之前的测试已经验证了Ceph在处理1亿个对象时的性能，本次测试是对其能力的进一步验证。 测试环境和配置： 使用了6个Red Hat存储节点，每个节点配备53个16TB的旋转设备和6个Intel QLC 3.9设备。 软件配置包括Red Hat Ceph Storage 4.1，所有守护进程（OSD、Monitor、Manager、RADOS Gateway）都容器化。 测试结果和性能分析： 在处理小对象（64KB）和大对象（128MB）时，Ceph展示了确定性的性能。 在达到10亿个对象时，系统仍然保持稳定的写入和读取性能。 在硬件故障模拟测试中，系统表现出了良好的容错能力，即使在节点或设备故障的情况下，性能下降也在可接受范围内。 性能优化的建议： 建议使用多个RADOS Gateway实例以提高性能。 推荐使用4%的闪存容量作为BlueStore的元数据存储。 建议增加OSD内存目标大小以提高性能。 决定的事项 确认了Ceph对象存储在处理大规模数据时的稳定性和性能。 确定了在设计和部署大规模Ceph集群时的最佳实践和配置建议。 后续行动计划 发布完整的测试报告，供社区和客户参考。 继续监控和优化Ceph在大规模数据处理中的性能，以支持未来的数据湖和大数据工作负载。 其他信息 会议中还讨论了关于BlueStore的配置和优化，以及如何更有效地使用闪存存储。 提供了关于如何根据测试结果进行集群规模估算的指导。 本次会议为Ceph对象存储在大规模数据处理中的应用提供了宝贵的性能数据和优化建议，有助于推动Ceph在企业级存储解决方案中的进一步应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-10-01","slug":"Ceph_Performance_Meeting_2020-10-01","date":"2020-09-30T16:00:00.000Z","updated":"2020-10-01T16:00:00.000Z","comments":true,"path":"2020/10/01/Ceph_Performance_Meeting_2020-10-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/10/01/Ceph_Performance_Meeting_2020-10-01/","excerpt":"","text":"会议纪要 关键细节 新PR和更新PR: 本周只有Igor提交的一个新PR，涉及PG移除的优化。此外，Paul Kuzner审查了一个关于并发检索设备数据的卷PR，仍在进行中。还有一个PR允许在RocksDB中动态调整级别，目前正在收集性能数据。 PG日志条目回收原型: Gabby正在开发一个原型，用于回收PG日志条目的键。初步测试显示，这种方法可能导致数据库输入记录显著增加，且在压缩过程中工作量大幅上升。 替代方案讨论: 讨论了三种替代方案：修改RocksDB、创建独立的PG日志解决方案、以及控制RocksDB的写前日志（WAL）。还提到了MyRocks的实现，可能提供有用的参考。 讨论的主要议题 PG日志优化: 讨论了如何优化PG日志，减少其在RocksDB中的存储和处理开销。提出了多种方法，包括修改RocksDB内部行为、创建独立解决方案、以及学习MyRocks的实现。 性能和正确性权衡: 讨论了在优化性能的同时如何保持系统的正确性，特别是在减少PG日志条目和重复条目时可能带来的风险。 决定的事项 进一步研究MyRocks: 决定进一步研究MyRocks的实现，了解其如何处理写前日志和事务，以寻找可能的优化点。 继续探索PG日志优化方案: 继续探索和评估不同的PG日志优化方案，包括修改RocksDB、创建独立解决方案等。 后续行动计划 阅读MyRocks相关文档: 团队成员需要阅读MyRocks的设计文档和相关博客，了解其优化策略。 继续测试和评估: 继续对不同的PG日志优化方案进行测试和评估，收集性能数据，确保优化方案既提高性能又不影响系统的正确性。 讨论和决策: 在下一次会议中，团队将根据收集的信息和测试结果，进一步讨论并决定最终的优化方案。 结论 会议讨论了PG日志的优化问题，提出了多种可能的解决方案，并决定进一步研究MyRocks的实现作为参考。团队将继续测试和评估不同的优化方案，确保在提高性能的同时保持系统的正确性。下一次会议将继续讨论并决定最终的优化方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthrough: Patrick Donnelly - Metadata Servers 2020-09-29","slug":"Ceph_Code_Walkthrough_-_Patrick_Donnelly_-_Metadata_Servers_2020-09-29","date":"2020-09-29T16:00:00.000Z","updated":"2020-09-30T16:00:00.000Z","comments":true,"path":"2020/09/30/Ceph_Code_Walkthrough_-_Patrick_Donnelly_-_Metadata_Servers_2020-09-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/30/Ceph_Code_Walkthrough_-_Patrick_Donnelly_-_Metadata_Servers_2020-09-29/","excerpt":"","text":"会议纪要 会议概述 本次会议是一次关于Ceph文件系统（CephFS）代码的详细讲解，由Patrick主讲。会议主要围绕CephFS的元数据服务器（MDS）进行，探讨了MDS的核心组件、代码结构以及关键功能。 主要议题 CephFS代码结构： CephFS的主要代码位于Ceph源码树中，特别是mds目录下。 涉及的主要组件包括MDS本身、客户端目录（client）以及OSD对象缓存器（osdc）。 MDS启动与状态管理： MDS的启动从main函数开始，配置信号处理、解析参数并进行全局初始化。 MDS启动后处于待机状态，等待被分配到CephFS集群中的一个位置。 MDS通过监听新的MDS地图来处理状态转换，如从待机状态到活动状态。 MDS Rank： MDS Rank是一个较新的抽象概念，用于管理MDS在CephFS文件系统中的状态。 处理MDS在故障转移和恢复过程中的状态转换，如重放、重新加入等。 FS Map与MDS Map： 监控器通过FS Map跟踪集群中的所有MDS。 MDS Map记录了MDS的状态、文件系统名称、最大MDS数量等信息。 MDS Server： 处理客户端请求的主要模块，包括客户端重新连接、会话管理以及客户端请求处理。 MDS Locker： 管理分布式锁，确保客户端对元数据的访问权限。 MD Cache： 管理MDS的全局缓存，包括inode、目录片段和子树的管理。 决定事项 会议详细讲解了CephFS的MDS组件及其代码结构，为参与者提供了深入理解CephFS内部工作机制的机会。 后续行动计划 继续定期举行Ceph代码讲解会议，以帮助社区成员更好地理解和贡献Ceph项目。 鼓励参与者在下次会议前阅读相关代码，以便更深入地参与讨论。 其他信息 会议中没有提出具体问题，但鼓励参与者在需要时通过聊天或BlueJeans提出问题。 下次Ceph代码讲解会议将在下个月举行。 会议结束 感谢Patrick的精彩讲解和所有参与者的积极参与。希望大家继续关注和支持Ceph项目。 本次会议纪要由专业的存储领域分布式存储Ceph的研发人员和视频会议字幕总结人员共同完成，确保了内容的准确性和专业性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-09-28","slug":"Ceph_Orchestrator_Meeting_2020-09-28","date":"2020-09-27T16:00:00.000Z","updated":"2020-09-28T16:00:00.000Z","comments":true,"path":"2020/09/28/Ceph_Orchestrator_Meeting_2020-09-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/28/Ceph_Orchestrator_Meeting_2020-09-28/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[列出参会人员] 主要议题： Pull Request 审核时间过长问题 讨论了两个特定的 Pull Request（PR），其中一个已经开放了28天，另一个21天。 提出了是否需要使用“urgent”标签来标记这些需要快速处理的PR。 代码质量和紧急修复的平衡 强调了在保证代码质量的同时，也需要考虑紧急修复的重要性。 提出了对于某些对项目有重大影响的改进，可能需要更快的合并，即使这可能意味着牺牲一些测试和文档的完善。 团队成员的参与和责任 讨论了团队成员在PR审核和测试中的参与度，特别是Red Hat的成员需要更多地参与进来。 提出了建立一个更开放的流程，让更多成员能够参与到测试和审核中，以减轻主要负责人的负担。 测试和文档的改进 讨论了如何改进测试流程和文档，特别是在Ceph项目中如何更好地运行和分析测试。 提出了可能需要一个上游工作坊来教育团队成员如何进行这些测试和分析。 决定事项： 标签使用 决定不使用“urgent”标签，而是通过日常站会来处理紧急的PR。 团队参与 鼓励所有团队成员更多地参与到PR的审核和测试中，特别是Red Hat的成员。 测试和文档改进 计划创建一个详细的文档，指导团队成员如何运行和分析测试，并可能组织一个上游工作坊来进一步培训。 后续行动计划： 文档创建 由[具体负责人]负责创建一个详细的测试和CI流程文档，预计下周完成并在下次会议中展示。 团队培训 计划组织一个上游工作坊，教育团队成员如何进行测试和分析，特别是如何使用Ceph Lab。 团队参与 所有团队成员应定期检查和参与PR的审核和测试，特别是Red Hat的成员需要增加参与度。 会议结束语： 会议在感谢所有参会人员的参与和讨论后结束，并期待在下次会议中看到具体的进展和成果。 会议记录人：[记录人姓名] 会议结束时间：[具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-09-24","slug":"Ceph_Performance_Meeting_2020-09-24","date":"2020-09-24T16:00:00.000Z","updated":"2020-09-24T16:00:00.000Z","comments":true,"path":"2020/09/25/Ceph_Performance_Meeting_2020-09-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/25/Ceph_Performance_Meeting_2020-09-24/","excerpt":"","text":"会议纪要 关键细节 新拉取请求 (Pull Requests): Adam Core Adam提交了一个新的PR，旨在为每个列族 (column family) 提供独立的RocksDB块缓存 (block caches)。 另一个新的PR是关于并发检索设备数据的软卷 (soft volume)，标记为性能相关。 更新拉取请求: 动态级别 (dynamic levels) 在RocksDB中的实现。 RGW中的D3N缓存更改，经过QA测试，但可能需要进一步的工作。 优化放置组 (Placement Group) 移除: Mark提到了一个优化放置组移除的PR，编号为37314，包含一些修复，如重用集合列表的下一个位置和立即从缓存中移除已删除的节点。 RocksDB性能分析: 讨论了RocksDB的写前日志 (write ahead log) 和内存表 (mem table) 的行为，特别是关于如何处理PG日志和对象节点的同步问题。 未来行动计划: Gabi将继续研究RocksDB代码，探索是否可以实现一个可丢弃的内存表。 重新评估和测试移除PG日志对性能的影响。 讨论的主要议题 RocksDB的缓存和写前日志行为: 讨论了如何优化RocksDB的缓存和写前日志，以减少IOPS和延迟。 PG日志的处理: 探讨了PG日志的存储和处理方式，以及如何在不牺牲一致性的前提下提高性能。 决定的事项 继续研究和优化RocksDB的使用: Gabi将继续深入研究RocksDB的内部机制，特别是内存表和写前日志的处理。 重新测试PG日志的影响: 计划重新运行移除PG日志的实验，以评估当前代码的性能影响。 后续行动计划 Gabi的研究工作: Gabi将在接下来的几天内继续研究RocksDB，特别是探索创建一个可丢弃的内存表的可能性。 性能测试: 重新进行性能测试，特别是移除PG日志的实验，以评估当前代码的性能表现。 会议跟进: 下次会议将讨论Gabi的研究进展和性能测试的结果。 结论 本次会议主要讨论了RocksDB的优化和PG日志的处理，确定了Gabi将继续深入研究RocksDB的内部机制，并计划重新进行性能测试以评估移除PG日志的影响。会议还提到了未来可能的改进方向，包括优化内存表和写前日志的处理。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph DocuBetter Meeting 2020-09-24","slug":"Ceph_DocuBetter_Meeting_2020-09-24","date":"2020-09-23T16:00:00.000Z","updated":"2020-09-23T16:00:00.000Z","comments":true,"path":"2020/09/24/Ceph_DocuBetter_Meeting_2020-09-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/24/Ceph_DocuBetter_Meeting_2020-09-24/","excerpt":"","text":"会议纪要 会议日期： 2020年9月24日 参会人员： [记录者姓名] 会议议题： 1. Tree Pane 格式问题 2. API 文档在 docs.com 上的显示问题 3. 文档改进流程的简化 4. 开发者指南的相关问题 会议内容： Tree Pane 格式问题 在 Tracker Issue 47496 中报告了 Tree Pane 的格式问题，该问题在 Ceph 文档议程中被提及。 当窗口变窄或深入到三到四级时，Tree Pane 的边距变得非常窄，每行只能显示标题中的几个字母。 目前尚不清楚如何解决此问题，但需要与 David 讨论。 API 文档在 docs.com 上的显示问题 API 文档目前未在 docs.com 上显示。 需要找到能够使自动生成的 Ceph API 文档与更新后的搜索功能协同工作的人员。 文档改进流程的简化 提出了一个想法，即不要求每个小的文档改进都创建一个 Tracker 票证。 建议将所有此类改进统一在 GitHub 下进行管理，以便未来可以搜索和查找。 认为这种文化上的改变可以增加社区的参与度。 开发者指南的相关问题 有一些关于开发者指南的小改动和具体问题需要与 Neha 和 Josh 讨论。 这些问题涉及工作流程是否需要更新。 后续行动计划： - 与 David 讨论 Tree Pane 格式问题的解决方案。 - 寻找能够解决 API 文档在 docs.com 上显示问题的人员。 - 推动简化文档改进流程的提案，并在未来进一步讨论和实施。 - 与 Neha 和 Josh 讨论开发者指南的相关问题，并确定是否需要更新工作流程。 会议结束： [记录者姓名] 确认会议内容并结束会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2020-09-23","slug":"Ceph_Science_Working_Group_2020-09-23","date":"2020-09-23T16:00:00.000Z","updated":"2020-09-24T16:00:00.000Z","comments":true,"path":"2020/09/24/Ceph_Science_Working_Group_2020-09-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/24/Ceph_Science_Working_Group_2020-09-23/","excerpt":"","text":"会议纪要 会议概述 本次会议是九月的一个小型聚会，由一群使用Ceph的研究系统管理员或大型集群辅助管理员组成，旨在讨论与Ceph相关的任何话题。会议鼓励参与者自由发言和提出讨论话题。 主要议题与讨论内容 近期故障报告 一位参与者报告了最近的一次长达四小时的全面停电事件，由于UPS仅能维持20分钟，整个数据中心宕机。其中两个集群在恢复后正常启动，但第三个近10PB的大型集群遇到了问题，需要手动干预才能启动。 Ceph Bug讨论 讨论了Ceph版本14.2.11和Octopus中的一些问题，特别是OSD map trimming逻辑的错误，该错误导致过早的trimming。此外，还提到了文件存储OSD在PG迁移后未能自动清理的问题，导致磁盘使用率异常高。 Octopus版本迁移经验 有参与者分享了从Luminous升级到Nautilus的经验，特别是关于S3网关的升级。讨论了升级过程中可能遇到的问题，特别是关于区域设置和客户端兼容性问题。 OpenStack与S3集成 讨论了如何在OpenStack环境中集成S3，特别是如何处理用户通过OpenStack管理S3凭证和配额的需求。提到了通过同步Keystone中的EC2凭证到Ceph网关来优化性能的方法。 大容量文件管理问题 讨论了在处理包含大量小文件的S3 bucket时可能遇到的管理和性能问题，特别是在进行resharding操作后，列表操作性能下降的问题。 Ceph-CSI使用情况 讨论了Ceph CSI在Kubernetes环境中的使用情况，特别是与RBD和CephFS的集成。提到了配置选项和可能的兼容性问题。 决定事项 对于Ceph版本14.2.11和Octopus中的已知问题，建议社区成员关注并参与修复。 对于大容量文件管理问题，建议进一步研究和测试可能的优化措施。 后续行动计划 继续监控和报告Ceph版本中的bug和性能问题。 对于S3和OpenStack集成问题，建议进一步研究和分享最佳实践。 对于Ceph-CSI的使用，建议社区成员分享更多实际使用经验和配置建议。 会议结束 会议在讨论了所有预定议题后结束，下一次会议计划在两个月后的11月25日举行。会议组织者将提前一周发送会议通知。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD Weekly 2020-09-23","slug":"Ceph_Crimson_SeaStor_OSD_Weekly_2020-09-23","date":"2020-09-22T16:00:00.000Z","updated":"2020-09-23T16:00:00.000Z","comments":true,"path":"2020/09/23/Ceph_Crimson_SeaStor_OSD_Weekly_2020-09-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/23/Ceph_Crimson_SeaStor_OSD_Weekly_2020-09-23/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统中的结构测试与修复讨论 会议时间：[具体日期] 参会人员：[具体人员名单] 主要讨论内容： 结构测试与修复进展 上周工作重点是结构测试的修复。 讨论了在处理对象上下文时，请求执行中的间隔变化问题。 提出了引入暂停和恢复语义（suspend and resume semantic）在tri-mutex中，以解决中断请求的顺序问题。 中断请求处理 讨论了中断请求在tri-mutex中的处理方式，特别是如何确保中断请求能够重新获取锁。 强调了在PG间隔变化时，所有请求需要重新排队（re-queue），而不是简单地重新获取锁。 请求处理流程 详细讨论了IO请求的处理流程，包括排队、获取锁、读取对象上下文等步骤。 强调了在PG间隔变化时，所有请求需要从处理流程的起点重新开始。 内存状态管理 讨论了在PG间隔变化时，如何处理内存中的对象上下文和状态。 决定在PG间隔变化时，所有请求需要丢弃所有内存状态，重新从起点开始处理。 垃圾收集（Garbage Collection） 讨论了Ceph存储系统中的垃圾收集机制，包括如何管理空间和避免大量垃圾收集操作。 介绍了两个可调参数：目标空闲空间和使用空间与不可用空间的比率。 其他工作进展 讨论了中断可 futures 的调试进展。 介绍了GH对象的集成和随机插入的单元测试进展。 决定事项： 所有请求在PG间隔变化时需要重新排队，从处理流程的起点重新开始。 在PG间隔变化时，丢弃所有内存状态，避免使用过时的对象上下文和状态。 继续优化垃圾收集机制，确保系统空间的有效管理。 后续行动计划： 继续进行结构测试的修复工作，确保请求处理的正确性和顺序。 完成中断可 futures 的调试，并提交相关PR。 完成GH对象的集成和单元测试，修复相关bug。 继续优化垃圾收集机制，确保系统的稳定性和性能。 备注： 会议中提到的“tri-mutex”、“PG interval change”、“re-queue”等关键词是Ceph存储系统中的专业术语，需要特别注意其在系统中的具体含义和应用。 会议结束时间：[具体时间] 下次会议预告：[具体日期和时间] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD Weekly 2020-09-16","slug":"Ceph_Crimson_SeaStor_OSD_Weekly_2020-09-16","date":"2020-09-15T16:00:00.000Z","updated":"2020-09-16T16:00:00.000Z","comments":true,"path":"2020/09/16/Ceph_Crimson_SeaStor_OSD_Weekly_2020-09-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/16/Ceph_Crimson_SeaStor_OSD_Weekly_2020-09-16/","excerpt":"","text":"会议纪要 关键细节 Thresha Totology Basis Threat Test: 上周仍在进行相关工作，最新问题涉及BlueStore中的一个段错误。 DIO Errors PR: David Zaffman已审核并批准，但仍有需要解决的关注点。 Snapshots in CStore: 讨论了在CStore中支持快照的可能性，需要进一步学习和讨论。 Test Case for Tree and Debug: 正在编写测试用例，并考虑使用reader's bench重现问题。 Scrubbing: 完成了昨天的scrubbing工作，有一个测试案例需要修复。 GC Stuff Debugging: 正在调试GC相关问题，预计几天内完成，之后将打包成PR。 Transaction Manager Layer: 正在进行性能测试，预计会有很多改进空间。 HSE Implementation: 阅读了HSE的实现，计划在详细测试后评估其CPU开销。 Piafano 3: 已经发送了初始版本，正在确保架构和设计决策的正确性。 讨论的主要议题 BlueStore中的段错误: 讨论了如何处理和重现该问题。 CStore中的快照支持: 讨论了是否可以采用不同的方法来支持快照。 Transaction Manager Layer的性能: 讨论了当前实现的性能问题和未来的改进方向。 HSE的实现和设计: 讨论了HSE的两个组件和其API的设计。 决定的事项 BlueStore段错误: 建议查看崩溃时的日志信息，而不是尝试重现。 CStore快照支持: 需要进一步学习和讨论，以决定是否采用不同的方法。 Transaction Manager Layer: 确认可以开始性能测试，尽管性能可能不佳。 后续的行动计划 BlueStore段错误: 查看日志信息，并考虑使用新引入的功能在笔记本上运行测试。 CStore快照支持: 深入研究并准备后续讨论。 Transaction Manager Layer: 进行性能测试并准备改进。 HSE实现: 继续阅读并准备性能测试。 Piafano 3: 继续完善并确保设计正确性。 其他事项 一位成员将从周四开始暂时离线，专注于数据库系统考试的复习。 会议结束 会议参与者确认无其他事项，会议结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-09-14","slug":"Ceph_Orchestrator_Meeting_2020-09-14","date":"2020-09-13T16:00:00.000Z","updated":"2020-09-14T16:00:00.000Z","comments":true,"path":"2020/09/14/Ceph_Orchestrator_Meeting_2020-09-14/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/14/Ceph_Orchestrator_Meeting_2020-09-14/","excerpt":"","text":"会议纪要 会议概要 会议主题: 今日的协调器会议 参会人员: 部分核心成员 会议时间: 今日 主要议题 新拉取请求（Pull Request）讨论 提出者: Paul 内容: 引入adm daemon在所有主机上的持久性，编号为130130。 目的: 解决从主机获取信息所需时间过长的问题，提升协调器和仪表板的性能。 讨论: 该请求目前仅限于收集主机上的硬件信息。 未来可能扩展为更全面的fadm diamond功能。 讨论了设计架构和性能问题，特别是SSH连接的效率和持久性问题。 文档站点问题 提出者: Zach 内容: 当前有两个不同的文档站点，一个在readthedocs.io，另一个在docs.conf。 问题: docs.conf的搜索功能有限，只能搜索第一个字符串。 readthedocs.io提供了更好的搜索功能，但没有API文档的自动生成。 讨论: 需要找到一个解决方案，既能提供良好的搜索功能，又能自动生成API文档。 提出了将API文档源代码提交到源代码树的建议，但存在维护成本问题。 决定事项 新拉取请求: 继续讨论和优化，确保其设计符合当前需求，同时考虑未来的扩展性。 文档站点: 需要进一步讨论和寻找解决方案，以整合搜索功能和API文档生成。 后续行动计划 新拉取请求: 继续与Paul合作，优化请求内容。 设计高层次的工作流程文档，明确需求和接口。 文档站点: 在领导团队会议上进一步讨论。 探索更有效的解决方案，以改善文档站点的搜索和API文档生成功能。 其他讨论 性能和可扩展性: 讨论了cephadm和仪表板的性能问题，特别是SSH连接的管理和优化。 设计文档: 强调了设计文档的重要性，以确保项目的长期维护和改进。 会议结束 下次会议: 下次同步会议再见。 本次会议重点讨论了新拉取请求的设计和性能问题，以及文档站点的整合问题。会议强调了设计文档的重要性，并提出了后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-09-10","slug":"Ceph_Performance_Meeting_2020-09-10","date":"2020-09-10T16:00:00.000Z","updated":"2020-09-10T16:00:00.000Z","comments":true,"path":"2020/09/11/Ceph_Performance_Meeting_2020-09-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/11/Ceph_Performance_Meeting_2020-09-10/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：Josh, Kifu, Igor 等 主要议题： Ceph项目进展更新 讨论和优化Ceph中的OSD异步恢复机制 改进Ceph中的BlueStore删除流程 讨论内容： Josh 报告了关闭和合并的PR（Pull Request）情况，特别是关于off-monitor PR的进展。 讨论了OSD异步恢复机制，目前考虑保持默认设置，但仍有讨论空间。 发现之前的测试可能因错误的crash规则导致结果不可靠，需要等待进一步的测试结果。 Kifu 提到了优化BlueStore的PR，该PR曾被关闭后又重新打开，但目前没有新的进展。 重点讨论： Igor 详细介绍了Ceph中删除操作的当前流程和存在的问题，包括删除速度慢、空间回收时间长等。 提出了几种改进方案，包括调整删除任务的休眠时间、使用更高效的数据库操作等。 展示了新的删除流程设计，通过先回收空间再进行数据库记录的删除，以提高效率。 进行了性能测试，对比了不同删除策略的性能，包括原始删除流程和改进后的流程。 决定事项： 继续讨论和优化OSD异步恢复机制，特别是关于默认设置的讨论。 进一步测试和验证Igor提出的删除流程改进方案，包括性能和稳定性的测试。 计划在下一次会议继续讨论Ceph的优化和改进，特别是关于BlueStore的删除流程。 后续行动计划： Igor 将继续进行删除流程的性能测试和优化，特别是关于使用删除范围功能的测试。 团队成员 将继续关注和参与Ceph项目的PR审查和讨论，确保项目的稳定性和性能。 下一次会议 将继续讨论Ceph的优化和改进，特别是关于BlueStore的删除流程和其他相关议题。 备注： Igor 将分享他的测试结果和幻灯片，供团队成员进一步分析和讨论。 会议时间 已充分利用，下一次会议将继续深入讨论Ceph的优化和改进。 会议结束时间：[具体时间] 下次会议预定时间：[具体日期和时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-09-09","slug":"Ceph_Crimson_SeaStor_OSD_2020-09-09","date":"2020-09-09T16:00:00.000Z","updated":"2020-09-10T16:00:00.000Z","comments":true,"path":"2020/09/10/Ceph_Crimson_SeaStor_OSD_2020-09-09/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/10/Ceph_Crimson_SeaStor_OSD_2020-09-09/","excerpt":"","text":"会议纪要 关键细节 会议开始时间: 未明确记录，但根据内容推断为近期。 参会人员: 包括但不限于Sam、Kofu等。 会议形式: 视频会议，部分参会者遇到网络问题。 讨论的主要议题 Ratio Test 进展: 讨论了Ratio Test的失败情况，分为自动响应失败和恢复阶段跟踪问题。 增加了功能以在转储前符号化电池信息，以便直接获取函数名而不是地址。 Subversion Submodule 更新: 更新了Subversion子模块到最新的上游版本，希望放弃自定义的分支。 Map Tree Code 调试: Kofu报告了在调试Map Tree代码方面的进展。 Journal Write Out Stream 元数据: Sam正在编写代码，以便在日志写入流中包含足够的元数据，用于识别逻辑地址和类型。 Interruptable Future Wrapper: 正在开发一个可中断的未来包装器，目前仍在进行中。 BlueJeans 应用升级问题: 讨论了从BlueJeans应用版本1升级到版本2的问题，以及在Fedora 32上的兼容性。 OSD通信压缩: 提到一个实习生正在研究压缩OSD通信，并寻求帮助。 决定的事项 将继续使用现有的tick方法来处理OSD map的订阅问题。 将更新PR以使用tick方法添加新的定时器。 将处理BlueJeans应用在Fedora 32上的兼容性问题。 将帮助实习生解决OSD通信压缩的问题。 后续行动计划 完成并提交符号化电池信息的API。 继续调试Map Tree代码。 完成Journal Write Out Stream元数据的编码工作。 完成Interruptable Future Wrapper的开发。 解决BlueJeans应用的兼容性问题。 协助实习生解决OSD通信压缩的问题。 其他备注 会议中存在一些背景噪音，但不影响主要讨论。 部分参会者遇到网络问题，建议后续会议前检查网络连接。 结束语 会议在讨论了各项议题和后续行动计划后结束，参会者表示将按计划推进各自的工作，并期待下次会议的进展报告。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2020-09-05","slug":"Ceph_Docubetter_Meeting_2020-09-05","date":"2020-09-09T16:00:00.000Z","updated":"2020-09-10T16:00:00.000Z","comments":true,"path":"2020/09/10/Ceph_Docubetter_Meeting_2020-09-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/10/Ceph_Docubetter_Meeting_2020-09-05/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [主持人]、[参会者] 主要议题： hacking.rst 集成到开发者指南 [主持人] 本周主要工作是将包含2300行代码的 hacking.rst 集成到开发者指南中。 遇到了文档构建问题，经过与 Sebastian 的合作，发现特定提交（commit）4ea54664 可以解决构建问题。 该问题已解决，hacking.rst 已成功集成，后续可能需要进一步调整。 文档构建问题 发现了其他PR中的构建问题，特别是与 prompt 指令相关的问题。 这些问题将在后续的非正式会议中进一步讨论和解决。 入门指南与部署指南 [主持人] 对入门指南和部署指南的看法有所改变，认为部署指南更为实用。 尽管如此，仍计划推进入门指南的发布，特别是针对新手。 网站界面更新 讨论了网站 landing page 的更新，包括添加三个按钮（tracker、dev guide、install guide）。 由于 Sebastian 对按钮大小的意见，该PR目前停滞，需要进一步调整和拆分。 文档贡献流程优化 与 Brad Hubbard 讨论了如何优化从远程分支拉取、修改并推送回原分支的流程。 该流程有助于处理格式不规范但内容有价值的贡献。 视频教程的想法 [主持人] 提出了制作视频教程的想法，特别是针对入门指南的安装步骤。 视频长度控制在47秒，强调简洁和实用。 决定事项： hacking.rst 已成功集成到开发者指南，后续可能需要进一步调整。 网站 landing page 的更新需要进一步讨论和调整按钮大小。 入门指南和部署指南的发布将继续推进，特别是针对新手。 视频教程的想法将在线下进一步讨论。 后续行动计划： [主持人] 将发送关于 hacking.rst 的邮件，鼓励更多人参与贡献。 继续解决文档构建问题，特别是与 prompt 指令相关的问题。 调整并拆分网站 landing page 的PR，以适应不同需求。 进一步讨论和优化视频教程的想法，确保内容简洁实用。 会议结束时间： [具体时间] 下次会议时间： [具体日期] 记录人： [记录人姓名] 审核人： [审核人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-09-08","slug":"Ceph_Orchestrator_Meeting_2020-09-08","date":"2020-09-07T16:00:00.000Z","updated":"2020-09-08T16:00:00.000Z","comments":true,"path":"2020/09/08/Ceph_Orchestrator_Meeting_2020-09-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/08/Ceph_Orchestrator_Meeting_2020-09-08/","excerpt":"","text":"会议纪要 会议概要 日期: 2023年8月 参与者: 团队成员 会议主题: 讨论Ceph项目的更新、问题和改进 主要议题 Ceph版本更新 15.2.5版本发布: 预计很快发布，解决了从旧版本升级时OSD支持模块导致的健康警告问题。 QA问题讨论 问题编号47336: 讨论了由Paul创建的PR引起的测试套件失败问题。具体错误为“unexpected argument --y”，需要进一步调查。 优化PR审查 优化PR: Paul提交了一个大型优化PR，旨在改进Ceph的cfdmls实现，提高效率，但需要团队审查。 文件生成问题 sudoers文件问题: 讨论了关于fadm用户和sudoers文件的生成问题，涉及包模式和root模式的使用，决定移除相关代码。 Dashboard改进 Dashboard与Cephadm交互: 讨论了Dashboard与Cephadm的集成问题，提出了修复方案。 文档构建错误 文档构建错误: 讨论了在构建包含2300行 restructuredText 文件的文档时遇到的错误，需要进一步的技术调查。 决定事项 15.2.5版本发布: 团队确认将尽快发布15.2.5版本，解决已知问题。 QA问题调查: 团队将深入调查编号47336的问题，以确定根本原因。 优化PR审查: 团队成员被要求审查Paul提交的优化PR，确保其对现有系统的影响最小。 文件生成问题: 决定移除sudoers文件生成相关代码，简化安装过程。 Dashboard改进: 确认将修复Dashboard与Cephadm集成的问题，并进行测试。 后续行动计划 发布15.2.5版本: 团队将完成最后的测试和文档更新，确保版本按时发布。 调查QA问题: 指定团队成员负责深入调查编号47336的问题，并提出解决方案。 审查优化PR: 所有相关团队成员需在近期内完成对优化PR的审查，并提供反馈。 文档错误修复: 指定技术专家负责调查并修复文档构建错误，确保文档的正确性和可用性。 其他 会议时间调整: 确认下次会议时间适合北半球参与者。 团队成员休假回归: 提醒团队成员注意新休假回归的同事，确保工作顺利交接。 结束语 会议在简洁高效的氛围中结束，团队成员对即将到来的任务和挑战充满信心。下次会议将继续跟进上述行动计划的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2020-09-02","slug":"Ceph_Developer_Monthly_2020-09-02","date":"2020-09-03T16:00:00.000Z","updated":"2020-09-04T16:00:00.000Z","comments":true,"path":"2020/09/04/Ceph_Developer_Monthly_2020-09-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/04/Ceph_Developer_Monthly_2020-09-02/","excerpt":"","text":"会议纪要 会议主题 本次会议主要围绕如何改进诊断、分析和修复Ceph存储系统中的故障进行头脑风暴。 讨论的主要议题 故障诊断与分析工具的改进： 讨论了如何更好地收集和分析故障日志，特别是对于长时间运行的任务和超时任务。 提到了使用新的调度器（dispatcher）来改善任务管理和日志收集。 探讨了如何通过改进日志系统和增加故障信息的详细度来简化故障排查过程。 故障排查工具和技术： 讨论了使用Sentry和Century等工具来跟踪故障发生的时间和频率。 提到了可能需要改进的故障排查流程，包括如何更有效地重现和调试故障。 日志分析和可视化工具： 讨论了使用lnav等工具来更好地管理和分析日志文件。 探讨了如何通过改进日志格式和内容来提高故障排查的效率。 特定领域的故障排查： 讨论了Crimson和Cephalium等特定组件的故障排查挑战和可能的改进措施。 决定的事项 确认了新的调度器（dispatcher）的实施和测试进展，预计将很快部署。 决定进一步研究和实施日志分析和故障排查工具的改进。 确认了需要对特定组件如Crimson的故障排查流程进行优化。 后续行动计划 继续测试和部署新的调度器（dispatcher）。 研究和实施日志分析工具的改进，如lnav的使用。 对特定组件如Crimson的故障排查流程进行优化，包括可能的信号处理改进。 定期回顾和更新故障排查流程和工具，确保其持续有效性。 其他讨论点 讨论了如何通过改进日志内容和格式来提高故障排查的效率。 探讨了如何通过增加故障信息的详细度来简化故障排查过程。 讨论了如何通过改进日志系统和增加故障信息的详细度来简化故障排查过程。 会议总结 本次会议是一个非常富有成效的讨论，产生了许多新的想法和改进措施。后续将继续跟进这些想法的实施，并定期回顾和更新故障排查流程和工具，确保其持续有效性。感谢所有参与者的积极参与和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-09-02","slug":"Ceph_Performance_Meeting_2020-09-02","date":"2020-09-02T16:00:00.000Z","updated":"2020-09-03T16:00:00.000Z","comments":true,"path":"2020/09/03/Ceph_Performance_Meeting_2020-09-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/03/Ceph_Performance_Meeting_2020-09-02/","excerpt":"","text":"Ceph 开发会议纪要 会议概要 本次会议主要讨论了Ceph存储系统中的多个技术议题，包括新的Pull Request（PR）、BlueStore的性能优化、OSD（Object Storage Daemon）的CPU效率提升以及未来可能的改进方向。 主要讨论议题 1. 新的Pull Request (PR) PR1: 来自Josh的PR旨在加速Monitor中的caps和cap更新。Joao已进行评审，默认行为未改变，仅在特定情况下提供跳过解析的选项。 PR2: 修改OSD异步恢复最小开销的默认值。该PR建议降低阈值以增加异步恢复，基于Red Hat内部测试，发现默认值100在某些RGW工作负载下导致大量异步恢复。 2. BlueStore性能优化 讨论了BlueStore在处理大量对象创建和删除时的性能瓶颈，特别是使用RocksDB时的解析和锁定问题。 提出了使用更大缓冲区减少写放大和尝试将部分数据移出RocksDB的建议。 3. OSD CPU效率提升 讨论了如何减少OSD的CPU使用，特别是在处理大量小对象时的效率问题。 提出了从字符串操作转向二进制格式操作的建议，以减少动态内存分配和提高比较效率。 4. 未来改进方向 讨论了可能的硬件优化，如使用Optane DIMMs，以及软件层面的改进，如简化数据结构和减少不必要的灵活性。 提出了对BlueStore和OSD进行更深入的性能分析和优化，特别是在处理小对象和频繁更新的场景。 决定事项 继续探讨和实验BlueStore的性能优化，特别是在减少RocksDB的使用和优化OSD的CPU效率方面。 计划在下一次会议中进一步讨论OSD的内存使用优化和BlueStore的结构简化。 后续行动计划 更新现有文档，总结本次会议的讨论点和未来研究方向。 准备下一次会议的讨论主题，包括具体的性能优化实验和可能的技术改进。 结论 本次会议为Ceph存储系统的未来发展提供了宝贵的讨论和建议，特别是在性能优化和CPU效率提升方面。期待下一次会议的进一步讨论和成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson / SeaStor OSD 2020-09-02","slug":"Ceph_Crimson_SeaStor_OSD_2020-09-02","date":"2020-09-01T16:00:00.000Z","updated":"2020-09-02T16:00:00.000Z","comments":true,"path":"2020/09/02/Ceph_Crimson_SeaStor_OSD_2020-09-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/02/Ceph_Crimson_SeaStor_OSD_2020-09-02/","excerpt":"","text":"会议纪要 关键细节 Tesla 策略测试: 上周在 Tesla 策略测试方面遇到了新的失败案例，已粘贴到聊天窗口供检查。 代码清理: 创建了 PR 进行恢复相关代码的清理工作，并尝试让 Crimson 通过两个测试：test_readers.py 和 test_stiff_circuit_output。 Excitement Trim 更新: Excitement Trim 已经更新了 force，请尽快审查并批准。 调试工作: 正在对旧的 map 和 tree 代码进行调试，功能已基本完成，正在进行测试案例的调试。 Crimson 焦点: 主要专注于卸载 RGW 中的 on-map 内容，但也关注 Crimson 的审查工作，特别是 search_one's_interruptable_elevator。 代码阅读和文档: 主要在进行代码阅读、审查，并将纸质文档中的图表复制到计算机形式，完成后将分享并操作文档。 工具使用: 使用 Lucidchart 进行图表绘制，已获得许可证。 基本空间会计: 已完成基本空间会计工作，正在进行相关调试，接下来将进行段扫描和清理。 中断改进: 上周仍在改进中断，代码已基本完成，但与 Radic 讨论后发现同时运行 erratic future 和 system future 存在问题，将在会议中讨论。 Hybrid Bar 修复: 上周重现并修复了 Hybrid Bar，已集成到 Ceph 的 osd 实现中，认为这是一个里程碑，并将总结当前状态发送 PR 供审查。 测试失败: 最近在 Unity 的 messenger 系统中发现了一些测试失败，已发送链接进行检查。 中断迭代器讨论: 昨天晚上发布了一个示例问题，讨论了中断迭代器的实现问题，建议将 aerator 重命名为 aerator_and_interrupter，以明确其多重责任。 主要议题 中断迭代器的实现和责任分配: 讨论了中断迭代器的实现问题，包括是否应该将中断功能集成到 aerator 中，以及如何处理多个请求和不同类型的 future 混合使用的问题。 性能和代码复杂性: 讨论了将中断功能集成到 aerator 中的性能影响和代码复杂性，以及是否应该采用更简单的方法，如使用装饰器或构建器来处理中断检查。 决定事项 中断迭代器的实现: 决定采用更简单的方法，如使用装饰器或构建器来处理中断检查，而不是将中断功能集成到 aerator 中。 性能考虑: 尽管存在性能担忧，但决定优先考虑代码的可用性和可维护性，而不是微小的性能提升。 后续行动计划 中断迭代器实现: 将继续探索和实现更简单的中断迭代器方法，如使用装饰器或构建器。 性能测试: 将进行性能测试，以确保新方法的性能影响在可接受范围内。 代码审查和批准: 将继续进行代码审查和批准工作，确保所有更新和修复都能及时合并到主分支。 其他 工具使用: 确认使用 Lucidchart 进行图表绘制，并已获得许可证。 文档更新: 将继续更新和分享文档，确保所有团队成员都能获取最新的信息和指导。 会议结束时，团队成员互相道别，并祝愿大家有一个愉快的一天。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-08-31","slug":"Ceph_Orchestrator_Meeting_2020-08-31","date":"2020-09-01T16:00:00.000Z","updated":"2020-09-02T16:00:00.000Z","comments":true,"path":"2020/09/02/Ceph_Orchestrator_Meeting_2020-08-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/09/02/Ceph_Orchestrator_Meeting_2020-08-31/","excerpt":"","text":"会议纪要 会议主题：Ceph Orchestrator 周会 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题及讨论内容： NFS 集成问题 问题概述：目前存在两个不兼容的 NFS 管理实现，分别在 Dashboard 和 Volumes NFS 模块中。这两个实现基于相同的代码库，但已经分叉到无法并行使用的程度。 主要挑战：需要统一这两个管理代码库，并找到迁移用户从 Nautilus 到 Octopus 的方法。 行动计划：继续讨论并寻找解决方案，可能需要自动化的迁移工具。 ceph.conf 生成问题 问题描述：由 config generate minimal conf 生成的 ceph.conf 文件不完整，无法满足所有边缘案例的需求。 解决方案：提出两种解决方案，一是提供扩展 ceph.conf 的方法，二是改进生成 minimal conf 的功能。 行动计划：希望尽快合并这些解决方案，以提供更灵活的配置管理。 容器中的 PID 1 问题 问题描述：当前 Ceph 容器中的 PID 1 处理不当，导致僵尸进程和无法创建核心文件。 解决方案：建议使用 Docker 和 systemd-nspawn 的 --init 标志来解决这个问题。 行动计划：考虑在某些发行版中默认启用此设置，并在其他发行版中提供安装依赖包的指导。 配置模板问题 问题描述：当前的配置模板硬编码在代码中，无法灵活修改。 解决方案：建议使用配置密钥存储来覆盖这些模板，但存在用户界面复杂和数据结构暴露的问题。 行动计划：继续讨论是否有实际需求来推动这一改变。 Ceph Orchestrator 模块开发 进展：现在可以在不预先创建环境或编译 Ceph 的情况下，直接开始开发 Ceph Orchestrator 模块。 行动计划：鼓励开发者利用这一改进进行模块开发。 Ceph Orchestrator 二进制文件重构 目标：讨论如何逐步重构 Ceph Orchestrator 二进制文件，以提高代码的可维护性和模块化。 行动计划：建议从简化 bootstrap 命令开始，逐步引入类和模块化。 后续行动计划： 继续讨论和解决 NFS 集成问题，特别是迁移用户的问题。 合并并实施 ceph.conf 生成问题的解决方案。 在支持的发行版中默认启用 --init 标志，并在其他发行版中提供安装依赖包的指导。 根据实际需求，决定是否实施配置模板的灵活修改方案。 逐步重构 Ceph Orchestrator 二进制文件，提高代码质量和可维护性。 会议总结： 本次会议主要讨论了 Ceph Orchestrator 相关的多个技术问题和解决方案，涉及 NFS 集成、配置文件生成、容器中的 PID 1 处理、配置模板灵活性以及代码重构等方面。会议确定了后续的行动计划，并鼓励团队成员积极参与到这些改进工作中。 会议结束时间：[具体时间] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-08-28","slug":"Ceph_Performance_Meeting_2020-08-28","date":"2020-08-26T16:00:00.000Z","updated":"2020-08-27T16:00:00.000Z","comments":true,"path":"2020/08/27/Ceph_Performance_Meeting_2020-08-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/27/Ceph_Performance_Meeting_2020-08-28/","excerpt":"","text":"会议纪要 会议概述 本次会议由于主持人迟到，会议开始时人数较少。会议主要讨论了Ceph项目的进展、待处理的Pull Requests（PRs）、以及一些性能相关的问题。 主要议题 PRs更新 本周关闭了一个PR，该PR旨在避免从machine ping一次性刷新过多数据，效果良好。 另一个PR由majianpeng更新，radik批准了减少buffer list重建的更改。 性能回归问题 Igor提到了最近关于性能回归的发现，特别是在某些场景下的改进，可能需要回溯到Octopus版本。 讨论了max blob size的更改原因及其对性能的影响，特别是对搜索范围和压缩的影响。 未来行动计划 计划在下周与Adam和Gabriel讨论关于简化数据结构和减少内存占用的想法。 讨论了关于性能CI的构建，包括使用cbt和jenkins进行自动化测试的可能性。 决定事项 确认了需要进一步讨论和测试的PRs。 确定了下周的会议将讨论数据结构简化和其他相关性能优化。 计划开始构建性能CI，以自动化和标准化性能测试。 后续行动计划 Igor和Mark将撰写关于当前CI系统中性能测试的概述，并发送至开发列表。 继续关注和讨论性能回归问题，并尝试在不同环境中复现。 探索和实施性能CI的构建，以确保性能测试的自动化和一致性。 其他讨论 讨论了关于硬件配置对性能测试的影响，特别是SSD和HDD的使用。 提到了关于压缩和blob size的优化，以及这些更改可能带来的复杂性和潜在影响。 会议结束 会议在讨论了性能测试和CI构建的重要性后结束，主持人因时间限制提前离开。 本次会议虽然人数不多，但讨论的内容非常深入和具体，涉及到了Ceph项目的多个关键技术点和未来的发展方向。通过这次会议，团队对当前的工作有了更清晰的认识，并为接下来的工作制定了具体的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk 2020-08-27: Secure Token Service in Ceph Rados Gateway - Pritha Srivastava","slug":"Ceph_Tech_Talk_2020-08-27_-_Secure_Token_Service_in_Ceph_Rados_Gateway_-_Pritha_Srivastava","date":"2020-08-26T16:00:00.000Z","updated":"2020-08-27T16:00:00.000Z","comments":true,"path":"2020/08/27/Ceph_Tech_Talk_2020-08-27_-_Secure_Token_Service_in_Ceph_Rados_Gateway_-_Pritha_Srivastava/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/27/Ceph_Tech_Talk_2020-08-27_-_Secure_Token_Service_in_Ceph_Rados_Gateway_-_Pritha_Srivastava/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了关于订阅频道、应用程序配置、安全策略以及资源访问控制的相关议题。会议中涉及了多个技术术语和操作流程，旨在优化用户体验和系统安全性。 主要议题 订阅频道与应用程序配置 讨论了如何通过订阅频道获取更新和信息。 涉及应用程序内部配置文件的调整和优化。 安全策略与资源访问控制 探讨了安全策略的实施，包括角色定义和权限管理。 讨论了如何通过策略文件控制资源的访问。 技术细节与操作流程 详细讨论了Websphere、Zoom等技术平台的使用和配置。 涉及用户权限、角色创建和策略文件的定义。 决定事项 确定了订阅频道的推广策略和用户引导流程。 明确了安全策略的实施细节，包括角色和权限的分配。 确定了应用程序配置文件的优化方案。 后续行动计划 继续优化订阅频道的用户体验，增加互动性和信息价值。 完善安全策略，确保系统的稳定性和数据的安全性。 定期更新应用程序配置文件，以适应新的功能需求和技术变化。 关键术语 Websphere Zoom 角色 (Role) 权限 (Permission) 策略文件 (Policy File) 结论 本次会议为后续的技术实施和用户服务提供了明确的方向和操作指南，确保了系统的安全性和用户体验的持续优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-08-09 Ceph Performance Weekly","slug":"2018-08-09_Ceph_Performance_Weekly","date":"2020-08-25T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/26/2018-08-09_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/26/2018-08-09_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 参会人员 Casey Mark Sage Igor Radek Gregor Jason Braddock Shawn Peng Alfredo Ari 会议时间 日期：具体日期未提供 时间：具体时间未提供 主要议题 旧的Pull Request复活 讨论了复活一个旧的Pull Request，该请求涉及重新启动一个复杂的实现，主要关于维护顺序的问题。 Radek的加密工作 Radek介绍了他在加密方面的工作，特别是关于使用低级AES实现的问题，该实现不使用硬件加速。讨论了与设置成本和实际加速之间的关系。 Igor的Tiny Appends Pull Request Igor介绍了他的Tiny Appends Pull Request，该请求涉及在数据库中直接存储小对象，而不是将它们存储在磁盘上。讨论了性能结果和潜在的改进。 EC Partial Stripe Reads 讨论了新的EC Partial Stripe Reads，需要进一步的审查。 RGW Up Tracker优化 讨论了RGW Up Tracker的优化，包括合并的请求和未合并的优化。 MVS Balancer和Blue Store Shard Completions 讨论了MVS Balancer的工作和Blue Store中的Shard Completions，特别是关于性能测试和线程配置的问题。 EDP配置选项和设备模板 讨论了EDP配置选项和设备模板，特别是关于如何简化用户设置和避免配置混乱的问题。 Blue Store的Tiny Writes优化 Igor详细介绍了Blue Store的Tiny Writes优化，包括性能测试结果和不同方法的比较。 决定事项 需要进一步审查和测试EC Partial Stripe Reads。 RGW Up Tracker的优化将继续进行，包括更详细的性能数据。 需要对Blue Store的Tiny Writes进行更深入的性能测试，特别是在实际使用场景中。 对于EDP配置选项和设备模板，决定不引入新的HDD/SSD设置，而是保持现有选项，避免用户混淆。 后续行动计划 对EC Partial Stripe Reads进行详细审查和测试。 继续优化RGW Up Tracker，提供更多性能数据。 对Blue Store的Tiny Writes进行实际使用场景的性能测试，特别是关注RocksDB的compaction负载。 继续讨论和优化EDP配置选项和设备模板，确保用户设置的简化和清晰。 其他讨论 讨论了RocksDB的compaction负载和如何更好地配置RocksDB的存储空间。 讨论了Blue Store的存储配置和如何动态调整数据库卷的大小。 会议结束 会议在感谢所有参与者的贡献后结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson / SeaStor OSD 2020-08-26","slug":"Ceph_Crimson_SeaStor_OSD_2020-08-26","date":"2020-08-25T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/26/Ceph_Crimson_SeaStor_OSD_2020-08-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/26/Ceph_Crimson_SeaStor_OSD_2020-08-26/","excerpt":"","text":"会议纪要 关键细节： 技术进展： 上周主要工作集中在基于技术的测试上，取得了一些进展。 解决了第一个恢复后视图错误，并将相关URL发送到聊天窗口。 报告并执行了一些基本的OSD操作测试，包括对crimson的测试，所有测试均已通过。 代码更新与实现： 根据评论更新了extend map 3。 仍在进行old map tree node的实现工作。 垃圾回收与空间管理： 正在开发垃圾回收功能，使用相同的extent rewrite机制。 计划实施空间计费，以确定哪个段适合进行垃圾回收。 提出了一个简单的内存计数器策略来管理每个段中的活动字节数。 中断处理： 正在调试可中断的擦除未来（interruptible eraser future），发现中断机制比预期复杂。 需要处理中断相关的错误，这需要额外的代码。 集成与测试： 已将aerated future与事务菜单接口集成，并迁移单元测试到Google Test框架。 正在集成cached extent逻辑，并研究lba map和lbht的实现。 潜在的新技术： 讨论了可能的异构存储引擎（如Micron），该引擎可能在未来用于替换现有的存储层。 该技术仍在开发中，特别是异步I/O支持尚未完成。 决定事项： 继续推进垃圾回收和空间管理功能的开发。 解决中断处理中的复杂问题，并确保其正确性。 探索和评估新的存储技术，如Micron，以备未来可能的集成。 后续行动计划： 完成old map tree node的实现。 继续调试和完善中断处理机制。 评估和测试新的存储技术，以确定其是否适合集成到现有系统中。 定期更新和维护extend map 3，确保其符合最新的需求和标准。 其他备注： 会议中提到了网络问题和通信中断，需要确保后续会议的稳定性。 对于新技术的探索，建议保持关注，但不应影响当前的主要开发任务。 结束语 感谢所有参与者的努力和贡献，期待下次会议能看到更多的进展和成果。祝大家工作顺利！","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthrough 2020-08-25: kRBD I/O Flow","slug":"Ceph_Code_Walkthrough_2020-08-25_-_kRBD_I_O_Flow","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Code_Walkthrough_2020-08-25_-_kRBD_I_O_Flow/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Code_Walkthrough_2020-08-25_-_kRBD_I_O_Flow/","excerpt":"","text":"会议纪要：2020年8月Ceph代码走读会议 会议概要 时间：2020年8月 主讲人：Ilya，Ceph维护和内核客户端开发人员 主题：内核RBD驱动程序的映射和解映射以及基本IO流程 讨论内容 内核RBD驱动程序概述 RBD驱动程序位于Linux内核源树的driver/block子目录下，包含一个源文件和一个小头文件。 支持大多数Ceph特性，但不支持基于日志的镜像和所谓的实时迁移。 新引入的基于快照的镜像在Octopus版本中被隐式支持。 依赖模块 RBD驱动程序依赖于另一个内核模块libceph，这是一个简化版的librados库，位于net/ceph子目录下。 libceph实现了认证框架和消息传递协议（如Messenger v1）。 映射和解映射过程 通过sysfs接口进行映射和解映射操作。 映射时，RBD命令行工具构建配置字符串并写入特定属性文件。 解映射时，通过写入设备ID和可选的强制标志来解除映射。 IO处理流程 入口点是rbd_rq函数，该函数由块层调用以处理每个IO请求。 IO请求被转换为RBD代码，并初始化为图像请求。 图像请求可能涉及多个对象请求，因为RBD图像被条带化到多个对象上。 对象映射和父图像处理 读取操作会查询对象映射，如果对象不存在，则处理为空洞。 如果存在父图像，则将对象范围反向映射到父图像并进行读取。 写入状态机 写入操作涉及对象映射更新和从父图像复制数据（如果需要）。 写入状态机处理对象删除和复制操作，确保数据一致性。 决定事项 目前没有计划实现基于日志的镜像和实时迁移功能。 RBD驱动程序将继续优化其IO处理流程和状态机设计。 后续行动计划 继续改进RBD驱动程序的性能和稳定性。 探索和解决与容器使用案例相关的问题。 其他讨论 关于多队列块层和硬件队列数量的讨论。 用户空间与内核空间实现的比较，以及NBD驱动程序的使用场景。 结束语 Ilya感谢大家的参与，并鼓励大家在Ceph邮件列表或通过电子邮件与他联系以获取更多信息。 本次会议详细介绍了Ceph内核RBD驱动程序的工作原理和IO处理流程，为参与者提供了深入的技术洞察，并为进一步的开发和优化工作奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day 2019: What's Coming in Octopus - Sage Weil","slug":"Ceph_Day_2019_-_What_s_Coming_in_Octopus_-_Sage_Weil","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_2019_-_What_s_Coming_in_Octopus_-_Sage_Weil/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_2019_-_What_s_Coming_in_Octopus_-_Sage_Weil/","excerpt":"","text":"会议纪要 会议主题： Ceph 下一个版本 Octopus 的更新介绍 主讲人： Sage Weil 日期： 会议中提到的 Octopus 版本预计在三月发布 关键细节： 1. 发布周期调整： Ceph 项目已调整为 12 个月的发布周期，每年三月发布一个主要版本，以实现更可预测的发布节奏。 2. Octopus 版本重点： - 可用性提升： 引入新的 Orchestrator API，支持 Rook 和 SSH Orchestrator，简化集群管理和文档。 - 质量改进： 强化了 RADOS 的鲁棒性，改进了部分对象恢复、优先级调度和快照修剪等功能。 - 性能优化： 在 BlueStore 前端进行了多项性能改进，包括改进的预取和压缩机制，以及对内存管理的优化。 - 多站点支持： 增强了对多站点复制的支持，特别是在 RBD 和 CephFS 方面，简化了设置过程并引入了基于快照的复制模式。 - 生态系统和社区集成： 加强了与 Kubernetes 的集成，特别是通过 CSI 和 Rook 项目，以及改进了与 Samba 和 NFS 的集成。 讨论的主要议题： - 可用性和用户体验： 讨论了如何通过新的 API 和改进的仪表板来提升用户体验。 - 质量和稳定性： 强调了持续改进 Ceph 的质量和稳定性，包括通过遥测和崩溃报告来收集数据以改进系统。 - 性能和扩展性： 讨论了如何通过优化存储后端和改进的内存管理来提高性能。 - 多站点和灾难恢复： 探讨了如何通过增强的多站点功能来支持全球分布的数据管理和灾难恢复。 决定的事项： - 发布策略： 确定每年三月发布一个主要版本，以实现更可预测的发布节奏。 - Octopus 版本重点： 确认 Octopus 版本将重点关注可用性、质量、性能、多站点支持和生态系统集成。 后续行动计划： - 开发和测试： 继续开发和测试 Octopus 版本的新功能和改进。 - 文档更新： 更新文档以反映新的 Orchestrator API 和改进的安装步骤。 - 社区反馈： 鼓励社区成员开启遥测功能并提供反馈，以帮助改进系统。 其他备注： - 社区和生态系统： 强调了与 Kubernetes 和其他社区项目的紧密合作，以及对 Samba 和 NFS 集成的持续改进。 - 未来展望： 讨论了 Ceph 的未来发展方向，包括对新硬件的支持和更高级的多站点功能。 会议结束： 会议在讨论了 Ceph 的未来发展方向和 Octopus 版本的重点后结束，随后进行了短暂的休息。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Ceph Supporting Genetic Research at Wellcome Sanger Institute - Matthew Vernon","slug":"Ceph_Day_CERN_2019_-_Ceph_Supporting_Genetic_Research_at_Wellcome_Sanger_Institute_-_Matthew_Vernon","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Ceph_Supporting_Genetic_Research_at_Wellcome_Sanger_Institute_-_Matthew_Vernon/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Ceph_Supporting_Genetic_Research_at_Wellcome_Sanger_Institute_-_Matthew_Vernon/","excerpt":"","text":"会议纪要 会议主题：Ceph在遗传学研究中的应用 主讲人：Dr. Vernon 会议时间：[具体时间] 会议地点：[具体地点] 会议内容总结： 背景介绍 Dr. Vernon在英国剑桥外的Sanger研究所工作，该研究所是全球领先的基因组研究和基因测序中心。 研究所拥有约50PB的数据存储需求，主要使用LSF集群进行批量计算，并提供Lustre作为快速临时存储。 Ceph的引入与应用 2016年，研究所开始使用Ceph，最初部署在三个服务器上，提供3PB的原始容量。 Ceph主要用于支持OpenStack，提供更灵活的计算环境，特别是通过Ceph的RGW（RADOS Gateway）提供S3服务，结果非常受欢迎。 Ceph的扩展与管理 随着需求增长，Ceph集群迅速扩展，到2017年底已达到18PB的容量。 使用Ceph Ansible进行集群管理，确保配置的一致性和自动化。 引入了HAProxy来优化RGW服务的性能和可靠性，特别是处理大量并发连接和空闲连接的问题。 挑战与解决方案 面临的主要挑战包括大规模删除操作（如删除包含7000万个对象的S3桶）和用户尝试将S3用作POSIX文件系统的问题。 通过改进Ceph的删除命令和引入HAProxy来解决这些问题，提高了服务的稳定性和性能。 未来展望 计划增加专门的RGW硬件，以进一步优化性能。 继续支持UK BioBank等大型项目，预计将处理更多的基因组数据。 决定事项： 继续使用和扩展Ceph集群，优化RGW服务。 引入专门的硬件和进一步的软件优化，以应对大规模数据处理的需求。 后续行动计划： 实施硬件升级，增加专门的RGW服务器。 持续监控和优化Ceph集群的性能，确保服务的稳定性和可靠性。 探索更多Ceph在基因组研究中的应用场景，以支持更多的科学研究需求。 会议结束： 会议在Dr. Vernon回答了几个问题后结束，感谢所有参与者的积极参与。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Ceph at the Flatiron Institute - Andras Pataki","slug":"Ceph_Day_CERN_2019_-_Ceph_at_the_Flatiron_Institute_-_Andras_Pataki","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Ceph_at_the_Flatiron_Institute_-_Andras_Pataki/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Ceph_at_the_Flatiron_Institute_-_Andras_Pataki/","excerpt":"","text":"会议纪要 会议主题：Flatiron Institute的Ceph存储系统介绍与经验分享 主讲人：Andres Pataki 会议概要： Andres Pataki来自Simon西班牙Flatiron研究所，介绍了Flatiron研究所的背景、Ceph存储系统的使用情况、技术细节、性能表现、硬件与软件挑战以及未来展望。 关键细节： Flatiron研究所背景： Flatiron研究所是Simons基金会的一个研究部门，由Simons家族资助，该家族在对冲基金行业取得了巨大成功。 研究所的使命是通过计算手段推进科学研究。 研究所位于纽约市曼哈顿中城，靠近Flatiron大楼，拥有约150名科学家，涉及天体物理学、生物学、量子化学和数学等多个领域。 Ceph存储系统使用情况： 研究所使用Ceph存储系统处理多种计算任务，包括基因组数据、早期宇宙的MPI模拟等。 集群规模：约40,000个核心，数百个GPU，存储空间约30PB。 使用Ceph的FS（文件系统）侧，主要因为传统代码不支持对象存储。 技术细节与性能： Ceph的恢复机制非常高效，特别是在处理多重故障时。 通过CRUSH算法，Ceph能够并行恢复数据，大大缩短了恢复时间。 性能测试显示，Ceph集群在处理大量数据时表现出色，但小文件性能仍有待提升。 硬件与软件挑战： 硬件方面，早期购买的NAS级硬盘存在数据 silently corrupted 的问题。 网络方面，早期40G接口存在丢包问题。 软件方面，从Hammer版本升级到Mimic，并计划升级到Nautilus。 经验与教训： 硬件测试至关重要，早期硬件问题导致数据损坏。 Ceph的滚动升级策略有效，未导致系统中断。 灾难恢复案例显示，Ceph的高冗余模型确保了数据安全。 未来展望： 小文件性能改进是当前的主要挑战。 考虑引入闪存存储，关注Ceph的Crimson项目。 探索多站点支持，以便在不同地理位置之间实现统一文件系统。 决定事项： 继续关注并测试Ceph的新版本和功能。 优化小文件性能，考虑引入闪存存储。 探索多站点支持，以实现更广泛的存储部署。 后续行动计划： 定期进行硬件和软件测试，确保系统稳定性。 持续监控和优化Ceph集群的性能。 与Ceph开发团队保持沟通，获取早期支持和修复。 结论： Flatiron研究所通过使用Ceph存储系统，成功支持了多个科学研究项目，尽管面临硬件和软件挑战，但通过持续的优化和升级，确保了数据的安全和系统的稳定运行。未来，研究所将继续探索Ceph的新功能和优化方案，以满足不断增长的计算和存储需求。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: CephFS: looking for the Swiss Army knife of POSIX filesystems - Mattia Belluco","slug":"Ceph_Day_CERN_2019_-_CephFS_-_looking_for_the_Swiss_Army_knife_of_POSIX_filesystems_-_Mattia_Belluco","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_CephFS_-_looking_for_the_Swiss_Army_knife_of_POSIX_filesystems_-_Mattia_Belluco/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_CephFS_-_looking_for_the_Swiss_Army_knife_of_POSIX_filesystems_-_Mattia_Belluco/","excerpt":"","text":"会议纪要 会议主题：Ceph文件系统（CephFS）在HPC环境中的应用与挑战 主讲人：Matteo Bellucco 会议时间：下午 会议地点：苏黎世大学 会议内容概述： Matteo Bellucco介绍了苏黎世大学在HPC环境中使用CephFS的经验，包括存储系统的需求、选择CephFS的原因、测试过程、生产部署以及未来的计划。 讨论的主要议题： 存储系统的需求： POSIX兼容性 可靠性（RAID 6） 可扩展性和可伸缩性 性能 成本效益（避免昂贵的许可证） 附加需求：配额支持、灵活性、避免单点性能下降等 选择CephFS的原因： 长期使用Ceph作为OpenStack部署的后端存储 Ceph的可靠性和可扩展性 Ceph Luminous版本的丰富功能，特别是支持覆盖的复活池和纠删码策略 测试过程： 使用小型测试床进行初步测试 遇到的问题包括ZLO元数据访问性能问题、缓存压力响应失败等 解决策略包括增加元数据池的存储空间、升级到Luminous版本等 生产部署： 部署了新的Ceph集群，包括三个监控节点和120个SATA硬盘 使用NVMe作为RocksDB和元数据池的存储 遇到的问题包括硬件不足、配额支持的实现等 未来的计划： 简化文件系统设置，利用CephFS的多重挂载支持 增加更激进的纠删码策略和压缩，减少成本 提供用户可访问的定期快照，以防止数据丢失或修改 决定的事项： 选择CephFS作为HPC环境的存储解决方案 部署新的Ceph集群，并逐步解决遇到的问题 未来将简化文件系统设置，提高系统的容错性和成本效益 后续行动计划： 继续优化CephFS的配置和性能 增加更多的节点以扩展存储能力 实施定期快照功能，提高数据安全性 会议结束语： Matteo Bellucco总结了CephFS在HPC环境中的应用经验，并欢迎与会者提出问题。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Ceph in Compute Canada - Mike Cave","slug":"Ceph_Day_CERN_2019_-_Ceph_in_Compute_Canada_-_Mike_Cave","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Ceph_in_Compute_Canada_-_Mike_Cave/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Ceph_in_Compute_Canada_-_Mike_Cave/","excerpt":"","text":"会议纪要 会议主题：Compute Canada 中 Ceph 的使用情况介绍 主讲人：Mike Cave 职位：Senior Unix Administrator 单位：University of Victoria, Research Computing Support Compute Canada 概述 性质：加拿大国家数字计算研究平台 服务：提供研究人员HPC资源、云资源、存储、备份等 资金模型：联合资助模式，由四个联盟共同运作 West Grid, Compute Ontario, Calcul Quebec, ACENET 站点：全国五个主要站点，支持超过70个机构 网络：100 Gigabit 全国网络 当前资源 HPC站点：四个活跃站点，包括新上线的Beluga（35,000核） 云站点：四个云站点，包括与HPC集群关联的Cedar和Graham Ceph 在 Compute Canada 的应用 Ceph部署：所有云站点均使用Ceph，存储规模从4.5 PB到100 TB不等 Arbutus云：最大云部署，提供10,000物理核心，虚拟化后提供近20,000核心，4.5 PB可用存储 Ceph 部署历史 初始阶段：500 TB三重复制存储，手动部署 扩展阶段：增加到18个OSD节点，260个OSD，使用SSD作为日志盘 新集群：32个OSD节点，640个OSD，5.3 PB原始存储，使用BlueStore和Erasure Coded Profile 监控与管理 监控系统：使用UV Stats、Prometheus、Grafana进行系统监控 日志管理：通过Flare系统集中管理日志，实现基于事件的智能报警 后续行动计划 数据迁移：用户自行迁移数据到新集群 硬件更新：逐步淘汰旧硬件，引入新硬件 持续监控：继续优化监控系统，确保集群稳定运行 结论 Mike Cave 介绍了Compute Canada在Ceph存储解决方案的应用和发展历程，强调了联合资助模式在资源共享和硬件更新方面的重要性，并展示了如何通过先进的监控和管理工具确保系统的高可用性和性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Ceph storage for openstack in a security - Etienne Chabrerie","slug":"Ceph_Day_CERN_2019_-_Ceph_storage_for_openstack_in_a_security_-_Etienne_Chabrerie","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Ceph_storage_for_openstack_in_a_security_-_Etienne_Chabrerie/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Ceph_storage_for_openstack_in_a_security_-_Etienne_Chabrerie/","excerpt":"","text":"会议纪要 会议主题： 法国内政部IT部门关于云服务部署的讨论 参会人员： 法国内政部IT部门的DevOps团队成员 会议时间： 下午 会议地点： 线上视频会议 会议内容总结： 背景介绍： 发言人目前在法国内政部IT部门工作，负责开发面向公众的云服务。 该部门负责国家内部安全、法国国家警察、身份文件发放（如护照、身份证）、选举物流组织等。 云服务概述： 提供基于OpenStack的安全云服务，已获得安全认证，适用于敏感应用。 客户需要存储的数据和应用需要私有云环境，无法使用Amazon Cloud或Google Cloud Platform。 技术挑战与解决方案： 客户需要更多的存储空间，因此需要可扩展的存储解决方案。 目前使用的技术包括OpenStack和VSA存储平台，但存在性能和配置复杂性问题。 计划部署新的存储系统，包括两个集群：一个用于块存储（RBD），另一个用于对象存储（S3和Swift）。 实施细节： 使用SSD存储以提高性能，特别是对于小IO操作。 开发Ansible和SaltStack playbooks以集成外部存储。 提供S3服务，支持双向复制，确保数据的高可用性和灾难恢复。 自动化与部署： 采用CI/CD策略，减少手动操作，提高部署的可靠性和效率。 使用Cobbler服务器进行节点部署，通过Ansible进行集成。 部署过程中使用DeepSea进行集群发现和配置。 性能评估： 进行了一些基准测试，结果显示新系统的性能优于现有系统。 后续行动计划： - 继续推进新存储系统的部署，确保其稳定性和性能。 - 优化CI/CD流程，提高自动化水平，减少人为错误。 - 定期进行性能评估和系统更新，确保满足客户需求。 备注： - 会议中提到的技术术语包括OpenStack、VSA、SSD、NVMe、Ansible、SaltStack、DeepSea、Ceph等，这些关键词体现了会议内容的专业性和技术深度。 会议结束时间： 未明确记录 记录人： [您的姓名] 审核人： [审核人姓名]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Scale out Sync & Share with Seafile on Ceph - Sönke Schippmann","slug":"Ceph_Day_CERN_2019_-_Scale_out_Sync_Share_with_Seafile_on_Ceph_-_Sonke_Schippmann","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Scale_out_Sync_Share_with_Seafile_on_Ceph_-_Sonke_Schippmann/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Scale_out_Sync_Share_with_Seafile_on_Ceph_-_Sonke_Schippmann/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统在布莱梅大学的应用与迁移策略 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容总结： Ceph集群介绍 布莱梅大学目前运行着一个900 millipetabyte（微拍字节）的Ceph集群，对Ceph系统在不同工作负载下的表现非常满意。 C4文件共享系统介绍 C4是一种同步和共享系统，类似于ownCloud和NextCloud，但在性能和硬件需求上更为高效。 布莱梅大学有约9000名C4用户，其中3000名在过去几个月内活跃，存储了35TB的数据，分布在1.5亿个对象中。 C4系统的硬件配置 C4系统运行在一个仅配备8个虚拟CPU和32GB RAM的虚拟机上，且大部分时间处于空闲状态。 存储迁移计划 目前，C4系统使用ZFS文件系统基于RBD卷进行存储，但正在迁移至Ceph的S3存储。 迁移的主要目的是利用Ceph的S3存储后端，通过Rados Gateway实现更高效的存储管理。 C4系统的存储后端配置 C4支持多种存储后端，包括文件系统存储、S3存储、OpenStack和Ceph直接存储。 对于S3存储，需要配置三个桶，并设置S3用户和放置目标规则，以便更好地管理数据池。 C4系统的配置文件调整 需要修改C4的配置文件，包括后端服务器和前端服务器的配置，以及一个JSON文件来指定存储目标。 对于已有用户数据的情况，需要确保默认存储设置为文件系统存储，以避免数据访问问题。 数据迁移策略 由于C4提供的迁移脚本仅支持离线迁移，布莱梅大学决定自行开发在线迁移脚本，以避免长时间的服务中断。 迁移工作已经进行了约三个月，预计年底前完成。 决定事项： 确认C4系统从文件系统存储迁移至Ceph S3存储的计划。 确认自行开发的在线迁移脚本的使用，以减少服务中断时间。 后续行动计划： 继续监控和调整迁移过程中的性能和稳定性。 完成迁移后，评估新存储系统的性能和用户反馈。 更新和维护C4系统的配置文件和文档，确保未来的可维护性。 附件： 迁移脚本和配置文件示例链接。 Ceph和C4系统的相关文档和更新。 备注： 本会议纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的全面记录和后续工作的有序进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Storage for High Energy Physics -  Andreas Joachim Peters","slug":"Ceph_Day_CERN_2019_-_Storage_for_High_Energy_Physics_-_Andreas_Joachim_Peters","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Storage_for_High_Energy_Physics_-_Andreas_Joachim_Peters/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Storage_for_High_Energy_Physics_-_Andreas_Joachim_Peters/","excerpt":"","text":"会议纪要 会议概述 本次会议由英国高能物理社区的存储软件开发者经理主持，讨论了在高能物理环境中使用Ceph等分布式存储系统的相关议题。会议涉及了存储系统的优化、与公共云服务的协作、数据管理策略以及未来的行动计划。 主要议题 存储系统优化： 讨论了如何在Ceph等分布式存储系统中实现高效的资源管理和数据处理。 强调了与Google Cloud Storage等公共云服务的协作，以提高数据处理的速度和效率。 数据管理策略： 探讨了在大型实验中如何有效地管理和存储数据，包括使用高性能计算（HPC）和光纤网络。 讨论了数据压缩和存储优化的技术，以及如何通过改进的数据访问协议来提高数据处理的效率。 未来行动计划： 确定了与公共云服务提供商（如Google Cloud）的合作计划，以实现更高效的数据处理和存储。 讨论了如何通过改进的数据管理系统和网络基础设施来支持未来的高能物理实验。 决定事项 确认了与Google Cloud Storage的合作关系，以优化数据处理和存储。 确定了改进数据访问协议和存储管理系统的具体措施。 后续行动计划 继续与公共云服务提供商合作，优化数据处理和存储解决方案。 开发和实施新的数据管理策略，以支持未来的高能物理实验。 定期评估和更新存储系统和网络基础设施，确保其满足不断增长的实验需求。 结论 本次会议为高能物理社区的存储和数据管理问题提供了重要的讨论平台，并确定了具体的合作和改进措施，以支持未来的实验需求。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Utilising Ceph for large scale to support the LHC experiments - Tom Byrne","slug":"Ceph_Day_CERN_2019_-_Utilising_Ceph_for_large_scale_to_support_the_LHC_experiments_-_Tom_Byrne","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Utilising_Ceph_for_large_scale_to_support_the_LHC_experiments_-_Tom_Byrne/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Utilising_Ceph_for_large_scale_to_support_the_LHC_experiments_-_Tom_Byrne/","excerpt":"","text":"会议纪要 会议主题：利用Ceph支持大型高吞吐量存储以支持LHC实验 会议参与者：Tom等 会议内容总结： Ceph集群介绍： Tom介绍了名为ECHO的大型Ceph集群，该集群位于英国的Rutherford Appleton实验室，主要服务于LHC实验。 ECHO集群目前拥有180个存储节点，5000个OSDs，并额外准备了1000个OSDs以备扩展。 所有数据池采用EC 8+3配置，使用librados striper，对象大小为64MB，相比其他集群较大。 集群当前运行在Luminous版本，并开始测试Mimic版本。 LHC实验背景： LHC实验在全球LHC计算网格中有大量计算和存储需求，Tier 1站点提供约40%的计算和存储资源。 ECHO集群为LHC实验提供所有磁盘存储，支持大规模数据处理。 数据处理流程： 实验开始时，粒子碰撞产生原始输出文件，存储在Tier 0，随后转移到Tier 1的磁盘，如ECHO集群。 实验还模拟大量碰撞数据，这些数据构成了存储在WLCG上的大部分内容。 数据需要重建，从探测器读数到粒子的动量和轨迹，这一过程通常在Tier 1进行。 数据访问架构： 主要使用GridFTP进行广域网传输，XRootD用于作业输入输出文件传输。 集群通过7个网关机器提供服务，内部工作节点通过这些网关与集群通信。 为了解决扩展性问题，XRootD服务器基础设施被容器化并在所有工作节点上运行。 监控和性能问题： 集群运行稳定，但偶尔会出现性能问题，影响外部传输。 缺乏监控使得定位和解决这些问题变得困难。 通过脚本收集慢请求的详细信息，并将其导入Elasticsearch进行分析。 发现了一些问题，如单个热门对象导致的锁定问题和OSD映射创建时间过长的问题。 决定事项： 继续监控和优化ECHO集群的性能，特别是解决已知的性能瓶颈。 等待Ceph新版本的发布，以解决当前已知的问题。 后续行动计划： 加强集群的监控系统，确保能够及时发现和解决性能问题。 继续测试和部署Ceph的新版本，以利用新功能和修复。 优化数据处理流程，提高数据传输和处理的效率。 关键词： Ceph ECHO集群 LHC实验 Tier 1站点 GridFTP XRootD Elasticsearch OSDs librados striper 通过这次会议，团队对如何利用Ceph支持大型高吞吐量存储以支持LHC实验有了更深入的了解，并制定了相应的监控和优化策略。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: What’s New In Nautilus & Community News - Mike Perez","slug":"Ceph_Day_CERN_2019_-_What_s_New_In_Nautilus_Community_News_-_Mike_Perez","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_What_s_New_In_Nautilus_Community_News_-_Mike_Perez/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_What_s_New_In_Nautilus_Community_News_-_Mike_Perez/","excerpt":"","text":"会议纪要 会议概述 会议由Mike Perez主持，他是Red Hat的开源项目办公室社区经理。会议在CERN举行，感谢Soft Iron和Western Digital的赞助以及CERN提供的场地。会议主要介绍了Ceph社区的最新动态和Nautilus版本的更新。 主要议题 Ceph基金会成立： 八个月前，Ceph基金会在柏林宣布成立，初始有31个成员，包括13个主要成员、10个一般成员和8个非营利及政府组织。 今年新增了两个一般成员和两个附属成员。 感谢Linux基金会在Ceph基金会成立和大型活动组织方面的支持。 文档改进： Ceph社区正在改进文档工具和流程，特别是通过DocuBetter项目。 会议每月的第二个和第四个星期三举行，欢迎任何人参与。 Ceph基金会正在寻找一名专职的文档改进人员，感兴趣的人可以提交简历。 Ceph简介： Ceph是一个统一存储系统，提供S3和Swift兼容接口，支持块存储和符合POSIX的文件系统。 Ceph使用CRUSH算法来确定数据位置，避免单点故障，支持复制和纠删码，强调数据安全和一致性。 Nautilus版本更新： Nautilus版本重点改进了易用性和管理功能。 引入了新的仪表盘，整合了多个分散的仪表盘项目，提供监控和管理功能。 推出了Orchestrator API，简化了Ceph的部署和管理，支持多种配置管理工具。 新增了自动管理放置组数量和设备健康指标功能。 Kubernetes和Rook： Ceph社区关注Kubernetes集成，通过Rook项目简化Ceph在Kubernetes中的部署和管理。 Rook是一个强大的Ceph操作器，支持声明式资源定义，简化集群管理。 决定事项 Ceph基金会将继续支持社区发展，特别是文档和易用性的改进。 将继续推动Ceph与Kubernetes的集成，通过Rook等项目简化部署。 后续行动计划 继续推进DocuBetter项目，改进Ceph文档和工具。 招聘专职的文档改进人员，提升Ceph的文档质量。 加强与Kubernetes社区的合作，推动Rook等项目的发展。 继续开发和优化Nautilus版本的功能，特别是仪表盘和Orchestrator API。 其他信息 会议感谢所有赞助商和组织者的支持。 鼓励社区成员参与Ceph Days活动，并提供支持。 会议结束 会议在感谢和掌声中结束，接下来将由Sage继续介绍Octopus版本的最新进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day CERN 2019: Speaker Panel Q/A","slug":"Ceph_Day_CERN_2019_-_Speaker_Panel_Q_A","date":"2020-08-24T16:00:00.000Z","updated":"2020-08-25T16:00:00.000Z","comments":true,"path":"2020/08/25/Ceph_Day_CERN_2019_-_Speaker_Panel_Q_A/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/25/Ceph_Day_CERN_2019_-_Speaker_Panel_Q_A/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统的功能讨论与用户反馈 参会人员：Ceph专家、CSC代表Peter Reverend、Ceph集群操作员等 会议时间：[具体日期] 会议地点：[具体地点] 主要议题及讨论内容： Ceph Dashboard支持多CRUSH规则的问题 讨论了Ceph Dashboard是否支持多CRUSH规则（multiple CRUSH rules）。 确认可以在Ceph Dashboard中修改池属性，但不确定是否可以直接在Dashboard中创建新的CRUSH规则。 提到Ceph团队正在不断更新和优化Dashboard的基本功能。 Safe Day Nordic活动信息 Peter Reverend询问Safe Day Nordic活动的举办地点。 确认活动将在挪威、瑞典、冰岛、芬兰等地举行，预计在11月底。 Ceph集群的Telemetry功能启用情况 调查了参会者中Ceph集群是否启用了Telemetry功能。 讨论了启用Telemetry的顾虑和问题，包括数据隐私和网络安全。 提到Telemetry数据目前被发送到上游Ceph实验室的机器，存储在PostgreSQL数据库中，只有少数开发人员有权访问。 强调Telemetry数据不包含敏感信息，未来可能会有摘要报告发送给相关人员。 CephFS的多站点使用情况 讨论了CephFS在多站点环境中的使用情况。 提到Ceph目前没有专门的多站点特性，但可以通过扩展RADOS集群来实现。 强调在多站点环境中，需要特别注意网络链接的质量和服务的实时性。 Ceph集群的运行和配置问题 讨论了Ceph集群的运行情况和配置问题，包括启用Telemetry功能的具体操作和配置HTTP代理的可能性。 决定事项： 确认Ceph Dashboard支持多CRUSH规则的修改，但创建新规则的功能尚不确定。 确认Safe Day Nordic活动的举办地点和时间。 讨论了Telemetry功能的启用情况和相关顾虑，强调数据安全和隐私保护。 讨论了CephFS在多站点环境中的使用和注意事项。 后续行动计划： 进一步确认Ceph Dashboard中创建新CRUSH规则的功能，并更新相关文档。 继续优化Telemetry功能，解决用户的顾虑，并确保数据安全和隐私保护。 提供更多关于CephFS多站点使用的指导和最佳实践。 更新和完善Ceph相关文档，包括Telemetry功能的详细说明和配置指南。 备注： 会议中提到的关键词和术语包括Ceph Dashboard、CRUSH rules、Telemetry、CephFS、RADOS cluster等。 会议记录了参会者的反馈和建议，为Ceph的进一步开发和优化提供了重要参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-08-24","slug":"Ceph_Orchestrator_Meeting_2020-08-24","date":"2020-08-23T16:00:00.000Z","updated":"2020-08-24T16:00:00.000Z","comments":true,"path":"2020/08/24/Ceph_Orchestrator_Meeting_2020-08-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/24/Ceph_Orchestrator_Meeting_2020-08-24/","excerpt":"","text":"会议纪要 会议时间与参与人员 时间： 会议开始时稍有延迟，大约晚了2分钟。 参与人员： 会议中提到了多位参与者，包括但不限于Karen Deck, Sebastian, 以及其他未明确提及姓名的团队成员。 主要议题与讨论内容 日志处理问题 问题描述： 当前容器日志通过systemd处理后，默认配置下会转发到syslog，导致日志管理变得复杂且难以使用。 讨论焦点： 是否应该中断日志转发链，以及如何在不破坏现有系统服务处理方式的前提下解决此问题。 提议解决方案： 探讨使用journald namespaces来解决日志管理问题，但未有明确结论。 Python版本支持问题 讨论内容： 由于CentOS 7默认安装Python 2，而Python 2已不再维护，团队讨论是否继续支持CentOS 7。 决策： 多数意见倾向于不再支持CentOS 7，以简化开发和部署过程。 新功能提议：硬件信息收集 提议内容： 提出一个新的pull request，旨在通过新的gather facts命令收集系统硬件详细信息，如CPU核心数、内存大小和网络接口等。 讨论结果： 团队认为这一功能对于用户了解硬件配置和优化部署流程非常有用，支持进一步开发和完善。 文档更新与简化 工作进展： Sebastian和另一位成员正在努力简化文档结构，特别是减少重复内容，但发现不同文档服务于不同用例，需要进一步分类和整合。 后续计划： 计划在9月1日前完成初步的文档更新，包括改进安装指南的呈现方式。 后续行动计划 日志处理： 继续探讨和测试使用journald namespaces的可行性。 Python版本： 确定不再支持CentOS 7，更新相关文档和部署指南。 硬件信息收集： 完善gather facts命令的功能，确保提供准确和有用的硬件信息。 文档更新： 继续进行文档的分类和简化工作，确保信息清晰且易于导航。 会议结束 会议时长： 约17分钟。 下次会议： 计划下周再次同步。 会议在简短而高效的讨论后结束，团队成员对未来的工作方向有了更清晰的认识。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-08-20","slug":"Ceph_Performance_Meeting_2020-08-20","date":"2020-08-19T16:00:00.000Z","updated":"2020-08-20T16:00:00.000Z","comments":true,"path":"2020/08/20/Ceph_Performance_Meeting_2020-08-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/20/Ceph_Performance_Meeting_2020-08-20/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了与Ceph性能相关的几个拉取请求（pull requests），并对一篇关于CRUSH算法扩展的论文进行了深入探讨。会议还涉及了后续行动计划和潜在的研究方向。 讨论的主要议题 拉取请求更新： 目前没有新的与性能相关的拉取请求。 一个由majianpeng提交的拉取请求因长时间未被审查而被stale bot关闭。 另一个majianpeng的拉取请求已由adam和会议参与者审查，主要涉及bluerock环境的刷新行为更改。 论文讨论： 论文介绍了一种新的CRUSH算法扩展，旨在解决集群扩展时数据迁移的问题。 该扩展通过引入时间维度映射，使得在集群扩展时大部分数据不需要迁移，仅写入新的OSDs。 论文还讨论了如何通过层合并来解决潜在的负载平衡问题。 论文的局限性和潜在改进： 论文的方法不适用于通用对象存储，如RGW。 引入的时间戳和复杂的管理算法增加了系统的复杂性。 讨论了是否可以通过改进现有的PG临时机制或引入新的多CRUSH规则方法来简化实现。 后续行动计划： 继续关注和改进现有的PG临时机制。 考虑实施一种新的多CRUSH规则方法，以简化集群扩展时的数据迁移。 探索其他可能的改进措施，如QoS机制，以更好地控制后台数据迁移对客户端IO的影响。 决定的事项 论文提出的方法虽然有其创新之处，但由于其局限性和复杂性，目前不考虑直接实施。 将重点放在改进现有的PG临时机制和探索新的多CRUSH规则方法上。 计划定期讨论和阅读新的研究论文，以保持对最新研究动态的关注。 后续行动计划 继续监控和改进PG临时机制。 探索和实施新的多CRUSH规则方法。 定期组织论文阅读和讨论会，以促进团队对最新研究成果的了解和应用。 会议结束 会议在讨论了未来的研究方向和行动计划后结束，参与者表示将积极参与后续的研究和开发工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk 2020-08-20: Edge Application - Streaming Multiple Video Sources","slug":"Ceph_Tech_Talk_2020-08-20_-_Edge_Application_-_Streaming_Multiple_Video_Sources","date":"2020-08-19T16:00:00.000Z","updated":"2020-08-20T16:00:00.000Z","comments":true,"path":"2020/08/20/Ceph_Tech_Talk_2020-08-20_-_Edge_Application_-_Streaming_Multiple_Video_Sources/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/20/Ceph_Tech_Talk_2020-08-20_-_Edge_Application_-_Streaming_Multiple_Video_Sources/","excerpt":"","text":"会议纪要 会议主题：Seth Tech Talk - 边缘应用视频流项目介绍 会议时间：具体时间未提供 会议地点：线上会议 主持人：Mike Perez（社区经理，Red Hat新兴技术部门） 参会人员：Jason Wang、Niharika Kompala（Red Hat实习生）、其他未具名观众 会议内容总结： 项目介绍： Jason Wang和Niharika Kompala作为Red Hat的实习生，介绍了他们夏季实习期间开发的边缘应用项目，该项目涉及多视频源的流媒体处理。 项目目标是通过边缘计算技术改善视频流的质量和延迟问题，特别是在处理大量摄像头数据时。 技术背景： 讨论了边缘计算的重要性，特别是在处理预计到2025年将达到750亿连接设备的庞大数据量时。 强调了边缘计算在提供低延迟和高速度处理方面的优势，特别是在5G技术和物联网（IoT）的背景下。 项目架构与技术实现： 项目使用了GStreamer框架来处理视频流，并开发了自定义的GStreamer插件来上传视频到Ceph存储系统。 利用Ceph的多部分上传功能和S3 API，实现了视频数据的同步和存储。 通过Knative函数触发器，实现了视频的拼接和分析处理，使用了OpenCV进行视频拼接。 演示与代码展示： 展示了项目的实际运行情况，包括视频流的上传和拼接过程。 讨论了在Fedora系统上运行GStreamer时遇到的问题，并介绍了使用Ubuntu容器作为解决方案。 未来工作与感谢： 提出了未来可能的扩展，如创建RGW NFS网关以支持RTMP视频流。 感谢Warman、Harrison以及Ceph团队的支持和帮助。 后续行动计划： 继续优化和扩展项目功能，特别是在Knative和Ceph的集成方面。 探索更多的边缘计算应用场景，以支持更广泛的视频流处理需求。 会议结束： 会议在感谢和告别中结束，主持人预告了下一次的Tech Talk主题。 备注： 会议中提到的GitHub项目URL未在纪要中提供，建议后续补充。 以上是本次Seth Tech Talk的会议纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-08-19","slug":"Ceph_Crimson_SeaStor_OSD_2020-08-19","date":"2020-08-18T16:00:00.000Z","updated":"2020-08-18T16:00:00.000Z","comments":true,"path":"2020/08/19/Ceph_Crimson_SeaStor_OSD_2020-08-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/19/Ceph_Crimson_SeaStor_OSD_2020-08-19/","excerpt":"","text":"会议纪要 主要议题与讨论内容 技术问题与解决方案 Ceph存储系统中的问题： 上周主要工作集中在技术基础的测试上，遇到了一些与后台字段恢复相关的问题，这些问题是由于缺少某些操作导致的。 增加了对这些操作的支持，并发现对象不一定总是包含映射，这导致了一些运行时的错误。 计划增强新添加操作的错误处理支持，以减少错误消息的意外性。 EIO处理案例 正在研究在代码中的哪个位置应该进行EIO处理，特别是在CRC不匹配和对象存储返回EIO的情况下。 传统上，这些处理在经典OSD中是通过rep_repair_primary函数完成的，而在Crimson中则需要在pg_backend中进行相应的处理。 CRUSH算法的扩展 讨论了在FAST 2020会议上提出的一篇关于CRUSH算法扩展的论文，该论文解决了在非平凡集群扩展时数据迁移的问题。 计划继续讨论该论文，并将其链接分享给团队成员以供进一步研究。 代码实现与测试 完成了字符串键布局操作，并正在处理树节点实现。 正在解决单元测试中发现的一个bug，并考虑如何改进基于PG日志的恢复。 强调了测试的重要性，特别是对于Crimson的稳定性和功能验证。 后续行动计划 需要对Crimson中的问题进行分类，并创建相应的bug报告。 强调了在病理运行中发现问题时，应及时创建bug报告的重要性。 计划继续优化代码，特别是错误处理和垃圾收集机制。 决定事项 继续推进对Crimson的测试和错误修复工作。 对发现的问题进行分类，并创建详细的bug报告。 继续研究和讨论CRUSH算法的扩展，以及其在Ceph中的应用。 后续行动计划 继续完善和增强Crimson的错误处理机制。 对Crimson中的问题进行分类，并创建详细的bug报告。 继续研究和讨论CRUSH算法的扩展，以及其在Ceph中的应用。 继续优化代码，特别是错误处理和垃圾收集机制。 会议结束 会议结束时，团队成员被鼓励继续关注和参与Crimson的开发和测试工作，并保持沟通和协作。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-08-17","slug":"Ceph_Orchestrator_Meeting_2020-08-17","date":"2020-08-16T16:00:00.000Z","updated":"2020-08-17T16:00:00.000Z","comments":true,"path":"2020/08/17/Ceph_Orchestrator_Meeting_2020-08-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/17/Ceph_Orchestrator_Meeting_2020-08-17/","excerpt":"","text":"会议纪要 - 今日的Orchestrator周会 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： 德国构建问题 德国构建因容器未推送到CPR容器注册表而中断。 I容器构建也出现问题，导致目前无法合并任何内容。 需要联系David Galloway解决，因其是唯一有权访问quiet.io的人员。 建议联系Christina Venus团队成员协助。 Cepheidiam二进制文件的重组 需要对Cepheidiam二进制文件进行重构。 讨论了重构的必要性和步骤，建议逐步进行。 涉及将self-adm作为一个适当的包进行分发，并确保其能在远程机器上正常工作。 文档整合 讨论了关于安装指南的整合问题。 建议将现有的两个安装指南合并为一个，并分为基础安装和附加功能（如Ganesha和MDS）的多个页面。 计划本周内开始整合工作，并发送Pull Request进行进一步讨论。 决定事项： 联系Christina Venus团队成员协助解决德国构建问题。 开始对Cepheidiam二进制文件进行重构工作。 合并现有的两个安装指南为一个，并分为基础和附加功能的不同页面。 后续行动计划： 联系David Galloway或Christina Venus团队成员解决容器推送问题。 开始Cepheidiam二进制文件的重构工作，并逐步实施。 整合安装指南，并发送Pull Request进行团队讨论和反馈。 其他讨论： 讨论了文档的详细程度和新手友好性，强调了为初学者提供详细步骤的重要性。 计划制作视频教程，以辅助文档说明。 会议结束： 会议在无其他议题讨论的情况下结束，提醒团队成员享受本周和剩余的周一。 备注： 会议记录中提到的“CPR容器注册表”、“Cepheidiam二进制文件”、“self-adm”等关键词保留了原文，以便于专业领域的准确理解。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-08-13","slug":"Ceph_Performance_Meeting_2020-08-13","date":"2020-08-12T16:00:00.000Z","updated":"2020-08-13T16:00:00.000Z","comments":true,"path":"2020/08/13/Ceph_Performance_Meeting_2020-08-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/13/Ceph_Performance_Meeting_2020-08-13/","excerpt":"","text":"会议纪要 关键细节 日期: [具体日期] 参会人员: [参会人员名单] 会议主持: [主持人姓名] 主要议题 PR讨论: Bufferless Depends优化: Radek和主持人共同完成的工作，旨在提高bufferless depends的速度。提出了两个互补的更改，第一个较小更改已在本周的PR中提交。该更改动态调整append buffer的长度，类似于C++中vector的增长方式，但有边界限制。尽管在某些情况下tc_malik会变慢，但总体上仍优于master版本，尤其是在pen_hole和ring buffer的情况下。 Ephemeral Pinning改进: Yan提交的PR，加强了最近引入的ephemeral pinning功能。目的是通过分发franks来减少子树的数量。 CRUSH算法扩展: 介绍了一篇在FAST会议上发表的论文，该论文提出了一种CRUSH算法的扩展，旨在改善集群扩展时的数据迁移问题。新算法引入了一个集中式的权威来管理数据迁移，通过添加一个虚拟层来减少数据迁移量，特别是在集群扩展时。 论文展示了在Ceph FS和RBD上的测试结果，显示新算法在IOPS和延迟方面有显著改进。会议讨论了该算法的潜在影响和是否需要在SSD上进行进一步测试。 决定事项 主持人将联系论文作者，探讨他们是否愿意在未来的会议中进行详细介绍。 参会人员将在接下来的两周内详细阅读论文，并在下次会议中进一步讨论。 后续行动计划 主持人将联系论文作者，安排一个会议时间。 所有参会人员需阅读论文，准备下次会议的讨论。 考虑在不同硬件上测试新算法，特别是SSD，以评估其在现代存储设备上的表现。 其他讨论 讨论了D3M缓存和Majin Peng的PR更新，以及Radic对减少buffer list重建的工作。 结论 会议结束时，所有参会人员同意在下次会议前详细阅读论文，并期待进一步的讨论和可能的实施测试。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-08-12","slug":"Ceph_Crimson_SeaStor_OSD_2020-08-12","date":"2020-08-11T16:00:00.000Z","updated":"2020-08-12T16:00:00.000Z","comments":true,"path":"2020/08/12/Ceph_Crimson_SeaStor_OSD_2020-08-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/12/Ceph_Crimson_SeaStor_OSD_2020-08-12/","excerpt":"","text":"会议纪要 关键细节 参会人员: 会议涉及多名研发人员，包括但不限于Sam、Tremaine等。 会议时间: 最近一周。 讨论的主要议题 结构测试与技术门槛测试: Tremaine上周在进行基于技术的门槛测试和修复工作。 发现存储检测器在Cremation启动时发出警告，原因是使用了阻塞API读取配置文件。 已改为使用异步IO（Async IO）来消除警告。 代码审查与PR更新: Tremaine本周将完成对Sam创建的PR的审查。 根据Sam的评论修改了外部map3pr，并更新了PR。 仍在处理omap3布局操作。 中断可处理的未来: 替换了所有sister future为aerator future，沿IO执行路径。 正在将中断逻辑嵌入到aero radio creator中，预计几天内提交PR。 性能回归测试: 讨论了使用pet market进行性能回归测试，但数据尚未准备好。 子树管理与内存解决方案: 实施并测试了带有子树管理的corporate tracking facility。 正在寻找将当前基于内存的解决方案转移到systole的方法。 异步own entry: 开始处理异步own entry，有一些问题通过邮件讨论。 缓存驱逐: 正在编写缓存层的缓存驱逐实现。 首先需要编写脏块写出，以便可以修剪日志。 决定的事项 配置文件读取: 从阻塞API改为异步IO。 PR审查: Tremaine负责完成对Sam的PR的审查。 中断逻辑: 将中断逻辑嵌入到aero radio creator中。 缓存驱逐: 开始实施缓存驱逐逻辑，首先处理脏块写出。 后续行动计划 提交PR: 完成中断逻辑的嵌入后，提交PR。 性能数据: 准备并发送性能回归测试的数据。 缓存驱逐: 继续实施缓存驱逐逻辑，并考虑是否需要通知机制。 异步own entry: 继续处理异步own entry，并解决相关问题。 其他讨论点 逻辑地址空间的使用: 讨论了逻辑地址空间的使用，指出当前的用法较为简单，未来可能需要更复杂的策略。 多核支持: 讨论了多核支持的问题，包括多进程和多线程的策略。 结论 会议涵盖了多个技术议题，包括代码审查、性能测试、缓存管理等，并制定了相应的行动计划。所有参与者将继续推进各自负责的任务，并保持沟通以解决可能出现的问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph DocuBetter Meeting 2020-08-12","slug":"Ceph_DocuBetter_Meeting_2020-08-12","date":"2020-08-11T16:00:00.000Z","updated":"2020-08-12T16:00:00.000Z","comments":true,"path":"2020/08/12/Ceph_DocuBetter_Meeting_2020-08-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/12/Ceph_DocuBetter_Meeting_2020-08-12/","excerpt":"","text":"会议纪要 会议概要 会议讨论了多个议题，包括文档更新、版本管理、合并请求流程、发布笔记的准备以及未来项目的规划。会议持续了20分钟，涉及多个关键项目的进展和决策。 主要议题 文档更新与管理 Sebastian正在休假，关于入门指南的讨论暂时搁置。如果他下周仍未回归，计划由Josh和其他成员先行审批，待他返回后再处理可能的反馈。 文档网站的重新组织正在进行中，特别是按钮大小和布局的讨论。Josh提出了增加按钮间距的建议。 版本与安装指南 讨论了安装指南的版本特定性问题，建议使用版本字符串而非硬编码版本号，以便未来版本更新时文档能自动适应。 讨论了如何处理过时或格式不佳的提交，计划通过重新编辑并保留原作者信息的方式来优化这些提交。 合并请求与开发流程 讨论了合并请求的格式和流程，特别是在开发者指南中增加合并请求格式的具体说明。 提出了一个文档检查清单，用于确保每次点发布前所有必要的文档更新都已完成。 视频制作计划 计划制作简短的视频教程，特别是关于安装和开发流程的指导视频，以满足年轻用户对视频内容的需求。 讨论了视频制作的可能性和预期效果，以及如何快速有效地生产这些视频内容。 决定事项 Sebastian的入门指南将由其他成员先行审批。 安装指南将采用版本字符串而非硬编码版本号。 将制定一个文档检查清单，确保每次发布前的文档准备工作。 计划制作视频教程，特别是关于安装和开发流程的指导视频。 后续行动计划 完成入门指南的审批和后续修订工作。 更新安装指南，使用版本字符串。 制定并实施文档检查清单。 开始制作视频教程，特别是关于安装和开发流程的指导视频。 备注 会议中提到的多个议题将在后续的会议中进一步讨论和细化。 计划在未来的会议中详细讨论视频制作的具体流程和技术细节。 会议结束时，所有参与者对未来的工作计划和目标表示了积极的期待，并确认了下次会议的时间。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-08-10","slug":"Ceph_Orchestrator_Meeting_2020-08-10","date":"2020-08-09T16:00:00.000Z","updated":"2020-08-10T16:00:00.000Z","comments":true,"path":"2020/08/10/Ceph_Orchestrator_Meeting_2020-08-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/10/Ceph_Orchestrator_Meeting_2020-08-10/","excerpt":"","text":"会议纪要 会议参与者 Karen Josh Jordan Zach Aaron 其他未明确提及的参与者 会议时间 日期：未明确提及 时间：早上 会议议程 确认Sebastian和Ken Hartzo的在线状态 讨论文档（docs）相关问题 更新Rook项目进展 讨论OSD移除设计文档的更新 会议内容 Sebastian和Ken Hartzo的状态 Sebastian正在休假，预计下周回归。 Ken Hartzo本周也在休假，不会参加会议。 文档（docs）问题讨论 Zach提出关于文档中存在的未完成或格式错误的PR问题，建议主动清理这些老旧的PR。 Zach询问是否可以自行处理这些PR，以加快文档的更新和清理。 会议中未有人反对，Zach将开始处理这些PR，并保持原提交者的信用。 Rook项目更新 Rook 1.4版本已经发布，会议中对此表示满意。 OSD移除设计文档更新 需要更新关于OSD移除的设计文档，将在后续进行。 决定事项 Zach将开始处理和清理文档中的老旧PR。 需要更新OSD移除的设计文档。 后续行动计划 Zach继续处理文档中的PR问题。 更新并完成OSD移除的设计文档。 会议结束 会议在无其他议题的情况下提前结束。 会议参与者互相道别，会议结束。 本次会议主要关注了文档管理和Rook项目的进展，以及对未来工作的规划。会议在确认了关键人员的在线状态后，重点讨论了文档的维护和更新问题，并做出了相应的决定和后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-08-06","slug":"Ceph_Performance_Meeting_2020-08-06","date":"2020-08-05T16:00:00.000Z","updated":"2020-08-06T16:00:00.000Z","comments":true,"path":"2020/08/06/Ceph_Performance_Meeting_2020-08-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/06/Ceph_Performance_Meeting_2020-08-06/","excerpt":"","text":"会议纪要 关键细节 PR提交情况: 本周收到了两份新的PR，均来自Majiang Peng。他还提交了其他非性能相关的PR，显示出活跃的贡献。 性能优化: 一个PR旨在避免在BlueStore环境中一次性刷太多数据，以减少延迟峰值。 另一个PR旨在减少BlueFS中的缓冲列表重建，复杂度较高，需要进一步审查。 RGW更新: 两个更新的PR涉及rgw的d3n缓存更改，Matt和Mark Hogan正在审查。 未解决的PR: 仍有一些PR需要审查，特别是来自ajianpang的PR，目前无人深入研究。 内存优化: 需要进一步研究Igor的内存减少PR和会议主持人的双缓存优化。 讨论的主要议题 性能优化: 讨论了如何通过改进缓存管理和数据刷新策略来优化性能，特别是在BlueStore环境中。 缓存策略: 讨论了缓存命中和未命中的影响，以及如何通过调整缓存大小和刷新策略来优化性能。 压缩测试: Adam分享了关于压缩测试的进展，强调了均匀分布在测试中的不适用性，建议使用更接近实际工作负载的分布。 决定的事项 PR审查: 确认了需要进一步审查的PR，包括性能优化和缓存策略相关的PR。 缓存策略: 讨论了双缓存策略的潜在益处和挑战，决定需要进一步的实现和测试。 后续的行动计划 PR审查: 继续审查和讨论未决的PR，特别是性能和缓存相关的PR。 缓存策略: 进一步研究和实现双缓存策略，特别是在BlueStore环境中。 压缩测试: 继续进行压缩测试，特别是使用更接近实际工作负载的数据分布。 性能监控: 考虑在CBT测试中加入性能监控，特别是在测试开始和结束时收集性能计数器。 其他讨论点 缓存命中和未命中的影响: 讨论了缓存命中和未命中对性能的影响，以及如何通过调整缓存策略来优化性能。 实际工作负载的模拟: 讨论了如何更准确地模拟实际工作负载，特别是在压缩测试中。 结论 会议涵盖了多个关键议题，包括性能优化、缓存策略和压缩测试。决定继续审查和讨论未决的PR，并进一步研究和实现双缓存策略。同时，考虑在CBT测试中加入性能监控，以更好地理解性能影响因素。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD Meeting 2020-08-05","slug":"Ceph_Crimson_SeaStor_OSD_Meeting_2020-08-05","date":"2020-08-04T16:00:00.000Z","updated":"2020-08-05T16:00:00.000Z","comments":true,"path":"2020/08/05/Ceph_Crimson_SeaStor_OSD_Meeting_2020-08-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/05/Ceph_Crimson_SeaStor_OSD_Meeting_2020-08-05/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的开发进展、遇到的问题以及后续的行动计划。会议中涉及了多个技术议题，包括代码重构、测试结果分析、PR（Pull Request）更新、内存数据结构管理等。 主要议题 代码重构与测试 上周创建了一个Ceph的PR，修复了一些问题以启用小规模运行测试。 最新的测试结果显示，测试被一些在Bluestore中的失败所阻塞，但这些失败与Ceph本身无关。 计划今天下午进一步调查这些失败的原因。 PR更新与审查 根据评论更新了PR，请求团队成员进行审查。 讨论了在旧节点中启动扩展映射树（extend map tree）的问题，决定不存储在外部映射树中。 代码重构涉及Sam的RBA pin patch，发现了一些问题，等待Sam更新后重新重构。 内存数据结构管理 讨论了在固定KV节点布局中使用cipher_le64的问题，由于缺乏常量操作接口，需要提供自己的包装结构。 讨论了在事务结束后保持对扩展的引用的安全性问题，建议在同一事务内保持引用，但不要在事务间保持。 未来工作计划 继续开发可中断的叙述未来（interruptible narrative future），并实现一系列错误率版本的未来设施。 计划实现跟踪设施，以便在树查找中保持节点可用性。 决定事项 需要进一步调查Bluestore中的测试失败原因。 PR需要根据团队反馈进行进一步的修改和审查。 在内存数据结构管理中，需要避免在事务间保持对节点的引用，以防止潜在的问题。 后续行动计划 今天下午对Bluestore中的测试失败进行详细调查。 继续更新和审查PR，确保代码质量和功能正确性。 开发和实现可中断的叙述未来及相关设施。 实现跟踪设施，确保在树查找中节点的可用性。 关键词 Ceph Bluestore PR (Pull Request) extend map tree RBA pin patch cipher_le64 interruptible narrative future 会议结束时，团队成员表示将继续关注各自负责的任务，并保持沟通以确保项目的顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-08-03","slug":"Ceph_Orchestrator_Meeting_2020-08-03","date":"2020-08-02T16:00:00.000Z","updated":"2020-08-03T16:00:00.000Z","comments":true,"path":"2020/08/03/Ceph_Orchestrator_Meeting_2020-08-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/08/03/Ceph_Orchestrator_Meeting_2020-08-03/","excerpt":"","text":"会议纪要：Ceph Orchestrator 周会 会议时间：[具体日期] 参会人员：[参会人员名单] 会议议程： 显示警告消息 OSD 移除设计命令 改进 Ceph Orchestrator 的开发者体验 使用单一容器镜像 讨论内容： 显示警告消息 议题概述：讨论如何通过 Ceph 健康检查（Ceph Health）向用户传播警告消息。 讨论要点： 当前已有多个拉取请求（pull requests）涉及此话题。 需要改进警告消息的显示方式，使其在仪表盘或健康输出中可见。 讨论了自动解决警告消息的机制，当前每六分钟自动解决一次。 提出了是否应允许用户手动触发健康检查循环（surf loop）的讨论。 决定事项： 需要提供一种自动解决警告消息的方法。 讨论了是否应允许用户手动触发健康检查循环，最终认为不应中断或排队循环。 OSD 移除设计命令 议题概述：讨论 Rook 和 Ceph 在 OSD 移除方面的设计。 讨论要点： Rook 不自动移除 OSD，而是提供一个一次性操作的 Kubernetes 作业。 讨论了与 Ceph 的相似性和差异，包括安全措施和强制标志。 决定事项： Rook 和 Ceph 应采用相似的 OSD 移除算法。 需要更新设计文档以反映新的 OSD 移除方法。 改进 Ceph Orchestrator 的开发者体验 议题概述：讨论如何改进 Ceph Orchestrator 的开发者体验。 讨论要点： 当前 Ceph Orchestrator 的开发者体验不佳，需要进行重构。 提出了将 Ceph Orchestrator 变为一个适当的 Python 包的建议。 决定事项： 需要进行基础工作，包括移除注入的代码并使其成为一个适当的 Python 包。 需要发布 Ceph Orchestrator，以便用户可以从下载平台获取而不是直接从 GitHub 下载。 使用单一容器镜像 议题概述：讨论在集群中使用单一容器镜像的需求。 讨论要点： 提出了在 Ceph Orchestrator 中使用单一容器镜像的建议。 讨论了如何将标签转换为摘要（digest）以确保一致性。 决定事项： 需要实现与 Ansible 类似的方法，将标签转换为摘要。 后续行动计划： 显示警告消息： 实现自动解决警告消息的机制。 讨论并决定是否允许用户手动触发健康检查循环。 OSD 移除设计命令： 更新设计文档以反映新的 OSD 移除方法。 确保 Rook 和 Ceph 采用相似的 OSD 移除算法。 改进 Ceph Orchestrator 的开发者体验： 进行基础工作，将 Ceph Orchestrator 变为一个适当的 Python 包。 发布 Ceph Orchestrator，使其可以从下载平台获取。 使用单一容器镜像： 实现将标签转换为摘要的方法，确保集群中使用单一容器镜像的一致性。 会议结束： 会议于[具体时间]结束，下次会议定于下周同一时间进行。 备注： 会议中提到的具体拉取请求和设计文档链接已记录在会议笔记中，供后续参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-07-30","slug":"Ceph_Performance_Meeting_2020-07-30","date":"2020-07-29T16:00:00.000Z","updated":"2020-07-30T16:00:00.000Z","comments":true,"path":"2020/07/30/Ceph_Performance_Meeting_2020-07-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/30/Ceph_Performance_Meeting_2020-07-30/","excerpt":"","text":"会议纪要 会议概述 本次会议是自上次会议以来的几周后的定期会议，由于夏季，活动相对较慢。会议主要回顾了近期Ceph项目的开发进展，特别是关于RGW（RADOS Gateway）和MDS（Metadata Server）的改进。 主要议题 RGW改进： Eric提交了一个PR，旨在提高RGW有序列表映射的效率，避免第二次遍历列表。 另一个PR涉及d3n缓存的上游更改，目前正在审查和测试中。 MDS改进： Majiang Ping提交了两个与BlueStore相关的PR，涉及小规模的改进。 一个关于MDS的PR已经合并，主要修复了在大量子树情况下的缓存修剪问题。 另一个PR涉及ceph-adm工具，改进了OSD的并行创建，显著提升了性能。 性能优化： Majiang Peng的另一个PR涉及启用RocksDB管道，可能带来性能提升。 Radek和Mark正在研究MDS中的缓冲列表（buffer list）和环形缓冲区（ring buffers），以减少CPU使用和内存分配成本。 决定事项 继续审查和测试所有新的和更新的PR。 进一步研究和优化MDS中的缓冲列表和环形缓冲区，以减少CPU和内存的使用。 后续行动计划 完成所有PR的审查和测试，确保代码质量和性能。 继续研究和优化MDS中的缓冲列表和环形缓冲区，目标是提高编码和解码的效率，而不需要改变现有的编码解码框架。 探索和评估更动态的内存分配策略，特别是在小规模追加操作中的应用。 其他讨论 讨论了缓冲列表在多线程环境下的使用情况，以及如何减少原子操作的开销。 分享了性能测试的结果和分析，强调了在实际应用中可能存在的性能差异。 结论 会议强调了持续改进Ceph项目的重要性，特别是在性能优化和代码质量方面。团队将继续努力，以实现长期目标，即在不改变现有编码解码框架的情况下，提高MDS的效率。 本次会议纪要由专业的存储领域分布式存储Ceph研发人员和视频会议字幕总结人员共同完成，确保了内容的准确性和专业性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-07-29","slug":"Ceph_Crimson_SeaStor_OSD_2020-07-29","date":"2020-07-28T16:00:00.000Z","updated":"2020-07-29T16:00:00.000Z","comments":true,"path":"2020/07/29/Ceph_Crimson_SeaStor_OSD_2020-07-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/29/Ceph_Crimson_SeaStor_OSD_2020-07-29/","excerpt":"","text":"会议纪要 关键细节 Messenger 相关问题：上周在测试基于病理的结构测试时发现了一些问题，今天再次运行测试时发现心跳（heartbeat）部分出现了崩溃，目前正在调查中。 FBA Ping 审查：正在审查 Sam 的 FBA Ping，但仍在努力解决中。 恢复和回填测试：正在寻找真正的测试失败案例，特别是与恢复和回填（recovery and backfill）相关的测试，以及阈值测试。 经典扫描（Classic Scrubbing）：已经更新了文档，并开始运行独立的测试套件。 内部节点插入和分裂实现：上周完成了内部节点插入和分裂的实现，目前正在跟踪树层次结构在递归分裂过程中的变化。 单元测试：正在为回填（backfill）准备单元测试，包括一个基本随机的测试案例，用于生成大量副本间的差异，确保这些差异被消除。 Tommy 的状态：Tommy 正在根据 Sam 的评论更新 PR，并处理网络问题。 Crimson 中断机制：上周在开发 Crimson 中断机制，但因其他工作进展不大，本周将继续开发。 讨论的主要议题 测试和调试：讨论了各种测试的进展和遇到的问题，包括心跳崩溃、恢复和回填测试、经典扫描等。 代码审查和实现：审查了 FBA Ping 和内部节点插入和分裂的实现，以及树层次结构的跟踪。 单元测试和基础设施：讨论了为回填准备的单元测试和相关的基础设施。 决定的事项 继续调查心跳崩溃问题：需要进一步调查和重现心跳崩溃的问题。 继续审查和更新 FBA Ping：需要继续审查并根据 Sam 的评论更新 FBA Ping。 继续开发 Crimson 中断机制：本周将继续开发 Crimson 中断机制。 后续的行动计划 调查心跳崩溃：继续调查并重现心跳崩溃的问题。 审查和更新 FBA Ping：继续审查并根据 Sam 的评论更新 FBA Ping。 开发 Crimson 中断机制：本周将继续开发 Crimson 中断机制。 准备单元测试：继续为回填准备单元测试，并确保测试案例能够生成并消除副本间的差异。 其他 网络问题：Tommy 遇到了网络问题，会议中等待其重新加入。 链接分享：分享了一个链接，用于解释单元测试的基础设施和实现细节。 结束语 感谢所有参与者的贡献和讨论，期待后续的进展和成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Science Working Group 2020-07-23","slug":"Ceph_Science_Working_Group_2020-07-23","date":"2020-07-27T16:00:00.000Z","updated":"2020-07-27T16:00:00.000Z","comments":true,"path":"2020/07/28/Ceph_Science_Working_Group_2020-07-23/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/28/Ceph_Science_Working_Group_2020-07-23/","excerpt":"","text":"会议纪要：Ceph用户组会议 - 2020年7月 会议概述 日期：2020年7月 形式：虚拟会议 目的：为科学研究和大型集群领域的专业人士提供一个非正式的交流平台，每两个月举行一次。 参与者：来自相关领域的专业人士和研究人员。 主要议题 近期故障和问题分享 部分集群故障：从1604到1804版本中，ifupdown脚本中的竞态条件导致绑定接口在VLAN中无法启动默认路由，影响OSD与客户端的通信。 解决方案：使用更新版本的ifupdown包，并在systemd服务文件中添加覆盖，确保OSD在无法ping通内部基础设施时不会启动。 Ceph集群容量管理 问题：一个13PB的生产集群达到满容量，且平衡器存在问题，导致无法有效重新平衡。 应对措施：停止集群三天，添加新硬件，使用app-map remap工具重新分配PG，并通过脚本优先处理满载的OSD。 Ceph Octopus升级经验分享 升级过程：从Nautilus升级到Octopus 15.2.3，过程中遇到性能下降和RGW统计问题。 问题：RGW统计数据不准确，导致用户配额问题；RGW日志记录问题导致性能问题。 解决方案：暂时回滚到Nautilus，调整日志级别。 Ceph Orchestrator和容器化部署 讨论：关于使用Ceph Orchestrator进行容器化部署的挑战和经验，特别是RGW的管理命令问题。 展望：容器化部署是未来趋势，但目前存在一些技术障碍。 决定事项 未来会议安排：下一次会议预计在9月的第四或第五个星期三举行。 信息共享：鼓励参与者通过会议链接中的pad共享信息和问题。 后续行动计划 技术问题跟进：继续关注和解决Ceph Octopus升级后的性能和稳定性问题。 容器化部署测试：进一步测试和优化Ceph Orchestrator的容器化部署方案。 社区支持：通过邮件列表和私人通讯渠道，加强社区成员之间的沟通和支持。 其他讨论 Ceph Octopus的新特性：如实时镜像迁移等，尚未有实际应用经验分享。 Ceph社区动态：提及CERN的LZ4压缩问题技术讨论，鼓励参与者观看相关视频。 会议结束 感谢参与者：会议在积极的氛围中结束，期待下一次会议的交流。 本次会议为Ceph用户和开发者提供了一个宝贵的交流平台，促进了问题的解决和技术的进步。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk: A Different Scale, Running Small Ceph Clusters in Multiple Data Centers 20200723","slug":"Ceph_Tech_Talk_-_A_Different_Scale_Running_Small_Ceph_Clusters_in_Multiple_Data_Centers_20200723","date":"2020-07-27T16:00:00.000Z","updated":"2020-07-28T16:00:00.000Z","comments":true,"path":"2020/07/28/Ceph_Tech_Talk_-_A_Different_Scale_Running_Small_Ceph_Clusters_in_Multiple_Data_Centers_20200723/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/28/Ceph_Tech_Talk_-_A_Different_Scale_Running_Small_Ceph_Clusters_in_Multiple_Data_Centers_20200723/","excerpt":"","text":"会议纪要 会议主题： 讨论小型子集群（small subclusters）在多数据中心中的应用 主讲人： Yuval（系统工程师，拥有17年系统工作经验，目前在柏林工作，自2017年起开始使用Ceph） 会议内容总结： 个人背景介绍： Yuval拥有17年系统工作经验，涉及多种存储系统。 目前在柏林工作，担任系统工程师，工作范围广泛。 自2017年起开始使用Ceph，首次接触的生产版本是Jewel。 讨论小型子集群的原因： 小型集群不仅实用，而且具有隐藏的优势。 小型集群易于扩展和管理，可以根据需要增加磁盘或节点。 使用案例介绍： 当前在不同地点运行多个小型子集群。 计划在未来几个月内升级到Octopus版本。 集群配置为四节点，三路复制，每个集群有三台监控器和三台管理器。 使用Ceph作为后端存储，直接连接到虚拟磁盘。 关于小型集群的常见问题： 是否需要四节点？是否浪费资源？ 小型集群的优势包括避免脑裂问题、可调整的复制级别、易于扩展和维护。 小型集群与大型集群的比较： 小型集群更易于手动管理，自动化需求较低。 手动升级和维护时间较短，例如从Mimic升级到Nautilus仅需40分钟。 生产环境中的真实故事： 从HDD迁移到SSD的不同策略。 节点更换和命名一致性的重要性。 减少PG数量以适应新的OSD配置。 集群间服务迁移的策略，使用Zstandard压缩算法进行数据迁移。 问答环节： 讨论了PG数量和内存使用的相关问题。 分享了关于PG比例和内存使用的实际经验。 决定事项： 小型集群在多数据中心中的应用具有实际优势，特别是在避免脑裂问题、易于管理和扩展方面。 小型集群的维护和升级相对简单，适合手动管理。 后续行动计划： 继续监控和优化小型集群的性能和资源使用。 考虑在未来的升级中采用更高效的数据迁移策略。 会议结束： 感谢参与者的提问和分享，鼓励进一步的技术交流和合作。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-07-27","slug":"Ceph_Orchestrator_Meeting_2020-07-27","date":"2020-07-26T16:00:00.000Z","updated":"2020-07-27T16:00:00.000Z","comments":true,"path":"2020/07/27/Ceph_Orchestrator_Meeting_2020-07-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/27/Ceph_Orchestrator_Meeting_2020-07-27/","excerpt":"","text":"会议纪要 会议概要 会议主题: 今日的Orchestrator会议 参会人员: 团队成员 会议日期: [具体日期] 主要议题与讨论内容 Bug修复与性能提升 上周进行了多项小bug的修复。 实现了OSD创建速度的大幅提升，现在可以并行在至少10个主机上同时执行，速度提升约10倍。 文档更新与代码审查 Karen Kevin提交了几个针对fadm文档的上游PR，请求团队成员进行审查。 确认了GitHub用户名的正确性以便后续的代码审查工作。 Rook 1.4版本准备 正在为Rook 1.4版本做准备，等待CSI 3.0版本的发布，该版本今日已发布。 计划下周创建分支并发布Rook 1.4版本。 Orchestrator设计哲学讨论 讨论了Orchestrator在处理demon失败时的行为和设计理念。 目前Orchestrator在demon失败后不会自动重新调度，依赖于systemd进行重启。 讨论了是否应该增加自动重新调度的功能，以及这可能带来的复杂性。 文档与安装指南更新 讨论了即将推出的Crisp安装指南的更新，该指南将被拆分为多个小PR以便审查。 寻求图形设计方面的帮助，特别是按钮设计。 决定事项 确认了GitHub用户名的正确性，以便进行代码审查。 确定了Rook 1.4版本的发布计划。 讨论了Orchestrator在处理demon失败时的行为，但未做出具体决定。 后续行动计划 继续进行Rook 1.4版本的准备工作。 提交并审查Crisp安装指南的多个PR。 寻求图形设计方面的帮助，以改进文档的视觉效果。 其他事项 无其他重要事项。 会议结束 会议在高效和快速的节奏中结束，期待下周再次会面。 备注: 本次会议纪要基于会议录音整理，确保了关键信息的准确性和完整性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-07-22","slug":"Ceph_Crimson_SeaStor_OSD_2020-07-22","date":"2020-07-22T16:00:00.000Z","updated":"2020-07-23T16:00:00.000Z","comments":true,"path":"2020/07/23/Ceph_Crimson_SeaStor_OSD_2020-07-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/23/Ceph_Crimson_SeaStor_OSD_2020-07-22/","excerpt":"","text":"会议纪要 关键细节 参与者: 分布式存储Ceph研发团队成员 日期: [具体日期] 主要议题: 讨论Ceph存储系统的优化和设计问题 讨论的主要议题 LBA树的修改: 对LBA树进行了32x的扩展，并提出了一些问题，计划后续讨论。 设计了Oman树的布局，计划在后续会议中详细讨论。 ** scrub功能的进展**: 目前正在进行scrub功能的基本工作，包括preemption的测试和一些可选间距问题的修改。 内存管理优化: 提出了将大部分空间管理移至内存中的想法，通过扫描LBA树来计算每个段的块使用情况，并在内存中维护这些数据。 讨论了在清理段时可能需要进行多次读取以确定块是否仍在使用，但认为这对于QLC闪存是可接受的。 模板和remover问题: 仍在解决模板相关的问题，特别是remover的实现，编译器提示remover是不完整的类型。 计划继续努力解决这些问题，并在单元测试中进行验证。 OMAP树布局: 讨论了OMAP树的内部节点和叶子节点的布局设计，包括键和值的存储方式。 提出了如果键或值过大，可以考虑单独分配空间的想法。 决定的事项 将继续推进scrub功能的开发和测试。 将实施内存管理优化的方案，并进行性能测试。 将继续解决模板和remover的问题，并在单元测试中验证。 将设计并实现OMAP树的布局，并考虑键和值的最大尺寸问题。 后续行动计划 进行内存管理优化的性能测试，评估其在实际应用中的表现。 解决模板和remover的问题，确保代码的完整性和正确性。 设计和实现OMAP树的布局，并在后续会议中讨论具体的实现细节。 在接下来的几周内，将继续推进上述工作，并根据需要进行调整和优化。 其他备注 下一周将有一位团队成员休假，但仍可通过电子邮件联系。 本次会议为Ceph存储系统的优化和设计提供了明确的方向和行动计划，确保了项目的持续进展和团队成员之间的有效沟通。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-07-20","slug":"Ceph_Orchestrator_Meeting_2020-07-20","date":"2020-07-19T16:00:00.000Z","updated":"2020-07-20T16:00:00.000Z","comments":true,"path":"2020/07/20/Ceph_Orchestrator_Meeting_2020-07-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/20/Ceph_Orchestrator_Meeting_2020-07-20/","excerpt":"","text":"会议纪要：Ceph Orchestrator 会议 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： 包模式（Package Mode）问题讨论 问题描述：包模式依赖于在所有主机上安装的 cephadm 二进制文件，升级过程复杂，因为对 cephadm 二进制文件的兼容性要求极高。如果不在容器化基础设施中，它基本上是外部依赖，这使得升级和更新 cephadm 变得非常困难。 讨论内容： 包模式的升级问题，特别是从 -2 版本升级时，用户更新 cephadm 的时间不确定。 需要保持与前两个主要版本和后两个次要版本的兼容性，目前无法提供。 决定事项： 暂时移除包模式，因为它未被文档化。 未来如有需求，可以考虑重新启用。 升级用户体验改进 问题描述：当前用户在升级集群时需要指定具体的 Ceph 版本，如 15.2.6，用户需要知道可用的版本并手动更新。 讨论内容： 讨论是否需要改进用户体验，例如提供 cephadm upgrade start --latest 选项来更新到最新的次要版本。 需要考虑如何实现这一功能，可能需要查询容器注册表以获取最新版本。 决定事项： 考虑添加 latest 选项，但需要进一步讨论和实现细节。 容器挂载问题 问题描述：容器停止后，容器挂载未正确刷新。 讨论内容： 需要进一步调查和解决此问题，可能需要调整测试环境或文档。 决定事项： 跟踪问题并寻找解决方案。 其他事项 Cephadm 安装指南：Zach 计划在本周三前提交 Cephadm 安装指南的 PR，鼓励大家提供反馈。 Rook 1.4 计划：Rook 1.4 计划在本月底发布，主要等待 CSI 3.0 发布。 后续行动计划： 包模式问题： 移除包模式，未来根据需求重新考虑。 考虑在 Orchestrator 中添加检查，确保所有主机上的 cephadm 版本正确。 升级用户体验： 讨论并实现 cephadm upgrade start --latest 选项。 容器挂载问题： 跟踪并解决容器挂载刷新问题。 Cephadm 安装指南： Zach 提交 PR，社区成员提供反馈。 Rook 1.4 发布： 等待 CSI 3.0 发布，计划本月底发布 Rook 1.4。 会议结束： 会议于[具体时间]结束，下次会议将在下周的 Orchestrator 会议中继续讨论。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-07-16","slug":"Ceph_Performance_Meeting_2020-07-16","date":"2020-07-15T16:00:00.000Z","updated":"2020-07-16T16:00:00.000Z","comments":true,"path":"2020/07/16/Ceph_Performance_Meeting_2020-07-16/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/16/Ceph_Performance_Meeting_2020-07-16/","excerpt":"","text":"会议纪要 会议概要 日期与时间: 具体日期未提供，会议在早晨开始。 参会人员: 会议参与者包括但不限于Josh、Matt、Igor、Radik等。 讨论的主要议题 PR合并情况: 讨论了多个PR的合并情况，包括性能测试、Jenkins失败原因、以及一些具体的技术实现细节。 提到了PR在Octopus版本的回溯问题。 性能优化: 讨论了MD的日志记录性能问题，特别是活跃的MDS配置下的日志记录代码开销。 探讨了使用Denk编码框架的可能性及其潜在问题。 RocksDB性能问题: Igor分享了RocksDB在大量删除操作后的性能问题，特别是在高负载下的表现。 讨论了手动压缩作为临时解决方案的有效性，以及自动压缩的潜在需求。 决定的事项 需要进一步研究和实验以确定Denk编码框架的可行性和性能提升。 对于RocksDB的性能问题，需要一个可靠的复现案例来进行深入分析和解决方案的开发。 后续行动计划 继续研究和实验Denk编码框架，特别是Radik将探索使用循环缓冲区来优化内存分配。 寻找和建立RocksDB性能问题的可靠复现案例，以便进行针对性的优化。 考虑实施自动压缩机制，以减轻手动压缩的负担。 其他备注 会议中提到了多个具体的PR和代码变更，这些细节对于后续的技术实现和问题解决具有重要参考价值。 强调了团队合作和持续改进的重要性，特别是在面对复杂的技术挑战时。 结论 会议对当前的技术挑战进行了深入的讨论，并制定了具体的后续行动计划。团队将继续致力于性能优化和问题解决，以提升Ceph存储系统的稳定性和效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-07-15","slug":"Ceph_Crimson_SeaStor_OSD_2020-07-15","date":"2020-07-14T16:00:00.000Z","updated":"2020-07-15T16:00:00.000Z","comments":true,"path":"2020/07/15/Ceph_Crimson_SeaStor_OSD_2020-07-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/15/Ceph_Crimson_SeaStor_OSD_2020-07-15/","excerpt":"","text":"会议纪要 会议概要 日期：[具体日期] 参会人员：[参会人员名单] 主持人：[主持人姓名] 主要议题 Ceph存储系统的开发进展 讨论了关于Ceph存储系统中的中断处理机制的改进，特别是关于中断可继续性的问题。 讨论了如何改进PR（Pull Request）的审查流程，以减少不必要的评论和提高效率。 技术细节讨论 讨论了如何通过使用管道（pipeline）方式来优化文件处理和其他事件处理的性能。 讨论了如何通过检查中断条件来中断正在进行的IO处理。 代码和功能改进 讨论了如何改进插入逻辑和模板的使用，以便在内部节点中共享相同的逻辑。 讨论了如何准备和分享元素在兄弟节点或同事之间的知识。 项目管理和时间安排 讨论了项目的时间安排，特别是考虑到即将在英格兰举行的虚拟会议，部分成员将减少工作时间。 决定事项 决定继续探索和改进中断处理机制，特别是通过使用管道方式来优化性能。 决定简化PR审查流程，减少不必要的评论，提高审查效率。 决定在代码中增加更多的检查点，以确保操作在恢复后仍然有效。 后续行动计划 继续开发和测试中断处理机制的新方法。 优化PR审查流程，确保审查的效率和质量。 在代码中实施更多的检查点，以提高系统的稳定性和可靠性。 确保项目的时间安排考虑到即将举行的虚拟会议的影响。 其他事项 讨论了如何更好地分享和整合系统内存与sISTAR。 讨论了如何进行map tree的调查和研究。 会议结束 会议在讨论了所有议题和决定后结束，感谢所有参与者的贡献和讨论。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthrough 2020-07-14: Dmclock","slug":"Ceph_Code_Walkthrough_2020-07-14_-_Dmclock","date":"2020-07-13T16:00:00.000Z","updated":"2020-07-14T16:00:00.000Z","comments":true,"path":"2020/07/14/Ceph_Code_Walkthrough_2020-07-14_-_Dmclock/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/14/Ceph_Code_Walkthrough_2020-07-14_-_Dmclock/","excerpt":"","text":"会议纪要 会议概述 本次会议是关于Ceph分布式存储系统中dmclock算法的实现讨论。会议由Eric主持，旨在回顾和讨论dmclock算法在Ceph中的应用和改进。 主要议题 dmclock算法介绍： dmclock是一种分布式服务质量（QoS）算法，用于在Ceph的OSD（对象存储守护进程）中提高公平性。 该算法基于mclock算法，并进行了分布式扩展，称为dmclock。 算法实现细节： dmclock算法作为库实现，包含头文件和模板化代码，可以灵活应用于多种场景。 算法的核心在于客户端和服务器端的交互，服务器不共享客户端信息，而是由客户端跟踪服务历史。 代码结构和组织： dmclock代码作为Ceph的子模块，包含客户端和服务器端的实现。 代码中使用了间接 intrusive heap数据结构来管理客户端请求的优先级。 性能和优化： 讨论了dmclock算法在Ceph中的性能表现和潜在的优化点。 提到了一些操作可能较为昂贵，例如通过过滤移除请求的操作。 决定事项 确认了dmclock算法在Ceph中的重要性和当前的实现状态。 讨论了算法的性能和可能的改进方向。 后续行动计划 继续优化dmclock算法的性能，特别是在处理请求过滤和移除操作方面。 鼓励社区成员参与dmclock算法的讨论和改进，特别是在Ceph社区中有经验的开发者。 其他备注 会议中提到了几位关键开发者（如Sam、Casey、Abhishek）在dmclock算法上的贡献。 Eric表示愿意回答关于dmclock算法的具体问题，尽管他可能需要一些时间来回顾相关细节。 本次会议为Ceph社区成员提供了一个深入了解和讨论dmclock算法的机会，有助于推动该算法在Ceph中的进一步应用和优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-07-13","slug":"Ceph_Orchestrator_Meeting_2020-07-13","date":"2020-07-12T16:00:00.000Z","updated":"2020-07-13T16:00:00.000Z","comments":true,"path":"2020/07/13/Ceph_Orchestrator_Meeting_2020-07-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/13/Ceph_Orchestrator_Meeting_2020-07-13/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： Fezzik, Travis, Oh, Mike, 以及其他相关人员 会议主持： [主持人姓名] 主要议题及讨论内容： Rook集成测试问题 讨论了Rook集成测试因近期更改而中断的问题。 决定暂时禁用该测试，并计划重新启用。 Kiefel提交了一个PR，预计将修复该问题。 后续行动：重新启用并监控测试，确保其正常运行。 容器镜像重命名 讨论了CI构建的容器镜像重命名的问题。 Deepika上周完成了相关工作，目前镜像重命名功能已恢复正常。 Drive Groups功能 讨论了Drive Groups功能的进展，目前仍在等待上游合并。 正在进行私有构建的测试，结果良好。 后续行动：继续等待上游合并，并进行进一步测试。 Rook Monitor模块的Placement Specifications 讨论了Rook Monitor模块中Placement Specifications的实现问题。 决定使用Kubernetes的Placement Specifications，而非Orchestrator风格的Placement Specifications。 需要进一步的示例和指导。 后续行动：提供更多示例，确保正确实现。 新成员介绍 介绍了新成员Karen Norma，她将负责文档工作。 Karen将专注于Ceph ADM和安装程序的文档，以及与Orchestrator相关的部分。 后续行动：与Karen建立联系，提供必要的资源和支持。 其他事项 讨论了SEF ADM安装指南的编写，建议与现有文档进行整合。 后续行动：安排会议，讨论具体细节。 决定事项： 重新启用并监控Rook集成测试。 继续推进Drive Groups功能的测试和合并。 提供更多Placement Specifications的示例和指导。 与Karen Norma建立联系，支持其文档工作。 后续行动计划： 监控Rook集成测试的运行情况。 继续跟进Drive Groups功能的上游合并。 提供Placement Specifications的示例和指导。 安排与Karen Norma的会议，讨论文档编写细节。 会议结束时间： [具体时间] 下次会议预告： 下周同一时间 备注： 请各位参会人员关注邮件和IRC频道，获取更多更新和资源。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-07-08","slug":"Ceph_Crimson_SeaStor_OSD_2020-07-08","date":"2020-07-07T16:00:00.000Z","updated":"2020-07-08T16:00:00.000Z","comments":true,"path":"2020/07/08/Ceph_Crimson_SeaStor_OSD_2020-07-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/08/Ceph_Crimson_SeaStor_OSD_2020-07-08/","excerpt":"","text":"会议纪要 关键细节 Ceph 存储系统稳定性测试： 使用 BB C locator 进行压力测试，成功解决由构建 locator chip 引起的崩溃问题。 在 CentOS 8 环境下，尝试通过基于 total 的环境将地址转换为堆栈回溯，并重复测试。 RocksDB 与 Ceph 集成问题： 讨论了 RocksDB 在 Ceph 中的使用问题，特别是 RocksDB 创建的存储与 Ceph 存储池的兼容性问题。 提出解决方案：通过覆盖创建的符号来中断物理存储，并在创建时配置存储池。 Ceph 存储地址对齐测试： 讨论了非页面对齐地址的测试，确保测试案例涵盖非页面对齐的逻辑地址。 计划编写测试案例并提供 PR 供审查。 Crimson 存储引擎的开发： 讨论了 Crimson 存储引擎的开发进展，包括回填（backfill）和恢复（recovery）功能的实现。 强调了 Crimson 与经典 OSD 在事件调度和处理上的差异，特别是在多管道处理和事件同步方面。 主要议题 Ceph 存储系统的稳定性与性能优化： 通过压力测试和地址转换技术解决系统崩溃问题。 优化 RocksDB 与 Ceph 的集成，确保存储一致性和性能。 Crimson 存储引擎的功能开发与测试： 详细讨论了 Crimson 引擎的回填和恢复功能的实现细节。 强调了代码的可测试性和与经典 OSD 的兼容性。 决定事项 继续推进 Crimson 存储引擎的开发： 确保 Crimson 引擎的回填和恢复功能与经典 OSD 兼容，并优化事件调度和处理机制。 编写和审查非页面对齐地址的测试案例： 确保测试案例覆盖所有可能的非页面对齐逻辑地址，并提供 PR 供社区审查。 后续行动计划 继续进行 Crimson 存储引擎的开发和测试： 完成回填和恢复功能的实现，并进行详细的测试以确保稳定性。 优化 RocksDB 与 Ceph 的集成： 通过覆盖符号和配置存储池来解决 RocksDB 创建的存储与 Ceph 存储池的兼容性问题。 编写和审查非页面对齐地址的测试案例： 确保测试案例的全面性和准确性，并提交 PR 供社区审查。 本次会议详细讨论了 Ceph 存储系统的多个关键问题，并制定了明确的后续行动计划，以确保系统的稳定性和性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph DocuBetter Meeting 2020-07-08","slug":"Ceph_DocuBetter_Meeting_2020-07-08","date":"2020-07-07T16:00:00.000Z","updated":"2020-07-08T16:00:00.000Z","comments":true,"path":"2020/07/08/Ceph_DocuBetter_Meeting_2020-07-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/08/Ceph_DocuBetter_Meeting_2020-07-08/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： 文档整合提案：讨论了关于整合dock站点文档的提案，但尚未发送给相关人员。计划在下次会议上进行详细讨论。 Ceph开发进展：提到了最近对Ceph的负载均衡器功能的更新，以及正在进行的家庭搬迁事宜。 文档更新与审核：讨论了关于PRF用户负载均衡器的文档更新，建议由Andrew和Oliver进行审核，因为他们是负载均衡器团队的成员。 Ceph文档会议取消：由于Deucey刚刚收购了Ranch，原定的Ceph io文档会议被取消，团队成员将参加关于收购的全员会议。 开发者指南更新：提出了对开发者指南的更新需求，认为不需要完全重写，而是进行必要的更新。已经创建了几个跟踪器bug来记录需要更新的内容。 决定事项： 确定由Andrew和Oliver负责审核PRF用户负载均衡器的文档更新。 计划在下周初与相关人员讨论对象工具的文档更新。 后续行动计划： 发送整合dock站点文档的提案给相关人员。 安排与Andrew和Oliver的会议，以审核PRF用户负载均衡器的文档。 更新开发者指南，并跟踪相关bug。 下周初与Josh讨论对象工具的文档更新。 其他事项： 会议结束时间为凌晨3点，参会人员将尽快休息。 祝正在进行家庭搬迁的参会人员一切顺利。 会议结束语： 会议结束，祝大家下周再见。 备注：会议中提到的关键术语和团队成员姓名已保留原文，以便准确传达会议内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-07-06","slug":"Ceph_Orchestrator_Meeting_2020-07-06","date":"2020-07-05T16:00:00.000Z","updated":"2020-07-06T16:00:00.000Z","comments":true,"path":"2020/07/06/Ceph_Orchestrator_Meeting_2020-07-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/06/Ceph_Orchestrator_Meeting_2020-07-06/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [列出参会人员] 缺席人员： Sebastian, Miguel 会议议程 NFS Config Objects Rook Manager Test 问题 Saif EDM 的目标和时间线 会议内容 NFS Config Objects Jeff Leighton 添加了此议题，但无人回应。 Rook Manager Test 问题 当前 Rook 的 Manager Test 失败，该测试针对 master 分支运行，以便在发布前发现早期破坏性更改。 发现 OSD 创建问题，Miguel 在上周五提交了 PR，希望修复此问题。 由于 Sebastian 本周不在，建议暂时禁用该测试，待 Sebastian 回来后再处理。 Saif EDM 的目标和时间线 Saif EDM 被正式宣布为不使用 Rook 安装 Ceph 的首选方法。 文档中已明确指出，安装时推荐使用 Saif EDM。 决定事项 暂时禁用 Rook Manager Test，待 Sebastian 回来后再处理。 确认 Saif EDM 作为非 Rook 安装 Ceph 的主要方法。 后续行动计划 禁用 Rook Manager Test。 继续关注 Saif EDM 的文档和实施情况。 会议结束 会议在无其他议题提出后结束。 下次会议将在 Sebastian 和 Miguel 回归后进行。 会议总结： 本次会议主要讨论了 Rook Manager Test 的问题和 Saif EDM 的实施情况，决定暂时禁用 Rook Manager Test，并确认 Saif EDM 作为安装 Ceph 的主要方法。下次会议将在关键人员回归后继续进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Developer Monthly 2020-07-02","slug":"Ceph_Developer_Monthly_2020-07-02","date":"2020-07-01T16:00:00.000Z","updated":"2020-07-01T16:00:00.000Z","comments":true,"path":"2020/07/02/Ceph_Developer_Monthly_2020-07-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/02/Ceph_Developer_Monthly_2020-07-02/","excerpt":"","text":"会议纪要 会议概要 会议主题：Ceph Bridge July 2020 更新 参会人员：Ceph 开发团队成员 会议时间：2020年7月 主要议题 Ceph 近期进展概述 完成了第一轮的 portal 问题添加，包括基本的基础设施和接口，用于 DNS 设备，抽象化了顺序写入过程和事务结构。 实现了 B-tree 映射逻辑地址和统计地址，详细信息可在 Ceph 的 rst 文档中查看。 恢复和回填工作 正在进行的工作是使恢复和回填功能达到支持 2008 年的基本水平，大部分基础设施已经就位，等待基本支持的 PR 完成。 Crimson OST 集成 正在将 Crimson OST 集成到 Ceph 中，使用外部线程池和消息传递系统，已合并并可进行基准测试。 容器化部署 正在准备容器镜像，以便在 Docker 中运行 Crimson。已经解决了 Crimson 和 Seastar 名称不同的问题，正在进行相关工具的更新。 测试和功能完善 讨论了 Crimson 存储的当前限制，包括缺少垃圾回收和脏节点写入功能。 强调了恢复和回填测试的重要性，以及如何通过随机化测试来发现潜在的 bug。 后续行动计划 继续完善 Crimson OST 的功能，特别是恢复和回填功能。 完成容器镜像的准备，并确保 Ceph 部署工具能够支持新的容器化部署方式。 增加更多的测试，特别是针对恢复和回填的随机化测试。 决定事项 继续推进 Crimson OST 的集成和功能完善。 完成容器镜像的准备，并更新相关工具以支持新的部署方式。 增加针对恢复和回填的随机化测试，以确保系统的稳定性和可靠性。 后续行动计划 完成 Crimson OST 的恢复和回填功能的开发。 更新容器镜像和相关工具，确保能够支持新的部署方式。 增加更多的测试，特别是针对恢复和回填的随机化测试，以发现和修复潜在的 bug。 其他讨论 讨论了 Crimson 存储的当前限制和未来的改进方向。 强调了测试的重要性，特别是针对恢复和回填的随机化测试。 会议结束 感谢所有参与者的贡献，期待下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD Weekly 2020-07-01","slug":"Ceph_Crimson_SeaStor_OSD_Weekly_2020-07-01","date":"2020-06-30T16:00:00.000Z","updated":"2020-07-01T16:00:00.000Z","comments":true,"path":"2020/07/01/Ceph_Crimson_SeaStor_OSD_Weekly_2020-07-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/07/01/Ceph_Crimson_SeaStor_OSD_Weekly_2020-07-01/","excerpt":"","text":"会议纪要 关键细节 新成员介绍: Gabby 加入团队，拥有20年存储行业经验。 技术讨论: 主要围绕分布式存储系统 Ceph 的开发和优化进行。 后续行动计划: 确定了一些关键任务和优先级，包括实现和测试新的功能。 讨论的主要议题 Ceph 开发进展: 讨论了 Crimson 和 Classical OSD 的开发状态。 涉及到了 backfill 功能的实现和测试。 讨论了加密功能的实现，特别是 OpenSSL 和 SSE 的兼容性问题。 测试和验证: 强调了测试的重要性，特别是对于 OSD 的杀掉和重启测试。 讨论了如何通过测试来验证和优化系统的恢复和备份功能。 代码优化和重构: 提到了代码的重构和清理工作，以提高代码的可维护性和性能。 讨论了如何通过合并代码库来统一不同版本的功能。 新功能开发: 讨论了新的功能开发，如基于 PG log 的恢复和 scrubbing 功能。 提到了新的工作流程和代码审查的准备。 决定的事项 优先级设定: 确定了一些功能的优先级，特别是与 Crimson 相关的功能。 测试策略: 确定了通过 Crimson 作为测试平台来验证新代码的有效性。 代码重构: 决定进行代码重构以提高代码质量和可维护性。 后续的行动计划 实现和测试 backfill 功能: 继续在 Crimson 上实现和测试 backfill 功能。 加密功能开发: 继续研究 OpenSSL 和 SSE 的兼容性问题，并实现加密功能。 代码重构和优化: 进行代码重构和优化，以提高系统的性能和稳定性。 新功能开发: 开发和测试新的功能，如基于 PG log 的恢复和 scrubbing 功能。 其他事项 新成员适应: 帮助新成员 Gabby 快速适应团队和工作环境。 会议安排: 计划在下一个会议中讨论更多关于 Ceph 的技术细节和开发进展。 结论 本次会议主要讨论了 Ceph 存储系统的开发进展，包括新功能的实现、代码的重构和优化、以及测试策略的制定。团队将继续推进这些关键任务，以确保系统的稳定性和性能。同时，新成员 Gabby 的加入将为团队带来新的活力和经验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-06-29","slug":"Ceph_Orchestrator_Meeting_2020-06-29","date":"2020-06-28T16:00:00.000Z","updated":"2020-06-29T16:00:00.000Z","comments":true,"path":"2020/06/29/Ceph_Orchestrator_Meeting_2020-06-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/29/Ceph_Orchestrator_Meeting_2020-06-29/","excerpt":"","text":"会议纪要 会议概要 日期与时间: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 主要议题与讨论内容 CI系统恢复 CI系统已恢复正常运行，这是一个积极的进展。 Alice的替换问题 讨论了在行业中测试的Alice替换问题，涉及使用hominids属性创建OSD时的问题。 决定明确要求用户将unmanned instructor参数设置为true，以防止集群中的STI重读。 需要进一步的信息来确定问题的具体情况，计划创建一个影响报告。 Rook的拖拽组（drag groups） 讨论了Rook的节点亲和性和节点选择问题，决定采用社区的placement方法。 创建了一个相关的pull request（编号3552442），并计划与Blaine同步以获取更多关于高级Cuban a displacement规范的信息。 集成测试问题 讨论了集成测试中偶尔失败的问题，决定增加更多的日志信息以帮助诊断问题。 Rook客户端发现问题 Jeff Leighton创建了一个pull request，以从NSF组织切换到工作中的存储库，但由于不再支持在目录上部署OSD而导致失败。 需要移除对目录的支持，并更新Rook管理模块的schema检查。 升级测试 Yuri正在进行从Octopus到Pacific的升级测试，并已有一个pull request（编号35808）成功运行。 目前没有针对Pacific的升级测试，计划在未来进行。 决定事项 明确要求用户将unmanned instructor参数设置为true。 增加集成测试的日志信息以帮助诊断问题。 移除对目录的支持并更新Rook管理模块的schema检查。 后续行动计划 创建一个影响报告，收集更多关于Alice替换问题的信息。 与Blaine同步以获取更多关于高级Cuban a displacement规范的信息。 继续进行从Octopus到Pacific的升级测试，并计划未来进行Pacific的升级测试。 其他事项 本周工作进展较为缓慢，没有重大进展。 会议结束时，主持人提醒大家在下周继续同步工作进展。 会议结束 会议在简短的讨论后结束，主持人祝愿大家周末愉快，并期待下周的同步。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Code Walkthrough: Overview of the Monitor 2020-06-24","slug":"Ceph_Code_Walkthrough_-_Overview_of_the_Monitor_2020-06-24","date":"2020-06-24T16:00:00.000Z","updated":"2020-06-24T16:00:00.000Z","comments":true,"path":"2020/06/25/Ceph_Code_Walkthrough_-_Overview_of_the_Monitor_2020-06-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/25/Ceph_Code_Walkthrough_-_Overview_of_the_Monitor_2020-06-24/","excerpt":"","text":"会议纪要 会议主题：Ceph Monitor代码架构与系统组件概述 参会人员：Josh、Greg等 会议内容： Ceph Monitor架构概述 主要组件：Ceph Monitor代码位于sourcetree内部，关键文件包括monitor.h和monitor.cc。 功能描述：Monitor是一个分布式系统，通过选举产生领导者（leader），领导者负责处理系统中的所有更新请求，并授予PMs（Placement Groups）租约，以便它们可以为Ceph系统的客户端提供读取服务。 选举机制 选举逻辑：所有Monitor通过Elector和选举逻辑组件进行领导者选举。 领导者职责：领导者负责排序所有传入的更新，并管理租约授予。 数据存储与消息处理 数据存储：使用LevelDB作为Monitor的数据存储，通过MonitorDBStore类进行封装。 消息处理：创建基于MonitorMap的消息处理机制，用于处理所有消息。 启动与初始化 启动流程：Monitor启动时进行一系列初始化操作，包括解析标志、创建数据存储、设置消息传递机制等。 Bootstrap过程：确保Monitor进入法定人数（quorum）并保持最新状态。 消息与请求处理 消息类型：Monitor处理多种消息类型，包括命令类型。 请求处理：通过handle_command函数处理命令，最终分发到特定的Monitor组件进行处理。 更新与提交 更新机制：通过Paxos算法进行更新提议，一旦多数系统成员确认，更新即被提交。 定时器与提议：定期提议更新以保持系统进度，避免频繁更新导致系统过载。 决定事项： 确认了Ceph Monitor的核心架构和关键组件。 明确了选举机制、数据存储、消息处理和更新提交的具体流程。 后续行动计划： 继续优化和更新Monitor的收集系统。 深入研究特定Monitor组件的实现细节，如OSD Monitor。 会议结束： 感谢Greg的详细讲解，参会人员对Ceph Monitor的架构和运作有了更深入的理解。会议在提问环节结束后圆满结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Tech Talk 2020-06-25: Solving the Bug of the Year","slug":"Ceph_Tech_Talk_2020-06-25_-_Solving_the_Bug_of_the_Year","date":"2020-06-24T16:00:00.000Z","updated":"2020-06-25T16:00:00.000Z","comments":true,"path":"2020/06/25/Ceph_Tech_Talk_2020-06-25_-_Solving_the_Bug_of_the_Year/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/25/Ceph_Tech_Talk_2020-06-25_-_Solving_the_Bug_of_the_Year/","excerpt":"","text":"会议纪要 会议主题： 解决年度Bug的技术分享 主讲人： Dan（来自CERN IT部门） 会议时间： [具体日期未提供] 会议地点： 线上 参会人员： Ceph社区成员及相关技术人员 会议内容总结： 背景介绍： CERN（欧洲核子研究组织）位于日内瓦，拥有世界上最大的机器——大型强子对撞机（LHC），并因发现希格斯玻色子而闻名。 Ceph自2013年起成为CERN IT基础设施的关键部分，特别是用于OpenStack的块存储和对象存储。 CERN拥有约10个Ceph集群，总存储容量达35 PB。 问题描述： 2020年2月20日，CERN的OpenStack块存储系统突然宕机，25%的OSD（对象存储守护进程）失效，导致所有I/O操作被阻塞。 经过初步调查，发现OSD进程无法重启，日志文件显示OSD映射（OSD map）存在CRC错误。 诊断与解决过程： 通过与Ceph社区的交流，快速定位到一个已知的相关问题，并找到了一个临时解决方案。 从Mon节点提取未损坏的OSD映射版本，覆盖损坏的版本，恢复了集群的运行。 进一步分析发现，损坏的OSD映射存在多个比特位翻转，怀疑是内存ECC错误、网络包损坏或软件bug。 根本原因分析： 排除了内存ECC错误和网络包损坏的可能性。 发现问题与LZ4压缩算法有关，特别是当压缩未对齐的内存时，可能导致数据损坏。 通过与LZ4开发者合作，确认了问题并找到了修复方案。 后续行动计划： 计划引入块存储可用性区域，以提高系统的容错能力。 将持续关注Ceph社区的更新，并考虑升级操作系统中的LZ4库版本。 感谢与致谢： - 感谢Ceph社区成员，特别是Dirtwash、Troy和Eric的帮助。 - 感谢CERN IT团队的同事们，以及LZ4算法的开发者。 会议结束： - 会议内容将被录制并上传至YouTube。 备注： - 本次会议详细讨论了Ceph集群中遇到的一个罕见但严重的Bug，以及如何通过社区合作和技术分析找到并解决问题的过程。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD 2020-06-24","slug":"Ceph_Crimson_SeaStor_OSD_2020-06-24","date":"2020-06-23T16:00:00.000Z","updated":"2020-06-24T16:00:00.000Z","comments":true,"path":"2020/06/24/Ceph_Crimson_SeaStor_OSD_2020-06-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/24/Ceph_Crimson_SeaStor_OSD_2020-06-24/","excerpt":"","text":"会议纪要 参会人员 Tommy 其他相关人员 会议时间 日期：具体日期未提供 时间：具体时间未提供 会议议题 Ceph存储系统的开发进展 技术问题讨论与解决方案 后续行动计划 会议内容 Ceph存储系统开发进展 Tommy上周仍在处理异步another tree，并审查了一些由Ritek编写的优秀blue storylines。 本周计划完成heartbeat的审查，并处理由工程师Stem提交的replicas by place。 技术问题讨论 缓存依赖追踪：Tommy正在为缓存添加支持，以跟踪依赖关系并确保所有父级extent被固定。这意味着任何逻辑extent（如extent tree或oh no tree extent）在内存中时，其所有映射页在lba tree中也将保持在内存中。 零拷贝数据序列化：Tommy正在调查零拷贝数据序列化方法，如flat buffers，以解决当前编码和解码方法消耗过多CPU的问题。 Crimson测试与优化：Tommy强调在Crimson运行自动化测试之前，不考虑进行性能优化，以避免引入新的bug。 后续行动计划 Crimson自动化测试：Tommy计划首先确保Crimson的自动化测试工作，以便后续可以自信地进行性能优化。 Topology工作：Tommy提到关于topology的工作接近完成，并寻求志愿者来处理pathology代码。 技术支持与访问：讨论了获取实验室访问权限的流程，以便能够运行pathology作业。 决定事项 确保Crimson的自动化测试工作是当前的首要任务。 需要获取实验室访问权限以进行进一步的开发和测试。 后续行动 Tommy将发送相关链接并在30分钟后再次联系。 评估使用现有dot pi安装Crimson OSD的工作量，并选择更简便的方法。 会议结束 会议在感谢和告别中结束。 备注：会议中提到的技术术语和项目名称如“async another tree”、“heartbeat”、“replicas by place”、“flat buffers”等，保留了英文原文以确保准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-24 :: Ceph Code Walkthrough: RGW Multisite Replication","slug":"2019-05-24_-_-_Ceph_Code_Walkthrough_-_RGW_Multisite_Replication","date":"2020-06-21T16:00:00.000Z","updated":"2020-06-22T16:00:00.000Z","comments":true,"path":"2020/06/22/2019-05-24_-_-_Ceph_Code_Walkthrough_-_RGW_Multisite_Replication/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/22/2019-05-24_-_-_Ceph_Code_Walkthrough_-_RGW_Multisite_Replication/","excerpt":"","text":"会议纪要 会议主题：Ceph多站点代码走查 主讲人：[主讲人姓名] 会议时间：[会议日期] 会议内容总结： 高层次概述： 主讲人介绍了基于日志的复制工作原理，包括不同类型的多站点日志、读取模型和协同程序（co-routines）的工作方式。 讨论了元数据和数据同步的代码细节。 日志基础复制： 在两个不同集群（位于世界不同地区）之间，每个集群上放置一个Zone，并将它们链接在一起。 当一个Zone（Zone A）进行更改时，它会在本地将更改写入日志，另一个Zone（Zone B）会从Zone A读取日志并获取最新副本。 主要日志类型： 元数据日志：记录用户和桶的所有更改。 桶索引日志：存储在桶索引中，记录对象的所有更改。 数据更改日志：记录哪些桶及其分片有更改。 日志分片： 这些多站点日志被分片存储在多个Rados对象中，以分散读取和写入操作，以及在同一Zone内运行的不同网关之间分散复制工作。 线程模型： 每个源Zone都有一个元数据同步线程和一个数据同步线程。 元数据同步有一个主Zone，其他Zone只从主Zone同步。 数据同步是主动-主动模式，每个Zone都从其他Zone同步数据。 协同程序框架： 协同程序（co-routines）用于处理多个分片并行工作，避免线程阻塞。 协同程序框架包括协同程序类、堆栈和调度管理器。 元数据同步： 元数据同步从主Zone读取元数据日志，并将其存储在本地。 元数据同步包括全量同步和增量同步。 数据同步： 数据同步处理数据更改日志，并启动桶同步进程。 数据同步也包括全量同步和增量同步。 桶同步： 桶同步从其他Zone读取桶索引日志，并处理日志条目。 桶同步包括全量同步和增量同步。 问题与讨论： 讨论了协同程序的调用方式、日志分片的管理、错误处理和重试机制。 解答了关于多部分对象处理、元数据同步的删除识别、Zone和Zone Group的配置等问题。 决定事项： 需要对代码中的魔法数字（magic numbers）进行审查和优化。 确认了协同程序框架的设计和使用方式。 后续行动计划： 继续优化和审查代码中的魔法数字。 深入理解协同程序框架的实现和应用。 确保多站点复制的稳定性和性能。 会议结束： 会议在预定时间内圆满结束，感谢所有参与者的积极参与和提问。 注： 以上纪要涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。涉及的计算机科学/Ceph相关领域英文原文关键词已保留。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-06-22","slug":"Ceph_Orchestrator_Meeting_2020-06-22","date":"2020-06-21T16:00:00.000Z","updated":"2020-06-22T16:00:00.000Z","comments":true,"path":"2020/06/22/Ceph_Orchestrator_Meeting_2020-06-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/22/Ceph_Orchestrator_Meeting_2020-06-22/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph存储系统的当前状态、遇到的问题以及未来的行动计划。会议涉及了多个关键议题，包括Ceph的部署、配置管理、文档改进以及测试框架的更新。 主要议题与讨论 Ceph状态更新 受到CPR长期自定义错误的影响，上周无法合并任何专业请求。 容器注册表构建失败，希望从今天开始恢复正常。 网关守护进程的适配问题 讨论了如何安全地适配现有的网关守护进程，提出了构建包含服务器规范的模板的方法。 强调了在官方文档中明确说明这一过程的重要性。 基于YAML的通信问题 讨论了与Nvidia的FIDM通信问题，特别是使用YAML配置时的错误处理和用户体验。 提出了改进建议，包括更好的文档说明和默认行为的调整。 集群配置的安全性 讨论了在修改集群配置时的安全性问题，特别是关于监控服务的最小实例数。 决定不限制用户配置，但会增加警告和确认步骤以确保用户了解潜在风险。 自动部署OSD的行为 讨论了用户对自动部署OSD的期望和实际行为之间的差异。 决定保持当前的自动部署行为，但会在文档中更明确地说明这一特性。 Ceph部署工具的定位 讨论了Ceph部署工具（如Ceph-Ansible）的定位，强调了其作为安装工具而非管理工具的角色。 提出了改进建议，包括更明确的规范文件和避免自动修改用户配置。 测试框架的更新 讨论了升级测试套件的进展，特别是关于RBD和RGW的测试。 计划继续扩展测试套件，并解决依赖于旧构建的问题。 决定事项 网关守护进程的适配 将提供一个包含服务器规范的模板，以安全地适配网关守护进程。 基于YAML的通信改进 将改进文档，明确说明YAML配置的使用方法和潜在风险。 集群配置的安全性 将增加警告和确认步骤，以确保用户在修改集群配置时了解潜在风险。 自动部署OSD的行为 将保持当前的自动部署行为，并在文档中更明确地说明。 Ceph部署工具的定位 将明确Ceph部署工具的定位，并改进规范文件和避免自动修改用户配置。 后续行动计划 改进文档 更新和完善Ceph的文档，特别是在自动部署OSD和YAML配置的使用方面。 测试框架的扩展 继续扩展和改进测试框架，确保所有组件的稳定性和兼容性。 用户反馈的收集 收集用户反馈，特别是在Ceph部署和管理工具的使用体验方面。 持续监控和改进 持续监控Ceph系统的运行状态，及时发现并解决潜在问题。 结论 会议强调了文档的重要性，特别是在用户教育和行为预期方面。同时，会议也强调了测试框架的持续改进和用户反馈的收集，以确保Ceph系统的稳定性和用户满意度。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-06-18","slug":"Ceph_Performance_Meeting_2020-06-18","date":"2020-06-18T16:00:00.000Z","updated":"2020-06-19T16:00:00.000Z","comments":true,"path":"2020/06/19/Ceph_Performance_Meeting_2020-06-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/19/Ceph_Performance_Meeting_2020-06-18/","excerpt":"","text":"会议纪要 关键细节 UPR 本周无特别事项。 PR关闭情况： Adams的PR与rocks TV sharding工作相关，防止大型读取日志大小被使用，设置了最大上限。 另一个PR涉及buffer lists编码工作的测试，原计划在测试目录中进行，但建议移至项目外部。 旧PR来自ma Jinping，关于mocking，因无人跟进被关闭，考虑重新开启。 更新PR： 关于blocking traces的PR，Egor自分配但尚未有时间处理。 mem pools splitting PR，改进内存池的粒度，更细致地管理内存使用。 blue store walking PR，仍在解决QA中发现的问题。 MVS中的PR，旨在优化大量读写器和写入器访问单个目录时的性能。 讨论的主要议题 IO 500测试： 初步怀疑MDS中目录的碎片化和导出导致性能下降和停滞。 通过预碎片化和预导出片段进行优化，但在高MDS数量下仍存在低吞吐量和周期性停滞。 使用GB PNP分析发现，大量工作与Southwest journaling相关，特别是e meta blob数据结构的解码过程缓慢。 尝试使用unordered map和vector进行优化，但发现问题可能在于buffer list本身的小分配问题。 讨论了MDS多线程化的必要性，以提高性能。 决定的事项 需要进一步优化buffer list的编码过程，可能通过切换到新的编码方案来预留空间，减少内存分配和碎片化。 考虑MDS的多线程化，以利用多核优势。 后续行动计划 继续优化IO 500测试中的性能问题，特别是buffer list的编码和内存管理。 探索MDS的多线程化方案，以提高整体性能。 持续跟进和更新相关PR的状态，确保项目进展顺利。 其他事项 讨论了内存 footprint 减少和依赖逻辑简化的重要性，希望在下一个版本中实现。 会议结束时，鼓励团队成员继续努力，期待下周有新的进展。 结束语 会议结束，感谢大家的参与，祝大家下周工作顺利。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor 2020-06-17","slug":"Ceph_Crimson_SeaStor_2020-06-17","date":"2020-06-16T16:00:00.000Z","updated":"2020-06-16T16:00:00.000Z","comments":true,"path":"2020/06/17/Ceph_Crimson_SeaStor_2020-06-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/17/Ceph_Crimson_SeaStor_2020-06-17/","excerpt":"","text":"会议纪要 会议主题： 讨论Ceph存储系统中的Alien、Bluestar和Sea Star内存分配器的相关问题及改进方案 参会人员： [未列出具体人员] 会议时间： [未提供具体时间] 会议地点： [未提供具体地点] 主要议题： 内存分配器初始化问题： 发现两个主要问题：未初始化内存分配器池和线程在初始化时的限制。 Sea Star内存分配器需要两阶段初始化，需要线程协助以克服32级最大限制。 线程管理假设的违反： Bluestar的Troggs DB假设使用静态线程池管理线程，但实际情况并非如此。 需要讨论这一违反假设的后果及其解决方案。 根节点结构的改进： 正在改进根节点的结构，将其大小从16字节减少到仅包含三个物理地址。 这将简化代码并避免每次滚动日志时写入额外的空页。 心跳重构： 进行了心跳重构，以减少抽象并进行全面审查。 I/O测试： 询问是否能够使用最新的补丁进行I/O测试。 生产环境中的内存分配器问题： 讨论了在生产环境中使用Sea Star内存分配器的问题，特别是线程管理和内存回收。 提出了一些解决方案，如限制线程数量和调整配置。 配置管理和默认值： 讨论了是否需要为Bluestar设置不同的默认配置值。 决定首先进行配置验证，以确保错误配置不会导致系统崩溃。 决定事项： 内存分配器初始化： 需要进一步讨论和解决Sea Star内存分配器的初始化问题。 线程管理： 需要重新评估Bluestar的线程管理策略，并可能调整其配置。 根节点结构改进： 继续进行根节点结构的改进工作，以简化代码并提高效率。 配置验证： 首先进行配置验证，确保错误配置不会导致系统崩溃，后续再考虑调整默认配置。 后续行动计划： 内存分配器问题： 继续研究和解决Sea Star内存分配器的初始化问题。 线程管理策略： 重新评估Bluestar的线程管理策略，并制定相应的调整方案。 根节点结构改进： 完成根节点结构的改进，并进行代码清理和优化。 配置验证和调整： 实施配置验证机制，并根据需要调整默认配置值。 会议结束语： - 感谢大家的参与和讨论，期待后续的进展和成果。 下次会议预告： - [未提供具体信息] 会议记录人： - [未提供具体人员] 会议结束时间： - [未提供具体时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-06-15","slug":"Ceph_Orchestrator_Meeting_2020-06-15","date":"2020-06-14T16:00:00.000Z","updated":"2020-06-15T16:00:00.000Z","comments":true,"path":"2020/06/15/Ceph_Orchestrator_Meeting_2020-06-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/15/Ceph_Orchestrator_Meeting_2020-06-15/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 主要议题 Sofia Morgan的新需求 提出了一个新的需求，具体细节待补充。 新增Tautology测试 讨论了如何轻松添加新的Tautology测试到Ceph中，希望未来能广泛应用。 ETCD配置管理 正在研究ETCD配置管理，认为这是一个重要的功能。 Drive Groups规范 通过邮件已经基本解决了Drive Groups的规范问题，会议上再次确认了相关细节。 讨论了如何在Rook中处理Drive Groups，特别是如何将Drive Groups转换为Kubernetes的Placement规范。 开发环境讨论 讨论了多种开发环境的优缺点，包括使用restart、bootstrap和C start等。 提出了使用Kay CLI工具来创建和管理开发环境，该工具能够快速设置虚拟机并映射开发文件夹到主机，以便于开发和测试。 每日测试运行 讨论了设置每日自动运行Rook测试的计划，目前正在准备相关的基础设施。 决定事项 Drive Groups处理：确认了将Drive Groups转换为Kubernetes Placement规范的方法，并将在Rook中实施。 开发环境：鼓励使用Kay CLI工具来设置开发环境，并计划进一步完善相关文档和演示。 每日测试：将继续推进每日自动运行Rook测试的计划，确保测试的持续性和可靠性。 后续行动计划 Drive Groups实施：Sebastian将跟进Drive Groups的实施细节，并确保与Kubernetes Placement规范的正确转换。 开发环境优化：Sumukha将准备一个关于使用Kay CLI工具的演示，并更新开发文档。 每日测试设置：Paul Miguel将继续推进每日测试的自动化设置，并与Adam讨论CI的相关事宜。 其他 会议中还讨论了一些其他小议题，但未形成具体决议。 会议结束 会议在确认无其他议题后结束，并约定下周再次开会。 备注: 本次会议记录涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划，确保了会议内容的完整性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-06-11","slug":"Ceph_Performance_Meeting_2020-06-11","date":"2020-06-10T16:00:00.000Z","updated":"2020-06-11T16:00:00.000Z","comments":true,"path":"2020/06/11/Ceph_Performance_Meeting_2020-06-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/11/Ceph_Performance_Meeting_2020-06-11/","excerpt":"","text":"会议纪要 会议概览 本次会议主要讨论了Ceph项目的进展情况，包括新的Pull Request（PR）、已关闭的PR、更新的PR以及一些重要的技术讨论。会议还涉及了即将到来的开发冻结前的准备工作。 主要议题 新PR介绍 新增了一个PR，旨在为Blue Store添加阻塞跟踪（blocking traces）。目前尚未有人审查此PR，建议相关开发人员关注。 已关闭PR 一个旧的PR因长时间未更新被stale bot关闭，该PR涉及ARM架构的新测试。 更新PR 多个PR被更新，包括： Adam的PR，旨在防止RocksDB中的巨大写日志大小，涉及大量关于写日志大小、缓冲区设置和写入限制的讨论。 Ma Jinping的PR，关于启用RocksDB的流水线写入功能，尽管测试未见性能提升，但仍被认为是一个有价值的改进。 一个关于改进mempool跟踪的PR，将随机数据结构分解为更具体的部分，如packin extents、blobs等，被认为是很有前景的改进。 一个关于基准测试buffer list encode和decode的PR，讨论了是否应将此类测试移至外部。 重要技术讨论 讨论了Igor的PR，旨在修复一个罕见的段错误（seg fault），涉及boost库中的复杂数据结构操作。 讨论了避免双重缓存的PR，需要进行显著的重构，目标是6月底前完成。 讨论了mempool的使用和内存管理，特别是关于重新分配内存到mempool的问题。 讨论了优先级缓存管理器（PCM）的改进，希望通过更详细的内存使用统计来优化缓存管理。 其他事项 继续进行IO500测试，特别是关于预分割和预导出目录碎片的优化工作。 决定事项 需要对新PR进行审查和测试，特别是关于Blue Store的阻塞跟踪和RocksDB的流水线写入功能。 需要进一步讨论和优化mempool的使用和内存管理。 需要继续推进避免双重缓存的PR，并确保在开发冻结前完成。 后续行动计划 审查和测试新PR，确保其有效性和性能影响。 继续优化IO500测试，特别是预分割和预导出目录碎片的性能。 在开发冻结前完成重要PR的合并和优化工作。 会议结束 会议在讨论了所有议题后结束，感谢所有参与者的贡献，并祝愿大家有一个愉快的周末。下次会议再见。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/Seastor OSD Weekly 2020-06-10","slug":"Ceph_Crimson_Seastor_OSD_Weekly_2020-06-10","date":"2020-06-09T16:00:00.000Z","updated":"2020-06-09T16:00:00.000Z","comments":true,"path":"2020/06/10/Ceph_Crimson_Seastor_OSD_Weekly_2020-06-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/10/Ceph_Crimson_Seastor_OSD_Weekly_2020-06-10/","excerpt":"","text":"会议纪要 关键细节 异步版本开发：计划在下一周尝试开发异步版本，特别是在处理repellents of the leaf notice方面。 性能测试：进行了两个分支的性能测试，包括graceful shutdown PR，发现其对性能有3.5%的惩罚。同时，从istil到Lipsy的sweetened memory allocator转换对性能有50%的影响。 内存分配器问题：讨论了sister's memory allocator和alien stars的问题，发现了一些重要的误解和实际问题，特别是在多线程环境下的内存分配。 系统崩溃原因分析：分析了系统崩溃的原因，涉及到sister memory allocator的内存分配问题，特别是在处理大量线程时的行为。 后续行动计划：需要进一步调查和优化sister memory allocator，特别是在多线程环境下的表现。同时，需要对系统的内存分配策略进行调整和优化。 讨论的主要议题 异步版本的开发：讨论了异步版本的开发计划和当前的进展。 性能测试结果：分享了性能测试的结果，特别是graceful shutdown PR和内存分配器转换的影响。 内存分配器问题：深入讨论了sister's memory allocator和alien stars的问题，包括其在多线程环境下的表现和存在的问题。 系统崩溃原因：分析了系统崩溃的原因，特别是在处理大量线程时的内存分配问题。 决定的事项 异步版本开发：决定在下一周尝试开发异步版本，特别是在处理repellents of the leaf notice方面。 性能测试：确认了性能测试的结果，并决定进一步调查和优化内存分配器。 内存分配器问题：决定进一步调查和优化sister's memory allocator，特别是在多线程环境下的表现。 后续的行动计划 异步版本开发：继续开发异步版本，并关注其在实际应用中的表现。 性能测试：继续进行性能测试，并根据测试结果调整和优化内存分配策略。 内存分配器问题：进一步调查和优化sister's memory allocator，特别是在多线程环境下的表现。 系统崩溃原因：继续分析系统崩溃的原因，并寻找解决方案。 结论 本次会议主要讨论了异步版本的开发、性能测试结果、内存分配器问题以及系统崩溃的原因。决定继续开发异步版本，并进一步调查和优化内存分配器。同时，需要继续分析系统崩溃的原因，并寻找解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph DocuBetter Meeting 2020-06-10","slug":"Ceph_DocuBetter_Meeting_2020-06-10","date":"2020-06-09T16:00:00.000Z","updated":"2020-06-10T16:00:00.000Z","comments":true,"path":"2020/06/10/Ceph_DocuBetter_Meeting_2020-06-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/10/Ceph_DocuBetter_Meeting_2020-06-10/","excerpt":"","text":"会议纪要 会议主题： 讨论和解决Ceph文档更新及社区贡献管理问题 参会人员： 主持人：[姓名] 记录人：[姓名] 其他相关人员：David Galloway, Sebastian 会议时间： [具体日期和时间] 会议地点： 视频会议 主要议题： 文档更新与社区贡献管理 讨论如何有效整合和处理来自社区的非标准格式或过时的pull request（PR）。 提出解决方案：通过创建正式的PR来整合这些贡献，确保文档的快速审批和更新。 技术细节讨论 详细讨论了使用Git命令（如fetch, pull, push）来管理远程分支和PR的具体操作流程。 强调了使用upstream和origin的区别及正确操作方法。 个人经验分享与学习 分享了个人在处理Git分支和合并时的错误和学习经验。 讨论了如何通过使用reflog来恢复和管理错误的分支操作。 文档网站和API问题 讨论了当前文档网站（readthedocs）的搜索功能问题及API文档的整合需求。 计划与David Galloway进一步讨论解决方案。 Ceph ATM指南更新 预计在7月1日前完成Ceph ATM指南的草稿，涵盖所有相关内容。 决定事项： 确定了解决非标准PR的流程和技术细节。 计划与David Galloway进一步讨论文档网站和API的问题。 确认了Ceph ATM指南的更新计划和时间表。 后续行动计划： 继续优化和标准化处理社区PR的流程。 与David Galloway安排会议，讨论文档网站和API的改进方案。 完成Ceph ATM指南的草稿，并进行内部审查。 其他事项： 计划在非录制会议中进一步讨论Sapphire相关事宜。 确认了会议记录的保密性和后续使用的注意事项。 会议结束时间： [具体时间] 下次会议安排： [具体日期和时间] 备注： 本次会议内容涉及技术细节和操作流程，建议相关人员在会后进行详细的技术文档整理和操作指南编写，以便团队成员参考和执行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-06-08","slug":"Ceph_Orchestrator_Meeting_2020-06-08","date":"2020-06-07T16:00:00.000Z","updated":"2020-06-08T16:00:00.000Z","comments":true,"path":"2020/06/08/Ceph_Orchestrator_Meeting_2020-06-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/08/Ceph_Orchestrator_Meeting_2020-06-08/","excerpt":"","text":"会议纪要 主要议题： Ceph 主要升级流程 讨论了如何在 Rook 中进行 Ceph 的主要升级。 确定了从 Nautilus 到 Octopus 的升级流程与补丁发布相似，用户只需更新 Rook 部署的版本，Rook 将处理升级过程中的所有必要步骤。 新增功能：计划功能 提出了新增一个名为“plan”的功能，该功能旨在提供调度器的预览，帮助用户根据服务规范了解哪些主机将接收服务。 讨论了是否需要一个新的命令关键字“plan”来实现这一功能，或者是否可以在现有的“apply”命令中添加一个参数来实现相同的功能。 监控堆栈容器版本管理 讨论了监控堆栈中使用的容器版本管理问题，建议将版本信息从代码中移出，使用配置文件来管理。 强调了提供默认配置的重要性，同时允许用户在必要时自定义容器版本。 决定事项： Ceph 升级流程：确认 Rook 将负责处理 Ceph 主要升级的所有必要步骤，用户只需更新 Rook 部署的版本。 计划功能：决定引入一个新的命令关键字“plan”，以便用户可以预览已应用的服务规范的结果，而不仅仅是新应用的规范。 容器版本管理：同意将容器版本信息从代码中移出，使用配置文件来管理，同时提供默认配置。 后续行动计划： Ceph 升级流程：继续优化 Rook 的升级流程，确保升级过程的稳定性和可靠性。 计划功能：开发并测试“plan”功能的实现，确保其能够准确预览服务规范的结果。 容器版本管理：开始将容器版本信息从代码中移出，并创建相应的配置文件，确保用户可以自定义容器版本。 其他讨论： 讨论了如何使驱动组（Drive Groups）在 Kubernetes 环境中工作，提出了使用节点亲和性等方法来实现。 下一步： 将未决问题和讨论移至邮件列表或聊天群组，以便进一步讨论和决策。 会议结束，期待下次会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2020-06-04","slug":"Ceph_Performance_Meeting_2020-06-04","date":"2020-06-03T16:00:00.000Z","updated":"2020-06-04T16:00:00.000Z","comments":true,"path":"2020/06/04/Ceph_Performance_Meeting_2020-06-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/04/Ceph_Performance_Meeting_2020-06-04/","excerpt":"","text":"会议纪要 关键细节 本周有多个新的PR（Pull Request）和已关闭的PR。 讨论了关于BlueStore中Ching块设备PR的具体问题，特别是擦除编码期间的限流问题。 Adam提交了一个PR，旨在防止当RocksDB分片启用时，写前日志大小过大。 Mudge和Ping提交了一个PR，关于启用RocksDB的流水线写入。 讨论了使用XXHash进行CRUSH选择的问题。 更新了RocksDB到6.8.1版本，可能带来一些性能改进。 讨论了关于性能CI（持续集成）的进展和计划。 主要议题 BlueStore性能优化 讨论了如何优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 讨论了RocksDB的写前日志大小和缓冲区管理，以及可能的限流行为。 性能CI的进展 讨论了性能CI的最新进展，包括测试环境和未来的计划。 讨论了如何更好地利用性能CI来避免合并到主分支的PR对性能产生负面影响。 Ceph的持续改进 讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 讨论了如何处理一些复杂的PR，特别是涉及多线程和锁定的代码。 决定事项 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 后续行动计划 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 其他讨论 讨论了关于Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 讨论了如何处理一些复杂的PR，特别是涉及多线程和锁定的代码。 讨论了如何更好地利用性能CI来避免合并到主分支的PR对性能产生负面影响。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能问题。 将继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 将继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 后续行动 继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 继续推进性能CI的工作，确保能够及时发现和解决性能问题。 继续审查和合并相关的PR，特别是那些能够带来性能改进和Bug修复的PR。 继续讨论和优化Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 结论 本次会议讨论了Ceph的多个PR，包括性能优化、内存管理改进和Bug修复。 将继续优化BlueStore的内存管理，特别是通过细分内存池来提高性能。 将继续推进性能CI的工作，确保能够及时发现和解决性能","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Crimson/SeaStor OSD Weekly 2020-06-03","slug":"Ceph_Crimson_SeaStor_OSD_Weekly_2020-06-03","date":"2020-06-02T16:00:00.000Z","updated":"2020-06-03T16:00:00.000Z","comments":true,"path":"2020/06/03/Ceph_Crimson_SeaStor_OSD_Weekly_2020-06-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/03/Ceph_Crimson_SeaStor_OSD_Weekly_2020-06-03/","excerpt":"","text":"会议纪要 主要议题与讨论内容 PR更新与同步 会议开始时，提到了上周的PR更新情况，特别是关于同步版本的问题。讨论了如何获取同步版本以及后续的审查和合并流程。 决定在PR流程中处理评论，并计划在后续步骤中解决这些评论。 代码重构与实现细节 讨论了提取公共代码的问题，特别是关于extended map tree和IRB tree的实现细节差异。 决定暂时不停止提取公共代码，因为对某些实现细节的理解还不够深入。 提到了正在实现的extended tree和key system的简化。 Transaction Manager与Cache 解释了transaction manager如何通过cache进行操作，并强调了transaction manager在系统中的重要性。 测试与性能评估 讨论了如何处理重复的crimson实例，并计划实施单元测试。 提到了关于active item的单元测试问题，并计划在不同环境下实施测试。 讨论了segment registry的实现，特别是如何跟踪和重用segments。 Recovery测试 讨论了如何在现有QA框架内进行recovery测试，特别是涉及OSD的关闭和启动。 建议先进行单元测试和手动测试，然后集成crimson到QA框架中。 内存分配器问题 讨论了内存分配器的问题，特别是关于使用Liberty allocator的必要性。 强调了需要一个单一的二进制文件，而不是根据不同的存储后端提供不同的二进制文件。 决定事项 继续推进PR的同步和审查工作。 暂时不停止提取公共代码，直到对实现细节有更深入的理解。 实施单元测试和手动测试，以验证recovery机制。 解决内存分配器的问题，确保最终提供一个单一的二进制文件。 后续行动计划 完成PR的同步和审查工作，并解决相关的评论问题。 继续实施extended tree和key system的简化工作。 实施单元测试和手动测试，确保recovery机制的正确性。 评估内存分配器的性能影响，并寻找解决方案以提供单一的二进制文件。 备注 会议中提到了一些技术细节和代码实现问题，这些需要在后续的工作中进一步细化和解决。 强调了测试和性能评估的重要性，特别是在集成crimson到QA框架中的过程中。 结束语 会议在讨论了各项议题和后续行动计划后结束，所有参与者将在接下来的工作中按照会议决定推进相关工作。感谢所有参与者的贡献和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator Meeting 2020-06-01","slug":"Ceph_Orchestrator_Meeting_2020-06-01","date":"2020-05-31T16:00:00.000Z","updated":"2020-06-01T16:00:00.000Z","comments":true,"path":"2020/06/01/Ceph_Orchestrator_Meeting_2020-06-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/06/01/Ceph_Orchestrator_Meeting_2020-06-01/","excerpt":"","text":"会议纪要 会议主题：Drive Groups 的讨论 参会人员：Blaine, Sebastian Wagner, 以及其他相关人员 主要议题： Drive Groups 的实现问题： Blaine 提到需要使用 Drive Groups 来配置主机。 Brooke 和 Young 已经完成了一个 PR，该 PR 将根据 Drive Group 规范在卷中应用到主机。 Sebastian Wagner 反对让 Ceph 进行主机验证，建议将此功能推给 Rook。 技术实现细节： 讨论了是否应该在 Rook 中重新实现逻辑，或者依赖于 Ceph 的内部逻辑。 提出了使用 CLI 命令查询 Ceph Manager 的方案，以确定 Drive Group 规范是否适用于特定节点。 讨论了使用 Python 库的选项，但认为这不是一个长期稳定的解决方案。 行动计划： 决定探索使用现有的 Ceph 集群工具来获取所需信息。 建议使用 Drive Group 文件规范中的预览参数来测试功能。 计划在未来实现一个新的 CLI 命令来获取这些信息，以避免使用外部脚本。 其他讨论： Zach Dover 介绍了他的工作，他正在编写一个基于 Seafile 的安装指南，并寻求关于网络配置的帮助。 讨论了与 Red Hat 的合作，以及如何共享文档和 QA 流程。 后续行动： 继续与 Sebastian Wagner 讨论技术细节。 Zach Dover 将与相关人员安排进一步的会议，以解决网络配置的具体问题。 继续推进 Drive Groups 的实现和文档编写工作。 会议结束： 会议在讨论完所有议题后结束，祝大家周一愉快。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-27 :: Ceph Science User Group Meeting","slug":"2020-05-27_-_-_Ceph_Science_User_Group_Meeting","date":"2020-05-27T16:00:00.000Z","updated":"2020-05-28T16:00:00.000Z","comments":true,"path":"2020/05/28/2020-05-27_-_-_Ceph_Science_User_Group_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/28/2020-05-27_-_-_Ceph_Science_User_Group_Meeting/","excerpt":"","text":"会议纪要 会议概述 本次会议是一个非正式的讨论会，主要围绕科学研究、大型集群以及与Ceph相关的各种话题展开。会议鼓励参与者自由发言，分享经验和技术问题。 主要议题 近期故障和解决方案 Liam分享了马里兰大学的一次故障经历，涉及数据库日志和数据分区在NVMe驱动器上的问题。他们使用的是Ceph的Nautilus版本，计划下个月升级到Octopus。 另一个参与者分享了MDS（Metadata Server）崩溃的经历，导致集群服务中断约一小时。他们通过减少MDS的缓存大小来解决问题。 硬件扩展和集群管理 讨论了在扩展集群时遇到的性能问题，特别是在添加新硬件后数据重新平衡的问题。 提到了使用Ceph的CRUSH map和upmap工具来管理数据分布，但存在一些挑战和限制。 Ceph版本升级和性能 讨论了从Luminous升级到Octopus的经验，以及升级过程中遇到的性能优化和问题。 提到了Ceph的Telemetry模块，以及它在某些情况下可能导致集群进入警告模式的问题。 容器化和Ceph的未来 讨论了Ceph与容器技术（如Docker）的集成，以及这对未来部署和管理的影响。 一些参与者表达了对容器化可能带来的性能影响和复杂性的担忧。 决定事项 计划在7月22日举行下一次会议，并将发送提醒通知。 建议参与者在主索引中添加他们的联系信息和集群配置，以便更好地匹配和交流。 后续行动计划 继续关注和讨论Ceph的最新版本和功能，特别是Octopus的升级和使用经验。 探索和测试Ceph与容器技术的集成，评估其对性能和管理的影响。 收集和分享集群配置和使用经验，以便更好地理解和解决共同面临的问题。 其他备注 会议鼓励新参与者加入，并提供了联系方式以便未来邀请。 会议结束时，主持人感谢所有参与者的贡献，并期待在下次会议中再次交流。 本次会议为Ceph社区成员提供了一个宝贵的交流平台，促进了知识共享和技术进步。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-28 :: Ceph Tech Talk - What's New In Octopus","slug":"2020-05-28_-_-_Ceph_Tech_Talk_-_What_s_New_In_Octopus","date":"2020-05-27T16:00:00.000Z","updated":"2020-05-28T16:00:00.000Z","comments":true,"path":"2020/05/28/2020-05-28_-_-_Ceph_Tech_Talk_-_What_s_New_In_Octopus/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/28/2020-05-28_-_-_Ceph_Tech_Talk_-_What_s_New_In_Octopus/","excerpt":"","text":"会议纪要 会议概要 日期: 2023年5月28日 主题: Seth Tech Talk - Ceph Octopus 版本更新及新功能介绍 主讲人: Josh Durgan (Red Hat) 和 Lance Kramer (Sousa) 参会人员: Ceph 社区成员及技术爱好者 讨论内容 Ceph Octopus 版本更新 发布时间: Octopus 版本于2020年3月发布，下一个版本 Pacific 预计于2021年3月发布。 支持与升级: 支持从 Luminous、Mimic 和 Nautilus 升级到 Octopus，但 Luminous 需要先升级到 Mimic 或 Nautilus。 主要改进与新功能 可操作性提升: Orchestrator API: 实现统一部署和管理，支持容器化部署，简化集群管理。 Ceph Dashboard: 界面布局调整，增强用户管理功能，改进 OSD 部署流程。 性能与稳定性: BlueStore 优化: 改进预取和压缩机制，优化内存使用和TRIM行为。 健康监控: 新增网络监控健康警报，改进内部健康警报处理。 多站点支持: RBD 镜像: 基于快照的灾难恢复，减少 I/O 开销。 Garbage Collection: 使用简单块用于垃圾回收，减少 RocksDB 瓶颈。 生态系统集成: Ceph CSI 和 Rook: 增强与 Kubernetes 的集成，支持更多存储模式和操作。 用户提问与回答 驱动器故障处理: Ceph Orchestrator 目前不直接处理驱动器故障，但有计划自动化这一过程。 SMR 磁盘支持: 目前不支持，但 Pacific 版本将引入新的后端存储以支持 SMR 磁盘。 后续行动计划 持续优化: 继续改进 Ceph Orchestrator 的功能，特别是在自动化驱动器故障处理方面。 新功能开发: 开发支持 SMR 磁盘的新后端存储，预计在 Pacific 版本中实现。 社区参与: 鼓励用户参与 Ceph 的 telemetry 和 crash reporting，以帮助改进产品。 结论 本次会议详细介绍了 Ceph Octopus 版本的新功能和改进，强调了其在可操作性、性能和多站点支持方面的进步。同时，讨论了未来版本的发展方向和社区参与的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-27 :: Crimson SeaStor OSD Weekly Meeting","slug":"2020-05-27_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-05-26T16:00:00.000Z","updated":"2020-05-26T16:00:00.000Z","comments":true,"path":"2020/05/27/2020-05-27_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/27/2020-05-27_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 关键细节 会议主题: 讨论和审查分布式存储系统Ceph的相关代码实现和优化。 参会人员: 包括但不限于Sam、John、Tim等。 会议日期: 最近一次会议。 讨论的主要议题 代码共享与优化: 讨论了如何将代码与Home站点共享，特别是关于RB树和Exchanger Map树的结构和布局。 强调了LVH（逻辑卷管理）树和LBA（逻辑块地址）树在节点更新和地址管理上的差异。 讨论了代码中处理分裂和合并的部分，特别是固定大小和固定键的B树。 会议时间调整: 提议将会议时间从周四改为周二，以避免连续会议的疲劳。 代码集成与测试: 讨论了将个人代码集成到主代码库的进度，特别是关于事务管理器和LBA管理器的实现。 强调了当前代码的局限性，如无法进行垃圾回收和段恢复。 节点布局与插入逻辑: 讨论了节点布局的设计，特别是如何处理插入操作中的层次和字符串重复问题。 审查了优雅关闭机制的实现，特别是消息传递部分和高层次的关闭过程。 决定的事项 会议时间调整: 同意将会议时间从周四改为周二。 代码审查与集成: 继续推进代码的审查和集成工作，特别是事务管理器和LBA管理器的实现。 后续的行动计划 代码优化: 继续优化和重构代码，特别是处理分裂和合并的部分。 功能完善: 完善事务管理器和LBA管理器的功能，包括垃圾回收和段恢复。 测试加强: 加强单元测试，确保代码的稳定性和可靠性。 节点布局优化: 继续优化节点布局，减少插入操作的复杂性。 其他 代码共享: 继续探索和实施代码共享的最佳实践，确保代码的可维护性和可扩展性。 技术细节: 深入理解LVH树和LBA树的技术细节，以便更好地进行代码优化和功能实现。 结束语 会议在讨论了多个技术细节和项目进展后结束，参会人员对未来的工作方向和目标有了更清晰的认识。感谢所有人的参与和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-25 :: Ceph Orchestration Meeting","slug":"2020-05-25_-_-_Ceph_Orchestration_Meeting","date":"2020-05-25T16:00:00.000Z","updated":"2020-05-25T16:00:00.000Z","comments":true,"path":"2020/05/26/2020-05-25_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/26/2020-05-25_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统的监控与升级策略讨论 会议地点：渥太华（Ottawa）与纽约（New York） 会议时间：具体日期未提及 参会人员：Erika、Cedrick、Josef（GM-Manager）等 主要议题： 1. 监控系统基础建设：讨论了直接监控（direct monitoring）的重要性，特别是在容器（containers）环境中，确保问题能够及时被发现和解决。 2. 私有注册表（Private Registry）：Cedrick提到了私有注册表的必要性，以及如何确保其安全性和可用性。 3. 升级策略：讨论了如何优化升级过程，包括连续交易更新服务（continous traded update service）和安全升级（safety and means that you cannot job in the upgrade）。强调了升级过程中的风险和必要性。 4. 文档更新：提到了上游文档（upstream documentation）的升级需求，以及如何确保文档的及时更新和准确性。 5. 配置优化：讨论了如何在支持配置（support configuration）中减少步骤，优化前序步骤（predecessor little steps），以提高效率和减少历史维度（historical dimension）的影响。 决定事项： - 需要建立一个基础的监控系统，特别是在容器环境中。 - 私有注册表的安全性和可用性需要进一步加强。 - 升级过程需要优化，确保安全和高效。 - 上游文档需要定期更新，确保信息的准确性和及时性。 - 支持配置需要优化，减少不必要的步骤，提高效率。 后续行动计划： - 制定详细的监控系统建设方案，并开始实施。 - 对私有注册表进行安全性和可用性评估，并制定改进措施。 - 制定升级过程的优化方案，并开始实施。 - 定期更新上游文档，确保信息的准确性和及时性。 - 优化支持配置，减少不必要的步骤，提高效率。 会议结束语：Erika总结了会议内容，并强调了各项任务的重要性和紧迫性。会议在确认后续行动计划后结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-21 :: Ceph Performance Meeting","slug":"2020-05-21_-_-_Ceph_Performance_Meeting","date":"2020-05-20T16:00:00.000Z","updated":"2020-05-21T16:00:00.000Z","comments":true,"path":"2020/05/21/2020-05-21_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/21/2020-05-21_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 日期与时间: 会议在预定的时间窗口内进行。 参与者: Adam, Mark, Igor, 以及其他未明确提及的参与者。 讨论的主要议题 AVX2编码优化: 本周有两个新的PR（Pull Request）与AVX2编码相关，用于缓冲列表的编码和解码。 声称在某些情况下速度提升两倍，其他情况下提升20%。 RocksDB数据损坏问题: 报告了数据损坏问题，可能与RocksDB更新到6.5.1版本有关。 正在考虑更新到6.5.1版本，以解决一些已知问题。 内存增长问题: 用户报告了内存增长问题，特别是在启用压缩的情况下。 Adam正在进行相关工作，发现对象在预创建但未填充数据时内存使用很小，但一旦填充数据后，内存使用会迅速增长。 OSD性能测试: 进行了关于在单个设备上运行多个OSD的性能测试。 结果显示，在某些情况下，单个OSD的性能优于多个OSD。 数据损坏与RocksDB: Igor报告了关于RocksDB数据损坏的问题，可能与最近的修改有关，特别是禁用BlueStore缓冲IO和预扩展写头日志的修改。 正在进一步调查和测试，以确认问题的根本原因。 决定的事项 继续对AVX2编码优化进行测试和评估。 考虑更新RocksDB到6.5.1版本，以解决数据损坏问题。 对内存增长问题进行深入分析，并寻找解决方案。 继续进行OSD性能测试，并根据结果调整配置和策略。 后续行动计划 完成AVX2编码优化的测试，并根据结果决定是否合并PR。 确认RocksDB数据损坏问题的根本原因，并制定相应的修复措施。 继续分析内存增长问题，并提出具体的解决方案。 根据OSD性能测试的结果，优化集群配置和运行策略。 其他事项 讨论了CBT（Ceph Benchmarking Tool）的使用和改进，以更好地支持性能测试。 确认了RocksDB数据损坏问题与特定修改的关系，并计划进行进一步的测试和验证。 结论 会议讨论了多个关键的技术问题，并制定了相应的行动计划。 感谢所有参与者的贡献，并期待后续的进展和解决方案。 会议结束语: 感谢大家的参与，祝大家有一个愉快的一周。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-20 :: Crimson SeaStor OSD Weekly Meeting","slug":"2020-05-20_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-05-19T16:00:00.000Z","updated":"2020-05-19T16:00:00.000Z","comments":true,"path":"2020/05/20/2020-05-20_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/20/2020-05-20_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph分布式存储系统的开发进展、性能测试、代码审查以及后续行动计划。与会人员包括Ceph研发人员和相关领域的专家。 主要议题 代码实现与分支管理 讨论了基于CMGA分支的简易实现，该实现已能支持所需的功能改进。 提到了对树结构和合并支持的持续工作，以及代码审查的进展。 性能测试与优化 讨论了使用CBT（Ceph Benchmark Tool）进行性能测试的情况，特别是关于CPU使用率和性能指标的准确性。 探讨了如何通过调整测试环境和工具来更准确地评估性能，包括使用不同的编译器（如Clang和GCC）。 代码审查与改进 讨论了B3节点的实现，特别是如何使代码更可重用。 提到了对layout.h文件的改进，以及如何更好地处理内存布局和操作。 后续行动计划 确定了继续进行代码审查和性能测试的计划。 讨论了如何改进CBT工具，以便更好地支持性能测试和数据收集。 决定事项 性能测试改进 将继续优化CBT工具，以提高性能测试的准确性和可靠性。 将探索使用不同的编译器和工具链，以确保测试结果的可比性。 代码审查与改进 将继续进行代码审查，特别是对B3节点的实现和layout.h文件的改进。 将探索如何使代码更可重用，并改进内存布局和操作。 后续行动 将继续进行性能测试和代码审查，以确保Ceph系统的稳定性和性能。 将探索如何改进CBT工具，以便更好地支持性能测试和数据收集。 后续行动计划 性能测试 继续优化CBT工具，提高性能测试的准确性和可靠性。 探索使用不同的编译器和工具链，确保测试结果的可比性。 代码审查 继续进行代码审查，特别是对B3节点的实现和layout.h文件的改进。 探索如何使代码更可重用，改进内存布局和操作。 工具改进 探索如何改进CBT工具，以便更好地支持性能测试和数据收集。 确保CBT工具的最新版本和相关依赖已合并到主分支。 结论 本次会议明确了Ceph系统的开发进展和后续行动计划，特别是在性能测试和代码审查方面。与会人员将继续努力，确保Ceph系统的稳定性和性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-18 :: Ceph Orchestration Meeting","slug":"2020-05-18_-_-_Ceph_Orchestration_Meeting","date":"2020-05-17T16:00:00.000Z","updated":"2020-05-18T16:00:00.000Z","comments":true,"path":"2020/05/18/2020-05-18_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/18/2020-05-18_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间 日期：具体日期未提供 时间：具体时间未提供 参会人员 Travis John Lucy Tommy 其他未提及姓名的参与者 主要议题 Ceph Y版本发布 Y版本即将发布，预计今天或本周内完成。 CLI重构讨论 讨论了如何统一apply和daemon ad命令，特别是在使用Porticus和subversion 3.5或6的情况下。 提出了一个文档草案，建议将讨论转移到会议中，并创建了一个小型文档来记录相关内容。 讨论了如何围绕Beck（一个中心构建块）重新设计整个CLI，包括对象和操作（verb）的概念。 提出了一些新的子命令，如spec modify，以简化修改流程。 讨论了过渡期的挑战，包括旧命令的兼容性和命令的冗长性。 代码重构和对象导向方法 讨论了如何通过采用更对象导向的方法来简化代码，特别是在FF Orchestrator中。 提出了一些具体的重构步骤，如将特定实现从模块中移出，保持模块独立性。 文档更新 讨论了关于设备文档的更新，建议将相关信息放在设备财务文档中。 Drive Group解析和匹配 讨论了在Ceph中Drive Group解析和匹配的实现，特别是在Rook和Ceph Manager模块中的处理。 提出了几种匹配机制，如使用主机名、标签等。 ** idempotence of the lv investment** 讨论了lv投资幂等性的实现，提出了一个PR，并请求社区成员进行测试。 本地开发和测试环境 讨论了如何在容器中本地测试和开发，提出了使用本地注册表和容器镜像的方法。 提出了一些工具和脚本，如cube chicka，以帮助开发和测试。 决定事项 继续讨论CLI重构，并在Google Docs上进行在线评论和讨论。 继续进行代码重构，特别是在FF Orchestrator中采用更对象导向的方法。 更新设备文档，并将相关信息放在设备财务文档中。 继续讨论Drive Group解析和匹配的实现，特别是在Rook和Ceph Manager模块中的处理。 继续测试和完善lv投资幂等性的实现。 继续讨论和完善本地开发和测试环境的方法和工具。 后续行动计划 在Google Docs上进行CLI重构的在线评论和讨论。 继续进行代码重构，特别是在FF Orchestrator中采用更对象导向的方法。 更新设备文档，并将相关信息放在设备财务文档中。 继续讨论Drive Group解析和匹配的实现，特别是在Rook和Ceph Manager模块中的处理。 继续测试和完善lv投资幂等性的实现。 继续讨论和完善本地开发和测试环境的方法和工具。 其他备注 会议中提到了一些具体的工具和脚本，如cube chicka，以帮助开发和测试。 会议中提到了一些具体的实现细节，如使用主机名、标签等匹配机制。 会议中提到了一些具体的代码重构步骤，如将特定实现从模块中移出，保持模块独立性。 会议结束 会议在讨论完所有议题后结束，计划下周再次开会。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-14 :: Ceph Performance Meeting","slug":"2020-05-14_-_-_Ceph_Performance_Meeting","date":"2020-05-13T16:00:00.000Z","updated":"2020-05-14T16:00:00.000Z","comments":true,"path":"2020/05/14/2020-05-14_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/14/2020-05-14_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 主要议题与讨论内容 RocksDB 升级 讨论了升级到最新版本的 RocksDB，该版本包含多项修复，包括数据损坏修复和崩溃启动修复。 预计会有性能提升，特别是迭代器速度和缓存改进。 决定由 Keefe 使用新的 Jenkins PvP 测试框架进行测试，即使性能有所提升或下降，也倾向于升级以获得修复。 Classic OSD 测试脚本更新 Keefe 合并了用于经典 OSD 测试的脚本，现在可以使用 BlueStore 进行测试，这是一个积极的进展。 并行 Crush 计算 关于平衡器的并行 Crush 计算 PR 被关闭，原因不明，可能是因为长时间无人审查。 更新 PR Adam 的 PR 更新，涉及 SEPA fest 测试，但由于 fest 测试未运行，具体效果不明。 另一个关于 BlueStore 更新的 PR，声称已修复之前的问题并通过测试，需要重新运行测试并审查其安全性。 其他更新 讨论了多个 PR，包括 FIFO 数据日志、MDS 预期文件 PR 等，这些 PR 正在接受审查但尚未有具体进展。 提到了减少内存占用的 PR，需要尽快进行测试并集成。 决定事项 确认升级 RocksDB 的计划，并由 Keefe 进行性能测试。 继续审查和测试 BlueStore 相关的 PR，确保其安全性和性能改进。 继续推进其他 PR 的审查和集成工作。 后续行动计划 Keefe 将运行 RocksDB 升级的性能测试。 对 BlueStore 相关的 PR 进行详细审查和测试。 继续推进其他 PR 的审查工作，并尽快集成重要的改进。 其他 会议提前结束，团队成员将在下周再次集合，讨论新的进展和问题。 会议结束","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-12 :: Crimson SeaStor OSD Weekly Meeting","slug":"2020-05-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-05-12T16:00:00.000Z","updated":"2020-05-13T16:00:00.000Z","comments":true,"path":"2020/05/13/2020-05-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/13/2020-05-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统的开发与优化 参会人员：Ceph研发团队成员 会议日期：[具体日期] 会议地点：视频会议 主要议题及讨论内容： 单元测试与代码重构 发言人：[姓名] 内容摘要： 正在增加更多的单元测试，并计划基于现有能力重写变异和复制逻辑。计划采用基于树的实现方式来处理分配和释放操作。同时，讨论了PR 334492的相关内容，将在会议后进行详细审查。 代码更新与功能实现 发言人：[姓名] 内容摘要： 更新了exact map tree的实现，正在尝试理解管理器接口并进行树形编码。关于树形实现的讨论，提到了与现有代码的相似性和可能的借用。 系统状态与功能清理 发言人：[姓名] 内容摘要： 成功实现了对象到两个副本的切换，并清理了分支，实现了一些缺失的功能。正在将分支合并到主分支，但由于基于较旧的恢复分支版本，需要追赶许多更新。 代码审查与项目进展 发言人：[姓名] 内容摘要： 审查了一个PR，认为虽然改动不大，但方向正确。讨论了内存泄漏问题，预计本周解决。 服务理解与状态机代码迁移 发言人：[姓名] 内容摘要： 主要通过阅读代码来理解服务，以便实际迁移状态机代码。计划通过提问来进一步理解服务和基础设施。 单元测试与逻辑实现 发言人：[姓名] 内容摘要： 成功实现了笔记分割的单元测试，正在处理增量图逻辑，涉及移除纸质映射。讨论了基于树形结构的实现细节。 树形结构的实现与优化 发言人：[姓名] 内容摘要： 实现了块布局和索引查找，计划基于当前工作实现插入和分割。讨论了如何最小化字符串比较的努力。 优雅关机策略讨论 发言人：[姓名] 内容摘要： 讨论了如何实现优雅关机，提出了通过设置停止标志或从信使中注销调度器来防止进一步事件处理。讨论了如何跟踪事件消费并让每个组件自行处理。 决定事项： 继续推进单元测试和代码重构工作。 解决内存泄漏问题，并确保代码合并到主分支的顺利进行。 深入理解服务和基础设施，以便更好地迁移状态机代码。 实现树形结构的插入和分割功能，优化字符串比较。 确定优雅关机的具体实现策略，包括如何处理事件消费和组件关机。 后续行动计划： 完成PR 334492的详细审查。 解决内存泄漏问题，并确保所有功能按预期工作。 继续阅读代码，理解服务和基础设施。 实现树形结构的插入和分割功能，并进行优化。 确定优雅关机的具体实现细节，并进行实施。 会议结束语： 感谢大家的参与和贡献，期待下次会议能看到更多的进展和成果。 备注： 会议中提到的具体姓名和日期等信息已省略，以保护隐私和安全。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-13:: Ceph DocUBetter Meeting","slug":"2020-05-13_-_-_Ceph_DocUBetter_Meeting","date":"2020-05-12T16:00:00.000Z","updated":"2020-05-13T16:00:00.000Z","comments":true,"path":"2020/05/13/2020-05-13_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/13/2020-05-13_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 会议概要 时间: [具体日期] 地点: 线上会议 参会人员: [列出主要参会人员] 主持人: [主持人姓名] 主要议题 Google Season of Docs 申请结果 未能成功申请，原因不明。 讨论了可能的原因，包括项目可能过于成熟和知名。 决定继续推进新手引导文档的编写工作。 API查询问题 来自Perth超级计算中心的Lucas Cervini联系，反映无法使用标准工具查询API。 已提交相关bug，并寻求进一步的文档支持或解决方案。 CephIO垃圾评论处理 每日处理约25条垃圾评论，保持评论质量。 讨论了评论审核的标准和流程。 Seth Vancouver会议状态 会议很可能被取消，建议联系Mike Perez确认。 GitHub通知设置 讨论了如何设置GitHub通知，以便及时响应pull request和bug。 Ceph培训文档编写 计划编写一个简单的内部使用文档，介绍如何使用实验室进行测试。 讨论了现有文档的更新和维护。 封装定义倡议 提出一个新倡议，旨在为每个概念提供简洁明了的定义，帮助新手理解。 讨论了如何在网站和文档中整合这些定义。 文档合规性和网站更新 讨论了文档合规性列表中的未完成项。 提到了Lars正在进行的全新网站建设项目。 文档重定向和报告机制 确认需要将docs.com重定向到readthedocs版本，并保留报告文档错误的机制。 对象存储工具文档PR 讨论了David即将审查的对象存储工具文档PR，并准备合并。 决定事项 继续推进新手引导文档的编写。 确认Seth Vancouver会议的状态，并更新相关信息。 设置GitHub通知以便及时响应开发活动。 编写和更新Ceph培训文档。 推进封装定义倡议，简化概念解释。 重定向docs.com到readthedocs，并保留报告文档错误的机制。 后续行动计划 联系Mike Perez确认Seth Vancouver会议的状态。 更新和维护Ceph培训文档。 实施封装定义倡议，开始编写简洁的概念定义。 完成对象存储工具文档PR的审查和合并。 确认并实施文档重定向和报告机制的更新。 备注 会议中提到的具体日期和细节需要进一步确认和跟进。 所有参会人员应关注GitHub通知，以便及时响应开发活动。 下次会议 预定于[具体日期]进行，具体时间和议程待定。 结束语: 感谢所有参会人员的积极参与和贡献，期待下次会议继续推进我们的项目和目标。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-07 :: Ceph Performance Meeting","slug":"2020-05-07_-_-_Ceph_Performance_Meeting","date":"2020-05-11T16:00:00.000Z","updated":"2020-05-12T16:00:00.000Z","comments":true,"path":"2020/05/12/2020-05-07_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/12/2020-05-07_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 新PR讨论： Adam提交的PR，关于在RADOS对象上实现队列段，以替代数据日志和元数据日志。 Sam的C store工作PR，Keith正在审查。 已关闭的PR： 监控器优先级缓存管理器的修复，确保内存释放和重新平衡。 Crimson和经典OSD性能测试框架中标准偏差的增加，以减少误报。 4k块大小调整的PR，与混合分配器和延迟大写PR合并。 OSD线程通知修复，改善随机读取工作负载的性能。 Adam的初始PR已合并，等待工具转换OSD格式。 KC的PR，使用迭代器进行比较操作符的缓冲列表。 其他讨论： 关于MDS的新预期文件延迟的PR讨论。 Igor的加速移除和内存减少PR的更新。 主要议题 性能测试： Neha分享了在Sepia实验室进行的性能实验结果，讨论了单节点和多节点的性能变异。 讨论了使用FIO进行更真实的负载测试，以及如何在Jenkins中集成这些测试。 CBT和Vstart的使用： 讨论了使用CBT构建集群的优点，以及如何在不使用预构建包的情况下进行测试。 探讨了在容器中运行gdb的可能性。 决定事项 继续推进Adam和Sam的PR工作。 确认使用CBT构建集群的可行性，并探索在Jenkins中集成更真实的负载测试。 后续行动计划 继续审查和测试新提交的PR。 Neha将继续进行更多的性能测试，特别是在不同机器上的测试。 探索和实现CBT构建集群的方法，以及在Jenkins中集成FIO测试。 继续讨论和优化MDS相关PR的实现。 备注 会议中提到的技术术语和工具，如RADOS, CBT, FIO, Jenkins等，保持原文以确保专业性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-11 :: Ceph Orchestration Meeting","slug":"2020-05-11_-_-_Ceph_Orchestration_Meeting","date":"2020-05-11T16:00:00.000Z","updated":"2020-05-12T16:00:00.000Z","comments":true,"path":"2020/05/12/2020-05-11_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/12/2020-05-11_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概要 主持人: Sebastian 参会人员: Travis, Yuri, Mira, 以及其他相关人员 会议日期: 具体日期未提供 会议主题: 讨论Ceph分布式存储系统的未来发展，特别是关于Ceph ADM（自动化部署工具）的更新和集成。 讨论内容 Ceph ADM的更新和未来计划 关键议题: 讨论Ceph ADM的重要性和未来发展方向。 决定事项: 确定Ceph ADM将成为Ceph的统一部署工具，支持容器化部署，提供统一的命令行接口，并集成到Ceph管理面板中。 后续行动: 继续开发和测试Ceph ADM，确保其满足企业级需求。 Ceph ADM的集成和测试 关键议题: 讨论Ceph ADM的集成细节和测试策略。 决定事项: 确认Ceph ADM的测试套件已经包含了一些基本测试，但需要进一步增强，特别是在服务部署和升级方面。 后续行动: 继续完善测试套件，确保所有服务都能通过Ceph ADM进行有效部署和管理。 Ceph ADM的用户体验和文档 关键议题: 讨论如何改进Ceph ADM的用户体验和文档。 决定事项: 确认需要改进文档和用户体验，特别是在错误处理和用户交互方面。 后续行动: 更新文档，提供更详细的错误信息和用户指南。 Ceph ADM的通信协议 关键议题: 讨论Ceph ADM使用的通信协议。 决定事项: 确认Ceph ADM使用SSH进行远程连接和命令执行。 后续行动: 确保所有用户都能通过SSH访问集群节点。 后续行动计划 开发和测试: 继续开发Ceph ADM，确保其满足企业级需求，并增强测试套件。 文档和用户体验: 更新文档，提供更详细的错误信息和用户指南。 通信协议: 确保所有用户都能通过SSH访问集群节点。 社区参与: 鼓励社区成员参与Ceph ADM的开发和测试，提供反馈和建议。 其他事项 IRC频道: 提供了一个IRC频道（#ceph-adm）供社区成员交流和讨论。 下次会议: 下次会议将在下周举行，具体时间和议题待定。 会议结束 结束时间: 会议在讨论完所有议题后结束。 感谢: Sebastian感谢所有参会人员的参与和贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-25 :: Ceph Code Walkthrough: RGW Request Workflow","slug":"2019-04-25_-_-_Ceph_Code_Walkthrough_-_RGW_Request_Workflow","date":"2020-05-06T16:00:00.000Z","updated":"2020-05-07T16:00:00.000Z","comments":true,"path":"2020/05/07/2019-04-25_-_-_Ceph_Code_Walkthrough_-_RGW_Request_Workflow/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/07/2019-04-25_-_-_Ceph_Code_Walkthrough_-_RGW_Request_Workflow/","excerpt":"","text":"会议纪要 会议主题：RGW子系统及请求工作流程介绍 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容： 介绍与目的 本次会议旨在为新RGW开发者介绍RGW子系统及其请求工作流程。 会议内容基于上一次RGW介绍，深入探讨RGW的特性和子组件。 会议面向新RGW开发者，为其打下基础，并为未来的深入讨论做准备。 RGW概述 RGW作为Ceph的对象网关，处理客户端通过HTTP与S3和Swift协议的交互。 RGW通过librados与OSD通信，管理用户和凭证，处理对象存储操作。 RGW包含多个子系统，如前端服务器、认证引擎、操作处理等。 RGW子系统详细介绍 前端服务器：包括CivetWeb和Beast，分别基于C和C++实现，处理HTTP请求。 认证引擎：支持本地用户认证和外部认证（如Keystone、STS、LDAP）。 操作处理：包括S3和Swift协议的具体操作，如创建桶、上传下载对象等。 对象布局：介绍如何在Rados中映射S3和Swift的桶和对象概念。 多站点复制：通过多集群实现数据复制，避免Paxos在广域网中的不稳定性。 垃圾收集与生命周期管理：后台删除对象，管理桶的生命周期规则。 RGW Admin与NFS插件：提供管理工具和NFS Ganesha插件。 请求工作流程 客户端发送请求至RGW前端。 前端调用process_request函数，触发认证引擎和操作处理。 认证通过后，执行具体操作，如读写对象。 操作完成后，返回响应给客户端。 后续行动计划 未来会议将深入探讨RGW的各个子组件，包括代码走查和实际操作演示。 鼓励参会者提供反馈，希望了解他们对未来会议内容的具体需求。 会议记录： 会议全程录制，链接将在稍后提供。 鼓励参会者在会议结束后提出问题。 会议结束语： 感谢所有参会者的参与和支持。 期待在未来的会议中再次与大家见面。 会议组织者： [组织者姓名] 会议记录人： [记录人姓名] 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-04 :: Ceph Orchestration Meeting","slug":"2020-05-04_-_-_Ceph_Orchestration_Meeting","date":"2020-05-06T16:00:00.000Z","updated":"2020-05-07T16:00:00.000Z","comments":true,"path":"2020/05/07/2020-05-04_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/07/2020-05-04_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概要 会议主题: Orchestrator 周会 日期: [具体日期] 参会人员: [参会人员名单] 讨论议题 Orchestrator CLI 简化: 讨论了关于通过参数（如 --pool 或 --namespace）和通过 YAML 文件（如 apply -e）两种方式创建新服务的问题。 决定简化 CLI，建议只使用 YAML 文件（spec）或参数，避免两者混用，以减少复杂性和潜在的冲突。 计划移除不再使用的特定参数版本，如 apply -I。 版本发布计划: 讨论了即将发布的 Ceph 版本 15.2 的发布时间，预计本周内发布。 决定在版本发布后合并下一个大的代码提交。 测试和集成: 讨论了将 Orchestrator 测试集成到 Rook CI/CD 的工作进展，Phillip 正在负责此项工作。 提到了使用 Ceph-Demon 模块简化虚拟机设置的方法，计划分享给团队。 讨论了将 Safe ADM 方法用于更广泛的测试，特别是希望将 Dashboard 集成到 Safe ADM 中，以进行更真实的测试。 Safe ADM 和 Tautology 集成: 讨论了 Safe ADM 与 Tautology 的集成，以及如何通过这种集成提高测试的覆盖率和可靠性。 提到了一个关于 RGW 的 bug，如果 Safe ADM 中有相应的测试，可能会更早发现。 Safe Deploy 的使用: 讨论了 Safe Deploy 的使用情况，目前并未被广泛支持或使用，建议不再关注。 决定事项 简化 Orchestrator CLI，移除不再使用的参数。 在 Ceph 15.2 发布后，合并下一个大的代码提交。 继续推进 Orchestrator 测试与 Rook CI/CD 的集成工作。 探索和实施 Safe ADM 在更广泛测试中的应用，特别是 Dashboard 的集成。 后续行动计划 完成 Ceph 15.2 的发布工作。 合并并发布下一个大的代码提交。 继续推进 Orchestrator 测试与 Rook CI/CD 的集成。 探索 Safe ADM 在 Dashboard 和其他组件中的应用。 寻找资源解决 RGW 相关的 bug，并增加相应的测试。 其他事项 讨论了 Safe ADM 和 Tautology 的集成进展，以及 Safe Deploy 的当前状态。 确认了 Safe ADM 作为测试工具的潜力和未来发展方向。 会议结束 会议在确认所有议题讨论完毕后结束，下一次会议时间待定。 以上是本次 Orchestrator 周会的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-05-05 :: Ceph Crimson Meeting","slug":"2020-05-05_-_-_Ceph_Crimson_Meeting","date":"2020-05-06T16:00:00.000Z","updated":"2020-05-07T16:00:00.000Z","comments":true,"path":"2020/05/07/2020-05-05_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/05/07/2020-05-05_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 参会人员 主持人：Oh shiny 参会人员：团队成员 会议时间 日期：具体日期未提供 时间：会议开始时间未提供 会议内容 个人工作更新 Oh shiny： 刚结束一天的休假，目前专注于Ceph的培训和当前状态的更新。 正在处理Ceph的拆分和合并工作，同时也在进行抵押支持的工作。 与James合作，审查他的新PR，并正在跟进外部树设计。 Buddy： 继续进行scrubbing工作，使用SML并收到了反馈，目前正在柏林进行状态检查。 阅读了PR并提交了修复，但尚未合并。 考虑将整个图表推送到GitHub。 James： 更新了文档，调整了接口文件以匹配新格式，并推送了第一个PR。 正在继续改进LBA树，并计划推送下一个PR。 Glenn： 继续进行索引润滑工作，实现了特殊版本的lookup，并决定推广逻辑。 正在尝试将通用逻辑应用于不同类型的节点。 技术讨论 Oh shiny： 分享了扩展树设计的文档，讨论了逻辑地址到物理地址的映射问题。 讨论了使用RPE树来管理分配树的可能性。 Glenn： 讨论了LBA树的设计，包括逻辑地址到物理地址的映射和引用计数的管理。 讨论了在克隆操作中如何处理引用计数和物理扩展的分配。 决定事项 确认了LBA树将处理逻辑地址到物理地址的映射，并维护引用计数。 讨论了在克隆操作中如何处理引用计数和物理扩展的分配。 后续行动计划 继续推进各自的工作，特别是文档更新和技术实现。 继续审查和讨论PR，确保代码质量和功能实现。 下周继续开会，讨论进一步的进展和问题。 会议结束 会议在讨论完所有议题后结束，大家将在下周继续跟进工作进展。 备注 会议中提到的技术细节和术语如SML、PR、LBA树等，保留了英文原文以确保准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-14 :: Ceph Crimson Meeting","slug":"2020-04-14_-_-_Ceph_Crimson_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-28T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-14_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-14_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储系统的开发与调试 参会人员：Ceph研发团队成员 会议时间：[具体日期] 主要议题： 对象类（Object Class）功能的实现与调试 讨论了对象类中新功能的实现，特别是在PG后端的实现。 强调了在对象类中实现新功能时，需要对应的函数来支持几何操作（geomet operation）。 消息传递系统（Messenger）的配置与测试 讨论了消息传递系统的硬编码配置问题，以及如何移除这些配置。 提到了单元测试已经验证了消息传递系统的更改，但发现了一些需要在主分支上修复的问题。 Crimson后端状态与调试 讨论了Crimson后端在达到后端状态时遇到的问题，以及如何解决这些问题。 提到了在Crimson中，事件处理和恢复操作的调度方式与传统OSD不同，需要进一步优化。 Scrubbing引擎的改进 讨论了如何重构现有的Scrubbing代码，以便更好地支持未来的开发和测试。 强调了如果重构能够简化代码并提高可测试性，将是非常有价值的。 SeaStar反应器的单元测试框架 讨论了如何使用SeaStar反应器进行单元测试，以及如何简化测试框架。 强调了任何能够简化单元测试编写的措施都将对开发有利。 决定事项： 继续推进对象类功能的实现和调试工作。 解决消息传递系统在主分支上的问题，并确保所有测试通过。 优化Crimson后端的调度机制，确保事件处理和恢复操作的正确性。 重构Scrubbing代码，提高其可测试性和可维护性。 完善SeaStar反应器的单元测试框架，简化测试流程。 后续行动计划： 完成对象类功能的实现，并进行详细的测试。 修复消息传递系统在主分支上的问题，并提交PR。 对Crimson后端进行进一步的优化和调试，确保其稳定性和性能。 开始重构Scrubbing代码，并进行单元测试。 完善SeaStar反应器的单元测试框架，并推广使用。 备注： 所有开发工作应遵循Ceph的开发规范和最佳实践。 定期进行代码审查和性能测试，确保代码质量和系统性能。 保持团队内部的沟通和协作，及时解决开发过程中遇到的问题。 会议结束： 会议于[具体时间]结束，感谢所有参会人员的积极参与和贡献。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。希望这份纪要能够帮助团队成员更好地理解和执行后续的开发工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-20 :: Ceph Orchestration Meeting","slug":"2020-04-20_-_-_Ceph_Orchestration_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-28T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-20_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-20_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题：Ceph 每周会议 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： Ceph 15.2.2 版本更新 进行了大量针对用户当前遇到问题的 bug 修复。 改进了文档，有助于用户解决未预料到的问题和可用性问题。 主机移除问题 讨论了从 Ceph 集群中移除主机的用户体验问题，当前流程繁琐且容易出错。 发现调度器的行为存在意外情况，例如在指定主机和数量时，调度器的行为不符合预期。 调度器行为调整 讨论了调度器在处理特定放置规范时的行为，特别是当指定主机和数量不匹配时的处理方式。 决定调整调度器的行为，优先考虑主机的指定，并在无法满足放置规范时给出警告或拒绝配置。 Prometheus 监控堆栈的高可用性 讨论了如何提高 Prometheus 监控堆栈的高可用性，包括在多个节点上部署 Prometheus 服务器和使用代理进行负载均衡。 提出了在每个节点上复制监控堆栈的方案，以避免数据丢失和提高响应性。 Ceph 命令工具箱 介绍了新的 Ceph 命令工具箱，可以简化运行 Ceph 命令的操作，特别是在需要一次性操作或自动化脚本时。 决定事项： 调整调度器的行为，优先考虑主机的指定，并在无法满足放置规范时给出警告或拒绝配置。 研究并实施 Prometheus 监控堆栈的高可用性方案。 继续完善 Ceph 命令工具箱，以简化管理和操作流程。 后续行动计划： 完成调度器行为的调整，并确保现有集群的平稳迁移。 进一步讨论和细化 Prometheus 监控堆栈的高可用性方案。 继续开发和测试 Ceph 命令工具箱，确保其稳定性和实用性。 其他讨论： 讨论了 Kubernetes 和 Ceph 在处理节点不足时的行为差异。 讨论了如何简化监控堆栈的配置和管理，特别是在使用代理进行负载均衡时。 会议结束： 会议于[具体时间]结束，下次会议定于下周同一时间进行。 以上是本次 Ceph 每周会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-21 :: Ceph Crimson Meeting","slug":"2020-04-21_-_-_Ceph_Crimson_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-29T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-21_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-21_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议概要 日期: 未明确 参与者: 未列出具体人员 议程: 讨论了Ceph存储系统中的一些技术问题，包括节点大小调整、数据结构设计、代码实现和测试等。 主要议题 节点大小调整问题: 讨论了在Ceph中调整节点大小的可行性和效率问题。 决定简化处理，不考虑双分裂情况，但节点一旦存储在树中，其大小不可更改。 提出了通过写入新的大块来处理节点大小扩展的方法。 数据结构设计: 讨论了O节点（Onoda notes）的内部结构设计，包括固定大小和可变大小部分的分离。 提出了将O节点分为固定大小和可变大小两部分的设计思路。 代码实现和测试: 讨论了代码实现的进展，包括已经实现的专利函数和即将进行的提取重设计。 提到了正在进行单元测试的开发，包括FS和LBA树的插入和分裂操作。 强调了文档编写和代码提交的重要性。 其他技术问题: 讨论了日志恢复、树节点类设计、块布局和哈希碰撞处理等问题。 提出了优先考虑空间效率而非计算效率的设计原则。 决定事项 简化节点大小调整的处理逻辑。 设计O节点的内部结构，分为固定大小和可变大小两部分。 继续推进代码实现和单元测试的开发。 编写相关文档并提交代码审查。 后续行动计划 完成单元测试的开发，并编写相关文档。 提交代码审查，并根据反馈进行调整。 继续进行提取重设计和日志恢复的开发。 关注并处理网络和会议时间安排的问题。 其他备注 会议中提到了网络问题和会议时间安排的调整，需要进一步确认和处理。 会议记录和讨论内容将更新到共享文档中，供后续参考。 结束语 感谢所有参与者的贡献，期待下周的会议继续推进项目进展。祝大家有一个愉快的一周！","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-22 :: Ceph Docubetter Meeting","slug":"2020-04-22_-_-_Ceph_Docubetter_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-29T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-22_-_-_Ceph_Docubetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-22_-_-_Ceph_Docubetter_Meeting/","excerpt":"","text":"会议纪要 参会人员 Zack 会议主持人 会议时间 日期：具体日期未提及 时长：未明确记录 会议内容 疫情更新 澳大利亚近期疫情控制良好，连续两天无新增病例和死亡病例。 讨论了澳大利亚与美国的疫情管理差异，对澳大利亚的疫情控制表示惊讶和赞赏。 工作更新 Zack近期在欧洲时间工作，与Sebastian合作处理orchestrator box bugs。 提到了长时间工作（17小时）的经历，以及对工作的热情和享受。 Ceph文档更新 讨论了Ceph文档的当前状态，特别是ceph.com和seba/install网站的问题。 提到了文档中的403和404错误，以及需要解决这些问题的紧迫性。 讨论了将文档迁移到readthedocs的计划，并需要处理冗余的网站。 信息检索倡议 提出了一个信息检索倡议，旨在改进文档的可发现性和可用性。 讨论了使用Sphinx和 restructured text来创建更好的文档索引。 提到了文档编写和版本控制的复杂性，以及需要简化这些流程。 Google Season of Docs 讨论了Google Season of Docs的参与计划，特别是关于初学者指南的项目。 提到了提交截止日期（5月4日），并计划提前准备和审查提案。 Ceph网站改进 讨论了改进ceph.io网站的必要性，包括简化用户和开发者的导航。 提到了添加视频和其他多媒体内容的可能性，以提高用户体验。 行动计划 计划在论坛中提出关于ceph.io网站改进的讨论，并创建相关的Trello卡片。 计划在Google Season of Docs截止日期前准备好提案，并提前进行审查。 后续行动 在论坛中提出ceph.io网站改进的讨论。 准备并审查Google Season of Docs的提案，确保在截止日期前提交。 继续跟踪和解决Ceph文档中的问题，特别是403和404错误。 备注 会议内容涉及Ceph文档和网站的改进，以及Google Season of Docs的参与计划。 讨论了疫情对工作和生活的影响，以及对澳大利亚疫情控制的赞赏。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-16 :: Ceph Performance Meeting","slug":"2020-04-16_-_-_Ceph_Performance_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-28T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-16_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-16_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 主要议题 新PR讨论 Igor提交了两个新PR： 将Metallic Size和BlueStore切换回4K用于硬盘，基于其在混合分配器上的出色工作。 延迟大写入PR，该PR看起来很有前景。 Ygritte确认大差异PR已默认启用，但混合分配器尚未默认启用，计划尽快完成。 性能优化 讨论了一个新的PR，该PR借鉴了几年前在文件存储中使用的前置分割方案，旨在通过预分割目录来提高大型目录的性能。 Nihad将平衡器和up matt模式默认开启，以便在下一个发布周期中进行更多测试。 Keith正在审查一个关于NVMe设备的PR，尚未有实质性进展。 性能测试 Mahan和Peng进行了一些关于单线程和双线程每分片的测试，发现单线程在高Q深度下的随机读性能显著提高。 讨论了是否应该从双线程每分片切换到单线程每分片，以及如何通过分析锁争用等问题来优化性能。 其他更新 Igor的两个PR（混合分配器和大写入）已合并。 讨论了增加Jenkins测试以捕获性能回归的可能性。 Adams的PR通过了最近的测试轮次，预计很快会合并。 决定事项 确认将大差异PR默认启用，并计划尽快将混合分配器也默认启用。 同意增加Jenkins测试以捕获性能回归，并可能调整测试参数以提高准确性。 决定继续探索单线程每分片的性能优势，并通过进一步的测试和分析来确定最佳配置。 后续行动计划 Igor将完成混合分配器的默认启用更改，并提交PR。 Mahan和Peng将继续进行单线程和双线程每分片的性能测试，并提供详细的性能分析。 继续推进Adams的PR合并进程，以解决相关的性能瓶颈问题。 探索和实施更广泛的性能测试策略，包括在更大的集群环境中进行测试。 其他 会议中还讨论了其他一些PR的更新和关闭情况，但没有重大决策或行动计划。 结论 会议涵盖了多个关于性能优化和测试的议题，确认了一些关键的PR合并和默认启用计划，并制定了进一步的性能测试和分析计划。所有参与者将在接下来的周期中继续推进这些工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04- 23 :: Ceph Performance Meeting","slug":"2020-04-_23_-_-_Ceph_Performance_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-29T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-_23_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-_23_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 主要议题与讨论内容 Ceph PR更新 本周有一个新的PR，涉及改进Ceph的测试基础设施，以减少由于随机变异导致的测试结果失败。 关闭的两个PR包括：使用全带宽进行填充和合并Keef的PR，后者移除了NVMe设备中的data buffman pool，据称这是一个性能改进。 BlueStore与Allocator讨论 讨论了关于BlueStore在Alex的设置中使用4K的问题，以及如何测试新的混合分配器。 计划随机切换分配器并进行测试，但此计划将推迟至后续讨论。 MDS目录预分割PR更新 更新了MDS目录预分割的PR，收到了反馈，建议减少添加的12字节，可能会减少到1字节，但会牺牲一些功能。 性能改进与PR更新 Margie和ping的PR进行了讨论，涉及通过不减少线程或分片来提高性能的简单修复。 Adam的RocksDB分片PR也进行了更新。 Ceph CI性能CI更新 讨论了Ceph CI性能CI的进展，包括启用非经典OSD设置的测试。 讨论了硬件资源的分配和使用，包括可能的重用Smitty机器和Jenkins节点的重新分配。 Jenkins与性能测试 讨论了如何在Jenkins中集成更多性能测试，包括使用FIO和Rados bench等工具。 讨论了如何处理硬件资源的争用问题，包括使用标签和预定的调度策略。 决定事项 将继续推进Ceph的测试基础设施改进，特别是在减少测试结果的变异性方面。 将考虑在Jenkins中集成更多的性能测试，特别是使用FIO和Rados bench。 将探索硬件资源的更有效分配，包括可能的重用现有机器和优化测试流程。 后续行动计划 继续更新和审查相关的Ceph PR。 进一步讨论和实施在Jenkins中集成性能测试的具体方案。 继续研究和优化硬件资源的分配和使用，确保测试的稳定性和可靠性。 其他事项 讨论了硬件性能随时间的变化，建议在长时间运行测试前重启机器以减少变异性。 讨论了使用单一节点进行基础性能测试的可能性，以简化测试流程和减少变异性。 会议结束时，团队成员表示期待接下来的进展，并祝愿大家有一个好的工作周。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-27 :: Ceph Orchestration Meeting","slug":"2020-04-27_-_-_Ceph_Orchestration_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-29T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-27_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-27_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 日期： 2023年某月27日 参会人员： 团队成员（具体名单未提供） 主持人： 未明确 会议议题： 每日测试套件的进展 讨论了SEF manager的每日测试套件，特别是与ha Miguel相关的工作。 确认CI（持续集成）是否通过，以便进行合并。 测试套件的运行策略 讨论了测试套件应运行在set master上，以测试manager模块的编排功能。 决定不在master或release builds上运行此测试，以避免不可靠性。 短期计划是将测试添加到mr. rook PRs中，以监控PR是否触发问题，但不阻塞master builder。 创建每日测试套件管道的计划 决定先合并当前工作，然后单独处理创建每日测试套件管道的工作。 确认需要一个新的工作项来创建每日测试套件管道。 技术支持和学习 讨论了团队成员对Yankees（可能是某种技术或工具）的经验有限，但愿意学习。 提到Adam Kreitman作为技术支持，他位于以色列，便于时区协调。 决定事项： 确认CI通过后，将进行代码合并。 测试套件将暂时添加到mr. rook PRs中，不阻塞master builder。 需要创建一个新的工作项来建立每日测试套件管道。 后续行动计划： 合并当前工作，并开始创建每日测试套件管道的工作。 团队成员将学习并适应新的技术或工具。 与Adam Kreitman保持联系，以便在技术问题上获得支持。 会议结束： 会议在确认无其他议题后结束，团队成员互相道别并祝愿大家有美好的一天。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-28 :: Ceph Crimson Meeting","slug":"2020-04-28_-_-_Ceph_Crimson_Meeting","date":"2020-04-28T16:00:00.000Z","updated":"2020-04-29T16:00:00.000Z","comments":true,"path":"2020/04/29/2020-04-28_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/29/2020-04-28_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[列出参会人员] 会议主持：[主持人姓名] 主要议题： 项目进展更新 Ceph存储系统优化：讨论了关于Ceph存储系统中的树状结构（tree-based）恢复机制的优化工作。 调试与修复：提到了在elbe tree相关代码中的调试工作，以及对PT log based recovery的bug修复。 技术细节讨论 空间与计算效率：探讨了如何通过确保树索引（tree index）的唯一性来提高空间和计算效率。 模板类型系统：讨论了定义模板类型系统以组织逻辑，控制代码复杂度。 节点间比较优化：讨论了在树结构中，父节点与子节点之间的字符串比较优化策略。 后续行动计划 代码审查与合并：提到即将进行的代码审查（PR review）和合并工作。 项目管理：提醒团队成员关注项目管理工具（如Google Doc），以便跟踪其他团队成员的工作进展。 决定事项： 确认了树状结构恢复机制的优化方向，特别是关于树索引的唯一性和节点间比较的优化。 确定了模板类型系统的定义和实施计划，以简化代码逻辑。 后续行动： 完成并提交PT log based recovery的bug修复代码。 继续进行elbe tree的调试工作，并优化树状结构的恢复机制。 实施并测试模板类型系统，确保其有效降低代码复杂度。 其他事项： 提醒团队成员使用项目管理工具，以便更好地协作和跟踪项目进度。 会议结束： 会议在[具体时间]结束，主持人感谢大家的参与，并鼓励团队成员继续保持沟通和协作。 备注：会议中提到的具体技术细节和代码优化方案需要进一步的技术文档和代码审查来确认和实施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-06 :: Ceph Orchestration Meeting","slug":"2020-04-06_-_-_Ceph_Orchestration_Meeting","date":"2020-04-12T16:00:00.000Z","updated":"2020-04-13T16:00:00.000Z","comments":true,"path":"2020/04/13/2020-04-06_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/13/2020-04-06_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 会议议题： Ceph项目进展回顾 上周Octopus版本的测试中发现了一些问题，这是预期之内的。 Page休假期间，工作负荷有所增加，幸运的是有志愿者帮助规划关键事件。 Drive Group重命名讨论 讨论了是否需要重命名Drive Group，目前已经重命名并在文档中更新。 需要进一步重命名Pisan类中的Drive Group。 OSI Replacement讨论 讨论了OSI Replacement的相关特性，包括代码路径的简化、子卷相关设置的一致性创建等。 文档中有许多相关的跟踪问题和新的特性报告，正在进行逐步的实现和修复。 开发环境优化讨论 讨论了如何简化Ceph的开发环境设置，特别是使用容器化方法。 提出了两种方法：一种是使用现有的容器镜像并复制必要的二进制文件和库，另一种是使容器更加不可变，通过链接指向外部卷。 讨论了非特权模式下运行容器的可能性，以及网络配置的问题。 决定事项： 继续推进OSI Replacement的实现和修复工作。 继续优化开发环境，特别是容器化方法的使用。 考虑在开发环境中使用环境变量来标识开发模式，并相应地挂载特定路径。 后续行动计划： 继续跟踪和解决Octopus版本中的问题。 完成Drive Group的重命名工作。 继续研究和实施开发环境的优化方案。 创建一个新的跟踪问题，用于处理容器镜像的定期清理和优化。 下次会议： 预定于下周进行，具体时间和议题待定。 会议结束： 会议于[具体时间]结束，感谢大家的参与。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-07 :: Ceph Testing Meeting","slug":"2020-04-07_-_-_Ceph_Testing_Meeting","date":"2020-04-12T16:00:00.000Z","updated":"2020-04-13T16:00:00.000Z","comments":true,"path":"2020/04/13/2020-04-07_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/13/2020-04-07_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议参与者： Yuri, Undine 会议日期： [具体日期未提供] 会议主要议题： 1. Ceph项目新功能讨论 - Yuri正在测试一个由Nathan引入的新功能，该功能允许在集群关闭前无限期睡眠。 - 该功能旨在允许用户在集群部署后进行调试或实验，通过在任务调度时添加“sleep before tear down”选项实现。 - 目前该功能尚未合并到主分支，Yuri正在对其进行审查和测试。 决定事项： - Yuri计划在功能测试完成后，通过邮件通知团队成员。 - 考虑增加通知功能，如在Rocket Chat或通过邮件通知。 后续行动计划： - Yuri将继续测试“sleep before tear down”功能，并确保其稳定性和可用性。 - 功能测试完成后，Yuri将通知团队成员，并考虑增加通知机制。 其他讨论内容： - 讨论了当前的工作环境和生活方式，特别是在疫情期间的居家工作和社交限制。 - 分享了个人的健康状况和家庭情况，以及疫情对个人和家庭的影响。 会议总结： 会议主要围绕Ceph项目的新功能“sleep before tear down”进行了讨论，Yuri负责该功能的测试和后续通知工作。此外，会议还涉及了疫情期间的工作和生活状态，以及个人和家庭的情况。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-07 :: Ceph Crimson Meeting","slug":"2020-04-07_-_-_Ceph_Crimson_Meeting","date":"2020-04-12T16:00:00.000Z","updated":"2020-04-13T16:00:00.000Z","comments":true,"path":"2020/04/13/2020-04-07_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/13/2020-04-07_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的研发进展，特别是关于crimson项目的实施细节和未来计划。会议中，团队成员分享了各自的工作进展，讨论了遇到的技术挑战，并确定了后续的行动计划。 主要议题 性能优化： 讨论了关于迁移（migration）和背景噪声（background noise）的问题。 探讨了如何选择合适的混合点（hybrid point）以优化性能，涉及prefix tree和bid tree等技术。 代码审查和项目管理： 强调了对crimson项目代码的短期审查需求，特别是随着项目向Carroll的迁移。 讨论了如何识别和分配低挂果（low-hanging fruit）任务给新加入的贡献者。 技术实现细节： 涉及了writable sister poll的设计理解，以及对sister设计的帮助。 讨论了关于backfill实现中的死循环问题，以及primary和Bakula环境中的迁移问题。 功能开发和测试： 讨论了LBAs（Logical Block Addresses）的代码实现，以及相关的单元测试。 涉及了heartbeat功能的改进和数据结构的模型化。 项目规划和目标设定： 讨论了关于snapshot功能的必要性和优先级。 确定了crimson项目在Pacific版本中的核心目标，包括速度和质量的提升。 决定事项 确定了crimson项目在Pacific版本中的核心目标，强调了速度和质量的重要性。 决定将snapshot功能作为扩展目标，而不是核心需求。 确定了需要进一步讨论和明确的低挂果任务，以便新贡献者能够更容易地参与项目。 后续行动计划 安排另一次会议以详细讨论和分配低挂果任务。 继续进行crimson项目的代码审查和性能优化工作。 确保所有团队成员更新其工作进展，并在Trello板上记录相关信息。 其他事项 讨论了关于自动分割磁盘为多个OSDs的问题，以及如何改进工具以支持这一功能。 强调了文档和工具的重要性，以降低新贡献者的入门门槛。 会议结束 会议在明确了后续行动计划和目标后结束，团队成员被鼓励继续更新其工作进展，并在Trello板上记录相关信息。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-08 :: Ceph Docubetter Meeting","slug":"2020-04-08_-_-_Ceph_Docubetter_Meeting","date":"2020-04-12T16:00:00.000Z","updated":"2020-04-13T16:00:00.000Z","comments":true,"path":"2020/04/13/2020-04-08_-_-_Ceph_Docubetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/13/2020-04-08_-_-_Ceph_Docubetter_Meeting/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： Zack, Linds, Nana, Josh, Kay foo, Keith, Linds, Lens 主要议题： 1. 搜索功能问题讨论 - Google CSC 在中国不可用，需要通过JavaScript脚本解决。 - 文档搜索可能是一个解决方案，但需要团队成员负责设置。 - 搜索功能是一个持续的难题，需要不断努力解决。 文档和网站组织优化 计划编写概览页面，清理和组织网站文档，以实现“意外发现”（discovery by serendipity）。 希望通过对网站的重新组织，使用户能够像在Wikipedia上一样，通过浏览网站发现新信息。 文档内容改进 计划与团队成员进行定期会议，提出基础问题，以便更好地理解项目和文档需求。 希望在文档页面上方添加简短描述，例如对“擦除编码”（erasure coding）的解释，以帮助用户理解。 团队协作和沟通 提议加入CLT（Component Lead Team）会议，以便更好地了解项目和团队成员。 希望建立一种机制，使得当有人遇到文档问题时，能够得到及时的反馈，而不是感觉无人回应。 决定事项： - Zack将被添加到CLT会议的邀请名单中。 - 计划继续优化搜索功能，并改进文档的可发现性和组织结构。 后续行动计划： - Nana将发送CLT会议的邀请给Zack。 - Zack将继续努力解决搜索问题，并开始编写概览页面和改进文档内容。 - 团队成员将支持Zack的工作，提供必要的帮助和反馈。 其他讨论： - Lens提出关于read the docs和udemy的适用性问题，建议可能需要分开处理API文档和其他类型的文档。 - 会议结束时，Zack提醒团队成员保持时间管理，确保会议效率。 会议结束： - 会议在讨论了所有议题和行动计划后结束，Zack感谢大家的参与并期待在未来的会议中继续合作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-09 :: Ceph Performance Meeting","slug":"2020-04-09_-_-_Ceph_Performance_Meeting","date":"2020-04-12T16:00:00.000Z","updated":"2020-04-13T16:00:00.000Z","comments":true,"path":"2020/04/13/2020-04-09_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/13/2020-04-09_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间 日期：具体日期未提供 时间：上午 参会人员 主持人：未明确 参会人员：团队成员 会议内容 优化和更新 NVMe设备优化：从up to miss easy提交了一个优化请求，目前需要有人进行审核，但优先级不高，因为相关人员目前在加拿大。 OSD线程优化：ma Jinping提交了一个更改OSD线程数的请求，讨论了理论测试和实际性能表现，建议进一步审查。 缓冲列表使用迭代器：讨论了使用迭代器进行比较操作的优化，已有人进行审核，整体看起来不错。 关闭和合并的PR 多个PR被关闭，包括一个移除vector的PR和一个关于Z Lib压缩配置的PR。 一些优化和文档更新的PR被合并，例如针对throttle的优化和blue FS缓冲I/O的默认禁用。 性能测试和CI讨论 讨论了性能CI的集成，包括Jenkins和CBT框架的使用，以及如何进行长期运行的测试。 讨论了如何更好地记录和可视化性能测试结果，包括使用数据库索引和时间序列数据。 硬件推荐更新 文档更新包括硬件推荐，提供了更新的建议，帮助用户了解不同硬件配置的预期性能。 后续行动计划 继续审查和优化PR，特别是性能相关的。 推进性能CI的集成和长期测试的实施。 讨论和实施更好的性能测试结果记录和可视化方法。 行动项 继续审查和优化PR，特别是性能相关的。 推进性能CI的集成和长期测试的实施。 讨论和实施更好的性能测试结果记录和可视化方法。 下次会议 时间：下周 内容：继续讨论性能CI的进展和任何需要解决的问题。 备注 会议中提到的具体技术细节和代码变更需要进一步的技术文档和代码审查来确保准确性和实施的有效性。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-04-13 :: Ceph Orchestration Meeting","slug":"2020-04-13_-_-_Ceph_Orchestration_Meeting","date":"2020-04-12T16:00:00.000Z","updated":"2020-04-13T16:00:00.000Z","comments":true,"path":"2020/04/13/2020-04-13_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/13/2020-04-13_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间与参与人员 日期： [具体日期未提供] 参与人员： Sebastian、Travis、Jeff、Daniel、Danny等（由于假期，部分人员未出席） 主要议题 系统故障转移与恢复讨论 讨论了系统的故障转移（failover）和恢复机制，特别是关于Ceph管理器（manager）的恢复能力和健康状态。 提到了Def ADM模块的测试不足问题，建议增加测试以确保在灾难恢复情况下的有效性。 管理器（Manager）与组件的高可用性 探讨了在管理器节点上部署多个组件（如Prometheus、Grafana等）的必要性和方式。 讨论了使用HAProxy进行负载均衡和故障转移的可能性，以及如何确保服务在管理器故障时的连续性。 Rook与Def ADM的集成与测试 讨论了Rook与Def ADM的集成测试进展，特别是关于夜间自动化测试的实施，以尽早发现问题。 提到了当前测试中存在的问题，如CIA测试失败，并讨论了解决方案和后续步骤。 决定事项 需要进一步测试和验证管理器的高可用性和故障转移机制，特别是在使用HAProxy的情况下。 计划在下一个会议中深入讨论管理器和组件的高可用性配置，并与上游团队协调。 确认将实施夜间自动化测试，以持续监控Rook与Def ADM的集成稳定性。 后续行动计划 增加对Def ADM模块的测试，特别是在灾难恢复场景下的测试。 研究并实施HAProxy配置，以支持管理器的高可用性和故障转移。 继续推进Rook与Def ADM的集成测试，确保所有组件的稳定性和兼容性。 跟踪并解决当前测试中遇到的问题，如CIA测试失败，并确保相关修复尽快合并到主分支。 其他讨论 讨论了Rook 1.3版本的发布情况，确认目前没有其他紧急的Orchestration问题需要讨论。 会议结束 会议在讨论了所有议题后结束，计划在后续会议中继续讨论未决问题。 备注： 由于会议记录中存在一些不清晰的部分和重复内容，上述纪要可能需要根据实际会议内容进行调整和补充。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-04 :: Ceph Crimson Meeting","slug":"2020-02-04_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-02T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-04_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-04_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： Ceph存储系统的支持与改进 讨论了Ceph的Crimson存储引擎的更新和支持情况。 分析了PG（Placement Group）集合的内存样式转换问题及其对性能的影响。 探讨了Ceph的OSD（Object Storage Daemon）在处理PG消息时的回归问题。 性能优化与错误修复 讨论了Ceph的内存存储在特定条件下的错误，特别是在OSD等于2或3时的连接问题。 讨论了Ceph的C++代码库（C star）的旧版本在创建CPU集合时未使用CPU信息的问题。 项目进展与后续计划 讨论了Ceph的对象类（Object Class）功能的实现进展，特别是对其他插件的支持。 讨论了Ceph的恢复机制和后台填充（backfill）机制的优化。 决定事项： 需要进一步调查和修复PG集合的内存样式转换问题，特别是在OSD等于2时的错误。 需要更新C star以正确传递CPU信息，并修复相关的回归问题。 需要对Ceph的对象类功能进行进一步的开发和测试，以支持更多的插件。 后续行动计划： 继续跟踪和修复PG集合的内存样式转换问题，并确保性能测试可以继续进行。 更新C star以正确处理CPU信息，并修复相关的回归问题。 继续开发和测试Ceph的对象类功能，以支持更多的插件。 安排定期的远程工作会议，以协调和跟踪项目的进展。 其他备注： 会议中提到了Ceph的恢复机制和后台填充机制的优化，以及C star的更新和性能问题。 讨论了Ceph的代码库（C star）的更新和性能问题，以及相关的错误和警告。 会议建议定期举行远程工作会议，以协调和跟踪项目的进展。 下次会议预告： 下次会议将于[具体日期]举行，将继续讨论Ceph的改进和优化，以及项目的进展和后续计划。 会议结束语： 会议在积极的氛围中结束，参会人员对项目的进展和后续计划表示乐观，并期待下次会议的进一步讨论。 会议记录人：[记录人姓名] 审核人：[审核人姓名] 日期：[具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-05 :: Ceph Developer Monthly","slug":"2020-02-05_-_-_Ceph_Developer_Monthly","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-05_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-05_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议概要 日期与时间: [具体日期] 参与者: Liam, Josh, 及其他相关人员 主要议题: Ceph项目的状态更新、功能开发进展、监控系统改进、自动化部署及未来计划 讨论内容 状态更新 目前主要进行的是一些小的修复和改进，包括监控系统的进展，如添加节点导出器和Prometheus的工作正在进行中。 部署FSS（File System Storage）的工作也在进行中，但还有一些紧急问题需要解决，特别是在 orchestrator 模块中。 监控系统改进 讨论了关于如何处理主机和主机名的模糊性问题，提出了一个方案来确保主机名的一致性，以便更好地集成到CRUSH map中。 需要增加基于每个主机的IP或完全限定域名的能力，以便在不依赖DNS的情况下进行通信。 自动化部署 讨论了关于Ansible playbook的使用，用于自动化Ceph集群的部署和转换过程。 强调了在监控方面和故障处理方面仍存在的主要差距。 功能开发进展 讨论了NFS网关的开发状态，目前仍在进行中，但尚未有人关注rgw NFS网关。 密码更改功能即将完成，正在进行最后的QA测试。 未来计划 计划在接下来的一个月内推动用户启用telemetry模块，目标是达到500或1000个活跃的集群。 讨论了关于cephalic的在线会议计划，建议分块进行，以便更有效地讨论各个议题。 决定事项 确认了Ceph集群的监控和自动化部署的改进方向。 确定了密码更改功能的最终测试和部署计划。 计划推动用户启用telemetry模块，并设定了具体的目标。 后续行动计划 继续推进监控系统和自动化部署的改进工作。 完成密码更改功能的QA测试并部署。 推动用户启用telemetry模块，并通过邮件列表和社交媒体进行宣传。 安排cephalic的在线会议，分块讨论各个议题。 其他 讨论了关于Ceph客户端版本和功能比特的命名问题，建议未来不再使用命名版本，而是直接使用功能比特来标识支持的功能。 会议结束时，所有参与者对未来的工作计划表示了肯定，并期待下一次的在线会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-11 :: Ceph Crimson Meeting","slug":"2020-02-11_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-11_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-11_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统中的一些技术问题，包括缓存机制、消息处理、性能优化以及代码实现细节。会议中，多位研发人员分享了他们在各自领域的进展和遇到的问题，并讨论了解决方案和后续行动计划。 主要议题 缓存机制： 讨论了OSD（Object Storage Daemon）地图处理路径中的缓存策略，特别是两级缓存的存在原因。 确认了使用增量缓存列表的必要性，以便在不同OSD地图版本间高效传输数据。 消息处理与路由： 探讨了在Crimson存储系统中实现消息路由的策略，特别是从一对一模型转向多对多模型的可能性。 讨论了在消息处理中添加PG（Placement Group）日志条目对性能的影响，并提出了优化编码效率的建议。 性能优化： 讨论了如何通过减少内存拷贝来提高本地堆栈的性能，特别是通过启用iommu和设备内存映射。 分析了pending和dirty状态在事务处理中的区别及其对性能的影响。 代码实现与测试： 分享了在Crimson中实现PG锁和写路径的进展，以及相关的性能测试结果。 讨论了如何通过代码审查和测试来确保新功能的稳定性和性能。 决定事项 将继续优化缓存机制，特别是在处理OSD地图和增量数据时的效率。 将探索从一对一消息模型转向多对多模型的可行性，并评估其对系统性能的影响。 将进行更多的性能测试，特别是关于内存拷贝和消息编码的优化。 将通过代码审查和测试来确保新功能的稳定性和性能。 后续行动计划 继续研究和优化缓存机制，特别是在处理OSD地图和增量数据时的效率。 探索从一对一消息模型转向多对多模型的可行性，并评估其对系统性能的影响。 进行更多的性能测试，特别是关于内存拷贝和消息编码的优化。 通过代码审查和测试来确保新功能的稳定性和性能。 创建一个Google文档，用于收集和讨论研发过程中的问题和解决方案，以便团队成员共享知识和经验。 其他事项 会议中提到了一些技术细节和代码实现问题，这些问题将在后续的研发过程中进一步探讨和解决。 鼓励团队成员在研发过程中保持沟通和协作，共同推动Ceph存储系统的优化和发展。 结束语 感谢所有参与会议的研发人员，期待大家在接下来的工作中取得更多的进展和成果。下次会议再见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-10 :: Ceph Orchestration Meeting","slug":"2020-02-10_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-10_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-10_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 参会人员 Daniel 主要议题 Ceph Orchestrator CLI 的命名和使用问题 讨论了关于Ceph Orchestrator（简称Orchestrator）的CLI命令的命名和使用问题。 讨论了是否可以使用缩写“orc”来替代“Orchestrator”，以及是否应该支持全称和缩写两种输入方式。 讨论了CLI命令的统一性和简化问题，提出了一些改进建议，如使用“service apply”和“demon add”等命令。 代码生成和存储库管理问题 讨论了代码生成文件的管理问题，特别是是否应该将生成的文件存储在Git仓库中。 讨论了是否应该依赖外部仓库或第三方工具来管理这些生成的文件。 提出了一些解决方案，如将生成的Python类文件存储在仓库中，或者使用外部工具来管理。 CLI命令的具体实现和改进 讨论了CLI命令的具体实现，如“service apply”和“demon add”等命令的实现细节。 讨论了如何处理不同服务类型的命令，以及如何简化命令的使用。 提出了一些改进建议，如统一命令的参数命名，简化命令的使用等。 决定事项 CLI命令的命名和使用 决定继续使用“Orchestrator”作为CLI命令的名称，但考虑支持缩写“orc”。 决定简化CLI命令，使用“service apply”和“demon add”等命令来统一和简化操作。 代码生成文件的管理 决定将生成的Python类文件存储在Git仓库中，作为临时解决方案。 决定未来考虑使用外部工具或第三方仓库来管理这些生成的文件。 后续行动计划 CLI命令的改进和实现 继续改进和实现CLI命令，确保命令的统一性和简化。 考虑支持缩写“orc”作为“Orchestrator”的替代。 代码生成文件的管理 继续寻找更好的解决方案来管理生成的文件，减少对Git仓库的依赖。 考虑使用外部工具或第三方仓库来管理这些文件。 文档和沟通 更新相关文档，确保所有开发人员了解新的CLI命令和代码生成文件的管理方式。 加强团队内部的沟通，确保所有决策和改进措施得到有效执行。 备注 会议中提到的“IRC chat”和“CLI”等术语，均保留原文，以确保专业性和准确性。 会议中提到的“rook”和“ceph”等项目名称，均保留原文，以确保专业性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-12 :: Ceph Docubetter Meeting","slug":"2020-02-12_-_-_Ceph_Docubetter_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-12_-_-_Ceph_Docubetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-12_-_-_Ceph_Docubetter_Meeting/","excerpt":"","text":"会议纪要 会议主题：Ceph存储系统中的PG修复与文档更新 与会人员：Ceph研发团队成员 会议时间：[具体时间] 会议地点：[具体地点] 主要议题： PG修复功能讨论 讨论了PG（Placement Group）修复功能在无校验和情况下的表现。 确认了PG修复在某些情况下可能使用损坏的版本作为修复版本，需要用户手动干预。 决定简化PG修复的文档描述，避免误导用户。 文档更新与改进 讨论了对象存储工具（Object Store Tool）的文档需求，确认需要进一步完善。 提出了对Ceph命令（如ceph df, ceph osd df）的文档更新需求，以反映最新的功能和变化。 强调了文档更新的紧迫性，特别是对于即将发布的Octopus版本。 后续行动计划 确定了对PG修复文档的修改，包括删除可能导致误解的段落。 计划对ceph df和ceph osd df命令的文档进行详细更新。 确定了对象存储工具的文档需求，并计划将其纳入文档更新计划。 决定事项： PG修复文档将进行简化，删除可能导致误解的详细描述。 需要对ceph df和ceph osd df命令的文档进行更新，以反映最新的功能和变化。 对象存储工具的文档需要进一步完善，并纳入文档更新计划。 后续行动计划： 修改并更新PG修复的文档，确保其准确性和简洁性。 对ceph df和ceph osd df命令的文档进行详细更新，并与团队成员进行沟通确认。 开始对象存储工具的文档编写工作，并确保其内容准确反映工具的功能和使用方法。 定期通过邮件列表收集用户对文档的反馈，并根据反馈进行相应的改进。 其他事项： 确认了使用Vstart进行虚拟集群测试的方法，以便更好地理解和测试Ceph的功能。 强调了团队成员之间的沟通和协作，特别是在文档编写和功能更新方面。 会议总结： 本次会议主要聚焦于Ceph存储系统中的PG修复功能和相关文档的更新。通过讨论，团队明确了文档更新的需求和优先级，并制定了具体的行动计划。后续将根据计划进行文档的修改和更新，以确保用户能够获得准确和有用的信息。同时，团队也将继续关注用户反馈，不断优化和改进文档内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-20 :: Ceph Performance Meeting","slug":"2020-02-20_-_-_Ceph_Performance_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-20_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-20_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间 日期：[具体日期] 时间：上午 参会人员 Josh Mike Igor 其他核心团队成员 主要议题 PRC（Pull Request Community）更新 Igor提交了几个新的PR，包括使用延迟写入避免小块碎片化的优化，以及基于AVL和位图的混合分配器。 讨论了其他PR的进展，包括SPD cape性能改进、nvme设备代码优化、upper list和nvme设备分割等。 性能优化讨论 Igor分享了关于使用AVL和位图混合分配器的性能数据，讨论了内存使用和性能优化的权衡。 讨论了4k最小分配单元对性能的影响，特别是在读写操作中的表现。 IO 500基准测试 讨论了在Ceph上运行IO 500基准测试的进展和挑战，包括性能瓶颈和MDS（Metadata Server）的负载均衡问题。 提到了使用新的officinalis节点进行测试，以及尝试使用FUSE客户端时遇到的问题。 决定事项 继续优化和测试Igor的PR，特别是混合分配器和延迟写入策略。 继续进行IO 500基准测试，重点关注MDS的负载均衡和客户端性能。 后续行动计划 Igor将继续优化混合分配器和延迟写入策略，并分享更多性能数据。 继续进行IO 500基准测试，尝试解决性能瓶颈和MDS负载均衡问题。 使用Patrick的脚本进行更深入的性能分析和调试。 其他讨论 讨论了Ceph在生产环境中的内存使用问题，以及如何通过优化分配器来解决。 提到了Ceph在IO 500基准测试中的排名，目标是提高性能并进入前13名。 会议结束 会议在感谢所有参会人员的参与后结束，并约定下周再次开会。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-24 :: Ceph Orchestration Meeting","slug":"2020-02-24_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-24_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-24_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概要 日期: [具体日期] 参会人员: [参会人员名单] 主持人: [主持人姓名] 记录人: [记录人姓名] 主要议题 Pull Request讨论 PR 33442: 讨论了关于在生产环境中添加P trace标志的问题，该标志用于调试容器。会议中提出了安全性考虑，认为不应无条件地在所有生产环境容器中添加此标志。 PR 大Rhenium: 讨论了将“no”重命名为“host”的请求，从通用Orchestrator的角度来看是有意义的，但可能会增加Ceph的复杂性。 测试流程改进 Brookside测试: 讨论了如何改进对Orchestrator接口变更的测试。提出了使用现有的持续集成系统进行命令行测试的方案，并计划本周内完成初步测试。 Nightly Builds: 讨论了建立nightly builds的必要性，以检测最新的稳定版本是否存在问题，而不影响正常的PR和主构建流程。 Blinking Lights功能 讨论了在Python中指定参数和函数结果的改进，以及在实际硬件上测试该功能的必要性。 Rook Client迁移 讨论了将Rook Client从ESF组织迁移到Rook组织的进展，目前尚未开始，需要先解决一些关于存储提供者的重构问题。 Safe to Fail功能 讨论了关于Safe to Fail功能的进展，目前没有新的信息，计划暂时保持现状。 决定事项 对于PR 33442，决定不在生产环境中无条件添加P trace标志。 对于Brookside测试，决定本周内完成初步的命令行测试。 对于Nightly Builds，决定本周内开始初步的nightly builds测试。 对于Blinking Lights功能，决定在实际硬件上进行测试。 对于Rook Client迁移，决定在解决存储提供者重构问题后再进行。 对于Safe to Fail功能，决定暂时保持现状。 后续行动计划 完成PR 33442的安全性评估和决策。 实施并测试Brookside的命令行测试方案。 开始并监控nightly builds的实施。 在实际硬件上测试Blinking Lights功能。 解决存储提供者重构问题后，迁移Rook Client。 监控并更新Safe to Fail功能的进展。 其他事项 会议日历条目的问题，决定由相关人员检查并修复。 下次会议 时间: 下周或明天 地点: [会议链接或地点] 备注 会议中提到的具体PR编号和技术细节需要进一步的技术文档和代码审查。 记录人: [记录人姓名] 审核人: [审核人姓名] 日期: [具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-26 :: Ceph Docubetter Meeting","slug":"2020-02-26_-_-_Ceph_Docubetter_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-26_-_-_Ceph_Docubetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-26_-_-_Ceph_Docubetter_Meeting/","excerpt":"","text":"会议纪要 会议参与者 Anthony Jat (作者，提出关于版本特定更改的结构化记录请求) 其他参与者包括David Zapman等 会议主要议题 文档更新与审核 已完成PG修复页面的更新，并等待批准。 正在完善CephFS、Ceph OSD DDF和Set Object Store Tool的文档。 已开始每周发送文档审核请求，以确保文档的准确性和完整性。 版本特定更改的记录 Anthony提出需要更结构化的方式来记录版本特定更改，特别是mano s daemon down reporters的行为变化。 讨论了如何在发布说明中更好地记录这些更改，并确保技术准确性。 网站搜索功能的问题 报告了网站搜索功能不工作的问题，计划进行本地测试和修复。 FreeBSD安装文档 计划在Octopus发布后，协助编写FreeBSD安装文档。 文档质量提升 讨论了如何通过标签和审核流程提升文档质量。 未来会议和活动 讨论了由于新冠病毒影响，可能取消或转为线上的开发者会议。 决定事项 确认了文档更新的进度和下一步计划。 同意在发布说明中更严格地记录和审核版本特定更改。 计划修复网站搜索功能。 确认了FreeBSD安装文档的编写计划。 讨论了文档质量提升的具体措施。 后续行动计划 继续完善和审核文档。 确保发布说明中包含所有必要的版本特定更改。 修复网站搜索功能。 协助编写FreeBSD安装文档。 关注并参与可能的线上开发者会议。 下次会议 计划在两周后举行，时间将更适应北美地区。 会议结束，感谢所有参与者的出席。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-18 :: Ceph Crimson Meeting","slug":"2020-02-18_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-18_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-18_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的研发进展，特别是关于B树的分割与合并策略、事务管理层的实现细节，以及性能优化问题。会议中还涉及了关于原子操作和缓冲区列表的命名空间问题，以及未来开发方向的讨论。 主要议题 B树的分割与合并策略： 讨论了使用自顶向下（top-down）方法进行B树的分割与合并，相比于传统的自底向上（bottom-up）方法，这种方法更为简洁和高效。 强调了在实现过程中需要考虑事务管理层的影响，以及如何通过图示来清晰展示设计思路。 事务管理层的实现： 讨论了事务管理层的设计，特别是在处理冲突事务时的策略，以及如何避免显式的锁定机制。 强调了事务管理层在处理并发操作时的重要性，以及如何通过事务层来确保数据的一致性。 原子操作和缓冲区列表的命名空间问题： 讨论了原子操作和缓冲区列表在不同版本中的命名空间问题，以及如何通过命名空间来避免符号冲突。 提出了两种解决方案：一是通过命名空间来区分不同的版本，二是使所有版本使用相同的缓冲区列表。 性能优化： 讨论了PG日志条目的编码方式对性能的影响，提出了需要对现有编码方式进行优化的建议。 强调了性能优化的重要性，但同时也指出了当前首要任务是确保系统的基本功能正常运行。 决定事项 决定采用自顶向下的方法来实现B树的分割与合并，以简化代码并提高效率。 决定在事务管理层中避免显式的锁定机制，转而依赖事务层来处理并发操作。 决定对原子操作和缓冲区列表进行命名空间处理，以避免符号冲突。 决定优先确保系统的基本功能，性能优化将在后续阶段进行。 后续行动计划 继续开发和测试B树的自顶向下分割与合并策略。 完善事务管理层的实现，确保其能够有效处理并发事务。 对原子操作和缓冲区列表进行命名空间处理，解决符号冲突问题。 开始对PG日志条目的编码方式进行性能优化，但优先级较低。 定期进行进度更新和问题讨论，确保项目按计划推进。 其他讨论 讨论了关于DMA（直接内存访问）的可能性，但目前未作为优先考虑。 强调了文档和图示在开发过程中的重要性，以及如何通过这些工具来帮助团队成员更好地理解和实施设计。 结论 会议强调了在Ceph开发过程中需要平衡功能实现和性能优化的关系，确保系统的基础功能稳定可靠，同时不断探索和实施性能优化措施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-02 :: Ceph Orchestration Meeting","slug":"2020-03-02_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-02_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-02_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了分布式存储系统Ceph的相关开发进展，特别是与Rook项目和Octopus版本的集成测试。会议中还涉及了天气闲聊、个人健康状况以及一些技术问题的讨论。 主要议题 天气与个人状况： 与会者讨论了各自地区的天气情况，包括雪和春天的到来。 Sebastian因病未能参加会议，会议对此表示遗憾。 Rook项目进展： 讨论了在Rook项目中创建新的Python客户端仓库的决策，并将Python客户端代码从现有仓库迁移到Rook中。 提到了Rook项目中对Octopus RC版本的测试，已有PR（Pull Request）开放进行集成测试。 Ceph Octopus测试： 讨论了如何对Octopus版本进行更频繁的测试，包括设置夜间构建以便持续测试最新主分支。 强调了需要一个可靠的镜像来进行测试。 技术问题与解决方案： 讨论了在设置Ceph集群时遇到的问题，特别是与监控节点和操作符的连接问题。 提到了一些正在进行的技术改进，如改进调度器和服务描述的更新。 后续行动计划： 继续进行Octopus版本的测试，并确保所有相关的PR得到适当的审查和合并。 解决技术问题，如改进Ceph集群的部署和管理，以及优化Rook项目的集成。 决定事项 创建新的Rook仓库用于Python客户端，并迁移相关代码。 继续推进Octopus版本的测试工作，确保测试的可靠性和频繁性。 后续行动 完成Rook项目中Python客户端代码的迁移工作。 继续进行Octopus版本的集成测试，并解决测试中遇到的问题。 解决Ceph集群部署中的技术问题，优化集群管理和操作。 其他 会议中还讨论了个人健康、天气等非技术话题，增强了团队的凝聚力。 本次会议为Ceph和Rook项目的进一步发展奠定了基础，并明确了下一步的工作重点和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-03 :: Ceph Testing Meeting","slug":"2020-03-03_-_-_Ceph_Testing_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-03_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-03_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 与会人员 会议主持人：未知 参会人员：未知（至少包括Adam） 会议时间 日期：具体日期未提供 时间：具体时间未提供 会议议题 Ceph Master分支的补丁测试 讨论了与Cat Food合作的Master分支补丁，特别是与Pi3兼容性的两个测试。 需要进一步测试其余部分的覆盖率，可能需要其他人员的帮助。 分支管理和测试 讨论了Octopus分支的当前状态，以及Master分支的工作内容。 讨论了哪些分支仍然活跃，以及如何确定哪些分支需要回溯这些更改。 提到了Nautilus和Mimic分支仍然活跃，但需要与Sage确认。 测试框架的使用 讨论了ToTology和SEF CI的使用，以及它们在现有集群上的应用。 Adam询问了如何利用ToTology在现有集群上执行测试，以及是否可行。 调度问题 讨论了调度裸机桌面的问题，以及如何改进锁定机制。 提到了需要重新设计队列机制，以更好地管理资源和优先级。 决定事项 需要进一步测试Master分支的补丁，确保不会破坏现有流程。 需要确定哪些分支需要回溯更改，并与Sage确认。 需要与相关人员讨论如何利用ToTology在现有集群上执行测试。 后续行动计划 继续测试Master分支的补丁，并确保其兼容性。 与Sage确认哪些分支需要回溯更改。 与相关人员讨论ToTology在现有集群上的应用，并寻求解决方案。 重新设计队列机制，以改进资源管理和优先级设置。 其他备注 会议被录音，录音文件将存档，具体链接将在描述中提供。 参会人员反馈 Adam表示感谢并计划进一步与相关人员讨论ToTology的应用问题。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-27 :: Ceph Performance Meeting","slug":"2020-02-27_-_-_Ceph_Performance_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-27_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-27_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间 日期：[具体日期] 时间：上午 参会人员 Mark Igor Radek David Stockman Patrick 其他相关人员 主要议题 Ceph文件系统深度剖析文档 Mark被询问是否在Inktank时期编写过一份95页的Ceph文件系统深度剖析文档。Mark确认了文档的存在，并表示虽然有些细节可能已过时，但整体架构未变。 本周PR（Pull Request）更新 Igor提交了一个PR，旨在增加分配统计信息，以进行性能测试。 Radek关闭了一个关于缓冲区列表的小改动PR。 Igor的另一个旧PR，关于BlueStore的自动调优，被stale bot关闭，目前不再相关。 Mark更新了混合分配器和内存减少的PR，目前等待审查和可能的重构。 IO 500测试进展 讨论了Ceph在IO 500测试中的表现，目前排名第12，接近第11。 讨论了MDS（Metadata Server）中的锁争用问题，尝试通过改进锁机制来优化性能。 管理器（Manager）性能问题 用户报告了管理器性能缓慢和CPU使用率高的问题。 通过gdb pmp分析，发现主要时间花费在dump OST stats和PG stats上。 David Stockman提交了一个PR，旨在优化这些统计信息的获取方式，预计能显著改善性能。 其他讨论 讨论了是否将某些PR合并到Octopus版本中，特别是关于混合分配器和内存减少的PR。 Igor表示，虽然有些PR可能会影响顺序读取性能，但整体上是有益的，建议先合并再进一步优化。 决定事项 同意合并混合分配器和内存减少的PR，但暂时不改变默认设置。 将继续优化管理器的性能问题，特别是统计信息的获取方式。 后续行动计划 Igor将继续调查顺序读取性能问题，并尝试在Archer集群上进行更多测试。 团队将继续关注并优化IO 500测试中的表现，特别是MDS的锁争用问题。 管理器的性能优化PR将尽快合并，并观察其效果。 会议结束 会议在大家互相道别后结束，期待下周的会议。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-03 :: Ceph Crimson Meeting","slug":"2020-03-03_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-03_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-03_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 关键细节 错误修复与性能问题： 讨论了由William编码的错误，该错误已修复。 当前版本的代码在测试环境中部署时遇到问题，仅能使用旧版本进行测试。 性能比较显示，某些情况下旧版本的性能优于当前版本。 代码与架构讨论： 讨论了使用Cilium和FreeBSD编译的代码。 涉及PG log based recovery的实现和优化。 讨论了持久内存（persistent memory）的使用和优化。 后续行动计划： 继续优化和测试PG log based recovery的实现。 探索持久内存的使用，以提高性能和可靠性。 继续进行代码清理和文档更新。 讨论的主要议题 错误修复与性能优化： 确认了由William修复的错误，并讨论了性能回归问题。 讨论了如何改进部署和测试流程，以避免类似问题。 代码与架构优化： 讨论了Cilium和FreeBSD的使用，以及如何优化编译和部署流程。 深入讨论了PG log based recovery的实现细节和潜在优化点。 探讨了持久内存的使用，以及如何通过不同的接口实现更好的性能。 未来工作方向： 确认了继续优化PG log based recovery的必要性。 讨论了持久内存的潜在优势和实现方式。 确认了代码清理和文档更新的重要性。 决定的事项 错误修复： 确认了由William修复的错误，并讨论了性能回归问题。 代码与架构优化： 确认了继续优化PG log based recovery的必要性。 确认了持久内存的潜在优势和实现方式。 后续行动计划： 继续优化和测试PG log based recovery的实现。 探索持久内存的使用，以提高性能和可靠性。 继续进行代码清理和文档更新。 后续的行动计划 错误修复与性能优化： 继续监控和优化部署和测试流程，以避免性能回归问题。 代码与架构优化： 继续优化PG log based recovery的实现。 探索持久内存的使用，以提高性能和可靠性。 文档与代码清理： 继续进行代码清理和文档更新，以提高代码的可维护性和可读性。 结论 本次会议主要讨论了错误修复、性能优化、代码与架构优化以及未来工作方向。确认了继续优化PG log based recovery的必要性，并探讨了持久内存的潜在优势和实现方式。后续将重点关注这些方面的优化和改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-09 :: Ceph Orchestration Meeting","slug":"2020-03-09_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-09_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-09_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间与参与人员 会议时间：周一，下午4点 参与人员：Pasi、Sebastian等 会议议题与讨论内容 会议时间调整 讨论了将会议时间从当前的4点推迟两小时的可能性，以适应俄罗斯作者的日程冲突。 Sebastian表示可以适应新的会议时间。 管理员密码问题 讨论了如何在命令中隐藏管理员密码信息，避免在文档文件中暴露敏感信息。 提出了两种解决方案：添加新参数或按参数隐藏信息。 决定首先明确解决方案，然后开始实施。 Python客户端集成 讨论了将Python客户端集成到rook组织中的进展。 确认了相关文件已经迁移到新的仓库，并计划后续跟进。 网络配置问题 讨论了在Kubernetes集群中网络配置的问题，特别是在使用不同网络提供商（如calico、flannel）时的兼容性问题。 确认了在某些情况下，网络配置可能导致无法与服务通信的问题。 集群状态与配置 讨论了如何在Kubernetes中配置和管理Ceph集群的守护进程（demons）。 涉及到了CRD（Custom Resource Definition）的使用和守护进程的自动管理。 数据安全与清理 讨论了在删除守护进程时如何处理数据，特别是监控器（monitors）的数据。 提出了备份数据和逐步删除的方案，以确保数据安全。 决定事项 确认了Python客户端的集成进展，并计划后续跟进。 决定在删除守护进程时采取逐步删除和备份数据的策略，以确保数据安全。 确认了在Kubernetes中配置和管理Ceph集群守护进程的方案。 后续行动计划 继续跟进Python客户端的集成工作。 解决网络配置问题，特别是与服务通信的问题。 实施守护进程的自动管理和数据备份策略。 确保Ceph集群在Kubernetes中的稳定运行和管理。 备注 会议中提到的技术术语和产品名称（如Ceph、rook、Kubernetes、calico、flannel等）保持原文，以确保专业性和准确性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-05 :: Ceph Performance Meeting","slug":"2020-03-05_-_-_Ceph_Performance_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-05_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-05_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[具体人员名单] 主要议题： 性能优化更新 本周没有太多新的或更新的性能相关的Pull Requests (PRs)，团队主要集中在为下一个版本Octopus的修复工作上。 关闭的PR包括： 对BlueStore的NVMe设备后端的小优化，移除了不必要的操作。 Igor提交的一个小PR，增加了日志分配统计，用于4K Metallic大小测试。 Casey合并的PR，允许修改配置索引卡，主要改变了默认的桶索引分片数量，以提高列表桶索引的速度。 IO 500测试进展 继续进行SELinux测试与IO 500评分提升工作。 发现内核客户端在大尺寸读取时性能较慢，Fuse客户端也因多种原因性能极差。 开发了一个后端用于IOR和MD测试，直接与Loops FFS集成，初步结果显示在大尺寸顺序读取上显著更快。 PG日志更新优化 讨论了移除PG日志调用的实验，结果显示延迟显著降低，IOPS每核心有所提升。 建议将PG日志更新从brats TB移至其他不引起大量光放大的地方。 决定事项： 继续优化和测试IO 500性能，特别是比较内核客户端和Loops FFS的性能。 进一步研究和实施PG日志更新的优化策略。 后续行动计划： 继续关注和处理性能相关的PRs。 完成IO 500测试，并根据结果调整策略。 实施PG日志更新的优化，并监测其对性能的影响。 其他讨论： 讨论了使用不同客户端（如Fuse和Loops FFS）的性能差异及其原因。 探讨了未来可能尝试的其他用户空间文件系统内核模块。 会议结束： 会议在讨论了所有议题后结束，团队成员将继续专注于各自的任务，并计划下周再次会议。 备注： 会议中提到的具体技术细节和代码优化建议，需要进一步的技术文档和代码审查来确保实施的正确性和有效性。 以上为会议的详细纪要，涵盖了会议的主要讨论点、决定和后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-10 :: Ceph Crimson Meeting","slug":"2020-03-10_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-10_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-10_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议时间与参与人员 时间： 由于时钟调整，会议在美国东部时间早上7点进行。 参与人员： 会议参与者包括多位研发人员，涉及分布式存储系统Ceph的多个方面。 主要讨论议题 代码审查与学习 一位成员正在阅读和学习其他成员与Sam合作编写的代码，特别是在某些服务上的工作。 该成员下载了相关代码到个人笔记本电脑，计划详细审查。 系统改进与跟踪路径 讨论了需要跟踪路径的需求，特别是在处理叶节点时，以便在不返回的情况下合并父节点。 提交了SMP更改以辅助讨论组，移除某些条件。 性能问题与代码修复 讨论了性能回归问题，特别是与USD性能相关的问题。 一位成员反向修复了一些补丁，但发现对性能没有显著影响。 事务处理与代码理解 讨论了事务处理的相关问题，特别是对象启动事务与块级事务的区别。 一位成员正在编写状态图，以更好地理解代码逻辑。 代码调试与环境设置 一位成员正在调试PG log base 2恢复代码，并发现了一些需要先修复的其他问题。 该成员还设置了Alien Store环境，计划进行FIO测试。 接口与内存管理 讨论了连接关闭接口的修改，以避免死锁问题。 探讨了Google的内存管理技巧，以及如何在Ceph中应用这些技巧。 索引与性能优化 讨论了如何在Ceph中有效地构建H对象的索引，特别是在处理变长键时。 提出了使用前缀压缩和其他编码技巧来优化性能。 决定事项 需要进一步研究和实验以解决性能回归问题。 需要对事务处理和状态图进行更深入的理解和文档化。 需要继续调试和修复PG log base 2恢复代码中的问题。 后续行动计划 继续审查和学习相关代码，确保对系统有深入的理解。 完成状态图的编写，并将其作为文档分享给团队。 继续进行FIO测试和环境设置，以支持后续的调试工作。 继续研究和实验，以找到有效的索引和性能优化方法。 其他事项 确认会议录音是否需要上传到YouTube，并安排相关人员负责。 强调在新代码中包含函数头注释的重要性，以提高代码的可读性和维护性。 会议结束 会议在讨论完所有议题后结束，计划下周再次进行会议。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-12 :: Ceph Performance Meeting","slug":"2020-03-12_-_-_Ceph_Performance_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-12_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-12_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间与参与人员 时间： 早晨6:30 参与人员： Mark, Greg, Igor, Adam, 及其他团队成员 会议议题与讨论内容 项目进展更新 PR更新： 本周没有新的或即将关闭的PR。团队成员主要集中在现有问题的处理上。 更新PR： Igor更新了关于hybrid alligator的PR，但具体内容未详细讨论。 IO 500测试套件后端开发 进展： 后端已成功开发并显示出高性能，甚至超过内核客户端。 性能分析： 发现内核部分可能存在需要修复的问题。 测试结果： 在IO 500测试中，团队目前排名第9，接近第8。 硬件分类问题： 讨论了IO 500测试中硬件分类不明确的问题，以及如何在不同系统配置下进行有效竞争。 性能优化讨论 Adam的测试发现： 所有alligators在磁盘使用率达到80%后，性能迅速下降。讨论了是否应关注超过80%的磁盘使用情况。 Igor的优化工作： 介绍了针对4k min alaq size的优化，包括hybrid alligator和deferred writes的改进。展示了性能数据，并讨论了未来的优化方向。 决定事项 Hybrid Alligator的合并： 计划将hybrid alligator合并到主分支，但不作为默认设置。 Deferred Writes的调整： 对于deferred writes的调整，团队决定等待进一步测试和评估。 后续行动计划 继续优化： 团队将继续优化IO 500测试套件的后端，并关注特定测试案例的性能问题。 性能测试： Adam将继续进行性能测试，并在下次会议中分享详细数据。 代码审查与合并： Igor将继续进行代码审查，并计划将改进合并到主分支。 其他事项 文档共享问题： 讨论了Google Doc的访问权限问题，Adam将尝试解决文档共享的访问问题。 会议结束 时间： 会议在预定时间结束后结束。 下次会议： 团队成员将在下次会议中继续讨论和评估性能优化进展。 本次会议主要集中在Ceph存储系统的性能优化和IO 500测试套件的开发进展上，团队成员分享了各自的发现和优化策略，并制定了后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-02-25 :: Ceph Crimson Meeting","slug":"2020-02-25_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-02-25_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-02-25_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 与会人员 Kiku 其他未具名参与者 会议日期 本周 主要议题与讨论内容 Ceph 8 Index 代码审查 Kiku 本周主要工作是审查 Ceph 8 Index 的代码，深入理解其设计。 计划继续审查代码，并可能对设计进行优化。 恢复逻辑的分解与优化 讨论了将恢复逻辑分解为至少四个不同阶段的可能性： PG log 基于恢复 回填恢复（backfill recovery） PG 扫描 分散状态与回填和 PG log 基于恢复相关 建议从后端扫描开始，逐步推进。 单元测试与系统测试 讨论了代码中单元测试的不足，特别是在回填逻辑方面。 提到了 PG log 的重要性，以及其难以复现的边缘案例。 建议在 crimson 中实现代码时，尝试将其分解为组件，以便更好地进行单元测试。 LLVM 支持与构建细节 讨论了是否需要支持 LLVM，特别是在非生产环境中。 决定先合并代码，后续再考虑构建和非生产环境的细节。 Sister Allocator 的使用 讨论了 Sister Allocator 在 POSIX 环境中的使用问题。 计划与 Sister Gas 确认是否可以在 POSIX 环境中使用 Sister Allocator。 性能改进与测试 讨论了性能改进的可能性，特别是在使用 Sister Allocator 时。 计划进行一些基准测试，以评估性能改进。 代码审查与注释 讨论了代码审查的重要性，特别是在 scrubbing 相关代码中。 计划对代码进行详细审查，并在必要时添加注释。 后续行动计划 继续审查和优化 Ceph 8 Index 的代码。 分解和优化恢复逻辑，特别是从后端扫描开始。 在 crimson 中实现代码时，尝试将其分解为组件，以便更好地进行单元测试。 确认 Sister Allocator 在 POSIX 环境中的使用问题，并进行必要的调试。 进行性能基准测试，以评估性能改进。 结论 会议强调了代码审查、单元测试和性能优化的重要性，并制定了具体的行动计划，以确保 Ceph 项目的持续改进和发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-25 :: Ceph Science User Group Meeting","slug":"2020-03-25_-_-_Ceph_Science_User_Group_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-25_-_-_Ceph_Science_User_Group_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-25_-_-_Ceph_Science_User_Group_Meeting/","excerpt":"","text":"会议纪要 参会人员 Matthew（Sanger Institute） Diamond Light Source的代表 会议概述 会议主要讨论了在COVID-19疫情期间的工作状态、Ceph存储系统的最新动态、以及一些技术问题和解决方案。 工作状态更新 大多数人在家工作，只有少数必要人员在现场，如动物护理和COVID-19序列处理人员。 讨论了在家工作的体验和挑战，以及如何适应新的工作环境。 Ceph相关讨论 Octopus版本更新：讨论了新版本Octopus的安装问题，特别是依赖项缺失的问题。还提到了仓库工作方式的变化，现在只有最新版本在仓库中，旧版本可能被删除。 容器化部署：讨论了Ceph部署在容器中的优缺点，多数人倾向于在专用硬件上直接部署，而不是使用容器。 自动修复功能：讨论了Ceph的自动修复功能，如何在发现不一致时立即修复，而不是等待手动干预。 压缩算法问题：提到了一个关于压缩算法（lz4）的数据损坏问题，建议使用其他压缩算法如snappy。 文件系统布局：讨论了CephFS的布局和性能问题，特别是关于使用擦除编码池的建议。 硬件更新策略：讨论了硬件过保后的处理策略，多数人倾向于继续使用直到出现高故障率。 其他技术讨论 内存中的OSD：讨论了在内存中运行OSD的可能性及其性能影响。 邮件服务器：讨论了自托管邮件服务器的使用情况，包括Dovecot和Office 365等。 后续行动计划 继续监控和测试Ceph的新版本和功能。 考虑硬件更新和迁移策略。 探索和优化邮件服务器解决方案。 会议结束 感谢所有参与者的参与，并提醒大家保持安全和健康。 下一次会议预计在5月底举行，具体信息将提前通知。 本次会议涵盖了多个技术议题，特别是在Ceph存储系统的使用和优化方面。通过这些讨论，团队成员能够分享经验、解决问题，并为未来的工作制定计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-16 :: Ceph Orchestration Meeting","slug":"2020-03-16_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-16_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-16_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概述 日期: 星期一 参与者: Lily及其他未明确提及的成员 背景: 由于学校关闭，孩子们在家，可能会有一些背景噪音。 主要议题 全球疫情情况 讨论了各国因疫情采取的封锁措施，如意大利、法国等地的封锁情况。 提到了美国和欧洲国家对非必要商业活动的关闭，仅保留药店和超市等基本服务。 Ceph开发相关 开发者峰会: 讨论了即将到来的开发者峰会的时间安排和内容。 OSD Remover功能: 讨论了OSD Remover的实现和使用场景，特别是替换和重用OSD ID的需求和挑战。 项目管理标签: 提出了为项目功能添加标签以更好地组织和跟踪功能的建议。 Sefie DM相关: 讨论了Sefie DM的功能和未来的改进方向。 OCS在裸金属环境中的测试 讨论了在裸金属环境中使用OCS（OpenShift Container Storage）的挑战和需求，包括网络隔离、多OSD每NVMe设备配置等问题。 提出了对现有OCS配置和功能的改进建议，以更好地支持高性能的裸金属环境。 决定事项 开发者峰会: 需要确定具体的时间和议程。 OSD Remover功能: 需要进一步讨论和明确其使用场景和实现细节。 项目管理标签: 同意需要改进项目管理和功能跟踪的方法。 OCS在裸金属环境中的测试: 需要进一步研究和解决相关的技术问题。 后续行动计划 开发者峰会: 安排具体的时间和议程，确保所有相关人员都能参与。 OSD Remover功能: 继续讨论并明确其使用场景和实现细节。 项目管理标签: 开始实施标签系统，以更好地组织和跟踪项目功能。 OCS在裸金属环境中的测试: 继续研究和解决相关的技术问题，并与相关团队进行更深入的讨论。 其他备注 会议中提到了全球疫情对日常生活和工作的影响，强调了团队成员之间的相互理解和支持。 会议记录中包含了一些技术细节和讨论，需要相关领域的专业人员进一步分析和处理。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-23 :: Ceph Orchestration Meeting","slug":"2020-03-23_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-23_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-23_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 参会人员： [参会人员名单] 会议主持： [主持人姓名] 主要议题： Pull Request 进展 目前有一个关于“doubling in nights”的Pull Request正在进行中，该请求已进入测试阶段。 项目更新 讨论了近期的工作进展，包括等待审查的PR和正在处理的小改动及bug修复。 特别提到了为即将到来的optimism准备相关工作。 技术关注点 提到了正在进行的NFS集成工作。 决定事项： 继续推进当前的Pull Request测试和审查工作。 确保所有小改动和bug修复按时完成，为即将到来的optimism做好准备。 后续行动计划： 继续关注和处理NFS集成相关的工作。 定期检查和更新项目进展，确保所有任务按计划进行。 会议结束时间： [具体时间] 下次会议预定： [具体日期和时间] 备注： 会议中提到的具体技术细节和项目名称（如“doubling in nights”和“NFS integration”）需要进一步的技术文档或代码审查来详细了解。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-24 :: Ceph Crimson Meeting","slug":"2020-03-24_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-24_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-24_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的多个技术问题，包括内存泄漏、B+树设计、数据压缩算法、以及项目管理工具的迁移等。会议中，团队成员分享了各自的工作进展，讨论了遇到的问题，并制定了后续的行动计划。 主要议题 内存泄漏问题： 讨论了由社区关闭时未正确释放资源导致的内存泄漏问题。 决定进一步记录和分析泄漏原因，并寻找解决方案。 B+树设计： 讨论了B+树的实现细节，特别是如何处理变长键和优化存储结构。 提出了使用固定部分和可变部分来优化键的存储，以减少空间浪费和提高查询效率。 数据压缩算法： 讨论了使用Arcade压缩算法和共享前缀提取来优化数据存储。 决定进一步研究和实现这些算法，以提高数据存储效率。 项目管理工具迁移： 讨论了从GitHub迁移到Trello进行项目管理的可行性和必要性。 决定进一步评估迁移的成本和收益，并与团队成员讨论以达成共识。 决定事项 内存泄漏问题： 继续跟踪和记录内存泄漏的具体情况，以便更好地理解和解决问题。 B+树设计： 继续研究和优化B+树的存储结构，特别是键的处理方式。 考虑在内存中创建原型，以便更好地理解和测试B+树的操作。 数据压缩算法： 进一步研究和实现Arcade压缩算法和共享前缀提取，以优化数据存储。 项目管理工具迁移： 评估从GitHub迁移到Trello的成本和收益，并与团队成员讨论以决定是否迁移。 后续行动计划 内存泄漏问题： 分配专人负责跟踪和解决内存泄漏问题。 定期更新团队成员关于内存泄漏问题的进展。 B+树设计： 分配专人负责B+树的设计和实现。 定期进行代码审查和测试，以确保B+树的稳定性和性能。 数据压缩算法： 分配专人负责研究和实现数据压缩算法。 定期更新团队成员关于数据压缩算法的进展。 项目管理工具迁移： 分配专人负责评估和准备项目管理工具的迁移。 定期与团队成员讨论迁移的进展和计划。 其他事项 团队成员分享了各自的工作环境和当前的疫情情况，强调了在家工作的新常态。 讨论了如何更好地利用远程工作的时间，提高工作效率。 会议结束 会议在团队成员的积极讨论和明确后续行动计划后结束，大家期待下一次会议的进展和成果。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。希望这份纪要能帮助团队成员更好地理解和执行会议内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-26 :: Ceph Performance Meeting","slug":"2020-03-26_-_-_Ceph_Performance_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-26_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-26_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 会议时间: [具体日期] 参会人员: Greg, Igor, Ilya, Mark Cogan, 以及其他相关人员 会议主题: 讨论Ceph存储系统的性能优化和相关PR（Pull Request）的进展 讨论的主要议题 Ephemeral Sharding PR: Greg询问关于Ephemeral Sharding PR的进展，是否已经可以正常工作。 目前还在更新中，尚未完全确认其状态。 Locking Improvement PR: 讨论了一个改变锁定机制的PR，该PR旨在减少全局锁的生命周期并引入适当的文件锁定。 Igor表达了对该PR的担忧，担心在当前架构下难以实现。 Performance Issues with OSD and Cache Management: 讨论了OSD在处理大量数据时，由于缓存管理不当导致的性能下降问题。 发现OSD在达到缓存限制后，开始从磁盘读取数据，导致页面缓存增加，最终引发内核交换，严重影响性能。 提出解决方案包括禁用BlueFS的缓冲I/O，以避免使用页面缓存作为辅助缓存。 Kernel RBD Performance Bottleneck: Ilya和Greg讨论了Kernel RBD在单客户端进行顺序读取时的性能瓶颈。 发现当I/O深度超过64时，内核中的内存复制操作时间增加，影响性能。 讨论了可能的解决方案，包括检查内核锁的状态和网络堆栈的行为。 决定的事项 禁用BlueFS缓冲I/O: 决定禁用BlueFS的缓冲I/O，以避免使用页面缓存，从而提高系统的稳定性和性能。 Josh将创建相关的PR。 PR的合并和测试: 确认将合并和测试相关的PR，包括Adam的Column Family Sharding PR和Igor的缓存缩减PR。 计划在下一个点发布版本中包含这些改进。 后续行动计划 PR的进一步审查和测试: 继续审查和测试涉及的PR，确保它们在合并前达到稳定状态。 性能测试和分析: 进行更多的性能测试，特别是在单网络接口下的测试，以进一步分析和解决性能瓶颈。 内核锁和网络堆栈的深入分析: 使用perf和lockstat等工具，深入分析内核锁和网络堆栈的行为，以找出性能问题的根本原因。 其他讨论 未来会议和性能优化: 讨论了即将到来的会议和可能的性能优化话题，包括对Boost和MDS的进一步优化。 结论 会议结束时，Greg感谢所有参与者的贡献，并期待在下一次会议中能有更多的进展和解决方案。 以上是本次会议的详细纪要，涵盖了会议的主要讨论内容、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-17 :: Ceph Crimson Meeting","slug":"2020-03-17_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-17_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-17_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的研发进展，包括技术问题、解决方案和后续行动计划。会议中涉及了多个技术议题，包括Ceph BlueStore的实现、对象类（CLS）的函数实现、以及OSD（对象存储守护进程）的恢复和清理工作。 主要议题 Ceph BlueStore的实现 讨论了使用新版本的BlueJeans进行视频会议，并测试了其白板功能和屏幕共享功能。 提到了BlueStore中的一些实现细节，如节点在树中的实现和团队讨论。 对象类（CLS）的函数实现 讨论了CLS法律项目的进展，包括对CBT的更新请求和产品审查。 发现了某些函数在测试中出现回归问题，需要进一步分析和修复。 OSD的恢复和清理工作 讨论了OSD中的恢复工作和清理工作，包括恢复和清理的具体任务分配。 提到了OSD中的加密和传统T的比较，以及在恢复工作中可能遇到的问题。 技术问题和解决方案 讨论了在OSD中处理OSD map消息时的问题，以及如何通过调试来解决这些问题。 提到了心跳竞赛问题和messenger连接接口的修改。 文档和协作 强调了文档的重要性，建议在Google Docs中进行协作，以适应不同的时区。 讨论了如何通过文档来协调和记录恢复和清理工作的进展。 决定事项 确认了BlueStore中的一些实现细节和团队讨论的结果。 确定了CLS法律项目的进展和需要解决的回归问题。 分配了OSD中的恢复和清理工作的具体任务。 强调了文档和协作的重要性，建议在Google Docs中进行协作。 后续行动计划 继续分析和修复CLS法律项目中的回归问题。 分配和执行OSD中的恢复和清理工作的具体任务。 在Google Docs中进行文档协作，记录和协调工作进展。 继续测试和优化BlueStore的实现，包括白板功能和屏幕共享功能。 关键词 Ceph BlueStore CLS law OSD 恢复工作 清理工作 Google Docs 文档协作 会议在讨论了各项议题后结束，与会者将在后续工作中继续推进各项任务的实施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-31 :: Ceph Crimson Meeting","slug":"2020-03-31_-_-_Ceph_Crimson_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-31_-_-_Ceph_Crimson_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-31_-_-_Ceph_Crimson_Meeting/","excerpt":"","text":"会议纪要 参会人员 Jeremy（因病缺席） John Scott Adam Radek Josh Anderson 主要议题 Ceph项目进展 John：上周主要忙于处理Ceph以外的任务，本周将重点关注Ceph相关工作，特别是关于CRUSH map的更新和同步。 Scott：上周根据John和Mark的反馈，对Ceph版本请求进行了大量修改，并解决了CNS路径调试问题。已提交PR修复CSO测试问题，并计划在本地测试通过后合并到主分支。 Adam：上周忙于处理DCM相关工作，本周回归Ceph，已提交多个PR，包括修复回归问题和改进代码结构。还讨论了增加单元测试以避免对象类问题，并建议引入新的测试标签。 Radek：正在完成状态机的工作，希望在一周内完成初步版本。还讨论了改进PR以在失败时重新读取对象状态，并考虑降低复制成本的问题。 Josh Anderson：上周调试了PG log based recovery代码，手动测试已通过，正在添加更多测试用例。 项目管理与组织 讨论了将现有项目卡片迁移到Carrillo，并按不同类别和里程碑进行组织，以提高项目管理的可见性和效率。 建议引入更短的里程碑，以便更好地跟踪进度。 决定事项 将现有项目卡片迁移到Carrillo，并按类别和里程碑进行组织。 引入新的测试标签，以便更灵活地运行特定测试。 后续行动计划 John：继续处理CRUSH map的更新和同步。 Scott：本地测试PR并合并到主分支。 Adam：继续处理回归问题，并增加单元测试。 Radek：完成状态机工作，并改进PR。 Josh Anderson：提交PG log based recovery的PR。 项目管理：迁移项目卡片到Carrillo，并按计划进行组织和跟踪。 其他事项 讨论了代码复制的性能问题，并计划后续进行优化。 确认了会议的音频问题已解决。 下次会议 下周同一时间进行。 会议结束 感谢大家的参与，祝大家有个愉快的一天/夜晚。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-30 :: Ceph Orchestration Meeting","slug":"2020-03-30_-_-_Ceph_Orchestration_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-30_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-30_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了关于Ceph存储系统的测试与集成问题，特别是与SAP EWM（Extended Warehouse Management）系统的结合使用。 主要议题 Ceph与SAP EWM的集成测试： 讨论了Kimba CDM（Ceph Distributed Storage）在SAP EWM环境下的测试情况。 强调了CDS（Common Data Service）在集成过程中的重要性。 技术细节与实施方案： 探讨了如何在Ceph系统中实现与SAP EWM的有效对接。 讨论了OK Labs在集成过程中的关键作用和可能的优化点。 决定事项 确认继续推进Ceph与SAP EWM的集成测试，确保系统的稳定性和性能。 指定了技术团队负责后续的测试和优化工作。 后续行动计划 技术团队将制定详细的测试计划，并开始下一阶段的集成测试。 定期更新项目进度，确保所有关键问题得到及时解决。 备注 会议中提到的“MSV”和“Trettner”可能是特定技术或人员的代号，需进一步确认其具体含义。 本次会议为Ceph与SAP EWM的集成项目提供了明确的方向和行动计划，确保项目按预期顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-03-24 :: Ceph Testing Meeting","slug":"2020-03-24_-_-_Ceph_Testing_Meeting","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/2020-03-24_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/2020-03-24_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议主题： 关于Ceph CI（持续集成）改进的讨论 会议时间： [具体时间] 参会人员： [参会人员名单] 会议记录： 议题讨论： 会议开始时，讨论了关于Ceph CI的改进提议。发言人提到了之前在邮件列表中发送的关于CI的邮件，并希望在会议上进一步讨论。 讨论了当前CI流程的问题，包括手动操作多、耗时长、容易出错以及缺乏自动化的集成测试。 提出了改进建议，包括自动触发集成测试、选择合适的测试子集以及根据文件变更自动调整测试范围。 决定事项： 决定在下周的CDS（持续交付系统）产品测试讨论会议上进一步讨论CI改进提议。 确定了会议时间为下周一上午7:10（太平洋时间）。 后续行动计划： 发言人计划参加下周的CDS会议，以获取更多利益相关者的支持和反馈。 计划与具有CI经验的同事合作，进一步推动CI改进的实施。 其他讨论： 讨论了疫情对工作和生活的影响，特别是远程工作的适应情况。 提到了以色列的疫情控制情况，以及对日常生活的具体影响。 会议总结： 本次会议主要围绕Ceph CI的改进进行了深入讨论，确定了下一步的行动计划，并安排了后续的会议时间。希望通过进一步的讨论和合作，能够有效提升Ceph的CI流程效率和质量。 会议结束时间： [具体时间] 下次会议预告： 下周一上午7:10（太平洋时间）的CDS产品测试讨论会议。 备注： 请所有参会人员注意查看邮件通知，确保不错过后续的会议安排。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Pacific: Performance","slug":"CDS_Pacific_-_Performance","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/CDS_Pacific_-_Performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/CDS_Pacific_-_Performance/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph项目在即将发布的Pacific版本中的各项开发进展和计划。会议涵盖了多个关键领域，包括性能优化、代码库的小规模改进、以及持续集成和测试的增强。 主要议题 BlueStore性能优化 Adam's comb family sharding: 该项目在Octopus时间框架内成为重要项目，虽然尚未合并，但正在积极开发中。预计将大幅改善写入放大和空间放大问题。 Double cache fix: 等待Adam's comb family sharding合并后，将解决缓存重复数据问题，避免缓存污染。 Cache age based bidding: 计划在上述修复后实施，通过分析缓存中数据的相对年龄来优化内存分配。 Node data structure diet: 由Igor负责，旨在减小O节点数据结构的大小，预计带来10-20%的改进。 Hybrid allocator and deferring big writes: 这些改进将有助于减少硬盘上的中间层，特别是在4K块大小的情况下。 PG log和PG balancer的改进 PG scaling和PG balancer的变化: 这些改进在Octopus中已经开始，但需要持续关注以确保不会引入不良行为。 RGW优化 避免写入暂停: 针对bucket index splitting的优化，虽然设计可行，但目前优先级较低。 MDS和CephFS的动态子树分区方案 MDS性能优化: 尝试通过改变MDS的请求服务方式来提高性能，特别是对于大型目录文件的处理。 RBD和内核客户端的性能问题 25Gbps链路的瓶颈问题: 正在诊断中，希望在Pacific版本中解决。 持续集成和性能测试 性能测试框架的增强: 计划通过Jenkins集成CBT来运行性能测试，确保不引入性能回归。 长期运行的大型规模测试: 考虑使用Toothology进行更复杂的性能测试，特别是对于大型集群和长时间运行的测试。 决定事项 BlueStore的多个性能优化将在Pacific版本中继续推进。 PG log和PG balancer的改进将持续进行，以确保稳定性和性能。 RGW的优化将根据优先级进行，可能会有所延迟。 MDS和CephFS的优化将尝试新的方法来提高处理大型目录的性能。 RBD和内核客户端的问题将作为优先事项进行诊断和修复。 性能测试框架将得到增强，包括Jenkins集成和Toothology的使用。 后续行动计划 继续推进BlueStore的性能优化工作，特别是Adam's comb family sharding和相关缓存优化。 持续监控和改进PG log和PG balancer的性能和稳定性。 评估RGW优化的优先级，并根据资源情况进行调整。 探索MDS和CephFS的新优化方法，特别是在处理大型目录文件时。 解决RBD和内核客户端的性能瓶颈问题，特别是在高速网络环境下。 增强性能测试框架，确保能够有效检测和防止性能回归。 结论 本次会议为Ceph的Pacific版本开发提供了明确的方向和行动计划，特别是在性能优化和持续集成测试方面。所有团队成员将继续努力，确保新版本的质量和性能达到预期目标。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Pacific: RADOS","slug":"CDS_Pacific_-_RADOS","date":"2020-04-02T16:00:00.000Z","updated":"2020-04-03T16:00:00.000Z","comments":true,"path":"2020/04/03/CDS_Pacific_-_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/03/CDS_Pacific_-_RADOS/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph存储系统的多个关键议题，包括数据复制、分布式跟踪、自动化恢复设置、管理器模块优化等。会议采用了开放互动的方式，鼓励与会者提出和讨论新的想法和问题。 主要议题 数据复制（Replication） 三星电子的代表介绍了在SAP系统中数据复制的过去和现在，以及未来的主要挑战和下一步计划。 讨论了指纹索引的可扩展性问题，以及如何在不改变现有系统的情况下添加新的元数据。 提出了使用另一个哈希函数来决定数据位置的方法，以提高数据放置的效率。 分布式跟踪（Distributed Tracing） 讨论了基于Jaeger的分布式跟踪在OSD中的应用，以及如何优化依赖关系以确保功能的实现。 自动化恢复设置（Simple Adaptive Recovery Settings） 重新评估了自动化恢复设置的需求，并计划在未来的版本中实现。 管理器模块优化（Manager Modules Optimization） 讨论了如何减少CPU周期和处理冗余信息，特别是在网络支付时间特性中。 提出了对管理器模块进行更深入的调查，以找出其他改进的机会。 平衡器（Balancer） 讨论了平衡器在考虑主OSD数量时的性能问题，并计划在未来的版本中进行改进。 自动化配置（Automated Provisioning） 讨论了自动化配置的需求，特别是在升级和格式转换的场景中。 Python子解释器（Python Subinterpreters） 讨论了Python子解释器在管理器模块中的应用问题，以及如何处理由于Python库的全局状态导致的冲突。 决定事项 继续推进数据复制和分布式跟踪的实现。 优化管理器模块，减少CPU使用和冗余信息处理。 改进平衡器，考虑主OSD的分布以提高性能。 探索自动化配置的新方法，特别是在升级和格式转换的场景中。 解决Python子解释器的问题，可能通过等待Python社区的改进或内部优化来实现。 后续行动计划 完成数据复制和分布式跟踪的实现，并进行测试。 对管理器模块进行深入分析，找出并实施优化措施。 改进平衡器，确保其在考虑主OSD数量时的性能。 探索自动化配置的新方法，特别是在升级和格式转换的场景中。 监控Python社区的动态，等待可能的改进，或内部实施优化措施。 结论 会议强调了Ceph存储系统在多个关键领域的持续改进和优化，以满足不断变化的技术需求和用户期望。通过开放的讨论和积极的行动计划，Ceph社区将继续推动存储技术的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Pacfic: CephFS","slug":"CDS_Pacfic_-_CephFS","date":"2020-04-01T16:00:00.000Z","updated":"2020-04-02T16:00:00.000Z","comments":true,"path":"2020/04/02/CDS_Pacfic_-_CephFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/02/CDS_Pacfic_-_CephFS/","excerpt":"","text":"会议纪要 主要议题与讨论内容 多文件系统（Multi FS）与快照复制（Snapshot Replication） 讨论了多文件系统和快照复制的优先级。 涉及快照调度和快照统计的相关PR（Pull Request），目前这些功能基本实现，但用户界面还需优化。 讨论了如何处理快照同步，包括是否需要创建新的守护进程（demon）来处理同步。 快照同步的具体实现 讨论了使用arsenic作为初始方案，后续可能采用更原生的接口。 讨论了是否需要创建新的守护进程来处理同步，或者是否可以在管理器模块中实现。 快照同步的细节 讨论了快照同步时如何处理文件系统的变化，以及如何确保同步过程中的数据一致性。 讨论了是否需要为快照同步创建不可变的目录结构。 其他议题 讨论了多MDS前向扫描（Multi MDS Forward Scrub）的实现难度和可能的解决方案。 讨论了FS top功能的实现进展和未来需要完成的任务。 讨论了Ganesha的PR进展和未来的工作计划。 决定事项 快照同步 决定采用arsenic作为初始方案，后续可能采用更原生的接口。 决定创建新的守护进程来处理快照同步。 多MDS前向扫描 决定采用冻结所有导出（exports）的方式来实现多MDS前向扫描。 FS top功能 决定继续推进FS top功能的实现，包括CLI包装器的编写。 Ganesha的PR 决定继续推进Ganesha的PR，包括清理和合并相关代码。 后续行动计划 快照同步 完成快照调度和快照统计的PR，优化用户界面。 创建新的守护进程来处理快照同步。 多MDS前向扫描 实现冻结所有导出（exports）的方式来完成多MDS前向扫描。 FS top功能 完成FS top功能的CLI包装器编写。 Ganesha的PR 清理和合并Ganesha的PR，完成最后的集成工作。 其他任务 继续推进其他议题的进展，包括批量文件创建和删除、自动扩展插件、QA测试套件的改进等。 备注 会议中提到的具体PR和代码细节需要进一步跟踪和确认。 部分议题如快照同步的具体实现细节和Ganesha的PR进展需要后续详细讨论和执行。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Pacific: RBD","slug":"CDS_Pacific_-_RBD","date":"2020-04-01T16:00:00.000Z","updated":"2020-04-02T16:00:00.000Z","comments":true,"path":"2020/04/02/CDS_Pacific_-_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/02/CDS_Pacific_-_RBD/","excerpt":"","text":"会议纪要 会议主题：Ceph Pacific 版本的 RBD 部分讨论 会议时间：2020年4月2日 14:00 UTC 参会人员：Ceph 研发团队成员及相关领域专家 主要议题及讨论内容： RBD 功能特性更新 Care Buddy 特性：虽然不直接与 Pacific 版本绑定，但希望在此开发周期内完成。Elia 正在处理与 RBD 相关的 messenger 工作，但目前进展顺利。 压缩提示：在 Octopus 周期后期添加，允许在 RBD 池中的图像上设置压缩提示，以优化压缩行为。 本地化读取提示：允许在图像上设置提示，以基于 CRUSH 位置进行本地化读取，特别适用于跨数据中心的集群。 异步重构 主要涉及 exclusive lock 代码的异步重构，这是当前同步路径中的最后一个障碍。此重构对于未来开发和功能实现至关重要。 性能优化 讨论了 librbd 的缓存机制，特别是对象 ID 的哈希映射缓存，以减少 CPU 使用和提高小工作负载的性能。 探讨了 librbd 的新 IO 接口，旨在通过线程池和更快的 IO 处理来提高性能。 RBD 与 RGW 集成 计划通过 RGW 暴露 RBD 快照，利用新的 zipper 插件层，实现快照差异的程序化暴露，而无需复制数据。 即时恢复功能 讨论了从 S3 或 Swift 备份的 RBD 图像进行即时恢复的功能，类似于实时迁移，但使用 S3 或 Swift 客户端来满足读取需求。 客户端加密 讨论了在 librbd 中实现客户端侧加密的可能性，以解决克隆图像和快照的加密问题，特别是初始化向量（IV）的管理。 RBD NBD 守护进程 计划实现一个 RBD NBD 守护进程，能够服务多个块设备，以适应 Kubernetes 和容器环境的需求。 快照协调 讨论了在创建快照时协调客户端工作负载的可能性，包括冻结和解冻文件系统，以避免数据不一致。 决定事项： 继续推进异步重构工作，以支持未来的功能开发。 探索和实现 RBD 与 RGW 的集成，以及即时恢复功能。 研究客户端侧加密的实现，特别是 IV 管理的问题。 后续行动计划： 完成异步重构，并确保其稳定性和性能。 实现 RBD NBD 守护进程的多设备支持。 继续研究和开发客户端侧加密功能。 监控和优化 librbd 的性能，特别是在高吞吐量和高工作负载情况下的表现。 会议总结： 会议涵盖了多个关键的 RBD 功能更新和性能优化议题，团队将继续推进这些工作，以确保 Pacific 版本的顺利发布和高质量。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020 02 03 :: Ceph Orchestration Meeting","slug":"2020_02_03_-_-_Ceph_Orchestration_Meeting","date":"2020-03-31T16:00:00.000Z","updated":"2020-03-31T16:00:00.000Z","comments":true,"path":"2020/04/01/2020_02_03_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/01/2020_02_03_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题 Ceph存储集群的驱动组管理 Rook与Ceph的集成问题 Ceph管理模块的决策与未来行动计划 主要讨论内容 驱动组（Drive Groups）的设计与实现 讨论了驱动组是否应通过某种ID进行版本控制，以及是否应具有API版本。 探讨了驱动组是否应接受JSON输入，以及是否应基于字符串。 讨论了驱动组在Ceph中的持久性和幂等性问题。 Ceph管理模块（Orchestrator Module）的功能与实现 讨论了管理模块是否应记住驱动组的使用情况。 探讨了管理模块是否应直接将驱动组转换为Ceph卷命令。 讨论了管理模块是否应存储驱动组的相关信息。 Rook与Ceph的集成问题 讨论了Rook是否应直接接受驱动组作为输入。 探讨了Rook在处理驱动组时的声明性和命令性问题。 讨论了Rook是否应在驱动组处理后自动重新添加OSD。 决定事项 驱动组的处理方式 决定驱动组应具有持久性和幂等性，以确保在不同时间点的一致性。 决定驱动组应通过Ceph管理模块进行处理，而不是直接通过Ceph卷命令。 Rook与Ceph的集成 决定Rook应直接接受驱动组作为输入，以简化集成过程。 决定Rook在处理驱动组时应考虑声明性和命令性之间的平衡。 后续行动计划 驱动组的进一步开发 继续开发驱动组的功能，确保其在Ceph中的正确使用。 完善驱动组的文档，以便用户更好地理解和使用。 Ceph管理模块的优化 优化Ceph管理模块，使其更好地处理驱动组和Ceph卷命令之间的转换。 确保管理模块能够记住驱动组的使用情况，以便更好地管理Ceph集群。 Rook与Ceph的集成测试 进行Rook与Ceph的集成测试，确保驱动组在Rook中的正确处理。 解决Rook在处理驱动组时可能出现的声明性和命令性问题。 其他讨论 Ceph管理模块的决策 讨论了Ceph管理模块是否应更具决策性，以及是否应改变用户配置。 决定暂时不改变用户配置，但保留未来改变的可能性。 OSD支持管理模块 讨论了OSD支持管理模块的功能，以及如何利用该模块进行OSD的移除操作。 会议总结 会议对驱动组的设计与实现、Ceph管理模块的功能与实现以及Rook与Ceph的集成问题进行了深入讨论。决定继续开发驱动组的功能，优化Ceph管理模块，并进行Rook与Ceph的集成测试。同时，保留了关于Ceph管理模块决策的灵活性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Pacific: RGW","slug":"CDS_Pacific_-_RGW","date":"2020-03-31T16:00:00.000Z","updated":"2020-04-01T16:00:00.000Z","comments":true,"path":"2020/04/01/CDS_Pacific_-_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/04/01/CDS_Pacific_-_RGW/","excerpt":"","text":"会议纪要 关键细节 会议主题: Ceph分布式存储系统开发进展讨论 参会人员: Ceph研发团队成员及相关领域专家 讨论内容: 主要围绕Ceph的Octopus版本更新、RGW（RADOS Gateway）功能优化、多站点（multi-site）同步策略、性能优化及监控等方面。 主要议题 Octopus版本更新: 讨论了Octopus版本的合并部分，特别是RGW的相关功能。 确认了同步请求流程的进展，但对象工作（objector work）有所延迟。 多站点同步策略: 讨论了多站点同步的路线图，特别是动态分片（dynamic rashard）的实现。 讨论了数据同步优化，包括同步状态的缓存和OMAP卸载。 性能优化: 讨论了数据同步优化、OMAP卸载以及类FIFO的实现。 提到了动态分片的具体实现细节和可能的性能提升。 监控与管理: 讨论了多站点同步的监控需求，特别是仪表盘（dashboard）的功能扩展。 讨论了API的简化和统一，以便更好地支持监控和管理功能。 决定事项 动态分片: 确认动态分片为优先开发项目，文档和设计已经就绪。 监控功能: 确认需要增强多站点同步的监控功能，特别是仪表盘的显示和性能计数器的使用。 API简化: 决定简化API，以便更好地支持多站点同步和监控。 后续行动计划 动态分片开发: 继续推进动态分片的开发工作，确保按计划完成。 监控功能开发: 开发团队将着手增强多站点同步的监控功能，特别是仪表盘的显示。 API简化: 开发团队将简化API，以便更好地支持多站点同步和监控。 文档更新: 更新相关文档，确保用户和开发者能够理解新功能和改进。 其他讨论点 对象模型重构: 讨论了对象模型的重构，特别是数据库后端的集成和策略层的构建。 RBD集成: 讨论了RBD（RADOS Block Device）与RGW的集成，特别是快照功能的集成。 开发工具: 讨论了新的开发工具，如see patch和see start，以简化开发流程。 结论 会议总结了Ceph的当前开发进展，确认了优先开发项目，并制定了后续的行动计划。团队将继续推进各项功能的开发，确保Ceph的稳定性和性能得到持续提升。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-30 :: Ceph Performance Meeting","slug":"2020-01-30_-_-_Ceph_Performance_Meeting","date":"2020-03-30T16:00:00.000Z","updated":"2020-03-31T16:00:00.000Z","comments":true,"path":"2020/03/31/2020-01-30_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/03/31/2020-01-30_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 新PR介绍: 会议开始时，提到了多个新的Pull Requests (PRs)，包括来自Casey和Braddock的优化buffer lists的PRs。 Igor的PR: Igor提交了一个简化Onoda pin和unpin逻辑的PR，该PR解决了之前尝试修复时引入的复杂性和潜在的竞态条件问题。 Zone Commodity配置: 讨论了允许zone commodity配置index charts的PR，该PR还包括增加bucket shards数量的简单更改。 PG autoscaler更新: 一个增加默认PG数量到32的PR已经合并，旨在提高OSD对更多PG的响应性。 Bufferless和Buffer List优化: Radek和Corel讨论了优化buffer list大小的旧努力，包括使用迭代器和减少内存占用。 讨论的主要议题 性能优化: 重点讨论了如何通过优化buffer lists和调整PG数量来提高性能。 简化逻辑: 强调了简化代码逻辑的重要性，如Igor的PR所示。 CI和测试: 讨论了CI系统的改进，包括增加对master分支的CI支持和对不同基准测试的性能比较。 决定的事项 合并PR: 多个PR被合并或准备合并，包括优化PG数量和bufferless使用的PR。 CI改进: 决定继续改进CI系统，增加对更多基准测试的支持。 后续行动计划 继续优化: 继续关注和优化buffer lists和PG autoscaler。 CI系统升级: 继续升级CI系统，确保所有测试环境的一致性和最新性。 性能测试: 进行更多的性能测试，特别是在不同硬件和配置下的测试。 其他讨论点 SSD性能问题: 讨论了SSD性能问题，特别是关于队列大小和服务时间的优化。 环境升级: 讨论了测试环境的升级，包括从CentOS 7升级到更高版本。 会议最后，主持人宣布将休息两周，期间可能不会有会议。整体上，会议聚焦于性能优化和CI系统的改进，同时讨论了具体的PR和未来的工作方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Pacific: Orchestrator, cephadm, rook","slug":"CDS_Pacific_-_Orchestrator_cephadm_rook","date":"2020-03-30T16:00:00.000Z","updated":"2020-03-31T16:00:00.000Z","comments":true,"path":"2020/03/31/CDS_Pacific_-_Orchestrator_cephadm_rook/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/03/31/CDS_Pacific_-_Orchestrator_cephadm_rook/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了Ceph Pacific版本的重点工作，强调了当前Ceph Octopus版本的许多未解决问题，并决定在Pacific版本中主要关注于修复bug和解决工作流程中的缺陷，而不是增加新功能。 主要议题 Ceph Octopus版本的现状 Ceph Octopus版本存在许多粗糙的边缘和未解决的问题。 建议在Pacific版本中优先解决这些问题，而不是增加新功能。 开发者体验和文档改进 讨论了改进Ceph的开发者体验，特别是在使用Ceph的ATM（自动化测试模块）时。 强调了改进CLI文档的必要性，确保其与最新的功能和变化保持同步。 功能和改进的优先级 确定了几个关键的改进领域，包括OSD管理、升级流程、以及对现有功能的增强。 讨论了如何更好地集成和测试新的和现有的功能，以确保它们在实际使用中的稳定性和可靠性。 未来的工作方向 讨论了未来的工作方向，包括对Ceph的长期支持和维护策略。 强调了持续集成测试的重要性，以确保代码的质量和稳定性。 决定事项 在Pacific版本中，将重点放在修复bug和改进现有功能上，而不是增加新功能。 改进开发者体验和文档，确保开发者能够更容易地使用和理解Ceph的功能。 优先考虑关键的改进领域，如OSD管理、升级流程和功能增强。 后续行动计划 继续改进和优化Ceph的开发者体验和文档。 实施和测试关键的改进领域，确保它们在Pacific版本中得到妥善解决。 加强持续集成测试，确保代码的质量和稳定性。 结论 本次会议明确了Ceph Pacific版本的工作重点和方向，强调了在当前版本中解决现有问题的重要性，并为未来的工作制定了具体的行动计划。通过这些努力，Ceph将继续保持其在分布式存储领域的领先地位。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-Jan-23 :: Ceph Tech Talk - Ceph for Storing MeerKAT Radio Telescope Data","slug":"2020-Jan-23_-_-_Ceph_Tech_Talk_-_Ceph_for_Storing_MeerKAT_Radio_Telescope_Data","date":"2020-02-11T16:00:00.000Z","updated":"2020-02-11T16:00:00.000Z","comments":true,"path":"2020/02/12/2020-Jan-23_-_-_Ceph_Tech_Talk_-_Ceph_for_Storing_MeerKAT_Radio_Telescope_Data/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/02/12/2020-Jan-23_-_-_Ceph_Tech_Talk_-_Ceph_for_Storing_MeerKAT_Radio_Telescope_Data/","excerpt":"","text":"会议纪要 会议基本信息 日期: 2020年1月 主讲人: Thomas Bennett 地点: 南非开普敦 会议形式: 在线会议 会议内容概述 Thomas Bennett在会议上介绍了南非的MeerKAT射电望远镜及其数据存储解决方案，特别是Ceph分布式存储系统的应用。他详细讨论了MeerKAT望远镜的科学应用、数据处理流程以及Ceph在其中的角色。 关键细节 MeerKAT射电望远镜: MeerKAT是目前世界上最强大的射电望远镜。 位于南非卡鲁干旱地区，距离开普敦约90公里。 负责管理南非所有大型天文项目和设施。 Ceph存储系统: MeerKAT项目自2018年4月开始使用Ceph作为生产集群。 Ceph集群分为冷缓冲区和热缓冲区，热缓冲区主要使用SSD存储。 用户通过数据服务门户进行认证，并使用S3接口访问观测数据。 数据处理与科学发现: MeerKAT望远镜能够捕捉到高分辨率的射电图像，揭示了银河系中心黑洞等天体现象。 最近的一项研究发现了银河系中的新结构，这些发现已发表在《自然》杂志上。 Ceph集群配置与管理: 目前运行的Ceph集群版本为Luminous，计划升级到Nautilus。 集群包括多个不同规模的集群，从几PB到几十PB不等。 使用Ansible进行部署，但正在考虑构建自己的部署方法。 未来计划: 计划对Ceph集群进行升级，并测试EC池的使用。 考虑使用更高效的硬件配置，如增加处理器性能和使用更多的NVMe驱动器。 继续参与Ceph社区活动，包括组织meetups和参与Ceph会议。 后续行动计划 完成Ceph集群的升级和测试。 继续优化数据处理流程和存储管理。 加强与Ceph社区的交流和合作，推动技术进步和应用扩展。 联系方式 主讲人: Thomas Bennett 邮箱: tom@ska.ac.za 网站: https://ska.ac.za 本次会议为与会者提供了关于MeerKAT射电望远镜及其数据存储解决方案的深入了解，特别是Ceph在大型科学项目中的应用和挑战。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-23 :: Ceph Performance Meeting","slug":"2020-01-23_-_-_Ceph_Performance_Meeting","date":"2020-01-29T16:00:00.000Z","updated":"2020-01-29T16:00:00.000Z","comments":true,"path":"2020/01/30/2020-01-23_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/30/2020-01-23_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 PG自动缩放: 上周会议后，关于PG自动缩放的几个提案已经提交，包括Nihad的提案，将PG数量默认设置为32。 PR更新: Radek的PR改变了标准列表T的编码方式，不再使用无缓冲复制。Keefe的PR涉及透明比较器，以避免额外工作。Igor的PR通过改变数据结构减少了缓存PG的内存占用。 性能优化: 一个关于OSD PG日志条目的点改变PR，以及关于分裂读IO的PR，如果IO大小较大或NDB设备，理论上有助于性能提升。 RGW过滤逻辑: Erica添加的RGW过滤逻辑已通过QA测试，但需要重新调整。 空间放大问题: Igor讨论了blob空间放大问题，特别是在Octopus版本中，使用记录池时可能出现的问题。建议将最小分配大小设置为4k，但仍在考虑是否回退到16k或更大，以从性能角度考虑。 讨论的主要议题 分配器行为: 讨论了分配器在处理大IO请求时的行为，特别是是否应该返回连续的块或小的碎片。 最小分配大小: 讨论了在不同设备和使用场景下，最小分配大小的最佳设置，特别是在SSD和HDD上的不同需求。 性能与空间利用的权衡: 讨论了在性能和空间利用之间的权衡，特别是在处理小文件和大文件混合的场景下。 决定的事项 分配器调整: 决定进一步调查分配器的行为，特别是是否能够优化以返回更大的连续块。 最小分配大小设置: 对于Octopus版本，决定对于HDD，如果不能及时解决分配器问题，将回退到64k的最小分配大小。 后续行动计划 分配器测试: Igor将尝试调整分配器，看是否能改善大IO请求的处理。 性能测试: 重新运行性能测试，特别是关注大IO请求的性能变化。 RGW逻辑调整: 重新调整RGW过滤逻辑，并考虑是否需要重新进行测试。 空间放大问题研究: 继续研究blob空间放大问题，并考虑是否需要调整最小分配大小设置。 会议在讨论了多个技术细节和未来行动计划后结束，所有参与者将在下周继续跟进相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-27 :: Ceph Orchestration Meeting","slug":"2020-01-27_-_-_Ceph_Orchestration_Meeting","date":"2020-01-29T16:00:00.000Z","updated":"2020-01-29T16:00:00.000Z","comments":true,"path":"2020/01/30/2020-01-27_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/30/2020-01-27_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 参会人员 Josh（未参加） Petrus 其他相关人员 会议时间 会议开始时间：待定（等待Josh加入） 主要议题 Ceph Python客户端库的存储位置 讨论内容： Ostia提出将Ceph Python客户端库作为外部依赖，而不是合并到Rook项目中。 讨论了将库放在Rook组织下的单独仓库的利弊。 讨论了版本管理和CI的复杂性。 决定： 同意将Ceph Python客户端库作为一个独立的仓库，以增加灵活性并减少问题。 将创建一个新的仓库在Rook组织下，并由Sebastian负责管理。 Rook项目的其他更新 Ceph客户端库的发布方式： 讨论了使用pip安装和后续的RPM包创建。 Rook项目的其他进展： 讨论了EUR/USD重构、Raw模式支持、PVC模型扩展等技术细节。 CI和日志管理 CI改进： 讨论了使用GitHub Actions来同步两个仓库，确保客户端代码的更新与CRD的变更同步。 日志管理： 讨论了改进日志管理，以便更好地监控和调试部署过程中的问题。 后续行动计划 创建新的Ceph Python客户端库仓库。 继续改进CI流程，确保客户端代码的自动更新。 进一步讨论和实施日志管理的改进措施。 其他事项 确认Trello板上的任务已迁移到Tracker。 讨论了使用Podman来优化容器元数据的获取。 会议结束 会议在讨论了所有议题后结束，期待后续的进展和实施。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-16 :: Ceph Performance Meeting","slug":"2020-01-16_-_-_Ceph_Performance_Meeting","date":"2020-01-22T16:00:00.000Z","updated":"2020-01-23T16:00:00.000Z","comments":true,"path":"2020/01/23/2020-01-16_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/23/2020-01-16_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间 日期：具体日期未提供 时长：约1小时 参会人员 主要参与者：Josh, Stage, Alex, 以及其他未提及的核心成员 主要议题 Ceph Balancer相关PR讨论 并行crush计算的PR需要审查。 另一个关于upmap模式使用MS基础设施的balancer PR已经关闭。 性能改进相关的balancer PR，特别是与manager相关的性能问题。 硬件推荐文档更新 当前文档质量不佳，需要更新。 透明大页（transparent huge pages）的设置需要根据版本进行调整。 PG（Placement Group）相关讨论 默认的PG数量需要调整，建议增加到11。 PG log长度的调整和PG数量的关系需要进一步测试。 Autoscaler测试结果 Alex分享了在OpenShift中使用Steph的测试结果，发现数据分布不均的问题。 通过调整目标比率和启用PG balancer，数据分布得到了改善。 决定事项 不缩减PG数量，除非有压力 避免过早缩减PG数量，以保持数据分布的均匀性。 自动选择PG log长度 根据PG数量自动选择PG log长度，以优化内存使用。 增加默认PG数量 增加默认的PG数量，以改善初始数据分布和性能。 后续行动计划 审查并行crush计算的PR 确保相关PR得到及时审查和合并。 更新硬件推荐文档 根据最新版本和最佳实践更新文档。 进一步测试PG相关设置 继续测试PG数量和PG log长度的最佳配置，以优化性能和数据分布。 跟踪Autoscaler的进一步优化 根据测试结果和用户反馈，进一步优化Autoscaler的性能和功能。 其他讨论 讨论了PG balancer的性能影响和潜在的改进方向。 讨论了PG数量对恢复速度的影响，以及如何平衡性能和数据安全性。 下次会议 预计下周同一时间再次召开会议，讨论进一步的进展和问题。 会议结束 会议在约1小时后结束，参与者表示感谢并期待下次会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-20 :: Ceph Orchestration Meeting","slug":"2020-01-20_-_-_Ceph_Orchestration_Meeting","date":"2020-01-22T16:00:00.000Z","updated":"2020-01-23T16:00:00.000Z","comments":true,"path":"2020/01/23/2020-01-20_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/23/2020-01-20_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 参会人员 会议参与者包括Farrakhan及其他相关人员。 主要议题 Orchestrator项目讨论 决定停用现有的trailer bots（ferry和trailer Borden的 orchestrated robot），转而支持Redman项目中的新Orchestrator。 新Orchestrator项目具有更多功能，如适当的过滤等。 培训进展分享 讨论了培训的进展，目前主要支持draining功能，未来可能扩展到其他功能。 技术问题讨论 讨论了关于dead list设置的问题，涉及到设备名称的使用和错误报告的改进。 讨论了SSH连接问题，特别是remoter库的使用和可能的替代方案。 SEF ATM安装和升级 讨论了SEF ATM的安装方式，包括使用pip安装和可能的替代方案。 讨论了SEF ATM在不同操作系统上的安装和维护问题。 决定事项 停用现有的trailer bots，转而支持新Orchestrator项目。 继续推进SEF ATM的pip安装方式，并考虑其在不同操作系统上的兼容性问题。 后续行动计划 继续改进Orchestrator项目，确保其功能和稳定性。 完善SEF ATM的安装和升级流程，特别是pip安装方式的优化。 继续解决技术问题，如SSH连接问题和错误报告的改进。 其他讨论 讨论了SEF ATM在不同操作系统上的安装和维护问题，特别是Debian系统的支持。 讨论了SEF ATM的版本控制和同步问题，确保用户能够获取正确的版本。 会议结束 会议在讨论完所有议题后结束，感谢所有参与者的贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-22 :: Ceph Science User Group Meeting","slug":"2020-01-22_-_-_Ceph_Science_User_Group_Meeting","date":"2020-01-22T16:00:00.000Z","updated":"2020-01-23T16:00:00.000Z","comments":true,"path":"2020/01/23/2020-01-22_-_-_Ceph_Science_User_Group_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/23/2020-01-22_-_-_Ceph_Science_User_Group_Meeting/","excerpt":"","text":"会议纪要 会议概述 本次会议是一个虚拟用户组会议，由Kevin主持，主要讨论了Ceph在科学计算和大型集群中的应用案例。会议参与者包括Liam Monahan、Tom Bennett等，讨论了Ceph的使用经验、问题和未来计划。 主要议题 Ceph集群的使用经验分享 Liam Monahan介绍了他们维护的一个拥有3.5 PB原始存储的Ceph集群，主要用于科学计算，特别是机器学习。 Tom Bennett分享了他们使用Ceph存储来自Meerkat望远镜的数据，目前有数亿个对象。 Ceph版本升级和问题讨论 讨论了从Luminous到Nautilus的升级过程，以及在升级到14.2.5和14.2.6版本时遇到的心跳问题和OMAP对象问题。 提到了Ceph集群在扩展时遇到的OSD映射创建延迟问题，以及如何通过调整参数来解决。 Ceph集群管理和优化 讨论了在多代硬件上运行Ceph集群的挑战，特别是从文件存储迁移到BlueStore时的问题。 分享了关于Ceph集群中PG（Placement Groups）的自动缩放和客户端扩展的经验。 未来计划和社区活动 讨论了即将到来的Ceph社区活动，如Ceph Day和Cephalocon，以及如何组织“Birds of a Feather”会议。 确定了下一次会议将在三月份举行，但可能会根据Cephalocon的时间进行调整。 决定事项 下一次会议计划在三月份举行，具体日期将根据社区成员的可用性进行调整。 将通过邮件列表和私人邮件通知所有参与者下一次会议的详细信息。 后续行动计划 继续监控和调整Ceph集群的性能，特别是在升级到新版本后。 探索和实施Ceph集群的优化策略，如PG自动缩放和客户端扩展。 组织和参与Ceph社区活动，如Ceph Day和Cephalocon，以促进知识共享和技术交流。 其他备注 会议中提到的Ceph相关工具和参数调整将在后续的邮件和文档中进一步详细说明。 鼓励社区成员在会议后继续通过邮件列表和私人邮件进行交流和讨论。 本次会议为Ceph用户提供了一个宝贵的交流平台，促进了经验分享和技术问题的解决，同时也加强了社区成员之间的联系。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-21 :: Ceph Testing Meeting","slug":"2020-01-21_-_-_Ceph_Testing_Meeting","date":"2020-01-22T16:00:00.000Z","updated":"2020-01-23T16:00:00.000Z","comments":true,"path":"2020/01/23/2020-01-21_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/23/2020-01-21_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 关键细节 Ceph版本迁移: 会议讨论了从CentOS 7迁移到CentOS 8的测试环境，以及相关的失败问题。 Luminous版本: 讨论了Luminous版本的测试和发布，强调了尽快完成该版本的必要性。 安全更新: 提到了即将发布的Nautilus版本的安全更新，包括两个CVE（Common Vulnerabilities and Exposures）。 Jenkins流程改进: 讨论了Jenkins发布流程的改进，特别是关于如何处理分支和发布的问题。 openSUSE支持: 讨论了在Sepia中支持openSUSE 15.1的进展，包括内核任务的更新和测试。 讨论的主要议题 版本迁移和测试: 讨论了从CentOS 7到CentOS 8的迁移对测试的影响，以及如何处理相关的失败问题。 Luminous版本的维护: 讨论了Luminous版本的维护状态和未来，包括是否继续支持该版本。 安全更新和热修复: 讨论了即将发布的安全更新和热修复流程，以及如何处理相关的CVE。 Jenkins发布流程: 讨论了Jenkins发布流程的改进，特别是如何处理分支和发布的问题。 openSUSE支持: 讨论了在Sepia中支持openSUSE 15.1的进展，包括内核任务的更新和测试。 决定的事项 Luminous版本的处理: 决定尽快完成Luminous版本的测试和发布。 安全更新和热修复: 决定按照当前流程处理即将发布的安全更新和热修复。 Jenkins流程改进: 决定继续讨论和改进Jenkins发布流程。 openSUSE支持: 决定继续推进在Sepia中支持openSUSE 15.1的工作。 后续的行动计划 完成Luminous版本的测试和发布: 尽快完成Luminous版本的测试和发布。 处理安全更新和热修复: 按照当前流程处理即将发布的安全更新和热修复。 改进Jenkins发布流程: 继续讨论和改进Jenkins发布流程。 推进openSUSE支持: 继续推进在Sepia中支持openSUSE 15.1的工作，包括内核任务的更新和测试。 参与人员 Nathan 其他未具名参与者 备注 会议中提到了多个技术细节和具体问题，需要相关人员继续跟进和处理。 对于Jenkins流程的改进，需要更多的讨论和实验来确定最佳方案。 对于openSUSE的支持，需要继续推进相关的工作，确保测试和发布的顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-22:: Ceph DocUBetter Meeting","slug":"2020-01-22_-_-_Ceph_DocUBetter_Meeting","date":"2020-01-22T16:00:00.000Z","updated":"2020-01-23T16:00:00.000Z","comments":true,"path":"2020/01/23/2020-01-22_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/23/2020-01-22_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 关键细节 会议主题: Ceph文档更新与讨论 参会人员: Sebastian, Josh, David, Zack, Brad, Neha, Lucas (远程) 会议时间: 预计不超过3小时 讨论的主要议题 Ceph入门指南更新: Sebastian提出不直接拉取默认包，而是通过包管理器安装软件的偏好。 Josh与Sebastian就此事进行了讨论，双方对最佳实践有不同看法。 Placement Group (PG) 修复文档: 讨论了PG不一致性的具体问题，特别是当PG标记为不一致时，实际上是指其中的对象不一致。 讨论了“stat mismatch”问题，即当前统计数据与预期不一致的情况。 决定在文档中增加关于如何处理PG不一致性的详细步骤，特别是当没有具体对象错误时的情况。 开发者指南: 讨论了开发者指南的存在和其内容，以及如何使其更易于发现和导航。 决定将已关闭的旧bug状态更新为“已解决”，并链接到开发者指南。 文档请求热线: 提出建立一个文档请求热线，以便用户可以快速联系并获得文档相关的帮助。 讨论了如何自动分配文档相关的bug给负责人员。 决定的事项 更新Ceph入门指南，以反映最佳实践的讨论结果。 完善PG修复文档，特别是关于PG不一致性和“stat mismatch”问题的详细说明。 改进开发者指南的可发现性和导航性。 探索建立文档请求热线的可能性，并研究如何自动分配文档相关的bug。 后续的行动计划 Zack将在接下来的几个小时内完成PG修复文档的更新，并在明天提供给David审查。 继续改进开发者指南，并确保其内容是最新的。 研究并实施文档请求热线的具体方案。 讨论并实施自动分配文档相关bug的机制。 其他事项 讨论了Lucas的案例，他成功地通过快速响应解决了文档相关的问题，并希望未来能提供类似的服务。 会议结束时，讨论了如何提高文档相关问题的响应速度和效率。 结论 会议主要集中在Ceph文档的更新和改进上，特别是关于PG修复和开发者指南的内容。通过这次会议，团队明确了未来的行动方向，并致力于提高文档的质量和可用性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-10-21 :: Crimson SeaStor OSD Weekly Meeting","slug":"2020-10-21_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-01-22T16:00:00.000Z","updated":"2020-01-23T16:00:00.000Z","comments":true,"path":"2020/01/23/2020-10-21_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/23/2020-10-21_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 关键细节 会议日期: [具体日期] 参会人员: [参会人员名单] 会议主持: [主持人] 讨论的主要议题 Ceph相关开发工作 审查了Horns Part-2编辑器，PR已准备好合并。 正在审查Retakes变更，以支持Crimson。 阅读了RFS源代码和相关文档，如PTR论文。 正在进行Crimson的内存设计，包括Petrie支持。 项目进展与问题 讨论了ScyllaDB的Slack注册问题，计划联系并获取意见。 讨论了性能问题，特别是原生与塑料堆栈的行为差异。 讨论了Crimson的恢复机制，包括日志处理、基于日志的恢复和回填。 代码与文档更新 更新了Ceph的Admin Socket实现，请求审查。 讨论了Systole中的bug，建议更新Sister版本。 讨论了编译器内部错误问题，建议检查内存和编译任务限制。 后续行动计划 继续推进Crimson的恢复机制实现。 更新Sister版本以解决已知问题。 确定代码格式规则，简化开发流程。 决定的事项 确定继续推进Crimson的恢复机制实现，包括日志处理和回填。 决定更新Sister版本以解决已知问题。 确定代码格式规则，简化开发流程。 后续的行动计划 继续推进Crimson的恢复机制实现。 更新Sister版本以解决已知问题。 确定代码格式规则，简化开发流程。 其他事项 下周将是中国春节，部分成员将无法参加下一次会议。 讨论了代码格式问题，建议使用自动格式化工具简化开发流程。 会议结束 会议于[具体时间]结束，下一次会议定于[具体日期]。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-14 :: Crimson SeaStor OSD Weekly Meeting","slug":"2020-01-14_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-01-15T16:00:00.000Z","updated":"2020-01-15T16:00:00.000Z","comments":true,"path":"2020/01/16/2020-01-14_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/16/2020-01-14_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 主要议题 Ceph存储系统的B+树异步版本开发 Sammy正在基于最新的episode版本重构B+树的实现，并尝试开发异步版本。 讨论了B+树与DoStore集成的问题，特别是关于键值布局、指针和地址处理的细节。 B+树的物理和逻辑地址处理 需要至少两个版本的B+树实现：一个物理地址处理，一个逻辑地址处理。 讨论了B+树的灵活性和适应性问题，以及如何处理不同版本的B+树实现。 Ceph存储系统的设计和实现 讨论了从零开始实现B+树的可行性，以及如何基于现有设计进行定制化开发。 强调了避免I/O操作，确保实现纯粹基于内存或功能性的设计。 事务处理和写放大问题 讨论了如何在同一事务中处理B+树更新和其他操作，以及如何减少写放大问题。 强调了事务处理的复杂性和对整体系统设计的影响。 决定事项 B+树的实现策略 决定从零开始实现B+树，但会参考现有的Petri设计，并进行高度定制化。 确定了不使用外部库，而是自行开发B+树实现，以更好地适应Ceph的特定需求。 事务处理和写放大问题的解决方案 确定了在事务处理中集成B+树更新的策略，以及如何通过优化设计和缓存管理减少写放大问题。 讨论了持久内存的使用，以及如何通过逻辑地址管理进一步优化写放大问题。 后续行动计划 B+树的开发和测试 Sammy将继续开发B+树的实现，并定期更新团队进展。 团队成员将参与代码审查和测试，确保实现符合预期。 事务处理和写放大问题的进一步研究 将继续研究和优化事务处理机制，确保系统在高负载下的稳定性和性能。 将探索持久内存的使用，以及如何通过逻辑地址管理进一步优化写放大问题。 团队协作和任务分配 团队将根据项目进展和需求，适时分配任务和资源，确保项目按计划推进。 将持续关注Ceph存储系统的性能和稳定性，及时调整开发策略和方向。 通过本次会议，团队对Ceph存储系统的B+树实现和事务处理机制有了更深入的理解，并制定了明确的开发和优化计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-13 :: Ceph Orchestration Meeting","slug":"2020-01-13_-_-_Ceph_Orchestration_Meeting","date":"2020-01-12T16:00:00.000Z","updated":"2020-01-13T16:00:00.000Z","comments":true,"path":"2020/01/13/2020-01-13_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/13/2020-01-13_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题：Ceph Orchestrator 会议 日期：[具体日期] 参会人员：[具体人员名单] 主要议题： OSD 移除与替换 讨论了关于移除和替换 OSD 的流程和责任分配。 提出了一个新的管理模块，用于处理 OSD 的排空（draining）操作，该模块可以被 Rook 和 Self ADM 直接消费，也可能被仪表盘独立使用。 讨论了排空 OSD 的具体步骤，包括设置权重为零、等待 OSD 为空等。 提出了一个新的安全命令（safe command）来管理排空功能，并可能提供 API 供仪表盘或其他组件使用。 依赖问题与改进 讨论了 Promoter 依赖的 exact-net 库不再活跃开发的问题，以及可能的替代方案。 提出了改进 Safe ADM 的可执行文件结构，避免单一文件的复杂性，并提出了使用 pip 安装的建议。 日常运营与更新 讨论了取消每日 Orchestrator 站立会议，改为每周会议。 更新了关于 Rook 支持分区（partitions）和改进 OSD 发现机制的工作进展。 决定事项： 将开发一个新的管理模块来处理 OSD 排空操作，以简化流程并提高效率。 考虑替换 exact-net 库，以解决其不再活跃开发带来的问题。 改进 Safe ADM 的文件结构，使其更易于维护和管理。 取消每日 Orchestrator 站立会议，改为每周会议。 后续行动计划： 开发新的管理模块，并确保其可以被 Rook 和 Self ADM 直接消费。 评估并替换 exact-net 库，以提高 Safe ADM 的稳定性和用户体验。 审查并合并关于改进 Safe ADM 文件结构的 Pull Request。 实施新的会议安排，取消每日站立会议，改为每周会议。 备注： 会议中提到的具体技术细节和代码实现需要进一步的技术讨论和开发工作。 所有决定和行动计划需要团队成员的协作和持续跟进。 下次会议： 日期：[具体日期] 时间：[具体时间] 地点：[具体地点或在线会议链接] 会议结束","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-07 :: Crimson SeaStor OSD Weekly Meeting","slug":"2020-01-07_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-01-10T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/11/2020-01-07_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/11/2020-01-07_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph分布式存储系统的多个开发和优化议题，包括代码适配、性能优化、错误修复以及新功能的探索。会议中，各研发人员分享了他们的工作进展、遇到的问题以及后续的行动计划。 主要议题 代码适配与优化 一位研发人员正在调整Petri免疫算法，以适应Ceph的需求，并移除了对Alice ale的依赖。 另一位研发人员正在改进CBT（Ceph Block Device），并与slob（Simple List of Blocks）合作，以支持度量指标。 性能与稳定性改进 讨论了如何利用slot和locator设计来优化内部节点的分割过程。 针对Ceph的锁定机制进行了讨论，特别是如何在不破坏兼容性的前提下改进锁定顺序和超时管理。 编译与兼容性问题 发现并修复了导致ARM编译失败的代码变更，强调了保持向后兼容性的重要性。 讨论了使用clunk格式和crank格式化工具来统一代码风格的可能性。 新功能探索 探讨了使用Chelsea和Archery来表示OSD（Object Storage Daemon）结构的设计思路，特别是如何简化存储结构和I/O处理机制。 讨论了利用混合逻辑时钟（HLC）来实现轻量级快照的可能性。 网络与内存优化 分析了DBT KQP巨大页面后台未启用导致的额外内存复制问题，并探讨了如何通过配置来实现真正的零拷贝。 讨论了TCP/IP堆栈中套接字放置的问题，特别是如何在多核环境中优化套接字的分配。 决定事项 将继续优化Ceph的锁定机制，确保在不破坏兼容性的前提下提高性能。 将探索使用clunk格式和crank格式化工具来统一代码风格，以提高代码质量和开发效率。 将深入研究使用Chelsea和Archery来优化OSD结构，特别是如何实现轻量级快照和简化I/O处理。 后续行动计划 各研发人员将继续他们的工作，并在下一次会议前提交更新的代码和文档。 将安排进一步的讨论，以解决网络和内存优化中的具体问题。 将评估和测试新的设计思路，确保它们能够有效地集成到Ceph系统中。 其他 会议中还提到了一些具体的错误修复和代码审查请求，强调了持续集成和测试的重要性。 鼓励团队成员在遇到问题时及时沟通，并利用邮件列表和文档共享来提高协作效率。 本次会议为Ceph项目的持续改进和发展奠定了基础，确保了团队在面对技术挑战时能够保持高效和协作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-08 :: Ceph Orchestration Meeting","slug":"2020-01-08_-_-_Ceph_Orchestration_Meeting","date":"2020-01-10T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/11/2020-01-08_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/11/2020-01-08_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 参会人员：[参会人员名单] 主要议题： Self-ADM 功能进展 Sage 在添加 self-adm 到 totality 方面取得了进展。 Paul Kastner 在为 self-edm 进行监控方面做了大量工作，效果显著。 OSD 移除流程简化 讨论了是否应该简化 OSD 的移除流程，Sage 的观点是保持 self-adm 代码简单，并由其他组件如 dashboard 来实现移除功能。 目前 Rook 中移除 OSD 的步骤较为繁琐，有七个步骤，但考虑到实际操作的复杂性，简化空间有限。 OSD 替换流程 讨论了 OSD 替换的复杂性，包括磁盘替换前后的处理步骤。 提出了两阶段操作的建议：首先标记 OSD 为销毁状态，然后在 Ceph 中重新创建 OSD。 Python 客户端代码生成 讨论了 Python 客户端代码生成的问题，特别是验证设置的手动更新。 Sebastian 表示需要找到时间来处理这个问题。 Rook 安全审查 讨论了 Rook 的安全审查结果，主要问题是敏感信息的日志记录，已有一个 PR 在处理。 决定事项： 需要进一步讨论 OSD 移除和替换流程的简化方案。 Python 客户端代码生成问题需要尽快解决。 Rook 的安全问题需要持续关注和改进。 后续行动计划： 下周与 Sage 讨论 OSD 移除和替换流程的具体实现方案。 Sebastian 将尽快处理 Python 客户端代码生成问题。 继续跟进 Rook 的安全审查问题，并实施必要的改进措施。 其他事项： Rook 1.2 版本已发布，计划今天进行第一次补丁发布。 需要确保端口设置在 1 到 65000 范围内，以加强 CRD 验证。 会议结束： 会议在讨论完所有议题后结束，下次会议将在下周进行。 备注： 会议中提到的具体技术细节和代码实现需要进一步的技术文档和讨论支持。 会议记录人：[记录人姓名] 会议日期：[具体日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2020-01-08:: Ceph DocUBetter Meeting","slug":"2020-01-08_-_-_Ceph_DocUBetter_Meeting","date":"2020-01-10T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/11/2020-01-08_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/11/2020-01-08_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 会议时间 新年伊始，具体日期未提及。 参会人员 会议主持人未明确提及，但提到了Brad和David。 其他参会人员包括Patrick、John Wilkins、Kafer等，具体角色未详细说明。 主要议题 Ceph文档更新 完成了Ceph入门指南的PR（Pull Request），感到松了一口气。 讨论了使用Rados命令存储和检索文件的计划，以及与Brad合作编写Rados速查表的计划。 提到了12月11日的会议记录被意外翻译成中文的问题，正在调查原因。 文档管理和更新 讨论了文档版本管理的问题，特别是旧文档的处理，建议从最近的两个版本开始处理。 提到了CloudStack文档的更新问题，建议只关注近期的更新。 文档审查流程 讨论了文档PR的审查流程，建议关注标记为“review required”的PR，并根据需要请求其他人的审查。 提到了一些技术性较强的文档，建议由专业人员进行审查。 个人健康状况 提到了即将进行的医院检查，可能涉及紧急手术，但预计不会影响工作。 决定事项 将继续处理Ceph文档的更新和审查工作。 将开始清理旧的文档PR，重点关注近两年的更新。 将根据需要请求专业人员的文档审查。 后续行动计划 继续与Brad合作编写Rados速查表。 清理和更新旧的文档PR，重点关注近两年的更新。 根据需要请求专业人员的文档审查。 如果医院检查结果需要紧急手术，将及时通知团队。 其他事项 讨论了不同国家对某些日常物品的不同称呼，如厨房台面在澳大利亚称为“bench”。 提到了澳大利亚的森林火灾情况，以及对当地居民的影响。 会议结束 会议在讨论完所有议题后结束，主持人感谢大家的参与，并祝愿医院检查顺利。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-16 :: Ceph Orchestration Meeting","slug":"2019-12-16_-_-_Ceph_Orchestration_Meeting","date":"2020-01-09T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/10/2019-12-16_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/10/2019-12-16_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间与参与人员 时间： 会议开始于预定时间，但有几分钟延迟。 参与人员： 会议由主持人主持，Brooke等团队成员参与。 主要议题与讨论内容 Ceph 1.2 版本发布计划 Brooke 计划在未来几天内完成1.2版本的发布，目前正在进行最后的修复工作。 讨论了关于自动删除OSD的代码变更，决定不再自动删除OSD，以避免数据丢失，改为用户手动操作。 设计文档与未来规划 讨论了OSD移除的设计文档，目前正在等待进一步的反馈和时间来重新审视。 提及了多站点RGW的设计进展，由Radia负责，可能对未来的对象存储CR有影响。 Ceph Orchestrator 与 Dashboard 集成 讨论了将新的CR添加到对象存储CR中，以支持跨集群配置。 计划在本周内由Elly开放设计PR，以便团队成员可以更积极地参与讨论和反馈。 Ceph Manager 模块的测试与集成 讨论了Ceph Manager模块的测试问题，目前缺乏有效的QA和CI集成。 提出了在Rook CI中集成Ceph Manager模块的建议，以便进行更有效的测试。 其他技术细节与问题 讨论了Ceph Orchestrator的并行化问题，以及如何在多节点环境中进行有效的部署和管理。 提及了Ganesha的集成问题，计划在未来进行更深入的探讨和实施。 决定事项 不再自动删除OSD，改为用户手动操作。 计划在本周内由Elly开放设计PR，以便团队成员可以更积极地参与讨论和反馈。 提出了在Rook CI中集成Ceph Manager模块的建议，以便进行更有效的测试。 后续行动计划 完成Ceph 1.2版本的发布工作。 Elly将在本周内开放设计PR。 进一步探讨和实施Ceph Manager模块的测试和集成方案。 对Ganesha的集成问题进行更深入的探讨和实施。 其他备注 会议中还讨论了一些技术细节和问题，但未形成具体的决定或行动计划。 会议结束时，主持人感谢大家的参与，并宣布会议结束。 会议结束 时间： 会议在讨论完所有议题后结束。 参与人员： 所有参与人员确认会议结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-24 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-12-24_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-01-09T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/10/2019-12-24_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/10/2019-12-24_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 主要议题与讨论内容 Ceph存储树实现 讨论了Ceph存储树的实现，特别是容量实现部分。 现有实现位于/included/c/CPPp3，状态良好，但需要进一步分离和优化。 计划将mutator接口与现有的Ceph机械结合，以支持内部节点的突变和分裂操作。 现代化的Ceph实现 探讨了使用Supra Prabhas 17技术对现有Ceph实现进行现代化的可能性。 讨论了是否存在已经现代化的资源，以及如何处理现有实现的局限性。 Crimson子树的扩展支持 讨论了为Crimson子树引入新的支持，这是一个较大的扩展。 涉及如何统一不同命令的处理，特别是在OSD级别。 命令接口的统一与优化 讨论了统一和优化命令接口的必要性，特别是在处理大型数据集时。 提出了逐步实施的计划，以确保与现有系统的兼容性。 OSD终止问题 讨论了在尝试终止OSD时遇到的问题，特别是在使用SIGINT时。 提出了一种可能的解决方案，并正在进行测试以确保其有效性。 快照支持与数据复制 讨论了在OSD级别支持快照的必要性，以及如何通过快照实现更高效的数据复制。 探讨了在Ceph中实现更高效快照创建和管理的潜在方法。 SSD优化与硬件控制 讨论了针对不同类型SSD（如FDR SSD）的优化策略，以及如何通过低级原语更好地利用硬件。 探讨了硬件级别并行化的可能性，以及如何通过不同段来增强并行性。 ACN问题与单元测试 讨论了ACN相关的问题，特别是在停止Caster时可能出现的错误。 提出了进行更多实验以重现和解决这些问题的计划。 决定事项 将继续优化Ceph存储树的实现，特别是容量部分。 将探索使用Supra Prabhas 17技术对Ceph进行现代化的可能性。 将逐步实施命令接口的统一和优化，以提高系统的整体性能。 将测试并实施OSD终止问题的解决方案。 将研究在OSD级别支持快照的方法，并探索更高效的数据复制机制。 将进行更多实验以优化SSD的使用，并探索硬件级别的并行化。 后续行动计划 继续进行Ceph存储树的开发和优化工作。 探索和实施Ceph的现代化方案。 逐步统一和优化命令接口，确保与现有系统的兼容性。 测试并部署OSD终止问题的解决方案。 研究并实施更高效的快照支持机制。 进行更多实验以优化SSD的使用，并探索硬件级别的并行化。 其他事项 会议参与者将在接下来的几周内继续跟进各自的工作，并在下一次会议中报告进展。 会议结束 下次会议时间：待定 会议纪要编写人：[您的姓名] 会议纪要审核人：[审核人姓名] 会议纪要发布日期：[填写日期]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-19 :: Ceph Performance Meeting","slug":"2019-12-19_-_-_Ceph_Performance_Meeting","date":"2020-01-09T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/10/2019-12-19_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/10/2019-12-19_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 主要议题与讨论内容 新PR介绍 来自Xixing（Shai Shin Guo 或 Guo）的PR，主要涉及管理器中的并行计算优化和平衡器改进，旨在消除upmap模式下对ms基础设施的使用。 讨论了两个被stale bot关闭的PR： 避免双重缓存的PR，等待Adam的数据库分片PR合并后再进行重写。 增加messenger IOPS的PR，由Roman在SUSE编写，Greg曾审阅但未有进展，建议作者重新开启或提交新PR。 硬件推荐文档更新 一个关于硬件推荐的PR，更新了文档内容，但尚未获得批准。 RGW桶分片默认数量调整 讨论了增加RGW桶分片默认数量的PR，进行了一些测试，但发现性能反而下降，需要进一步分析原因。 Purple测试适配ARM架构 一个旧PR，关于将Purple测试适配到ARM架构，最近由Kifu审阅并更新。 避免OSD和RGW之间的解码-重新编码步骤 讨论了避免OSD和RGW之间解码-重新编码步骤的PR，提出了在CLS侧添加模板的可能解决方案。 PG日志性能优化 继续进行PG日志的测试，发现性能提升在达到一定上限后转为降低CPU使用率，考虑采用新的存储机制如循环缓冲区。 决定事项 等待Adam的数据库分片PR合并后再重写避免双重缓存的PR。 建议增加messenger IOPS的PR作者重新开启或提交新PR。 硬件推荐文档更新的PR需要获得批准。 增加RGW桶分片默认数量的PR需要进一步测试和分析性能问题。 避免OSD和RGW之间解码-重新编码步骤的PR需要进一步讨论和实现。 PG日志性能优化需要探索新的存储机制。 后续行动计划 重写避免双重缓存的PR。 重新开启或提交增加messenger IOPS的PR。 获取硬件推荐文档更新的PR批准。 进一步测试和分析增加RGW桶分片默认数量的PR。 实现避免OSD和RGW之间解码-重新编码步骤的PR。 探索PG日志的新存储机制。 其他事项 会议结束时，提醒与会者享受假期，并将在一月份重新开会。 会议结束 会议在简短的讨论后结束，祝大家节日快乐。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-17 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-12-17_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2020-01-09T16:00:00.000Z","updated":"2020-01-10T16:00:00.000Z","comments":true,"path":"2020/01/10/2019-12-17_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2020/01/10/2019-12-17_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 关键细节 会议日期: [具体日期] 参会人员: [列出主要参会人员] 会议时长: [会议持续时间] 讨论的主要议题 Ceph BlueStore性能问题: 问题描述: 在特定工作负载下，特别是当工作负载为单个任务且块大小较大时，Crimson OSD的性能不如Classic OSD。 原因分析: 发现与Ceph的分配器（allocator）有关，特别是在使用C-star分配器时，无法分配特定页码（如81、92），导致错误。 解决方案: 建议使用默认分配器来构建版本，并考虑增加页码限制或调整分配策略。 提交策略改进: 建议: 提交代码时，应详细说明变更策略和具体改动，而不仅仅是单一标题，以便于评审人员理解。 行动: 将在提交中添加更多注释和详细说明。 性能回归问题: 讨论: 当块大小大于4K时，性能下降被认为是预期的，需要通过改进策略来解决。 后续行动: 需要进一步研究并决定是否采用DPDK或POSIX堆栈作为首选驱动程序。 其他议题: F2FS文件系统: 讨论了F2FS中的段和区域的概念，以及是否需要在Ceph中引入类似的层次结构。 会议安排: 由于即将到来的假期，决定取消接下来两周的会议。 决定的事项 性能问题: 确认了性能下降的原因，并决定使用默认分配器来解决当前问题。 提交策略: 同意改进提交信息，增加详细说明以帮助评审。 驱动程序选择: 暂定使用POSIX堆栈，但需要进一步测试和调整以优化性能。 后续行动计划 性能优化: 继续研究和测试不同的分配器和堆栈选项，以找到最佳性能配置。 代码提交: 改进提交信息的详细程度，确保包含足够的上下文和策略说明。 假期安排: 确认了假期期间的会议取消，并计划在假期后恢复会议。 其他备注 假期通知: 部分团队成员将在接下来的两周内休假，会议将暂停。 技术讨论: 对于F2FS的段和区域概念进行了初步讨论，但未做出最终决定。 结束语 感谢所有参会人员的积极参与和贡献，期待在假期后继续推进项目进展。祝大家假期愉快！","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-11:: Ceph DocUBetter Meeting","slug":"2019-12-11_-_-_Ceph_DocUBetter_Meeting","date":"2019-12-11T16:00:00.000Z","updated":"2019-12-11T16:00:00.000Z","comments":true,"path":"2019/12/12/2019-12-11_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/12/2019-12-11_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 参会人员 Sage Zack Brad Marc Patrick David Florian JT Layton Brett 会议时间 凌晨3:30 会议议题 硬件推荐 Marc创建的硬件推荐文档需要审查。 讨论了是否应该在文档中明确提及测试的操作系统。 模板更新 Brad修改了模板，试图恢复到原始的自然模板。 讨论了颜色和样式的调整。 Bug更新 Zack对etherpad中的bug进行了编号和修复。 讨论了bug的进度和需要进一步审查的bug。 硬件推荐PR 讨论了两个PR和一个关于硬件推荐的minor PR。 决定在Marc的PR中整合所有想法。 Landing Page和Getting Started Guide 计划在今年年底前完成Landing Page和Getting Started Guide的更新。 讨论了需要添加的图片和结构调整。 PG Repair Page 讨论了PG Repair Page的内容和需要与David沟通的事项。 Python 3迁移 讨论了从Python 2迁移到Python 3的计划和潜在影响。 旧业务回顾 讨论了之前的硬件推荐和操作系统测试的明确提及。 讨论了文档bug的报告机制和简化流程。 网络和Placement Groups问题 讨论了网络架构和Placement Groups的问题，计划安排会议进行深入讨论。 文档更新和命名规范 讨论了文档更新和命名规范的更改，计划进行大规模的grep和replace操作。 文档bug报告机制 讨论了简化文档bug报告机制，建议使用email list或etherpad。 决定事项 硬件推荐文档需要审查和整合。 Landing Page和Getting Started Guide的更新计划在今年年底前完成。 简化文档bug报告机制，建议使用email list或etherpad。 安排会议讨论网络架构和Placement Groups问题。 后续行动计划 Marc负责整合硬件推荐文档。 Zack负责更新Landing Page和Getting Started Guide。 安排会议讨论网络架构和Placement Groups问题。 简化文档bug报告机制，建议使用email list或etherpad。 其他备注 会议中提到了网络连接问题和视频质量问题。 讨论了Python 3迁移的潜在影响和需要进行的更改。 讨论了文档更新和命名规范的更改。 会议结束 会议在讨论了所有议题后结束，计划在下周安排进一步的会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-10 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-12-10_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-12-11T16:00:00.000Z","updated":"2019-12-11T16:00:00.000Z","comments":true,"path":"2019/12/12/2019-12-10_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/12/2019-12-10_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 参会人员 主持人: [未提及] 记录人: [未提及] 参会人员: [未提及] 会议时间 日期: [未提及] 时间: [未提及] 会议地点 线上会议 会议议题 Ceph Crimson存储支持的PR审查 Ceph BlueStore设计文档的讨论 Ceph相关代码的更新和问题解决 会议内容 1. Ceph Crimson存储支持的PR审查 Brunei的PR: 正在审查以支持Stock到Crimson的迁移。 代码审查建议: 建议在PR中包含详细的修改信息和策略，以帮助理解和审查。 2. Ceph BlueStore设计文档的讨论 新设计文档: Sam的新设计文档被提及，建议在会议中花费半小时进行详细介绍。 设计理念: 设计理念类似于ButterFS，特别是在日志结构文件系统方面。 物理布局: 讨论了磁盘上的物理布局，包括数据块和元数据块的区分。 流的数量: 讨论了流的数量的调整参数，以及如何在不同类型的存储设备上进行优化。 3. Ceph相关代码的更新和问题解决 Ceph BlueStore的调试: 正在进行Ceph BlueStore的调试阶段，接近完成CPU周期操作的展示。 代码替换和错误修复: 讨论了代码替换和使用Self-Evaluator时遇到的比较错误，以及如何解决这些问题。 Ceph BlueStore的性能优化: 讨论了如何进一步优化Ceph BlueStore，包括内存使用和日志记录的优化。 决定事项 设计文档的进一步讨论: 决定在下次会议中详细讨论Sam的新设计文档。 代码审查和更新: 继续进行代码审查和更新，确保Ceph Crimson和BlueStore的稳定性和性能。 后续行动计划 完成PR审查: 完成对Brunei的PR的审查，并确保包含详细的修改信息。 设计文档的更新: Sam将更新设计文档，并在下次会议中进行详细介绍。 代码调试和优化: 继续进行Ceph BlueStore的调试和优化工作，解决已知问题并提升性能。 其他事项 会议记录: 确保会议记录的准确性和完整性，以便后续参考。 文档链接: 提供相关文档和论文的链接，以便团队成员进一步研究和讨论。 会议结束 下次会议: 预定于下周进行，具体时间和议题待定。 会议总结 本次会议主要围绕Ceph Crimson和BlueStore的开发和优化进行了深入讨论，包括代码审查、设计文档的讨论以及具体问题的解决。团队成员将继续努力，确保Ceph项目的稳定性和性能提升。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-12 :: Ceph Performance Meeting","slug":"2019-12-12_-_-_Ceph_Performance_Meeting","date":"2019-12-11T16:00:00.000Z","updated":"2019-12-12T16:00:00.000Z","comments":true,"path":"2019/12/12/2019-12-12_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/12/2019-12-12_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 主要议题 文档更新：来自heat的PR更新了关于CPU和内存推荐的文档，调整了之前建议的1GB内存每TB硬盘空间的配置，使其更符合BlueStore的实际情况。 已关闭的PR： I/O Ewing支持：已合并。 BlueStore数据库空间智能使用框架：Igor的工作，改进了数据库空间的使用效率。 其他更新： VL APR：因测试中遇到bug，暂时关闭，计划未来重新提交。 OP Tracker PR：因争议性较大，被Dale bot关闭，建议重新设计接口。 Op Tracker默认禁用：决定不实施。 Finisher优化：更新后需要重新测试。 CLS桶列表过滤优化：减少了数据传输量，已进入测试阶段。 性能优化讨论 PG Log优化：通过移除PG Log的OMAP写入和完全禁用PG Log，观察到性能和尾部延迟的显著改善。具体测试结果显示在EtherPad中。 内存目标调整：增加内存目标以减少映射条目读取，提高吞吐量。 BlueStore优化：讨论了BlueStore中PG Log和OMAP的优化策略，包括简化数据结构和直接写入对象数据的可能性。 后续行动计划 继续运行测试，包括在新的节点上进行测试，以及在RGW案例中验证优化效果。 调查并解决最近一个月内可能影响性能的合并问题。 进一步分析和优化PG Log代码，包括可能的微基准测试。 探索使用Crimson作为潜在的优化方案。 其他事项 会议决定下周继续讨论，之后将有一段时间的休息。 结论 会议强调了持续优化Ceph存储系统的必要性，特别是在性能和资源管理方面。团队将继续进行深入测试和分析，以实现更高效的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-09 :: Ceph Orchestration Meeting","slug":"2019-12-09_-_-_Ceph_Orchestration_Meeting","date":"2019-12-09T16:00:00.000Z","updated":"2019-12-09T16:00:00.000Z","comments":true,"path":"2019/12/10/2019-12-09_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/10/2019-12-09_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 关键细节 SSH Orchestrator监控功能：Paul已经开始在SSH Orchestrator中创建监控功能，会议参与者对此表示赞赏，并计划进行审查。 多驱动组命名：会议讨论了支持多个驱动组的情况，并建议为每个驱动组命名，以便更好地理解和描述其用途。 LVM问题：Sebastian提到LVM（逻辑卷管理）与EVS（企业卷服务）不兼容的问题，建议考虑不使用LVM。 系统单元和容器化：讨论了系统单元（system D unit）和容器化的问题，特别是关于如何处理容器关闭时的清理工作。 Python 3迁移：计划在接下来的一周内进行Python 3的迁移，以支持await语法。 OMAP转换问题：在从旧版本升级到Octopus版本时，发现了OMAP使用统计信息的不同消息，讨论了如何处理这一问题。 主要议题 SSH Orchestrator的监控和命名规范：如何有效地监控SSH Orchestrator，并为多个驱动组提供命名规范。 LVM与EVS的兼容性问题：讨论了LVM与EVS之间的兼容性问题，并探讨了可能的解决方案。 系统单元和容器化的清理工作：如何确保在容器关闭时进行适当的清理工作，避免遗留问题。 Python 3迁移和OMAP转换：计划进行Python 3的迁移，并处理OMAP转换过程中出现的问题。 决定事项 驱动组命名：决定为每个驱动组命名，以便更好地理解和描述其用途。 LVM的使用：考虑不使用LVM，以避免与EVS的兼容性问题。 系统单元和容器化的清理工作：决定需要一个包装器（wrapper）来处理容器关闭时的清理工作。 Python 3迁移：计划在接下来的一周内进行Python 3的迁移。 OMAP转换问题：决定不自动转换OMAP，而是通过文档告知用户，并可能在未来进行自动化处理。 后续行动计划 审查SSH Orchestrator监控功能：对Paul创建的监控功能进行审查。 处理LVM问题：进一步讨论和决定如何处理LVM与EVS的兼容性问题。 系统单元和容器化的清理工作：开发一个包装器来处理容器关闭时的清理工作。 Python 3迁移：进行Python 3的迁移，并确保相关代码的兼容性。 OMAP转换问题：更新文档，告知用户OMAP转换的问题，并考虑未来的自动化解决方案。 结论 会议讨论了多个与SSH Orchestrator、LVM、系统单元和容器化、Python 3迁移以及OMAP转换相关的重要议题，并做出了相应的决定和后续行动计划。所有参与者将继续推进这些任务，以确保项目的顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-04 :: Ceph Developer Monthly","slug":"2019-12-04_-_-_Ceph_Developer_Monthly","date":"2019-12-04T16:00:00.000Z","updated":"2019-12-05T16:00:00.000Z","comments":true,"path":"2019/12/05/2019-12-04_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/05/2019-12-04_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议概要 本次会议主要围绕Ceph的Orchestrator功能展开讨论，涉及其与NDS交付内容的交互方式、部署流程、监控系统集成等多个方面。 主要议题 Orchestrator功能介绍： Orchestrator在Ceph管理器中提供了一个通用的API和代码层，支持通过Rook或SSH实现守护进程的部署。 目标是简化集群安装流程，减少步骤，提供完整的集群安装体验，并支持磁盘更换、节点添加/移除等操作。 部署流程简化： 讨论了如何通过Orchestrator API标准化部署流程，减少对第三方工具的依赖，使部署和维护更加容易。 提出了使用容器化部署的优势，简化了包管理过程。 监控系统集成： 讨论了Prometheus和Grafana的部署和集成，以及如何通过Orchestrator管理这些监控组件。 探讨了如何在Ceph集群中集成外部监控系统，以及如何处理容器和物理主机之间的监控数据。 升级和维护： 讨论了集群升级的流程，包括如何检查和执行升级，以及如何处理升级过程中的暂停和恢复。 提出了通过Orchestrator API进行声明式管理的可能性，以简化操作和维护。 决定事项 确认了Orchestrator的核心功能和目标，包括简化部署流程和提供完整的集群管理功能。 确定了监控系统的基本集成方案，包括Prometheus和Grafana的部署和管理。 讨论了升级流程的实现细节，包括如何通过Orchestrator API进行管理和控制。 后续行动计划 继续完善Orchestrator的功能，特别是监控系统的集成和升级流程的实现。 探索通过Orchestrator API进行声明式管理的可能性，以进一步简化操作和维护。 考虑重命名当前的部署工具，以更好地反映其功能和用途。 其他讨论点 讨论了MDS（Metadata Server）的亲和性和可用性区域的配置。 探讨了如何在Ceph集群中集成外部监控系统，以及如何处理容器和物理主机之间的监控数据。 本次会议为Ceph的Orchestrator功能的发展和集成提供了明确的方向和行动计划，旨在进一步简化Ceph集群的部署和管理流程。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-05 :: Ceph Performance Meeting","slug":"2019-12-05_-_-_Ceph_Performance_Meeting","date":"2019-12-04T16:00:00.000Z","updated":"2019-12-05T16:00:00.000Z","comments":true,"path":"2019/12/05/2019-12-05_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/05/2019-12-05_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 时间: 本周 参与人员: 团队成员（Patrick, David, Akutan, Igor, Adam, Eric, Mark, Josh, Brett, Matt, Alex Calhoun等） 主要议题: 讨论和回顾本周的Pull Requests（PRs），以及关于持久内存（Persistent Memory）和平衡器（Balancer）的讨论。 讨论的主要议题 PRs回顾: Patrick的PR：在MDS中释放reheat页面，类似于OSD和Mons中的处理方式。 David的PR：平衡器修复，已合并。 MDS CPU亲和性PR：已合并。 自动标量默认PG计数增加：从8增加到16。 增强OSD Numa亲和性兼容性PR：已合并。 删除范围（Delete Range）PR：已合并。 O节点固定代码PR：已合并，但存在段错误问题，需进一步观察。 其他PRs：由于长时间未更新，被stale bot关闭。 持久内存（Persistent Memory）讨论: 讨论了持久内存的使用和潜在的性能提升。 讨论了如何利用持久内存API和库，以及如何处理内存分配和事务问题。 提出了使用持久内存来优化PG日志的存储和恢复过程。 平衡器（Balancer）和自动标量（Autoscaler）的协同工作: 讨论了平衡器和自动标量如何协同工作，特别是在集群容量变化时的处理策略。 讨论了如何避免两者在优化过程中相互干扰。 决定的事项 文档更新: Mark将提交一个PR，更新关于OSD内存目标的文档，建议不推荐将OSD内存目标设置低于默认值。 持久内存的进一步研究: 团队将组建一个工作组，进一步研究如何利用持久内存来优化Ceph的性能。 后续的行动计划 持久内存的实验: 获取带有持久内存的开发机器，进行实验和测试。 平衡器和自动标量的进一步测试: 进行更多测试，确保平衡器和自动标量在实际工作负载下的协同工作效果。 文档更新PR的审查: 团队成员将对Mark提交的文档更新PR进行审查。 其他讨论 持久内存的硬件选择和配置: 讨论了不同类型的持久内存硬件，以及如何在服务器中配置和使用它们。 平衡器和自动标量的实际应用: 讨论了在实际集群中如何配置和使用平衡器和自动标量，以优化性能和资源利用。 结论 会议涵盖了多个技术议题，特别是关于持久内存和平衡器的讨论，团队成员积极参与并提出了建设性的意见和建议。后续将通过实验和测试来验证这些想法，并进一步优化Ceph的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-03 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-12-03_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-12-04T16:00:00.000Z","updated":"2019-12-05T16:00:00.000Z","comments":true,"path":"2019/12/05/2019-12-03_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/05/2019-12-03_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 关键细节： 讨论主题：会议主要讨论了关于Ceph存储系统中的多个技术问题，包括代码优化、性能测试、内存管理以及新的设计方案。 参与者：会议涉及多位Ceph研发人员，包括但不限于Anders、Radek等。 主要议题： 代码优化： 讨论了使用单一锁（main lock）替代旧机制的可能性，以简化代码并减少对查找表效率的担忧。 提到了关于使用Clang编译器的问题，以及如何统一代码格式以提高开发效率。 性能测试： 强调了在发布模式下进行性能测试的重要性，因为调试模式下的结果可能不准确。 讨论了Ceph的Crimson版本与Classic版本在不同构建模式下的性能差异。 内存管理： 提到了在特定条件下可能出现的内存分配问题，建议通过邮件详细讨论解决方案。 新设计方案： 讨论了一个新的设计文档，涉及如何优化数据布局和垃圾收集策略，特别是在处理闪存系统时。 提到了使用类似于日志结构文件系统的方法来减少写放大问题。 决定事项： 性能测试：决定在发布模式下重新进行性能测试，以获得更准确的结果。 代码优化：同意使用单一锁机制，并考虑统一代码格式。 新设计方案：将继续研究和开发新的数据布局和垃圾收集策略。 后续行动计划： 性能测试：重新进行性能测试，并确保使用发布模式。 代码优化：实施单一锁机制，并探索统一代码格式的可能性。 新设计方案：继续研究和开发新的设计方案，并准备提交PR以供审查。 其他事项： 会议中还提到了关于Ceph的Crimson版本的一些具体技术细节和未来的工作计划。 强调了在开发过程中保持沟通和协作的重要性。 结论： 会议主要集中在Ceph存储系统的优化和性能提升上，涉及代码结构、性能测试方法和新的设计理念。通过这次会议，团队明确了下一步的工作重点和行动计划，以确保Ceph系统的稳定性和高效性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-12-03 :: Ceph Testing Meeting","slug":"2019-12-03_-_-_Ceph_Testing_Meeting","date":"2019-12-03T16:00:00.000Z","updated":"2019-12-04T16:00:00.000Z","comments":true,"path":"2019/12/04/2019-12-03_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/04/2019-12-03_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议概要 本次会议主要讨论了Ceph存储系统的多个分支（如Nautilus、Luminous等）的开发状态、Python 3迁移、以及后续的测试和发布计划。 主要议题 Nautilus分支状态： Yuri报告Nautilus即将发布，目前由Sage和David负责升级和测试。 讨论了Nautilus的发布笔记和可能的向后兼容性问题。 Luminous分支的Python 3迁移： Yuri提到正在处理Luminous分支的几个PR，需要进行测试。 讨论了Luminous分支的Python 3迁移状态和可能的测试需求。 Master分支的兼容性和测试： 讨论了Master分支的兼容性问题，特别是与Python 3的兼容性。 讨论了Jenkins实例中使用的CentOS 7.6和7.8镜像的需求。 后续行动计划： 决定对Nautilus、Mimic和Luminous分支进行Python 3的向后移植。 讨论了如何处理分支的测试和发布，特别是关于如何处理旧版本的向后兼容性问题。 决定事项 Nautilus即将发布，需要关注其发布笔记和向后兼容性。 Luminous分支的Python 3迁移正在进行中，需要进行更多的测试。 需要为Master分支准备更多的CentOS镜像以支持测试。 决定对Nautilus、Mimic和Luminous进行Python 3的向后移植，并确保这些分支的稳定性和兼容性。 后续行动计划 Yuri将继续处理Luminous分支的PR，并添加测试标签。 Pierre将负责Nautilus分支的PR工作。 需要为Master分支准备更多的CentOS镜像。 对Nautilus、Mimic和Luminous进行Python 3的向后移植，并确保这些分支的稳定性和兼容性。 其他讨论 讨论了Ceph的发布周期和命名规则，下一个版本将是Octopus。 讨论了资源锁定机制和测试套件的优化问题。 会议结束 会议在讨论了所有议题后结束，团队成员将继续按照会议决定的事项推进工作。 以上是本次会议的详细纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-02 :: Ceph Orchestration Meeting","slug":"2019-11-02_-_-_Ceph_Orchestration_Meeting","date":"2019-12-02T16:00:00.000Z","updated":"2019-12-03T16:00:00.000Z","comments":true,"path":"2019/12/03/2019-11-02_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/12/03/2019-11-02_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概述 本次会议主要讨论了多个技术更新和项目进展，涉及存储技术、监控系统以及销售策略等多个方面。会议中，团队成员对各项议题进行了深入讨论，并就后续行动计划达成一致。 主要议题 Ceph存储更新： 讨论了Ceph存储系统的最新更新，包括性能优化和稳定性改进。 强调了对Ceph监控系统的持续关注和优化需求。 监控系统升级： 详细讨论了监控系统的升级计划，包括高级监控集群的部署和测量技术的更新。 确认了监控系统在项目中的重要性，并计划加强其功能以满足更高要求。 销售策略与市场分析： 回顾了上周的销售会议，讨论了销售策略的调整和市场趋势的分析。 强调了持续跟踪市场动态和客户需求的重要性。 决定事项 确认了Ceph存储系统的更新计划，并指定了负责人进行后续的实施和监控。 确定了监控系统升级的具体时间表和所需资源。 决定加强销售团队的培训和市场分析工作，以提升销售业绩。 后续行动计划 由技术团队负责Ceph存储系统的更新和监控，确保按时完成并达到预期效果。 监控系统升级项目将由专门的团队负责，确保升级过程中的数据安全和系统稳定性。 销售团队将进行定期培训和市场分析会议，以适应市场变化并优化销售策略。 其他事项 会议中还讨论了其他次要议题，如团队建设活动和日常运营管理，但未形成具体决议。 会议结束 会议在明确了各项议题的后续行动计划后结束，全体成员将按照会议决议执行相关工作。 注： 由于会议录音内容较为零散且部分内容不清晰，上述纪要基于可理解的部分进行总结。如有遗漏或误解，请与会者补充和修正。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-26 :: Ceph Testing Meeting","slug":"2019-11-26_-_-_Ceph_Testing_Meeting","date":"2019-11-26T16:00:00.000Z","updated":"2019-11-27T16:00:00.000Z","comments":true,"path":"2019/11/27/2019-11-26_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/27/2019-11-26_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间： [未提供具体日期和时间] 参会人员： Yuri, Bruno, Greg, 以及其他未提及名字的成员 会议议题： 1. 假期安排： - Yuri提到他们在美国有较长的圣诞假期。 - 讨论了新年假期的安排。 Ceph项目更新： 最近有几个PR（Pull Request）被合并到Ceph的master分支，目前没有发现问题。 讨论了在drop目录下的远程目录是否发生变化，确认没有变化。 讨论了Nautilus 14版本的工作进展，预计很快可以发布。 技术问题讨论： Greg提到了一些旧的PR，特别是关于过滤选项的问题，发现inspect选项的过滤逻辑与预期不符。 讨论了如何处理这些技术问题，包括关闭当前PR并创建新的PR。 其他事项： 提到了一个关于添加过滤选项的新的ticket（编号1366），需要进一步审查。 讨论了关于部署过程的测试和细节。 决定事项： - 确认远程目录在drop目录下没有变化。 - 决定关闭当前的PR并创建新的PR来解决过滤选项的问题。 - 需要审查新的ticket 1366。 后续行动计划： - Greg将关闭当前的PR并创建新的PR。 - 需要审查并处理ticket 1366。 - 继续推进Nautilus 14版本的发布工作。 其他备注： - 会议中提到了假期安排和个人旅行计划。 - 提醒团队成员在假期期间保持联系。 会议结束： - 会议在讨论完所有议题后结束，祝大家假期愉快。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-25 :: Ceph Orchestration Meeting","slug":"2019-11-25_-_-_Ceph_Orchestration_Meeting","date":"2019-11-26T16:00:00.000Z","updated":"2019-11-27T16:00:00.000Z","comments":true,"path":"2019/11/27/2019-11-25_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/27/2019-11-25_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间 会议日期：具体日期未提及 会议时间：具体时间未提及 参会人员 Sebastian Han Juan Miguel Travis Sage Jeff 其他未提及姓名的参与者 会议议题 KubeCon 回顾 上周由于KubeCon活动，部分成员不在场。 Juan Miguel因父亲住院，返回故乡照顾，希望他父亲早日康复。 SSH Orchestrator 更新 上周在SSH Orchestrator方面进行了大量工作，包括bug修复和权限问题处理。 Zach负责编写安装文档，改进了安装模式，支持通过RPM包安装ceph。 讨论了增加Python客户端库到Rook，并在Rook Orchestrator中使用。 感恩节假期安排 本周美国感恩节，许多成员将休假，特别是周四和周五。 SSH Orchestrator 功能扩展 讨论了增加主机标签功能，类似于Rook的节点标签。 探讨了使SSH Orchestrator更加声明性，类似于Rook的工作方式。 讨论了增加调度算法，以随机或基于服务数量的方式分配服务。 并行处理和升级问题 讨论了增加并行处理能力，以提高效率。 讨论了升级流程，包括检查和实际升级步骤，以及与Rook升级管理的结合。 其他议题 讨论了 blinking lights 功能的实现。 讨论了Rook版本环境变量的使用和移除。 讨论了容器镜像版本检查的优化。 决定事项 SSH Orchestrator 功能扩展 增加主机标签功能。 探索使SSH Orchestrator更加声明性。 增加简单的调度算法。 并行处理和升级问题 增加并行处理能力。 优化升级流程，与Rook升级管理结合。 其他决定 移除Rook版本环境变量。 优化容器镜像版本检查。 后续行动计划 SSH Orchestrator 功能扩展 实现主机标签功能。 探索声明性配置。 实现简单的调度算法。 并行处理和升级问题 增加并行处理能力。 优化升级流程，与Rook升级管理结合。 其他行动 移除Rook版本环境变量。 优化容器镜像版本检查。 下次会议安排 下次会议定于12月4日，将讨论升级相关事宜。 备注 会议中提到的具体技术细节和代码变更需要进一步的技术文档和代码审查。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-27 :: Ceph Orchestration Meeting","slug":"2019-11-27_-_-_Ceph_Orchestration_Meeting","date":"2019-11-26T16:00:00.000Z","updated":"2019-11-27T16:00:00.000Z","comments":true,"path":"2019/11/27/2019-11-27_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/27/2019-11-27_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 日期： [未提供具体日期] 参会人员： Sebastian, Keifa, 以及其他相关人员 会议目的： 讨论Ceph Orchestrator的性能问题及后续行动计划。 主要议题及讨论内容： 会议时间调整： Sebastian提出由于Paul无法参加晚间会议，建议调整会议时间或取消。 决定取消当前会议，后续会议将在Sebastian休假回来后重新安排。 Ceph Orchestrator性能问题： 当前Orchestrator使用单线程池（kernel threads）处理后台操作，导致性能受限。 讨论了三个主要的使用案例：部署OSD、设备列表刷新（device ls refresh）和服务列表刷新（service ls refresh）。 提出增加线程池数量至10以提升性能，但仍存在局限性。 探讨了使用parallel SSH或pssh工具来并行处理多个主机上的操作，以提高效率。 GitHub浏览技巧： 分享了在GitHub上快速查找文件的技巧，通过输入“T”并搜索文件名。 Dashboard更新： OSD创建的相关Pia已获批准，等待QA测试。 讨论了预览功能的进展。 决定事项： 取消当前会议，直至Sebastian休假回来。 研究使用parallel SSH或pssh工具来解决Orchestrator的性能问题。 继续推进Dashboard的更新和预览功能。 后续行动计划： Sebastian休假期间，团队将通过Dashboard stand-up进行同步。 研究并评估parallel SSH或pssh工具的可行性，并考虑维护或采用现有项目。 其他事项： Sebastian休假期间，团队成员需自行处理升级等相关事宜。 会议结束时，Sebastian祝愿大家假期愉快，并感谢大家的努力。 会议结束： 会议在Sebastian的祝福中结束，Keifa和其他成员也表达了良好的祝愿。 备注： 会议中提到的技术术语和工具如“kernel threads”、“parallel SSH”、“pssh”等，是计算机科学和Ceph分布式存储领域的关键技术点。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-26 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-11-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-11-26T16:00:00.000Z","updated":"2019-11-27T16:00:00.000Z","comments":true,"path":"2019/11/27/2019-11-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/27/2019-11-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 主要议题与讨论内容 Ceph存储系统开发进展 初步放置实现：会议开始时，团队成员讨论了关于Ceph存储系统中初步放置实现的进展，特别是接口设计和Zinnias API的影响。 性能测试：团队决定进行性能测试，以评估Chromaticity的性能，并与Farsi进行比较，以便决定是否继续开发该系统。 Ceph存储系统的优化与改进 Crimson OSD与Alien Blue Star的性能比较：讨论了如何证明Alien Blue Star在性能模型或对快速闪存的支持上存在问题，以及如何通过性能测试来展示Crimson OSD的优势。 Ceph存储系统的错误处理和清理：团队成员分享了他们在错误处理和代码清理方面的工作，包括对aerator接口的改进和错误方法的添加。 Ceph存储系统的未来计划 会议和文档准备：团队讨论了即将到来的会议和文档准备工作，包括准备演讲主题和相关技术文档的编写。 用户空间驱动程序的使用：讨论了在Ceph存储系统中使用用户空间驱动程序的可行性和潜在问题，特别是在多进程设计方面的考虑。 决定事项 决定进行性能测试，以评估Chromaticity的性能，并与Farsi进行比较。 确定需要进一步研究和文档化的领域，包括用户空间驱动程序的使用和Ceph存储系统的多进程设计。 后续行动计划 进行性能测试，并准备相关报告，以展示Chromaticity相对于Farsi的性能优势。 继续研究和改进Ceph存储系统的错误处理和代码清理工作。 准备即将到来的会议和文档，包括编写技术文档和准备演讲主题。 其他讨论点 讨论了Ceph存储系统中OMAP数据和ONO数据的存储接口问题，以及如何优化这些接口以提高性能。 讨论了Ceph存储系统中多进程设计和用户空间驱动程序的使用，以及如何避免潜在的性能瓶颈。 结论 会议强调了Ceph存储系统性能优化的重要性，并确定了具体的行动计划和研究方向。团队将继续致力于提高系统的性能和稳定性，并准备相关的技术文档和演讲，以便在未来的会议中展示其工作成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-19 :: Ceph Testing Meeting","slug":"2019-11-19_-_-_Ceph_Testing_Meeting","date":"2019-11-24T16:00:00.000Z","updated":"2019-11-25T16:00:00.000Z","comments":true,"path":"2019/11/25/2019-11-19_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/25/2019-11-19_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间 （未提及具体时间） 参会人员 Nathan, Yuri, Patrick, Rakesh, Maneka, Sage, Marcus, Suzi, Davis 等 会议主题 Ceph分布式存储项目进展 Python 3 迁移相关讨论 Dashboard PR 合并及审查流程 Mimic 项目进展 关键细节 1. Ceph分布式存储项目进展 Dashboard PR 合并及审查流程: 由于多个Dashboard PR未在分支中，Nathan建议合并PR并重建，预计今天或明天完成。 对于特定PR，需要增加审查人数至六人以确保质量。 需要确保所有PR都包含在伊朗中，以便进行测试和审查。 对于rgw PR，Nathan将在会议后再次合并。 Mimic 项目进展: Patrick的团队在Mimic项目上进展顺利，但需要审批。 已通过邮件通知相关团队，预计今天或明天可以完成审批。 Python 3 迁移: 正在进行Python 3迁移，并尝试使测试在Python 2和Python 3上都能运行。 遇到单元测试兼容性问题，需要更多工作来解决。 计划添加Jenkins任务以部署Python 3环境。 目前基于openSUSE操作系统，未来可能支持更多操作系统。 2. 其他讨论 Python 3 迁移相关: 讨论了Python 3迁移的优先级和资源分配问题。 讨论了如何使用Sweet测试套件进行Python 3测试。 讨论了如何处理Scipio实验室中的工作节点故障问题。 技术问题: 讨论了如何解决Scipio实验室中工作节点故障的问题。 决定事项 合并Dashboard PR并重建。 增加特定PR的审查人数。 审批Mimic项目。 继续进行Python 3迁移。 解决技术问题。 后续行动计划 Nathan合并Dashboard PR。 审查并合并rgw PR。 审批Mimic项目。 继续进行Python 3迁移。 解决技术问题。 会议总结 本次会议讨论了Ceph分布式存储项目进展、Python 3 迁移、Dashboard PR 合并及审查流程、Mimic 项目进展等议题。会议明确了后续行动计划，并要求各方积极配合完成相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-19 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-11-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-11-24T16:00:00.000Z","updated":"2019-11-25T16:00:00.000Z","comments":true,"path":"2019/11/25/2019-11-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/25/2019-11-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： 本次会议主要讨论了Ceph分布式存储的相关研发进展、视频会议字幕翻译工作以及相关工作计划的总结。 关键细节： Ceph研发进展： 已开始审查Readex Air项目，并着手进行Tamez项目的查看。 对于HPN（高性能网络）的需求，需要进一步的讨论和准备。 英国树（British tree）的初步实现正在进行中。 已有多个补丁被接受，包括来自Crimson的补丁，以及针对Hag的解决方案。 对于一个优化方案，将引入第三个值来减少状态转换的开销。 正在讨论是否将用户空间驱动程序作为Crimson和Sister的主要后端。 视频会议字幕翻译： 正在翻译英文字幕为中文。 已完成部分工作，并计划下周继续进行。 其他： 有成员计划请假。 有成员正在准备下周的代码审查。 讨论的主要议题： Ceph研发进展中的HPN需求。 用户空间驱动程序的优先级。 视频会议字幕翻译工作的进展。 代码审查的准备。 决定的事项： 继续推进Ceph研发工作，特别是针对HPN的需求和用户空间驱动程序的讨论。 继续进行视频会议字幕翻译工作。 准备下周的代码审查。 后续行动计划： Ceph研发团队继续推进相关研发工作。 视频会议字幕翻译团队继续翻译工作。 准备下周的代码审查。 其他： 会议中提到了一些计算机科学/ceph相关领域英文原文的关键词，例如： HPN (High Performance Network) British tree Ceph POSIX IPC (Instructions Per Cycle) Reactor User space drivers 备注： 本次会议纪要仅供参考，具体内容以会议录音或录音整理为准。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-20 :: Ceph Orchestration Meeting","slug":"2019-11-20_-_-_Ceph_Orchestration_Meeting","date":"2019-11-24T16:00:00.000Z","updated":"2019-11-25T16:00:00.000Z","comments":true,"path":"2019/11/25/2019-11-20_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/25/2019-11-20_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议概要 日期: [未提供] 参会人员: Sebastian, Tim, Keifa, Josh, 及其他相关人员 主持人: Sebastian 主要议题 Orchestrator 测试改进 讨论了关于 SSHFS Writer 的实现，这将有助于改进 Orchestrator 的测试流程。 提到了使用 Rook 进行测试，并期待 Forger 的进展。 代码审查与集成问题 Keifa 报告了一个待审查的贴纸问题，并请求团队成员进行审查。 Tim 表示他将在接下来的两周内专注于下游工作，并愿意在离开前帮助审查代码。 CI 和测试框架 Josh 讨论了关于 Rook 的 CI 进展，尽管遇到了时区和可用性的挑战。 提到了对 Orchestrator 特定测试的需求，但目前进展缓慢。 技术问题与解决方案 讨论了关于 IP 地址包的问题，该问题影响了 SSH Orchestrator 的测试。 提到了需要加入 GitHub 的 Orchestrator 团队以更好地协作。 项目进展与未来计划 讨论了关于设备 ID 属性的实现，这将有助于改进设备管理。 提到了 Rook 正在开发的一个零售功能。 决定事项 需要尽快解决 IP 地址包的问题，以确保测试的顺利进行。 Tim 将在离开前帮助审查代码，团队成员应提前请求他的帮助。 需要加入 GitHub 的 Orchestrator 团队以加强协作。 后续行动计划 继续推进 SSHFS Writer 的实现，以改进 Orchestrator 的测试。 解决 IP 地址包的问题，并确保相关 PR 得到及时审查。 加入 GitHub 的 Orchestrator 团队，以更好地管理和协作项目。 继续关注设备 ID 属性的实现，并确保其对设备管理的影响。 其他事项 会议中提到了一些技术细节和具体问题的讨论，这些需要在会后进一步跟进和解决。 会议结束 会议在讨论了所有议题后结束，团队成员将继续推进各自的任务和项目。 注意: 会议中提到的具体技术细节和问题需要进一步的技术文档和代码审查来确保准确性和实施的可行性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-21 :: Ceph Performance Meeting","slug":"2019-11-21_-_-_Ceph_Performance_Meeting","date":"2019-11-24T16:00:00.000Z","updated":"2019-11-25T16:00:00.000Z","comments":true,"path":"2019/11/25/2019-11-21_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/25/2019-11-21_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 关键细节 新PR概览: 本周有三个新的PR。 David Zetland的PR涉及改进upnot balancer的逻辑，以解决优化不佳导致的速度过慢问题。 MDS的PR关于设置CPU亲和性。 Adam的PR标题为“Got the World on a String”，涉及字符串优化，使用string_view或其他方法。 已关闭或更新的PR: Neha的快速修复，禁用arm range合并。 调整默认的max MF条目每请求的合并。 一个关于从用户空间拉取事件的PR被stale bot关闭，因需要内核中的实验性内容。 一个旧的PR避免OSD消耗map被关闭，无具体解释。 PG autoscaler默认PG数216已批准。 Eric的OSD中GW CLS代码的过滤改进已更新。 其他讨论: 关于4K min_alloc_size的讨论，涉及SSD和NVMe驱动器的性能和空间放大问题。 讨论了如何处理混合工作负载，特别是对于RGW工作负载的影响。 提到了新的Intel节点的测试，包括读写性能和I/O操作。 主要议题 性能优化: 重点讨论了如何改进upnot balancer的逻辑，以及字符串优化的方法。 硬件兼容性: 讨论了4K min_alloc_size在不同类型存储设备上的表现和优化策略。 系统配置: 涉及MDS的CPU亲和性设置和OSD的过滤改进。 决定事项 继续对4K min_alloc_size进行更多测试和研究，特别是对于RGW工作负载的影响。 对于新的Intel节点，将继续优化配置以提高性能。 后续行动计划 对4K min_alloc_size进行更多测试，包括RGW工作负载的性能评估。 继续优化新的Intel节点的配置，以达到更好的读写性能和I/O操作。 下周会议将继续讨论相关PR和配置优化。 其他备注 会议中提到了一些技术细节和测试结果，需要进一步分析和验证。 对于混合工作负载的处理，需要找到更通用的解决方案。 以上是本次会议的纪要，涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-12 :: Ceph Testing Meeting","slug":"2019-11-12_-_-_Ceph_Testing_Meeting","date":"2019-11-16T16:00:00.000Z","updated":"2019-11-17T16:00:00.000Z","comments":true,"path":"2019/11/17/2019-11-12_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/17/2019-11-12_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Kira, Yuri, Nathan, Sage, Jason, 安德鲁，以及其他未具名成员 会议主题： Ceph项目进展、问题讨论和后续行动计划 关键细节： Ceph Mimic版本： Sage发布了一个针对Mimic的PR，旨在解决升级和客户端测试失败的问题。 Nathan已开始测试该PR，并计划将其合并到Mimic的候选版本中。 会议决定合并该PR，并运行测试以验证其效果。 Ceph Luminous版本： 目前没有针对Luminous的PR，主要关注Nautilus版本。 会议决定将Luminous版本作为最后一个LTS版本，并给予更多时间来完善。 Ceph Nautilus版本： Sage提到一个潜在回归，其中BlueStore在某些情况下会导致数据损坏。 如果有人提交修复该问题的PR，则将立即进行热修复。 Ceph Octopus版本： Timothy九有一个关于Oculus的PR。 会议讨论了测试和部署Oculus的进展。 Ceph测试： Sage正在编写新的测试用例，用于测试Ceph集群管理器。 讨论了在OpenStack上进行测试的可能性。 Ceph任务： Sage正在重构Ceph任务，以提高其效率和可靠性。 讨论了使用容器进行任务升级的可能性。 Ceph PR管理： 讨论了一些旧的PR，并决定关闭一些不再需要的PR。 决定的事项： 合并Sage的Mimic PR，并运行测试以验证其效果。 继续关注Luminous版本，并给予更多时间来完善。 如果有人提交修复BlueStore回归问题的PR，则立即进行热修复。 继续推进Oculus的测试和部署。 继续重构Ceph任务，并提高其效率和可靠性。 关闭一些不再需要的PR。 后续行动计划： Nathan将合并Sage的Mimic PR，并运行测试。 Sage将继续推进Oculus的测试和部署。 Sage将继续重构Ceph任务，并提高其效率和可靠性。 会议参与者将继续关注Ceph项目的进展，并积极参与。 关键术语： Ceph Mimic Luminous Nautilus Octopus Oculus BlueStore Task PR Regression Hotfix","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-12 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-11-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-11-16T16:00:00.000Z","updated":"2019-11-17T16:00:00.000Z","comments":true,"path":"2019/11/17/2019-11-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/17/2019-11-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 会议地点： San Francisco 参会人员： Alan（以色列，Ra'anana办公室） Roland Ronnie Peter 其他成员 会议主题： Ceph存储系统设计讨论 Alligator文件系统设计 Crimson性能测试 Native Stack的使用 会议内容： 1. Alligator文件系统设计 讨论了是否需要文件系统以及使用Alligator的原因。 结论：由于传统文件系统无法满足Ceph的需求，Alligator将直接在块设备上运行，不使用文件系统。 关键词：Alligator, 文件系统, 块设备 2. Crimson性能测试 讨论了Crimson在POSIX和Native Stack上的性能测试结果。 结论：Native Stack在性能上具有优势，但存在一些稳定性问题。 关键词：Crimson, POSIX, Native Stack 3. Native Stack的使用 讨论了Native Stack的局限性以及是否使用的问题。 结论：目前不考虑使用Native Stack，而是专注于POSIX Stack。 关键词：Native Stack, POSIX Stack 4. SP Decay 讨论了SP Decay的实现和测试。 结论：SP Decay的实现需要优先级，但测试工作可以继续进行。 关键词：SP Decay 5. 其他 Alan介绍了自己的背景和工作。 讨论了Ceph社区和Surveillance Cluster。 讨论了Crimson和Native Stack的兼容性。 后续行动计划： 继续进行SP Decay的测试工作。 完成Alligator文件系统的设计。 优化Crimson的性能。 备注： 会议中涉及的技术细节较多，建议参会人员仔细阅读会议记录。 会议中提到的关键词需要进一步了解其含义。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-13:: Ceph DocUBetter Meeting","slug":"2019-11-13_-_-_Ceph_DocUBetter_Meeting","date":"2019-11-16T16:00:00.000Z","updated":"2019-11-17T16:00:00.000Z","comments":true,"path":"2019/11/17/2019-11-13_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/17/2019-11-13_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Zach Dover（文档编写人员）、Jack、Gary、Sage、Patrick等 会议主题： 讨论Ceph文档的更新和改进计划 关键细节： Zach Dover介绍： Zach Dover是新加入的文档编写人员，负责Ceph文档的编写工作。他来自美国，在澳大利亚居住了8年，对科幻文学和计算机网络有浓厚的兴趣。 文档编写计划： Zach正在编写Ceph的入门指南，目标是使其尽可能用户友好。 他计划在下周完成指南的编写，并希望得到团队的审核。 除了入门指南，Zach还将更新硬件和操作系统推荐页面。 RST工具讨论： 团队讨论了是否需要将RST工具替换成其他语言，以简化文档编写流程。 大部分成员认为目前没有更换工具的必要，但可以列出RST工具的不足之处，以便寻找替代方案。 Sphinx模板更新： Sage建议更新Sphinx模板，以提高文档的可读性和美观性。 他将调查现有的Sphinx模板，并选择一个合适的模板进行更新。 网站更新： 会议讨论了网站更新计划，包括添加社区日历和改进着陆页。 Sage建议将网站从WordPress迁移到静态站点生成器，以便更好地维护。 着陆页改进： Zach指出当前着陆页存在信息不足、结构混乱等问题。 他建议添加图片和链接，以改善用户体验。 决定的事项： Zach将继续编写Ceph的入门指南，并更新硬件和操作系统推荐页面。 Sage将调查Sphinx模板，并选择一个合适的模板进行更新。 Sage将领导网站更新项目，包括添加社区日历和改进着陆页。 后续行动计划： Zach将在下周完成入门指南的编写，并提交给团队审核。 Sage将调查Sphinx模板，并选择一个合适的模板进行更新。 Sage将领导网站更新项目，并与团队沟通具体细节。 备注： 会议中提到了Ceph的安装过程，包括文档F comm、Doc's master bootstrap等。 会议还讨论了Ceph社区日历和着陆页的更新计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-11 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-11-11_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-11-14T16:00:00.000Z","updated":"2019-11-15T16:00:00.000Z","comments":true,"path":"2019/11/15/2019-11-11_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/15/2019-11-11_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员，包括Mishkin、Mia、Young Waller、Eric、Jason、Adam、Ben、Josh、Ilya等。 会议主题： Ceph存储系统近期更新及讨论 分布式存储Ceph的性能优化 内存管理策略讨论 会议关键细节： 1. Ceph存储系统近期更新： PG Autoscaler更新： 实施了新的最小默认PG数量，从4个增加到16个，以提升并行性和可扩展性。 RBD更新： 实现了RBD复制的日志核心代码的第一部分。 OSD更新： 增强了OSD的亲和性阶段。 MDS更新： MDS机会和MDS缓存内存限制得到更新。 RGW更新： 将额外的过滤功能移动到CLS代码中。 2. 性能优化讨论： 透明大页面（THP）问题： 讨论了THP可能导致内存使用过高的问题，并考虑通过限制THP使用来解决这个问题。 内存分配器优化： 讨论了TC malloc内存分配器的性能问题，并考虑使用内存池或对象池来优化内存分配。 缓冲区管理： 讨论了缓冲区管理的最佳实践，并考虑使用scatter-gather I/O来减少缓冲区管理的开销。 3. 决定的事项： 接受新的PG Autoscaler默认值。 禁用novelist的arm range和novelist。 降低默认的max OMAP增加量。 实施Eric的PR以减少bucket列表中的chard条目数。 继续测试和优化THP和TC malloc。 考虑使用内存池或对象池来优化内存分配。 4. 后续行动计划： 继续跟进THP和TC malloc的优化。 完成RBD复制的日志核心代码。 实施新的PG Autoscaler默认值。 禁用novelist的arm range和novelist。 降低默认的max OMAP增加量。 完成其他待办事项。 5. 会议总结： 本次会议讨论了Ceph存储系统近期更新、性能优化策略以及内存管理策略。会议达成了多项决定，并制定了后续行动计划，以进一步提升Ceph存储系统的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-13 :: Ceph Orchestration Meeting","slug":"2019-11-13_-_-_Ceph_Orchestration_Meeting","date":"2019-11-14T16:00:00.000Z","updated":"2019-11-15T16:00:00.000Z","comments":true,"path":"2019/11/15/2019-11-13_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/15/2019-11-13_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： [此处填写会议具体时间] 会议地点： [此处填写会议地点] 参会人员： [此处填写参会人员名单] 会议主题： 讨论Ceph分布式存储的最新进展、视频会议字幕翻译工作以及相关议题。 会议内容： 1. Ceph分布式存储进展 - 议题：会议首先讨论了Ceph分布式存储的最新研发进展。 - 关键细节：提到了Ceph在存储领域的重要性和持续的研发投入。 - 讨论内容：包括Ceph系统性能优化、故障处理机制、安全性提升等方面。 - 关键词：Ceph, 分布式存储, 存储性能, 故障处理, 安全性。 2. 视频会议字幕翻译 - 议题：随后，会议转向视频会议字幕翻译工作，特别是英译中的翻译任务。 - 关键细节：讨论了翻译工作的具体流程、质量控制和效率提升。 - 讨论内容：包括如何准确翻译专业术语、保持翻译的流畅性和准确性。 - 关键词：字幕翻译，英译中，专业术语，翻译质量，效率。 3. 其他议题 - 议题：会议还涉及了其他相关议题，如音乐、艺术和文化等。 - 关键细节：提到了音乐元素在会议中的穿插，以及对艺术和文化价值的讨论。 - 讨论内容：包括对艺术作品的欣赏、文化差异的理解等。 决定事项： 继续加强Ceph分布式存储的研发，尤其是性能和安全性方面的提升。 优化字幕翻译工作流程，确保翻译质量，提高翻译效率。 在会议中适当融入音乐和文化元素，提升会议的趣味性和参与度。 后续行动计划： 研发团队：制定详细的研发计划，明确研发目标和时间节点。 翻译团队：优化翻译流程，加强团队培训，提升翻译质量。 会议组织者：在后续会议中考虑加入更多音乐和文化元素，丰富会议内容。 会议总结： 本次会议就Ceph分布式存储、字幕翻译及其他相关议题进行了深入讨论，并制定了相应的行动计划。会议强调了技术创新和团队协作的重要性，为后续工作的开展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-11 :: Ceph Orchestration Meeting","slug":"2019-11-11_-_-_Ceph_Orchestration_Meeting","date":"2019-11-10T16:00:00.000Z","updated":"2019-11-11T16:00:00.000Z","comments":true,"path":"2019/11/11/2019-11-11_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/11/2019-11-11_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Miguel、Sebastian、Paige、Mike Latimer、其他未提及的参与者 会议主题： Ceph社区讨论、Rook项目进展、Orchestrator相关讨论 关键细节： Ceph社区讨论： 上周在Epic City的CDM会议中，进行了关于Ceph的积极讨论。 讨论了从Orchestrator视角添加新功能，但具体细节未透露。 提出了关于Rook和升级相关的问题，需要与State团队讨论。 容器镜像名称变化是否足以进行升级，以及Rook是否依赖于不同的镜像名称或标签。 讨论了不使用“latest”版本的原因。 Rook项目进展： SEF（Staff Volume Inventory）已合并至上周的版本中。 Client Python作为依赖项，已讨论在Rook仓库中引入Python客户端库。 Sebastian将更新现有PR或创建新PR以实现此功能。 Orchestrator相关讨论： Orchestrator方面正在积极进行代码开发。 有多个团队参与Elaste orchestrated effort，以及大量的PF（Performance Fix）。 大新闻是DeepSea Orchestrator的开发工作可能即将停止，团队将更加专注于Cosmo和Rook两个Orchestrator。 Daniel（来自Red Hat的新成员）正在研究Antilochus Twitter。 讨论了关于Hedgehog Twitter的决策，决定停止该项目。 决定的事项： Sebastian将更新现有PR或创建新PR以将Python客户端库引入Rook仓库。 团队将专注于Cosmo和Rook两个Orchestrator，DeepSea Orchestrator的开发工作可能即将停止。 后续行动计划： Sebastian将更新现有PR或创建新PR。 团队将继续专注于Cosmo和Rook两个Orchestrator的开发。 Daniel将继续研究Antilochus Twitter。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-06 :: Ceph Developer Monthly","slug":"2019-11-06_-_-_Ceph_Developer_Monthly","date":"2019-11-06T16:00:00.000Z","updated":"2019-11-06T16:00:00.000Z","comments":true,"path":"2019/11/07/2019-11-06_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/07/2019-11-06_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知（会议记录中未提及所有参会人员姓名） 会议主题： Crimson 项目更新 小对象存储优化 瞬时挂载更新 分布式重复数据删除（Dee Dup）项目状态 统计信息和崩溃报告 主要讨论内容： 1. Crimson 项目更新 Crimson 项目旨在提高 Ceph 的计算效率，减少开销。 项目已进行了一年以上，目前处于功能完善阶段。 Crimson 管理器已实现与现有异步管理器的通信，并支持 v2 协议。 对象存储组件目前使用内存存储进行原型设计，后续将移植 Blue Store。 2. 小对象存储优化 小对象存储在空间利用方面存在开销，需要优化。 讨论了减少最小分配大小、使用 RocksDB 存储小对象、优化对象存储接口等方法。 认为将小对象存储在复制池中可能是一个解决方案。 3. 瞬时挂载更新 瞬时挂载（Export Ephemeral Pinning）旨在优化元数据分布。 使用一致哈希算法实现元数据的随机和分布式分区。 讨论了基准测试方案，包括权威子树数量、MDS 热度因子、跨 MDS 操作等。 4. 分布式重复数据删除（Dee Dup）项目状态 Dee Dup 项目旨在通过内容地址存储和引用计数实现重复数据删除。 项目已完成了大部分基础设施和基本功能，目前处于完善和测试阶段。 讨论了使用外部工具测试 Dee Dup 的工作流程，并希望获得用户反馈。 5. 统计信息和崩溃报告 Ceph 现在可以收集崩溃报告，并将其发送到上游实验室。 崩溃报告包含堆栈跟踪、版本信息和崩溃签名等信息。 讨论了如何将崩溃签名与跟踪器中的问题关联起来，并优先处理。 讨论了如何改进崩溃报告的收集和展示方式。 决定事项： 继续推进 Crimson 项目，完善功能并进行测试。 优化小对象存储，减少空间开销。 完善瞬时挂载功能，并进行基准测试。 完善 Dee Dup 项目，并进行用户测试。 改进崩溃报告的收集和展示方式。 后续行动计划： 项目负责人将创建 Trello 卡片，跟踪各项任务的进度。 邀请更多开发者参与讨论和开发。 发布相关文档，提供技术支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-07 :: Ceph Performance Meeting","slug":"2019-11-07_-_-_Ceph_Performance_Meeting","date":"2019-11-06T16:00:00.000Z","updated":"2019-11-07T16:00:00.000Z","comments":true,"path":"2019/11/07/2019-11-07_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/07/2019-11-07_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： - 集体（包括存储领域分布式存储Ceph的研发人员、视频会议字幕翻译及总结人员） 会议内容： 一、天气讨论 会议开始时，与会人员就所在地区的天气进行了简单的交流。 二、Ceph相关议题 并行压缩问题： 研发人员提到，用户反馈了RocksDB损坏的问题，可能与并行压缩参数的更改有关。目前，已创建了一个不合并的分支，并正在调查该问题。 深度清理问题： 有用户报告说，即使关闭了深度清理，仍然有大量深度清理正在进行。研发人员建议将深度清理的睡眠时间设置得更高，并逐步增加，以观察是否有助于解决问题。 范围删除问题： 用户反馈说，范围删除导致性能下降，并可能导致内存碎片。研发人员建议在删除大量对象时禁用范围删除，并进一步调查该问题。 删除范围与RocksDB损坏问题： 研发人员表示，删除范围可能与RocksDB损坏问题有关。建议在Nautilus版本中禁用删除范围，并回退到RocksDB旧版本。 PG数量问题： 讨论了增加PG数量可能带来的问题，例如数据丢失和CPU使用率增加。建议在减少PG数量时，首先增加PG日志长度，以避免数据移动。 三、后续行动计划 研发人员将继续调查并行压缩、深度清理、范围删除和RocksDB损坏问题。 用户将根据建议调整深度清理和范围删除的设置。 研发人员将考虑更改PG数量和PG日志长度的默认值。 四、其他事项 讨论了其他一些议题，例如自动缩放器、数据移动和AWS环境。 五、总结 本次会议讨论了Ceph中的一些重要问题，并制定了后续行动计划。研发人员将继续努力解决这些问题，并提高Ceph的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-06 :: Ceph Orchestration Meeting","slug":"2019-11-06_-_-_Ceph_Orchestration_Meeting","date":"2019-11-05T16:00:00.000Z","updated":"2019-11-05T16:00:00.000Z","comments":true,"path":"2019/11/06/2019-11-06_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/06/2019-11-06_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Tim、Joshua、Terry（来自红帽）、Castella、Yeshua等 会议主题： 讨论Ceph orchestrator项目进展、CI/CD流程、会议安排等。 会议内容： 会议时间安排： 目前Ceph orchestrator项目有两个会议：周一和周三的15分钟站立会议，用于讨论项目进展和协调工作。 周一15:00 UTC的会议为社区会议，用于讨论更广泛的话题。 周三的会议可能因时区问题需要调整。 CI/CD流程： 目前Ceph orchestrator项目的CI/CD流程主要依赖于GitHub的Bot进行代码测试和发布。 需要考虑如何更有效地验证orchestrator与各种组件的兼容性，例如Rook等。 项目进展： Tim将离开项目三个月，预计在11月底结束工作。 Joshua主要在Rook项目上工作，与Ceph orchestrator项目存在一些重叠，需要确保两者不重复工作。 Terry刚加入Ceph orchestrator项目，正在学习相关知识和技能。 行动计划： 确定CI/CD流程的改进方案。 确保Ceph orchestrator项目与其他组件的兼容性。 调整会议时间，以适应不同时区的人员。 关键词： Ceph orchestrator、CI/CD、GitHub、Rook、会议时间、兼容性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-05 :: Ceph Testing Meeting","slug":"2019-11-05_-_-_Ceph_Testing_Meeting","date":"2019-11-04T16:00:00.000Z","updated":"2019-11-05T16:00:00.000Z","comments":true,"path":"2019/11/05/2019-11-05_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/05/2019-11-05_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间：[具体日期] 会议地点：[具体地点] 参会人员：Sebastian, [其他参会人员姓名] 会议主题：Ceph项目进展及后续行动计划 一、会议关键细节 Sebastian分享了近期在乌克兰的旅行经历，提到当地气温低至-5度。 由于假期原因，Nathan和IB未能参加本次会议。 David和Gregory讨论了Ceph代码提交和合并事宜。 Nathan询问URI的讨论内容，Sebastian表示已经看到。 讨论了Ceph的下一个版本发布计划，包括Mimic和Luminous的发布。 讨论了Nautilus版本的问题，包括GCC分段错误和Bionic的崩溃。 讨论了Python 3相关的问题，预计在QA阶段出现。 讨论了backports和稳定版本的问题。 二、讨论的主要议题 Ceph项目版本发布计划：Mimic和Luminous的发布。 Nautilus版本的问题：GCC分段错误、Bionic的崩溃和Python 3相关问题。 backports和稳定版本的问题。 三、决定的事项 继续推进Mimic和Luminous的发布，合并已有的Pull Requests。 重点关注Nautilus版本的问题，解决GCC分段错误、Bionic的崩溃和Python 3相关问题。 在QA阶段进行问题排查，确保Ceph版本稳定。 跟进backports和稳定版本的问题。 四、后续行动计划 Nathan和Gregory继续跟进Mimic和Luminous的发布。 解决Nautilus版本的问题，包括GCC分段错误、Bionic的崩溃和Python 3相关问题。 跟进backports和稳定版本的问题。 所有参会人员保持沟通，及时汇报问题进展。 [备注]：会议中提到的部分计算机科学/ceph相关领域英文原文关键词包括：Ceph、Mimic、Luminous、Nautilus、Pull Requests、backports、stable releases、GCC segmentation fault、Bionic、Python 3。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-11-04 :: Ceph Orchestration Meeting","slug":"2019-11-04_-_-_Ceph_Orchestration_Meeting","date":"2019-11-03T16:00:00.000Z","updated":"2019-11-04T16:00:00.000Z","comments":true,"path":"2019/11/04/2019-11-04_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/04/2019-11-04_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Jerry、Rick、Olly、DW、Sebastian、Lauren等 会议主题： Rook 项目进展讨论及行动计划 关键细节及议题： Orchestrator 工作流： Jerry 提到 Orchestrator 工作流需要支持多站点设置，并创建区域。 Rick 表示 Rook 只支持独立区域，不支持多站点配置。 Jerry 认为可能需要一个更高级的工作流，先进行多站点操作，然后再启动 Demon，或者创建其他所需资源。 Rook 与 Octopus： DW 更新了 Rook 的路线图，并确保 Rook 准备好 Octopus 的发布。 Rick 提到需要查看 Octopus 的待办事项列表，并确定 Rook 需要实现的功能。 Python 客户端库： Jerry 提到将 Python 客户端库放入 Rook 仓库可以使版本依赖管理更加简洁。 DW 同意将 Python 客户端库添加到 Rook 仓库中。 驱动器组支持： Jerry 讨论了将驱动器组集成到 Rook Orchestrator 中的方案。 他建议在 Orchestrator 层面获取驱动器信息，并将其传递给 Rook。 他还提到应该在 Rook 安全集群内部实现卷创建，而不是依赖于外部实现。 闪烁灯集成： Rick 提到闪烁灯集成目前受阻，需要等待相关 pull request 合并。 Sebastian 提到可以将闪烁灯集成到 Europe Manager 模块中。 远程调用问题： Lauren 提到远程调用库不支持 SSH 选项参数，需要升级库版本。 Jerry 计划使用 pip 安装新版本的远程调用库。 决定的事项： Jerry 将继续与 Ollie 讨论 RGB 工作内容。 DW 将更新 Rook 的路线图，确保 Rook 准备好 Octopus 的发布。 将 Python 客户端库添加到 Rook 仓库中。 探索将驱动器组集成到 Rook Orchestrator 中的方案。 解决远程调用库的问题。 后续行动计划： Jerry 与 Ollie 讨论 RGB 工作内容。 DW 更新 Rook 路线图。 完成将 Python 客户端库添加到 Rook 仓库的工作。 探索将驱动器组集成到 Rook Orchestrator 中的方案。 解决远程调用库的问题。 备注： 会议中提到了一些计算机科学/ceph 领域的英文关键词，如：Orchestrator、Rook、Octopus、RBD、Rook、Python、SSH、RemoteOH 等。 会议中讨论了一些技术细节，如：工作流、版本依赖管理、驱动器组、闪烁灯、远程调用等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-28 :: Ceph Orchestration Meeting","slug":"2019-10-28_-_-_Ceph_Orchestration_Meeting","date":"2019-11-02T16:00:00.000Z","updated":"2019-11-03T16:00:00.000Z","comments":true,"path":"2019/11/03/2019-10-28_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/03/2019-10-28_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题： Ceph 和相关项目开发进度讨论 会议时间： 2023年11月某日 参会人员： Active, Mike, Joshua, Kiefer, Emma 等 会议内容： 1. SSH Orchestrator 和 Docker 集成： Active 正在开发 SSH Orchestrator，并取得了一些进展。 Mike 正在与 Joshua 合作，将 SSH Orchestrator 与 Docker 集成，并希望帮助完善 SAP 守护进程的方案。 讨论了使用 bootstrap 命令的可能性，以及如何使其适用于更多容器。 2. Ceph 集群文件系统问题： 讨论了 Ceph 集群中 MDS 进程的分配问题，以及如何确保其在多个文件系统之间均匀分配。 发现了现有设置无法将 MDS 分配到特定文件系统的问题，并讨论了可能的解决方案。 3. Rook 项目进度： Active 提到了 Rook 项目的一些开放 PR，并请求其他成员查看。 讨论了 Rook 项目中的一些问题，例如 Python 代码的异步缓存处理。 讨论了将验证逻辑移动到 orchestrator 接口的可能性。 4. Ceph 存储设备信息收集： 讨论了如何从存储设备中收集信息，并将其存储在 Ceph 存储系统中。 讨论了将存储设备信息添加到配置映射中，并使用配置映射来存储设备信息。 5. 其他： 讨论了 Ceph 工作组的一些其他问题，例如工作负载的监控和集成。 讨论了将一些 PR 放入 IRC 频道进行讨论。 后续行动计划： Active 继续开发 SSH Orchestrator。 Mike 和 Joshua 继续推进 Docker 集成工作。 解决 Ceph 集群文件系统问题。 完善 Rook 项目的验证逻辑。 收集 Ceph 存储设备信息。 讨论其他 Ceph 工作组问题。 备注： 会议中提到了一些计算机科学/ceph 领域的英文关键词，例如 SSH Orchestrator、Docker、SAP 守护进程、MDS、Rook、配置映射等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-29 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-10-29_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-11-02T16:00:00.000Z","updated":"2019-11-03T16:00:00.000Z","comments":true,"path":"2019/11/03/2019-10-29_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/03/2019-10-29_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： （会议时间） 会议地点： （会议地点） 参会人员： （列出参会人员） 会议主题： 讨论Ceph存储系统开发进展、Sister项目更新、性能优化及未来规划。 关键细节： 1. Sister项目更新： - 临时实例化问题：讨论了关于临时实例化的问题，并提到需要对相关代码进行重构，以确保其不会改变系统的可观察行为。 - 性能优化：讨论了使用原生堆栈进行性能优化的可能性，并提到需要进一步测试以验证性能提升。 - DPDK测试：强调了DPDK测试的重要性，以验证使用原生堆栈后性能的实际提升，并讨论了与POSIX标签相关的潜在交互问题。 2. Ceph存储系统开发进展： - Crimson分支：讨论了Crimson分支的开发进展，包括内存复制问题、文件系统性能优化等。 - Zoned Native Storage：讨论了Zoned Native Storage的实现，并提到需要消费相关论文和规范以了解其设计理念。 - Open Channel SSD：讨论了Open Channel SSD的现状，认为其作为行业标准已不再可行。 3. 其他议题： - 代码重构：讨论了代码重构的建议，包括将共享代码放入公共命名空间，以提高代码可读性和可维护性。 - 会议安排：由于部分成员下周将前往旧金山，会议决定取消下周会议，并在下周之后继续召开。 讨论的主要议题： Sister项目开发进展及性能优化 Ceph存储系统开发进展及Crimson分支 Zoned Native Storage的实现 Open Channel SSD的现状 代码重构建议 会议安排 决定的事项： 继续推进Sister项目开发，并关注性能优化。 完成Crimson分支的开发，并解决内存复制问题。 消费相关论文和规范，了解Zoned Native Storage的设计理念。 考虑Open Channel SSD的现状，并寻找替代方案。 实施代码重构建议，提高代码可读性和可维护性。 取消下周会议，并在下周之后继续召开。 后续行动计划： 各成员继续推进各自的工作，并及时汇报进展。 组建团队，共同讨论和解决开发过程中遇到的问题。 定期召开会议，讨论项目进展和规划。 注意事项： 请各成员关注邮件列表，及时了解项目进展。 请各成员积极参与讨论，并提出建设性意见。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-31 :: Ceph Performance Meeting","slug":"2019-10-31_-_-_Ceph_Performance_Meeting","date":"2019-11-02T16:00:00.000Z","updated":"2019-11-03T16:00:00.000Z","comments":true,"path":"2019/11/03/2019-10-31_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/03/2019-10-31_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： David、Casey、Eric、Adam、Prasad、Matt等 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、项目进展 PRs状态： 新的Orbitty缓存复制日志PR已提交，待审查。 Rosanell提交了多个关于Numa亲和力更新和增强的PR，包括OSD和GW。 Eric的PR涉及桶索引的动态重启，已合并。 Adams的PR修复了某些日志行为，以支持Roxie的PR，已合并。 其他PRs状态更新，包括对缓存、JW桶分片数量、蓝存储性能优化等。 讨论话题： RocksDB分片： Adam分享了他在RocksDB分片方面的测试结果，发现分片对延迟影响不大，但写放大和压缩时间有所改善。讨论了分片可能导致延迟的原因，以及如何提高性能。 BlueStore性能优化： 讨论了BlueStore性能优化PR，包括同步收集列表和压缩率等。 Rgw桶分片： 讨论了提高Rgw桶分片数量的PR，以及如何平衡分片数量和性能之间的关系。 二、决定事项 对RocksDB分片进行进一步测试，以验证性能改进和延迟影响。 对BlueStore性能优化PR进行审查和合并。 对Rgw桶分片数量进行测试，以确定最佳分片数量。 三、后续行动计划 Adam将继续测试RocksDB分片，并与团队分享测试结果。 Eric将审查BlueStore性能优化PR，并与团队讨论合并事宜。 Prasad将进行Rgw桶分片测试，并与团队讨论结果。 四、其他事项 讨论了RocksDB锁定的潜在问题，以及如何解决。 讨论了Rgw桶创建和删除的性能问题。 五、会议总结 本次会议讨论了Ceph分布式存储项目的多个关键议题，并制定了后续行动计划。团队将继续努力优化Ceph性能，并解决潜在问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-30 :: Ceph Orchestration Meeting","slug":"2019-10-30_-_-_Ceph_Orchestration_Meeting","date":"2019-11-02T16:00:00.000Z","updated":"2019-11-03T16:00:00.000Z","comments":true,"path":"2019/11/03/2019-10-30_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/11/03/2019-10-30_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储项目讨论 会议时间： 2023年11月（具体日期未知） 参会人员： - 未知（提及了Sun、CH、Letta Pia、Katy Wiseman、Edie等） - Paul Kozma - AJ - Sage Ki Foo - Brad Hubbard - 会议记录者 会议关键细节： 1. Python 3问题： - 由于CentOS 7缺少Python 3的某些包，导致无法在Sintra 7和Central US 8环境中运行Ceph。 - 讨论了在CentOS 7中添加所需Python 3包的可能性，并提出了由Ceph项目成员提交请求的建议。 2. Ceph集群状态监控： - 提出了一个用于监控Ceph集群状态的工具，该工具使用了一种未命名的数据结构来存储状态信息。 - 讨论了使用OC metadata来改进数据结构，并计划在未来进行改进。 3. 设备共享问题： - 讨论了当多个设备共享同一个OSD时可能出现的冲突问题。 - 提出了使用CID来区分不同设备的建议。 4. SSH Orchestrator集成： - CH正在努力集成SSH Orchestrator，但由于CentOS 7缺少Python 3的某些包，导致集成受阻。 - 讨论了使用远程IO包的兼容性问题。 5. 人员变动： - 会议记录者将在2023年12月至2月期间离职。 - 讨论了在离职前如何为团队做出贡献。 决定事项： 由Ceph项目成员提交请求，在CentOS 7中添加所需Python 3包。 进一步改进Ceph集群状态监控工具。 使用CID来区分共享同一个OSD的不同设备。 寻找解决方案以解决SSH Orchestrator集成问题。 讨论了离职人员的贡献问题。 后续行动计划： 由Ceph项目成员提交请求，在CentOS 7中添加所需Python 3包。 进一步改进Ceph集群状态监控工具。 使用CID来区分共享同一个OSD的不同设备。 寻找解决方案以解决SSH Orchestrator集成问题。 讨论了离职人员的贡献问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-22 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-10-22_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-10-30T16:00:00.000Z","updated":"2019-10-31T16:00:00.000Z","comments":true,"path":"2019/10/31/2019-10-22_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/31/2019-10-22_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储项目讨论 会议时间： [会议具体时间] 参会人员： [参会人员名单] 会议内容： 一、Ceph存储优化 F2FS文件系统： 讨论了F2FS文件系统在Flash存储优化方面的优势，认为其与Ceph的使用场景非常契合。 Crimson存储系统： 讨论了将F2FS文件系统移植到Crimson存储系统的可行性，并计划进行测试和优化。 二、代码优化与重构 命名空间管理： 讨论了Ceph代码中不同环境（如Crimson、Alien等）使用不同命名空间的问题，提出了统一命名空间和头文件的建议，以提高代码的可读性和可维护性。 编译时配置问题： 讨论了Ceph中编译时配置导致的问题，如无法同时构建Diane Store和Alien Store，建议改为运行时配置。 三、功能开发与测试 Crimson OS测试： 讨论了Crimson OS的测试进展，包括测试用例的编写和测试结果的收集。 异常处理： 讨论了Ceph中Future对象异常处理的方式，提出了使用异常处理方法替换异常值的建议。 异步消息传递： 讨论了异步消息传递模块的开发进展，包括与现有v2版本的兼容性测试和代码清理。 四、其他事项 DM时钟服务器： 讨论了DM时钟服务器的合并进度，以及其对其他模块的影响。 DBTK与Crimson： 讨论了将DBTK与Crimson结合使用的可行性，并寻求相关帮助。 五、行动计划 Ceph存储优化： 继续进行F2FS文件系统移植到Crimson存储系统的测试和优化工作。 代码优化与重构： 实施统一命名空间和头文件的建议，解决编译时配置问题。 功能开发与测试： 完成Crimson OS的测试工作，优化异步消息传递模块。 其他事项： 完成DM时钟服务器的合并，探索DBTK与Crimson的结合使用。 六、会议总结 本次会议讨论了Ceph分布式存储项目的多个方面，包括存储优化、代码重构、功能开发等。会议明确了后续的工作计划和目标，为项目的顺利进行提供了指导。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-23 :: Ceph Orchestration Meeting","slug":"2019-10-23_-_-_Ceph_Orchestration_Meeting","date":"2019-10-30T16:00:00.000Z","updated":"2019-10-31T16:00:00.000Z","comments":true,"path":"2019/10/31/2019-10-23_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/31/2019-10-23_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 与会人员： - 不明（So or Thunder） - 不明（Keifa） - 不明（II） - 不明（Joshua Hesketh） - 不明（Sebastian，主要工作于me desperate funding） - 不明（Keifer） - 不明（Rope module） 会议主题： Ceph分布式存储项目进展、Orchestrator组件介绍及后续工作安排 关键细节及讨论议题： Drive Group预览功能： Keifa提到需要对Drive Group的预览功能进行审查，以便在合并后可以在仪表板上实现预览功能。 该功能目前尚未实际使用，因此需要有人进行单元测试和实际应用。 Inventory清理： II提到Inventory部分需要清理，但目前仍等待最新成员的审查。 Orchestrator组件： Joshua Hesketh刚加入存储团队，正在学习Orchestrator组件。 Orchestrator组件是一个接口，用于创建、部署、移除服务以及获取运行在集群上的服务列表。 Orchestrator组件旨在构建Ceph和部署工具（如Rook、DeepSea等）之间的桥梁。 Orchestrator接口允许不同的orchestrator后端实现该接口，从而在Surf仪表板上实现部署任务。 Dashboard支持： 如果部署工具没有Orchestrator模块，则无法通过内置的Chef仪表板进行部署。 Keifer正在为Dashboard添加新功能，例如从GUI部署新的OS Days，这需要通过Orchestrator模块实现。 后续行动计划： Keifa将创建一个PR来读取pison comical，以开始更多choline模块的工作。 Joshua Hesketh将学习Orchestrator组件的文档，并了解其工作原理。 II将继续清理Inventory部分。 决定事项： Keifa将审查Drive Group预览功能，并在合并后进行测试。 Joshua Hesketh将学习Orchestrator组件的文档，并了解其工作原理。 II将继续清理Inventory部分。 后续行动： Keifa创建PR并开始更多choline模块的工作。 Joshua Hesketh学习Orchestrator组件的文档。 II清理Inventory部分。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-23 :: Ceph Science User Group Meeting","slug":"2019-10-23_-_-_Ceph_Science_User_Group_Meeting","date":"2019-10-30T16:00:00.000Z","updated":"2019-10-31T16:00:00.000Z","comments":true,"path":"2019/10/31/2019-10-23_-_-_Ceph_Science_User_Group_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/31/2019-10-23_-_-_Ceph_Science_User_Group_Meeting/","excerpt":"","text":"会议纪要 会议时间： 一个月前（具体日期未提及） 会议地点： 线上会议 参会人员： 多位Ceph用户和开发者 会议主题： Ceph集群运行状况、升级经验分享、新技术讨论 会议内容： 一、CERN CEPhta项目 CERN的CEPhta项目取得了显著成果，感谢Dan和Julian的贡献。 项目视频中存在部分视频长度不正确的问题，正在修复中，修复后将上传至YouTube。 二、集群规模与性能 Tom提到他们计划增加1000个OSD，但尚未实施。 讨论了单一大集群与多个小集群的优缺点，不同用户有不同的偏好。 讨论了OSD map更新时间随集群规模增长的情况，目前没有遇到明显问题。 三、存储类型与配置 讨论了S3存储与块存储分离的配置，以避免混合使用场景。 讨论了使用CHAP代理进行QoS控制，以防止S3用户占用过多资源。 讨论了使用ZRAM压缩交换空间，以增加服务器内存使用效率。 四、Ceph Nautilus版本升级 多位用户分享了从Mimic升级到Nautilus的经验，包括升级过程、遇到的问题和解决方案。 讨论了在Nautilus版本1424中发现的bug，并等待修复。 五、Ceph Seth使用经验 Rafael分享了他们公司使用Ceph Seth的经验，包括集群规模、使用场景和升级计划。 讨论了S3集群之间的复制、多区域S3和灾难恢复等话题。 六、其他讨论 讨论了使用NVMe卡作为rocksdb存储的配置，包括RAID配置和性能监控。 讨论了使用Ceph文件系统（CephFS）与高性能计算（HPC）集群的集成。 讨论了使用Condor调度器在空闲CPU上运行Ceph工作负载。 七、后续行动计划 确定下一次会议时间（预计为1月份）。 继续关注Ceph社区动态和bug修复。 八、其他事项 无 总结： 本次会议讨论了Ceph集群的运行状况、升级经验、新技术等话题，参会者分享了宝贵的经验和见解。会议内容丰富，对Ceph用户和开发者都有一定的参考价值。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-Oct-24 :: Ceph Tech Talk - Ceph at Nasa","slug":"2019-Oct-24_-_-_Ceph_Tech_Talk_-_Ceph_at_Nasa","date":"2019-10-30T16:00:00.000Z","updated":"2019-10-31T16:00:00.000Z","comments":true,"path":"2019/10/31/2019-Oct-24_-_-_Ceph_Tech_Talk_-_Ceph_at_Nasa/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/31/2019-Oct-24_-_-_Ceph_Tech_Talk_-_Ceph_at_Nasa/","excerpt":"","text":"会议纪要： 会议主题： NASA大气科学数据存储与处理 会议时间： 不详 参会人员： NASA大气科学团队成员，包括数据科学家、工程师等 会议内容： NASA大气科学数据存储现状： NASA大气科学团队负责处理和分析来自多颗卫星的原始数据，包括US-10、NOAA-20、JPSS-2等。 数据量巨大，每年产生约10PB的数据，需要高效的存储和数据处理方案。 目前主要使用Ceph作为数据存储平台，包括Rados、RGW和S3。 使用FusedFS作为POSIX文件系统层，方便科学家访问数据。 使用PostgreSQL数据库跟踪文件元数据，并确保数据完整性。 Ceph的使用情况： NASA团队直接使用Ceph，未使用Ceph Gateway。 使用Python绑定的库Fredo4CEPH进行数据访问。 使用PDS服务器进行数据索引和分块，提高数据处理效率。 使用Kubernetes管理Ceph集群和应用程序。 面临的挑战： 数据量增长迅速，需要更大的存储容量和更高的性能。 Ceph集群出现了一些故障，需要改进集群稳定性和可靠性。 需要更好的数据访问方式，例如支持变量级别的数据访问。 未来计划： 考虑迁移到BlueStore后端，提高性能。 研究使用Striper进行数据分块，提高数据访问效率。 使用upmap进行集群升级，提高集群性能和可靠性。 探索使用Geospatial Data Abstraction Library (GDAL)进行数据访问。 行动计划： 继续使用Ceph作为数据存储平台，并改进集群性能和可靠性。 研究使用BlueStore后端和Striper进行数据分块。 使用upmap进行集群升级。 探索使用GDAL进行数据访问。 关键词： NASA、大气科学、Ceph、Rados、RGW、S3、FusedFS、PostgreSQL、BlueStore、Striper、upmap、GDAL","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-03 :: Ceph Performance Meeting","slug":"2019-10-03_-_-_Ceph_Performance_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-03_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-03_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage, Igor, Adam, Mark, Casey, Ellen, Marcus, etc. 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、议题一：存储性能优化 磁盘配置： 探讨使用16K金属尺寸和间距对硬盘和NVMe驱动器的性能影响。初步测试表明，性能表现与使用16K金属尺寸相当，但间距带来的收益巨大，建议采用。 Igor对硬盘进行了测试，初步结果良好，但需要进一步验证。 性能测试： Sage在Luminous和Nautilus代码库上对SSD进行了大量测试，结果与NVMe的测试结果一致，性能表现相当。 Adam更新了性能测试数据，展示了使用SSD时的CPU使用率。 性能优化： Eric正在对CLS或RGW进行过滤优化，以减少发送给GW的数据量，但担心解码开销。 Casey提到重新排列存储桶目录条目，以仅解码需要过滤的部分，而不是整个条目。 Adam对性能进行了基准测试，并修复了一些bug，目前PR已通过测试。 其他优化： Margie和Ping有一个互斥锁竞争的PR，理论上可以改善某些性能问题，但需要进一步验证。 Igor更新了智能DB空间使用框架，以改进SS文件的新位置决策。 二、议题二：功能开发 存储池自动缩放： Sage提出将PG自动缩放与旧式存储池兼容，以避免在集群中创建大量空存储池时缩放。 OSD性能跟踪器： Sage建议禁用OSD性能跟踪器，因为它可能对性能产生负面影响。 文件系统创建： 讨论在RBD上创建文件系统时的性能问题，并决定推迟优化，专注于实际使用场景。 加密性能： 讨论加密对性能的影响，并决定进一步研究。 三、议题三：其他 新节点： 新的Intel节点已到位，将用于测试和开发。 Sharding： Adam正在对数据库进行性能基准测试，并尝试调整fao以处理更多数据。 测试： 讨论了在新的Intel节点上进行测试的计划，包括对HS性能进行测试。 四、行动计划 确认磁盘配置和性能测试结果。 进一步研究性能优化方案。 完成功能开发。 进行新节点的测试和开发。 完成Sharding和测试工作。 五、后续行动 Sage将更新Trello板，包括所有性能优化方案。 Adam将继续进行性能基准测试和fao调整。 Igor将继续更新智能DB空间使用框架。 Sage将跟进PG自动缩放和OSD性能跟踪器的问题。 Marcus将研究加密对性能的影响。 新节点将用于测试和开发。 备注： 会议中提到了大量Ceph相关的英文关键词，如OSD、PG、CLS、RGW、RBD、SSD、NVMe等。 会议纪要仅为总结，具体细节请参考会议录音或相关文档。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-08 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-10-08_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-08_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-08_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： [姓名]（负责RocksDB和Blue Store移植） [姓名]（负责Ceph存储引擎优化） [姓名]（负责Ceph存储引擎性能测试） [姓名]（负责Ceph存储引擎安全） [姓名]（负责Ceph存储引擎兼容性） [姓名]（负责Ceph存储引擎架构设计） [姓名]（负责Ceph存储引擎文档） 会议内容： 1. RocksDB和Blue Store移植 [姓名] 正在测试RocksDB的移植版本，性能表现良好。 [姓名] 正在将Blue Store移植到Ceph存储引擎中，但遇到了一些问题，需要进一步研究。 2. Ceph存储引擎优化 [姓名] 正在优化Ceph存储引擎的性能，包括： 使用随机读取而不是顺序读取进行性能测试。 开发用于Ceph存储引擎的watchdog功能。 优化Ceph存储引擎的调试功能。 [姓名] 正在研究如何将Ceph存储引擎的性能测试自动化。 3. Ceph存储引擎安全 [姓名] 正在测试Ceph存储引擎的安全性，包括： 检查单元测试中是否存在遗漏的测试用例。 修复Ceph存储引擎中的一些安全问题。 4. Ceph存储引擎兼容性 [姓名] 正在测试Ceph存储引擎的兼容性，包括： 将Ceph存储引擎的配置文件迁移到新的配置框架。 修复Ceph存储引擎中的一些兼容性问题。 5. Ceph存储引擎架构设计 [姓名] 正在研究Ceph存储引擎的架构设计，包括： 设计Ceph存储引擎的插件架构。 研究Ceph存储引擎如何支持不同的硬件平台。 研究Ceph存储引擎如何支持不同的工作负载。 6. Ceph存储引擎文档 [姓名] 正在编写Ceph存储引擎的文档，包括： 编写Ceph存储引擎的API文档。 编写Ceph存储引擎的配置文档。 编写Ceph存储引擎的故障排除文档。 决定事项： 继续推进RocksDB和Blue Store的移植工作。 继续优化Ceph存储引擎的性能。 继续测试Ceph存储引擎的安全性、兼容性和文档。 设计Ceph存储引擎的插件架构。 行动计划： [姓名] 将在月底前完成RocksDB移植版本的PR。 [姓名] 将在月底前完成Ceph存储引擎性能测试的自动化。 [姓名] 将在月底前完成Ceph存储引擎安全测试的PR。 [姓名] 将在月底前完成Ceph存储引擎兼容性测试的PR。 [姓名] 将在月底前完成Ceph存储引擎文档的PR。 其他事项： [姓名] 将在11月参加Ceph存储引擎的培训。 [姓名] 将在11月参加Ceph社区的会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-07 :: Ceph Orchestration Meeting","slug":"2019-10-07_-_-_Ceph_Orchestration_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-07_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-07_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 参会人员： [请列出参会人员名单] 会议主题： 分布式存储Ceph项目讨论 会议内容： 一、Ceph CI更新 Adam升级了Jenkins版本，并更新了插件，解决了之前CPU使用率过高的问题。 系统进行了一些磁盘空间清理，将不再保存所有构建，以减少存储压力。 期待升级后构建更加可靠。 二、外部集群 外部集群的PR即将完成，目前处于最终审查阶段。 即使Arches作为要求可能即将被移除，外部集群功能仍对OCS有益。 三、Ceph Manager模块异步配置 讨论了Ceph Manager模块异步配置的PR，主要关注使用互斥锁（mutex）还是通道（channels）。 决定使用互斥锁，因为它在此场景中更简单。 建议使用同步组（sync group）来控制并发，以确保在所有模块配置完成后才切换到OSD代码。 四、卷内信息提取 讨论了从配置映射中提取卷内信息的PR。 目前PR已提交，Sebastian开始进行审查。 目前CI构建出现问题，无法查看构建日志，需要进一步调查。 五、布宜诺斯艾利斯会议 Charlotte将在布宜诺斯艾利斯参加一个关于如何为TrueIT项目贡献的演讲。 演讲将用西班牙语进行。 六、其他 会议期间，讨论了一些与编排相关的邮件，但没有紧急事项。 会议期间，CI构建出现问题，需要进一步调查。 后续行动计划： Adam将继续调查CI构建问题。 Charlotte将继续审查卷内信息提取的PR。 Sebastian将继续审查外部集群的PR。 Charlotte将准备布宜诺斯艾利斯的演讲。 备注： 会议中提到的英文关键词包括：CI、Rook、Cassandra、Jenkins、mutex、channels、sync group、OCS、Arches、TrueIT。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-14 :: Ceph Orchestration Meeting","slug":"2019-10-14_-_-_Ceph_Orchestration_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-14_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-14_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： Travis, Alfredo, Sage, Vickie, Anson Bullard, Federico 等 会议内容： 一、会议议程 Brooksie CI 和测试 Jenkins 更新 测试自动化 SSH 协议的编排 其他议题 二、会议讨论 Brooksie CI 和测试 上周进行了关于 Brooksie CI 和测试的会议，讨论了如何简化测试流程，并引入其他测试框架。 Travis 正在努力改进测试，使其更加绿色，并将在本周五提交相关 PR。 Jenkins 已更新，AWS thinkin's 插件稳定，目前没有发现任何问题。 测试自动化 讨论了将测试自动化作为默认设置，以便在每次 PR 提交时自动运行测试。 Travis 的 PR 将帮助实现这一目标，但需要升级 Polly 以确保其正常工作。 讨论了默认使用被动测试集的可行性，并避免运行不同测试套件可能带来的潜在问题。 SSH 协议的编排 讨论了 SSH 协议编排的进展，目前 Sage 正在负责相关工作。 讨论了从 Ansible 协排过渡到 SSH 协排的可行性，以及如何进行过渡。 Federico 将跟进相关讨论，并与团队成员沟通。 三、行动计划 Travis 继续改进测试，并在本周五提交相关 PR。 Sage 继续推进 SSH 协排相关工作。 Federico 跟进 SSH 协排的讨论，并与团队成员沟通。 讨论后续的测试自动化方案。 四、其他事项 无 五、会议总结 本次会议主要讨论了测试自动化、SSH 协排等议题，并制定了相应的行动计划。会议进展顺利，取得了一定的成果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-10 :: Ceph Performance Meeting","slug":"2019-10-10_-_-_Ceph_Performance_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-10_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-10_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间 会议时间 参会人员 [所有参会人员姓名] 会议主题 新的PRs更新 内存需求文档更新 性能测试和测试节点更新 RGW崩溃问题 Docker镜像发布流程 会议内容 1. 新的PRs更新 - Eric提交了一个关于RGW动态分片数量的PR。 - Sage提交了一个PR，可能解决了缓存抖动问题。 - Sage正在研究内存清理问题，以避免污染缓存。 - Adams提交了一个PR，防止日志被损坏。 - 更新了key foo测试，修复了之前的问题。 - 使用优先级缓存管理器为MDS缓存设置内存限制。 - Adam重写了shardene工作，以便进行测试。 2. 内存需求文档更新 - 由于硬盘容量的增加，许多客户对现有内存需求文档提出了问题。 - 讨论了是否需要更新文档，并提出了一个基于OSD类型的推荐方案。 - 决定提交一个更新文档的PR。 3. 性能测试和测试节点更新 - Intel捐赠了新的测试节点，用于性能测试。 - 在新节点上进行了单OSD性能测试，发现性能有了显著提升。 - 发现使用4K金属大小的RBD测试比使用16K大小更快。 - 进行了RocksDB调优，以优化性能。 - 讨论了是否使用FIO对象存储工具进行测试。 4. RGW崩溃问题 - 在Kubernetes环境中运行Ceph时，RGW出现崩溃问题。 - 分析了核心转储文件，发现与已知问题相关。 - 讨论了可能的解决方案，包括重启Pod和进行夜间重启。 5. Docker镜像发布流程 - 讨论了Docker镜像的发布流程，以及如何跟踪和修复问题。 - 决定联系Ken来获取更多信息。 行动计划 [所有参会人员姓名]将更新文档的PR。 [所有参会人员姓名]将继续进行性能测试。 [所有参会人员姓名]将调查RGW崩溃问题。 [所有参会人员姓名]将与Ken联系，了解Docker镜像的发布流程。 会议总结 本次会议讨论了Ceph项目的多个方面，包括PR更新、文档更新、性能测试、RGW崩溃问题和Docker镜像发布流程。会议确定了行动计划，并分配了任务。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-15 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-10-15_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-15_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-15_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： Mitch, Radek, Dan, Josh, 以及其他相关人员 会议主题： Ceph crimson 项目进展、性能测试、错误处理优化、对象上下文工作、异步测试等 关键细节与讨论议题： 1. Crimson 项目进展 - Mitch 汇报了 crimson 项目的进展，提到已经在 crimson 中实现了内存主题存储接口，并进行了基准测试，结果显示 crimson 在性能上优于传统 OSD。 - 讨论了 crimson 的性能优化，包括使用多线程和优化锁机制。 - 讨论了 crimson 在多客户端场景下的性能，发现 crimson 在高并发情况下表现良好。 2. 错误处理优化 - 讨论了使用 futures 和编译器特性进行错误处理的优缺点，并决定进行实验来比较不同方法的性能。 - 认为使用 futures 进行错误处理可能会带来不必要的性能开销，并决定尝试使用手动处理错误的方法。 3. 对象上下文工作 - Radek 汇报了 crimson 对象上下文工作的进展，介绍了 intrusive LRU 和 snap context 的实现。 - 讨论了对象上下文工作对性能的影响，并决定进一步优化。 4. 异步测试 - Dan 汇报了异步测试的进展，介绍了测试策略和测试结果。 - 讨论了异步测试中的问题，并决定进一步调查。 5. 其他 - 讨论了 crimson 中的 TOF 消息处理，并决定进行改进。 - 讨论了 crimson 的内存压缩和加密问题。 决定事项： 进一步优化 crimson 的性能，包括使用多线程、优化锁机制和减少复制操作。 对错误处理进行实验，比较不同方法的性能。 完成对象上下文工作，并进一步优化。 完成异步测试，并解决测试中的问题。 改进 crimson 中的 TOF 消息处理。 调查 crimson 的内存压缩和加密问题。 后续行动计划： Mitch 继续进行 crimson 的性能优化。 Radek 完成对象上下文工作，并进行优化。 Dan 完成异步测试，并解决测试中的问题。 其他相关人员继续进行相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-16 :: Ceph Orchestration Meeting","slug":"2019-10-16_-_-_Ceph_Orchestration_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-16_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-16_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年10月（具体日期未提及） 参会人员： Sebastian, Hayley, Isaac Hecker, Vidya, Jason, Greg, Christopher, Adam, Blaine, Nathan 会议主题： 分布式存储Ceph项目进展、视频会议字幕翻译及总结工作、会议时间调整、Python 3迁移、Togglify部署等 关键细节及讨论议题： 1. Ceph项目进展 问题： 在进行Salah基因测试时，出现“空间不足”的问题，导致测试无法进行。目前不清楚具体原因。 解决方案： Vidya将尝试重新运行失败的测试，以获取更多信息。 Jason怀疑可能是配置错误，也将进行调查。 后续行动： 观察测试结果，确定问题原因。 如果是配置错误，进行修复。 2. 视频会议字幕翻译及总结工作 讨论： 目前字幕翻译工作进展顺利。 总结工作需要进一步优化，以提高效率和质量。 3. 会议时间调整 问题： 由于时间冲突，难以确定合适的会议时间。 解决方案： 使用Doodle进行投票，选择合适的会议时间。 确定会议时间为每周三上午8点。 4. Python 3迁移 进展： Python 3迁移工作正在进行中，已提交相关补丁。 后续行动： 继续推进Python 3迁移工作。 Nathan将帮助进行代码迁移。 5. Togglify部署 讨论： 目前使用Togglify进行部署，但需要将其集成到Togglify的基础设施中。 可以考虑使用Terraform进行部署。 后续行动： 探索使用Terraform进行部署的可行性。 讨论并确定具体的部署方案。 6. 其他 讨论： 提出为Togglify添加支持GitHub分支的功能，以提高测试效率。 讨论并确定具体实现方案。 决定事项： 继续推进Ceph项目进展，解决“空间不足”问题。 优化视频会议字幕翻译及总结工作。 确定每周三上午8点为会议时间。 推进Python 3迁移工作。 探索使用Terraform进行Togglify部署的可行性。 后续行动计划： 观察测试结果，确定Ceph项目“空间不足”问题的原因。 进行Togglify部署方案讨论，并确定具体方案。 推进Python 3迁移工作，并与Nathan沟通。 优化视频会议字幕翻译及总结工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-17 :: Ceph Performance Meeting","slug":"2019-10-17_-_-_Ceph_Performance_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-20T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-17_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-17_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月（具体日期未提及） 参会人员： 会议记录中未明确列出参会人员，但提到了以下几位： Bono（负责Bono的缓存独立化） Radek（负责降低日志级别） Eric（负责减少有序桶列表中的压力条目数量） Adam（负责修复日志问题） Patrick（负责MDS缓存内存限制的调整） Igor（负责短蓝存储工作） Josh（负责审查代码） Roman（负责I/O Uring引擎的PR） Sue（负责I/O Uring引擎的测试） Alex（负责4K金属信号测试） Seifer（负责性能测试） 会议内容： 新提交的PR： Bono的PR：将Bono的缓存独立化，解决用户大量固定条目导致内存增长和性能下降的问题。 Radek的PR：降低Crimson的日志级别，可能用于性能提升。 Eric的PR：减少有序桶列表中的压力条目数量，提高效率。 Adam的PR：修复日志问题。 Patrick的PR：调整MDS缓存内存限制。 Igor的PR：短蓝存储工作，降低压缩放大。 Josh的PR：修复固定条目计算错误。 讨论的主要议题： Bono缓存独立化：该PR解决了用户大量固定条目导致的问题，但引入了额外的锁定竞争，需要通过增加缓存卡数量来缓解。 4K金属信号：Igor的测试结果表明，4K金属信号在写入性能方面有显著提升，但读取性能有所下降。需要进一步测试和分析。 I/O Uring引擎：Roman和Sue的测试结果表明，I/O Uring引擎在性能方面表现良好，但需要新的内核才能测试。 决定的事项： 接受Bono缓存独立化PR，并采取措施缓解锁定竞争。 继续测试4K金属信号，并分析读取性能下降的原因。 接受I/O Uring引擎PR，但将其标记为实验性功能。 后续行动计划： Bono和Igor继续优化Bono缓存独立化和4K金属信号。 Roman和Sue继续测试I/O Uring引擎。 所有PR提交者继续修复代码问题。 总结： 本次会议讨论了多个Ceph项目的进展和问题，并做出了相应的决策。会议强调了性能优化和代码质量的重要性，并要求相关人员进行进一步的工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-21 :: Ceph Orchestration Meeting","slug":"2019-10-21_-_-_Ceph_Orchestration_Meeting","date":"2019-10-20T16:00:00.000Z","updated":"2019-10-21T16:00:00.000Z","comments":true,"path":"2019/10/21/2019-10-21_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/21/2019-10-21_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日（具体日期未提及） 会议地点： 线上会议 参会人员： 未知（会议纪要中未提及具体姓名） 会议主题： Ceph Orchestrator相关议题 Rook项目进展 安全守护进程（sage daemon）相关讨论 关键细节 Ceph Orchestrator相关议题 预览驱动器组功能： 新的Pull Request允许在仪表板和编排器中预览驱动器组，但需要依赖Rook的卷库存功能。 Rook项目进展： Rook 1.1.3版本预计明天发布，主要修复了OSD配置和升级问题。 安全守护进程（sage daemon）： 讨论了sage daemon的功能和范围，以及是否将其作为独立项目或集成到Ceph源代码树中。 Rook项目进展 Rook 1.1.3版本： 计划明天发布，主要修复了OSD配置和升级问题。 OSD配置问题： 配置覆盖没有被正确应用，需要进一步调查和修复。 OSD升级问题： 需要确保在升级过程中始终进行OSD pod的同步。 安全守护进程（sage daemon） 功能： sage daemon用于启动和管理安全守护进程，包括创建密钥环、配置守护进程等。 范围： 讨论了sage daemon的功能和范围，以及是否将其作为独立项目或集成到Ceph源代码树中。 独立项目： 一些参与者认为sage daemon应该作为一个独立项目进行开发，以便更好地控制其版本和功能。 集成到Ceph源代码树中： 一些参与者认为sage daemon应该集成到Ceph源代码树中，以便更好地与Ceph生态系统整合。 决定的事项 Rook 1.1.3版本： 计划明天发布。 sage daemon： 讨论了sage daemon的功能和范围，需要进一步讨论和决策。 后续行动计划 Rook 1.1.3版本： 发布Rook 1.1.3版本。 sage daemon： 发布sage daemon的设计文档。 讨论sage daemon的集成方案。 确定sage daemon的开发和发布计划。 计算机科学/ceph相关领域英文原文关键词 Ceph Orchestrator Rook sage daemon Pull Request Inventory OSD Upgrade Configuration Dependency Scope Integration","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-02 :: Ceph Developer Monthly","slug":"2019-10-02_-_-_Ceph_Developer_Monthly","date":"2019-10-01T16:00:00.000Z","updated":"2019-10-02T16:00:00.000Z","comments":true,"path":"2019/10/02/2019-10-02_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/02/2019-10-02_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议主题： 分布式存储Ceph相关研发进展及讨论 会议时间： 未知 参会人员： 未知 会议内容： 1. SSH Orchestrator工具 该工具旨在简化Ceph集群的部署和管理，通过脚本和Ansible自动化工具实现。 工具支持在容器中运行Ceph守护进程，并提供了集群初始化和部署功能。 工具支持从Docker Hub或其他容器镜像仓库拉取容器镜像，并支持自定义容器镜像。 工具支持集群自动扩容和缩容，并可以与Ceph Manager和Dashboard集成。 2. BlueStore存储引擎 讨论了BlueStore存储引擎在处理小对象时的空间效率问题。 提出将小对象数据存储在RocksDB中，以减少空间浪费。 讨论了将RocksDB的分配粒度降低到4KB的可行性，以进一步减少空间浪费。 3. 自动恢复功能 介绍了Ceph 15.2版本中引入的自动恢复功能，该功能允许客户端在黑名单后自动恢复连接。 讨论了该功能的两种模式：no和clean，其中clean模式允许客户端自动重新连接。 4. Ceph Nautilus/Octopus版本 讨论了Ceph Nautilus和Octopus版本的开发进展。 讨论了性能改进、Rgw功能增强、BlueStore优化等方面的进展。 5. 其他 讨论了Ceph集群性能优化、RocksDB缓存管理等方面的技术问题。 后续行动计划： 完善SSH Orchestrator工具，并与其他工具集成。 解决BlueStore存储引擎的空间效率问题。 测试和优化自动恢复功能。 完成Ceph Nautilus/Octopus版本的开发工作。 持续优化Ceph集群性能。 会议总结： 本次会议主要讨论了Ceph集群的部署、管理和性能优化等方面的技术问题，并介绍了Ceph Nautilus/Octopus版本的开发进展。会议明确了后续行动计划，以确保Ceph集群的稳定性和高性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-02 :: Ceph Testing Meeting","slug":"2019-10-02_-_-_Ceph_Testing_Meeting","date":"2019-10-01T16:00:00.000Z","updated":"2019-10-02T16:00:00.000Z","comments":true,"path":"2019/10/02/2019-10-02_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/02/2019-10-02_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Isaac, Lenox, Amira, Zach, Greg, Josh, Nathan, Sebastian, Blaine, Shailesh等 会议主题： Ceph项目进展、测试工作、社区参与、会议时间调整等 关键细节： Ceph项目进展： Isaac分享了他在欧洲的经历，并讨论了Ceph性能测试和部署测试的最新进展。 讨论了Doji测试的失败原因，包括分支检出失败、任务调度问题等。 讨论了Ceph项目代码审查和Python 3迁移的进展。 讨论了Ceph项目社区参与和贡献者招募。 测试工作： 讨论了Ceph项目的持续集成和测试工作，包括Doji测试、Beaker测试、Pytest测试等。 讨论了测试覆盖率、测试用例编写和测试结果分析。 社区参与： 讨论了Ceph项目的社区参与和贡献者招募。 讨论了如何吸引更多社区成员参与Ceph项目。 会议时间调整： 讨论了Ceph项目会议时间的调整，以适应不同时区成员的参与。 讨论了使用Doodle工具进行会议时间投票。 讨论的主要议题： Ceph项目测试工作进展 Ceph项目代码审查和Python 3迁移 Ceph项目社区参与和贡献者招募 Ceph项目会议时间调整 决定的事项： 继续推进Ceph项目测试工作，解决Doji测试失败问题。 继续推进Ceph项目代码审查和Python 3迁移。 积极招募Ceph项目社区成员。 使用Doodle工具进行Ceph项目会议时间投票。 后续行动计划： Isaac将继续跟进Ceph项目测试工作，解决Doji测试失败问题。 Amira将继续推进Ceph项目代码审查和Python 3迁移。 社区成员将继续参与Ceph项目，贡献代码和测试用例。 使用Doodle工具进行Ceph项目会议时间投票，确定新的会议时间。 其他事项： 讨论了Ceph项目社区成员Brunner和Lane的参与情况。 讨论了Ceph项目社区成员Shailesh的参与情况。 关键词： Ceph Doji测试 Beaker测试 Pytest测试 代码审查 Python 3迁移 社区参与 贡献者 Doodle工具","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-10-01 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-10-01_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-10-01T16:00:00.000Z","updated":"2019-10-02T16:00:00.000Z","comments":true,"path":"2019/10/02/2019-10-01_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/10/02/2019-10-01_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Jim, Riddick, Sage, 其他研发人员 会议主题： Ceph分布式存储系统研发讨论 主要议题及讨论内容： 1. Blue Store性能问题及解决方案 问题： Blue Store在处理较慢的硬盘和SSD时存在性能问题，可能会增加开销。 解决方案： 长期计划是使用新的存储系统来支持高性能设备，Blue Store主要针对硬盘和较慢的SSD。 在短期，如果Blue Store能够带来显著的性能提升，即使增加一些开销也是值得的。 需要评估在Blue Store中引入伊利诺伊州加速器的努力是否值得。 2. Ceph存储引擎优化 议题： 对Ceph存储引擎进行优化，提高性能。 讨论内容： Jim正在更新现有分支，优化存储引擎性能。 已经将socket系统中的注册数据结构进行了优化，避免了不必要的开销。 正在研究如何实现socket系统，并尝试使用Gaussian数据结构来维护注册信息。 3. Ceph对象存储调度器 议题： 开发Ceph对象存储调度器，提高系统性能。 讨论内容： 正在实现背景恢复功能，并使用Crimson进行调度。 将实现对象读写锁定，并修改接口以支持不同的锁定策略。 需要实现对象状态增长，以支持更复杂的锁定机制。 4. Ceph配置选项 议题： 为Ceph配置系统添加新的配置选项，以支持调度器和其他功能。 讨论内容： 将在Crimson中添加新的实验性配置选项，用于控制调度器和对象读写锁定等功能。 将使用注释或标签来标识这些实验性选项，以避免在生产环境中使用。 5. Ceph与其他存储系统的兼容性 议题： 与Percy Store进行兼容性测试。 讨论内容： 需要阅读Percy Store的初步草案，并制定兼容性测试计划。 将在Google文档中记录设计方向、问题和目标，以便讨论。 后续行动计划： Jim继续优化Ceph存储引擎。 开发Ceph对象存储调度器，并实现对象读写锁定。 为Ceph配置系统添加新的实验性配置选项。 与Percy Store进行兼容性测试。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-18 :: Ceph Orchestration Meeting","slug":"2019-09-18_-_-_Ceph_Orchestration_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-18_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-18_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年3月24日 参会人员： 集合会议参与者 会议主题： Ceph分布式存储项目相关议题讨论 会议内容： 1. Pod管理外部Kubernetes集群功能 销售人员提出Pod管理功能需要支持连接外部Kubernetes集群。 目前存在一个bug，阻止了事件推送到外部Kubernetes节点。 开发人员正在修复该bug，并添加代码以允许将消息推送到外部Kubernetes集群。 修复预计将在明天完成，并提交Pull Request。 2. Rook与Kubernetes资源整合 Arun正在研究Rook与Kubernetes资源整合的工作。 讨论了将Rook和Kubernetes事件创建资源的方式统一，以简化代码和维护。 认为可以使用Cuban客户端代码对象，或者自动生成Python类来处理自定义资源定义。 讨论了使用Cuban客户端代码对象的优势和挑战，并决定在Pull Request中实现该功能。 3. Rook与Cuban客户端代码对象 讨论了Rook模块主要使用字典而不是Cuban客户端代码对象的原因。 认为使用Cuban客户端代码对象可以简化代码并提高可维护性。 讨论了自动生成Python类来处理自定义资源定义的方案。 4. 主机方程 Kiefer完成了主机方程的mock-ups，并已合并。 讨论了主机方程的演示和文档工作。 认为需要更多的资源和努力来推动主机方程的进展。 5. 安全性部署 讨论了安全性部署的废弃问题。 认为应该逐步淘汰安全性部署，并寻找替代方案。 行动计划： 开发人员将在明天完成Pod管理外部Kubernetes集群功能的修复，并提交Pull Request。 Arun将继续研究Rook与Kubernetes资源整合的工作。 讨论使用Cuban客户端代码对象或自动生成Python类来处理自定义资源定义的方案。 Kiefer将推动主机方程的进展，并完成演示和文档工作。 讨论安全性部署的替代方案。 备注： 会议中讨论了一些计算机科学/ceph相关领域英文原文的关键词，例如：Kubernetes, Rook, Cuban, custom resource definitions, Python classes等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-23 :: Ceph Orchestration Meeting","slug":"2019-09-23_-_-_Ceph_Orchestration_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-23_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-23_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 与会人员： Kifa、Recovery、Travis、Fashion Wagner、Sebastian Hunt、Adam（Red Hat）、其他团队成员 会议主题： Orchestrator项目进展、Rook CI、Rook 1.1.1发布、Ceph集群管理、Rook操作工具等 会议关键细节 OSD创建与平衡： 讨论了OSD创建过程中可能产生的大量流量问题，以及是否需要将OSD自动添加到crash map。 提出了将新添加的OSD权重设置为0的方案，以便平衡器可以逐步将其映射到crash map。 决定不将此功能设置为默认行为，需要用户手动调整权重。 Dashboard中的驱动器组创建： 讨论了Dashboard创建驱动器组的需求，需要Rook提供正确的卷库存信息。 决定在Dashboard中实现创建驱动器组的功能，但需要Rook提供安全卷库存。 讨论了保留两种发现机制以避免破坏现有功能。 Rook CI： 讨论了Rook CI的长期计划，并计划下周三进行社区电话会议。 由于Adam（Red Hat）的休假，会议时间需要调整。 Rook 1.1.1发布： 介绍了Rook 1.1.1的发布，其中包含许多修复和稳定性改进。 讨论了Rook 1.1.2的发布计划。 Rook操作工具： 讨论了Rook操作工具的改进，包括如何处理在未安装任何软件的宿主机上运行脚本的情况。 决定使用简单的脚本，并尽量保持其可读性和简洁性。 决定的事项 不将OSD自动添加到crash map的默认行为。 在Dashboard中实现创建驱动器组的功能，需要Rook提供安全卷库存。 下周三进行Rook CI社区电话会议，时间待定。 发布Rook 1.1.2。 改进Rook操作工具。 后续行动计划 Kifa继续进行OSD创建和平衡的改进。 Recovery继续进行Dashboard驱动器组创建的实现。 Adam（Red Hat）和团队继续进行Rook CI的改进。 Travis和团队继续进行Rook 1.1.2的发布。 Fashion Wagner和Sebastian Hunt继续进行Rook操作工具的改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-24 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-09-24_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-24_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-24_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目进展及问题讨论 会议内容： 一、项目进展 Riddick Spear计划： 项目负责人正在撰写Riddick Spear计划，旨在更好地支持写入操作，并定义项目范围和估算时间线。 计划将在本周末前完成，并提交给利益相关者。 Ackerson计划： 项目负责人正在撰写Ackerson计划，解释Ceph存储的核心概念和项目范围。 计划将在本周末前完成，并提交给利益相关者。 性能测试： 针对Ceph存储性能进行了测试，发现了一些问题。 将进一步调查并修复这些问题。 Riddick pantry writer问题： Riddick pantry writer在返回响应时存在问题，需要进一步调试。 将尝试使用未修改的Constantine虚拟版本进行调试。 Ceph OSD操作接口： 项目负责人正在修改Ceph OSD操作接口，以支持状态错误和状态迁移。 修改后的接口将简化代码并提高可读性。 Ceph恢复机制： 项目负责人正在重构Ceph恢复机制，以创建更清晰的接口，并提高异步操作的处理效率。 二、讨论的主要议题 Ceph经典OSD与Crimson接口整合： 讨论了如何整合Ceph经典OSD和Crimson之间的接口，以简化代码并提高可读性。 决定尝试使用状态机来封装异步操作，并避免使用future eyes。 Ceph调度器与Gemini Cook集成： 讨论了如何将Ceph调度器与Gemini Cook集成，以便更有效地处理异步操作。 决定研究如何将Gemini Cook与Ceph调度器集成，以实现更高效的资源调度。 Ceph性能测试： 讨论了Ceph性能测试的重要性，并决定开展更多测试以评估性能。 三、决定的事项 完成Riddick Spear和Ackerson计划，并提交给利益相关者。 解决Riddick pantry writer问题。 修改Ceph OSD操作接口，并提交相关代码。 重构Ceph恢复机制，并提交相关代码。 研究Ceph调度器与Gemini Cook的集成方案。 开展更多Ceph性能测试。 四、后续行动计划 项目负责人将继续推进Riddick Spear和Ackerson计划的编写。 技术人员将继续调试Riddick pantry writer问题。 技术人员将继续修改Ceph OSD操作接口和重构Ceph恢复机制。 技术人员将研究Ceph调度器与Gemini Cook的集成方案。 技术人员将开展更多Ceph性能测试。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-25 :: Ceph Testing Meeting","slug":"2019-09-25_-_-_Ceph_Testing_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-25_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-25_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间： [未提供具体时间] 会议地点： [未提供具体地点] 参会人员： [未提供具体人员] 会议主题： 讨论Rook CI的进展和后续行动计划 关键细节 会议延迟： 由于Adam的参与问题，原定会议需推迟约一个月。 会议工具： 讨论了使用GitHub、etherpad或Google Drive作为文档共享工具，最终决定使用GitHub。 会议时间调整： 由于Nathan的时间冲突，讨论了调整会议时间，并决定使用Doodle工具进行投票选择合适的时间。 Rook CI： 讨论了Rook CI的必要性，以及如何使用新的API和任务来部署和测试Rook集群。 测试框架： 讨论了使用Totality作为测试框架的可行性，并讨论了其与Rook和DeepSea的差异。 Red Hat部署： 讨论了Red Hat如何部署Rook集群，包括使用Ansible和RPM包。 讨论的主要议题 会议延迟： 由于Adam无法参加，会议需要推迟，这可能会影响CI的效率。 会议工具： 选择合适的工具进行文档共享和协作。 Rook CI： 讨论如何实现Rook CI，包括使用Totality作为测试框架。 测试框架： 比较Totality与其他测试框架的差异，并评估其适用性。 Red Hat部署： 了解Red Hat如何部署Rook集群，以便更好地与上游流程集成。 决定的事项 推迟会议： 将会议推迟约一个月，等待Adam的参与。 使用GitHub： 使用GitHub作为文档共享和协作工具。 使用Doodle工具： 使用Doodle工具进行投票选择合适的时间。 实现Rook CI： 使用Totality作为测试框架，并开发新的API和任务来部署和测试Rook集群。 了解Red Hat部署： 了解Red Hat如何部署Rook集群，以便更好地与上游流程集成。 后续行动计划 Adam： 尽快加入会议，并参与讨论。 Nathan： 使用Doodle工具进行投票选择合适的时间。 开发团队： 开发新的API和任务，以支持Rook CI。 测试团队： 使用Totality作为测试框架，并编写测试用例。 集成团队： 了解Red Hat的部署流程，并与上游流程集成。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-30 :: Ceph Orchestration Meeting","slug":"2019-09-30_-_-_Ceph_Orchestration_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-30_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-30_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年10月（具体日期未提及） 参会人员： 多名参与者，包括负责分布式存储Ceph的研发人员、视频会议字幕翻译及总结人员 会议主题： 讨论Ceph存储项目中的多个议题，包括远程执行、类型检查、设计文档更新、OSD资源限制、Ceph 1.12版本发布、以及存储卷的发现和库存管理等。 关键细节与讨论议题： 远程执行： 讨论使用“用户mojo”代替“power-maker”进行远程执行的可能性。 提及一个开源播客，其中讨论了在本地主机上执行的部分。 讨论将“安全部署”拆分为“低云部分”和远程执行按钮的必要性。 类型检查： 提出在Rook模块中实现静态类型检查的需求，以确保API匹配。 讨论使用Brookes F giant Python库作为临时测试工具。 认为将此工具集成到Rook项目或Ceph项目中是有益的。 设计文档： 讨论替换OSD的设计文档，并强调删除和替换OSD实际上是一个连续的过程。 强调需要对设计文档进行彻底审查。 Ceph 1.12版本发布： 讨论Ceph 1.12版本的发布计划，包括下一轮修复和更新。 OSD资源限制： 讨论在升级过程中OSD使用过多内存并导致崩溃的问题。 认为需要为OSD设置默认的资源限制，以防未指定限制时使用全部内存。 存储卷发现和库存管理： 讨论使用Safestorage Volume Inventory（SVI）进行存储卷发现和库存管理的可能性。 讨论将SVI输出传递给编排器，以便生成磁盘组。 决定的事项： 将类型检查工具集成到Rook项目或Ceph项目中。 对设计文档进行最终审查。 计划Ceph 1.12版本的发布。 为OSD设置默认资源限制。 将SVI输出传递给编排器。 后续行动计划： 完成类型检查工具的集成。 完成设计文档的审查。 准备Ceph 1.12版本的发布。 实施OSD资源限制设置。 实现SVI输出传递给编排器的功能。 其他事项： 参会者讨论了Ceph 1.12版本中OSD升级和崩溃的问题。 讨论了Ceph集群中与文件系统相关的损坏问题。 讨论了Ceph集群中与SMB/CIFS文件系统相关的损坏问题。 讨论了Ceph集群中与RBD镜像相关的损坏问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-19 :: Ceph Performance Meeting","slug":"2019-09-19_-_-_Ceph_Performance_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-19_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-19_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Rob（公司技术团队）、Luke（公司技术团队）、会议主持人（Ceph研发人员） 会议内容： 一、本周Ceph社区动态 本周共有3个新的Pull Request（PR），包括： 修复BlueStore中未使用的计算错误，可能由Sager和Igor负责审查。 将OSD的默认截止值降低。 新的PR，不直接影响性能，但简化了OST操作的诊断。 其他更新包括： RGW最大使用率trim条目更改。 Loose Store引入了自动修复旧的Stata Festa问题。 更新了Eric的Teaches以在OST中进行更智能的过滤。 Sam的ODMG跟踪点PR。 MDS缓存内存限制仍在开发中。 Adam的Sharding工作有所进展，但遇到了RocksDB损坏问题。 二、公司集群性能问题 公司集群配置： 120个节点，每个节点一个OSD，OSD为RAID 5 24盘驱动器。 集群总容量约为3.5PB。 使用版本14.2.4。 节点运行Red Hat 7.6，内核版本5.2.3，网络为25G。 每个节点约768GB内存，约80个CPU。 性能问题： 在进行大数据分析时，读取和写入Rgw的性能出现明显下降，导致段错误和超时。 问题出现在读取数据并进行分析时，而不是在数据导入时。 集群中其他服务（如Elasticsearch和S3）的性能没有受到影响。 三、讨论和建议 建议检查OSD内存目标设置，考虑将其从默认的4GB增加到16GB或32GB。 建议检查Rgw的内存使用情况，确保没有超出限制。 建议检查Rgw配置，确保没有启用可能导致性能下降的选项。 建议尝试使用更小的RAID配置，例如RAID 1或RAID 10。 建议在Rgw容器中启用调试功能，以便收集更多错误信息。 四、后续行动计划 Rob和Luke将根据讨论的建议对集群进行配置更改，并观察性能是否有所改善。 Rob和Luke将记录所有更改和观察结果，并在下次会议中分享。 五、其他 会议中还讨论了Ceph的元数据存储、RocksDB性能优化、NVMe存储和对象存储等话题。 Seagate公司代表Philip和Mark介绍了他们的工作，包括自主存储设备和嵌入存储等。 总结： 本次会议讨论了公司Ceph集群的性能问题，并提出了相应的解决方案。参会人员将根据讨论结果进行配置更改，并观察性能是否有所改善。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-17 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-09-17_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-09-29T16:00:00.000Z","updated":"2019-09-30T16:00:00.000Z","comments":true,"path":"2019/09/30/2019-09-17_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/30/2019-09-17_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [所有参会人员姓名] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、项目进展 Ceph分布式存储： 项目成员在Ceph分布式存储方面取得了进展，但存在一些问题需要解决。 项目成员正在努力改进性能测试，并计划在Crimson版本中实施改进。 项目成员正在解决与双工回环相关的性能问题。 字幕翻译及总结： 项目成员对视频会议字幕进行了翻译和总结，并分享了各自的进展。 项目成员正在解决一些技术问题，例如UNIX域套接字测试用例的编写。 二、讨论的主要议题 Ceph分布式存储： 回归问题： 项目成员发现存在收入回归问题，需要进行修复。 多PG操作： 项目成员决定不支持在constant中执行多PG操作，以简化实现。 消息传递： 项目成员讨论了如何有效地传递消息，并决定将信息集中在一个消息中。 字幕翻译及总结： 单元测试： 项目成员正在改进单元测试，并添加了日志和阻塞超时。 性能问题： 项目成员讨论了与性能测试相关的问题，并计划在Crimson版本中实施改进。 三、决定的事项 Ceph分布式存储： 修复收入回归问题。 实现多PG操作的简化版本。 优化消息传递机制。 在Crimson版本中实施性能改进。 字幕翻译及总结： 完成UNIX域套接字测试用例的编写。 改进单元测试，并添加日志和阻塞超时。 解决与性能测试相关的问题。 四、后续行动计划 Ceph分布式存储： 项目成员将继续修复收入回归问题。 项目成员将实现多PG操作的简化版本。 项目成员将优化消息传递机制。 项目成员将在Crimson版本中实施性能改进。 字幕翻译及总结： 项目成员将完成UNIX域套接字测试用例的编写。 项目成员将改进单元测试，并添加日志和阻塞超时。 项目成员将解决与性能测试相关的问题。 五、其他事项 项目成员将讨论项目进度安排，并在Boojum频道进行讨论。 项目成员将分享各自的进展，并互相学习。 备注： 会议中提到的关键术语包括：Ceph、分布式存储、字幕翻译、总结、单元测试、性能测试、回归问题、多PG操作、消息传递、UNIX域套接字等。 会议中提到的关键英文原文包括：regression、multiple PG ops、constant、message、performance test、UNIX domain sockets等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-11:: Ceph DocUBetter Meeting","slug":"2019-09-11_-_-_Ceph_DocUBetter_Meeting","date":"2019-09-19T16:00:00.000Z","updated":"2019-09-20T16:00:00.000Z","comments":true,"path":"2019/09/20/2019-09-11_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/20/2019-09-11_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 一、会议主题 讨论FFS文档中的不足，以及Patrick及其团队为弥补这些不足所做的工作。 二、会议关键细节 1. 成功团队正在着手改进FFS文档，目前主要关注以下几个方面： - 介绍材料、自我评估和与架构相关的相关信息，以帮助用户更好地理解FFS的工作原理。 - 每两周评估文档改进效果，填补现有空白。 - 撰写文档，包括FFS架构图、高级需求、快速入门指南、CSS高级概念、分布式元数据缓存、MVS日志记录和元数据池、客户端直接访问数据池、Rados命名空间使用等。 目前正在进行的工作包括： 重新组织文档目录，使其更易于用户理解。 改进快速入门指南，避免提及过时的SEP部署。 完善CSS高级概念文档。 记录FFS的各个方面的文档。 提供子树管理的概述。 记录I/O格式文档。 需要改进的方面： 确定最终产品的具体外观和结构。 关注用户反馈的文档问题，并在etherpad上进行跟踪。 三、讨论的主要议题 1. 如何改进FFS文档，使其更易于用户理解。 2. 如何跟踪和解决文档中的问题。 3. 如何确定最终产品的具体外观和结构。 四、决定的事项 1. 成功团队将继续改进FFS文档，并每两周进行评估。 2. 关注用户反馈的文档问题，并在etherpad上进行跟踪。 3. 在一个月或一个半月后，再次召开会议，讨论文档改进进展。 五、后续行动计划 1. 成功团队继续撰写和改进FFS文档。 2. 关注用户反馈的文档问题，并在etherpad上进行跟踪。 3. 在一个月或一个半月后，再次召开会议，讨论文档改进进展。 关键词：FFS文档、成功团队、架构、用户理解、快速入门指南、CSS高级概念、分布式元数据缓存、MVS日志记录、元数据池、客户端直接访问数据池、Rados命名空间使用、I/O格式、etherpad","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-10 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-09-10_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-09-19T16:00:00.000Z","updated":"2019-09-20T16:00:00.000Z","comments":true,"path":"2019/09/20/2019-09-10_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/20/2019-09-10_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Jemaine（负责Ceph存储），Tom（负责集成测试），Dr. Merlin（负责代码调试），Conscious（负责测试），其他相关人员 会议内容： 一、Ceph存储集成测试 Jemaine正在努力将Ceph存储集成到Jenkins中，并取得了一些进展。 Tom提出关于如何对Commission进行CBD测试的疑问，建议使用CBT进行测试。 Jemaine将继续测试Jenkins集成，并随后与Riddick合作启用RBD和日志恢复功能。 二、代码调试 Dr. Merlin在调试代码时发现，在GDB环境中，某些代码修改后会导致promise broken异常消失。 Conscious提出，在OST启动时出现网络问题，导致get future失败。 Dr. Merlin认为这是一个bug，需要进一步调查。 三、测试问题 Conscious在测试中发现，某些测试输出被Jenkins控制台吞没，导致无法查看完整日志。 Jemaine建议尝试重现问题，并希望Conscious能够提供更多信息。 四、其他事项 Conscious提出，在编译单元测试时，存在大量无法丢弃的future警告，建议进行审计和注释。 Jemaine表示，已修复大部分future non discard future问题，但仍需关注OSD部分。 Conscious建议记录丢弃future的原因，例如使用gate确保实例的生命周期。 五、行动计划 Jemaine继续测试Jenkins集成，并与Riddick合作启用RBD和日志恢复功能。 Dr. Merlin和Conscious继续调查promise broken异常问题。 Conscious尝试重现Jenkins测试问题，并提供更多信息。 Conscious和Jemaine对无法丢弃的future进行审计和注释。 六、后续会议 下次会议时间待定。 关键词： Ceph存储 Jenkins集成 CBD测试 CBT测试 RBD 日志恢复 GDB promise broken future non discard future gate OSD","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-16 :: Ceph Orchestration Meeting","slug":"2019-09-16_-_-_Ceph_Orchestration_Meeting","date":"2019-09-19T16:00:00.000Z","updated":"2019-09-20T16:00:00.000Z","comments":true,"path":"2019/09/20/2019-09-16_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/20/2019-09-16_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 会议记录者，Jonathan，DePaul，Percept，Travie，Adam Freeman等 会议主题： 讨论Ceph项目的进展、问题及后续行动计划。 关键细节： Estate Orchestrator： Jonathan提到已将Estate Orchestrator的更改推送到分支，以便继续工作。他还提到了PR 3026，该PR使得completions可组合，这对于桌面和仪表板非常重要。 Cuban ettus events bekata Nautilus： 由于存在tracker issue 41737，Nautilus模块遇到了阻塞。该问题与两个端口有关，需要在master分支中修复。 Rook 1.0： Rook 1.0已发布，目前看起来一切顺利。计划在本周进行补丁发布。 Orchestrator问题： 讨论了关于polls的持续时间和reclaim策略的问题。决定更改默认策略以保留规则，并考虑在self中启用secure pull deletion标志。 Rook CI： 讨论了Rook CI的未来。短期内，将更新旧的Jenkins实例。长期目标是实现自动化，类似于F CIA。会议决定将讨论移至上游，并与Greg和Adam Freeman一起讨论。 决定事项： 将修复Nautilus模块的tracker issue 41737。 计划进行Rook 1.0的补丁发布。 更改默认策略以保留规则，并考虑在self中启用secure pull deletion标志。 将Rook CI讨论移至上游，并与Greg和Adam Freeman一起讨论。 后续行动计划： Jonathan将继续工作在Estate Orchestrator上。 讨论修复Nautilus模块的tracker issue 41737。 计划进行Rook 1.0的补丁发布。 讨论并实施新的reclaim策略。 讨论并实施Rook CI的自动化。 将讨论移至上游，并与Greg和Adam Freeman一起讨论。 关键词： Estate Orchestrator PR 3026 Nautilus Rook 1.0 Orchestrator polls reclaim策略 Rook CI","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-12 :: Ceph Performance Meeting","slug":"2019-09-12_-_-_Ceph_Performance_Meeting","date":"2019-09-19T16:00:00.000Z","updated":"2019-09-20T16:00:00.000Z","comments":true,"path":"2019/09/20/2019-09-12_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/20/2019-09-12_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Mark, Garrett, Eric, Casey, Sage, Neha, Igor, OSHA, Ping, Adam, Josh, 等 会议主题： Ceph分布式存储项目进展讨论 主要讨论议题： SATA SSD利用率： 讨论了SATA SSD的利用率，指出其接近最大吞吐量，但具体取决于设备性能和IO负载类型。 Luminous代码改进： 讨论了Luminous代码的改进，包括性能提升和功能增强。 CLS代码中的过滤功能： 讨论了在OSD中的CLS代码中实现过滤功能的改进，包括对性能提升和减少网络使用量的影响。 bucket reshaping性能： 讨论了bucket reshaping的性能，包括在resharding过程中允许客户端写入和优化锁定机制。 4K金属块大小： 讨论了在OMAP中使用4K金属块大小对性能和空间利用率的影响。 小对象在OMAP中的存储： 讨论了在OMAP中使用小对象（小于4K）存储的改进，包括对性能和空间利用率的影响。 决定事项： 推进Luminous代码的改进，并迁移到Nautilus代码库进行对比测试。 评估CLS代码中过滤功能的性能提升和网络使用量减少。 研究bucket resharding的性能和优化锁定机制。 在OMAP中使用4K金属块大小进行测试，并评估其对性能和空间利用率的影响。 对小对象在OMAP中的存储进行改进，并评估其对性能和空间利用率的影响。 后续行动计划： Mark将继续推进Luminous代码的改进。 Eric将评估CLS代码中过滤功能的性能提升和网络使用量减少。 Casey将研究bucket resharding的性能和优化锁定机制。 Josh将测试4K金属块大小在OMAP中的性能和空间利用率。 OSHA和Ping将评估小对象在OMAP中的存储改进。 其他事项： 会议中提到了许多其他PR和改进，包括自动更新、测试、性能优化等。 会议讨论了如何进行基准测试和验证回归。 会议讨论了如何优化小对象存储。 关键词： Ceph Luminous Nautilus SATA SSD CLS bucket resharding 4K金属块大小 OMAP 小对象 基准测试 回归 性能优化","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-11:: Ceph Orchestration Meeting","slug":"2019-09-11_-_-_Ceph_Orchestration_Meeting","date":"2019-09-19T16:00:00.000Z","updated":"2019-09-20T16:00:00.000Z","comments":true,"path":"2019/09/20/2019-09-11_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/20/2019-09-11_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph集群中设备管理及Orchestrator模块的优化 完成项（Completion）的实现和改进 Dashboard的锁机制 会议内容： 一、设备管理 讨论了如何通过Orchestrator模块实现设备管理，包括创建新的OSD（Object Storage Device）。 确定了从简单设备组开始，逐步过渡到更复杂的设备组的策略。 计划实现从单个设备创建OSD的功能，并考虑支持多选设备创建多个OSD。 二、完成项（Completion）实现 讨论了Ceph中完成项的改进，包括合并读取和写入完成项，使用统一的完成项类。 介绍了新的完成项结构，其中完成项在获得结果后立即完成，但进度引用（Progress Reference）会保持活跃，直到OSD实际创建完成。 讨论了使用进度引用进行锁定的必要性，以避免在Dashboard中同时执行多个OSD创建操作。 三、Dashboard的锁机制 讨论了在Dashboard中实现锁机制的必要性，以避免同时进行多个系统更改操作。 确定了一种基于进度引用的锁定策略，用于在Dashboard中阻止创建新的OSD，直到当前操作完成。 讨论了不同Orchestrator模块中锁定机制可能存在的差异，并计划在Orchestrator中实现通用的锁定机制。 四、其他 讨论了Rook模块的性能问题，并确认引入事件监听器后性能问题已基本解决。 讨论了Dashboard中可能需要添加分页功能。 行动计划： 实现从单个设备创建OSD的功能。 优化完成项结构，并实现基于进度引用的锁定机制。 在Orchestrator中实现通用的锁定机制。 在Dashboard中实现分页功能。 备注： 部分内容涉及Ceph相关领域英文原文，如“Completion”、“Progress Reference”、“Orchestrator”等。 会议中提到的“Kiva”和“Brooke”可能是项目或模块的名称，具体含义需要根据实际情况进行解释。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-21 :: Ceph Testing Meeting","slug":"2019-08-21_-_-_Ceph_Testing_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-05T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-21_-_-_Ceph_Testing_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-21_-_-_Ceph_Testing_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： 多位Ceph研发人员及测试人员 会议主题： Ceph项目进展、测试模块、代码合并及后续行动计划 会议内容： 1. 代码合并与测试模块： 目前Ceph项目的代码合并尚未完成，主要问题在于构建集成部分需要处理。 新的Manager模块需要测试，但目前缺乏测试环境和测试方法。 Sage提到Dan预计明天会发布新的SEF（可能指某种测试文件或工具），这将有助于测试新模块。 2. 测试环境： 目前Ceph项目的测试环境相对简单，主要是文档和流程测试，以及与Red Hat OpenShift容器存储产品的集成测试。 对于Surf产品中的未测试部分，目前没有明确的测试计划。 3. 人力资源与集成： 目前Ceph项目的人力资源较为紧张，缺乏足够的测试人员。 集成方面，目前没有计划将Authority和Person模块与其他模块进行整合。 4. 其他： 关于CentOS 8i的迁移，目前尚未完成，预计在CentOS 8发布后进行。 会议中提到一个关于迁移的pull request，但由于Python 3迁移问题，该请求已基本废弃。 决定事项： 加快代码合并进度，解决构建集成问题。 建立新的测试环境和测试方法，确保新模块的稳定性。 评估人力资源配置，增加测试人员。 研究Authority和Person模块与其他模块的整合方案。 后续行动计划： 由Dan负责发布SEF，并协助测试新模块。 Alfredo和团队负责优化测试环境和测试方法。 人力资源部门负责招聘测试人员。 技术团队评估Authority和Person模块的整合方案。 备注： 会议中多次提到“build integrations”和“container”等关键词，表明构建集成和容器技术是当前Ceph项目关注的重点。 会议中提到的“Python 3”和“CentOS 8i”等关键词，表明Python 3迁移和CentOS 8i迁移是当前Ceph项目面临的技术挑战。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-20 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-08-20_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-05T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-20_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-20_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间：[请填写日期和时间] 会议地点：[请填写地点] 参会人员：[请填写参会人员名单] 一、会议关键细节 会议讨论了Ceph存储系统在不同场景下的性能优化问题。 讨论了Ceph存储系统测试工具的改进和性能测试的持续时间。 讨论了Ceph存储系统中的线程创建和销毁问题，以及如何解决线程卡住的问题。 讨论了Ceph存储系统中UNIX域套接字的实现和改进。 讨论了Ceph存储系统中的代码审查和问题反馈。 二、主要议题 性能优化：针对Ceph存储系统在不同场景下的性能问题，参会人员讨论了可能的优化方案，包括测试工具的改进、性能测试的持续时间等。 线程问题：讨论了Ceph存储系统中线程创建和销毁的问题，以及如何解决线程卡住的问题。 UNIX域套接字：讨论了Ceph存储系统中UNIX域套接字的实现和改进，包括如何保证其功能与原生实现一致。 代码审查和反馈：讨论了Ceph存储系统中的代码审查和问题反馈机制，以及如何提高代码质量和效率。 三、决定的事项 针对性能优化问题，参会人员决定进行更深入的测试和性能分析，以便找到优化方案。 针对线程问题，参会人员决定进一步研究线程卡住的原因，并寻找解决方案。 针对UNIX域套接字，参会人员决定继续改进其实现，并确保其功能与原生实现一致。 针对代码审查和反馈，参会人员决定加强代码审查力度，提高代码质量。 四、后续行动计划 针对性能优化问题，参会人员将在下周进行更深入的测试和性能分析。 针对线程问题，参会人员将继续研究线程卡住的原因，并寻找解决方案。 针对UNIX域套接字，参会人员将继续改进其实现，并确保其功能与原生实现一致。 针对代码审查和反馈，参会人员将加强代码审查力度，提高代码质量。 五、备注 会议中提到了Ceph存储系统测试工具的改进和性能测试的持续时间，但未进行详细讨论。 会议中提到了Ceph存储系统中的线程创建和销毁问题，但未找到具体的解决方案。 会议中提到了Ceph存储系统中UNIX域套接字的实现和改进，但未进行详细讨论。 会议中提到了Ceph存储系统中的代码审查和问题反馈机制，但未进行详细讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-28:: Ceph DocUBetter Meeting","slug":"2019-08-28_-_-_Ceph_DocUBetter_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-05T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-28_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-28_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 参会人员： Andy Young, Brad, Josh, [其他参会人员] 会议目的： 讨论Ceph社区文档中存在的差距，并探讨改进文档结构和内容的方法，以更好地满足不同层次用户的需求。 关键议题： 文档差距： C++ API文档不完整 Barberry和librbd API文档不完善 蓝鲸存储文档缺乏 设备推荐和内核版本选择文档陈旧 升级流程文档缺失或不完整 文档改进方向： 创建面向初学者和高级用户的文档 梳理现有文档结构，提供清晰的用户路径 补充缺失的文档内容，例如蓝鲸存储、设备推荐、升级流程等 优化配置文档，实现自动化生成 提供清晰的安装指南，包括使用Ceph-deploy和Ansible 决定事项： 由Brad负责C++ API文档的编写 由Josh负责蓝鲸存储文档的编写 由Andy Young负责设备推荐文档的更新 创建Trello看板，用于跟踪文档改进任务 安排后续会议，继续讨论文档改进事宜 后续行动计划： Brad、Josh、Andy Young分别负责各自文档的编写和更新 创建Trello看板，跟踪文档改进任务 安排后续会议，讨论文档改进进展和后续计划 备注： 会议中提到了多个文档和项目，包括Barberry、librbd、蓝鲸存储、设备推荐、升级流程、Ceph-deploy、Ansible等。 会议强调了文档质量的重要性，并鼓励社区成员积极参与文档编写和更新工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-26 :: Ceph Orchestration Meeting","slug":"2019-08-26_-_-_Ceph_Orchestration_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-05T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-26_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-26_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Pete, Travis, Blaine, Ben等 会议主题： Rook模块开发进度、Ceph集群管理、API设计等 关键细节与议题： 人员情况： Specter将在9月份回归。 Travis正在处理一些与Kubernetes事件相关的模块审查工作。 Rook模块开发： 特斯拉（Tesla）已经完成了Rook模块的PM工作，并创建了一些代码。 Paul希望稍后进行修改，Pete表示可以接受。 需要解决Rook模块内部锁消息的问题，目前没有测试，只能手动测试。 Rook 1.1版本： 特斯拉希望在1.1版本中加入一些新功能。 目标发布日期是下周，但可能会比较紧张。 已经合并了修复Yum安装问题的PR，但部分构建失败，需要进一步调查。 API设计： Travis正在尝试解决Rook orchestrator API中操作不可组合的问题。 需要改进API，使其使用futures和promises。 需要设计一种方法来检测哪些主机会受到操作的影响，以便确保不会同时部署OSD。 其他议题： 讨论了如何从orchestrator直接运行作业，需要更多设计。 讨论了如何使用host labels进行放置操作。 决定事项： 继续推进Rook 1.1版本的发布。 解决Rook模块内部锁消息的问题。 改进Rook orchestrator API。 设计一种方法来检测主机受到操作的影响。 后续行动计划： 特斯拉继续完成Rook模块的修改工作。 Travis调查Yum安装问题。 设计并实现改进的Rook orchestrator API。 设计一种方法来检测主机受到操作的影响。 备注： 下周美国将有一个假期，可能影响工作进度。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-02 :: Ceph Orchestration Meeting","slug":"2019-09-02_-_-_Ceph_Orchestration_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-06T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-09-02_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-09-02_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年8月某日 参会人员： Travis（远程）、Kiki（远程）、其他与会人员 会议主题： 讨论Ceph集群中OSD替换、驱动器组（Drive Group）以及Cubanetosca事件模块的测试问题。 关键细节： OSD替换： Travis提到，在之前的会议上已经讨论了替换名为“toasty”的OSD，并询问是否有人员负责此事。现在Kiki回归，可以进行讨论。 讨论了OSD替换的步骤，包括移除磁盘和创建新设备。 Travis表示，API中已经移除了replace OSD的调用，因为替换OSD的操作实际上是销毁旧OSD并创建新OSD的组合操作。 讨论了驱动器组（Drive Group）在OSD替换中的作用，以及是否需要持久化存储驱动器组信息。 认为驱动器组规范目前并不实用，因为它增加了复杂性，并没有带来太多实际价值。 认为需要从用户界面层面获取反馈，以确定是否需要持久化存储驱动器组信息。 驱动器组： 讨论了驱动器组在OSD替换中的作用，以及是否需要持久化存储驱动器组信息。 认为驱动器组规范目前并不实用，因为它增加了复杂性，并没有带来太多实际价值。 认为需要从用户界面层面获取反馈，以确定是否需要持久化存储驱动器组信息。 Cubanetosca事件模块测试： 讨论了Cubanetosca事件模块缺乏测试的问题。 了解到有一个名为Adam的开发者正在尝试为Rook和Orchestrator创建测试套件，并希望测试Cubanetosca事件模块。 认为为Cubanetosca事件模块添加测试套件是一个好主意。 决定的事项： 继续讨论OSD替换和驱动器组规范，并从用户界面层面获取反馈。 跟进Cubanetosca事件模块的测试工作。 后续行动计划： Kiki将参加9月6日的任务板会议，并讨论驱动器组规范和OSD替换的问题。 与Adam联系，了解Cubanetosca事件模块测试的进展情况。 备注： 会议中提到了一些Ceph相关的英文关键词，如OSD、Drive Group、Cubanetosca等。 会议中涉及了一些技术细节，可能需要具备一定的Ceph知识才能理解。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-22 :: Ceph Performance Meeting","slug":"2019-08-22_-_-_Ceph_Performance_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-05T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-22_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-22_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 项目进展： 已合并的PR： 增加East Heart缓冲区大小至64K Sage的64K Yarn调整 待处理的PR： Casey的关于扩展LTTE Angie跟踪点的PR Alec关于64K大小的Yarn的PR Sam的关于扩展LTTE Angie跟踪点的PR 雷达后端复制的PR（Radek审查，有关于CPU使用率的担忧） Ken Adams的PR（Josh审查，表示感谢） 调整MVS缓存内存限制的PR（仍在进行中） 分布式数据缓存RGW的PR（Mark Hogan正在工作） 其他进展： Igor更新了其新的较小版本的Blue Store，该版本可以智能地选择文件存储位置。 Eager功能正在开发中。 Sam的PR旨在扩展LTTE Angie跟踪点，但存在一些关于安全性的担忧。 雷达后端的PR已通过审查，但仍有一些关于CPU使用率的担忧。 Ken Adams的PR已通过Josh的审查。 MVS缓存内存限制的调整PR仍在进行中。 分布式数据缓存RGW的PR由Mark Hogan负责。 讨论议题： 新的S3基准测试： 会议讨论了新的S3基准测试，该测试旨在提供一个轻量级、快速、易于使用的工具，以展示Ceph的功能。 该测试旨在解决现有基准测试工具的不足，例如GetPut的速度较慢，并且需要大量的CPU资源。 测试结果表明，Ceph在多分片情况下具有更高的性能。 桶重组： 会议讨论了桶重组的性能问题，特别是关于CPU使用率和延迟的问题。 讨论了将桶重组检查移至后台线程的提案，以减少性能影响。 讨论了通过调整重组算法来提高性能的提案。 对象存储优化： 讨论了对象存储优化，特别是关于减少写放大和空间放大的问题。 讨论了使用T-rex DB等工具来优化对象存储的提案。 决定事项： 将继续开发新的S3基准测试。 将继续优化桶重组和对象存储。 将审查和合并待处理的PR。 后续行动计划： 继续开发新的S3基准测试。 优化桶重组和对象存储。 审查和合并待处理的PR。 讨论和实施关于桶重组和对象存储优化的提案。 备注： 会议中提到了一些计算机科学/ceph相关领域英文原文的关键词，例如： Ceph Blue Store Eager LTTE Angie OSD RGW S3 T-rex DB RocksDB Rados PG PG log PG info CLS CLS igw OMAP Write amplification Space amplification","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-03 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-09-03_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-06T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-09-03_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-09-03_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间：[请填写具体日期和时间] 会议地点：[请填写会议地点] 参会人员：Keefer，其他研发人员 会议内容： 性能测试与集成 Keefer汇报了上周关于性能测试的工作，比较了基准测试与改进后的结果。 下一步计划将测试结果集成到Jenkins中，并探索不同的集成方法，如GitHub API。 预计在本周内完成集成，以便在GitHub上展示测试结果的差异。 GitHub API使用 讨论了使用GitHub API展示测试结果的可行性，包括在PR页面添加检查标签。 决定利用GitHub API的灵活性来展示更详细的测试结果。 调试与代码问题 Keefer在调试过程中遇到了一些问题，特别是在GDB环境中。 讨论了代码在不同环境下的行为差异，以及如何解决这些问题。 Crimson项目 在Crimson项目中，讨论了以下议题： 观察通知机制的实施。 对大PG对象上下文的细粒度锁定。 系统的预定订单。 讨论了即将到来的峰会，并确认了参会人员。 Sister项目 讨论了Sister项目的以下议题： 在Sister中修复一个小的bug。 支持UNIX域套接字。 关于连接接受的讨论，包括POSIX套接字的处理方式。 决定将修复的代码提交到Sister项目的分支，并定期与上游合并。 性能测试 讨论了在性能测试中使用Rkt和CBT进行性能比较的必要性。 提出了在测试中关闭单元测试以避免性能影响的建议。 后续行动计划 Keefer将继续工作，解决调试问题和性能测试。 其他研发人员将继续工作在各自的项目中，并准备即将到来的峰会。 备注： - 会议中提到了一些计算机科学/ceph相关领域的英文关键词，包括：GitHub API, Jenkins, performance tests, POSIX sockets, UNIX domain sockets, PG objects, connection acceptance, debugging, performance comparison, Rkt, CBT等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-29 :: Ceph Performance Meeting","slug":"2019-08-29_-_-_Ceph_Performance_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-06T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-29_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-29_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 未知 参会人员： 多位 Ceph 项目成员 会议主题： Ceph 项目进展讨论，重点讨论 RGW 性能优化、OSD 性能优化、代码重构等议题。 关键细节： RGW 性能优化： 讨论了通过优化目录条目过滤、减少解码操作、优化 JSON 格式输出等方式提升 RGW 性能。 探讨了使用 OMAP 缓存来减少重复数据访问，并提高数据检索效率。 讨论了优化 OSD 操作，减少内存占用，提高数据处理速度。 OSD 性能优化： 讨论了优化目录条目处理，减少从 RocksDB 到 RGW 的数据传输。 讨论了优化数据哈希算法，支持数据排序，避免重复读取。 讨论了优化 JSON 格式输出，减少数据传输量。 代码重构： 讨论了将 OSD 操作中的 case 语句拆分成独立函数，提高代码可读性和可维护性。 讨论了使用新的 JSON 解析库，优化数据解析效率。 主要议题： 如何进一步优化 RGW 性能，特别是目录条目处理和 JSON 格式输出。 如何优化 OSD 操作，减少内存占用，提高数据处理速度。 如何使用 OMAP 缓存来提高数据检索效率。 如何优化数据哈希算法，支持数据排序。 决定的事项： 将继续优化 RGW 性能，重点关注目录条目处理和 JSON 格式输出。 将继续优化 OSD 操作，减少内存占用，提高数据处理速度。 将探索使用 OMAP 缓存来提高数据检索效率。 将优化数据哈希算法，支持数据排序。 将将 OSD 操作中的 case 语句拆分成独立函数，提高代码可读性和可维护性。 后续行动计划： 各成员将继续推进相关优化工作。 将定期召开会议，讨论项目进展和遇到的问题。 将及时更新项目文档，记录项目进展和决策。 其他事项： 讨论了将小数据存储到 X-ADDERS 的提议，并决定不采纳该提议。 讨论了将小对象存储到 RocksDB 的提议，并决定将其作为备选方案进行研究。 关键词： RGW OSD 性能优化 OMAP 缓存 数据哈希 JSON 格式 代码重构","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-28 :: Ceph Science User Group Meeting","slug":"2019-08-28_-_-_Ceph_Science_User_Group_Meeting","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-06T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-08-28_-_-_Ceph_Science_User_Group_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-08-28_-_-_Ceph_Science_User_Group_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： 来自全球多个机构的Ceph用户和开发者，包括： 美国威斯康星大学 英国萨里大学 瑞士苏黎世大学 美国印第安纳大学 美国密歇根大学 英国南安普顿大学 美国罗切斯特理工学院 英国牛津大学 美国橡树岭国家实验室 红帽公司 会议主题： Ceph用户的使用案例和经验分享 Ceph的性能优化和问题解决 Ceph的未来发展方向 Ceph社区建设和活动 会议内容： Ceph使用案例： 美国威斯康星大学使用Ceph作为OpenStack的块存储和对象存储，并用于科学计算和大数据分析。 英国萨里大学使用Ceph作为对象存储，并用于视频流媒体和备份。 瑞士苏黎世大学使用Ceph作为对象存储，并用于高性能计算和科学数据存储。 美国印第安纳大学使用Ceph作为对象存储，并用于数据传输和共享。 美国密歇根大学使用Ceph作为对象存储，并用于数据共享和备份。 英国南安普顿大学使用Ceph作为对象存储，并用于科学计算和大数据分析。 美国罗切斯特理工学院使用Ceph作为文件系统和对象存储，并用于高性能计算和虚拟化。 英国牛津大学使用Ceph作为对象存储，并用于数据备份和共享。 美国橡树岭国家实验室使用Ceph作为对象存储，并用于数据存储和备份。 红帽公司使用Ceph作为文件系统和对象存储，并用于云服务和数据中心。 Ceph性能优化和问题解决： 讨论了Ceph性能优化的一些方法，例如使用NVMe硬盘、优化存储池配置、使用性能监控工具等。 分享了一些Ceph常见问题的解决方法，例如客户端挂起、MDS服务器内存不足、数据损坏等。 Ceph未来发展方向： 讨论了Ceph的一些未来发展方向，例如支持更多协议、提高性能、增强安全性等。 Ceph社区建设和活动： 讨论了如何加强Ceph社区建设，例如组织线上和线下活动、建立用户交流平台等。 计划在瑞士日内瓦举办Ceph Day活动，并邀请Ceph用户和开发者参加。 行动计划： 继续组织Ceph用户会议，分享经验和讨论问题。 加强Ceph社区建设，建立用户交流平台。 在瑞士日内瓦举办Ceph Day活动。 推动Ceph的发展，提高其性能和安全性。 关键词： Ceph OpenStack 对象存储 块存储 高性能计算 数据备份 数据共享 社区建设","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-09-04 :: Ceph Developer Monthly","slug":"2019-09-04_-_-_Ceph_Developer_Monthly","date":"2019-09-05T16:00:00.000Z","updated":"2019-09-06T16:00:00.000Z","comments":true,"path":"2019/09/06/2019-09-04_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/09/06/2019-09-04_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员 会议主题： 返回写入缓冲区或数据： 讨论在写操作中记录返回值和输出缓冲区，以及如何处理输出缓冲区的内容。 集群镜像简化： 讨论简化集群镜像设置的过程，以便于用户使用。 关键细节与讨论： 1. 返回写入缓冲区或数据 背景： 目前，Ceph只记录写操作的返回值，并显式清除输出缓冲区。这导致在某些情况下无法获取完整的操作信息。 解决方案： 在返回值旁边添加一个返回值长度字段。 更新OSD的解码器以填充该字段。 设置最大返回值长度为32字节。 提供配置选项以控制最大返回值长度。 在PG日志条目或dup日志条目中记录返回值。 担忧： 需要确保输出缓冲区不会被填充随机数据。 需要考虑如何处理超出配置选项大小的缓冲区。 2. 集群镜像简化 背景： 为了简化Rook集群镜像设置，需要改进Ceph集群镜像功能。 解决方案： 提供一个命令，用于输出一个base64编码的JSON文件，包含集群信息。 在另一个集群上使用该命令导入JSON文件。 使用RBD镜像池和FSID来标识集群。 提供可选的集群友好名称。 支持单向和双向镜像。 讨论： 是否需要在bootstrap步骤中创建临时用户。 是否需要在集群B上创建本地用户以进行通信。 如何跟踪集群模式（例如，图像模式和完整模式）。 后续行动计划： 返回写入缓冲区或数据： 完成代码更改，并添加配置选项。 在主分支上合并更改，并观察一段时间以确保没有问题。 集群镜像简化： 完成CLI命令和API的更新。 完成文档更新。 其他事项： 跟踪Ceph manager在启用新模块时重启的问题。 完成对象删除功能，删除所有克隆和快照。 统一Ceph monitor和daemon命令。 备注： 会议中提到了一些Ceph相关的英文关键词，如PG、OSD、RBD、monitor、daemon等。 会议讨论了一些计算机科学和Ceph领域的概念，如集群镜像、日志条目、配置选项等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-19 :: Ceph Orchestration Meeting","slug":"2019-08-19_-_-_Ceph_Orchestration_Meeting","date":"2019-08-18T16:00:00.000Z","updated":"2019-08-19T16:00:00.000Z","comments":true,"path":"2019/08/19/2019-08-19_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/19/2019-08-19_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： Petrus, Francis, Steve, Mario, Chief, William, Trekker, Joey, etc. 会议主题： Ceph分布式存储项目讨论，包括OSD替换、功能冻结、Rook与Orchestrator的兼容性等。 关键细节与讨论议题： OSD替换： Petrus提到，替换OSD目前存在痛点，因为orchestrator API中缺少必要的代码支持。 讨论了通过orchestrator API调用set_volume创建新OSD并指定现有OSD ID的需求。 认为orchestrator在UI层面提供替换OSD的界面将有助于简化流程。 功能冻结： Petrus提到，Ceph 1.1版本功能冻结将在本周五进行，预计9月初发布。 讨论了可能影响Orchestrator的功能，如disruption budgets、bucket object bucket claims等。 Rook与Orchestrator兼容性： Petrus表示，Orchestrator团队将专注于确保最新master分支的Rook与最新Rook版本兼容。 讨论了Orchestrator与Rook之间的兼容性问题，以及未来版本的规划。 其他议题： 讨论了Ceph集群的启动过程，以及是否需要使用safethought conf等配置文件。 讨论了将override config代码从CRD中移除的PR。 决定事项： Petrus将与Chief讨论如何改进Orchestrator的UI，以简化OSD替换流程。 Petrus将关注Ceph 1.1版本的发布，确保Orchestrator的兼容性。 Joey将关注将override config代码从CRD中移除的PR。 后续行动计划： Petrus将与Chief讨论并改进Orchestrator的UI。 Petrus将关注Ceph 1.1版本的发布，并与Rook团队沟通兼容性问题。 Joey将关注PR的进展，并确保override config代码从CRD中移除。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-15 :: Ceph Performance Meeting","slug":"2019-08-15_-_-_Ceph_Performance_Meeting","date":"2019-08-14T16:00:00.000Z","updated":"2019-08-15T16:00:00.000Z","comments":true,"path":"2019/08/15/2019-08-15_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/15/2019-08-15_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Igor、Sam、Jinping、Egor、Adam、Sonia、Josh等 会议主题： Ceph社区本周工作进展、关键议题讨论及后续行动计划 会议内容： 一、本周工作进展 Igor： 提交了关于优化BlueStore中设备空间利用的pull request，通过利用现有的路径模型来简化空间管理，提高效率。 Sam： 提交了关于BlueStore QoS功能的pull request，通过添加跟踪点来收集数据，以便更准确地设置节流值。 对BlueStore的NVMe性能进行了分析，发现并发性对性能有显著影响。 Jinping： 提交了关于BlueStore锁定的pull request，旨在减少锁定，提高性能。 Egor： 提交了关于BlueStore性能优化的pull request，包括减少锁获取和更新finisher。 Adam： 继续推进BlueStore的优化工作，包括将IOU ring相关的工作移到后台运行。 对BlueStore的Object存储进行了优化，将对象拆分为更小的提交，以便更容易审查。 Sonia： 探索了使用4K块大小的BlueStore性能，发现在某些情况下，性能有所提升。 对BlueStore的Alligator aging测试进行了改进。 二、讨论的主要议题 BlueStore性能优化： 如何优化BlueStore的性能，包括锁管理、路径模型、节流值设置等。 如何通过添加跟踪点来收集数据，以便更准确地设置节流值。 如何根据不同的设备类型调整节流值。 BlueStore QoS功能： 如何实现BlueStore的QoS功能，以满足不同用户的需求。 如何通过节流值控制不同用户的I/O请求。 BlueStore与RBD的兼容性： 如何确保BlueStore与RBD的兼容性。 如何处理不同存储引擎之间的性能差异。 三、决定的事项 Igor： 尽快审查Igor的优化pull request。 Sam： 将跟踪点集成到CDT中，并进行QoS实验。 Adam： 继续推进BlueStore的优化工作，并与社区进行讨论。 Sonia： 与社区讨论4K块大小对BlueStore性能的影响。 四、后续行动计划 继续优化BlueStore的性能。 实现BlueStore的QoS功能。 确保BlueStore与RBD的兼容性。 对不同存储引擎进行性能测试。 五、其他事项 会议中讨论了BlueStore的Alligator aging测试，并决定对其进行改进。 会议中讨论了BlueStore的4K块大小问题，并决定进行更多测试。 总结： 本周Ceph社区在BlueStore性能优化、QoS功能实现等方面取得了进展，并讨论了后续的工作计划。社区将继续努力，为用户提供更好的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-13 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-08-13_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-08-13T16:00:00.000Z","updated":"2019-08-14T16:00:00.000Z","comments":true,"path":"2019/08/14/2019-08-13_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/14/2019-08-13_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： [所有参会人员姓名] 会议主题： Ceph项目进展及讨论 一、关键细节 性能测试与监控： [姓名] 在Jenkins中添加了新的性能测试脚本，基于Redick的工作，可以单行命令运行CBT测试。 下一步计划编写一个工具，用于比较测试结果与基线，并投票决定是否上线。 [姓名] 将对RocksDB进行性能测试，以确定未来路线。 代码审查与提交： [姓名] 正在审查[姓名]的代码更改，用于运行性能测试。 [姓名] 完成了对Ceph集群性能测试的代码审查。 [姓名] 提交了支持UNIX域套接字的PR，并计划改进实现方式。 [姓名] 正在实施Crimson的TLS支持。 Crimson项目： [姓名] 正在解决Crimson中与heap profile冲突的问题。 [姓名] 讨论了使用Cassandra作为RocksDB替代品的可能性。 [姓名] 讨论了基于Samsung技术的存储设备，该技术可以减少CPU使用。 会议与活动： 讨论了在即将到来的Ceph Day会议前或后的团队会议安排。 讨论了在即将到来的Ceph Day会议期间可能进行的讨论。 二、讨论的主要议题 性能测试与监控： 如何更有效地进行性能测试和监控。 如何将性能测试结果与基线进行比较。 代码审查与提交： 如何提高代码审查的效率和质量。 如何确保代码更改符合Ceph项目的标准。 Crimson项目： 如何解决Crimson中存在的问题。 如何选择合适的替代技术。 会议与活动： 如何安排Ceph Day会议期间的团队会议。 如何在会议期间进行有效的讨论。 三、决定的事项 性能测试与监控： [姓名] 将编写一个工具，用于比较测试结果与基线。 [姓名] 将进行RocksDB的性能测试。 代码审查与提交： [姓名] 将继续审查[姓名]的代码更改。 [姓名] 将继续进行Ceph集群性能测试的代码审查。 [姓名] 将改进UNIX域套接字的实现方式。 [姓名] 将实施Crimson的TLS支持。 Crimson项目： [姓名] 将解决Crimson中与heap profile冲突的问题。 [姓名] 将评估使用Cassandra作为RocksDB替代品的可能性。 [姓名] 将继续跟踪基于Samsung技术的存储设备的进展。 会议与活动： 将在Ceph Day会议期间安排团队会议。 四、后续行动计划 性能测试与监控： [姓名] 将编写一个工具，用于比较测试结果与基线。 [姓名] 将进行RocksDB的性能测试。 代码审查与提交： [姓名] 将继续审查[姓名]的代码更改。 [姓名] 将继续进行Ceph集群性能测试的代码审查。 [姓名] 将改进UNIX域套接字的实现方式。 [姓名] 将实施Crimson的TLS支持。 Crimson项目： [姓名] 将解决Crimson中与heap profile冲突的问题。 [姓名] 将评估使用Cassandra作为RocksDB替代品的可能性。 [姓名] 将继续跟踪基于Samsung技术的存储设备的进展。 会议与活动： 将在Ceph Day会议期间安排团队会议。 将收集用户反馈，以了解用户的需求和期望。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-14:: Ceph DocUBetter Meeting","slug":"2019-08-14_-_-_Ceph_DocUBetter_Meeting","date":"2019-08-13T16:00:00.000Z","updated":"2019-08-14T16:00:00.000Z","comments":true,"path":"2019/08/14/2019-08-14_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/14/2019-08-14_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [所有参会人员姓名] 会议主题： 讨论Ceph项目相关事宜，包括PR签核流程、上游文档职位开放以及开源软件峰会演讲事宜。 关键细节： PR签核流程： 讨论了移除签核流程的可能性，但考虑到与其他PR的整合难度，决定保留签核流程。 提出在合并提交中添加“已签核”信息，以便在后续模块中体现，而非在原始PR中。 计划编写文档或制作视频教程，指导用户在不同状态下如何添加签核信息。 上游文档职位： 讨论了为上游文档职位开放的招聘信息，要求应聘者具备基本的技术文档编写经验，熟悉相关工具。 鼓励有意向的人士通过SEF的邮箱发送简历和申请材料。 开源软件峰会演讲： 提到Ceph项目将在开源软件峰会欧洲上进行的演讲，主题为“开源软件的成长与持续发展”。 计划与社区经理Mike讨论如何将演讲内容与Ceph项目相结合，强调文档的重要性。 Ceph网站改进： 讨论了如何改进Ceph网站，特别是入门部分。 计划邀请Mike参与讨论，并探讨如何吸引更多人参与到网站建设工作中。 决定的事项： 编写文档或制作视频教程，指导用户添加PR签核信息。 招聘上游文档职位，要求应聘者具备相关经验。 与社区经理Mike讨论演讲内容与Ceph项目的结合，以及Ceph网站改进方案。 后续行动计划： [具体负责人] 负责编写文档或制作视频教程。 [具体负责人] 发布上游文档职位招聘信息。 [具体负责人] 与社区经理Mike沟通，讨论演讲内容与Ceph项目的结合。 [具体负责人] 与社区经理Mike沟通，探讨Ceph网站改进方案。 备注： 会议中提到的部分计算机科学/ceph相关领域英文原文关键词包括：PR（Pull Request）、signed off by、merge commit、distributed systems、C++、open-source software、self development process、TOC（Table of Contents）、open source summit Europe。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-05 :: Ceph Orchestration Meeting","slug":"2019-08-05_-_-_Ceph_Orchestration_Meeting","date":"2019-08-11T16:00:00.000Z","updated":"2019-08-11T16:00:00.000Z","comments":true,"path":"2019/08/12/2019-08-05_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/12/2019-08-05_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Orchestra团队成员 会议主题： Orchestra项目进展及讨论 会议内容： 一、会议改进建议 会议议程： 团队成员对现有的会议议程表示满意，建议继续使用Pet或Google Doc等工具创建议程，以提高会议效率。 参会人员： 建议邀请更多外部人员参与会议，例如来自欧洲或亚太地区的团队成员。 二、项目进展 Noah的PR： 关于Mons运行Monzon的PR已合并。 Peavey的PR： 已合并，需要指定持久卷声明模板，Mons将启动。 PBS的PR： 希望本周完成，完成后只剩下收集日志和崩溃转储。 Orchestrator模块： 讨论了如何在外部存储类中部署OSD，以及是否需要为Kubernetes环境提供特定的设置。 CR验证PR： 使用CRD验证生成API代码，发现了一些未实现或已删除的功能。 Rook PR： 发现了一个与schema相关的失败，需要进一步调查。 事件记录： 讨论了将事件记录到Rook的问题，以及是否应将其与Orchestrator相关联。 集群本地存储： 在使用Portman部署集群本地存储时遇到了困难，需要进一步调查。 Isis和NFS： 对Isis和NFS进行了一些调查和修复。 三、行动计划 邀请外部人员： 尝试邀请来自欧洲或亚太地区的团队成员参加下周三的会议。 Rook PR调查： 进一步调查Rook PR中的schema失败。 事件记录： 进一步调查将事件记录到Rook的问题。 集群本地存储： 解决集群本地存储部署中的问题。 Isis和NFS修复： 完成Isis和NFS的修复。 四、其他事项 DNS使用： 讨论了在Kubernetes中使用DNS代替IP地址的问题，以解决一些部署问题。 Monitor身份： 讨论了Monitor的身份问题，以及是否需要更改Monitor ID。 五、会议总结 本次会议讨论了Orchestrator项目的进展和讨论了一些关键问题。团队将继续努力解决遇到的问题，并推动项目向前发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-06 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-08-06_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-08-11T16:00:00.000Z","updated":"2019-08-11T16:00:00.000Z","comments":true,"path":"2019/08/12/2019-08-06_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/12/2019-08-06_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 圣克拉拉 参会人员： Marya, Peter, Suri, Rida, Milan, Comment, Justin 会议内容： 1. 复制副本测试： Marya汇报了其复制副本测试的进展，使用Crimson II进行测试，未引入性能退步。 讨论了将测试合并到Merger的可行性，但需要Crimson Messenger的支持。 Marya表示将尝试将测试用例与近期更改（如Innings更改）进行验证。 2. 性能测试集成： 讨论了将性能测试集成到Jenkins和Ritter的TD Site中。 需要比较不同测试用例的性能，包括Crimson II和Crimson Messenger。 计划编写SMO测试，比较基线性能。 需要确保测试用例能够反映实际使用场景。 3. 对象存储设计： 讨论了对象存储的设计，包括命名空间和硬件支持。 认识到需要支持不同的硬件，包括HDD和SSD。 讨论了Sister和Blue Store的差异和适用场景。 4. 其他议题： Suri汇报了其在Crimson中实现安全类和对象类的进展。 Rida讨论了Sitar输入缓冲区的实现，并计划与Avi面对面讨论。 Comment讨论了使用Python或批处理代码驱动测试的想法。 Milan讨论了将UNIX域套接字支持合并回系统的计划。 行动计划： Marya将继续进行复制副本测试，并尝试将其合并到Merger。 讨论性能测试用例的设计和实现。 继续进行对象存储的设计和开发。 Suri将完成Crimson中安全类和对象类的实现。 Rida将讨论Sitar输入缓冲区的实现。 Comment将研究使用Python或批处理代码驱动测试。 Milan将合并UNIX域套接字支持。 备注： 会议中提到了Crimson II、Crimson Messenger、Sister、Blue Store、Innings、Merger、TD Site、SMO、Sitar、输入缓冲区等关键术语。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-08 :: Ceph Performance Meeting","slug":"2019-08-08_-_-_Ceph_Performance_Meeting","date":"2019-08-11T16:00:00.000Z","updated":"2019-08-11T16:00:00.000Z","comments":true,"path":"2019/08/12/2019-08-08_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/12/2019-08-08_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 核心团队成员 会议主题： 讨论Ceph项目的最新进展、关键问题及后续行动计划。 关键细节： Alec尺寸变更： 由于碎片化导致的空间浪费，团队成员正在讨论将Alec尺寸从64k调整到更大的值，以优化存储效率。 讨论中提出了两个PR：一个将Alec尺寸设置为64k，另一个在共享设备上使用64k的Alec尺寸，但在Blue Store TV或Well设备上不使用。 异步读取PR： 讨论了一个实现异步读取的OSD PR，但需要进一步的性能和剖析数据来评估其影响。 其他PR： Jinping的PR：优化了IO通知解锁操作，提高了性能。 Igor的PR：减少了锁获取的开销。 Champagne的PR：减少了不必要的通知，可能略微提高了性能。 Eric的PR：合并了一个小的RG w PR qualms PR，可能没有太大影响，但有助于提高性能。 Blue Store Alexeyes： Neha的PR：针对Blue Store Alexeyes进行了一些调整。 Adam的PR：对Boost和元数据进行了研究，并将其组织到不同的列族中。 讨论了将PG日志信息存储在单独的列族中的利弊，以及如何优化存储和内存缓冲区。 其他议题： MDS和Mon内存限制的优化。 自动化Rocks DB文件在BlueFS设备之间移动的PR。 IOU ring和messenger的PR。 op tracker PR。 cash bidding rebase。 讨论的主要议题： Alec尺寸变更： 讨论了将Alec尺寸从64k调整到更大的值的利弊。 分析了不同Alec尺寸对性能的影响。 讨论了是否应该将PG日志信息存储在单独的列族中。 其他议题： 讨论了如何优化存储和内存缓冲区。 讨论了如何将Rocks DB文件在BlueFS设备之间移动。 决定的事项： 继续讨论Alec尺寸变更，并收集更多数据。 对异步读取PR进行进一步的分析。 对其他PR进行审查和合并。 继续优化MDS和Mon内存限制。 完成其他议题的相关工作。 后续行动计划： 收集更多数据以评估Alec尺寸变更的影响。 对异步读取PR进行进一步的分析。 完成其他PR的审查和合并。 完成MDS和Mon内存限制的优化。 完成其他议题的相关工作。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，例如Alec、Blue Store、RocksDB、OSD、PG、column family等。 会议中讨论了一些具体的性能测试和实验，例如迭代测试、写入测试等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-12 :: Ceph Orchestration Meeting","slug":"2019-08-12_-_-_Ceph_Orchestration_Meeting","date":"2019-08-11T16:00:00.000Z","updated":"2019-08-11T16:00:00.000Z","comments":true,"path":"2019/08/12/2019-08-12_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/12/2019-08-12_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Orchestrators 团队周会 会议内容： 1. 团队成员近况分享 - 成员们分享了近期的工作和生活情况，包括新办公地点的搬迁和新环境的适应。 - 提到由于搬迁，近期工作较为繁忙，但整体氛围良好。 2. 主要议题讨论 - Rook 的 OS D 集成： 成员介绍了 Rook 的 OS D 在 Peavey 上的集成进展，已准备合并代码，预计 CI 通过后即可合并。 - Dashboard 展示： 讨论了如何将 OS D 集成信息展示在 Dashboard 上，以便用户了解存储类别的选择和使用方式。计划在周三进行讨论，由 Bangalore 的开发团队参加。 - CSI 驱动默认启用： 成员提到 CSI 驱动默认启用，对编排方面的影响不大。 - zrd 验证最终审查： 成员介绍了 zrd 验证的最终审查进展，目前仍在跟踪 CI 问题，预计很快完成。 - 事件报告： 成员介绍了将事件报告引入 Kubernetes 的 PR，但尚未进行详细审查。 - 持久卷云支持： 讨论了持久卷云支持的实现方式，由于环境差异，需要进一步研究如何正确实现。 3. 决定事项 - 计划在周三进行 Dashboard 展示方式的讨论。 - 加快 zrd 验证最终审查的进度。 - 对事件报告 PR 进行审查。 - 研究持久卷云支持的实现方式。 4. 后续行动计划 - 成员们将根据讨论结果，继续推进相关项目的开发工作。 - 定期进行团队周会，讨论项目进展和问题。 5. 其他事项 - 无。 备注： - 会议中提到了一些计算机科学/ceph 领域的英文关键词，如 Rook、OS D、Peavey、Dashboard、CSI、zrd、Kubernetes 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-30 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-07-30_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-08-01T16:00:00.000Z","updated":"2019-08-02T16:00:00.000Z","comments":true,"path":"2019/08/02/2019-07-30_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/02/2019-07-30_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间：[请填写具体时间] 会议地点：[请填写具体地点] 参会人员：[请填写参会人员名单] 一、会议关键细节 会议开始时，由于部分成员迟到，会议延迟开始。 会议中，多位成员汇报了各自的工作进展和遇到的问题。 二、讨论的主要议题 Ceph存储系统相关： 成员汇报了在Ceph存储系统中遇到的14octuple问题，目前第一轮测试案例仍失败，但已取得一定进展。 讨论了replica的优化方案，包括基于meaning change实现lucid connection等。 成员分享了在Ceph存储系统中关于POSIX接口的修改，以及针对any store API的改进。 讨论了关于dirt class的支持，已提交PR进行修复。 成员分享了关于Ceph存储系统中object class DPI的实现，以及针对crimson的优化方案。 视频会议字幕翻译及总结： 成员分享了关于视频会议字幕翻译的实践经验，包括英译中和总结工作。 讨论了翻译过程中遇到的问题，以及如何提高翻译质量。 其他议题： 成员汇报了关于back off功能的实现，以及如何避免频繁连接到manager。 讨论了关于admin console interface的实现，以及如何支持UNIX domain sockets。 成员分享了关于Protocol v2 looseness policy的实现和测试情况。 讨论了关于rocksDB在Ceph存储系统中的应用，以及与C-store的集成。 三、决定的事项 针对Ceph存储系统： 继续优化14octuple问题，提交相关PR。 完善replica的优化方案，并提交相关PR。 完善Ceph存储系统中关于POSIX接口的修改，并提交相关PR。 修复dirt class问题，并提交相关PR。 优化Ceph存储系统中object class DPI的实现，并提交相关PR。 针对视频会议字幕翻译及总结： 提高翻译质量，分享翻译经验。 完善翻译流程，确保翻译准确性和时效性。 针对其他议题： 完成back off功能的实现，并提交相关PR。 支持UNIX domain sockets，实现admin console interface。 完成Protocol v2 looseness policy的测试，并提交相关PR。 探索rocksDB在Ceph存储系统中的应用，并与C-store进行集成。 四、后续行动计划 各成员按照决定的事项，继续推进各自的工作。 定期召开会议，汇报工作进展和讨论相关问题。 加强团队协作，共同推进Ceph存储系统和视频会议字幕翻译及总结工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-08-01 :: Ceph Performance Meeting","slug":"2019-08-01_-_-_Ceph_Performance_Meeting","date":"2019-08-01T16:00:00.000Z","updated":"2019-08-02T16:00:00.000Z","comments":true,"path":"2019/08/02/2019-08-01_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/08/02/2019-08-01_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Neha, Josh, Adam, Eric, Igor, Aaron, Mark, Sam 等 会议主题： 本周 PR 回顾： 合并了 RocksDB 新版本到 master，支持了 proxy cache 和 range。 Moshing 和 Peng 提交的 PR 减少了 BlueStore 的唤醒次数，可能带来性能提升。 May 提交的 PR 通过所有测试，为 BlueStore 带来了 25-30% 的随机小写性能提升。 Trim cache on ad PR 合并到 P 上。 Eric 提交的 RGW 效率提升 PR 已进入测试阶段。 Adams 提交的 PR 正在测试中，希望尽快合并。 RFC：将 BlueFS Alexeyes 默认值设置为与 BlueStore 相同，并设置为 16K： 背景：为了解决 BlueFS 和 BlueStore 在碎片化方面的差异，提出了将两者分配大小设置为相同的 RFC。 讨论： Neha 介绍了 RFC 的背景和目的。 Josh 解释了 PR 的具体实现方式。 Mark 提出了对性能影响的担忧，并希望进行更多测试。 Adam 认为将分配大小设置为 16K 是一个合理的折衷方案。 决定将 PR 作为高优先级任务进行测试和评估。 其他议题： Igor 的 RocksDB 提示文件 PR 仍在进行中。 6.1.2 版本已合并到 master，并计划将其回滚到 Nautilus。 MDS 和 Demon 内存限制调整 PR 正在开发中。 OpTracker 事件优化 PR 已与 Patrick 达成共识。 Igor 的自动调整 PR 需要重构和重置。 行动计划： 对 BlueFS Alexeyes 默认值设置为 16K 的 PR 进行测试和评估。 继续开发其他 PR。 讨论将 RocksDB 6.1.2 版本回滚到 Nautilus 的可行性。 关注 Igor 的 RocksDB 提示文件 PR 的进展。 后续会议： 下周会议可能讨论 Sam 关于 LoRan 内部延迟的分享。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-29 :: Ceph Orchestration Meeting","slug":"2019-07-29_-_-_Ceph_Orchestration_Meeting","date":"2019-07-29T16:00:00.000Z","updated":"2019-07-30T16:00:00.000Z","comments":true,"path":"2019/07/30/2019-07-29_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/30/2019-07-29_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： 本次会议主要讨论了Ceph集群的运维、管理和优化问题，包括客户端库更新、Orchestrator队列管理、Rook模块的启用配置、CRD验证等议题。 会议内容： 客户端库更新： 目前Sentra 7芯片上的Cumulative Client Python库版本过旧，无法满足Ceph客户端的最低要求。 由于Sentra 7芯片的Python库版本不支持Ceph客户端的某些功能，导致Watcher模块无法正常工作。 讨论了将Python库打包成RPM包并在CentOS 7上安装的方案，以解决依赖问题。 希望CentOS团队能够将更新回滚到CentOS 7，以便用户能够使用最新版本的客户端。 Orchestrator队列管理： 讨论了Orchestrator队列中任务挂起的问题，如果任务因任何原因挂起，目前没有其他方法清除队列，除非重启Manager。 提出了添加一个安全Orchestrator文本层的想法，以便在需要时安全地清除队列。 Rook模块的启用配置： 讨论了Rook中Manager模块的启用配置问题，目前Rook只能自动启用某些模块，没有提供用户自定义模块的选项。 提出了在Rook CR中添加一个通用设置，以指示是否启用特定模块的方案。 讨论了是否应该自动启用PG自动缩放器，以及是否应该将此功能设置为默认启用。 CRD验证： 讨论了CRD验证的更新，包括对集群、存储池和文件系统的验证。 讨论了将两个PR合并的建议，因为它们之间存在冲突。 其他议题： 讨论了基于PVC的OSD创建、LVM配置和Rook的其他功能。 后续行动计划： 完成Python库的RPM包打包和安装。 实现Orchestrator队列的安全清除功能。 更新Rook模块的启用配置。 完成CRD验证的更新。 继续推进Rook的其他功能开发。 备注： 会议中提到了SSH Orchestrator，但被推迟到下周讨论。 总结： 本次会议讨论了Ceph集群的多个关键议题，并制定了后续的行动计划。会议内容涵盖了客户端库更新、Orchestrator队列管理、Rook模块的启用配置、CRD验证等多个方面，对于Ceph集群的运维和管理具有重要意义。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-24:: Ceph DocUBetter Meeting","slug":"2019-07-24_-_-_Ceph_DocUBetter_Meeting","date":"2019-07-24T16:00:00.000Z","updated":"2019-07-25T16:00:00.000Z","comments":true,"path":"2019/07/25/2019-07-24_-_-_Ceph_DocUBetter_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/25/2019-07-24_-_-_Ceph_DocUBetter_Meeting/","excerpt":"","text":"会议纪要 会议时间： 美国太平洋时间9点 参会人员： Gemini（主持人）、James、Gabriela 会议主题： Ceph 文档贡献与改进 会议内容： 文档贡献情况： Gemini 提到上周有新的 pull request 被提交，包括添加 YouTube 链接到入门页面和修复测试链接。 Gabriela 作为实习生，正在审阅入门文档，并发现了一些问题，例如重复的角色和重复的月份。 Gemini 解释了重复月份的问题，并建议 Gabriela 在修复前确认理解正确。 签名的处理： Gabriela 在创建 pull request 时遇到了签名的麻烦，无法在 UI 中编辑。 讨论了签名的必要性，以及对于新贡献者来说可能存在的障碍。 提出了两种解决方案： 完全放宽签名要求，或为新贡献者提供更详细的指导。 制作视频教程，介绍如何在提交时添加签名。 将讨论结果提交给 Sage 和其他相关人员，以决定是否放宽签名要求。 其他议题： Gemini 提到可能需要解决重复月份的问题。 讨论了在 Ceph 项目中签名的必要性，以及是否需要更新相关文档。 后续行动计划： Gemini 将与 Sage 和其他相关人员讨论签名要求，并在下次会议汇报结果。 Gemini 将制作视频教程，介绍如何在提交时添加签名。 Gabriela 将继续审阅入门文档，并修复发现的问题。 会议总结： 本次会议主要讨论了 Ceph 文档的贡献与改进，包括 pull request 的处理、签名的处理以及文档中的重复问题。会议提出了改进方案，并将后续行动计划分配给相关人员。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-25 :: Ceph Performance Meeting","slug":"2019-07-25_-_-_Ceph_Performance_Meeting","date":"2019-07-24T16:00:00.000Z","updated":"2019-07-25T16:00:00.000Z","comments":true,"path":"2019/07/25/2019-07-25_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/25/2019-07-25_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储项目讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Eric、Bret、Josh、Casey等 会议内容： 1. RGW数据副本删除请求 - 讨论了RGW（Rados Gateway）请求中删除数据副本的功能。 - 该功能将基于当前正在合并的代码进行实现。 - 可能会将其回溯到Nautilus版本，具体取决于后续讨论。 2. 双缓存机制 - 讨论了双缓存机制的优化，该机制将基于Eric正在合并的代码实现。 - 讨论了将该功能回溯到Nautilus版本的可能性，需要进一步讨论。 3. 格式变更 - 由于格式变更，用户可能需要重新安装OSDS（Object Storage Device Server）。 - 讨论了回溯该变更到Nautilus版本的可能性，需要进一步讨论。 4. Pull Requests - 讨论了当前待处理的Pull Requests，包括： - 重新实现缓存的Pull Request - 改变trim行为的Pull Request - 避免双重缓存的Pull Request 5. RocksDB优化 - 讨论了RocksDB的优化，包括： - 读取前优化 - ARM范围优化 - 自动调整读取前优化 6. RocksDB版本选择 - 讨论了选择RocksDB版本的问题，包括： - Luminous版本：5.9 - Nautilus版本：5.17.2 - 是否需要更新到更高级的版本 7. RocksDB回溯 - 讨论了将RocksDB优化回溯到Luminous版本的可能性。 8. RocksDB性能优化 - 讨论了RocksDB的性能优化，包括： - 连接线程 - 读取前优化 - ARM范围优化 9. 其他议题 - 讨论了其他议题，包括： - 快速垃圾回收 - BlueFS碎片化问题 后续行动计划： 进一步讨论双缓存机制回溯到Nautilus版本的可能性。 审查并合并待处理的Pull Requests。 选择合适的RocksDB版本，并进行回溯和优化。 评估其他议题的解决方案。 备注： 会议中提到了一些关键的技术术语，如RGW、OSDS、RocksDB、ARM范围、读取前优化等。 会议讨论了多个技术细节，需要进一步研究和验证。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-23 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-07-23_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-07-23T16:00:00.000Z","updated":"2019-07-23T16:00:00.000Z","comments":true,"path":"2019/07/24/2019-07-23_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/24/2019-07-23_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要： 会议时间： 未知 会议主题： Ceph 存储系统相关技术讨论 关键细节： 会议背景： 会议讨论了 Ceph 存储系统在性能优化、稳定性提升和功能扩展等方面的议题。 主要议题： Ceph BlueStore 与 CRimsonOS 的兼容性： 讨论了如何让 BlueStore 在 CRimsonOS 上运行，并分析了两种解决方案的优缺点。 RocksDB 与 CRimsonOS 的兼容性： 讨论了如何将 RocksDB 移植到 CRimsonOS，并分析了移植过程中可能遇到的问题。 Ceph 存储系统性能优化： 讨论了如何优化 Ceph 存储系统的性能，包括 I/O 性能、内存使用率和网络带宽等。 Ceph 存储系统功能扩展： 讨论了如何扩展 Ceph 存储系统的功能，例如支持新的存储介质、提供更多存储服务等。 讨论的主要议题： Ceph BlueStore 与 CRimsonOS 的兼容性： 方案一： 将 BlueStore 移植到 CRimsonOS，但需要修改大量代码，工作量较大。 方案二： 将 BlueStore 运行在单独的进程中，并通过共享内存进行通信，但可能会引入性能开销。 方案三： 将 BlueStore 与 CRimsonOS 的共享代码分离，并引入新的命名空间，以避免符号冲突。 方案四： 使用链接器魔法将 BlueStore 链接到一个不导出任何符号的对象文件。 RocksDB 与 CRimsonOS 的兼容性： 讨论了如何将 RocksDB 移植到 CRimsonOS，并分析了移植过程中可能遇到的问题。 Ceph 存储系统性能优化： 讨论了如何优化 Ceph 存储系统的性能，包括 I/O 性能、内存使用率和网络带宽等。 Ceph 存储系统功能扩展： 讨论了如何扩展 Ceph 存储系统的功能，例如支持新的存储介质、提供更多存储服务等。 决定的事项： 继续讨论 BlueStore 与 CRimsonOS 的兼容性问题，并评估不同方案的可行性。 将 RocksDB 移植到 CRimsonOS，并分析移植过程中可能遇到的问题。 优化 Ceph 存储系统的性能，并扩展其功能。 后续行动计划： 继续讨论 BlueStore 与 CRimsonOS 的兼容性问题，并评估不同方案的可行性。 将 RocksDB 移植到 CRimsonOS，并分析移植过程中可能遇到的问题。 优化 Ceph 存储系统的性能，并扩展其功能。 其他事项： 讨论了 Ceph 存储系统与其他技术的兼容性，例如 RocksDB 和 CRimsonOS。 讨论了 Ceph 存储系统的性能优化和功能扩展方案。 关键词： Ceph BlueStore CRimsonOS RocksDB 性能优化 稳定性提升 功能扩展 共享内存 命名空间 链接器魔法","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-22 :: Ceph Orchestration Meeting","slug":"2019-07-22_-_-_Ceph_Orchestration_Meeting","date":"2019-07-22T16:00:00.000Z","updated":"2019-07-23T16:00:00.000Z","comments":true,"path":"2019/07/23/2019-07-22_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/23/2019-07-22_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年某日 参会人员： 众人（具体姓名未提及） 会议内容： 一、Kieffer 驱动集成改进 - 主要工作集中在改进 Kieffer 驱动集成。 二、Ceph 14.2 版本相关 - 14.2 版本的镜像已修复了 NFS Kinshasa 打包问题，由 Thomas 解决。 - 目前 14.2 镜像正在重建中，为 Rook 1.1 版本提供基础。 - 如果 14.3 版本发布时间较长，则可能使用 14.2 版本配合 Rook 1.1 版本发布。 三、动态存储卷问题 - 在使用 AWS 时，尝试在 TV 设备上运行 OSD，而不是传统的 /dev 下的原始设备。 - 在尝试使用 set volume 配置 PV 时，由于设备挂载方式不同，无法找到大小属性，导致设置失败。 - 已与 Alfredo 开启线程讨论该问题，但尚未创建跟踪问题。 - 建议创建一个 Red Hat 集成的跟踪问题，以便进一步跟踪。 四、其他事项 - 合并了由 so-meager 提交的 ant-eww 创建 PR。 - 尝试使用 diamond 工具，但需要先完成其他工作。 五、行动计划 - 继续改进 Kieffer 驱动集成。 - 关注 14.2 版本及 Rook 1.1 版本发布。 - 解决动态存储卷问题，并创建跟踪问题。 - 完成其他待办事项。 会议总结： 本次会议主要讨论了 Ceph 14.2 版本相关问题以及动态存储卷问题。会议确定了后续行动计划，并要求相关人员继续推进相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-16 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-07-16_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-07-21T16:00:00.000Z","updated":"2019-07-21T16:00:00.000Z","comments":true,"path":"2019/07/22/2019-07-16_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/22/2019-07-16_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间 [请填写会议具体时间] 参会人员 [请填写参会人员名单] 会议主题 本周Ceph项目进展讨论及后续行动计划 关键细节与议题 1. 分布式存储Ceph相关议题 副本权利（Replica Rights）：讨论了如何并行处理读取请求，以及是否可以将多个读取请求合并为单个消息。讨论了RBD和OSD的操作，以及是否需要在操作前预先加载缓存。最终决定，至少在目前阶段，不会为每个读取请求创建单独的读取操作，而是考虑在操作前预先加载缓存。 性能测试：讨论了为性能测试分配专用机器，并使用Jenkins自动化测试的计划。决定与Afraid和David协调，以推进这一计划。 Crimson与Perfstat集成：讨论了Crimson与Perfstat集成的进展，以及如何在不依赖网络的情况下运行CBT。决定继续进行相关工作，并考虑在后续步骤中考虑并行处理读取请求。 Crimson错误处理：讨论了Crimson错误处理机制的改进，包括授权结果反馈和错误处理代码的改进。决定继续进行相关工作，并考虑在后续步骤中集成授权结果反馈。 2. 视频会议字幕翻译与总结 Crimson与Perfstat集成：讨论了Crimson与Perfstat集成的进展，以及如何在不依赖网络的情况下运行CBT。决定继续进行相关工作，并考虑在后续步骤中考虑并行处理读取请求。 Crimson错误处理：讨论了Crimson错误处理机制的改进，包括授权结果反馈和错误处理代码的改进。决定继续进行相关工作，并考虑在后续步骤中集成授权结果反馈。 Crimson与BlueStar集成：讨论了将BlueStar集成到Crimson中的进展，以及解决宏定义冲突的问题。决定使用命名空间来区分不同的代码分支，并继续进行相关工作。 决定事项 性能测试：与Afraid和David协调，为性能测试分配专用机器，并使用Jenkins自动化测试。 Crimson与Perfstat集成：继续进行相关工作，并考虑在后续步骤中考虑并行处理读取请求。 Crimson错误处理：继续进行相关工作，并考虑在后续步骤中集成授权结果反馈。 Crimson与BlueStar集成：使用命名空间来区分不同的代码分支，并继续进行相关工作。 后续行动计划 性能测试：与Afraid和David协调，为性能测试分配专用机器，并使用Jenkins自动化测试。 Crimson与Perfstat集成：继续进行相关工作，并考虑在后续步骤中考虑并行处理读取请求。 Crimson错误处理：继续进行相关工作，并考虑在后续步骤中集成授权结果反馈。 Crimson与BlueStar集成：使用命名空间来区分不同的代码分支，并继续进行相关工作。 其他 会议讨论了多个技术细节，包括RBD、OSD、CBT、Perfstat、Crimson和BlueStar等。 会议强调了团队合作和沟通的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-17 :: Ceph Orchestration Meeting","slug":"2019-07-17_-_-_Ceph_Orchestration_Meeting","date":"2019-07-21T16:00:00.000Z","updated":"2019-07-21T16:00:00.000Z","comments":true,"path":"2019/07/22/2019-07-17_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/22/2019-07-17_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [所有参会人员姓名] 会议主题： Ceph分布式存储项目进展及问题讨论 会议内容： 一、Ceph Orchestrator性能优化 问题： Ceph Orchestrator性能较慢，特别是对于Dashboard和Kiva的使用。 解决方案： 探索使用Costner的改进版Rook模块，以提高性能。 讨论将Rook模块优化纳入Ceph Orchestrator的拉取请求中。 二、Ceph Dashboard集成 问题： Ceph Dashboard集成存在一些问题，例如服务显示不正常、软盘和磁盘代码的奇怪位置等。 解决方案： 确认软盘和磁盘代码功能在Ceph中已有实现，但位置不太合理。 讨论优化软盘和磁盘代码功能，使其更易于使用。 三、Ceph Rook模块 问题： Ceph Rook模块需要更多关注和维护。 解决方案： 鼓励Young更多参与Ceph Rook模块的上游维护。 四、Ceph测试Orchestrator 问题： Ceph测试Orchestrator的功能需要增强，以便更好地支持集成测试。 解决方案： 鼓励开发人员增强测试Orchestrator的功能，以便返回更多数据。 五、其他 讨论了Ceph Inventory命令的改进，以便更好地支持磁盘识别。 讨论了Ceph Dashboard的命名一致性问题和SSH Orchestrator的简单设置。 后续行动计划： Costner将修改Rook模块，以提高Ceph Orchestrator性能。 开发人员将优化Ceph Dashboard和Rook模块。 Young将更多参与Ceph Rook模块的上游维护。 开发人员将增强测试Orchestrator的功能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-18 :: Ceph Performance Meeting","slug":"2019-07-18_-_-_Ceph_Performance_Meeting","date":"2019-07-21T16:00:00.000Z","updated":"2019-07-21T16:00:00.000Z","comments":true,"path":"2019/07/22/2019-07-18_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/22/2019-07-18_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 会议地点： 线上会议 参会人员： Adam, Sage, Igor, Patrick, Lucas, Marcus, Bella, Alex, David 等 会议主题： Ceph 项目进展、技术讨论、行动计划 会议内容： 一、Ceph 项目进展 Adam 近期提交了三个新的 Pull Request (PR) 用于图表工作，令人兴奋。 Sage 正在审查 Adam 的 PR，并希望尽快将其集成到自己的工作中。 Igor 的 PR 是一个很好的发展方向，团队将尝试使其更明确。 Patrick 和 Sage 就 AppTracker 的 PR 进行了讨论，讨论了字符串视图和动态事件的接口问题。 Sage 认为应该将字符串视图和动态事件分开，以避免复制和优化性能。 团队将进行更大范围的审查，以确定动态事件的接口应该是什么样子，并避免在一般情况下进行复制。 Sage 认为应该去掉动态事件，只传递信息。 Sage 和 Adam 正在合作解决 RocksDB 的复制问题。 团队正在讨论将 RocksDB 的 delete range 功能集成到 Nautilus 中。 Sage 认为应该将 RocksDB 5.18.12 版本的 delete range 功能集成到 Nautilus 中。 团队正在讨论如何测试 RocksDB 的 delete range 功能。 二、技术讨论 Sage 讨论了 RocksDB 的 OpTracker 性能问题，认为当前 OpTracker 对随机写入的性能影响很大。 团队讨论了 OpTracker 的改进方案，包括使用采样和优化 OpTracker 代码。 Sage 认为应该修复 OpTracker 中的明显问题，例如字符串复制，而不是完全重写代码。 团队讨论了将 OpTracker 的快速锁应用于其他地方的可能性。 三、行动计划 Sage 和 Adam 将继续合作解决 RocksDB 的复制问题。 团队将进行更大范围的审查，以确定动态事件的接口应该是什么样子，并避免在一般情况下进行复制。 Sage 将与团队讨论 OpTracker 的改进方案。 团队将测试 RocksDB 的 delete range 功能，并决定是否将其集成到 Nautilus 中。 团队将讨论如何将 RocksDB 的 OpTracker 的快速锁应用于其他地方。 四、其他事项 Sage 和 Bella 将讨论 Jenkins 集成事宜。 Marcus 将分享关于 Tableau 存储的跟踪信息。 五、会议总结 本次会议讨论了 Ceph 项目的进展、技术讨论和行动计划。团队将继续努力解决各种问题，并推动 Ceph 项目的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-15 :: Ceph Orchestration Meeting","slug":"2019-07-15_-_-_Ceph_Orchestration_Meeting","date":"2019-07-21T16:00:00.000Z","updated":"2019-07-21T16:00:00.000Z","comments":true,"path":"2019/07/22/2019-07-15_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/22/2019-07-15_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 参会人员： Sebastia, Travis, Bart, Joshua, Yanis, Kieffer, Conor, Blaine, Hansel 会议主题： Ceph 驱动器组讨论、Rook 项目进展、社区发布计划 会议内容： 一、驱动器组讨论 背景： 周五在 container holla 上讨论了驱动器组（drive groups）的问题，但并非讨论的最佳场所。 主要议题： 是否需要全局信息将驱动器组转换为安全卷。 如何在本地和全局层面处理驱动器组。 驱动器组元描述应该在 Sapphire 层还是 Orchestrator 层完成。 Orchestrator 应如何处理驱动器组。 讨论结果： 需要进一步讨论驱动器组在全局层面的处理方式。 建议在 Sapphire 层或 Orchestrator 层以上完成驱动器组元描述。 Orchestrator 应负责处理驱动器组，并确保其一致性和可靠性。 需要考虑如何将驱动器组描述传递给 Orchestrator，并避免增加 Orchestrator 的负担。 二、Rook 项目进展 Rook 1.1 版本发布计划： 目标：8月中旬完成特性开发，8月底发布 1.1 版本。 需要确定最低 SEF 版本，以支持新的功能。 建议将最低 SEF 版本设置为 Mimic 13.4，以支持安全卷。 Rook 与 Ceph 集成： Rook 1.1 版本将包含针对 RGW 的关键修复。 需要考虑如何在 Dashboard 中优化 Orchestrator 的性能。 需要实现 Orchestrator API 的 introspection 功能，以便 UI 能够了解 Orchestrator 的实现。 三、后续行动计划 Sebastia 和 Joshua 将继续讨论驱动器组的问题，并完善相关文档。 Kieffer 将优化 Orchestrator 的性能，并实现 Orchestrator API 的 introspection 功能。 Blaine 将负责 Rook 1.1 版本的发布计划。 所有参与者将根据讨论结果，继续推进 Ceph 和 Rook 项目的开发。 会议总结： 本次会议讨论了 Ceph 驱动器组和 Rook 项目的进展，并制定了后续行动计划。会议取得了积极成果，为项目的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"July 2019 :: Ceph Developer Monthly","slug":"July_2019_-_-_Ceph_Developer_Monthly","date":"2019-07-21T16:00:00.000Z","updated":"2019-07-21T16:00:00.000Z","comments":true,"path":"2019/07/22/July_2019_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/22/July_2019_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2019年7月CD Emma会议 会议主题： Ceph存储系统监控与优化 参会人员： David、Neha、Josh、Paul、Brad、Michael、Chad、Tom、Alex、Leonard、Cooper等 会议内容： 一、减少延迟时间 David介绍了用于检测慢速网络连接性的工具，通过设置警告级别和不同时间间隔的平均ping时间来识别网络问题。 讨论了使用最大ping时间而不是平均ping时间的可行性，以及如何处理心跳接口的重置情况。 提出了收集负载平均数和磁盘利用率等指标，以提供更全面的监控信息。 讨论了如何处理网络拓扑问题，例如识别故障交换机或机架。 决定将此功能作为开发选项，并限制其时间间隔范围。 二、健康警报 讨论了使用“静音”功能来处理健康警报，包括设置静音时间、匹配模式、匹配规则等。 讨论了如何处理不同类型的健康警报，例如OSD失败、性能下降等。 决定在初始阶段使用简单的模式，并根据需要逐步扩展。 三、请求诊断 讨论了改进请求诊断的方法，例如记录更详细的日志、生成更清晰的错误消息、收集更多指标等。 讨论了如何处理磁盘忙、I/O错误、CPU负载过高等问题。 决定增加性能计数器，并将相关信息记录到日志中。 四、其他议题 讨论了使用脚本分析集群日志和性能数据的方法。 讨论了在仪表板中提供历史视图和热图的功能。 讨论了收集和存储崩溃转储文件的方法。 讨论了向Ceph集群添加“通道”概念，以便更灵活地启用或禁用不同类型的遥测数据。 行动计划： David将修改代码，并提交一个包含上述功能的pull request。 其他参会人员将审查pull request，并提供反馈。 根据反馈，进一步改进功能。 将功能集成到Ceph存储系统中。 总结： 本次会议讨论了Ceph存储系统监控和优化的多个方面，包括网络监控、健康警报、请求诊断、崩溃转储文件收集等。会议确定了行动计划，并将在后续工作中实施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-09 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-07-09_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-07-10T16:00:00.000Z","updated":"2019-07-11T16:00:00.000Z","comments":true,"path":"2019/07/11/2019-07-09_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/11/2019-07-09_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、Crimson存储引擎讨论 问题： Crimson存储引擎在处理大量客户端请求时，存在队列深度不足的问题，可能导致性能瓶颈。 解决方案： 提高队列深度并增加客户端请求时间，以避免性能问题。 关键点： 需要更新Crimson存储引擎，以支持更高的队列深度和客户端请求时间。 二、输入缓冲区工厂 问题： 输入缓冲区工厂的细节讨论，特别是用户空间IP/TCP在Crimson中的实现。 解决方案： 研究内存复制操作在原生堆栈中的实现，特别是在运行助手应用程序时。 引入iommu和PTEs来提高安全性。 优化DMA和内存复制操作，以支持不同的硬件平台。 关键点： 需要支持不同的DMA技术，如InfiniBand和RoCE。 需要抽象内存复制操作，以便在不同平台之间进行替换。 三、CI/CD流程 问题： Jenkins不支持CBT，且无法访问Pelagic。 解决方案： 创建本地CI/CD流程，使用Docker进行测试。 使用脚本启动和停止测试实例。 关键点： 需要创建脚本，用于启动和停止测试实例。 需要选择合适的CI/CD工具。 四、错误处理 问题： 需要处理从对象存储传播的错误。 解决方案： 使用error handling primitives，如ignore和fork。 优化现有代码，以使用新的error handling primitives。 关键点： 需要确定最佳的error handling strategy。 需要测试新的error handling primitives。 五、其他 Crimson协议： 修复与Crimson消息传递相关的bug。 清理协议v2的日志。 理解握手过程。 工具： 需要一个通用的工具，用于捕获和发送Crimson协议v2包。 需要一个Crimson协议v2的Wireshark插件。 后续行动计划： Crimson存储引擎： 更新Crimson存储引擎，以支持更高的队列深度和客户端请求时间。 输入缓冲区工厂： 优化内存复制操作，支持不同的硬件平台。 CI/CD流程： 创建本地CI/CD流程，使用Docker进行测试。 错误处理： 确定最佳的error handling strategy，并优化现有代码。 Crimson协议： 修复与Crimson消息传递相关的bug，清理协议v2的日志，理解握手过程。 工具： 开发一个通用的工具，用于捕获和发送Crimson协议v2包，以及一个Crimson协议v2的Wireshark插件。 备注： 部分计算机科学/ceph相关领域英文原文的关键词已保留在会议纪要中。 会议纪要已涵盖会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-08 :: Ceph Orchestration Meeting","slug":"2019-07-08_-_-_Ceph_Orchestration_Meeting","date":"2019-07-10T16:00:00.000Z","updated":"2019-07-11T16:00:00.000Z","comments":true,"path":"2019/07/11/2019-07-08_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/11/2019-07-08_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Christopher、Joyce、Eric、其他人 会议主题： Ceph orchestrator 会议纪要 会议内容： 1. Christopher自我介绍 Christopher是来自Souza公司的工程师，曾在SUSE公司工作六年，现加入Theft Team，主要负责容器、Rook以及一些编排工作。 2. Group Drive Group项目介绍 该项目旨在实现驱动器组的概念，可以将多个驱动器进行分组管理，例如使用特定型号或大小的驱动器。 目前该项目的实现较为简单，需要进一步完善。 讨论了将驱动器组逻辑移至Volume层，以实现更灵活的管理。 3. Python Common包 该包是一个Python库，可以共享Ceph组件之间的代码，是SSH orchestrator等项目的关键组件。 讨论了检查代码的必要性。 4. Dashboard集成 Keva正在开发将orchestrator界面集成到dashboard的功能，初始将从主机开始。 5. Rook项目进展 讨论了Rook项目的一些进展，包括PVS on cloud platforms spec、监控器放置、cmd reporter等。 6. 其他议题 讨论了将manager rook模块集成到monitoring storage classes in prometheus的可能性。 计划在周三讨论该议题。 行动计划： Christopher将完善Group Drive Group项目。 Keva继续开发Dashboard集成功能。 讨论Rook项目的具体进展。 在周三讨论将manager rook模块集成到monitoring storage classes in prometheus的可能性。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，如orchestrator、volume、drive group、monitor、Rook、prometheus等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-10:: Ceph DocUBetter meeting","slug":"2019-07-10_-_-_Ceph_DocUBetter_meeting","date":"2019-07-10T16:00:00.000Z","updated":"2019-07-11T16:00:00.000Z","comments":true,"path":"2019/07/11/2019-07-10_-_-_Ceph_DocUBetter_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/11/2019-07-10_-_-_Ceph_DocUBetter_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Gabriella（Truman大学学生）、Noah（研发人员）、Mike（研发人员）、David Gallery（其他人员） 会议主题： 讨论和规划Ceph文档改进，包括网站结构、文档内容、文档构建时间等。 主要议题及决定： 文档构建时间优化： Gabriella正在尝试减少文档构建时间，目前已将Sphinx构建与Python绑定构建分离，但效果尚不理想。 讨论了使用更现代的文档框架，如实时编辑功能，以提高文档构建效率。 Noah表示，除非涉及框架变更等根本性问题，否则减少文档构建时间的方法相对简单。 文档内容更新： 从Docks方面，Sarah提到需要更新Docks中的安全组件（safecom）文档，包括为新用户添加新页面或编辑现有页面，使其包含所有必要信息。 讨论了将Ceph仓库中“Docs”目录中的所有信息整合到Docks中，并对其进行结构化。 文档更新要求： 强调任何创建PR的人员都应支持文档更新，包括添加新功能或修改配置值。 如果添加新功能，应至少提供该功能的基本描述，以便用户了解其作用。 其他事项： 讨论了招聘文档编写人员的进展情况，将在下次会议中更新。 后续行动计划： Gabriella继续优化文档构建时间。 Sarah更新Docks文档。 所有创建PR的人员注意文档更新的要求。 下次会议更新招聘文档编写人员的进展情况。 备注： 会议中提到了Ceph的“onboarding”经验，即新用户或新贡献者的入门体验。 会议强调了提高文档质量和用户体验的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-10 :: Ceph Orchestration Meeting","slug":"2019-07-10_-_-_Ceph_Orchestration_Meeting","date":"2019-07-10T16:00:00.000Z","updated":"2019-07-11T16:00:00.000Z","comments":true,"path":"2019/07/11/2019-07-10_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/11/2019-07-10_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Kiefer、Sebastian、Yuri、Nathan、Greg、Zach、Liam、Casey、Abby 等 会议主题： Ceph 项目开发讨论，包括分布式存储 Ceph 的研发、Orchestrator 功能改进、测试策略等。 关键细节： Orchestrator 功能改进： Kiefer 正在开发一个新的 Orchestrator 功能，用于列出主机并展示主机库存。他计划在 Orchestrator 主页上添加一个新页面，列出所有主机，并展示每个主机的详细信息。 Christopher 正在研究如何将驱动器组添加到 Safe Dashboard 中，以提供更复杂的存储配置选项。 测试策略： Nathan 提出了测试 Rook Orchestrator 的问题，并讨论了如何将测试集成到现有的测试套件中。 Greg 提出了在测试中使用不同部署工具的抽象层，以便与现有的测试套件兼容。 David 讨论了 Nautilus 释放的情况，包括发现的问题和修复措施。 其他议题： Liam 讨论了将驱动器组添加到 Safe Dashboard 的合理性。 Sebastian 提出了使用 SSH Orchestrator 替代 Def Deploy 的可能性。 决定的事项： Kiefer 将继续开发新的 Orchestrator 功能，并将其集成到 Ceph 项目中。 Christopher 将研究如何将驱动器组添加到 Safe Dashboard 中。 Nathan 和 Greg 将继续研究测试 Rook Orchestrator 的策略。 David 将继续修复 Nautilus 释放中发现的问题。 后续行动计划： Kiefer 将提供新的 Orchestrator 功能的截图和详细信息。 Christopher 将提供关于将驱动器组添加到 Safe Dashboard 的更多细节。 Nathan 和 Greg 将继续与社区讨论测试 Rook Orchestrator 的策略。 David 将继续修复 Nautilus 释放中发现的问题。 关键词： Orchestrator Dashboard Inventory Hosts Testing Rook Def Deploy SSH Nautilus Ceph 备注： 会议中提到了多个 Ceph 相关项目，包括 Rook、Def Deploy 等。 会议讨论了测试策略的改进，以适应新的 Orchestrator 功能和测试需求。 会议还讨论了 Nautilus 释放的进展和问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-JUN-27 :: Ceph Tech Talk - Intro to Ceph","slug":"2019-JUN-27_-_-_Ceph_Tech_Talk_-_Intro_to_Ceph","date":"2019-07-07T16:00:00.000Z","updated":"2019-07-07T16:00:00.000Z","comments":true,"path":"2019/07/08/2019-JUN-27_-_-_Ceph_Tech_Talk_-_Intro_to_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/08/2019-JUN-27_-_-_Ceph_Tech_Talk_-_Intro_to_Ceph/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Safe、其他Ceph研发人员 会议主题： Ceph分布式存储系统介绍 会议内容： 一、Ceph概述 Ceph是一款开源的分布式存储系统，具备统一存储、可扩展、高可用、高可靠等特点。 Ceph支持对象存储、块存储和文件存储，可满足不同存储需求。 Ceph采用软件定义存储架构，可运行在任何通用硬件上。 二、Ceph架构 Ceph Monitors： 负责认证、数据放置和策略管理，是集群的中心协调点。 Ceph Managers： 聚集实时指标，并提供可插拔的管理功能，如仪表板和自动化任务。 Ceph OSDs： 负责存储数据和处理I/O请求，是集群的工作节点。 Ceph RGW： 提供S3和Swift API兼容的对象存储服务。 Ceph RBD： 提供虚拟块设备接口，用于虚拟机镜像存储。 Ceph FUSE： 提供POSIX分布式文件系统，支持文件和目录操作。 三、Ceph数据存储 Ceph使用CRUSH算法进行数据放置，确保数据在集群中均匀分布，并避免单点故障。 Ceph支持多种数据复制和纠删码策略，确保数据可靠性和可用性。 Ceph使用对象存储格式存储数据，每个对象具有唯一名称和属性。 四、Ceph管理 Ceph提供集成的仪表板，用于监控集群健康、配置和管理集群。 Ceph支持配置管理、监控、故障排除和升级等功能。 Ceph支持设备健康监控和故障预测，可提高系统可靠性。 五、Ceph社区 Ceph是一个活跃的开源社区，拥有来自全球的贡献者。 Ceph与OpenStack、Kubernetes等平台紧密集成，可方便地在云环境中部署和使用。 Ceph组织举办各种活动，如Ceph Days和CephCon，以促进社区交流和知识分享。 后续行动计划： 继续优化Ceph性能和功能。 加强Ceph社区建设，吸引更多开发者参与。 推广Ceph在各个领域的应用。 关键词： Ceph、分布式存储、对象存储、块存储、文件存储、CRUSH算法、Rados、RGW、RBD、FUSE、OpenStack、Kubernetes","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-01 :: Ceph Orchestration Meeting","slug":"2019-07-01_-_-_Ceph_Orchestration_Meeting","date":"2019-07-02T16:00:00.000Z","updated":"2019-07-03T16:00:00.000Z","comments":true,"path":"2019/07/03/2019-07-01_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/03/2019-07-01_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知，但提到了Joan Miguel, Takata, Billy, Nick Payne, Patrick Connelly, Frida, Taste, Element等。 会议主题： Ceph社区讨论，包括Python代码统一、API生成、Orchestrator功能、SD移除、Rook与Ceph的集成、Drive Groups等。 会议关键细节： Python代码统一： 讨论了将Ceph中分散的Python代码统一到一个地方的提案，以减少代码重复并提高代码质量。提议得到了积极的响应，但需要更多人的反馈。 API生成： 讨论了API生成的问题，包括何时触发API生成、API生成后的测试等。决定在API发生变化时触发生成，并要求API变更者负责重建文件和提交新生成的API方法。 Orchestrator功能： 讨论了Orchestrator的功能，包括SD移除、替换OSD等。认为目前SD移除的代码不够清晰，可能存在性能问题。 Rook与Ceph的集成： 讨论了Rook与Ceph的集成，包括如何处理SD移除、替换OSD等。认为Rook需要更好的支持Ceph的驱动组功能。 Drive Groups： 讨论了Drive Groups的功能和实现方式，认为将其集成到Ceph Volume中可以简化操作并提高效率。 决定的事项： 继续推进Python代码统一的提案，并邀请更多社区成员参与反馈。 完善API生成机制，确保API生成的正确性和可靠性。 优化Orchestrator的功能，提高代码质量和性能。 加强Rook与Ceph的集成，提高Rook对Ceph功能的支持。 探索将Drive Groups集成到Ceph Volume中的可能性。 后续行动计划： 继续讨论并完善Python代码统一的提案。 开发API生成工具，并编写相应的测试用例。 优化Orchestrator的功能，并修复相关bug。 与Rook社区合作，改进Rook对Ceph功能的支持。 探索将Drive Groups集成到Ceph Volume中的可能性。 其他： 提到了Ceph社区每周会议和每月上游会议，鼓励大家积极参与。 关键词： Python代码统一、API生成、Orchestrator、SD移除、Rook、Drive Groups、Ceph Volume","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-07-02 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-07-02_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-07-02T16:00:00.000Z","updated":"2019-07-03T16:00:00.000Z","comments":true,"path":"2019/07/03/2019-07-02_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/07/03/2019-07-02_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： [请列出参会人员姓名] 会议主题： Ceph 项目进展讨论 会议内容： 一、Ceph 项目进展 Chromatin Woody 生存性测试： 上周已完成测试，目前处于提交阶段。 Ceph CI 测试： 已将相关代码推送到 CI 仓库，但暂未包含 master 分支。下一步将包含 master 分支并定期运行测试。 API 优化： 讨论了将 API 优化作为代码列表选项之一，并计划添加 API 以便使用。 Boost 结果： 将 Boost 结果引入 Indigo 代码库，并得到了大家的支持。 对象类代码： 讨论了在 Crimson 中实现 lgw 任何权限的代码，并考虑了使用对象类来实现。 错误处理： 讨论了将错误信息转换为可读字符串的方案，以提高错误处理的可读性。 Ceph 文件系统： 讨论了 Ceph 文件系统在 POSIX 网络栈和内核网络中的性能优化问题。 二、具体议题讨论 Chromatin Woody 生存性测试： 已完成测试，目前处于提交阶段。 下一步将包含 master 分支并定期运行测试。 Ceph CI 测试： 已将相关代码推送到 CI 仓库，但暂未包含 master 分支。 下一步将包含 master 分支并定期运行测试。 API 优化： 讨论了将 API 优化作为代码列表选项之一。 计划添加 API 以便使用。 Boost 结果： 将 Boost 结果引入 Indigo 代码库。 得到了大家的支持。 对象类代码： 讨论了在 Crimson 中实现 lgw 任何权限的代码。 考虑了使用对象类来实现。 错误处理： 讨论了将错误信息转换为可读字符串的方案。 提高错误处理的可读性。 Ceph 文件系统： 讨论了 Ceph 文件系统在 POSIX 网络栈和内核网络中的性能优化问题。 讨论了使用 I/O 环 (IO_uring) 进行优化的可能性。 讨论了将预取 (prefetch) 功能作为编译时选项的可行性。 三、行动计划 将 Chromatin Woody 生存性测试代码提交到 master 分支。 定期运行 Ceph CI 测试。 添加 API 以便使用。 实现对象类代码。 将错误信息转换为可读字符串。 评估使用 I/O 环进行优化的可行性。 考虑将预取功能作为编译时选项。 四、其他事项 讨论了 Ceph 在多核心机器上运行时的性能问题。 讨论了 Ceph 在云环境中的性能问题。 会议总结： 本次会议讨论了 Ceph 项目的多个议题，并制定了相应的行动计划。会议内容涵盖了 Ceph 项目的多个方面，包括代码开发、性能优化、错误处理等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-25 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-06-25_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-06-27T16:00:00.000Z","updated":"2019-06-27T16:00:00.000Z","comments":true,"path":"2019/06/28/2019-06-25_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/28/2019-06-25_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目进展及问题讨论 会议内容： 1. CBT与SD测试进展 问题： 上周，某位开发人员在尝试使商业SD卡在CBT上运行时遇到了问题，具体是Columbus大学的PG在激活后无法正常工作。 解决方案： 开发人员通过替换Sam的sims更改来解决该问题，但测试结果显示该功能仍然无法正常工作。 后续行动： 开发人员将再次调查该问题，并尝试找到解决方案。 2. Crimson项目进展 问题： 开发人员仍在尝试将Crimson与CBT更新兼容。 解决方案： 开发人员已更新测试套件，并计划在下午重新运行测试。 后续行动： Alfredo休假归来后，将与其他开发人员一起更新Crimson，使其能够与CBT兼容。 3. 性能测试 问题： 需要部署性能测试并集成到RCI中，以便将最新的性能问题结果作为基准。 解决方案： 将部署性能测试，并将其集成到RCI中。 后续行动： 在合并之前，需要在本地上运行性能测试，并将结果与PR一起发布。 4. 其他讨论 PR审查： 开发人员讨论了如何快速构建系统以审查特定PR，并提出了使用Git工作区和get命令的建议。 代码审查工具： 讨论了使用哪些工具来审查代码，并分享了使用GitHub和Git工作区的经验。 5. 行动计划 开发人员将继续调查CBT与SD测试的问题，并尝试找到解决方案。 开发人员将更新Crimson，使其与CBT兼容。 将部署性能测试并集成到RCI中。 会议总结： 本次会议讨论了Ceph分布式存储项目的进展和问题。开发人员将继续努力解决CBT与SD测试的问题，并更新Crimson项目。此外，还将部署性能测试并集成到RCI中。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-27 :: Ceph Performance Meeting","slug":"2019-06-27_-_-_Ceph_Performance_Meeting","date":"2019-06-27T16:00:00.000Z","updated":"2019-06-27T16:00:00.000Z","comments":true,"path":"2019/06/28/2019-06-27_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/28/2019-06-27_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月某日 参会人员： Mark, Casey, David, Roman, Alfredo, Orlando, Kiki Foo, Radek 等 会议主题： Ceph 分布式存储项目进展及讨论 关键细节： 调试级别调整： 讨论了将 trim 和 boost 的调试级别提高到 20 以上的建议，并决定将 trim 整块代码放入单独的调试模块中。 性能优化： 讨论了禁用 apptracker 可能带来的 20% 到 30% 的性能提升。 分析了删除操作优化，发现 OST 在删除 PG 时花费大量时间，并讨论了优化扫描、预取和预加载到缓存中的策略。 讨论了 steno SD 或 SDHC 卡的恢复最大活跃数，并决定增加并发回填以提升性能。 讨论了 max backfills 和 max active 之间的关系，并决定进行实验以确定是否需要增加 max backfills。 讨论了优化 BlueStore 缓存，包括避免重复缓存和缓存旋转等。 性能测试： 讨论了在硅谷进行性能测试，并计划设置持续性能基准测试，以便在发布分支中测试新功能。 讨论了 Jenkins 和 GitHub 的集成，以及使用 GitHub API 进行结果发布。 讨论了性能测试标签和回归检测，以及如何确定回归的阈值。 硬件测试： 讨论了 Intel 提供的新 Officalis 集群，包括 TLC 和 QLC 驱动器的配置。 讨论了将节点迁移到 Jenkins 以进行性能回归测试。 讨论了将高效能节点用于 PR 测试。 决定事项： 将 trim 和 boost 的调试级别提高到 20 以上。 将 trim 整块代码放入单独的调试模块中。 禁用 apptracker 进行性能测试。 优化删除操作，包括扫描、预取和预加载。 增加并发回填以提升性能。 进行实验以确定是否需要增加 max backfills。 优化 BlueStore 缓存，包括避免重复缓存和缓存旋转。 在硅谷进行性能测试，并设置持续性能基准测试。 使用 Jenkins 和 GitHub 进行集成，并发布测试结果。 使用 GitHub API 进行结果发布。 确定性能测试标签和回归检测的阈值。 使用 Intel 提供的新 Officalis 集群进行测试。 将节点迁移到 Jenkins 以进行性能回归测试。 将高效能节点用于 PR 测试。 后续行动计划： 进行 trim 和 boost 调试级别调整的测试。 进行禁用 apptracker 和优化删除操作的测试。 进行 steno SD 或 SDHC 卡的恢复最大活跃数和 max backfills 的实验。 优化 BlueStore 缓存。 设置持续性能基准测试。 完成 Jenkins 和 GitHub 的集成。 进行性能测试标签和回归检测的测试。 准备 Intel 提供的新 Officalis 集群。 将节点迁移到 Jenkins。 将高效能节点用于 PR 测试。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-24:: Ceph Orchestration Meeting","slug":"2019-06-24_-_-_Ceph_Orchestration_Meeting","date":"2019-06-27T16:00:00.000Z","updated":"2019-06-27T16:00:00.000Z","comments":true,"path":"2019/06/28/2019-06-24_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/28/2019-06-24_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年6月24日 会议主题： Orchestrator 周会 参会人员： 多位Orchestrator团队成员 会议内容： 1. RGW区域设置讨论 成员提到在实施RGW区域设置时遇到的问题，尤其是在配置Amazon S3组时需要访问所有组，这导致配置过程较为繁琐。 讨论了Rook的设计，其中默认情况下不允许用户选择任何区域组，而是将它们放入一个依赖组中。 决定将节点管理和配置分开处理，使用默认配置和特定的指示来添加或删除节点。 讨论了邀请Matt Benjamin团队的人员参与审查和提供建议，以帮助设计更合适的配置方案。 2. Orchestrator自命名空间包 讨论了将Python代码抽取到公共包中的想法，这是一个很好的想法，但可能会带来很多风险和代码重构。 决定在Sebastian返回后，在下次会议上讨论此问题。 3. Rook进展 Sebastian介绍了Rook的最新进展，包括连接外部集群和部署NFS的PR。 讨论了PR中的一些冲突，Sebastian表示将重新提交改进升级的PR。 4. 治理和CI/CD 讨论了治理的更新，以及如何处理CI/CD中的问题。 讨论了如何处理 Skip CI 标志和构建失败的情况。 5. 基于PVC的OSD设计 讨论了基于PVC的OSD设计进展，以及设备集的考虑。 6. OSD重设计 讨论了Peter提出的OSD重设计，以及如何解决合并冲突和功能不匹配等问题。 讨论了将命令运行器框架应用于Semoran检查器，并构建一个基本的管道结构。 后续行动计划： 与Matt Benjamin团队沟通，获取关于RGW区域设置的建议。 在下次会议上讨论Orchestrator自命名空间包的问题。 继续推进Rook的PR。 解决CI/CD中的问题。 完成基于PVC的OSD设计。 完成OSD重设计。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-20 :: Ceph Performance Meeting","slug":"2019-06-20_-_-_Ceph_Performance_Meeting","date":"2019-06-19T16:00:00.000Z","updated":"2019-06-20T16:00:00.000Z","comments":true,"path":"2019/06/20/2019-06-20_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/20/2019-06-20_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员 会议主题： Ceph项目进展、问题讨论及后续行动计划 会议内容： 一、新功能请求 蓝星缓存改进： 本周有两个与蓝星缓存相关的功能请求，其中一个被另一个替代，但都涉及蓝星缓存的改进。 Paddy Aura： Paddy Aura的popup history功能进展良好，反映了缓存情况。 Journal性能证明： Jason的功能请求证明了journal性能，已合并。 Peachy映射缓存： 上周已合并，用于存储给定OST映射的重算计算，显著提高了性能。 Sun的恢复操作优先级提升： Sun将恢复操作的优先级提升，以便在客户端操作触发时更加高效。 Igor修复Blue Store问题： Igor修复了Blue Store的一些极端情况问题，避免了ID耗尽。 Adam的Objector工作： Adam的Objector工作正在进行中，Casey表示正在重构librettists库，并与rgw进行整合。 优化对象创建操作： 一个优化对象创建操作的PR即将合并，可以跳过Blue Store中的查找，提高效率。 二、垃圾回收 垃圾回收性能： 讨论了垃圾回收的性能问题，并提出了改进建议。 三、Blue Store/Orcs关闭 Stan和Pat： Stan和Pat正在努力关闭Blue Store或Orcs。 四、其他讨论 能量消耗： 讨论了能量消耗问题，并提出了改进建议。 性能提升： 讨论了性能提升问题，并提出了改进建议。 恢复操作优化： 讨论了恢复操作的优化问题，并提出了自适应恢复的方案。 安全模式： 讨论了安全模式的使用和性能影响，并提出了性能测试和优化建议。 全闪存性能： 讨论了全闪存性能问题，并提出了改进建议。 五、后续行动计划 性能测试： 进行安全模式的性能测试，并分析性能影响。 优化代码： 优化垃圾回收、安全模式和全闪存性能相关的代码。 自适应恢复实现： 实现自适应恢复功能。 性能分析： 使用性能分析工具分析性能瓶颈。 六、其他 会议中提到了一些其他问题，如日志性能、锁竞争等，并提出了改进建议。 总结： 本次会议讨论了Ceph项目的多个方面，包括新功能请求、性能优化、安全模式、自适应恢复等。会议确定了后续行动计划，并要求相关人员完成相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-19 :: Ceph Orchestration meeting","slug":"2019-06-19_-_-_Ceph_Orchestration_meeting","date":"2019-06-18T16:00:00.000Z","updated":"2019-06-18T16:00:00.000Z","comments":true,"path":"2019/06/19/2019-06-19_-_-_Ceph_Orchestration_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/19/2019-06-19_-_-_Ceph_Orchestration_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： （未提及姓名，但提到了以下人员：huh, me, paint him, Joshua, Brooke, Jim, Timm, Sebastian, Pierre, John Spray, Travis） 会议主题： 讨论Ceph分布式存储的RTW（Rook Toolkit）服务接口、调度器（Orchestrator）功能以及后续行动计划。 会议内容： 会议时间调整： 由于新西兰的参会者时间较晚，会议决定将会议时间提前，以便所有参会者都能参加。 会议时间初步定于下午5:30。 安全守护者（Safe Demon）探讨： Joshua提出探讨安全守护者技术，这可能有助于所有调度器，特别是Essentia Orchestrator，以封装运行容器镜像所需的所有操作。 目前这一想法还处于概念阶段，没有代码实现。Rock Point方面有一个相关的pull request。 接口讨论： 讨论了现有RTW服务接口存在的问题，包括不愉快的端点和RTW更新名称风格。 提出了改进接口的建议，例如提供新的端点以创建新的存储桶、配置新的存储桶组等。 讨论了将服务器管理、存储桶组管理和RDW结构管理分离的必要性。 RDW结构管理： 讨论了RDW结构管理的最佳实践，包括使用Rook的admin命令进行管理，以便任何工具都可以轻松地进行此类管理。 强调了将RDW网关命令封装在调度器之外的重要性。 Rook与Ceph的集成： 讨论了Rook与Ceph集成的细节，包括RDW网关和RDW实例之间的区别。 提出了将RDW网关视为默认区域，除非显式指定其他区域。 其他议题： Timm提到他在缓存库存和服务方面的工作进展，并已合并了Sebastian和Pierre的修改。 讨论了Ganesha的pull request以及与Dipsy编排相关的端点URL。 行动计划： 调整会议时间，确保所有参会者都能参加。 Joshua继续研究安全守护者技术。 改进RTW服务接口，包括提供新的端点和改进命令。 分离服务器管理、存储桶组管理和RDW结构管理。 进一步研究Rook与Ceph的集成细节。 Timm继续进行缓存库存和服务的工作，并合并相关pull request。 备注： 会议中提到了一些关键术语，如RTW服务、调度器、RDW、Rook、Ceph等，这些术语在会议记录中已保留英文原文。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-19 :: Container Huddle - DeviceSet discussion","slug":"2019-06-19_-_-_Container_Huddle_-_DeviceSet_discussion","date":"2019-06-18T16:00:00.000Z","updated":"2019-06-19T16:00:00.000Z","comments":true,"path":"2019/06/19/2019-06-19_-_-_Container_Huddle_-_DeviceSet_discussion/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/19/2019-06-19_-_-_Container_Huddle_-_DeviceSet_discussion/","excerpt":"","text":"会议纪要 会议主题： 讨论PR3：06中存储类设备集的当前状态和设计 会议时间： 2023年11月（具体日期未知） 参会人员： 不详 会议内容： 一、会议背景 当前Ceph集群在动态环境中运行时，需要基于全局唯一标识符（GUB）来管理状态，这需要在Kubernetes中本地提供设备，并使用主机路径绑定存储，这种方式存在一些局限性。 为了解决这些问题，提出了存储类设备集的概念，它允许在Kubernetes中动态地创建存储设备，并使用PVC来管理这些设备。 二、主要议题 存储类设备集的设计： 存储类设备集将使用Kubernetes原生的方式在集群CR（Cluster Resource）中指定所需的存储容量和设备数量。 操作员可以根据这些信息创建OSD，并确保它们在域内或根据集群CR中的配置进行分布。 操作员将启动或创建PVC，并为每个PVC启动OSD准备Pod，然后根据准备Pod的结果启动OSD守护进程。 存储类设备集的设计将采用与现有OSD创建模式相同的模式，主要区别在于基于PVC而不是节点启动主机准备Pod。 资源管理和放置： 存储类设备集将包含资源字段，用于指定OSD Pod的资源需求（CPU和内存）。 放置字段将允许操作员指定OSD Pod的放置策略，例如在特定的可用区或节点上。 需要讨论资源管理和放置字段是否应该包含在存储类设备集中，以及如何处理不同类型设备之间的资源需求差异。 OSD管理： 建议使用StatefulSet来管理OSD Pod，这将为每个OSD Pod提供唯一的标识符，并允许在失败时进行故障转移。 需要讨论如何处理多个OSD Pod共享同一PVC的情况，以及如何确保每个Pod都具有唯一的OSD ID。 三、决定事项 继续讨论资源管理和放置字段是否应该包含在存储类设备集中，并考虑使用DriveGroup Beck来管理设备。 讨论如何使用StatefulSet来管理OSD Pod，并确保每个Pod都具有唯一的OSD ID。 更新设计文档，并提供有关资源管理和放置的示例。 四、后续行动计划 更新设计文档，并提供有关资源管理和放置的示例。 讨论并确定资源管理和放置字段是否应该包含在存储类设备集中。 研究如何使用StatefulSet来管理OSD Pod，并确保每个Pod都具有唯一的OSD ID。 完成存储类设备集的设计和实现。 五、其他 会议中讨论了DriveGroup Beck的概念，并探讨了如何将其用于存储类设备集的实现。 讨论了使用PVC进行设备放置时的限制，例如无法使用亲和性策略。 总结： 本次会议讨论了存储类设备集的设计和实现，并确定了后续行动计划。该设计旨在解决Ceph集群在动态环境中运行时存在的问题，并提高存储管理的灵活性和可扩展性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-19 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-06-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-06-18T16:00:00.000Z","updated":"2019-06-18T16:00:00.000Z","comments":true,"path":"2019/06/19/2019-06-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/19/2019-06-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员，包括负责Ceph存储、视频会议字幕翻译及总结的人员 会议主题： 讨论Ceph存储性能测试、代码布局、异常处理、Sister API扩展等议题 会议内容： 1. Ceph存储性能测试 一位研发人员汇报了Ceph存储性能测试的最新进展，包括对相邻缓冲指针合并工作的改进和性能测试结果的更新。 讨论了与CI/CD集成的性能测试，提出了一种绕过主分支和C/Stark权限的方法，以实现更长时间的性能测试。 2. 代码布局 讨论了Ceph代码布局，包括管道和管道阶段的命名和实现方式。 提出了一种将逻辑移出PG分析器的做法，并讨论了是否需要对此进行更改。 3. 异常处理 讨论了Ceph代码中的异常处理方式，包括try-catch语句的使用。 讨论了如何处理异常和错误，以及如何确保异常能够被正确捕获和传播。 4. Sister API扩展 讨论了Sister API的扩展，包括对输入缓冲区工厂和精确读取的支持。 讨论了如何处理DPDK和POSIX网络栈之间的差异，以及如何确保数据对齐和连续性。 5. 其他议题 讨论了Ceph存储的延迟特性，以及如何优化性能。 讨论了如何处理不同类型的网络栈，以及如何为不同的用例选择最佳的网络栈。 决定事项： 继续推进Ceph存储性能测试和代码布局的改进。 继续讨论Sister API扩展的细节，并制定相应的实现方案。 在Sister讨论列表上继续讨论Sister API扩展和输入缓冲区工厂的细节。 后续行动计划： 研发人员将继续推进Ceph存储性能测试和代码布局的改进。 研发人员将制定Sister API扩展的实现方案，并进行相应的测试。 研发人员将继续讨论Sister API扩展和输入缓冲区工厂的细节。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-17:: Ceph Orchestration Meeting","slug":"2019-06-17_-_-_Ceph_Orchestration_Meeting","date":"2019-06-16T16:00:00.000Z","updated":"2019-06-16T16:00:00.000Z","comments":true,"path":"2019/06/17/2019-06-17_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/17/2019-06-17_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题： Octopus 项目路线图讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Octopus项目成员，包括负责SSH Orchestrator、Rook Traverse、ESS Afton等模块的开发人员。 会议内容： 一、SSH Orchestrator 讨论重点： SSH Orchestrator是会议主要讨论的议题。目前存在一个API断裂的风险，团队决定等待该问题解决后再考虑对Rope Orchestrator的修改。 行动计划： 关注SSH Orchestrator的进展，等待API断裂问题解决。 研究Rope Orchestrator的修改方案。 二、Rook Traverse 讨论重点： Rook Traverse项目成员将缺席本次会议。 行动计划： 无。 三、动态生成STI 讨论重点： 针对云环境，提出动态生成STI的请求，以支持集群扩展。 行动计划： 完成设计文档。 研究将所有T设备背后的存储池信息集成到本地存储集群中。 四、ESS Afton 讨论重点： ESS Afton项目需要做一些架构变更，以支持将核心功能迁移到上游。 行动计划： 组建文档，为后续讨论提供基础。 Sebastian将加入会议，并贡献自己的力量。 五、升级测试 讨论重点： 针对Octopus的升级测试，需要确保所有组件都经过充分的测试。 行动计划： 确保所有组件都经过升级测试。 考虑在下一个周期进行全面的升级测试。 六、资源分配 讨论重点： 针对Octopus项目的资源分配。 行动计划： Octopus项目团队将专注于Rook和Rook Traverse的开发。 研究如何将一些部署自动化功能集成到Orchestrator层或其之上。 七、其他 讨论重点： 如何将一些部署自动化功能集成到Orchestrator层或其之上。 如何简化集群部署流程。 如何解决容器镜像管理问题。 行动计划： 研究将部署自动化功能集成到Orchestrator层或其之上。 研究简化集群部署流程的方法。 解决容器镜像管理问题。 八、后续行动 各团队成员将根据会议讨论的内容，执行相应的行动计划。 定期召开会议，跟踪项目进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-13 :: Ceph Performance Meeting","slug":"2019-06-13_-_-_Ceph_Performance_Meeting","date":"2019-06-12T16:00:00.000Z","updated":"2019-06-13T16:00:00.000Z","comments":true,"path":"2019/06/13/2019-06-13_-_-_Ceph_Performance_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/13/2019-06-13_-_-_Ceph_Performance_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Neha, Sage, Radek, Adams, Jason, Eric, Orlando, Roman, Mark Cogan, Tiago, Igor, Josh 等 会议内容： 一、Ceph 项目进展 Neha： 已添加对 CBT 或病理学任务中新的客户端端点的支持，正在进行最终测试。 Sage： 正在审查 PG 映射缓存 PR，该 PR 提供了显著的性能提升。 Radek： 正在努力优化输入缓冲区工厂，以改善 Crimson 的性能。 Adams： 正在开发新的 shirt and blue 存储迭代，需要审查。 Jason： 提交了异步消息 PR，降低了调用次数，并提高了性能。 Eric： 正在进行多点同步公平性工作，已进入 2003 测试阶段。 Roman： 正在进行 IO 环境引擎工作，需要重新审查。 Mark Cogan： 正在进行分布式数据缓存 PR，已审查。 Igor： 审查了 mall P PR，该 PR 提高了 Auto Tuning 的启动效率。 Tiago： 正在进行分布式数据缓存 PR，已审查。 二、Ceph 测试平台（CBT） Neha： CBT 支持客户端端点，可以用于 Crimson 测试和夜间测试。 讨论： 讨论了 CBT 的未来发展方向，包括： 支持更多安装方法，例如 Ansible 后端。 自动发现集群信息。 支持容器化测试。 UI 和结果解析工作。 三、RocksDB Orlando： 正在开发 CBT 图形和结果解析功能。 Adams： RocksDB 的数据布局需要仔细考虑，以避免重复和性能问题。 四、其他 讨论： 讨论了其他一些 PR 和议题，例如用户空间 IO 事件、MDS 缓存内存限制自动调整等。 五、行动计划 Neha：完成客户端端点支持测试。 Sage：完成 PG 映射缓存 PR 的审查。 Radek：完成输入缓冲区工厂优化。 Adams：完成 shirt and blue 存储迭代 PR 的审查。 Jason：继续优化异步消息。 Eric：完成多点同步公平性测试。 Roman：重新审查 IO 环境引擎 PR。 Mark Cogan：继续进行分布式数据缓存开发。 Igor：继续进行 mall P 开发。 Tiago：继续进行分布式数据缓存开发。 Orlando：继续开发 CBT 图形和结果解析功能。 Adams：优化 RocksDB 数据布局。 其他成员：继续关注和参与 Ceph 项目开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Octopus Roadmap Planning series: RADOS","slug":"Ceph_Octopus_Roadmap_Planning_series_-_RADOS","date":"2019-06-12T16:00:00.000Z","updated":"2019-06-13T16:00:00.000Z","comments":true,"path":"2019/06/13/Ceph_Octopus_Roadmap_Planning_series_-_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/13/Ceph_Octopus_Roadmap_Planning_series_-_RADOS/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 会议记录未提及具体人员，但提到了以下关键词：Josh、Caroline、ZTE、Sam、Kyle、Anaya、Daniel、Susan、Marcus、Rock 会议内容： 一、Ceph Octopus版本更新 EC数据恢复： EC数据恢复功能已基本准备就绪，将加入Octopus版本。 容量不足警告： 将在Octopus版本中加入容量不足警告功能，用于检测Rush级别X的失败容忍度。 自适应恢复设置： 讨论了自适应恢复设置，可能需要更详细的讨论，但确定将其加入Octopus版本。 QoS和队列深度管理： 讨论了QoS和队列深度管理，可能需要更多讨论，但确定将其加入Octopus版本。 集群健康监控： 讨论了集群健康监控，包括OSU报告、OSCE剪贴板和PI时间等，可能需要更多讨论，但确定将其加入Octopus版本。 ping回复时间： 讨论了ping回复时间，可能需要更详细的监控，但确定将其加入Octopus版本。 3因子服务器： 讨论了3因子服务器，可能需要更多讨论，但确定将其加入Octopus版本。 预同步深度睡眠或删除命令： 讨论了预同步深度睡眠或删除命令，可能需要更多讨论，但确定将其加入Octopus版本。 快照： 讨论了快照，可能需要更多讨论，但确定将其加入Octopus版本。 注入配置选项： 讨论了注入配置选项，可能需要更多讨论，但确定将其加入Octopus版本。 LTTE和j trace points： 讨论了LTTE和j trace points，可能需要更多讨论，但确定将其加入Octopus版本。 本地读取测试： 讨论了本地读取测试，可能需要更多讨论，但确定将其加入Octopus版本。 新的健康警告： 讨论了新的健康警告，可能需要更多讨论，但确定将其加入Octopus版本。 Mon和BlueStore： 讨论了Mon和BlueStore，可能需要更多讨论，但确定将其加入Octopus版本。 内存目标： 讨论了内存目标，可能需要更多讨论，但确定将其加入Octopus版本。 消息传递： 讨论了消息传递，可能需要更多讨论，但确定将其加入Octopus版本。 网络安全： 讨论了网络安全，可能需要更多讨论，但确定将其加入Octopus版本。 哈希缓存： 讨论了哈希缓存，可能需要更多讨论，但确定将其加入Octopus版本。 二、后续行动计划 各参会人员根据会议讨论内容，制定详细的技术方案和开发计划。 定期召开会议，跟踪项目进度，及时解决遇到的问题。 与社区保持密切沟通，收集用户反馈，持续改进Ceph产品。 三、其他事项 讨论了Ceph社区中的一些热点话题，例如Ceph版本发布、社区活动等。 对Ceph未来的发展方向进行了展望。 四、会议总结 本次会议讨论了Ceph Octopus版本更新计划，明确了后续行动计划，为Ceph社区的未来发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-12:: Ceph DocUBetter meeting","slug":"2019-06-12_-_-_Ceph_DocUBetter_meeting","date":"2019-06-11T16:00:00.000Z","updated":"2019-06-12T16:00:00.000Z","comments":true,"path":"2019/06/12/2019-06-12_-_-_Ceph_DocUBetter_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/12/2019-06-12_-_-_Ceph_DocUBetter_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Mike, Noah, Ike, Greg, David, Barry 等 会议主题： 讨论关于文档承包商角色的职责、资格和奖金，以及如何改进文档和用户体验。 关键细节： 新角色： 讨论了一个新的文档承包商角色，旨在改进Ceph项目的文档和用户体验。 职责： 维护和更新上游用户文档。 与开发者和用户合作开发所需内容。 提高新贡献者的入职文档。 资格和奖金： 讨论了候选人的资格要求和奖金结构。 招聘流程： 讨论了招聘流程和预算分配。 改进文档： 讨论了如何改进现有文档，包括： 创建5-10分钟的总结性技术文章，介绍不同组件。 更新和改进入职文档。 记录配置选项。 其他事项： 讨论了如何改进会议记录的结构。 讨论了如何改进视频会议的设置。 主要议题： 如何定义“所需内容”。 如何改进新贡献者的入职流程。 如何改进文档和用户体验。 决定的事项： 将讨论的文档承包商角色的职责、资格和奖金等细节发送给John进行审核。 在下一场董事会会议上进一步讨论招聘流程和预算分配。 继续改进文档和用户体验。 后续行动计划： Mike将回复John，请求他审核文档承包商角色的职责描述。 在下一场董事会会议上，进一步讨论招聘流程和预算分配。 继续改进文档和用户体验。 计算机科学/ceph相关领域英文原文关键词： Documentation contractor Onboarding documentation Technical writer User experience Ceph project Community Documentation improvements","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-12:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-06-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-06-11T16:00:00.000Z","updated":"2019-06-12T16:00:00.000Z","comments":true,"path":"2019/06/12/2019-06-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/12/2019-06-12_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： Lisa, Sam, Riddick, Robin, Tamara 等 会议主题： Ceph分布式存储项目开发讨论 会议内容： 一、Crimson Flavor 新特性 新 Flavor 引入： 将引入新的 Crimson Flavor，用于病理学安装任务和 CBD 测试，作为性能基准与 CI 中的性能测试进行比较。 测试计划： 将进行性能测试，使用 Crimson 包验证 PR，并逐步将其纳入夜间测试。 二、Jenkins 和 Make Check 集成 测试参数： 将使用与 CBT 相同的简单测试集，用于 Jenkins 和 Make Check 的验证。 正确性测试： 需要能够运行低级和崩溃测试，以验证 OSD 功能。 三、输入缓冲区概念 RFC 第三版： 推出了支持输入缓冲区概念的 RFC 第三版，该概念支持基本对齐和额外部分。 性能测试： 进行了性能测试，并提供了测试结果。 四、内存对齐问题 scatter gather 问题： 使用 scatter gather 读取大块数据时，可能会遇到内存对齐问题。 解决方案： 推出输入缓冲区工厂，以提供更灵活的内存管理，并解决对齐问题。 五、其他讨论 private 接口： 讨论了在连接中使用 private 接口的问题，以确保不会滥用该接口。 数据段读取： 讨论了如何正确读取数据段，并确保数据对齐。 后续行动计划： 完成输入缓冲区概念的实现。 更新安装任务，以使用 Crimson Flavor。 完成性能测试，并逐步将其纳入夜间测试。 完成RFC第三版的审查和反馈。 备注： 会议中提到了一些计算机科学/ceph相关领域英文原文的关键词，如：Crimson Flavor、performance testing、input buffer factory、scatter gather、private interface 等。 会议讨论的内容涵盖了会议的关键细节、讨论的主要议题、决定的事项以及后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-12 :: Ceph Testing Weekly","slug":"2019-06-12_-_-_Ceph_Testing_Weekly","date":"2019-06-11T16:00:00.000Z","updated":"2019-06-12T16:00:00.000Z","comments":true,"path":"2019/06/12/2019-06-12_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/12/2019-06-12_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： （未提及具体日期，请补充） 会议地点： （未提及具体地点，请补充） 参会人员： （未提及具体人员，请补充） 会议内容： 1. Ceph 升级降级问题 Josh 和其他成员正在尝试实现 Ceph 的降级功能。 目前遇到了问题，需要提交 PR 进行测试，但相关成员暂时无法完成。 讨论了基于 Nautilus 的点对点降级模型，并计划将其应用到 Octopus 版本。 对于跨版本降级，目前还没有具体计划。 2. smoke 测试 目前 smoke 测试已通过，主要修复了与 suite 相关的失败任务。 讨论了是否可以不定期运行 Raiders 测试，以减少测试任务数量并提高效率。 提出了将测试任务运行在虚拟化环境中的问题，并讨论了使用 OVH 等云服务提供商的可能性。 3. 测试用例 讨论了使用快照进行升级和降级的测试用例。 认为需要在升级前后进行数据一致性和兼容性测试。 讨论了使用 snapshot 和 binary phase 的可能性和复杂性。 4. 多操作系统测试 讨论了多操作系统测试用例的改进。 认为需要在测试用例中考虑不同操作系统之间的兼容性问题。 5. 其他事项 讨论了与 Red Hat 等下游发行版合作的可能性。 讨论了如何更好地与社区成员沟通和协作。 行动计划： Josh 将与相关成员合作，解决降级功能遇到的问题。 继续优化 smoke 测试，并探讨不定期运行 Raiders 测试的可能性。 完善测试用例，确保升级和降级操作的安全性。 改进多操作系统测试用例，提高兼容性。 加强与社区成员的沟通和协作。 关键词： Ceph 升级降级 smoke 测试 snapshot binary phase 多操作系统测试","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Nobody Knows What PGs are Good For, Only I Do - Danil Kipnis, 1&1 IONOS Cloud GmbH","slug":"Nobody_Knows_What_PGs_are_Good_For_Only_I_Do_-_Danil_Kipnis_1_1_IONOS_Cloud_GmbH","date":"2019-06-09T16:00:00.000Z","updated":"2019-06-10T16:00:00.000Z","comments":true,"path":"2019/06/10/Nobody_Knows_What_PGs_are_Good_For_Only_I_Do_-_Danil_Kipnis_1_1_IONOS_Cloud_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/10/Nobody_Knows_What_PGs_are_Good_For_Only_I_Do_-_Danil_Kipnis_1_1_IONOS_Cloud_GmbH/","excerpt":"","text":"会议纪要 会议主题： 分布式存储架构讨论及Ceph相关技术探讨 参会人员： Daniel（Iona云服务基础设施团队） 会议内容： 一、Iona云服务架构介绍 存储架构： Iona云服务为每个客户虚拟机提供两个不同的存储机器，并将卷通过网络导出到虚拟机管理器，形成RAID 1。这种架构通过增加新的存储机器对来扩展集群规模，并需要迁移旧卷以平衡集群负载。 目标： 向分布式块存储发展，使每个客户卷存储在集群中的每个机器上，以实现最高的吞吐量。 二、分布式存储面临的挑战 数据冗余与故障影响： 如果每个卷分散在所有机器上，虽然提高了读写吞吐量，但集群中任何故障都可能影响所有客户卷。 数据共享与恢复风险： 如果每个磁盘的数据与集群中的其他磁盘共享，虽然提高了读写吞吐量，但在恢复过程中其他磁盘发生故障的概率也较高。 三、Ceph PG间接层解决方案 PG间接层： 通过在集群中引入PG（Placement Group）间接层，可以解决上述问题。PG间接层通过以下方式实现： 数据分布控制： 控制数据分布到物理设备上的数量，实现数据冗余。 去聚类控制： 控制恢复单个故障设备所需的时间，以及该设备与其他设备共享数据的数量。 PG间接层的优势： 提供了数据分布和去聚类的控制能力。 是实现关键复制策略和集群扩展的通用框架。 四、Ceph集群配置示例 RPG（Replication Placement Group）： RPG位于RADOS对象之上，通过哈希映射到放置组，放置组存储在OSD上。 客户卷配置： 每个客户卷通过网络协议（如SRP、iSCSI）导出到客户端，客户端在本地构建RAID数组，并使用与Crash相同的配置方法来管理此类配置。 五、会议结论 Ceph PG间接层是解决分布式存储面临挑战的有效方法。 需要进一步研究和探讨Ceph集群配置和优化策略。 后续行动计划： Daniel将继续研究Ceph集群配置和优化策略。 团队将关注Ceph社区动态，学习借鉴最佳实践。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-05 :: Ceph Developer Monthly part 1","slug":"2019-06-05_-_-_Ceph_Developer_Monthly_part_1","date":"2019-06-06T16:00:00.000Z","updated":"2019-06-06T16:00:00.000Z","comments":true,"path":"2019/06/07/2019-06-05_-_-_Ceph_Developer_Monthly_part_1/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/07/2019-06-05_-_-_Ceph_Developer_Monthly_part_1/","excerpt":"","text":"会议主题： Ceph 存储系统开发讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Lily, Justin, Jason, Josh, Jr., Patrick, Aashish, Casey 等 会议内容： 一、RBD 云迁移功能 背景： RBD 云迁移功能自 Jewel 版本以来一直存在，但使用率不高，存在 journaling 和可路由网络问题。 改进方案： 提供多种可选镜像模式，包括基于周期性计划的自动快照和按需迁移。 扩展跨集群实时迁移功能，以加快迁移过程。 考虑使用 Radios 代理或类似技术来解决可路由网络问题。 考虑使用推模型而不是拉模型来提高效率。 考虑使用伪存储桶来实现多站点 RGW 复制。 二、快照管理 背景： 用户需要更灵活的快照管理功能。 改进方案： 提供基于子目录的快照计划，包括定时快照和保留策略。 提供独立的快照计划和修剪计划，以提高灵活性。 考虑使用卷名称而不是文件系统名称来指定快照路径。 考虑限制快照创建速率，以避免性能问题。 三、灾难恢复 背景： 用户需要更简单的灾难恢复解决方案。 改进方案： 提供基于快照的灾难恢复模式，包括源目录、目标目录和同步频率。 提供更高效的快照复制机制，例如使用 rsync 或类似工具。 提供回滚功能，以便在灾难发生时恢复数据。 四、集群进度监控 背景： 用户需要更详细的集群进度监控信息。 改进方案： 扩展进度模块，以跟踪更广泛的集群活动，例如 OSD 备份、数据恢复和负载均衡。 为进度事件添加完成时间估算，以便用户了解恢复进度。 五、降级支持 背景： 用户需要支持降级到旧版本。 改进方案： 使用现有的升级测试套件来测试降级。 更小心地处理向后兼容性，以避免破坏现有集群。 后续行动计划： Jason 将准备更详细的提案，包括新的镜像模式和灾难恢复功能。 Lily 和 Justin 将继续改进快照管理功能。 Josh 和 Jr. 将继续改进进度模块。 Casey 将考虑降级支持。 其他事项： 会议讨论了如何改进 Ceph 的文档和测试。 会议讨论了如何提高 Ceph 的性能和可靠性。 关键词： RBD 云迁移 快照 灾难恢复 进度监控 降级支持","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-05 :: Ceph Developer Monthly part 2","slug":"2019-06-05_-_-_Ceph_Developer_Monthly_part_2","date":"2019-06-06T16:00:00.000Z","updated":"2019-06-06T16:00:00.000Z","comments":true,"path":"2019/06/07/2019-06-05_-_-_Ceph_Developer_Monthly_part_2/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/07/2019-06-05_-_-_Ceph_Developer_Monthly_part_2/","excerpt":"","text":"会议纪要 会议时间： [请填写会议日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph 分布式存储系统功能标志、升级降级策略及测试方案讨论 会议内容： 一、功能标志与升级降级策略 功能标志： 讨论了在升级和降级过程中引入新的方法，如 RVD 特性用于滚动 OSD 上的客户端使用情况。同时，讨论了是否需要为类似功能添加计费机制。 缺失的功能标志： 指出在 RW 方式中缺少一些功能标志，特别是 RDW 特性，需要重点关注。 COS 守护进程版本： 强调了基于 COS 守护进程的版本信息对于确定基础版本的重要性。 升级降级策略： 讨论了在升级过程中是否允许降级，以及如何处理不兼容的更新。提出了一种策略，即在特定版本系列中明确决定不支持从 5.4 版本降级。 特殊版本发布： 提出在发布说明中明确指出某些特殊版本不支持降级，以避免用户误解。 迁移路径： 讨论了在引入重大变更时，需要提供迁移路径，以便用户能够选择不访问某些功能。 二、测试方案 测试自动化： 提出了使用 Jenkins 测试和编写脚本来自动检测代码中数值变化的建议，以便进行额外的审查。 向后兼容性测试： 讨论了如何使用旧代码版本与新构建的代码进行交互，以测试向后兼容性。 自动化测试套件： 讨论了构建一个自动化测试套件，以生成更具代表性的测试用例，并检测潜在的不兼容性。 三、行动计划 与 URI 合作，基于现有的 PGP 套件进行测试。 尝试为现有工作负载添加更多测试用例。 开发自动化工具，以检测代码中数值变化。 构建自动化测试套件，以生成更具代表性的测试用例。 四、其他事项 会议结束时，没有其他事项需要讨论。 会议总结： 本次会议讨论了 Ceph 分布式存储系统功能标志、升级降级策略及测试方案。会议明确了相关策略和行动计划，为后续开发工作提供了指导。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-03:: Ceph Orchestration Meeting","slug":"2019-06-03_-_-_Ceph_Orchestration_Meeting","date":"2019-06-06T16:00:00.000Z","updated":"2019-06-06T16:00:00.000Z","comments":true,"path":"2019/06/07/2019-06-03_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/07/2019-06-03_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员，包括负责分布式存储Ceph的研发人员、视频会议字幕翻译及总结人员等。 会议主题： 讨论Ceph Orchestrator和Nautilus的进展，以及相关技术挑战和解决方案。 会议内容： 1. Dashboard讨论 讨论是否将Dashboard作为Orchestrator的一部分进行讨论。 确定Dashboard将主要关注集成到Orchestrator中。 讨论Dashboard的可用性，以及远程拨入的可能性。 确定在两周后的面对面会议中讨论Dashboard。 2. Nautilus进展 讨论Nautilus中Nathan提交的多个pull request。 讨论回滚Orchestrator更改的哲学，以及将更改回滚到master分支的目标。 讨论将Rook模块作为Rook模块添加到Octopus的可行性。 3. AP状态管理 讨论AP状态管理中的一些疑问和困难，特别是在没有使用AKS的情况下。 讨论默认配置和手动配置的问题。 讨论Rook允许创建多个对象存储区域，但没有允许它们跨集群工作的限制。 讨论最终用户对配置参数的控制。 4. Orchestrator API一致性 讨论不同Orchestrator之间API不一致性问题。 讨论是否应该将update操作仅实现于Rook和Kubernetes中，并使用其他Orchestrator的其他操作。 讨论如何使Dashboard能够处理不同Orchestrator的API调用。 5. Rook API更新 讨论Rook API的更新，包括添加新的命令和参数。 讨论如何处理Rook API中的update和remove操作。 6. Rook治理 讨论Jared提交的Rook治理更新PR，包括添加更多具有push访问权限的“所有者”。 讨论创建一个委员会来监督Rook项目。 7. 41.1版本发布 讨论即将发布的41.1版本，包括外部集群管理、OSD备份等功能。 讨论更新roadmap文档和功能板。 后续行动计划： 继续讨论Dashboard和Orchestrator的集成。 完成Nautilus的pull request。 解决AP状态管理中的问题。 实现Orchestrator API一致性。 更新Rook API。 完成Rook治理更新。 发布41.1版本。 备注： 会议中提到了多个英文关键词，例如“Orchestrator”、“Nautilus”、“Rook”、“AP”、“Kubernetes”等，这些关键词在会议讨论中占有重要地位。 会议纪要中尽量保留了原文的表述，以确保准确传达会议内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-06 :: Ceph Performance meeting","slug":"2019-06-06_-_-_Ceph_Performance_meeting","date":"2019-06-06T16:00:00.000Z","updated":"2019-06-06T16:00:00.000Z","comments":true,"path":"2019/06/07/2019-06-06_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/07/2019-06-06_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Mark、Sam、Ronan、Igor、Casey、Adam、Roman、Alfredo等 会议内容： 1. 项目进展 拉取请求（Pull Requests，PRs）： 审批了由客户端操作触发的恢复操作优先级更高的PR，并要求进行更广泛的测试。 Jason提交的异步消息传递PR，避免了出站消息的SIS调用，对小操作性能提升10-15%，但对大操作无影响。 Igor的垃圾收集PR，旨在避免Blue Store中blob计数过度增长，但需要更多测试和审查。 多站点sink公平性PR，关于在网关和多个站点之间共享工作，需要测量以确认其按预期分配工作。 其他PR，包括OST并行清理PG on maps、优化对象溢出检测、RBD性能改进、RGW允许RATOS GW管理员列出无序存储桶、负载均衡PG改进等。 更新： Adam的更新，包括避免Blue Store中重复缓存、IO ring工作更新等。 Roman关于用户空间IO get_event的更新，可能会带来性能提升。 Auto-tuning MVS缓存的工作仍在进行中。 Igor的更加激进的启动时调整PR，需要重新审查。 2. 讨论议题 性能测试： 讨论了在PR提交时进行性能测试的计划，包括在CBT中添加标签、比较结果与基线等。 讨论了使用Telemetry进行资源分配和结果查询的需求。 讨论了使用新节点进行性能测试的硬件配置。 讨论了将Telemetry用于PR测试的潜在优势。 硬件分配： 讨论了将新节点用于开发、性能测试和回归测试的方案。 讨论了将节点分配给特定开发者的需求。 讨论了将节点作为Jenkins从属节点使用的需求。 其他： 讨论了Xerox TV和RocksDB sharding的进展，包括改进写放大和压缩结果。 3. 决定事项 将部分新节点用于性能测试和回归测试。 将部分节点分配给Crimson开发者。 将部分节点作为Jenkins从属节点使用。 将Telemetry用于PR测试。 继续推进Xerox TV和RocksDB sharding的工作。 4. 行动计划 Mark将跟进Alfredo，以便他加入性能测试项目。 Sam将跟进Telemetry的集成。 Igor将重新审查垃圾收集PR。 Roman将跟进用户空间IO get_event的更新。 其他团队成员将跟进各自的项目。 5. 下次会议 下次会议将在2023年11月的某个时间举行。 备注： 会议中提到了多个技术术语，如CBT、CBT gesture notes、RocksDB、RATOS、Telemetry等，这些术语在存储领域和Ceph项目中都很常见。 会议中提到了多个项目，如Crimson、Blue Store、IO ring、MVS缓存等，这些项目都是Ceph的重要组成部分。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-06-04 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-06-04_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-06-06T16:00:00.000Z","updated":"2019-06-06T16:00:00.000Z","comments":true,"path":"2019/06/07/2019-06-04_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/06/07/2019-06-04_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员姓名] 会议主题： Ceph 项目进展讨论 会议内容： 1. 对象类支持 [姓名] 正在准备 Chrome 对象类支持，主要是重构和移除大写互斥锁，替换为在 waste_start 未定义时禁用的互斥锁。 由于 [姓名] 正在休假，集成性能测试到 CI 的进展缓慢，需要尽快赶上进度。 对象类使用 alien 或 stack switching 魔法运行的想法，将尝试在 alien 中运行对象类。 对象类是围绕 OSD 和 PG 提供的功能的薄包装，是同步的，可能会阻塞整个反应器线程。 计划重写所有对象类，仅对支持 RBD 的子集进行操作，并定义函数类型，返回对应的功能类型。 2. Alien 存储和输入缓冲区工厂 [姓名] 正在开发 alien 存储解决方案，并专注于输入缓冲区工厂的概念。 通过分析 SPDK 的 BDF 和 NVMe 驱动程序文档，确定了连续性的实际需求。 BDF 是一个比 SPDK NVMe 驱动程序更高级的概念，不仅允许消费 NVMe，还可以消费 Linux AIO 或保存 RPD。 输入缓冲区工厂的概念已经提交 PR，并扩展了文档。 [姓名] 正在尝试将输入缓冲区工厂的概念引入 crimson osd，但遇到了一些问题。 3. IO 环 (IOU Ring) [姓名] 认为使用 IOU Ring 将有助于减少开销，但仍然需要执行内存复制以保持用户空间应用程序和内核之间的隔离。 IOU Ring 的目标是减少用户空间网络和存储的开销，因为它允许在内核中处理这些操作。 [姓名] 认为尝试确保不与 IOU Ring 不兼容是合理的。 4. Peering 代码 [姓名] 上周合并了 crimson peering 功能，现在可以启动多个 OSD，并执行一些操作，例如创建 PG 和拉取池。 下一步是实施基于日志的恢复和填充，以便在删除 crimson obesity 后将其恢复。 [姓名] 提交了一个 PR，请求对 peering 代码进行评论。 [姓名] 正在处理 peering 消息，并尝试将其转换为可以阻塞和转储的操作。 5. 复制支持 [姓名] 认为复制支持比对象类支持更重要，因为它将影响接口设计。 [姓名] 将查看 [姓名] 的 PR28395，并开始实施复制支持。 6. CStar 数据源实现 [姓名] 发现了 CStar 消息测试的长期问题，并将其解决。 [姓名] 提交了一个 PR，以支持当前的对齐和填充要求。 [姓名] 认为切换到 consume 接口是合理的，因为它可以减少用户空间到用户空间的复制。 [姓名] 认为我们需要一个统一的接口，该接口不需要区分是否使用基于 DPDK 的堆栈或 POSIX 堆栈。 7. 其他事项 [姓名] 将参加 11 月在加州洛杉矶举行的 3DBenchmarks 提交和 Sister Summit。 [姓名] 将联系 CDB 团队，以讨论重构或更改 read exactly 或 consume 接口。 后续行动计划： [姓名] 将继续开发 alien 存储解决方案和输入缓冲区工厂。 [姓名] 将实施复制支持。 [姓名] 将与 CDB 团队讨论接口更改。 [姓名] 将参加 11 月在加州洛杉矶举行的 3DBenchmarks 提交和 Sister Summit。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-28 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-05-28_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-05-28T16:00:00.000Z","updated":"2019-05-28T16:00:00.000Z","comments":true,"path":"2019/05/29/2019-05-28_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/29/2019-05-28_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [列出参会人员姓名] 会议主题： Ceph分布式存储项目讨论 会议内容： 1. 性能测试与集成 [参会人员姓名] 将进行Ceph性能测试，并将测试参数集成到持续集成（CI）系统中。 测试将包括对现有CI系统的改进，例如模型测试以检查深度场、检查子模块更改以及检查添加到消息中的部分行。 将特别关注由PR引入的性能影响，例如延迟和性能下降。 2. 远程游标 [参会人员姓名] 已经发送了远程游标测试。 测试将使用可选选项，其中SST的默认值为3和4，而Prashanta的默认值为添加。 在本地模式下，将使用一个比Chroma ST更快的SSD。 3. 测试方法 讨论了测试方法，包括使用Radosbench进行吞吐量测试。 通过将thread count增加到足够高，以至于延迟变得非常糟糕，以评估OSD的饱和度。 建议使用-T选项将thread count增加到256，并观察延迟。 4. DPDK与DPDK-based系统 讨论了DPDK与DPDK-based系统的实现，并探讨了接口设计的原因。 讨论了内存拷贝和用户空间到用户空间的对齐问题。 讨论了使用scatter-gather数据结构以避免内存拷贝的需求。 5. POSIX接口 讨论了POSIX接口的修改，包括对定位器的使用。 讨论了可能的修改和接口扩展。 6. 代码审查 [参会人员姓名] 完成了对一些代码的审查，并提出了反馈。 7. 操作系统升级 讨论了Fedora 30的安装问题，包括与BCM相关的DMA调用问题。 8. 操作系统性能优化 讨论了操作系统性能优化，包括使用更大的缓冲区。 9. 操作系统调度 讨论了操作系统调度，包括使用seastar进行任务调度。 10. 操作系统任务执行 讨论了操作系统任务执行，包括使用future和promise进行任务之间的通信。 11. 后续行动计划 继续进行性能测试和集成。 完成DPDK和DPDK-based系统的测试。 完成POSIX接口的修改和接口扩展。 完成代码审查。 解决操作系统升级问题。 完成操作系统性能优化。 完成操作系统调度和任务执行。 会议总结： 本次会议讨论了Ceph分布式存储项目的多个方面，包括性能测试、远程游标、DPDK、POSIX接口、代码审查、操作系统升级和优化。会议确定了后续行动计划，包括完成各项任务并解决遇到的问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-29 :: Ceph Orchestration Meeting","slug":"2019-05-29_-_-_Ceph_Orchestration_Meeting","date":"2019-05-28T16:00:00.000Z","updated":"2019-05-28T16:00:00.000Z","comments":true,"path":"2019/05/29/2019-05-29_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/29/2019-05-29_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 参会人员： 会议记录中未提及具体人员姓名，但涉及以下议题： Ceph存储系统测试 Pull Request管理 TLS配置 代码审查 会议安排 会议内容： 测试进展： 参会者报告了对“big hot pants”功能的测试进展良好。 有讨论关于治理和类似事项，但对会议主持人来说不感兴趣。 参会者检查了仪表板团队的一些工作，并关注了相关议题。 Pull Request： 参会者对“inventory and services”的Pull Request进行了审查，但尚未在Deep Sea上进行测试。 参会者将尝试在下午或周五进行测试，以获取更多反馈。 TLS配置： 参会者更新了关于询问TLS的Pull Request，包括证书和密钥文件。 计划在两周内完成测试系统和工作台功能。 代码审查： 参会者对“tearless porkers”代码进行了审查，认为总体良好，但建议改进一些错误信息。 会议安排： 由于个人原因，原定于下周三的会议将被取消。 会议安排调整为下周一下午进行，不再安排周三会议。 后续行动计划： 参会者将继续对“inventory and services”的Pull Request进行测试。 参会者将完成TLS配置的Pull Request，并确保测试系统和工作台功能在两周内完成。 参会者将关注并参与后续的代码审查工作。 备注： 会议中提到了一些Ceph相关的关键词，如“big hot pants”、“inventory and services”、“TLS”、“tearless porkers”等。 会议记录中未提及具体人员姓名，但涉及了多个议题和任务。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-29 :: Ceph Testing meeting","slug":"2019-05-29_-_-_Ceph_Testing_meeting","date":"2019-05-28T16:00:00.000Z","updated":"2019-05-29T16:00:00.000Z","comments":true,"path":"2019/05/29/2019-05-29_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/29/2019-05-29_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： Vacuum, Pakrac, Gretchen, Yuri, Yuki, Danka, DTRS, Zach, others 会议主题： 分布式存储Ceph的测试与部署工具讨论 关键细节： Orchestrator测试： Vacuum提出将继续每周加入会议，直到Orchestrator的测试得到完善。目前对Orchestrator的最终进展并不自信。 Barcelona会议： Pakrac分享了Barcelona会议的收获，认为会议内容丰富，但测试方面遇到了一些困难。 降级与回滚： 讨论了降级与回滚的区别，以及在进行点发布时需要进行的测试。决定在每次点发布前进行测试，确保新旧版本的数据兼容性。 部署工具： 讨论了Ceph的部署工具，包括Leap和Terraform。Yuki提到Leap目前只能用于OpenStack，但可以考虑扩展到其他平台。 KVM： 讨论了使用KVM进行测试的可能性，以及如何将部署工具与Terraform集成。 主要议题： Orchestrator测试： 完善Orchestrator的测试，确保其稳定性和可靠性。 降级与回滚测试： 在每次点发布前进行测试，确保新旧版本的数据兼容性。 部署工具： 优化Ceph的部署工具，使其更易于使用和扩展。 决定的事项： Vacuum将继续每周加入会议，直到Orchestrator的测试得到完善。 在每次点发布前进行测试，确保新旧版本的数据兼容性。 探索使用KVM进行测试的可能性，以及将部署工具与Terraform集成。 后续行动计划： Vacuum将继续完善Orchestrator的测试。 团队成员将进行降级与回滚测试。 探索使用KVM进行测试的可能性，以及将部署工具与Terraform集成。 关键词： Orchestrator 测试 降级 回滚 部署工具 KVM Terraform","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-07 :: Crimson SeaStor OSD Weekly Meeting","slug":"2019-05-07_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-07_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-07_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： [会议记录中未提及具体姓名，以下为推测] Pittock - 负责Crimson项目的开发 [音乐] - 负责Crimson项目的开发 [Sam] - 负责Crimson项目的开发 [John] - 负责Crimson项目的开发 [Nathan] - 负责Crimson项目的开发 [Julie-san] - 负责Crimson项目的开发 [其他人员] - 可能是Ceph社区的其他成员 会议内容： 1. Crimson项目进展 Pittock： 上周准备了中国国庆假期后的工作，包括为Crimson项目准备slice和simpler kong。 上周主要工作： 在Crimson项目上提交了一个工作进度的pull request，其中包含对right和rightful操作的区分，以及对lock hints的处理。 创建了一个独立的分支来处理Fiji的分离。 下一步计划： 继续处理Crimson项目的recreation功能。 与[音乐]合作，确保PG创建和通知处理功能正常工作。 [音乐]： 正在处理Crimson项目的process notify messages，以便更好地处理事件。 下一步计划： 完成recreation功能。 推送一个PR来替换现有的Rio Kiowa版本。 [Sam]： 正在处理Crimson项目的PG创建和通知处理功能。 下一步计划： 完成PG创建和通知处理功能。 开始实现恢复功能。 [John]： 正在处理Crimson项目的异常处理机制。 下一步计划： 与社区讨论如何改进异常处理机制。 尝试使用C++异常处理库来优化异常处理性能。 [Nathan]： 与[John]讨论了异常处理机制的改进方案。 下一步计划： 与社区讨论异常处理机制的改进方案。 [Julie-san]： 与[John]讨论了异常处理机制的改进方案。 下一步计划： 与社区讨论异常处理机制的改进方案。 2. Ceph社区讨论 [Sam]： 提出了Crimson项目与经典OSD之间的差异，并讨论了如何处理这些差异。 [John]： 讨论了Crimson项目中的异常处理机制，并提出了改进方案。 [Nathan]： 与[John]讨论了异常处理机制的改进方案。 [Julie-san]： 与[John]讨论了异常处理机制的改进方案。 3. 行动计划 Pittock： 继续处理Crimson项目的recreation功能。 与[音乐]合作，确保PG创建和通知处理功能正常工作。 [音乐]： 完成recreation功能。 推送一个PR来替换现有的Rio Kiowa版本。 [Sam]： 完成PG创建和通知处理功能。 开始实现恢复功能。 [John]： 与社区讨论如何改进异常处理机制。 尝试使用C++异常处理库来优化异常处理性能。 [Nathan]： 与社区讨论异常处理机制的改进方案。 [Julie-san]： 与社区讨论异常处理机制的改进方案。 4. 其他事项 [Sam]： 讨论了Crimson项目中的消息传递机制，并提出了改进方案。 [John]： 讨论了Crimson项目中的事件调度机制，并提出了改进方案。 [Nathan]： 讨论了Crimson项目中的事件调度机制，并提出了改进方案。 [Julie-san]： 讨论了Crimson项目中的事件调度机制，并提出了改进方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-02 :: Ceph Performance meeting","slug":"2019-05-02_-_-_Ceph_Performance_meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-02_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-02_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月某日（具体日期未提及） 参会人员： Josh, Mark, Keef, Jason, Sage, Adam, Radek, Mohamed等 会议主题： Ceph项目进展讨论 主要议题： PR讨论： Keef提交了一个PR，利用用户空间IOKit事件来优化性能，该PR受到C star和FIO代码的启发。目前尚未测试，需要一些修复，但预计会很有趣。 Jason为LebaDB添加了支持zero copyrights的功能，性能提升了4%，主要表现在CPU使用率下降。该PR已经审查，预计很快会合并。 Sage提交了多个Crimson相关PR，旨在通过批处理和负载PGs多线程化来提高性能。目前效果有限，但某些步骤（如PGs加载）的改进可能显著。 Adam完成了对EC stripe cache的代码开发，并正在进行测试。他欢迎任何人对代码进行审查。 Sage提交了针对Booster分配器的老化测试PR，希望将其转换为单元测试。 日志记录优化： Sage提到，在master分支中，已经将日志记录的默认方式从D out更改为LTTE ng，以减少字符串开销。 Mark分享了一个关于LTTE ng性能提升的PR，该PR在NVMe环境中对大型I/O操作的性能提升非常显著。 参会人员讨论了是否应该使用二进制日志格式，以及是否应该保留文本日志以方便用户阅读。 其他事项： Sage提到，近期将加入对prefetch for rocks DB和masterful的讨论。 Adam提到，他正在尝试将Booster分配器的老化测试转换为单元测试。 行动计划： Keef将继续修复其PR，并测试其性能。 Jason的PR预计很快会合并。 Sage将继续关注Crimson相关PR，并与其他开发人员合作优化性能。 Adam将继续进行EC stripe cache的测试，并欢迎任何人对代码进行审查。 Sage将继续推动prefetch for rocks DB和masterful的讨论。 参会人员将继续讨论日志记录优化方案。 后续会议： 下周将再次召开核心会议，继续讨论Ceph项目的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-13:: Ceph Orchestration Meeting","slug":"2019-05-13_-_-_Ceph_Orchestration_Meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-13_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-13_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年5月13日 会议主题： Orchestrator 团队会议 会议内容： 1. 独立模式（Standalone Mode）讨论 Rook 4.5 版本中曾包含独立模式，但后续废弃，转而使用 Kubernetes 进行编排。 独立模式面临挑战，需要重新实现 Kubernetes 的许多功能，例如集群管理、资源分配等。 现有的 Orchestrator 仍需解决类似挑战，但已具备中央组件，简化了部分功能。 2. Rook 1.0.1 版本发布 由于主要版本发布后出现了一些升级问题，例如主机网络与 0.9 版本升级不兼容，将推出 1.0.1 版本进行修复。 期望在第二天发布此补丁版本，并计划后续推出 1.0.2 版本。 3. Cephalocon 会议地点 Cephalocon 会议地点（Red Hat Office）目前不可用，因为会议室被董事会会议占用。 Mike Perez 正在寻找替代地点，包括酒店或附近的场地。 需要进一步跟进并确认会议地点。 4. Kubecon 会议 Rook 将在 Kubecon 上进行演讲和展示，需要志愿者协助在展位上为用户解答问题。 5. 其他事项 有关会议地点的具体信息，将通过电子邮件进一步确认。 下次会议将在下周举行。 行动计划： Travis 负责发布 Rook 1.0.1 版本。 Mike Perez 负责寻找 Cephalocon 会议地点。 团队成员准备 Kubecon 会议的相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-06 :: Ceph Orchestration Meeting","slug":"2019-05-06_-_-_Ceph_Orchestration_Meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-06_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-06_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议主题： Ceph分布式存储及Orchestrator相关议题讨论 参会人员： 未知 会议内容： 1. Ceph安全服务（Iscsi）问题 讨论了上周五提交的关于Iscsi服务类型的一个bug。 提出了一个临时解决方案：复制管理员角色并移除Iscsi作用域，从而避免执行相关代码。 认为这个解决方案似乎可行，但需要进一步测试。 讨论了手动配置Safe Eyes CoS URL作为另一种解决方案。 强调了这是一个BEC（Base Exception Class）问题，需要尽快修复。 2. Orchestrator相关 讨论了关于Orchestrator合同的问题，以及如何解决冲突。 提出了一个建议：将所有Orchestrator请求合并到一个pull request中，以简化集成过程。 认为这个建议是合理的，但需要进一步讨论和测试。 3. 其他事项 讨论了Ansible Orchestrator的pull request，以及如何处理冲突。 讨论了将证书放入Manager的流程。 讨论了监控等后续工作。 行动计划： 对Iscsi服务类型的bug进行进一步测试和修复。 讨论、测试并实施Orchestrator pull request合并方案。 处理Ansible Orchestrator的pull request冲突。 完成证书放入Manager的流程。 继续进行监控等后续工作。 后续会议： 下次会议定于周三或下周召开。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-09 :: Ceph Performance meeting","slug":"2019-05-09_-_-_Ceph_Performance_meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-09_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-09_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间 会议时间 会议地点 会议地点 参会人员 [列出参会人员姓名] 会议主题 本周Ceph社区动态及关键议题讨论 会议内容 1. Ceph社区动态 - 本周新提交的Pull Request (PR) 主要集中在GW管理员功能增强、Seastar性能改进、RBD零拷贝权限、Radix工作、Adam的工作更新、Igor的RocksDB测试、双缓存PR、IOU环工作等方面。 - 由于Red Hat峰会，社区活动相对较少。 2. 主要议题讨论 （1）GW管理员功能增强 - 新增PR允许进行无序存储桶列表，以提高性能。 - 该功能扩展了之前的API，允许应用选择是否进行有序列表。 （2）Seastar性能改进 - Seastar升级带来了性能提升。 - 通过C API实现了RBD的零拷贝权限，进一步提升了性能。 （3）Radix工作 - Radix工作部分已关闭，具体原因待定。 （4）Adam的工作更新 - Adam的工作持续更新，进展良好。 （5）Igor的RocksDB测试 - Igor的RocksDB测试发现存在一些问题，需要进一步测试和修复。 （6）双缓存PR - 双缓存PR在测试中表现良好，但存在一些潜在问题，需要进一步讨论和改进。 - 当用户更改存储桶配置时，可能会导致性能问题。 - 需要开发工具来帮助迁移和升级。 （7）IOU环工作 - IOU环工作正在进行中，但仍存在一些问题。 - 需要学习IOU环代码，并修复潜在的问题。 （8）LVM缓存 - LVM缓存测试表明，在特定场景下，使用缓存可以提高性能。 - 需要进一步研究在不同工作负载下的性能表现。 决定事项 继续关注和跟进上述议题，并积极讨论和解决相关问题。 在Red Hat峰会结束后，恢复正常会议节奏。 后续行动计划 各议题负责人继续推进相关工作。 定期召开会议，讨论社区动态和关键议题。 会议总结 本周Ceph社区动态活跃，但受Red Hat峰会等因素影响，活动相对较少。会议讨论了多个关键议题，包括GW管理员功能增强、Seastar性能改进、Radix工作、Adam的工作更新、Igor的RocksDB测试、双缓存PR、IOU环工作、LVM缓存等。会议决定继续关注和推进相关工作，并定期召开会议讨论社区动态和关键议题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-08 :: Ceph Testing meeting","slug":"2019-05-08_-_-_Ceph_Testing_meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-08_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-08_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sebastian, Greg 会议主题： 分布式存储Ceph项目进展及视频会议字幕翻译相关事宜 会议内容： 1. Ceph项目进展 集成Look into Totality的可行性： Greg提到，将Look集成到Totality的计划目前不可行，但从长远来看，这仍然是一个需要考虑的方向。由于他目前正忙于另一个Rados相关项目，因此短期内不会继续推进集成工作。 Rook集成测试： Sebastian提到，将Rook集成到Ceph环境中的测试工作可以通过集成测试进行。他计划使用最新的self容器构建，并在Jenkins中运行测试。 Jenkins集成： Greg表示，为了在Jenkins中实现Rook测试，需要为Pull Requests构建容器镜像，但目前该功能尚未实现。 Rook集群： Sebastian询问是否有可用的Rook集群进行测试，目前David Galloway等人可能在使用一个Rook集群，但具体位置不明。 Jenkins运行环境： Greg不确定Jenkins运行环境是否有权限访问相关基础设施，需要进一步调查。 2. 视频会议字幕翻译 Sebastian正在负责英译中的字幕翻译工作。 Greg询问Sebastian关于某个测试 orchestrator 的事情，Sebastian表示他将会推进这个项目。 3. 决定事项 暂时搁置集成Look into Totality的计划。 推进Rook集成测试，并在Jenkins中实现。 调查Rook集群的可用性。 进一步调查Jenkins运行环境的权限问题。 Sebastian将继续推进字幕翻译工作。 4. 后续行动计划 Greg将调查Rook集群的可用性，并与David Galloway等人联系。 Greg将调查Jenkins运行环境的权限问题，并尝试解决。 Sebastian将继续推进Rook集成测试和字幕翻译工作。 5. 其他事项 会议中提到了一些计算机科学/ceph相关领域英文关键词，例如： Rados systemd Rook Jenkins Pull Requests Container Terraform Vagrant 备注： 会议中提到的项目名称和术语可能需要根据实际情况进行调整。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-14:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-05-14_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-14_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-14_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员，包括负责视频会议字幕翻译和总结的人员 会议主题： Ceph分布式存储系统开发讨论，涵盖性能优化、调试工具、功能改进等方面。 关键细节： 异常处理： 讨论了Ceph中异常处理的现状，指出当前异常处理机制存在不足，建议增加配置变量以在异常发生时记录回溯信息并终止进程。 调试工具： 介绍了新工具“two lines”用于调试Ceph，并讨论了如何改进调试环境，例如记录异常信息和回溯。 性能优化： 讨论了Ceph中对象上下文缓存的使用，指出当前缓存机制可能影响性能，建议优化缓存实现或考虑使用其他数据结构。 讨论了持久内存的使用，探讨了如何利用持久内存提高性能，并指出需要考虑持久内存的特性和相关库。 讨论了Ceph中多个操作对同一对象上下文进行修改的情况，指出需要考虑操作之间的依赖关系和冲突，并建议使用状态机来管理对象上下文。 功能改进： 讨论了Ceph中快照和擦除操作的性能，指出可能需要牺牲一些延迟以提高性能。 讨论了Ceph中消息批处理对性能的影响，并建议改进消息批处理机制。 讨论了Ceph中对象上下文缓存的使用，指出可能存在双重缓存问题，并建议优化缓存机制。 主要议题： 异常处理改进 调试工具改进 性能优化 功能改进 决定的事项： 增加配置变量以在异常发生时记录回溯信息并终止进程。 优化对象上下文缓存机制。 探索使用持久内存提高性能。 使用状态机管理对象上下文。 改进消息批处理机制。 后续行动计划： 完善异常处理机制。 优化对象上下文缓存机制。 探索使用持久内存提高性能。 使用状态机管理对象上下文。 改进消息批处理机制。 讨论Ceph中快照和擦除操作的性能问题。 讨论Ceph中对象上下文缓存的使用问题。 备注： 会议中提到了Ceph中的一些关键概念，如对象上下文、快照、擦除等。 会议中提到了Ceph中的一些关键技术，如状态机、消息批处理等。 会议中提到了Ceph开发团队的一些工具和库，如two lines、boost intrusive LRU等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-27:: Ceph Orchestration Meeting","slug":"2019-05-27_-_-_Ceph_Orchestration_Meeting","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-27T16:00:00.000Z","comments":true,"path":"2019/05/28/2019-05-27_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/2019-05-27_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年3月28日 会议主题： 讨论Ceph存储集群中的一些功能实现和改进方案。 参会人员： Travis, Eric Fox, Stefan等。 会议内容： 1. 会议取消情况： - 由于今天是美国阵亡将士纪念日，美国团队成员无法参加本次会议，因此Travis取消了本次会议。 2. Ceph相关议题： - Podcast评论： Travis提到已经创建了一个关于Ceph的播客，并收到了一些评论。讨论了在评论时需要点击提交按钮才能完成评论的问题。 - Trivial Completions： 讨论了新的Trivial Completions计划，并指出忽略其他属性可能存在风险。建议在返回结果时返回失败，以防止问题发生。 - Kiche信息持久化： 讨论了Kiche信息的持久化问题，并提出了使用持久存储字典来存储主机列表的方案。讨论了是否需要持久化这些信息，以及是否可以使用其他类来实现类似功能。 - SSH Orchestrator： 讨论了SSH Orchestrator的实现，并指出SSH Orchestrator存储已知主机列表的方式与其他Orchestrator不同。讨论了是否需要将持久化存储字典替换为字典，以提高性能。 - Ansible Orchestrator： 讨论了Ansible Orchestrator的性能问题，并提出了将部分信息缓存到Ansible中的方案。讨论了是否需要修改playbook以实现快速版本。 3. 其他议题： - Ansible Orchestrator支持安全Ansible： 讨论了Ansible Orchestrator是否支持安全Ansible，并指出这是当前工作的重点。 - 测试自动化： 讨论了测试自动化的重要性，并指出应该优先考虑自动化测试。 4. 行动计划： - 完成Ansible Orchestrator的修改，并确保功能正常。 - 对Ceph进行自动化测试。 - 在下周的会议上继续讨论其他议题。 5. 会议总结： 本次会议讨论了Ceph存储集群中的一些功能实现和改进方案，并制定了相应的行动计划。会议强调了Ansible Orchestrator的重要性和测试自动化的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph and NVMe/TCP - Orit Wasserman, Lightbits Labs","slug":"Ceph_and_NVMe_TCP_-_Orit_Wasserman_Lightbits_Labs","date":"2019-05-27T16:00:00.000Z","updated":"2019-05-28T16:00:00.000Z","comments":true,"path":"2019/05/28/Ceph_and_NVMe_TCP_-_Orit_Wasserman_Lightbits_Labs/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/28/Ceph_and_NVMe_TCP_-_Orit_Wasserman_Lightbits_Labs/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： Owen Basserman（Life Bits Lab 架构师），Ceph 开发团队 会议主题： Life Bits Lab 的 Envy Me TCP 技术介绍及与 Ceph 集成的可能性探讨 会议内容： 1. Owen Basserman 自我介绍及 Envy Me TCP 介绍 Owen Basserman 介绍了自己的背景，从 Ceph 核心开发者转为 Life Bits Lab 架构师。 Envy Me TCP 是一种优化高性能的 NVMe-over-TCP 协议，旨在提高存储性能和降低延迟。 Envy Me TCP 之所以选择 TCP，是因为其广泛的应用和成熟的技术，无需改变现有网络基础设施。 Life Bits Lab 是 Envy Me TCP 的主要发明者之一，与 Facebook、Intel 等公司共同推动其标准化。 2. Envy Me TCP 的优势及应用 Envy Me TCP 可以在不降低服务器容量的情况下，安全地使用 NVMe TCP 进行元数据存储。 具有复杂的保护机制，即使单个 SSD 失效也不会影响整体性能。 可用于大规模部署和长距离传输，适用于需要高性能存储的场景。 3. Envy Me TCP 与 Ceph 的集成 Owen 提出将 Envy Me TCP 与 Ceph 集成，以进一步提高 Ceph 的性能和稳定性。 目前，Envy Me TCP 与 Ceph 的集成尚处于初步阶段，需要解决延迟和成本问题。 未来，Life Bits Lab 正在开发键值接口，以实现 Envy Me TCP 与 Ceph 的深度融合，并完全替代 RBD。 4. 后续行动计划 Life Bits Lab 将继续优化 Envy Me TCP，并探索与 Ceph 的集成方案。 Ceph 开发团队将与 Life Bits Lab 保持沟通，共同推进 Envy Me TCP 的集成工作。 5. 其他事项 会议最后，Owen Basserman 鼓励大家对 Envy Me TCP 进行更多了解，并欢迎感兴趣的人士与其交流。 关键词： Envy Me TCP, NVMe-over-TCP, Ceph, RBD, 高性能存储, 集成","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"200 Clusters vs 1 Admin - Bartosz Rabiega, OVH","slug":"200_Clusters_vs_1_Admin_-_Bartosz_Rabiega_OVH","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/200_Clusters_vs_1_Admin_-_Bartosz_Rabiega_OVH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/200_Clusters_vs_1_Admin_-_Bartosz_Rabiega_OVH/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 与会人员： Bartosz La Vega（OVH Poland DevOps工程师） 会议主题： OVH在Ceph分布式存储系统（SEF）的部署、管理和维护经验分享 会议内容： 一、背景介绍 Bartosz La Vega介绍了自己的背景，自2016年起在OVH担任DevOps工程师，负责Safe as a Service团队，提供管理的Safe集群服务。 OVH是欧洲最大的云服务提供商之一，拥有26个数据中心，采用水冷技术，服务器容量超过100万台。 二、Safe在OVH的应用 Safe主要用于OVH的公共云服务，提供额外的块存储服务。 OVH还提供名为“云磁盘阵列”的产品，为外部客户提供专用Safe集群。 三、Safe集群规模 OVH目前拥有超过50PB的Safe存储空间，分布在210个集群中，集群规模从小型到大型不等。 四、Safe集群设计目标 无单点故障 最大化性能，最小化成本 对硬件资源有良好的控制 易于部署、升级和管理 五、实现设计目标的方法 无单点故障： 采用三副本机制和DC拓扑结构，确保数据安全。 性能优化： 使用FlashCache和NVMe加速HDD驱动器，提高I/O性能。 资源隔离： 使用Macvlan技术提供不同的网络接口，以及容器技术进行资源隔离和分配。 六、集群管理 自动化控制平面： 开发了一个自动化控制平面，用于管理集群配置、容器的创建和升级、集群的扩展和缩减等操作。 远程API： 为客户提供远程API，以便管理自己的Safe集群。 维护操作： 利用Apache Airflow等开源项目，实现集群的自动维护操作，如磁盘替换、NVMe预测性维护等。 七、总结 OVH通过开发自动化控制平面和集成监控解决方案，实现了对Safe集群的高效管理和维护。 单个系统管理员能够管理超过200个Safe集群，大大提高了运维效率。 后续行动计划： 继续优化控制平面，增加更多功能，如监控、自愈等。 计划升级Safe集群到Luminous版本。 探索更多自动化和智能化运维技术。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"A Glimpse of the New Ceph Messenger Built on Seastar - Yingxin Cheng & Vivian Zhu, Intel","slug":"A_Glimpse_of_the_New_Ceph_Messenger_Built_on_Seastar_-_Yingxin_Cheng_Vivian_Zhu_Intel","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/A_Glimpse_of_the_New_Ceph_Messenger_Built_on_Seastar_-_Yingxin_Cheng_Vivian_Zhu_Intel/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/A_Glimpse_of_the_New_Ceph_Messenger_Built_on_Seastar_-_Yingxin_Cheng_Vivian_Zhu_Intel/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 会议主题： Ceph 新消息传递组件（Crimson Messenger）的开发进展 参会人员： Intel，Ceph 团队成员 会议内容： 一、背景介绍 Ceph 核心对象层重构项目（Crimson）旨在提升在现代硬件上的性能。 现代硬件特点：多核心、NUMA 架构、高速存储设备（如 NVMe SSD、持久内存）、高速网络。 SAP 架构和 POSIX 线程存在性能瓶颈，需要优化。 二、Crimson Messenger 的目标 利用 C++ Star 框架实现同步编程，统一架构。 实现跨核心通信的最小化，建立直接核心到核心连接。 利用 C++ Star 框架进行性能验证和优化。 三、Crimson Messenger 的设计 基于 C++ Star 框架，实现异步 I/O、任务调度、网络堆栈等功能。 实现直接核心到核心连接，减少跨核心通信。 利用 C++ Star 框架的异步编程模型，实现代码简洁、易于维护。 四、性能测试 与现有异步消息传递组件进行性能对比，Crimson Messenger 在大部分场景下性能更优。 利用 C++ Star 框架的异步编程模型，实现代码简洁、易于维护。 五、挑战和未来工作 C++ Star 框架的功能不够完善，可能需要定制化实现。 需要深入了解 C++ Star 框架的编程模型，才能正确实现代码。 需要持续优化性能，并确保可靠性。 六、行动计划 完成 Crimson Messenger 的核心功能。 进行性能测试和优化。 评估 C++ Star 框架的定制化需求。 将 Crimson Messenger 集成到 Ceph 中。 七、总结 Crimson Messenger 是 Ceph 核心对象层重构项目的重要组成部分，旨在提升 Ceph 在现代硬件上的性能。目前，Crimson Messenger 已取得初步进展，但仍面临一些挑战。未来，Ceph 团队将继续努力，确保 Crimson Messenger 的成功应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"A Hitchhiker's Guide to Ceph RGW PubSub & Cats vs. Dogs - a Hybrid Cloud Storage Story","slug":"A_Hitchhiker_s_Guide_to_Ceph_RGW_PubSub_Cats_vs._Dogs_-_a_Hybrid_Cloud_Storage_Story","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/A_Hitchhiker_s_Guide_to_Ceph_RGW_PubSub_Cats_vs._Dogs_-_a_Hybrid_Cloud_Storage_Story/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/A_Hitchhiker_s_Guide_to_Ceph_RGW_PubSub_Cats_vs._Dogs_-_a_Hybrid_Cloud_Storage_Story/","excerpt":"","text":"会议纪要 会议主题： Ceph 新功能介绍及混合云应用案例 会议时间： 2023年X月X日 参会人员： 未知 会议内容： 一、会议背景 本次会议主要介绍了 Ceph 的一项新功能，该功能已存在数月，并具有以下特点： 关键技术： Kubernetes、Canary、PUPs 应用场景： 混合云、数据存储、事件发布/订阅 二、会议关键细节 Kubernetes 与 Canary： Kubernetes 是一种容器编排平台，Canary 是 Kubernetes 中的一种框架，用于实现无服务器功能。 Ceph 利用 Kubernetes 的功能，实现了事件发布/订阅机制。 PUPs 功能介绍： PUPs 是 Ceph 中的事件发布/订阅机制，它允许用户将事件发布到不同的主题，并订阅感兴趣的事件。 PUPs 支持多种消息传递协议，包括 HTTP、AMQP、Kafka 等。 数据模型： 主题：用于分类消息的术语，类似于 Kafka 和 AMQP。 订阅：将特定主题与存储桶关联，以便将事件推送到目标位置。 过滤器：允许用户订阅特定类型的事件，例如对象创建或删除。 混合云应用案例： 会议演示了一个将图像分类算法部署在公共云上的案例。 当用户上传图像到 Ceph 存储桶时，PUPs 会将事件发布到主题，并触发相应的处理流程。 处理流程包括从 Ceph 获取图像、调用分类算法、将结果存储回 Ceph 等。 三、讨论的主要议题 如何利用 PUPs 实现混合云应用？ 如何在 Ceph 中集成其他消息传递协议？ 如何优化 PUPs 的性能和可靠性？ 四、决定的事项 未来将支持更多消息传递协议，例如 Kafka、ActiveMQ 等。 将考虑实现“推送模式”，以便直接将消息发送到外部系统。 将优化 PUPs 的性能和可靠性。 五、后续行动计划 完善文档，介绍 PUPs 的使用方法。 开发更多示例，展示 PUPs 在混合云中的应用。 优化 PUPs 的性能和可靠性。 六、其他 会议演示了如何使用 PUPs 实现图像分类，并展示了相关代码。 会议还讨论了如何将 PUPs 与其他技术（例如 Lambda 函数、服务函数等）集成。 关键词： Ceph、PUPs、Kubernetes、Canary、混合云、事件发布/订阅、消息传递协议","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Affordable NVMe Performance on Ceph & Ceph on NVMe - True... - Wido den Hollander & Piotr Dalek","slug":"Affordable_NVMe_Performance_on_Ceph_Ceph_on_NVMe_-_True..._-_Wido_den_Hollander_Piotr_Dalek","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Affordable_NVMe_Performance_on_Ceph_Ceph_on_NVMe_-_True..._-_Wido_den_Hollander_Piotr_Dalek/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Affordable_NVMe_Performance_on_Ceph_Ceph_on_NVMe_-_True..._-_Wido_den_Hollander_Piotr_Dalek/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议地点： 未提及 参会人员： - Peter Dark，OVH波兰软件工程师，Ceph软件操作支持专家 - Whedon All，Ceph 2010年加入者，Ceph培训师和顾问 会议议程： Ceph概述： Ceph是一个开源的分布式存储系统，适用于大规模云服务和企业级应用。 Ceph提供高可用性、高可靠性和高性能，适用于不同规模的公司。 Ceph是否适合您的需求： 在决定使用Ceph之前，需要评估其是否适合您的具体需求。 需要考虑性能、容量、恢复能力、SLA等因素。 Ceph集群的性能优化： 选择合适的硬件：CPU、NVMe驱动器、网络等。 调整Ceph配置：副本因子、存储池、OSD数量等。 使用性能优化工具：如Rados bench进行基准测试。 Ceph集群的性能瓶颈： CPU瓶颈：优化CPU配置、关闭超线程、禁用日志记录等功能。 网络瓶颈：调整MTU、关闭CPU缓解措施等。 存储瓶颈：选择合适的NVMe驱动器、优化存储池配置等。 Ceph集群的可靠性： 使用三副本因子以提高数据可靠性。 避免使用缓存驱动器，因为它们可能降低性能或导致数据丢失。 定期测试集群的恢复能力。 Ceph集群的性价比： 选择合适的硬件和配置，以实现最佳性能和成本效益。 可以参考会议中提供的示例系统。 行动计划： 评估Ceph是否适合您的需求。 选择合适的硬件和配置。 进行性能优化和可靠性测试。 定期监控集群性能。 会议总结： 本次会议详细介绍了Ceph的特性和使用方法，并提供了性能优化和可靠性测试的建议。通过合理配置和使用Ceph，可以构建高性能、高可靠性和高性价比的分布式存储系统。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Brazilian Government Case - Brenno Martinez, Serpro","slug":"Brazilian_Government_Case_-_Brenno_Martinez_Serpro","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Brazilian_Government_Case_-_Brenno_Martinez_Serpro/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Brazilian_Government_Case_-_Brenno_Martinez_Serpro/","excerpt":"","text":"会议纪要 会议时间：[请填写具体日期和时间] 会议地点：[请填写会议地点] 参会人员：Brenda Martinez（自力更生工场代表） 会议主题：自力更生工场在巴西政府项目中的Ceph使用经验分享 会议内容： 一、背景介绍 Brenda Martinez介绍了自力更生工场，这是一家巴西政府下属的IT公司，为公共机构和巴西公民提供解决方案。自力更生工场拥有自己的数据中心，并开发了基于OpenStack、Kubernetes等技术的云解决方案“estelí”，意为造船厂。 二、Ceph使用历程 1. 2017年初，自力更生工场开发团队请求使用Ceph对象存储来存储巴西驾驶执照数据，目前已有超过6000万份驾驶执照，每份执照包含照片、签名、指纹和二维码。 2. 由于预算限制，自力更生工场在一开始没有为Ceph购买新的硬件。 3. 在测试阶段，Ceph集群出现了一些性能问题，如操作缓慢、OSD频繁上下线、Keystone服务不稳定等。 三、问题分析与解决方案 1. 发现问题主要原因是单个桶中存储了过多的对象（数千万），导致性能问题。 2. 采取的解决方案： - 限制每个桶的对象数量（100个桶，每个桶10万个对象）。 - 增加Keystone服务器数量，并优化代码以复用令牌。 - 经过6个月的努力，升级了硬件，并添加了支持动态rashard的版本（从Java升级到luminous）。 四、Ceph应用现状 1. 目前，Ceph为巴西驾驶执照提供对象存储服务，确保了驾驶执照数据的安全。 2. Ceph还为云解决方案中的容器提供块和文件系统存储服务。 3. Ceph将很快为Hadoop集群提供存储服务。 4. 自力更生工场正在实施多站点环境。 五、总结 自力更生工场在Ceph的使用过程中遇到了一些挑战，但通过不断优化和升级硬件，成功解决了性能问题。Ceph已成为自力更生工场存储解决方案的重要组成部分，为各类应用提供了稳定可靠的服务。 后续行动计划： 1. 持续优化Ceph集群性能，确保稳定运行。 2. 推广Ceph在更多领域的应用，如大数据、人工智能等。 3. 与Ceph社区保持紧密合作，共同推动Ceph技术的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CRUSH-ing the OSD Variance Problem - Tom Byrne, Storage Sysadmin","slug":"CRUSH-ing_the_OSD_Variance_Problem_-_Tom_Byrne_Storage_Sysadmin","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/CRUSH-ing_the_OSD_Variance_Problem_-_Tom_Byrne_Storage_Sysadmin/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/CRUSH-ing_the_OSD_Variance_Problem_-_Tom_Byrne_Storage_Sysadmin/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储系统中的 OSD 利用率管理 会议时间： 2023年11月（具体日期未提及） 参会人员： Tom（Rutherford 下午实验室系统管理员）、Ceph 开发者、其他相关人员 会议内容： 一、会议背景 Tom 介绍了自己及工作背景，他在 Rutherford 下午实验室负责与研究人员合作存储数据，自 2015 年开始关注 Ceph，主要关注高性能物理实验的对象存储。Echo 是他们运行的最大的高性能计算集群，已投入生产两年，目前容量超过 40PB，主要服务于大型实验设施。 二、OSD 利用率管理 问题概述： Echo 集群中 OSD 利用率存在较大差异，导致空间浪费和数据分布不均。 解决方案： 初始方案： 使用 reweight by utilization 尝试平衡 OSD 利用率，但效果不佳，因为 Echo 集群存在大量硬件更换和数据迁移，导致利用率波动。 改进方案： 引入 upmap balancer，通过强制移动 placement groups 到空置或利用率较低的 OSD，有效平衡了集群利用率，并将利用率差异从 40% 降低到 5%，增加了 6PB 的额外可用空间。 upmap balancer 优势： 更高效地平衡集群利用率。 更灵活地控制 placement groups 的分布。 提高集群的可用性和可靠性。 三、添加 OSD 添加过程： 添加 OSD 时，需要逐步增加权重，并监控集群状态。 挑战： 添加新 OSD 时，可能存在 placement groups 在现有 OSD 之间移动的情况，导致数据分布不均。 解决方案： 使用 upmap map 将 placement groups 移动到新 OSD。 使用工具监控 placement groups 的移动情况，确保数据分布均匀。 四、结论 Tom 总结了会议内容，强调了 upmap balancer 在平衡 Ceph 集群利用率方面的重要性，并分享了添加 OSD 的经验和挑战。 五、后续行动计划 继续使用 upmap balancer 平衡 Echo 集群的利用率。 持续监控集群状态，确保数据分布均匀。 评估添加更多 OSD 的可行性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CephFS as a Scalable Filer - Rafael Lopez & Brett Milford, Monash University","slug":"CephFS_as_a_Scalable_Filer_-_Rafael_Lopez_Brett_Milford_Monash_University","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/CephFS_as_a_Scalable_Filer_-_Rafael_Lopez_Brett_Milford_Monash_University/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/CephFS_as_a_Scalable_Filer_-_Rafael_Lopez_Brett_Milford_Monash_University/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Raphael（来自澳大利亚莫纳什大学），Brett（来自澳大利亚莫纳什大学） 会议主题： 莫纳什大学在Ceph文件系统（CFS）方面的应用与实践 会议内容： 一、莫纳什大学简介 莫纳什大学是澳大利亚一所大型研究型大学，拥有超过70,000名学生和44,000名研究生。学校致力于提供高性能计算和可扩展存储服务，主要研究领域包括医学、药学、信息技术和商业等。 二、莫纳什大学研究数据中心 莫纳什大学研究数据中心是学校的一个重要组织，专注于提供高性能计算和可扩展存储服务。主要服务包括： Monash eResearch： 一个全国性的高性能计算集群，专注于GPU风格的应用。 CBL： 另一个GPU密集型虚拟实验室。 研究云： 为研究社区提供基础设施即服务。 RDS： 提供研究数据存储服务，包括数据收集和归档。 三、Ceph文件系统（CFS）在莫纳什大学的应用 莫纳什大学在CFS方面的应用主要包括以下几个方面： CFS集群： 莫纳什大学拥有多个CFS集群，用于存储和共享数据。 虚拟文件服务器： 使用CFS和RBD构建虚拟文件服务器，提供NFS和SMB服务。 对象存储： 使用CFS对象存储服务，用于存储大量数据。 四、CFS在莫纳什大学的性能测试 Raphael对CFS在不同场景下的性能进行了测试，并与虚拟文件服务器进行了比较。主要测试结果如下： NFS和SMB： CFS在NFS和SMB性能方面优于虚拟文件服务器，特别是在读写带宽和IOPS方面。 元数据密集型任务： 对于元数据密集型任务，如文件复制和目录遍历，CFS的性能明显优于虚拟文件服务器。 SMB： CFS在SMB性能方面也优于虚拟文件服务器，尤其是在读写带宽和IOPS方面。 五、CFS在莫纳什大学的挑战 Ceph版本： 莫纳什大学使用的是Red Hat Enterprise Ceph，存在一些包装问题。 Ceph访问： 提供原生Ceph访问和强制配额存在一些挑战。 备份： 备份大型文件系统存在一些挑战。 六、后续行动计划 升级Ceph版本： 考虑升级Ceph版本，以解决包装问题。 优化Ceph配置： 优化Ceph配置，以提高性能和可靠性。 测试Ceph功能： 测试Ceph的新功能，以进一步提高其可用性和可靠性。 七、会议总结 莫纳什大学在Ceph文件系统方面取得了显著成果，并成功将其应用于研究数据存储和共享。CFS在莫纳什大学的性能表现良好，但还存在一些挑战需要解决。莫纳什大学将继续优化Ceph配置，并探索新的技术，以进一步提高Ceph的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph BenchOps: Following DevOps Practices for Benchmarking Ceph - Ivo Jimenez, UC Santa Cruz","slug":"Ceph_BenchOps_-_Following_DevOps_Practices_for_Benchmarking_Ceph_-_Ivo_Jimenez_UC_Santa_Cruz","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Ceph_BenchOps_-_Following_DevOps_Practices_for_Benchmarking_Ceph_-_Ivo_Jimenez_UC_Santa_Cruz/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Ceph_BenchOps_-_Following_DevOps_Practices_for_Benchmarking_Ceph_-_Ivo_Jimenez_UC_Santa_Cruz/","excerpt":"","text":"会议纪要： 会议主题：简化Ceph（安全存储）项目上线流程 会议时间：[请填写具体时间] 会议地点：[请填写具体地点] 参会人员：Eva Jimenez（加州大学圣克鲁兹分校博士研究生） 会议内容： 项目背景： 加州大学圣克鲁兹分校的Graduate of Graduate课程时间较短（仅三个月）。 学生在项目上的工作时间有限。 目标是简化学生使用Ceph（安全存储）的上线和部署流程。 现有工作流程： 学生进行实验性工作流程，围绕Ceph进行实验。 目前的流程包括编译Ceph、工作、再次编译等，流程复杂且交互性强。 改进措施： 使用GitHub Action工作流程，这是一种工作流程规范语言，允许用户表达工作流程以及运行时执行的操作。 所有工作流程阶段均容器化，每个操作都在Docker容器中运行。 提供一个完整的功能性端到端工作流程，学生可以直接开始工作。 具体实施： 第一个工作流程：仅包含一个构建Ceph并生成所需文件的步骤，输出为容器，学生可直接启动容器并运行Bstar进行工作。 第二个工作流程：支持在云环境中进行基准测试和部署，使用GitHub Action提供的云资源操作。 使用NSF资助的云平台进行实验。 工作流程中的所有参数均进行了文档化，方便学生修改和记录。 后续计划： 开发基于Rook和Ceph的容器化工作流程。 进一步优化工作流程，提高效率和用户体验。 会议结论： 通过使用GitHub Action工作流程和容器化技术，可以显著简化Ceph项目的上线和部署流程，提高学生的工作效率和学习体验。后续将重点开发基于Rook和Ceph的容器化工作流程，进一步提升项目质量。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Manager Dashboard - The New Way To Manage Ceph & Gateway Management in Ceph Dashboard","slug":"Ceph_Manager_Dashboard_-_The_New_Way_To_Manage_Ceph_Gateway_Management_in_Ceph_Dashboard","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Ceph_Manager_Dashboard_-_The_New_Way_To_Manage_Ceph_Gateway_Management_in_Ceph_Dashboard/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Ceph_Manager_Dashboard_-_The_New_Way_To_Manage_Ceph_Gateway_Management_in_Ceph_Dashboard/","excerpt":"","text":"会议纪要 会议主题 本次会议主要讨论了Ceph存储系统的仪表盘（原名为“Safe Dashboard”）的最新功能和改进，并进行了现场演示。 关键细节 仪表盘发展历程：从Luminous版本引入的初始版本，到后续的改进，包括用户管理、角色配置、SSL支持、审计日志等功能。 新功能： 用户注册和角色配置，支持不同权限的用户。 SSL支持，增强安全性。 审计日志，记录操作记录。 多语言支持，目前支持6-7种语言。 API文档完善，方便开发者使用。 配置管理器，在UI中修改配置。 存储池管理，包括创建、删除、修改等功能。 RBD镜像管理，包括快照、克隆、移动到回收站等功能。 RGW镜像镜像功能，配置远程节点和复制策略。 外部服务管理： 支持管理RGW、NFS Ganesha和iSCSI网关。 通过REST API与网关进行交互，实现用户管理、存储池管理等功能。 讨论的主要议题 仪表盘的功能和改进。 如何使用仪表盘管理外部服务。 用户反馈和改进建议。 决定的事项 将仪表盘的功能和改进进行总结和记录。 邀请用户测试仪表盘，并提供反馈和建议。 继续完善仪表盘的功能和性能。 后续行动计划 继续开发仪表盘的新功能。 优化仪表盘的用户体验。 加强社区合作，收集用户反馈和建议。 计算机科学/CEPH相关领域英文原文关键词 Ceph Dashboard Safe Dashboard Self-manage Dashboard Luminous Nautilus Octopus REST API Angular Cherry Pie River Chairs AngularJS RBG Mirroring OSD Management Crush Map Monitor Manager Modules Pool Manager RBD Mirroring RGW Management NFS Ganesha iSCSI Gateway Management","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Orchestrator: Bridging the Gap Between Ceph and Deployment - Sebastian Wagner, SUSE","slug":"Ceph_Orchestrator_-_Bridging_the_Gap_Between_Ceph_and_Deployment_-_Sebastian_Wagner_SUSE","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Ceph_Orchestrator_-_Bridging_the_Gap_Between_Ceph_and_Deployment_-_Sebastian_Wagner_SUSE/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Ceph_Orchestrator_-_Bridging_the_Gap_Between_Ceph_and_Deployment_-_Sebastian_Wagner_SUSE/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储集群管理与视频会议字幕翻译 会议时间： 2023年11月（具体日期未提及） 参会人员： - Claudia Koreck - Sebastian Wagner - André（Sea Orchestrator 维护者） - Lukas - Kassie - Carey - Joseph - Minni - Josef - Alexander Huber - Roger - Janka - Juli - De Castries - Peter - Toni - Britta - Lucas - 其他未具名成员 会议内容： 一、Ceph 存储集群管理 集群管理模块： 模块连接到集群，实现集群管理功能。 与 Brander 服务连接，实现品牌管理。 与外部 orchestrator 连接，实现外部集群管理。 提供统一的用户界面，方便用户操作。 数据接口： 通过 Dashboard 实现数据访问。 支持监控、资源管理等功能。 用户可以根据权限访问数据。 集群监控： 监控集群状态，包括存储、网络、节点等。 发现问题并及时处理。 集群升级： 支持集群升级，包括硬件升级、软件升级等。 确保集群稳定运行。 二、视频会议字幕翻译 英译中： 对视频会议内容进行英译中翻译。 确保翻译准确、流畅。 总结： 对视频会议内容进行总结，提炼关键信息。 三、讨论议题 集群管理模块的改进： 提高模块的稳定性和可扩展性。 优化用户界面，提高用户体验。 集群监控的优化： 提高监控的准确性。 实现实时监控。 集群升级的自动化： 实现集群升级的自动化，减少人工干预。 视频会议字幕翻译的准确性： 提高翻译的准确性，减少错误。 四、决定事项 集群管理模块： 对集群管理模块进行优化，提高稳定性和可扩展性。 集群监控： 优化集群监控，提高监控的准确性和实时性。 集群升级： 实现集群升级的自动化。 视频会议字幕翻译： 提高翻译的准确性。 五、后续行动计划 集群管理模块： 制定详细的技术方案。 进行开发测试。 集群监控： 制定详细的改进方案。 进行开发测试。 集群升级： 制定详细的自动化方案。 进行开发测试。 视频会议字幕翻译： 制定详细的翻译规范。 进行翻译实践。 六、其他 会议期间，与会人员对 Ceph 存储集群管理和视频会议字幕翻译进行了深入讨论，并提出了许多有价值的意见和建议。 会议气氛热烈，参会人员积极参与，取得了良好的效果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Operations at CERN: Where Do We Go From Here? - Dan van der Ster & Teo Mouratidis, CERN","slug":"Ceph_Operations_at_CERN_-_Where_Do_We_Go_From_Here_-_Dan_van_der_Ster_Teo_Mouratidis_CERN","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Ceph_Operations_at_CERN_-_Where_Do_We_Go_From_Here_-_Dan_van_der_Ster_Teo_Mouratidis_CERN/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Ceph_Operations_at_CERN_-_Where_Do_We_Go_From_Here_-_Dan_van_der_Ster_Teo_Mouratidis_CERN/","excerpt":"","text":"会议纪要 会议时间： 下午2点 会议地点： CERN 参会人员： Dan（CERN运营人员）、Teo（CERN系统操作人员） 会议主题： CERN的Ceph集群运营总结及未来展望 会议内容： 一、CERN Ceph集群发展历程 2013年，CERN开始使用Ceph作为云存储解决方案。 2013年，建立了第一个Ceph集群，容量300TB。 2015年，集群容量扩展至3PB，并开始参与纠删码开发。 2016年，升级了大型集群，硬件更新，数据迁移至新集群，无停机时间。 2017年，8个Ceph集群投入生产，并决定将S3和CFS也提升至生产状态。 2018年，开始关注Stefan、Fest在HPC领域的应用。 二、CERN Ceph集群现状 目前CERN拥有多个Ceph集群，主要用于OpenStack Cinder和Glance。 集群规模从1PB到5PB不等。 部分集群采用全闪存架构，以提高性能。 正在逐步升级至Nautilus版本。 三、近期运营经验 迁移经验： 通过使用AdMob balancer和subvolume命令，实现了集群迁移，并提高了性能。 性能优化： 通过使用BlueStore，提高了文件存储性能。 S3认证： 通过同步EastAuckland s l's与Rattus gate，提高了S3认证速度。 HPC应用： 在HPC领域，使用Ceph作为存储解决方案，并取得了良好的性能。 备份： 使用Rustic工具和备份调度系统，实现了对CERN Box的备份。 物理分析： 使用Ceph进行物理分析演示。 四、未来计划 进一步优化Ceph集群性能。 探索Ceph在更多领域的应用。 参与Ceph社区建设。 五、行动计划 持续关注Ceph社区动态，及时跟进新功能。 优化Ceph集群性能，提高稳定性。 探索Ceph在更多领域的应用，如边缘计算、物联网等。 加强与Ceph社区的合作，共同推动Ceph技术的发展。 六、其他 CERN计划于今年9月在日内瓦举办Ceph Day，聚焦研究、学术和非营利机构。 关键词： Ceph、集群、性能优化、迁移、备份、HPC、物理分析、OpenStack、S3、Keystone","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Practice And Usage In China Mobile - Zhang Shaowen, China Mobile (Suzhou) Software Technology","slug":"Ceph_Practice_And_Usage_In_China_Mobile_-_Zhang_Shaowen_China_Mobile_Suzhou_Software_Technology","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Ceph_Practice_And_Usage_In_China_Mobile_-_Zhang_Shaowen_China_Mobile_Suzhou_Software_Technology/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Ceph_Practice_And_Usage_In_China_Mobile_-_Zhang_Shaowen_China_Mobile_Suzhou_Software_Technology/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 未提及 主持人： Carolyn，中国移动软件技术 参会人员： 中国移动相关技术人员，存储领域专家 会议内容： 一、中国移动业务介绍 Carolyn首先介绍了中国移动的业务范围，包括提供移动语音和多媒体服务，以及国际有线、远程移动电信网络。中国移动是全球最大的移动通信运营商，拥有超过9亿用户。 二、中国Beryl云计算产品 Cloud Recorder： 介绍了Cloud Recorder产品，它涵盖了Icepak和SAS服务，目前负责中国移动私有云Habana云性能管理云。 Big Cloud： Big Cloud产品已为超过30家中国移动专业公司提供IT服务，包括业务支撑、网络管理和任务管理。 三、中国Beryl云存储解决方案 Block Storage： 中国移动正在构建统一外交服务平台，支持集团的生产性对话，降低成本，提高效率。使用了基于Ceph的块存储解决方案，总容量超过40PB。 Object Storage： 中国移动对象存储基于Ceph解决方案，总容量超过1300PB。 四、中国Beryl私有云 一级私有云： 使用OpenStack平台，通过私有云管理平台实现资源统一管理，实现全网资源统一视图和部分省级资源的访问控制。 二级私有云： 总容量30PB，OSD数量超过2600个。 五、Ceph实践 CephFS： 中国移动在CephFS的基础上构建了统一外交服务平台。 Ceph Object Storage： 中国移动对象存储基于Ceph解决方案，支持Swift和S3接口。 Ceph管理平台： 中国移动开发了Ceph管理平台，用于集群部署、资源监控、自动化部署和运维升级等功能。 Ceph硬件配置： 中国移动提供了多种Ceph硬件配置，以满足不同用户需求，包括性能型、平衡型和通用型。 Ceph缓存： 中国移动使用Ceph缓存技术提高数据访问效率，并使用Ceph Block Device作为缓存设备。 六、Ceph Object Storage应用场景 备份： 将虚拟机镜像备份到Ceph对象存储。 归档： 存储图片、视频等大数据。 大数据分析： 支持大数据系统，如Hadoop、Spark等。 网站托管： 托管企业网站、数据网站等。 七、后续行动计划 持续优化Ceph管理平台，提高运维效率。 探索Ceph在更多领域的应用。 加强Ceph社区贡献，推动Ceph技术发展。 关键词： Ceph, 分布式存储, 块存储, 对象存储, CephFS, Ceph Object Storage, Ceph Block Device, Ceph缓存, Ceph管理平台","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Configuring Small Ceph Clusters for Optimal Performance - Josh Salomon, Red Hat","slug":"Configuring_Small_Ceph_Clusters_for_Optimal_Performance_-_Josh_Salomon_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Configuring_Small_Ceph_Clusters_for_Optimal_Performance_-_Josh_Salomon_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Configuring_Small_Ceph_Clusters_for_Optimal_Performance_-_Josh_Salomon_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： （请填写会议具体时间） 会议地点： （请填写会议具体地点） 参会人员： Josh Solomon，Red Hat 会议主题： 优化小型Ceph集群性能 会议内容： 关键议题 小型Ceph集群的独特性：小型集群（如三节点集群）在默认设置下可能无法达到最佳性能，因为Ceph是为大规模集群设计的。 性能瓶颈分析：在小型集群中，性能瓶颈可能存在于多个方面，如存储、网络、CPU等。 数据平衡的重要性：分布式系统容易受到“链中最弱环节”现象的影响。数据平衡可以确保资源均匀分配，避免性能瓶颈。 Ceph的数据平衡机制：Ceph通过放置组（Placement Groups，PGs）来平衡数据。PGs的数量和分布对于性能至关重要。 讨论要点 PGs的数量和分布： PGs的数量应选择2的幂，以获得更好的统计分布。 避免在PGs之间分配资源差异较大的设备。 在小型集群中，应考虑使用较少的PGs，因为过多的PGs可能导致性能下降。 平衡工具： 平衡器（Balancer）：可以优化PGs在数据存储设备上的分布。 OSD crush权重：可以手动调整OSD的权重，以影响数据分布。 PG自动缩放器（PG Autoscaler）：可以根据数据量自动调整PGs的数量。 监控和评估： 使用ceph osd df和ceph df命令来监控数据分布和集群健康。 使用ceph osd primary balancer脚本来评估主PGs的平衡情况。 性能优化： 考虑使用多个RGW实例来提供不同质量的服务。 注意内存和CPU的使用情况，避免交换空间过度使用。 决定事项 提高小型Ceph集群性能的关键在于： 选择合适的PGs数量和分布。 使用合适的平衡工具来优化数据分布。 监控和评估集群健康和性能。 根据实际情况调整配置和资源分配。 后续行动计划 Josh Solomon将提供相关工具和脚本，以帮助用户优化小型Ceph集群性能。 用户可以参考会议内容，根据自己的实际情况进行调整和优化。 会议总结 本次会议讨论了优化小型Ceph集群性能的关键技术和方法。通过合理配置、监控和优化，可以有效提高小型Ceph集群的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Day 2 Operations : Make Friends with Your Ceph Cluster - Adrien Gillard, Pictime Groupe","slug":"Day_2_Operations_-_Make_Friends_with_Your_Ceph_Cluster_-_Adrien_Gillard_Pictime_Groupe","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Day_2_Operations_-_Make_Friends_with_Your_Ceph_Cluster_-_Adrien_Gillard_Pictime_Groupe/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Day_2_Operations_-_Make_Friends_with_Your_Ceph_Cluster_-_Adrien_Gillard_Pictime_Groupe/","excerpt":"","text":"会议纪要 会议主题：Ceph 分布式存储最佳实践与维护 会议时间：[具体日期] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议内容： 一、会议背景 介绍 Ceph 分布式存储在医疗健康和公共服务领域的应用。 分享 Ceph 分布式存储在法国 Lille 和巴黎地区的应用经验。 二、会议主要议题 日志与监控 日志聚合：介绍 ELK（Elasticsearch、Logstash、Kibana）堆栈，用于日志聚合和可视化。 监控：强调监控与指标的区别，介绍 Zabbix 等开源监控工具和 Prometheus 指标收集。 指标收集：推荐 Ceph Metrics 项目，用于收集、存储和分析 Ceph 集群指标。 配置管理 使用配置管理工具，如 Puppet、Chef、Ansible 等，实现集中式配置管理。 推荐使用 Git 作为配置存储和版本控制工具。 使用 GitOps 策略，实现自动化测试和部署。 更新 强调及时更新 Ceph 集群的重要性，以及更新过程中需要注意的事项。 阅读发布说明和更新说明，了解新特性和潜在问题。 分享更新经验，及时反馈问题和改进建议。 维护与集群生命周期 预防性维护：定期检查集群状态，及时发现和解决问题。 故障处理：介绍磁盘故障处理流程，包括智能检查、磁盘替换等。 数据完整性：强调 Scrub 的作用，以及如何调整 Scrub 配置以减少对集群的影响。 新特性：介绍 Ceph 的新特性，如 Balancer Manager、Orchestrator、Dashboard、PG Increase/Decrease、自动调优、磁盘故障预测等。 三、行动计划 各参会人员根据会议内容，结合自身实际情况，制定相应的维护和优化计划。 积极参与 Ceph 社区，分享经验和改进建议。 关注 Ceph 的新特性，及时更新集群。 四、会议总结 本次会议分享了 Ceph 分布式存储的最佳实践和维护经验，为参会人员提供了有益的参考。希望参会人员能够将所学知识应用到实际工作中，不断提升 Ceph 集群的管理水平。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Configuring Ceph Deployments with an Easy to Use Calculator - Karl Vietmeier, Intel Corporation","slug":"Configuring_Ceph_Deployments_with_an_Easy_to_Use_Calculator_-_Karl_Vietmeier_Intel_Corporation","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Configuring_Ceph_Deployments_with_an_Easy_to_Use_Calculator_-_Karl_Vietmeier_Intel_Corporation/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Configuring_Ceph_Deployments_with_an_Easy_to_Use_Calculator_-_Karl_Vietmeier_Intel_Corporation/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： Carl (Intel数据中心组织云解决方案架构师) 会议主题： Ceph存储系统中WAL和DB分区大小及所需空间 会议内容： 背景介绍： Carl介绍了Intel数据中心组织，并说明了本次会议将讨论Ceph存储系统中WAL和DB分区的大小以及所需空间。 问题提出： 由于对WAL和DB分区大小的疑问较多，且现有文档给出的建议过大，因此决定进行实证测试以确定更合适的大小。 测试方法： 使用现有的基准测试服务器和集群，对不同大小的对象进行测试，以确定WAL和DB分区的大小。 测试结果： WAL大小主要取决于元数据量和处理速度。 经过测试，建议将元数据大小设置为每个对象20KB，每个OSD需要约5GB的元数据空间。 根据测试结果，文档中推荐的4%的空间可能过大，实际所需空间可能在2-3GB之间。 WAL大小主要与数据变化率有关，建议设置80秒的缓冲区。 结论： 建议根据实际使用情况调整WAL和DB分区大小，并进行测试验证。 WAL分区空间可能在2-3GB之间，DB分区空间约为5GB。 行动计划： 将测试结果整理成文档，供相关人员参考。 鼓励用户根据实际使用情况调整WAL和DB分区大小，并进行测试验证。 备注： 会议中提到的一些关键词：WAL、DB、元数据、对象、OSD、RocksDB、CBT、I/O大小等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Exploring the Performance Limits of CephFS in Nautilus - Manoj Pillai, Red Hat","slug":"Exploring_the_Performance_Limits_of_CephFS_in_Nautilus_-_Manoj_Pillai_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Exploring_the_Performance_Limits_of_CephFS_in_Nautilus_-_Manoj_Pillai_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Exploring_the_Performance_Limits_of_CephFS_in_Nautilus_-_Manoj_Pillai_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： Manoj Pillai（Red Hat 性能工程团队），其他与会人员 会议主题： 探索 Nautilus 中 Surface 的性能限制 会议内容： 背景介绍： Manoj Pillai 介绍了自己从 Red Hat 软件定义存储项目 Cluster 移动到 Safe 项目的过程，并分享了他对性能问题的关注和解决方法。 性能测试： 使用 FIO 和 smallfile 工具进行性能测试，评估 Surface 的 I/O 性能。 测试内容包括大型文件顺序 I/O、随机 I/O 和小型文件 I/O，以及一些日常管理员和用户常使用的命令。 测试硬件配置包括高性能 NVMe 驱动、25G 以太网和高端 CPU。 测试结果： Surface 在顺序 I/O 和随机读方面表现出色，但随机写性能较差。 在小型文件 I/O 方面，Surface 的性能较差，尤其是在创建和删除命令方面。 测试结果表明，MDS 可能是性能瓶颈之一。 未来工作： 研究提高 MDS 可扩展性和性能的方法。 探索可能的调整和修复方案，以提高 Surface 的 I/O 性能。 关键细节： 性能瓶颈： MDS 可能是性能瓶颈之一。 测试结果： Surface 在顺序 I/O 和随机读方面表现出色，但随机写和小型文件 I/O 性能较差。 未来工作： 研究提高 MDS 可扩展性和性能的方法。 讨论的主要议题： Surface 的性能限制。 MDS 可能是性能瓶颈之一。 提高 MDS 可扩展性和性能的方法。 决定的事项： 研究提高 MDS 可扩展性和性能的方法。 探索可能的调整和修复方案，以提高 Surface 的 I/O 性能。 后续行动计划： Manoj Pillai 将继续研究 MDS 的性能和可扩展性问题。 与社区合作，探索可能的调整和修复方案。 关键词： Surface Nautilus MDS I/O 性能 可扩展性 性能瓶颈","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Failing Better - When Not To Ceph and Lessons Learned - Lars Marowsky-Brée, SUSE","slug":"Failing_Better_-_When_Not_To_Ceph_and_Lessons_Learned_-_Lars_Marowsky-Bree_SUSE","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Failing_Better_-_When_Not_To_Ceph_and_Lessons_Learned_-_Lars_Marowsky-Bree_SUSE/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Failing_Better_-_When_Not_To_Ceph_and_Lessons_Learned_-_Lars_Marowsky-Bree_SUSE/","excerpt":"","text":"会议纪要 会议主题： Ceph 的限制和约束 会议时间： 2023年11月（具体日期未提及） 参会人员： Las（Sousa 公司 Ceph 研发人员）及其他未提及人员 会议内容： Ceph 的优势： 适用于超大规模存储系统，如 CERN 等。 具备高可用性和可靠性。 支持多种存储协议，如 POSIX 文件系统、对象存储等。 具备良好的扩展性。 Ceph 的限制： 对于小规模集群，性能可能不如预期。 对于大数据应用，需要考虑数据增长速度和存储成本。 对于传统工作负载，可能需要调整以适应 Ceph 的特性。 对于单节点故障，可能需要考虑数据恢复时间。 对于硬件选择，需要考虑兼容性和可靠性。 对于网络选择，需要考虑带宽和延迟。 Ceph 的使用场景： 超大规模存储系统。 大数据应用，数据增长速度快。 对可用性和可靠性要求高的应用。 需要支持多种存储协议的应用。 Ceph 的注意事项： 需要了解 Ceph 的特性和限制。 需要根据实际需求选择合适的硬件和网络。 需要考虑数据恢复时间和成本。 需要关注性能和延迟。 行动计划： 深入了解 Ceph 的特性和限制。 根据实际需求选择合适的硬件和网络。 制定数据恢复策略。 关注性能和延迟。 会议总结： Ceph 是一款功能强大的分布式存储系统，适用于多种场景。但同时也存在一些限制和约束。在部署和使用 Ceph 时，需要充分了解其特性和限制，并根据实际需求进行合理规划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Getting Started as a Rook-Ceph Developer - Blaine Gardner, SUSE","slug":"Getting_Started_as_a_Rook-Ceph_Developer_-_Blaine_Gardner_SUSE","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Getting_Started_as_a_Rook-Ceph_Developer_-_Blaine_Gardner_SUSE/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Getting_Started_as_a_Rook-Ceph_Developer_-_Blaine_Gardner_SUSE/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议地点] 参会人员： Blaine Gardner（Sousa企业存储部门，Rook维护者之一）、Sebastian Vogner（Rook Orchestrator维护者）、Travis Neilson（Rook原始维护者） 会议主题： Rook 开发入门及社区参与 会议内容： Rook 简介： Rook 是一个用于在 Kubernetes 上创建、部署和管理存储集群的框架。 Rook 使用 Kubernetes API 和自定义资源定义（CRD）来实现其功能。 Rook 的核心概念包括 Operator、CRD、Pod、Config Map、Secret、DaemonSet 等。 Rook 的目标是将 Ceph 存储系统与 Kubernetes 集成，使其易于管理和扩展。 Rook 架构： Rook 使用 Operator 模式，其中 Operator 是一个运行在 Kubernetes 上的应用程序，用于管理 Ceph 集群。 Rook 的主要组件包括： Rook Operator：管理 Ceph 集群的整个生命周期。 CRD：定义 Ceph 集群的配置和数据。 Pod：运行 Ceph 服务（如 Monitor、OSD、MDS 等）的容器。 Config Map 和 Secret：存储配置信息和敏感信息。 DaemonSet：在 Kubernetes 节点上运行特定的服务（如 Redis Gateway）。 Rook 开发： 开发 Rook 需要熟悉 Kubernetes、容器化和 Ceph。 开发者可以使用 MiniCube 或其他 Kubernetes 集成测试环境来测试 Rook。 Rook 提供了单元测试和集成测试，以确保代码的质量。 开发者可以使用 GitHub 和 Slack 等平台与其他 Rook 开发者进行交流。 社区参与： Ceph 社区日历提供了上游协调和社区活动的信息。 Rook 社区活跃，开发者可以通过 GitHub、Slack 等平台与其他开发者进行交流。 讨论的主要议题： Rook 的架构和功能 Rook 开发的流程 社区参与的方式 决定的事项： 鼓励开发者参与 Rook 社区 提供 Rook 开发资源和支持 后续行动计划： Sebastian Vogner 将介绍 Rook Orchestrator 的开发环境 Travis Neilson 将介绍 Rook 的测试环境 Blaine Gardner 将回答关于 Rook 的问题 会议总结： 本次会议介绍了 Rook 的架构、功能和开发流程，并鼓励开发者参与 Rook 社区。会议还讨论了社区参与的方式，并制定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Healthier Ceph Clusters with Ceph-medic - Alfredo Deza, Red Hat","slug":"Healthier_Ceph_Clusters_with_Ceph-medic_-_Alfredo_Deza_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Healthier_Ceph_Clusters_with_Ceph-medic_-_Alfredo_Deza_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Healthier_Ceph_Clusters_with_Ceph-medic_-_Alfredo_Deza_Red_Hat/","excerpt":"","text":"会议纪要 会议主题： 健康安全集群与Set Medic 参会人员： Alfredo Lisa（Red Hat） 会议内容： 一、背景介绍 Alfredo Lisa来自Red Hat，主要讨论如何通过Set Medic提高集群健康和安全。 在开发过程中，经常会遇到部署问题，难以理解问题根源。 二、关键问题与解决方法 问题： 部署集群时，使用标准部署流程，但某些组件无法正常启动。 解决方法： 首先查看Rados故障排除指南，分析日志，检查系统D等。 使用Somatic工具进行自动化错误检查，快速定位问题。 三、Somatic工具介绍 功能： 支持Docker容器、OpenShift、Kubernetes或裸机主机。 自动连接集群中的所有节点，获取集群上下文。 比较不同节点之间的信息，快速定位问题。 示例： 在Kubernetes集群中，发现某个节点上的FS IV与其它节点不同，导致问题。 Somatic工具可以轻松识别并解决问题。 四、行动计划 尝试使用Somatic工具，并提交系统票据和问题反馈。 根据反馈，持续改进Somatic工具。 五、总结 Somatic工具可以帮助开发者快速定位集群问题，提高集群健康和安全。希望大家尝试使用该工具，并积极反馈，共同改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Geographical Redundancy with rbd-mirror: Best... - Florian Haas","slug":"Geographical_Redundancy_with_rbd-mirror_-_Best..._-_Florian_Haas","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Geographical_Redundancy_with_rbd-mirror_-_Best..._-_Florian_Haas/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Geographical_Redundancy_with_rbd-mirror_-_Best..._-_Florian_Haas/","excerpt":"","text":"会议纪要 会议主题： Ceph RBD镜像功能详解及最佳实践 会议时间： 2023年11月（具体日期未提及） 参会人员： Lorien（Ceph研发人员），以及通过Twitter提问的观众 会议内容： 一、RBD镜像功能概述 RBD镜像是一种异步复制Radice块设备内容到远程集群的功能，已存在三年。 主要应用于跨地域数据备份和灾难恢复。 与传统同步复制相比，RBD镜像不受网络延迟影响，更适用于长距离复制。 二、RBD镜像工作原理 应用程序写入数据时，首先与主OSD通信，主OSD负责将数据复制到非主OSD。 RBD镜像通过RBD层进行异步复制，使用RBD日志记录所有写操作。 RBD镜像守护进程监控日志更新，并将其应用到远程集群的RBD镜像中。 三、RBD镜像配置 启用RBD日志记录： 使用rbd feature enable pool/image journal命令启用RBD日志记录。 配置RBD镜像守护进程： 创建具有适当权限的RBD镜像守护进程身份，并将其配置为访问本地和远程集群。 连接RBD镜像实例： 使用rbd mirror pool peer add命令连接RBD镜像实例，实现双向镜像。 启动RBD镜像服务： 使用systemd或容器管理工具启动RBD镜像守护进程。 四、RBD镜像模式 单向镜像： 数据只能从主集群复制到远程集群。 双向镜像： 数据可以在主集群和远程集群之间双向复制。 五、RBD镜像性能 RBD镜像对读取性能影响较小，但对写入性能有一定影响，特别是在使用相同存储池的情况下。 可以通过调整RBD日志记录参数来优化性能。 六、RBD镜像与云平台集成 可以将RBD镜像与OpenStack集成，实现跨地域数据备份和灾难恢复。 需要配置OpenStack集群、RBD镜像、存储网络等，并确保OpenStack元数据也得到复制。 七、最佳实践 在启用RBD日志记录之前，评估其性能影响。 选择合适的RBD镜像模式和存储池。 使用自动化工具简化RBD镜像配置和管理。 后续行动计划： 完善RBD镜像文档。 优化RBD镜像性能。 推进RBD镜像与其他云平台的集成。 关键词： RBD镜像、异步复制、日志记录、性能、OpenStack、灾难恢复","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Highly Available Git on CephFS with Rook, Kubernetes, and OpenStack - James E. Blair, Red Hat","slug":"Highly_Available_Git_on_CephFS_with_Rook_Kubernetes_and_OpenStack_-_James_E._Blair_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Highly_Available_Git_on_CephFS_with_Rook_Kubernetes_and_OpenStack_-_James_E._Blair_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Highly_Available_Git_on_CephFS_with_Rook_Kubernetes_and_OpenStack_-_James_E._Blair_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： James Blair（Red Hat CTO办公室），OpenStack社区代表 会议主题： Open Dev项目介绍及在OpenStack中的应用 会议内容： James Blair自我介绍： 来自Red Hat，代表OpenStack社区，介绍Open Dev项目。 Open Dev项目介绍： Open Dev是一个为OpenStack开发的软件开发环境，是目前世界上第三活跃的免费软件项目。 项目使用免费软件进行开发和系统运营。 主要工具包括Gerrit（代码审查）、Zul（持续集成和持续部署）和Git T（代码托管）。 Git T服务目前运行在8个虚拟机上，需要扩展和优化。 Git T服务优化： 当前Git T服务运行在独立的虚拟机上，难以扩展和规模扩展。 计划将Git T服务迁移到共享一切模型，使用Ceph Filesystem（Ceph文件系统）作为共享文件系统，Percona XtraDB Cluster作为数据库，Elasticsearch集群用于全文索引。 使用Kubernetes进行管理，利用OpenStack提供的服务，如负载均衡器、块存储和虚拟机。 自动化部署： 使用Kubernetes on OpenStack项目进行自动化部署，该项目提供一系列Ansible Playbook，用于在OpenStack上部署Kubernetes，并配置与OpenStack的集成。 使用Rook进行Ceph集群的部署和管理。 Rook部署： 使用Rook的Flex存储驱动程序在Kubernetes上部署Ceph集群。 使用Rook的Operator简化Ceph集群的部署和管理。 使用BlueStore存储驱动程序提高性能。 其他部署： 使用Percona XtraDB Cluster作为数据库。 使用Ansible Playbook创建Percona集群。 使用Kubernetes部署Git T应用程序。 行动计划： 完成Git T服务的迁移和优化。 继续使用Rook和Ceph进行部署和管理。 探索使用Ceph作为Percona XtraDB Cluster的后端存储。 会议总结： Open Dev项目是一个基于OpenStack的软件开发环境，该项目使用免费软件进行开发和系统运营。Git T服务是Open Dev项目的重要组成部分，目前正在进行优化和扩展。会议介绍了Git T服务的优化方案、自动化部署和Rook部署等内容。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Hands On with Rook: Ceph & Kubernetes - Maxime Guyot, Root Pi & John Studarus, Packet Host","slug":"Hands_On_with_Rook_-_Ceph_Kubernetes_-_Maxime_Guyot_Root_Pi_John_Studarus_Packet_Host","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Hands_On_with_Rook_-_Ceph_Kubernetes_-_Maxime_Guyot_Root_Pi_John_Studarus_Packet_Host/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Hands_On_with_Rook_-_Ceph_Kubernetes_-_Maxime_Guyot_Root_Pi_John_Studarus_Packet_Host/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未知） 会议地点： 线上会议 参会人员： John, Max（主持人）、所有参与者 会议主题： 使用 Rook 在裸金属上运行分布式存储 Ceph 的研讨会 会议内容： 一、会议概述 本次会议主要介绍了如何使用 Rook 在裸金属上部署和运行 Ceph 分布式存储系统。会议内容涵盖了 Ceph 集群的搭建、配置、监控和升级等方面。 二、主要议题 环境搭建： 参会者将使用两台物理服务器进行实验，一台为 T1 小型服务器，另一台为 C2 中型服务器。 T1 服务器仅包含文件系统，C2 服务器包含文件系统和多个 NVMe SSD 驱动器。 参会者可通过 SSH 访问实验环境。 Rook 部署： 使用 Rook 部署 Ceph 集群，包括 Ceph Mon、Manager 和 OSD。 验证 Kubernetes 集群是否正常运行。 Ceph 集群配置： 创建 Ceph 块存储池和文件系统。 创建 Ceph 对象存储网关（RGW）。 使用 Ceph 对象存储上传和下载文件。 监控： 使用 Prometheus 和 Grafana 监控 Ceph 集群的健康状况、性能和容量。 创建自定义仪表板以可视化监控数据。 升级： 使用 Rook 升级 Ceph 集群到最新版本。 三、决定事项 参会者将使用提供的实验环境进行实验。 主持人将解答参会者提出的问题。 参会者将根据实验指南完成实验任务。 四、后续行动计划 参会者完成实验任务并提交实验报告。 主持人整理实验结果并撰写实验总结。 主持人收集参会者反馈，改进实验指南。 五、会议总结 本次会议成功介绍了如何使用 Rook 在裸金属上部署和运行 Ceph 分布式存储系统。参会者通过实验加深了对 Ceph 和 Rook 的理解，并掌握了相关操作技能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"I Need More Space, It's Not You It's BlueStore - Mohamad Gebai, SUSE","slug":"I_Need_More_Space_It_s_Not_You_It_s_BlueStore_-_Mohamad_Gebai_SUSE","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/I_Need_More_Space_It_s_Not_You_It_s_BlueStore_-_Mohamad_Gebai_SUSE/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/I_Need_More_Space_It_s_Not_You_It_s_BlueStore_-_Mohamad_Gebai_SUSE/","excerpt":"","text":"会议纪要 会议主题： “空间不足，问题不在于你，而在于BlueStore的故事” 会议时间： （请在此处填写会议具体时间） 会议地点： （请在此处填写会议地点） 参会人员： 主讲人：Mohammed Dubai，Sousa软件工程师 与会人员：（请在此处填写与会人员名单） 会议内容： 1. 会议概述 Mohammed Dubai分享了几个来自Sousa用户邮件列表的案例，探讨了用户在使用Ceph存储时遇到的空间使用问题。 2. 关键案例分析 案例一：FDF命令分析 - 问题描述：用户使用FDF命令查看空间使用情况，发现使用率高达92%，但实际可用的空间只有1.5GB。 - 原因分析：数据分布不均，部分存储池使用率极高，导致“最大可用空间”指标不准确。 - 解决方案：使用upmap balancer进行数据均衡，确保数据分布均匀。 案例二：RBD和XFS文件系统 - 问题描述：用户创建了一个1TB的RBD，在XFS文件系统上使用7tf工具，发现使用了500MB空间，但删除文件后空间并未释放。 - 原因分析：XFS文件系统的元数据占用空间，且删除文件后空间未被正确释放。 - 解决方案：在文件系统上运行FS trim命令，释放未使用的块。 案例三：Radios和对象存储 - 问题描述：用户使用Radios向存储池推送100个100字节的对象，发现实际存储空间使用率远高于预期。 - 原因分析：BlueStore的最小分配单位是64KB，导致大量小对象产生大量开销。 - 解决方案：优化应用程序，使用更大的对象或提高最小分配单位。 案例四：BlueStore压缩 - 问题描述：启用BlueStore压缩后，发现压缩后的数据与分配到磁盘的数据存在差异。 - 原因分析：对象过小导致压缩效率低下，产生额外开销。 - 解决方案：使用更大的对象或优化应用程序。 决定事项： 使用FDF命令时，需结合数据分布情况综合判断空间使用情况。 对于RBD和XFS文件系统，注意元数据占用空间，并定期运行FS trim命令。 优化应用程序，使用更大的对象或提高最小分配单位，提高存储效率。 启用BlueStore压缩时，注意对象大小，避免压缩效率低下。 后续行动计划： 与会人员根据会议内容，结合自身实际情况，优化Ceph存储配置和应用设计。 针对案例中提到的问题，Sousa团队将进一步完善相关功能，提高存储效率。 会议总结： 本次会议针对Ceph存储空间使用问题进行了深入探讨，分享了多个案例及解决方案，有助于与会人员更好地了解和解决空间使用问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Juggling Petabytes: Managing Ceph at Scale with Ceph-ansible - Matthew Vernon","slug":"Juggling_Petabytes_-_Managing_Ceph_at_Scale_with_Ceph-ansible_-_Matthew_Vernon","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Juggling_Petabytes_-_Managing_Ceph_at_Scale_with_Ceph-ansible_-_Matthew_Vernon/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Juggling_Petabytes_-_Managing_Ceph_at_Scale_with_Ceph-ansible_-_Matthew_Vernon/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 巴塞罗那 参会人员： 会议主讲人，Saenger研究院的Ceph存储团队，以及与会听众 会议主题： Saenger研究院的Ceph存储集群部署、管理及经验分享 会议内容： 一、Saenger研究院简介 Saenger研究院成立于1992年，专注于基因测序和基因组分析。在人类基因组测序中，Saenger研究院是最大的贡献者。研究院拥有约20,000个核心的计算集群，以及约15PB的Lustre存储和20PB的iRODS对象存储。 二、Ceph存储集群部署 Saenger研究院于2016年开始使用Ceph存储，目前拥有51个节点，18PB的原始容量。集群使用Supermicro服务器，配置有半TB的RAM、 Mellanox 100G网络和SAS驱动器。研究院还拥有一个测试集群和一个灾备站点。 三、Ceph存储集群管理 Saenger研究院使用Ansible进行集群管理，并基于Ceph Ansible Wall进行定制。他们还使用Collectd收集Ceph集群的指标，并使用Nagios进行监控。研究院还编写了脚本，用于监控OSD状态和硬盘健康状况。 四、Ceph存储集群升级 Saenger研究院已将Ceph集群从Jewel版本升级到Luminous版本，并计划在未来迁移到Nautilus版本。升级过程相对顺利，但迁移到BlueStore时遇到了一些挑战。 五、Ceph存储集群使用经验 Saenger研究院对Ceph存储集群非常满意，认为其具有以下优点： 易于扩展 高可靠性 高性能 六、Ceph存储集群的挑战 Saenger研究院在使用Ceph存储集群时也遇到了一些挑战，主要包括： Rados Gateway服务管理复杂 大型OMAP对象 无法自动迁移数据到纠删码池 无法自动缩减池大小 部署过程复杂 七、行动计划 Saenger研究院将继续使用Ceph存储集群，并致力于解决上述挑战。他们计划： 使用新的Ceph功能，例如纠删码和自动缩减池大小 优化Rados Gateway服务管理 简化部署过程 八、会议总结 本次会议分享了Saenger研究院在Ceph存储集群部署、管理及使用方面的经验。与会人员对Saenger研究院的经验进行了讨论，并提出了宝贵的建议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keeping up a Competitive Ceph/RadosGW S3 API - Javier Muñoz, Igalia","slug":"Keeping_up_a_Competitive_Ceph_RadosGW_S3_API_-_Javier_Munoz_Igalia","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keeping_up_a_Competitive_Ceph_RadosGW_S3_API_-_Javier_Munoz_Igalia/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keeping_up_a_Competitive_Ceph_RadosGW_S3_API_-_Javier_Munoz_Igalia/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储项目进展及字幕翻译工作讨论 会议时间：[请插入具体日期和时间] 会议地点：[请插入具体地点] 参会人员：[请插入参会人员名单] 会议内容： 一、Ceph分布式存储项目进展 1. 项目背景：回顾了Ceph分布式存储项目的历史，包括意大利项目、公司行动团队等，强调了项目的重要性和贡献。 2. 项目现状：介绍了Ceph分布式存储项目的最新进展，包括新增功能、性能优化、安全性提升等。 3. 项目挑战：讨论了项目在实施过程中遇到的问题，如数据存储管理、性能优化、兼容性等。 4. 项目决策：确定了后续行动计划，包括优化存储管理、提升性能、加强安全性等。 二、字幕翻译工作讨论 1. 翻译任务：介绍了字幕翻译工作，包括英译中、总结等工作内容。 2. 翻译质量：强调了翻译质量的重要性，要求翻译人员准确、流畅地完成翻译任务。 3. 翻译工具：讨论了翻译工具的选择和优化，以提高翻译效率和准确性。 4. 后续计划：制定了字幕翻译工作的后续计划，包括翻译任务分配、进度跟踪等。 三、其他事项 1. 人员介绍：介绍了参会人员及各自职责。 2. 项目合作：讨论了与合作伙伴的合作关系，包括技术支持、资源共享等。 3. 项目推广：讨论了Ceph分布式存储项目的推广计划，包括线上宣传、线下活动等。 四、行动计划 1. Ceph分布式存储项目： - 优化存储管理； - 提升性能； - 加强安全性； - 制定详细的项目实施计划。 字幕翻译工作： 分配翻译任务； 跟踪翻译进度； 提高翻译质量。 五、后续会议 1. 确定下次会议时间及地点； 2. 确定下次会议议题。 会议总结： 本次会议对Ceph分布式存储项目进展及字幕翻译工作进行了全面讨论，明确了后续行动计划。参会人员表示将全力以赴，确保项目顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Ceph Journey - A Perspective - Dr. Gerald Pfeifer, Chief Technology Officer, SUSE","slug":"Keynote_-_Ceph_Journey_-_A_Perspective_-_Dr._Gerald_Pfeifer_Chief_Technology_Officer_SUSE","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_Ceph_Journey_-_A_Perspective_-_Dr._Gerald_Pfeifer_Chief_Technology_Officer_SUSE/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_Ceph_Journey_-_A_Perspective_-_Dr._Gerald_Pfeifer_Chief_Technology_Officer_SUSE/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议地点： 巴塞罗那 参会人员： Ceph社区成员、开发人员、用户等 会议主题： Ceph社区发展、新技术趋势、产品发布及未来规划 会议内容： 一、Ceph社区发展 社区活力与支持： 会议强调了Ceph社区的健康活力和强大支持，特别是Ceph基金会成立后，社区得到了进一步的加强。 开源精神： 强调了开源精神的重要性，认为开源不仅仅是代码和许可证，更重要的是社区和合作。 用户案例： 分享了几个Ceph在大学、科技公司、政府机构等不同领域应用的案例，展示了Ceph的强大功能和稳定性。 二、新技术趋势 容器化： 认为Ceph非常适合容器化，例如用于超融合基础设施和OpenStack。 人工智能运维： 认为Ceph可以进一步发展，实现自我管理、自我优化和自我修复，减少运维人员的参与。 互操作性： 认为Ceph需要与其他平台和系统更好地集成，例如Windows和VMware。 混合云： 认为Ceph可以支持混合云环境，包括定价模型和多云数据管理。 三、产品发布及未来规划 Ceph产品发布： 宣布了Ceph企业存储6.0版本，基于Nautilus分支，将包含Ceph的最新功能和改进。 未来规划： 计划在2023年进一步扩展Ceph的功能，包括增强容器化、人工智能运维、互操作性和混合云支持。 四、行动计划 社区建设： 继续加强Ceph社区建设，吸引更多开发者、用户和合作伙伴加入。 技术创新： 加快Ceph的技术创新，推动Ceph在更多领域得到应用。 产品迭代： 持续迭代Ceph产品，提供更多功能和更好的用户体验。 五、其他事项 庆祝Ceph社区成就： 鼓励参会者庆祝Ceph社区的成就，并分享自己的贡献。 互动交流： 鼓励参会者积极参与会议，与其他参会者交流心得。 总结： 本次会议回顾了Ceph社区的发展历程，探讨了新技术趋势和未来规划，并宣布了Ceph企业存储6.0版本。会议强调了社区、创新和产品迭代的重要性，为Ceph的未来发展指明了方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: A Wonderful Journey On Ceph - Luo Kexue, Senior Software Engineer, ZTE Corporation","slug":"Keynote_-_A_Wonderful_Journey_On_Ceph_-_Luo_Kexue_Senior_Software_Engineer_ZTE_Corporation","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_A_Wonderful_Journey_On_Ceph_-_Luo_Kexue_Senior_Software_Engineer_ZTE_Corporation/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_A_Wonderful_Journey_On_Ceph_-_Luo_Kexue_Senior_Software_Engineer_ZTE_Corporation/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写会议地点] 参会人员： Luo Kashia（来自中国的软件工程师），Mike（主持人） 会议主题： ZTE公司与Ceph社区的参与与贡献 会议内容： 自我介绍： Luo Kashia介绍了自己是中国的一名软件工程师，目前就职于SiLiCoPress公司。 他感谢Mike的正确发音，并提到自己有一个英文名字Science。 ZTE公司介绍： ZTE公司成立于1985年，致力于为全球客户提供通信产品和服务。 公司拥有超过80,000名员工，107个分支机构，19个研发中心遍布全球。 公司产品包括移动设备、核心网络、5G无线、云计算和存储等。 Ceph社区的参与： 随着越来越多的客户选择OpenStack作为云解决方案，ZTE团队面临了可扩展性、功能和可靠性等挑战。 他们开始学习Ceph，并发现Ceph社区的一些文档存在错误和遗漏，于是开始修复这些问题。 在贡献文档的过程中，他们熟悉了Ceph社区的贡献流程，并报告了一些问题。 由于一些问题无法及时解决，他们决定自己修复这些问题，并开始修复Ceph的bug。 随着对Ceph的深入了解，他们成为了真正的Ceph社区成员，并积极参与Ceph社区的贡献。 Ceph社区的贡献： ZTE团队在Ceph社区贡献了包括bug修复、功能增强和性能优化等方面的内容。 他们参与了Rados、BlueStore、RBDS、QoS、单一恢复映射等组件的改进。 去年，他们加入了Ceph基金会，成为高级会员。 Ceph书籍的编写： 由于中国有很多开发者对Ceph的BlueStore和RBD等组件难以理解，ZTE团队编写了两本关于Ceph的书籍，帮助中国开发者更好地理解Ceph。 基于Ceph的分布式存储解决方案： ZTE团队基于Ceph构建了一个分布式存储解决方案，称为Club Storage。 Club Storage与开源Ceph兼容，并集成了缓存、智能网关等新组件，以优化性能和提供不同类型的存储服务。 Club Storage的成功案例： Club Storage因其卓越的产品能力而获得了全球客户的认可，包括中国三大运营商以及Wang welcome等。 总结： Luo Kashia鼓励更多的人加入Ceph社区，并享受这个过程。 他认为硅谷应该是一个庆祝的地方，而不是测试或考试。 行动计划： [请填写后续行动计划]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Ceph as Part of the Data Infrastructure for Zoned Storage - Jorge Campello De Souza","slug":"Keynote_-_Ceph_as_Part_of_the_Data_Infrastructure_for_Zoned_Storage_-_Jorge_Campello_De_Souza","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_Ceph_as_Part_of_the_Data_Infrastructure_for_Zoned_Storage_-_Jorge_Campello_De_Souza/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_Ceph_as_Part_of_the_Data_Infrastructure_for_Zoned_Storage_-_Jorge_Campello_De_Souza/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 会议地点： [具体地点] 参会人员： [参会人员名单] 会议主题： Saif项目作为Zone存储数据基础设施的一部分 会议内容： 开场： 会议以简短的互动开始，主持人介绍了Saif项目作为数据基础设施的一部分，并强调了数据驱动经济对数据基础设施带来的压力。 数据驱动经济的影响： 会议指出，当前数据驱动经济下的新技术（如人工智能、机器学习等）导致数据量激增，对数据基础设施提出了更高的要求。 存储技术转型： 主持人介绍了存储技术的转型，特别是SMR（单磁记录）技术在硬盘驱动器中的应用，以及SSD中擦除块的约束。 Zone Block Devices： 详细解释了Zone Block Devices的工作原理，包括线性地址空间、区域划分、顺序写入等特性，以及其带来的性能和效率提升。 SEF与Zone Block Technologies： 讨论了如何将Zone Block Technologies整合到SEF（Sage）项目中，以利用这些新技术提高存储效率。提到与CMU（卡内基梅隆大学）的合作，共同推进相关研究。 行动计划： 鼓励参会人员进一步了解这些新技术，并参与到相关研究和项目中。 关键细节： 数据驱动经济对数据基础设施带来的压力。 SMR技术在硬盘驱动器中的应用。 Zone Block Devices的特性及其优势。 SEF与Zone Block Technologies的整合。 讨论的主要议题： 如何应对数据驱动经济带来的挑战。 如何利用新技术提高存储效率。 如何将Zone Block Technologies整合到SEF项目中。 决定的事项： 推进SEF与Zone Block Technologies的整合。 加强与CMU等机构的合作。 鼓励参会人员参与相关研究和项目。 后续行动计划： 与CMU等机构合作，推进Zone Block Technologies的研究。 将研究成果应用到SEF项目中。 加强与社区的合作，共同推动存储技术的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Pushing the Limits of Ceph Performance through Software & Hardware Innova... - Tushar Gohad","slug":"Keynote_-_Pushing_the_Limits_of_Ceph_Performance_through_Software_Hardware_Innova..._-_Tushar_Gohad","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_Pushing_the_Limits_of_Ceph_Performance_through_Software_Hardware_Innova..._-_Tushar_Gohad/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_Pushing_the_Limits_of_Ceph_Performance_through_Software_Hardware_Innova..._-_Tushar_Gohad/","excerpt":"","text":"会议纪要 会议主题： Ceph 社区发展及英特尔贡献 会议时间： (未提供) 参会人员： Tushar (英特尔)，Ceph 社区成员 会议内容： 一、会议概述 Tushar 代表英特尔介绍了英特尔在 Ceph 社区的贡献和发展历程，重点阐述了英特尔在 Ceph 性能提升方面的努力以及与社区的合作成果。 二、英特尔在 Ceph 社区的贡献 长期贡献历史： 英特尔自 2014 年以来一直积极参与 Ceph 社区，早期主要关注可管理性和企业级功能，近年来则专注于性能提升。 性能提升： 英特尔是 BlueStore 的早期贡献者，并持续优化其通信路径和相关功能。此外，英特尔还参与了 Crimson OST 项目，并取得了显著进展。 客户端缓存： 英特尔正在开发持久双向缓存，并改进了 DMA 通信，以提升性能。 容器化支持： 英特尔是 Ceph Container 和 OpenStack Helm 项目的早期参与者，并继续贡献相关技术。 三、硬件与软件结合 英特尔通过硬件和软件创新，为 Ceph 性能提升做出了贡献： QLC SSD： QLC SSD 是成本优化的存储解决方案，适用于读密集型工作负载，可扩展至 30TB，实现 500PB 的存储能力。 高耐用性 SSD： 与标准 TLC SSD 相比，高耐用性 SSD 具有更高的耐用性，适用于高性能工作负载。 第二代 Z 系列处理器： 第二代 Z 系列处理器为 Ceph 提供了强大的计算能力。 持久内存： 持久内存可提升存储和内存之间的性能。 四、合作成果 英特尔与合作伙伴和客户合作，共同构建了基于 Ceph 的新工作负载架构，例如 OVH 与英特尔合作构建的基于 Ceph 的存储解决方案。 五、后续行动计划 英特尔将继续与 Ceph 社区合作，推动 Ceph 性能提升，并探索更多合作机会。 六、总结 英特尔在 Ceph 社区中发挥着重要作用，通过硬件和软件创新，为 Ceph 性能提升做出了贡献，并与社区共同推动 Ceph 的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: State of the Cephalopod - Sage Weil, Co-Creator, Chief Architect & Ceph Project Leader","slug":"Keynote_-_State_of_the_Cephalopod_-_Sage_Weil_Co-Creator_Chief_Architect_Ceph_Project_Leader","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_State_of_the_Cephalopod_-_Sage_Weil_Co-Creator_Chief_Architect_Ceph_Project_Leader/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_State_of_the_Cephalopod_-_Sage_Weil_Co-Creator_Chief_Architect_Ceph_Project_Leader/","excerpt":"","text":"会议纪要 会议主题： CephCon 2023 开幕式及Nautilus版本介绍 会议时间： 2023年（具体日期未提及） 会议地点： 巴塞罗那 参会人员： Ceph社区成员、赞助商、Linux Foundation代表等 会议内容： 一、会议开场 致谢： Sage（Red Hat Ceph项目负责人）首先感谢所有赞助商、Ceph基金会、Linux Foundation以及程序委员会成员对本次会议的支持。 Ceph基金会介绍： Sage介绍了Ceph基金会，该基金会于六个月前成立，旨在支持Ceph项目和社区。基金会拥有31个成员组织，包括许多赞助商、一般成员和关联成员。 CephCon历史回顾： Sage回顾了CephCon的历史，从2004年的OSD I会议到今天的CephCon，Ceph项目不断发展壮大。 会议反馈： Sage鼓励参会者提供对会议的反馈，包括喜欢什么、不喜欢什么，以及任何问题。 二、Ceph介绍 Ceph定义： Ceph是一个统一的存储系统，提供对象存储、块存储和分布式文件系统等功能。 Ceph特点： 开源： Ceph是开源软件，用户可以自由下载、使用和修改。 可靠性： Ceph通过复制和纠错技术，确保数据安全，无单点故障。 可扩展性： Ceph可以在线扩展或缩减，支持硬件升级和软件升级。 Ceph社区优先事项： 可用性和管理： 提高Ceph的易用性和管理性。 容器生态系统： 支持Ceph与Kubernetes集成。 多站点和混合云： 支持多站点和混合云部署。 性能： 提高Ceph的性能。 质量： 保证Ceph的质量和稳定性。 三、Nautilus版本介绍 Nautilus版本特点： 新的仪表盘： 提供监控、管理等功能，简化Ceph的使用和管理。 ** Orchestrator API**： 允许Ceph与部署工具和编排框架集成，实现自动化部署和管理。 Rook： 支持Ceph与Kubernetes集成。 Ceph容器项目： 提供Ceph容器镜像，简化Ceph的部署。 Rados Gateway： 支持多站点和混合云部署。 性能优化： 提高Ceph的性能。 Ceph性能优化： Blue Store： 优化Blue Store性能。 RocksDB： 更新RocksDB版本，提高性能。 Rados Gateway： 优化Rados Gateway性能。 Ceph性能测试集群： Officinalis集群： 新的测试集群，用于性能测试。 四、未来计划 Ceph性能优化： Project Crimson： 重写Ceph I/O路径，提高性能和效率。 Ceph社区优先事项： 质量： 保证Ceph的质量和稳定性。 可用性和管理： 提高Ceph的易用性和管理性。 容器生态系统： 支持Ceph与Kubernetes集成。 多站点和混合云： 支持多站点和混合云部署。 性能： 提高Ceph的性能。 五、结束语 Sage感谢参会者的到来，并欢迎他们参加CephCon 2023。 后续行动计划： 收集参会者对会议的反馈。 推进Ceph项目的开发。 支持Ceph社区的活动。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Supporting Swiss Academia with Ceph & OpenStack - Jens-Christian Fischer","slug":"Keynote_-_Supporting_Swiss_Academia_with_Ceph_OpenStack_-_Jens-Christian_Fischer","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_Supporting_Swiss_Academia_with_Ceph_OpenStack_-_Jens-Christian_Fischer/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_Supporting_Swiss_Academia_with_Ceph_OpenStack_-_Jens-Christian_Fischer/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 会议地点： [具体地点] 参会人员： [参会人员名单] 会议主题： SEF在学术领域的应用与实践 会议关键细节： 演讲者： 来自Swiss Academic and Research Network (Swisscom) 的研发人员，负责SEF（Ceph）的使用和推广。 演讲内容： 介绍了Swisscom作为国家研究教育网络的角色和职责，及其如何服务于学术机构和研究机构。 分享了Swisscom在构建和运营Ceph集群方面的经验，包括集群规模、存储容量、硬件升级等。 讨论了Swisscom如何解决Ceph集群中遇到的问题，例如硬件故障、软件故障和网络问题。 介绍了Swisscom如何利用Ceph提供各种存储服务，例如文件存储、对象存储和块存储。 分享了Swisscom在学术研究中的应用案例，例如南极洲探险数据存储和分析。 讨论的主要议题： Ceph集群的规模和性能： 演讲者分享了Swisscom运营的Ceph集群规模和性能数据，并介绍了集群的硬件配置和存储容量。 Ceph集群的稳定性： 演讲者强调了Ceph集群的稳定性，并分享了Swisscom如何解决集群中遇到的问题。 Ceph集群的应用： 演讲者介绍了Swisscom如何利用Ceph提供各种存储服务，并分享了Ceph在学术研究中的应用案例。 Ceph与其他存储系统的比较： 演讲者讨论了Ceph与其他存储系统的比较，并强调了Ceph的灵活性和可扩展性。 决定的事项： Swisscom将继续投资Ceph集群，并计划将虚拟机工作负载迁移到NVMe存储。 Swisscom将继续与学术机构和研究机构合作，推广Ceph在学术研究中的应用。 后续行动计划： Swisscom将与其他Ceph用户分享其经验和最佳实践。 Swisscom将参加Ceph社区活动，并与其他Ceph用户交流。 Swisscom将继续开发新的存储服务，以满足学术机构和研究机构的需求。 关键词： Ceph 分布式存储 学术研究 研究教育网络 瑞士 Swisscom OpenStack 欧洲网格倡议","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: The System that Matters - Tim Massey, Chief Executive Officer & Phil Straw, CTO","slug":"Keynote_-_The_System_that_Matters_-_Tim_Massey_Chief_Executive_Officer_Phil_Straw_CTO","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_The_System_that_Matters_-_Tim_Massey_Chief_Executive_Officer_Phil_Straw_CTO/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_The_System_that_Matters_-_Tim_Massey_Chief_Executive_Officer_Phil_Straw_CTO/","excerpt":"","text":"会议纪要 会议时间 （请在此处填写会议具体时间） 会议地点 巴塞罗那 与会人员 Tim Massie，SoftIron公司CEO Phil Strazdins，SoftIron公司技术专家 会议主持人及与会嘉宾 会议主题 SoftIron公司在Ceph社区中的角色、Ceph的快速发展和硬件加速在Ceph存储产品中的应用。 会议内容 Tim Massie发言摘要： SoftIron是一家专注于软件定义存储的公司，致力于推广Ceph存储技术。 SoftIron相信Ceph将成为存储领域的标准，并愿意将公司的发展押注在Ceph上。 Ceph作为一个开源项目，具备灵活性和可扩展性，这使得它能够快速发展和被广泛采用。 SoftIron致力于提供全面支持的Ceph存储解决方案，帮助用户轻松部署和使用Ceph。 为了加速Ceph的普及，SoftIron宣布在其存储产品中集成硬件加速功能。 Phil Strazdins发言摘要： SoftIron在Ceph社区中扮演着重要角色，致力于提供高性能、低功耗、易于使用的Ceph存储产品。 SoftIron采用了系统级方法来优化Ceph性能，包括硬件选择、驱动程序和软件优化。 硬件加速在Ceph中具有巨大潜力，尤其是在数据保护和恢复方面。 SoftIron正在开发基于硬件的加速器，以加速Ceph中的擦除编码和恢复操作。 通过硬件加速，Ceph可以实现更高的性能、更低的功耗和更优的成本效益。 决定事项 SoftIron将继续致力于Ceph社区的发展，推动Ceph技术的普及和应用。 SoftIron将在其存储产品中集成硬件加速功能，以提升Ceph的性能和效率。 SoftIron将与其他合作伙伴合作，共同推动Ceph技术的发展和应用。 后续行动计划 SoftIron将继续优化其Ceph存储产品，提升性能和用户体验。 SoftIron将与Ceph社区保持紧密合作，共同推动Ceph技术的发展。 SoftIron将参加Ceph相关会议和活动，分享其经验和成果。 关键词 Ceph 软件定义存储 硬件加速 擦除编码 数据保护 性能 成本效益","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: Town Hall - Panel","slug":"Keynote_-_Town_Hall_-_Panel","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_Town_Hall_-_Panel/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_Town_Hall_-_Panel/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： 各组件负责人、技术领导 会议主题： Ceph社区现状、发展计划、问题解答 会议内容： 一、会议开场 会议主持人介绍了参会人员，并欢迎提问。 每位参会人员进行了自我介绍，包括姓名、工作内容和常用的编辑器。 二、如何开始贡献 讨论了新用户如何开始为Ceph贡献代码。 建议从回溯工作开始，熟悉软件的代码库。 提到Ceph社区正在改进入门页面，提供更多帮助信息。 强调Ceph的文档需要更新，鼓励大家参与文档贡献。 提到Ceph的新功能管理器，使用Python编写，降低了新功能的开发门槛。 三、文档贡献 讨论了Ceph文档的更新和维护。 指出文档信息架构需要更新，以适应当前需求。 鼓励大家通过GitHub链接直接修复文档中的错误。 强调Ceph社区需要更多文档贡献者。 四、Ceph功能与性能 讨论了Ceph的深度去重功能。 解释了去重算法的挑战和实现方式。 比较了不同客户端的性能差异。 讨论了读取所有副本的OSD的性能问题。 提到Ceph与OpenStack Cinder的集成。 讨论了RocksDB和LevelDB的问题。 讨论了Ceph与OpenStack Swift的对比。 五、Ceph社区协作 讨论了Ceph社区的协作方式。 提到使用IRC、邮件列表和GitHub进行沟通。 强调Ceph社区欢迎更多贡献者。 六、Ceph发展路线图 讨论了Ceph的发展路线图。 提到可以通过Ceph Tracker和Trello板跟踪Ceph的开发进度。 每位组件负责人介绍了自己团队的工作重点和未来计划。 七、会议总结 感谢参会人员的提问和贡献。 鼓励大家继续关注Ceph社区，并积极参与贡献。 后续行动计划： Ceph社区将继续改进入门页面和文档。 鼓励更多用户参与Ceph文档的贡献。 Ceph社区将继续关注性能和功能改进。 Ceph社区将继续加强协作，共同推动Ceph的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynote: What's Planned for Ceph Octopus - Sage Weil, Co-Creator, Chief Architect Ceph","slug":"Keynote_-_What_s_Planned_for_Ceph_Octopus_-_Sage_Weil_Co-Creator_Chief_Architect_Ceph","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynote_-_What_s_Planned_for_Ceph_Octopus_-_Sage_Weil_Co-Creator_Chief_Architect_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynote_-_What_s_Planned_for_Ceph_Octopus_-_Sage_Weil_Co-Creator_Chief_Architect_Ceph/","excerpt":"","text":"会议纪要 会议时间 [请填写具体日期] 会议地点 [请填写会议地点] 与会人员 [请填写与会人员名单] 会议主题 Ceph 项目未来发展方向及社区参与方式 会议内容 一、Ceph Octopus 版本重点 易用性提升： 改进 Orchestrator API，增强集群与 Rook 或裸金属编排工具的交互能力。 通过 CLI 和仪表板提供端到端 GUI 体验，简化操作流程。 自动化升级过程，提高升级效率。 质量提升： 优化 Nautilus 和 Telemetry 功能，提供更全面的监控和故障报告。 加强文档质量，提升用户体验。 完善测试套件，确保代码质量。 性能优化： 改进 BlueStore 性能，包括 RocksDB 的优化和 T-RocksDB 的引入。 异步化创建和删除操作，提升性能。 多站点、多集群支持： 优化 GW 多站点功能，包括桶粒度控制、透传存储、双向复制等。 探索 SouthFS 的更多功能，如灾难恢复和双向复制。 生态系统建设： 加强与 Kubernetes、OpenStack 等生态系统的集成。 关注大数据、机器学习等新兴领域。 二、社区参与方式 贡献代码：通过 GitHub 提交 pull request，参与代码审查。 提交 bug：在 Ceph 用户邮件列表或 GitHub 上提交 bug。 完善文档：参与 Ceph 文档的编写和修订。 参与会议：加入 Ceph 社区会议，交流经验。 组织活动：参与 Ceph 社区活动，如 CephDay。 决定事项 Ceph 项目将继续关注易用性、质量、性能、多站点/多集群支持以及生态系统建设等方面。 鼓励社区成员积极参与 Ceph 项目的开发、测试和文档编写。 后续行动计划 Ceph 项目团队将继续推进 Octopus 版本的开发工作。 社区成员可以关注 Ceph 项目邮件列表和 GitHub，了解项目进展。 Ceph 项目团队将定期举办线上和线下活动，促进社区交流。 其他事项 [请填写其他需要记录的事项]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Keynotes: Supermicro® SuperStorage Systems Based on New Intel® Xeon® Scalable Pro... - David Ramirez","slug":"Keynotes_-_Supermicro_SuperStorage_Systems_Based_on_New_Intel_Xeon_Scalable_Pro..._-_David_Ramirez","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Keynotes_-_Supermicro_SuperStorage_Systems_Based_on_New_Intel_Xeon_Scalable_Pro..._-_David_Ramirez/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Keynotes_-_Supermicro_SuperStorage_Systems_Based_on_New_Intel_Xeon_Scalable_Pro..._-_David_Ramirez/","excerpt":"","text":"会议纪要： 会议时间： 未知 会议主题： 新技术介绍与讨论 参会人员： 未知 会议内容： 一、会议关键细节 新技术介绍： 基于NVMe的新一代数据中心持久内存（DC persistent memory）。 新一代Intel SK级CPU，性能提升55%，且价格与上一代SK Lake相同。 新存储技术，性能提升，价格更优。 服务器解决方案： 标准密度存储服务器，支持3.5英寸和2.5英寸硬盘，混合解决方案可包括NVMe。 特殊服务器，可容纳多达60个硬盘驱动器，支持多种存储类型，包括NVMe和DC persistent memory。 网络支持，推荐25Gbps和100Gbps网络，以支持高性能和低延迟。 硬件支持： 支持Intel Xeon Scalable CPU，最高支持205个核心。 支持24个DDR4内存插槽，最高支持6TB RAM。 支持8TB NVMe SSD和48TB DC persistent memory。 二、讨论的主要议题 新一代存储技术及其性能优势。 服务器解决方案的适用场景和优势。 网络和硬件支持对存储性能的影响。 三、决定的事项 推广新一代存储技术和服务器解决方案。 优化网络和硬件配置，提升存储性能。 研究DC persistent memory的应用场景。 四、后续行动计划 继续关注新技术发展，及时更新产品。 与合作伙伴共同推广存储解决方案。 深入研究DC persistent memory的应用，探索新的应用场景。 五、会议总结 本次会议介绍了新一代存储技术和服务器解决方案，讨论了相关议题，并制定了后续行动计划。相信通过不断的技术创新和产品优化，我们能够为客户提供更优质、更高效的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Learn Ceph — For Fun, For Real, For Free! - Florian Haas, City Network","slug":"Learn_Ceph_For_Fun_For_Real_For_Free_-_Florian_Haas_City_Network","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Learn_Ceph_For_Fun_For_Real_For_Free_-_Florian_Haas_City_Network/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Learn_Ceph_For_Fun_For_Real_For_Free_-_Florian_Haas_City_Network/","excerpt":"","text":"会议纪要 会议主题： Ceph 云学院课程更新及用户反馈征集 会议时间： [具体时间] 参会人员： [参会人员名单] 会议内容： 一、会议背景 由 Flavian 主讲的会议主要介绍了 Ceph 云学院（City Cloud Academy）的更新情况，特别是针对 Ceph 分布式存储基础课程（CC 212）的改进和新增内容。 二、讨论的主要议题 传统培训模式的局限性： Flavian 指出，传统的面对面培训方式存在成本高、效率低、难以规模化等问题。 在线学习的不足： Flavian 认为，在线学习往往依赖于视频教程和文档，缺乏互动性和实践性，不利于学习者掌握复杂技术。 Ceph 云学院的优势： Flavian 介绍了 Ceph 云学院基于 Open EDX 平台，提供沉浸式、互动性强的实验室环境，并允许学习者与同行交流，具有快速创新和开放的特点。 课程更新： Flavian 详细介绍了 CC 212 课程的新增内容，包括： 更新至 Nautilus 版本 使用 CephFS 卷而非 Ceph Disk 涵盖更多 Ceph 技术细节，如 fuse、内核文件系统驱动等 提供实用的仪表盘操作内容 涵盖 Eurasia 代码库和配置文件 更新至最新版本 三、决定的事项 Ceph 云学院将继续免费提供 CC 212 课程，每月开放 20 个免费名额。 欢迎用户反馈课程内容，以便持续改进课程质量。 四、后续行动计划 Ceph 云学院团队将根据用户反馈，不断完善课程内容。 Ceph 云学院将积极推广课程，扩大用户群体。 五、其他事项 用户可以通过访问 City Cloud Academy 网站查看课程详情。 用户可以通过 Twitter 关注 Ceph 云学院，获取最新课程信息。 会议总结： 本次会议介绍了 Ceph 云学院的课程更新情况，并强调了用户反馈对课程改进的重要性。Ceph 云学院将继续致力于提供高质量、实用的 Ceph 技术培训，帮助用户更好地掌握 Ceph 技术。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Making Ceph Fast in the Face of Failure - Neha Ojha, Red Hat","slug":"Making_Ceph_Fast_in_the_Face_of_Failure_-_Neha_Ojha_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Making_Ceph_Fast_in_the_Face_of_Failure_-_Neha_Ojha_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Making_Ceph_Fast_in_the_Face_of_Failure_-_Neha_Ojha_Red_Hat/","excerpt":"","text":"会议纪要： 会议主题： Ceph 分布式存储在故障处理和性能优化方面的进展 参会人员： Neha Mucha（Ceph 技术负责人），Red Hat 高级软件工程师 会议内容： 一、故障处理机制 日志恢复： 通过分析 OSD 的 PG 日志进行数据恢复，速度快，但可能因日志过长导致内存溢出。 填充恢复： 通过比较磁盘上的对象状态进行数据恢复，速度慢，但不会出现日志溢出问题。 二、Ceph 故障处理优化 早期版本问题： 在 Ceph 早期版本中，故障恢复和填充操作会影响客户端 I/O，导致性能下降。 Infernalis 版本改进： 默认设置优化了 OSD 最大填充和 OST 恢复最大活跃参数，提高了性能。 Luminous 版本改进： 引入 OST 恢复扫描选项，通过控制恢复速率来平衡客户端 I/O 和恢复操作。 Mimic 版本改进： 引入异步恢复，通过推迟对非活跃 OSD 的恢复操作来提高性能。 Nautilus 版本改进： 实现了 PG 日志长度硬限制，防止日志溢出；引入强制恢复和强制填充选项，在池级别进行操作；改进了异步恢复的计算方法。 三、未来工作计划 部分恢复： 仅复制修改过的对象部分，提高效率。 擦除编码池恢复： 在擦除编码池中进行更小的数据恢复。 自适应恢复： 根据客户端 I/O 量动态调整恢复速率。 全功能 QoS 项目： 提高资源分配效率，保证关键数据优先恢复。 四、总结 Ceph 分布式存储在故障处理和性能优化方面取得了显著进展，通过不断改进和优化，Ceph 的可靠性和性能得到了显著提升。 关键词： Ceph、分布式存储、故障处理、性能优化、日志恢复、填充恢复、异步恢复、QoS、自适应恢复","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"MeerKAT Astronomy Data Store Deployment and Operations - Martin Slabber, SARAO","slug":"MeerKAT_Astronomy_Data_Store_Deployment_and_Operations_-_Martin_Slabber_SARAO","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/MeerKAT_Astronomy_Data_Store_Deployment_and_Operations_-_Martin_Slabber_SARAO/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/MeerKAT_Astronomy_Data_Store_Deployment_and_Operations_-_Martin_Slabber_SARAO/","excerpt":"","text":"会议纪要 会议时间： （请在此处填写会议具体时间） 会议地点： （请在此处填写会议具体地点） 参会人员： Martin（来自南非的Answer Africa公司） Ceph社区其他成员 会议内容： 1. 演讲者介绍及背景 - 演讲者Martin来自南非的Answer Africa公司，该公司正在建设一个名为MeerKAT的射电望远镜。 - Martin将分享他们如何使用Ceph存储技术，并回顾天文学数据存储的历史。 2. 天文学数据存储历史回顾 - 从古代的洞穴壁画到现代的数字存储，Martin回顾了天文学数据存储的历史。 - 重点介绍了从石板到光栅、从胶片到磁带等不同存储介质的发展历程。 3. Meerkat望远镜及Ceph存储应用 - MeerKAT望远镜位于南非的沙漠地区，具有低人口密度和低干扰的特点。 - 该望远镜由64个碟形天线组成，用于接收和记录天文数据。 - Ceph存储集群用于存储天文数据，包括临时数据和最终结果。 4. Ceph存储集群架构 - Martin介绍了他们使用的Ceph存储集群架构，包括存储节点、计算节点和网络。 - 他们使用SSD和硬盘驱动器混合存储，以满足不同的性能和容量需求。 - 他们还使用自定义软件来处理数据传输和科学数据处理。 5. 硬件选择与挑战 - 由于预算限制，他们决定自行开发存储节点硬件。 - 他们选择了低射频干扰的硬件，以满足望远镜对环境的要求。 - 在硬件开发过程中遇到了一些挑战，如控制器过时、内存不足等。 6. 自动化与监控 - 他们使用Ansible和Mass等工具来自动化部署和管理Ceph存储集群。 - 他们使用Prometheus、Grafana和Alertmanager等工具来监控集群状态和性能。 7. 总结与展望 - Martin感谢Ceph社区的帮助和支持，并表示将继续使用Ceph存储技术。 - 他们计划在南非开展Ceph社区活动，促进Ceph技术在南非的应用。 行动计划： （请在此处填写后续行动计划，例如：） 完善Ceph存储集群监控和自动化工具。 探索Ceph在更多领域的应用。 参与Ceph社区活动，分享经验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Messenger V2: The New Ceph Wire Protocol - Ricardo Dias, SUSE Linux","slug":"Messenger_V2_-_The_New_Ceph_Wire_Protocol_-_Ricardo_Dias_SUSE_Linux","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Messenger_V2_-_The_New_Ceph_Wire_Protocol_-_Ricardo_Dias_SUSE_Linux/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Messenger_V2_-_The_New_Ceph_Wire_Protocol_-_Ricardo_Dias_SUSE_Linux/","excerpt":"","text":"会议纪要 会议主题： 新SEF信使协议（Messenger v2）介绍及配置 参会人员： Ricardus（Sousa公司高级软件工程师） 会议内容： 1. SEF信使组件简介 SEF信使是一个通信库，负责集群内部各个组件之间的通信。 该组件存在于服务器守护进程（如Mon、OSD等）和客户端库（如librgw等）中。 信使抽象了物理通信技术，工作在传输层之上，确保消息可靠交付，并处理连接故障。 2. 新协议的需求 Messenger v1协议存在扩展性差、安全性不足等问题。 新协议（Messenger v2）旨在解决这些问题，并支持以下特性： 可扩展性：允许在不破坏现有版本的情况下扩展协议。 多种认证方案：支持多种认证方式，包括无认证、suffix认证等。 加密：支持端到端加密，保证数据安全。 结构化消息：消息结构清晰，易于维护。 3. Messenger v2协议工作原理 协议分为四个阶段：交换信息、认证、会话建立和消息交换。 交换信息阶段，客户端和服务器交换支持的特性和所需功能。 认证阶段，客户端和服务器协商认证方式和连接模式。 会话建立阶段，客户端和服务器交换身份信息，并生成会话cookie。 消息交换阶段，客户端和服务器可以发送和接收消息。 4. 加密模式 如果协议协商使用安全模式，则所有消息将进行加密和签名。 使用AES 128 GCM算法进行加密，保证数据的机密性和完整性。 5. 配置和管理 需要配置地址向量，指定每个守护进程监听的端口号。 新增配置选项，包括messenger1和messenger2，用于控制监听协议版本。 默认启用messenger v2，可以通过配置文件禁用。 6. 升级 从Luminous或Mimic版本升级到Nautilus版本时，需要启用messenger v2。 使用safe mon messenger2命令启用messenger v2。 7. 问题解答 使用CRC32进行完整性检查。 加密模式对性能有一定影响，具体影响待测试。 后续行动计划： 完成性能测试，评估加密模式对性能的影响。 撰写文档，详细介绍新协议的配置和管理方法。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Monitoring Ceph with Prometheus - Jan Fajerski, SUSE","slug":"Monitoring_Ceph_with_Prometheus_-_Jan_Fajerski_SUSE","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Monitoring_Ceph_with_Prometheus_-_Jan_Fajerski_SUSE/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Monitoring_Ceph_with_Prometheus_-_Jan_Fajerski_SUSE/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员] 会议主题： Prometheus 监控工具介绍与Ceph应用 会议内容： Prometheus 简介： Prometheus 由SoundCloud于2012年开发，受Google内部项目Barkman启发。 Prometheus 是CNCF会员项目，广泛用于高维数值数据监控，不适用于文本指标分析。 Prometheus 基于拉取模式，从端点拉取指标，具有可扩展性。 Prometheus 包含强大的查询语言PromQL，具有丰富的功能。 Prometheus 的关键组件包括： Exporter： 暴露指标的组件，如Ceph的manager模块。 Alert Manager： 负责处理警报，支持集群。 Prometheus 配置： Prometheus 使用YAML文件进行配置，包括Scrape配置、Service Discovery等。 Service Discovery支持静态配置、Kubernetes、文件SD等。 监控应具备弹性和可扩展性，可使用多个Prometheus实例进行水平扩展。 Prometheus 查询语言 (PromQL)： PromQL 是Prometheus的查询语言，支持标签匹配、算术运算、聚合操作等。 PromQL 具有以下类型： 瞬时向量： 每个指标在特定时间戳的值。 范围向量： 每个指标在时间范围内的值。 示例查询： 计算文件系统使用率。 计算指标每秒速率。 联合不同Exporter的指标。 使用预测线性进行趋势分析。 Prometheus 警报： Prometheus 警报使用PromQL表达式，支持条件、持续时间、标签等。 Prometheus 提供了默认的警报和仪表板，用户可以根据需求进行定制。 行动计划： [请填写行动计划，例如：] 推广Prometheus在Ceph集群中的应用。 提供Prometheus配置和查询语言的文档。 开发Ceph的Prometheus Exporter。 收集用户反馈，改进Prometheus功能。 会议总结： 本次会议介绍了Prometheus监控工具及其在Ceph集群中的应用。Prometheus具有强大的功能和易用性，是Ceph集群监控的理想选择。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Object WORM Feature in Ceph Rados Gateway - Zhang Shaowen","slug":"Object_WORM_Feature_in_Ceph_Rados_Gateway_-_Zhang_Shaowen","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Object_WORM_Feature_in_Ceph_Rados_Gateway_-_Zhang_Shaowen/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Object_WORM_Feature_in_Ceph_Rados_Gateway_-_Zhang_Shaowen/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： 介绍和讨论Ceph分布式存储系统中的数据持久性功能——Warm Storage（热存储） 参会人员： John Shaw（中国移动软件部门），其他与会人员 会议内容： 1. 热存储概述 John Shaw介绍了热存储的概念，即不可变存储，数据一旦写入，就不能被修改或删除。 热存储的两种类型：物理热存储（如CD、DVD）和逻辑热存储（软件实现）。 热存储的重要性：随着信息爆炸和信息安全需求的提高，热存储在医疗、金融等领域发挥重要作用。 2. S3对象锁定 S3对象锁定功能可以通过Ejector Locker实现，防止对象被删除或覆盖。 对象锁定可以设置保留期限，确保数据在指定时间内不被修改。 S3提供了两种保护类型：保留期限和法务持有者。 保留期限保护对象版本在一定时间内不被修改，法务持有者则允许在保留期限到期后删除对象。 3. Ceph中的热存储实现 Ceph分布式存储系统已经实现了热存储功能。 Ceph添加了六个新的API，用于设置默认保留期限、对象锁定和法务持有者。 Ceph还提供了对象锁定配置和法务持有者配置。 4. 后续行动计划 添加测试用例，确保热存储功能正常工作。 改进支持对象锁定的策略。 5. 总结 热存储是Ceph分布式存储系统的一项重要功能，可以提高数据的安全性和可靠性。 Ceph的热存储实现已经取得了进展，但仍需进一步完善。 关键词： 热存储（Warm Storage）、不可变存储、S3对象锁定、保留期限、法务持有者、Ceph分布式存储","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Object Bucket Provisioning in Rook-Ceph - Jonathan Cope & Jeff Vance, Red Hat","slug":"Object_Bucket_Provisioning_in_Rook-Ceph_-_Jonathan_Cope_Jeff_Vance_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Object_Bucket_Provisioning_in_Rook-Ceph_-_Jonathan_Cope_Jeff_Vance_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Object_Bucket_Provisioning_in_Rook-Ceph_-_Jonathan_Cope_Jeff_Vance_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： John Cope（红帽公司CTO办公室），Jeff（红帽公司CTO办公室），以及其他参会人员 会议主题： Ceph存储桶提供程序（Brooks F bucket provisioner）及其API 会议内容： 一、会议背景 John Cope和Jeff共同开发了Brooks F bucket provisioner和bucket provisioner API。 该API是一个库，用于实现存储桶的提供程序，并处理所有控制循环，使对象存储提供商的开发更加容易。 他们将讨论Brooks F bucket provisioner和bucket provisioner API，并展示一个演示。 二、关键议题 Kubernetes和Rook： Kubernetes是一个开源容器编排平台，具有存储抽象层。 Rook是一个用于在Kubernetes上部署、管理和扩展存储解决方案的开源项目。 目前，Rook支持多种存储类型，但无法提供Ceph GW存储桶。 Brooks F bucket provisioner： 该提供程序旨在补充Rook的存储功能，并提供Ceph GW存储桶的提供程序。 它使用CRDs扩展Kubernetes，以识别新的资源。 该提供程序是一个库，而不是操作员，因此可以轻松集成到应用程序中。 它支持动态提供程序，并允许使用现有或新存储桶。 bucket provisioner API： 该API是一个库，用于实现存储桶的提供程序。 它是可扩展的，并支持多种对象存储。 它简化了存储桶的提供程序开发，并使应用程序的可移植性更好。 三、决定事项 将在演示中展示Brooks F bucket provisioner和bucket provisioner API。 将继续开发AWS S3、Azure、Google Cloud Storage等提供程序。 将添加更多功能，例如指标和擦除功能。 四、后续行动计划 完成演示。 继续开发提供程序。 修复问题和请求。 添加新功能。 五、其他讨论 会议还讨论了以下问题： 如何监控使用bucket provisioner的存储桶。 如何限制对存储桶的访问。 如何设置存储桶的配额。 六、总结 Brooks F bucket provisioner和bucket provisioner API是简化Ceph GW存储桶提供程序开发的重要工具。它们将使应用程序的可移植性更好，并使存储管理更加容易。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimize librbd for Lower CPU Cost and Higher Scalability - Li Wang, DiDi","slug":"Optimize_librbd_for_Lower_CPU_Cost_and_Higher_Scalability_-_Li_Wang_DiDi","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Optimize_librbd_for_Lower_CPU_Cost_and_Higher_Scalability_-_Li_Wang_DiDi/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Optimize_librbd_for_Lower_CPU_Cost_and_Higher_Scalability_-_Li_Wang_DiDi/","excerpt":"","text":"会议纪要 会议时间：[请填写会议时间] 会议地点：[请填写会议地点] 参会人员：[请填写参会人员名单] 主持人：[请填写主持人姓名] 一、会议内容 Liberty优化工作分享 主持人来自PD云存储团队，首先介绍了Liberty优化工作，主要包括以下内容： Liberty架构概述：Liberty是一种基于Ceph的分布式存储解决方案，适用于虚拟化场景，其数据流如图所示。 IBD LPS优化：针对IBD LPS在随机写测试中不随集群规模扩展的问题，提出了解决方案，包括并行化闪存工作、优化单线程设计为多线程设计等。 客户端镜像缓存：利用Ceph的快照功能，将虚拟机系统盘的只读数据存储在Ceph中，以节省存储空间。通过优化镜像缓存机制，提高虚拟机启动速度。 写操作CPU开销优化：针对Liberty导致的CPU使用率过高问题，提出优化方案，包括升级Ceph版本、使用新的API调用方式等。 数据恢复优化：介绍数据恢复过程中的优化策略，包括使用Rebalance优化请求逻辑、回调机制等。 社区合作与经验分享 主持人分享了与社区合作的经验和遇到的问题： Liberty延迟问题：Liberty在SSD和NVMe存储上的延迟较高，可能影响数据库等对延迟敏感的应用。 硬件利用率问题：当平均负载超过60%时，可能出现延迟和缓慢请求。 价格与性能平衡：社区在硬件优化方面投入较多，但客户更关注价格和性能平衡。 CPU使用率问题：Liberty导致CPU使用率过高，限制了SSD的性能。 二、会议决定 与社区合作，共同优化Liberty性能，特别是延迟、硬件利用率和CPU使用率等问题。 探索新的优化方案，提高Liberty在虚拟化场景下的性能和稳定性。 三、后续行动计划 优化Liberty代码，提高性能和稳定性。 与社区合作，共同解决Liberty在虚拟化场景下的性能瓶颈。 收集用户反馈，持续改进Liberty产品。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimizing Ceph Object Storage for Production in Multisite Clouds - Michael Hackett & Vikhyat Umrao","slug":"Optimizing_Ceph_Object_Storage_for_Production_in_Multisite_Clouds_-_Michael_Hackett_Vikhyat_Umrao","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Optimizing_Ceph_Object_Storage_for_Production_in_Multisite_Clouds_-_Michael_Hackett_Vikhyat_Umrao/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Optimizing_Ceph_Object_Storage_for_Production_in_Multisite_Clouds_-_Michael_Hackett_Vikhyat_Umrao/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Mike Hackett、Vicky Adam Rao（Red Hat 原理软件工程师） 会议主题： 优化多站点云中Ceph对象存储性能 会议内容： 一、Ceph对象存储概述 Ceph对象存储（Rados Gateway）提供RESTful API和Swift API，支持用户管理、配额等功能。 Ceph对象存储支持多站点部署，可与其他云平台集成。 Ceph对象存储支持多种性能配置，可根据应用需求选择合适的存储介质。 二、硬件选择 选择硬件时，需要考虑以下因素： 使用场景： 流媒体、图像存储、归档等。 工作负载类型： IOPS优化、容量优化、吞吐量优化。 预期增长： 硬盘数量、服务器数量、机架数量等。 节点密度： 硬盘数量、内存、CPU等。 硬件选择应考虑性能和可靠性，避免因硬件问题导致性能瓶颈。 三、网络配置 网络配置对Ceph性能至关重要，需要确保以下方面： 网络带宽： 确保网络带宽满足需求。 网络延迟： 确保网络延迟在可接受范围内。 网络冗余： 采用冗余网络架构，避免单点故障。 四、存储驱动器 选择合适的存储驱动器，例如： SSD和NVMe： 用于IOPS优化。 HDD和SSD： 用于容量优化。 选择驱动器时，需要考虑性能、容量和成本等因素。 五、集群调优 集群调优包括以下方面： 集群映射大小： 设置合理的集群映射大小，避免性能瓶颈。 擦除： 定期进行擦除，确保数据一致性。 回填： 调整回填设置，确保性能和可靠性。 CRUSH规则： 设置合理的CRUSH规则，优化数据分布。 六、多站点配置 多站点配置包括以下步骤： 创建全局领域。 创建区域组。 创建区域。 创建区域组。 创建用户。 配置节点。 同步配置。 多站点配置支持数据同步、容灾等功能。 七、常见问题及解决方案 动态分片不支持： 建议在部署集群前规划好桶大小。 数据同步缓慢： 检查网络带宽、延迟和冗余配置。 数据损坏： 定期进行数据检查和修复。 八、后续行动计划 完善多站点配置文档。 开发多站点配置工具。 优化CRUSH规则。 支持更多硬件平台。 总结： 本次会议介绍了Ceph对象存储的多站点配置和性能优化方法，并讨论了常见问题和解决方案。希望本次会议内容能够帮助大家更好地使用Ceph对象存储。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Per OSD Recovery Bandwidth Control Based on dmClock - Xie Xingguo & Yan Jun, ZTE Corporation","slug":"Per_OSD_Recovery_Bandwidth_Control_Based_on_dmClock_-_Xie_Xingguo_Yan_Jun_ZTE_Corporation","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Per_OSD_Recovery_Bandwidth_Control_Based_on_dmClock_-_Xie_Xingguo_Yan_Jun_ZTE_Corporation/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Per_OSD_Recovery_Bandwidth_Control_Based_on_dmClock_-_Xie_Xingguo_Yan_Jun_ZTE_Corporation/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： City Corporation 参会人员： Hinging, She Single 会议主题： 基于TM Clock的云附加存储方法设计、实现和测试 会议内容： 一、背景及问题 背景： 存储去重对客户端性能有较大影响，但去重又是提高数据可靠性的必要手段。 问题： 如何在保证数据可靠性的同时，尽量减少去重对客户端性能的影响。 二、解决方案 主要思路： 通过控制去重操作的带宽，平衡去重与客户端性能之间的关系。 核心方法： 使用DM Clock进行带宽控制。 根据客户端性能要求，将去重操作分为三个级别：低、中、高。 根据负载状态，动态调整去重级别。 三、DM Clock 原理： 基于DM Clock进行带宽控制，类似于计算带宽预留。 实现： DM Clock类和DM Clock客户端已集成到Ceph中。 基于DM Clock带宽计算公式，确定客户端目标带宽。 考虑其他服务完成的增量数据，进行带宽分配。 四、去重操作实现 原OpIE类和DM Clock客户端： OpIE类被分为文件类型、去重、scrub和快照。 每个类型都有自己的QS参数，并使用多队列进行服务。 改进： 引入新的DM Clock OpIE类，用于接收其他OSD发送的计数。 添加新的OpIE类型和Visual类，用于从其他OSD推送OpIE。 设置目标带宽，实现去重操作的带宽控制。 五、负载状态与去重级别 负载状态： 根据OSD的负载状态，将其分为四个级别：活跃、去重、恢复、重建。 去重级别： 根据负载状态，将去重操作分为三个级别：低、中、高。 六、集群工作模式 客户端优先级模式： 优先保证客户端性能，限制去重操作带宽。 去重优先级模式： 优先完成去重操作，可能影响客户端性能。 自适应模式： 根据负载状态，动态调整去重级别。 七、测试结果 测试环境：使用Ceph集群进行测试。 测试结果： 在去重操作期间，客户端性能保持在10,000 IOPS左右。 去重操作完成时间为30分钟。 与其他模式相比，自适应模式在保证数据可靠性的同时，对客户端性能影响最小。 八、后续行动计划 进一步优化DM Clock算法。 优化自适应模式，提高其性能。 在更多场景下进行测试，验证方案的有效性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Practices of Ceph Object Storage in Public Cloud Services - Yu Liyang, China Mobile","slug":"Practices_of_Ceph_Object_Storage_in_Public_Cloud_Services_-_Yu_Liyang_China_Mobile","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Practices_of_Ceph_Object_Storage_in_Public_Cloud_Services_-_Yu_Liyang_China_Mobile/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Practices_of_Ceph_Object_Storage_in_Public_Cloud_Services_-_Yu_Liyang_China_Mobile/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： Carolyn、Chana Baba、团队其他成员 会议主题： 公共云平台建设与优化讨论 会议内容： 一、公共云平台现状 平台规模： 目前云平台已支持政府、企业及内部客户，用户数量不断增加，位于北京、Cointreau和Enchantra，总容量预计超过15PB。 网络架构： 采用高速光纤网络，使用Rackware进行用户和数据管理，降低云存储的延迟。 存储特性： 用户可比较不同产品，根据需求选择合适的存储方案。目前开发了部分S3特性，如数据包、通知、日志记录和存储类，支持数据在不同存储类之间迁移。 二、主要议题 集群扩展问题： 由于用户上传文件过多，导致资源消耗过快，需要扩展集群。但添加新端口会引发数据重平衡，影响用户体验。 W模块更新： 云集群更新时，需要对W模块进行修改，但W模块的STI数量庞大，更新过程耗时较长。 性能压力： 生产环境中，主节点的并发请求量超过一万，导致处理速度缓慢，修改元数据时延迟较大。 三、决策事项 集群扩展： 考虑采用其他方案解决集群扩展问题，如增加服务器、优化资源分配等。 W模块优化： 优化W模块的更新流程，提高效率。 性能优化： 分析主节点性能瓶颈，进行针对性优化。 四、后续行动计划 技术团队针对集群扩展问题进行调研，提出解决方案。 技术团队优化W模块更新流程，提高效率。 性能团队分析主节点性能瓶颈，并提出优化方案。 五、其他事项 保持与用户的沟通，了解他们的需求和反馈。 定期对云平台进行性能测试，确保平台稳定运行。 关键词： 公共云平台、集群扩展、W模块、性能优化、S3特性、元数据","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Practices of Using NFS Over RGW - Enming Zhang, UMCloud","slug":"Practices_of_Using_NFS_Over_RGW_-_Enming_Zhang_UMCloud","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Practices_of_Using_NFS_Over_RGW_-_Enming_Zhang_UMCloud/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Practices_of_Using_NFS_Over_RGW_-_Enming_Zhang_UMCloud/","excerpt":"","text":"会议纪要 会议时间：[请填写会议时间] 会议地点：[请填写会议地点] 参会人员：[请填写参会人员名单] 会议主题：使用FS/RGW的实践与问题探讨 一、会议关键细节 会议主持人：Ming Jong 讨论主题：FS/RGW在客户生产环境中的应用实践及遇到的问题 主要议题：FS/RGW中NFS返回的已删除数据无法进行垃圾回收的问题 二、讨论的主要议题 问题背景：在测试环境中，通过FS写入文件并执行Rados TF，发现NFS返回的已删除数据无法被垃圾回收。 问题分析： 通过日志分析，发现GC处理过程中GC对象映射可能会被更新多次。 由于请求ID在初始化后不再改变，导致两个进程可能获得相同的标签，从而引发问题。 解决方案： 在每次写入文件时，获取新的请求ID，生成对象标签，确保标签的唯一性。 目前已通过MITRE的pro请求修复了此问题。 三、决定的事项 将修复方案应用到实际生产环境中，解决NFS返回的已删除数据无法进行垃圾回收的问题。 对FS/RGW的使用场景进行分析，为后续推广提供参考。 四、后续行动计划 对FS/RGW的使用场景进行深入研究，总结出更全面的适用场景，为用户提供更精准的指导。 针对其他FS/RGW相关问题，继续跟进并解决。 定期组织技术分享，提高团队成员对FS/RGW的了解和掌握程度。 五、会议总结 本次会议针对FS/RGW在客户生产环境中的应用实践及遇到的问题进行了深入探讨，并提出了相应的解决方案。会议明确了后续行动计划，为FS/RGW的推广和应用奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RADOS Object Class Development in C++ Lua - Noah Watkins, Red Hat","slug":"RADOS_Object_Class_Development_in_C++_Lua_-_Noah_Watkins_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/RADOS_Object_Class_Development_in_C++_Lua_-_Noah_Watkins_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/RADOS_Object_Class_Development_in_C++_Lua_-_Noah_Watkins_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议具体地点] 参会人员： [请填写参会人员名单] 会议主持人： Noah Watkins 会议主题： 基于 Ceph 的扩展功能与应用 会议内容： 1. 介绍与背景 Noah Watkins 介绍了自己作为 Red Hat 工程师，主要工作在 Rook 集成领域，今天将分享扩展应用程序功能的方法。 使用 Stuff 架构图展示了客户端通过 API 访问集群的流程，并重点介绍了 RBD（块设备功能）和 RBD LS（列出 RBD 管理的镜像）。 2. RBD 的工作原理 讨论了 RBD LS 如何工作，并指出 RBD LS 列出由 Stuff 管理的镜像，但未讨论数据库的安装。 解释了 Ceph 将数据存储在对象中，并通过应用程序特定接口访问这些对象，例如 RBD 和 RGW。 强调了使用对象类（object classes）来扩展接口，即动态地将代码编译成对象并插入到 OSD 中。 3. 应用示例 以一个简单的客户端应用程序为例，演示了如何使用 liber8 O API 读取对象并计算校验和。 介绍了 Skyhook 项目，这是一个基于 Stuff 的弹性数据库引擎，使用对象类来加速查询。 展示了 Skyhook 在性能方面的提升，例如在查询 10% 的亿级行时，性能提高了 6 倍。 讨论了 Ceph 源代码树中提供的对象类示例，包括 Lua 对象类。 4. Lua 对象类 指出 Lua 对象类可以简化开发过程，并提供了与 C++ 相同的功能。 介绍了 Lua 对象类的开发过程，包括编写 Lua 代码、编译和插入到 OSD 中。 强调了 Lua 对象类的安全性和错误处理。 5. 示例：缩略图生成 以缩略图生成为例，演示了如何使用对象类来处理图像数据。 介绍了缓存缩略图以避免重复计算的概念。 6. 未来发展方向 讨论了正在开发的更多用例，例如 HDFS 的多维数据切片和用于高能物理的存储系统。 提到了使用 WebAssembly 作为 Lua 的替代方案。 7. 问答环节 回答了关于对象类与擦除池兼容性、脚本部署和 Lua 与 Haproxy 集成等问题的疑问。 行动计划： [请填写行动计划，例如：进一步研究 Skyhook 项目、探索 Lua 对象类的安全性、开发更多示例应用等。] 备注： 会议中提到了许多 Ceph 相关的关键词，例如 RBD、RGW、liber8 O、对象类、Lua、Skyhook 等。 会议内容深入浅出，为开发人员提供了丰富的 Ceph 扩展功能和应用案例。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rapid Design and Effective Operating of a General Purpose Object Storage at RWTH - Jonas Jansen","slug":"Rapid_Design_and_Effective_Operating_of_a_General_Purpose_Object_Storage_at_RWTH_-_Jonas_Jansen","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Rapid_Design_and_Effective_Operating_of_a_General_Purpose_Object_Storage_at_RWTH_-_Jonas_Jansen/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Rapid_Design_and_Effective_Operating_of_a_General_Purpose_Object_Storage_at_RWTH_-_Jonas_Jansen/","excerpt":"","text":"会议纪要 会议主题：如何快速设计和高效运营安全的Ceph集群 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 一、会议关键细节 主讲人：Jana Johnson，来自are wth大学 讨论内容：如何快速设计和高效运营安全的Ceph集群 二、讨论的主要议题 集群容错性： 使用多个数据中心，并确保数据中心之间有高速连接（如暗光纤）。 在设计时考虑数据中心的扩展性，避免后期难以调整。 考虑故障域，确保单个节点故障不会超过集群容量的9%。 效率： 使用纠删码提高效率，但需注意适用于所有存储类型。 考虑存储效率与成本效益，合理配置冗余资源。 合规性与工作量优化： 使用配置管理工具（如Zabbix）自动化操作系统更新。 建立良好的测试环境，确保基础设施代码的更新或变更。 使用版本控制系统（如Git）管理配置文件和基础设施代码。 对于节点安装，建议重新安装而非修复，以保证合规性。 安全性： 定期进行安全测试，使用工具如Mozilla Observatory测试网关配置。 定期检查TLS证书，确保其有效性和安全性。 将网关网络与集群公共网络分离，以增强安全性。 收集和整合安全日志，以全面了解攻击向量。 Ceph的优势： Ceph易于部署，可直接从仓库拉取使用。 Ceph可扩展性强，可根据需求调整配置。 Ceph的默认配置良好，可直接使用。 三、决定的事项 参会人员需根据讨论内容，评估自身集群的容错性、效率、合规性和安全性。 建议使用配置管理工具、版本控制系统和测试环境，以提高集群的可靠性和安全性。 定期进行安全测试，及时更新安全补丁。 四、后续行动计划 参会人员根据会议内容，对自身集群进行优化和调整。 建立良好的测试环境，确保基础设施代码的更新或变更。 定期进行安全测试，及时更新安全补丁。 分享会议内容，让更多团队成员了解如何设计和运营安全的Ceph集群。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RWX Storage for Container Orchestrators with CephFS and Manila - Tom Barron, Red Hat","slug":"RWX_Storage_for_Container_Orchestrators_with_CephFS_and_Manila_-_Tom_Barron_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/RWX_Storage_for_Container_Orchestrators_with_CephFS_and_Manila_-_Tom_Barron_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/RWX_Storage_for_Container_Orchestrators_with_CephFS_and_Manila_-_Tom_Barron_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写会议地点] 参会人员： Tom Barron（红帽下游项目Kim团队负责人）、Robert Vacek（CERN实习生）、James Blair等 会议主题： OpenStack Manila与容器编排的集成，特别是针对Ceph文件系统（CephFS）的读写多故事（WX）存储。 会议内容： 背景介绍： Tom Barron介绍了自己的背景和目前的工作，包括作为红帽下游项目Kim团队负责人的角色。 他强调了OpenStack Manila在提供可扩展存储基础设施、选择自由和多云租户方面的优势。 OpenStack与容器编排： Tom讨论了OpenStack和Kubernetes等容器编排工具之间的差异，以及如何为应用开发者提供更便捷的基础设施服务。 他指出，虽然OpenStack提供了基础设施即服务，但应用开发者仍然需要具备一定的系统管理员技能。 WX存储： Tom介绍了Kubernetes中的WX存储概念，即读写多故事存储，它允许多个应用程序同时写入同一个文件系统。 他强调了CephFS在实现WX存储方面的优势，并讨论了CephFS与Kubernetes CSI接口的集成。 Manila与CephFS： Tom介绍了Manila如何支持CephFS，包括通过NFS前端和本地接口。 他还讨论了即将到来的Manila CSI工作，以及如何将更多功能暴露给容器编排工具。 后续行动计划： CERN的Robert Vacek正在开发Manila CSI插件，Tom的团队将进行集成测试和验证。 他们计划使用Ansible playbook在OpenStack环境中部署Manila和CephFS。 他们还计划探索将Ceph和Ganesha服务运行在Kubernetes集群中，并使用Courier进行网络隔离。 决定事项： Tom的团队将继续推动Manila CSI插件的开发和集成。 他们将与CERN合作，进行集成测试和验证。 他们将探索在Kubernetes环境中运行Ceph和Ganesha服务。 后续行动： Tom的团队将发布Ansible playbook，以便用户可以在OpenStack环境中部署Manila和CephFS。 他们还将与其他感兴趣的开发者合作，共同推动Manila和CephFS的发展。 备注： 会议中还讨论了其他一些相关话题，例如CephFS的快照支持、存储扩展和拓扑感知等。 会议纪要中保留了一些计算机科学/CEPH领域英文原文的关键词，以保持原文的专业性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rebuilding a Faster OSD with Future - Kefu Chai & Radoslaw Zarzynski, Red Hat","slug":"Rebuilding_a_Faster_OSD_with_Future_-_Kefu_Chai_Radoslaw_Zarzynski_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Rebuilding_a_Faster_OSD_with_Future_-_Kefu_Chai_Radoslaw_Zarzynski_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Rebuilding_a_Faster_OSD_with_Future_-_Kefu_Chai_Radoslaw_Zarzynski_Red_Hat/","excerpt":"","text":"会议纪要 会议主题： Ceph Crimson 项目进展及未来方向 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议内容： 一、会议背景 技术发展： 随着固态硬盘（SSD）和NVMe接口的普及，存储速度得到了显著提升。然而，Ceph存储系统在处理高速存储设备时，面临着性能瓶颈。 CSD架构： Ceph存储驱动器（CSD）最初针对旋转硬盘设计，其I/O性能有限。随着存储设备的升级，CSD的性能已无法满足需求。 二、Crimson项目 项目目标： 重构CSD，使其能够充分利用高速存储设备，提高I/O性能。 技术方案： 使用用户空间驱动器，减少内核空间与用户空间之间的数据拷贝。 采用无锁设计，避免锁竞争导致的性能瓶颈。 利用未来存储设备（如NVMe）的并行处理能力。 项目进展： 已完成CSD的重构，初步测试结果表明性能提升显著。 目前仅支持内存存储和简单的I/O路径，未来将支持更多功能。 三、下一步工作 性能测试： 将性能测试集成到持续集成（CI）流程中，确保代码质量。 功能完善： 支持更多存储设备、恢复机制和高级功能。 社区合作： 欢迎更多开发者参与Crimson项目，共同推动Ceph存储系统的发展。 四、讨论要点 RocksDB的集成： 短期内，Crimson将支持RocksDB，通过用户空间线程或扩展RocksDB来实现。 长期来看，可能不再使用RocksDB，而是利用新型存储硬件。 网络栈： 目前使用基于内核的网络栈，未来可能考虑使用PDK网络栈。 五、行动计划 性能测试： 在CI流程中集成性能测试。 功能开发： 优先开发支持更多存储设备和恢复机制的功能。 社区建设： 持续开展社区活动，吸引更多开发者参与。 六、总结 Crimson项目旨在重构Ceph存储驱动器，提高其性能。项目进展顺利，未来将支持更多功能和存储设备。Ceph社区将共同努力，推动Ceph存储系统的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rapid Processing of NASA Satellite Data Stored with Ceph - Kevin Hrpcek & Steve Dutcher","slug":"Rapid_Processing_of_NASA_Satellite_Data_Stored_with_Ceph_-_Kevin_Hrpcek_Steve_Dutcher","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Rapid_Processing_of_NASA_Satellite_Data_Stored_with_Ceph_-_Kevin_Hrpcek_Steve_Dutcher/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Rapid_Processing_of_NASA_Satellite_Data_Stored_with_Ceph_-_Kevin_Hrpcek_Steve_Dutcher/","excerpt":"","text":"会议纪要 会议主题： NASA卫星数据快速处理及后端存储解决方案 与会人员： Kevin（主持人）、Steve（发言人），来自威斯康星大学麦迪逊分校SSE C团队 会议内容： 1. SSE C团队介绍 - SSE C成立于50多年前，是卫星遥感技术的先驱中心。 - 团队主要工作包括：地球遥感成像、传感器数据验证与校准、数值天气预报建模、气象卫星研究、冰芯钻探等。 - 主要项目：NASA Vera卫星大气步骤项目，旨在生成2级和3级NASA产品，并与NASA科学团队合作，高效处理大量数据。 2. 数据处理挑战 - 使用Vera卫星等极地轨道卫星收集数据，每天产生大量数据，需要高效处理。 - 使用MODIS传感器等卫星数据，进行数据验证与校准，需要长期存储。 - 使用TROPICS项目，需要收集来自6颗立方星的数据，数据量更大。 3. 存储解决方案 - 预计每年需要增长1PB存储空间，需要良好的数据复制和海量存储。 - 使用Ceph作为存储解决方案，已使用4-5年，效果良好。 - 每天数据摄入量达600GB，产品生成量达500GB，其他产品生成量达700GB。 4. 数据处理流程 - 使用RabbitMQ进行消息传递，将感兴趣的数据文件发送到计算节点。 - 使用Ceph存储文件，并记录文件信息到数据库。 - 开发了PG Track工具，用于跟踪文件存储状态。 - 开发了Ceph Sleight工具，用于简化Ceph操作。 5. 容器化与自动化 - 使用Kubernetes进行容器化部署，例如PDS Serve服务。 - 使用HTCondor进行计算任务调度，支持科学团队进行数据处理。 6. 工具与架构 - 开发了FUSE层，为用户提供POSIX访问权限。 - 开发了Track Everything工具，用于跟踪Ceph集群中的对象。 7. 挑战与经验 - 集群规模不断增长，需要关注设置和优化。 - 遇到过集群故障，但未丢失任何对象。 - Ceph性能良好，可满足高吞吐量计算需求。 8. 未来计划 - 移动BlueStore，解决大文件存储限制问题。 - 可能升级Ceph到最新版本，以利用新技术。 行动计划： - 持续关注Ceph社区，跟进新技术。 - 优化集群设置，提高性能。 - 开发更多工具，简化数据处理流程。 总结： SSE C团队通过使用Ceph等开源技术，成功解决了NASA卫星数据快速处理和存储的挑战，为科学研究和气候变化研究提供了有力支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rook - Running Ceph Using Kubernetes - Alexander Trost & Kim-Norman Sahm, Cloudibility UG","slug":"Rook_-_Running_Ceph_Using_Kubernetes_-_Alexander_Trost_Kim-Norman_Sahm_Cloudibility_UG","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Rook_-_Running_Ceph_Using_Kubernetes_-_Alexander_Trost_Kim-Norman_Sahm_Cloudibility_UG/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Rook_-_Running_Ceph_Using_Kubernetes_-_Alexander_Trost_Kim-Norman_Sahm_Cloudibility_UG/","excerpt":"","text":"会议纪要 会议时间： （请在此处填写会议时间） 会议地点： （请在此处填写会议地点） 参会人员： Alexander（Rook项目成员） 同事（因身体原因未能出席） Sir Sir（Rook项目的吉祥物） 其他参会人员 会议议程： Rook项目介绍 Rook与Ceph的集成 Rook的架构 Rook的部署与配置 Rook的社区参与 问答环节 会议内容： 1. Rook项目介绍 Rook是一个开源项目，旨在帮助企业将Ceph等存储系统容器化，并在Kubernetes中进行部署和管理。Rook可以帮助用户轻松地部署、配置和管理Ceph集群，并提供与Kubernetes的原生集成。 2. Rook与Ceph的集成 Rook支持将Ceph作为存储后端进行部署和管理。除了Ceph之外，Rook还可以支持其他存储后端，例如Cassandra、HDFS等。 3. Rook的架构 Rook的架构主要包括以下组件： Rook Operator：负责管理Ceph集群的生命周期，包括创建、删除、升级和故障转移等操作。 Rook Discovery Agent：负责发现节点上的存储设备，并将其信息传递给Rook Operator。 Ceph组件：包括Monitors、OSDs、MDS等。 Kubernetes API：用于与Kubernetes集群进行交互。 4. Rook的部署与配置 Rook提供了丰富的配置选项，允许用户根据需求进行定制。例如，用户可以指定要使用的节点、存储设备、网络配置等。 5. Rook的社区参与 Rook社区非常活跃，许多社区成员为Rook的开发和改进做出了贡献。Rook项目也积极参与开源社区，与其他开源项目进行合作。 6. 问答环节 会议的最后是问答环节，参会者就Rook的部署、配置、性能等方面提出了问题，Alexander和社区成员进行了详细的解答。 决定事项： Rook项目将继续完善与Ceph的集成，并支持更多存储后端。 Rook项目将加强社区建设，吸引更多开发者参与。 Rook项目将关注用户反馈，不断改进产品。 后续行动计划： Rook项目团队将继续开发Rook，并发布新的版本。 Rook社区将持续开展活动，促进社区成员之间的交流。 Rook项目将积极与其他开源项目合作，共同推动开源生态的发展。 关键词： Rook Ceph Kubernetes Operator CSI Container Storage Interface Ceph Block Pool Persistent Volume Persistent Volume Claim Storage Class Horizontal Pod Autoscaler","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Releasing Ceph - Deep Dive Into Build Infrastructure - Alfredo Deza & Ken Dreyer, RedHat","slug":"Releasing_Ceph_-_Deep_Dive_Into_Build_Infrastructure_-_Alfredo_Deza_Ken_Dreyer_RedHat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Releasing_Ceph_-_Deep_Dive_Into_Build_Infrastructure_-_Alfredo_Deza_Ken_Dreyer_RedHat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Releasing_Ceph_-_Deep_Dive_Into_Build_Infrastructure_-_Alfredo_Deza_Ken_Dreyer_RedHat/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储项目 - 安全狗发布流程改进 参会人员： Fred Odessa (Ceph 项目安全团队)、Ken Dryer (Ceph 人员工程团队)、Alfredo (Ceph 人员工程团队) 会议内容： 一、会议背景 Fred Odessa 介绍了自己作为 Ceph 项目安全团队的一员，负责安全狗的发布工作，已有五年经验。 Ken Dryer 和 Alfredo 也介绍了他们在 Ceph 人员工程团队的工作，负责构建和发布 Ceph 软件。 二、安全狗发布过程中的问题 GPG 密钥管理问题： 早期在发布过程中，GPG 密钥被复制到多个服务器，导致密钥泄露，需要重新生成密钥并加强密钥管理。 构建环境问题： 早期构建环境自动化程度低，依赖关系复杂，难以维护。 服务器依赖问题： 每个发行版都使用独立的服务器进行构建，服务器故障会导致整个系统瘫痪。 发布流程复杂： 发布流程复杂，需要大量手动操作，效率低下。 三、改进措施 自动化构建： 使用 Jenkins Job Builder 进行自动化构建，提高构建效率。 分布式构建： 使用多个 Jenkins 节点进行分布式构建，提高系统可靠性。 容器化： 使用容器技术，实现更灵活的部署和扩展。 文档化： 加强文档编写，提高系统可维护性。 API 开放： 开放 API，方便第三方集成。 四、未来规划 提高构建系统可扩展性： 通过 API 开放和集成第三方构建系统，提高构建系统可扩展性。 改进发布流程： 简化发布流程，提高发布效率。 支持更多平台和架构： 支持更多平台和架构，例如 ARM、FreeBSD 等。 五、讨论要点 如何提高构建系统的可扩展性？ 如何改进发布流程？ 如何支持更多平台和架构？ 六、行动计划 Fred Odessa 和 Ken Dryer 将继续推进自动化构建和发布流程的改进。 Alfredo 将研究如何提高构建系统的可扩展性。 Ceph 社区将共同努力，支持更多平台和架构。 七、总结 本次会议讨论了 Ceph 安全狗发布流程的改进，提出了改进措施和未来规划。通过改进构建系统和发布流程，Ceph 将能够更好地支持用户和社区发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Rook Deployed Scalable NFS Clusters Exporting CephFS - Patrick Donnelly & Jeff Layton, Red Hat, Inc.","slug":"Rook_Deployed_Scalable_NFS_Clusters_Exporting_CephFS_-_Patrick_Donnelly_Jeff_Layton_Red_Hat_Inc.","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Rook_Deployed_Scalable_NFS_Clusters_Exporting_CephFS_-_Patrick_Donnelly_Jeff_Layton_Red_Hat_Inc./","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Rook_Deployed_Scalable_NFS_Clusters_Exporting_CephFS_-_Patrick_Donnelly_Jeff_Layton_Red_Hat_Inc./","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未知） 参会人员： Patrick Donnelly（Red Hat SEPA fest 技术负责人）、Jeff Lee（Red Hat 存储专家） 会议主题： 使用 Ceph 部署 NFS 集群，探讨使用 rope 和 ffs 进行导出，介绍 SEPA fest 的相关技术。 会议内容： 1. SEPA fest 简介 SEPA fest 是一种 POSIX 分布式文件系统，基于对象存储构建。 特点： MDS（元数据服务器）集群化，元数据存储分离。 客户端直接访问所有文件数据，无需与 MDS 交互。 客户端和 MDS 共同维护元数据分布式缓存，包括 i-nodes 和目录。 客户端通过 capabilities 获取读写权限，确保数据一致性。 主要客户端：step views 和内核客户端。 2. 部署 NFS 集群的原因 部署 NFS 网关的原因包括： 部分客户端可能无法正确处理 Ceph，需要通过网关进行转换。 网络安全，例如防火墙保护集群数据。 OpenStack Manila 等场景需要隔离数据访问。 3. Ceph 集群与 NFS 网关 Ceph 集群已支持主动/被动网关，但性能扩展性较差。 希望实现主动/主动部署，实现线性扩展。 目标： 线性扩展集群。 容器化部署，利用 Kubernetes 等基础设施。 避免使用第三方软件，例如 pacemaker。 使用 NFS Ganesha 作为 NFS 服务器。 4. NFS 协议 NFS 协议历史悠久，早期版本无状态，需要附加协议处理。 NFSv4 和 NFSv4.1 引入会话层和会话恢复机制。 Ganesha 使用 Ratius 存储跟踪客户端状态，支持会话恢复。 5. 复杂性挑战 网络文件系统（NFS）和集群文件系统（SEPA fest）都使用基于租约的会话机制，需要处理会话超时和租约过期等问题。 需要处理 IP 迁移，当 NFS Ganesha 服务器失败时，需要将 IP 地址迁移到新的服务器。 6. 解决方案 使用 Rook 和 Kubernetes 进行部署和管理。 利用 Kubernetes 的 IP 迁移功能。 通过 Rook 部署和管理 Ganesha 容器。 使用 Dashboard API 配置 Ganesha 导出。 7. 未来工作 支持基于子卷的主动/主动部署。 支持迁移到新的 IP 地址。 优化子卷的 grace 期。 与 SMB 集成。 行动计划： 完善 Rook 和 Kubernetes 的集成。 优化 Ganesha 的配置和管理。 在 Ceph 中实现基于子卷的主动/主动部署。 研究与 SMB 的集成方案。 总结： 本次会议讨论了使用 Ceph 部署 NFS 集群的方案，并分析了相关技术和挑战。会议明确了未来工作方向和行动计划，为 Ceph 的存储功能扩展提供了新的思路。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Running Backups with Ceph-to-Ceph - Michel Raabe, B1 Systems GmbH","slug":"Running_Backups_with_Ceph-to-Ceph_-_Michel_Raabe_B1_Systems_GmbH","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Running_Backups_with_Ceph-to-Ceph_-_Michel_Raabe_B1_Systems_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Running_Backups_with_Ceph-to-Ceph_-_Michel_Raabe_B1_Systems_GmbH/","excerpt":"","text":"会议纪要 会议主题： 使用Ceph进行数据备份 参会人员： 来自德国的To Be One Systems公司的Seth及其团队成员 会议内容： 一、会议背景 Seth介绍了他们公司主要业务为云计算服务，包括OpenStack和Ceph等。在为客户的Ceph集群进行部署和维护过程中，发现客户对数据备份的需求日益增长。 二、备份方案探讨 备份需求： 客户希望对Ceph集群进行数据备份，包括全量备份和增量备份。 备份方式应支持离线备份，满足合规性要求。 备份工具应具备文件浏览器功能，方便用户进行数据恢复。 Ceph提供的备份方案： Ceph Replication： 可以配置跨集群复制，将数据从源集群复制到目标集群。 F3 Multi-Site Replication： 可以在多个Ceph集群之间进行数据复制，支持读写分离。 自定义脚本： 可以使用Ceph提供的命令行工具进行数据备份和恢复。 备份方案面临的挑战： 数据一致性： 在进行备份时，需要确保数据的一致性，避免数据损坏。 灾难恢复： 需要考虑灾难恢复方案，确保在数据丢失的情况下能够快速恢复。 带宽和成本： 复制大量数据需要消耗大量带宽，并可能产生较高的成本。 文件浏览器： Ceph本身不提供文件浏览器功能，需要使用第三方工具。 三、解决方案 Ceph Replication： 使用Ceph Replication进行跨集群数据复制，确保数据一致性。 使用F3 Multi-Site Replication实现读写分离，提高性能。 使用自定义脚本进行增量备份，降低带宽消耗。 第三方工具： 使用Becky等第三方工具进行数据备份和恢复，并支持文件浏览器功能。 使用Ceph Airship进行集群迁移，将数据从旧集群迁移到新集群。 四、后续行动计划 继续探索Ceph Replication和F3 Multi-Site Replication的使用方法，优化备份方案。 评估第三方工具的性能和可靠性，选择合适的备份工具。 与Ceph社区沟通，推动Ceph文件浏览器功能的开发。 五、其他讨论 如何管理大量快照？ 通过限制快照数量或使用第三方工具进行快照管理。 如何在Ceph集群之间进行数据复制？ 使用Ceph Replication或F3 Multi-Site Replication进行数据复制。 总结： 本次会议讨论了使用Ceph进行数据备份的方案和挑战，并提出了相应的解决方案。后续将继续探索优化备份方案，并推动Ceph文件浏览器功能的开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Testing Ceph: Status, Development, & Opportunities - Gregory Farnum, Red Hat","slug":"Testing_Ceph_-_Status_Development_Opportunities_-_Gregory_Farnum_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Testing_Ceph_-_Status_Development_Opportunities_-_Gregory_Farnum_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Testing_Ceph_-_Status_Development_Opportunities_-_Gregory_Farnum_Red_Hat/","excerpt":"","text":"会议纪要 会议主题： Ceph 测试框架的历史、当前开发进展及贡献机会 与会人员： Greg（Ceph 测试框架负责人）、Steph（Ceph 测试框架开发人员）、Brad（Ceph 社区成员） 会议内容： 一、Ceph 测试框架历史 Ceph 测试框架起源于 2009 年，旨在解决分布式系统测试难题。 早期使用 AutoTest 进行测试，但效果不佳。 TV 开发了 Orchestration 模块，通过 SSH 集成测试节点，实现自动化测试。 Orchestration 模块最初仅作为测试运行器，随后发展成为一个完整的框架。 二、Ceph 测试框架现状 Toothology： Ceph 测试框架的核心，支持自动化测试、测试运行、结果收集等功能。 Sepia Lab： 用于运行 Ceph 测试的巨型实验室，拥有 250 多台服务器。 测试类型： 单个用户测试、SEF 测试、Ceph PR 测试、夜间测试等。 其他测试系统： Jenkins 测试、make check 测试、Ceph 对象存储库测试等。 三、测试框架的不足 Toothology 与守护进程的直接交互： 无法测试单元测试、系统集成测试、Kubernetes 集成测试等。 性能测试： 缺乏性能测试和分析工具。 规模测试： 缺乏针对大规模集群的测试。 部署工具测试： 无法测试安装和集群配置工具。 Orchestrator 测试： 与测试框架未集成。 框架弱点： 与 Sepia Lab 强烈耦合、文档不明确、代码和测试循环复杂等。 四、改进计划 扩展 Toothology API，支持使用 init 系统重启守护进程。 开发性能测试和分析工具。 开发大规模测试方案。 集成部署工具。 集成 Orchestrator 测试。 改进框架设计，提高可扩展性和可维护性。 五、贡献机会 维护 Ceph 对象存储库。 开发新的测试工具。 改进测试框架。 六、后续行动 在邮件列表上讨论改进计划。 开发新的测试工具和功能。 鼓励更多社区成员参与测试框架开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Testing Ceph for the Cloud, in the Cloud - Adam Wolfe Gordon, DigitalOcean","slug":"Testing_Ceph_for_the_Cloud_in_the_Cloud_-_Adam_Wolfe_Gordon_DigitalOcean","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Testing_Ceph_for_the_Cloud_in_the_Cloud_-_Adam_Wolfe_Gordon_DigitalOcean/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Testing_Ceph_for_the_Cloud_in_the_Cloud_-_Adam_Wolfe_Gordon_DigitalOcean/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： KubeCon会议现场 参会人员： Adam Wolfe（DigitalOcean存储团队），其他Ceph社区成员 会议内容： 一、会议背景 Adam Wolfe是DigitalOcean存储团队的一员，负责管理Kubernetes产品。 DigitalOcean是一家公有云提供商，自2011年起提供虚拟机、块存储、对象存储等服务，并基于Ceph技术构建了其存储产品。 DigitalOcean在全球拥有21个集群和9个数据中心，存储容量约40PB。 二、主要议题 Ceph测试环境搭建： DigitalOcean之前一直使用社区构建的Ceph版本，没有进行太多定制化开发。 随着业务规模扩大，DigitalOcean开始需要更多控制权，以满足服务质量要求，并解决对象存储中的扩展限制和bug。 因此，DigitalOcean决定搭建自己的Ceph测试环境，并开发内部工具以实现自动化测试。 搭建测试环境遇到的挑战： Toothology框架的限制： Toothology是Ceph的集成测试框架，但在云环境中运行时存在一些假设，例如测试节点之间通过DNS名称通信。DigitalOcean通过安装DNS Masq和配置hosts文件来解决此问题。 网络配置问题： Toothology使用的Ansible自动化脚本尝试使用DHCP配置网络，但DigitalOcean的Droplets不支持DHCP。DigitalOcean通过黑名单规则解决了此问题。 Ceph包路径问题： Toothology假设Ceph包存储在Shaymin系统中，而DigitalOcean使用自己的内部仓库。DigitalOcean通过创建符号链接解决了此问题。 SHA-1验证问题： Toothology尝试验证SHA-1值是否存在于上游仓库中，但DigitalOcean使用私有GitHub仓库。DigitalOcean修改了Toothology代码以跳过此验证。 自动化测试环境搭建： DigitalOcean使用Terraform和Ansible自动化脚本搭建Ceph测试环境，包括Droplets、Paddles服务器、Head节点和Test节点。 用户可以通过运行单个命令来启动测试环境，并可以轻松地扩展或缩减规模。 三、行动计划 DigitalOcean将继续优化Ceph测试环境，并开源其自动化脚本，以帮助社区成员快速搭建测试环境。 DigitalOcean将继续向Ceph社区贡献代码，并积极参与社区活动。 四、会议总结 本次会议介绍了DigitalOcean如何搭建Ceph测试环境，并分享了在搭建过程中遇到的挑战和解决方案。DigitalOcean的自动化脚本为Ceph社区提供了宝贵的资源，有助于促进Ceph技术的发展和应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Unlimited Fileserver with Samba CTDB and CephFS - Robert Sander, Heinlein Support GmbH","slug":"Unlimited_Fileserver_with_Samba_CTDB_and_CephFS_-_Robert_Sander_Heinlein_Support_GmbH","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Unlimited_Fileserver_with_Samba_CTDB_and_CephFS_-_Robert_Sander_Heinlein_Support_GmbH/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Unlimited_Fileserver_with_Samba_CTDB_and_CephFS_-_Robert_Sander_Heinlein_Support_GmbH/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 伦敦 参会人员： Robby Sandrock（柏林，德国，Linux顾问）、其他未提及姓名的参会者 会议主题： Ceph分布式存储系统在视频会议字幕翻译中的应用与优化 关键细节： Robby Sandrock 介绍了Linux咨询公司的背景，以及他们在处理大量数据时的挑战。 Ceph分布式存储系统 被提及作为解决数据存储和可靠性问题的解决方案。 Samba 和 NFS 协议在会议中被讨论，用于文件共享和数据同步。 CDB（Cluster Database）是一个分布式数据库，用于处理大规模数据存储和查询。 讨论的主要议题： Ceph性能优化： 讨论了如何提高Ceph集群的性能，包括使用集群、性能模式、优化配置等。 Samba和NFS配置： 讨论了Samba和NFS配置的最佳实践，以及如何实现高效的数据共享。 CDB分布式数据库： 讨论了CDB在处理大规模数据存储和查询方面的优势。 决定的事项： 性能优化： 将进一步研究Ceph性能优化方案，并尝试实施。 配置优化： 将优化Samba和NFS配置，以提高数据共享效率。 CDB应用： 将探讨CDB在处理大规模数据存储和查询方面的应用。 后续行动计划： 性能优化小组： 成立一个小组，专门负责研究Ceph性能优化方案。 配置优化小组： 成立一个小组，专门负责优化Samba和NFS配置。 CDB应用小组： 成立一个小组，专门负责探讨CDB在处理大规模数据存储和查询方面的应用。 其他： 会议中展示了Ceph、Samba和NFS的配置示例。 讨论了使用CDB处理大规模数据存储和查询的最佳实践。 分享了一些成功案例，例如在体育、医疗和科研领域的应用。 关键词： Ceph 分布式存储 Samba NFS CDB 性能优化 配置优化 数据共享 大规模数据存储 分布式数据库","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Using Devops Practices for Operating CEPH - Anders Bruvik, Safespring","slug":"Using_Devops_Practices_for_Operating_CEPH_-_Anders_Bruvik_Safespring","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Using_Devops_Practices_for_Operating_CEPH_-_Anders_Bruvik_Safespring/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Using_Devops_Practices_for_Operating_CEPH_-_Anders_Bruvik_Safespring/","excerpt":"","text":"会议纪要 会议主题： DevOps实践在基础设施团队中的应用 会议时间： [请填写会议具体时间] 参会人员： [请填写参会人员名单] 会议内容： 一、DevOps概述 DevOps的定义： DevOps并非一个产品、部门或可雇佣的职位，而是一种文化，强调不同背景和职位的人共同协作，从想象、开发、部署到运营整个系统。 如Ken McGraw所言：“DevOps是一种文化，其中人们无论职位或背景如何，都一起工作，以想象、开发、部署和运营一个操作系统。” DevOps的目标： 通过自动化和协作提升软件交付速度和效率。 降低风险，缩短上市时间。 提高员工满意度。 二、DevOps实践 构建管道： 将配置从版本控制系统中自动部署到生产环境，实现自动化流程。 管道的主要目的是测试和筛选，确保所有配置更改都适合生产环境。 自动化测试： 转变传统测试模式，将大量手动测试转变为自动化单元测试。 将系统分解为可测试的小部件，对每个部件进行独立测试，并确保其可重新部署。 利用容器化和配置管理工具，实现自动化部署。 监控： 对系统进行监控，以评估性能和识别潜在问题。 三、基础设施团队的角色 基础设施团队的工作： 开发和维护基础设施。 构建和部署系统。 基础设施团队的优势： 建设基础设施很有趣，可以激发团队活力。 四、行动计划 建立DevOps文化： 在团队中推广DevOps理念，鼓励协作和自动化。 培训团队成员掌握相关技能。 实施自动化测试： 开发自动化测试脚本，对系统进行测试。 利用容器化和配置管理工具，实现自动化部署。 监控系统性能： 对系统进行监控，确保其正常运行。 五、总结 本次会议介绍了DevOps在基础设施团队中的应用，强调了自动化、测试和协作的重要性。参会人员应积极推动DevOps实践，以提高团队效率和系统稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Upgrade and Scale-Out an In-production Ceph Cluster on Mixed Arm Micro-server Platform - Aaron Joue","slug":"Upgrade_and_Scale-Out_an_In-production_Ceph_Cluster_on_Mixed_Arm_Micro-server_Platform_-_Aaron_Joue","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/Upgrade_and_Scale-Out_an_In-production_Ceph_Cluster_on_Mixed_Arm_Micro-server_Platform_-_Aaron_Joue/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/Upgrade_and_Scale-Out_an_In-production_Ceph_Cluster_on_Mixed_Arm_Micro-server_Platform_-_Aaron_Joue/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议地点] 参会人员： Aaron（嵌入式技术公司代表） [其他参与者姓名] 会议内容： 1. 公司及产品介绍 - Aaron介绍了其公司嵌入式技术，一家提供安全存储解决方案的公司。 - 公司产品基于微服务器架构，每个节点配置一个硬盘和一个SSD，易于部署和扩展。 - 产品获得2016年Interop最佳产品奖和台湾Computex最佳ROI金奖。 2. 客户背景及需求 - 一家台湾大型电信公司因市场竞争压力，决定将传统的VMware或昂贵存储迁移到开源解决方案。 - 公司内部私有云项目采用OpenStack和自开发云管理门户，并计划使用Ceph作为存储解决方案。 - 初期集群规模较小，但用户增长迅速，导致性能问题。 3. 问题分析 - 集群规模过小，仅21个OSD承载140个VM，导致I/O压力过大。 - 通过日志分析，发现读写吞吐量低，I/O请求过多，OSD磁盘利用率过高。 - CPU利用率低，瓶颈在于磁盘I/O。 4. 解决方案 - 短期方案：增加15个OSD节点，将集群规模扩大到66个OSD。 - 长期方案：增加更多OSD节点，并升级到64位ARM服务器和Ceph Luminous版本。 - 挑战：在不中断服务的情况下升级，缩短迁移时间，同时将旧服务器操作系统从Debian升级到CentOS。 5. 升级策略 - 监控节点升级：先升级WebUI版本，然后逐步升级监控节点到Luminous版本。 - OSD节点升级：添加新OSD节点，逐步替换旧OSD节点，并升级到Luminous版本。 - 数据迁移：使用Ansible Playbook进行数据迁移，确保最小化服务中断。 6. 总结 - 通过分析、规划和实施，成功解决了电信公司的存储性能问题，并实现了平滑升级。 后续行动计划： [请填写后续行动计划，例如：验证升级效果、优化配置、提供技术支持等]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"What are “caps”? (And Why Won’t my Client Drop Them?) - Gregory Farnum, Red Hat","slug":"What_are_caps_And_Why_Won_t_my_Client_Drop_Them_-_Gregory_Farnum_Red_Hat","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/What_are_caps_And_Why_Won_t_my_Client_Drop_Them_-_Gregory_Farnum_Red_Hat/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/What_are_caps_And_Why_Won_t_my_Client_Drop_Them_-_Gregory_Farnum_Red_Hat/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 未提及 参会人员： Greg（Rados团队测试人员），其他Ceph开发人员，以及与会观众 会议主题： Ceph文件系统inode能力（caps） 会议内容： Ceph架构概述： 介绍了Ceph集群的组成部分，包括监视器（Monitors）、OSD（Object Storage Daemons）和MDS（Metadata Servers），以及它们在处理数据、元数据和客户端请求时的角色。 文件系统一致性： 解释了为什么Ceph文件系统需要一致性，特别是在实现POSIX文件系统标准时。强调了MDS在维护元数据一致性方面的作用。 caps的介绍： 详细介绍了Ceph中用于权限控制和状态委托的caps机制。解释了不同类型的caps（如pin cap、auth cap、link cap、adder cap、file cap等）以及它们的功能。 caps的使用： 解释了如何通过MDS向客户端发放caps，以及客户端如何使用这些caps进行文件操作。讨论了caps的有效期、更新和撤销。 caps架构的后果： 讨论了使用caps架构可能带来的影响，包括MDS缓存大小、客户端行为、以及可能出现的问题（如客户端失败、缓存压力等）。 编程示例： 展示了Ceph客户端库中如何使用caps进行文件操作，包括获取caps、检查caps状态、以及处理caps更新。 NFS委托： 介绍了Ceph如何支持NFS委托，允许客户端在本地执行读/写操作，同时维护缓存一致性。 关键议题： Ceph文件系统的一致性 caps机制及其在权限控制和状态委托中的作用 caps的使用和影响 客户端行为和MDS缓存管理 NFS委托 决定事项： 无 后续行动计划： 无 备注： 会议中提到了一些Ceph版本和功能，如mimic和Nautilus，这些信息可能会随时间而变化。 会议中讨论了一些可能的问题和解决方案，但未做出具体决定。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"echo “Subject: Update on librmb” | sendmail -v SDS@ceph.com - Danny Al-Gaaf, Deutsche Telekom AG","slug":"echo_Subject_-_Update_on_librmb_sendmail_-v_SDS@ceph.com_-_Danny_Al-Gaaf_Deutsche_Telekom_AG","date":"2019-05-23T16:00:00.000Z","updated":"2019-05-23T16:00:00.000Z","comments":true,"path":"2019/05/24/echo_Subject_-_Update_on_librmb_sendmail_-v_SDS@ceph.com_-_Danny_Al-Gaaf_Deutsche_Telekom_AG/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/24/echo_Subject_-_Update_on_librmb_sendmail_-v_SDS@ceph.com_-_Danny_Al-Gaaf_Deutsche_Telekom_AG/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 项目开发人员、运营人员、技术专家等 会议主题： Ceph存储系统性能优化、邮件系统安全与稳定性改进、项目进度与风险评估 会议内容： 一、Ceph存储系统性能优化 主要问题： 邮件系统中的NFS感染，导致性能下降，邮件传输速度慢。 解决方案： 优化Ceph集群配置，提高存储性能。 引入新的存储解决方案，如使用Ceph作为邮件索引存储，以优化性能。 采用开源工具，如Nexans，进行性能监控和分析。 行动计划： 立即进行性能测试，评估优化效果。 根据测试结果调整Ceph集群配置。 引入新的存储解决方案，并进行测试。 二、邮件系统安全与稳定性改进 主要问题： 邮件系统存在安全漏洞，可能导致数据泄露。 解决方案： 加强邮件系统安全防护，如使用防火墙、入侵检测系统等。 定期进行安全漏洞扫描和修复。 优化邮件系统备份策略，确保数据安全。 行动计划： 制定邮件系统安全防护方案，并实施。 定期进行安全漏洞扫描和修复。 优化邮件系统备份策略，并进行测试。 三、项目进度与风险评估 项目进度： 项目按计划进行，但存在一些风险。 风险： Ceph存储系统性能优化可能影响邮件系统稳定性。 邮件系统安全漏洞可能导致数据泄露。 行动计划： 加强性能优化和安全性测试，确保项目顺利进行。 制定应急预案，应对潜在风险。 四、其他 邮件系统功能改进： 讨论了邮件系统功能改进的需求，如邮件搜索、邮件分类等。 开源软件应用： 讨论了使用开源软件进行邮件系统开发的可行性。 总结： 本次会议讨论了Ceph存储系统性能优化、邮件系统安全与稳定性改进、项目进度与风险评估等重要议题。会议明确了下一步工作计划和行动计划，确保项目顺利进行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-29:: Ceph Orchestration Meeting","slug":"2019-04-29_-_-_Ceph_Orchestration_Meeting","date":"2019-05-12T16:00:00.000Z","updated":"2019-05-13T16:00:00.000Z","comments":true,"path":"2019/05/13/2019-04-29_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/13/2019-04-29_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年4月29日 会议主题： Orchestrators 团队会议 会议内容： 一、Rook 1.0.0 更新 Rook 1.0.0 版本即将发布，代码层面已无阻塞问题。 唯一待解决的问题是新的网站正在开发中，预计明天可以完成。团队将审查新网站，并确保它与 Rook 1.0.0 版本一同发布。 新网站将带来新的视觉和用户体验。 讨论了 Rook 管理器配置路径的问题，确认需要在路径中包含管理器 ID 以确保配置的有效性。 二、Ceph 与 Tautology 集成 团队正在讨论将 Ceph 与 Tautology 集成，但遇到了一些困难。 API 集成非常底层，难以使用。 团队建议将测试分为两部分：一部分在 Tautology 中进行，另一部分在 Cuban Edda 环境中进行。 需要解决 Docker 镜像构建和不同 Kubernetes 环境测试的问题。 三、自动化测试 团队讨论了自动化测试的重要性，并分享了各自的环境和测试工具。 建议结合各自的努力，构建一个可由所有人使用的测试框架。 讨论了自动化构建 Docker 镜像的问题。 四、其他事项 讨论了 Ceph 的内存目标设置问题。 讨论了 Ceph 与其他存储提供商的集成。 讨论了即将举行的 Ceph 会议。 五、行动计划 审查新网站，确保其与 Rook 1.0.0 版本一同发布。 解决 Rook 管理器配置路径问题。 继续推进 Ceph 与 Tautology 的集成。 构建自动化测试框架。 解决 Docker 镜像构建问题。 六、后续行动 团队成员将根据行动计划继续推进工作。 团队将定期召开会议，讨论进度和问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-05-01 :: Ceph Developer Meeting","slug":"2019-05-01_-_-_Ceph_Developer_Meeting","date":"2019-05-12T16:00:00.000Z","updated":"2019-05-13T16:00:00.000Z","comments":true,"path":"2019/05/13/2019-05-01_-_-_Ceph_Developer_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/05/13/2019-05-01_-_-_Ceph_Developer_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Brad、Sofia、Sridhar 等 会议主题： - 多数据中心测试 - 监视器选举策略 - 内存目标设置 - 监视器性能优化 关键细节与讨论议题： 多数据中心测试： 讨论了多数据中心测试的进展，准备通过iptables进行测试，模拟网络故障。 讨论了监视器在故障情况下的内存使用策略，包括如何映射故障到 crush map，以及如何处理选举过程中的故障。 认为在选举过程中，监视器应该根据其连接的节点数量进行排序，选择连接节点数量最多的监视器作为领导者。 监视器选举策略： 讨论了监视器选举策略的优化，包括如何处理网络故障、延迟和可靠性问题。 认为应该为每个监视器设置一个可靠性分数，并根据连接数量、延迟和可靠性等因素计算总分。 讨论了如何通过选举消息共享信息，以及如何确保信息的一致性。 内存目标设置： 讨论了内存目标设置的进展，包括 RocksDB 和 OSD map cache 的内存分配。 讨论了如何根据缓存大小和性能需求调整内存分配。 监视器性能优化： 讨论了监视器性能优化的方法，包括提高连接数量、降低延迟和提升可靠性。 认为应该通过增加监视器副本数量来提高可靠性，并确保监视器副本均匀分布在不同的数据中心。 决定的事项： 完成多数据中心测试，并分析测试结果。 优化监视器选举策略，包括设置可靠性分数和计算总分。 调整内存目标设置，确保缓存大小和性能需求得到满足。 进一步研究监视器性能优化方法，并实施相应的改进措施。 后续行动计划： Sofia 将编写测试脚本，模拟网络故障，并分析测试结果。 Brad 将优化监视器选举策略，并实现相应的代码。 Sridhar 将调整内存目标设置，并确保缓存大小和性能需求得到满足。 团队将共同研究监视器性能优化方法，并实施相应的改进措施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-23:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-04-23_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-24T16:00:00.000Z","updated":"2019-04-25T16:00:00.000Z","comments":true,"path":"2019/04/25/2019-04-23_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/25/2019-04-23_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： 线上会议 参会人员： 全体研发人员 会议主题： Ceph项目进展及问题讨论 会议内容： 1. 项目进展 Crimson项目： 项目组成员汇报了Crimson项目的进展，包括集成v1和v2版本的工作，以及经典消息传递系统的优化。 讨论了Crimson OSD与经典OSD的互操作性测试，以及远程消息传递的测试结果。 确定了下一步的工作计划，包括优化配置代理、测试Crimson OSD在不同主机上的性能，以及进行更复杂的测试案例。 其他项目： 项目组成员汇报了其他项目的进展，包括执行阶段、优化未来状态、日志恢复等。 2. 问题讨论 Crimson项目： 讨论了Crimson OSD与经典OSD连接失败的问题，并决定进行调试。 讨论了Crimson OSD在本地测试环境中性能不如预期的问题，并决定进行进一步的测试和分析。 讨论了PG日志和PG后端的设计，并确定了基本结构。 其他问题： 讨论了日志恢复的效率问题，并决定寻找更高效的解决方案。 3. 决定事项 Crimson项目： 继续优化配置代理。 进行更复杂的测试案例，包括多连接测试。 调试Crimson OSD与经典OSD连接失败的问题。 进行进一步的测试和分析，以确定Crimson OSD在本地测试环境中性能不如预期的原因。 设计PG日志和PG后端。 其他项目： 按计划推进其他项目。 4. 后续行动计划 Crimson项目： 项目组成员将继续跟进Crimson项目的相关工作，并及时汇报进展。 项目组成员将进行必要的测试和分析，并解决遇到的问题。 其他项目： 项目组成员将按计划推进其他项目。 5. 其他事项 项目组成员将参加巴塞罗那的面对面会议，并讨论Ceph项目的相关事宜。 关键词： Crimson OSD 经典OSD 配置代理 互操作性 测试 性能 日志恢复 PG 后端","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-25 :: Ceph Performance meeting","slug":"2019-04-25_-_-_Ceph_Performance_meeting","date":"2019-04-24T16:00:00.000Z","updated":"2019-04-25T16:00:00.000Z","comments":true,"path":"2019/04/25/2019-04-25_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/25/2019-04-25_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： Igor, Adam, Radek, Ma Jinping, Sam, Daehan, Abhishek, Nick等 会议主题： Ceph分布式存储项目进展及讨论 关键细节与议题： Pull Requests (PRs) 讨论： 本周有许多PR被关闭，部分原因是旧的BOTS自动关闭了这些PR。 Igor的PR关于RocksDB的预取和缓冲读取模式，目前还在调查直接IO模式。 Ma Jinping的PR进行了一些性能优化，但具体影响尚不明确。 Radek的PR引入了Crimson OSD的执行阶段，目前还在讨论中。 Sam的PR关于增强指令缓存局部性，目前还在讨论中。 Adam的PR关于优化Booster缓存和Roxy D块缓存，已合并。 Beige的PR关于UTF-8优化，已合并。 Jason的PR关于RBE和右回退哈希，目前还在讨论中。 Daehan的PR关于测试RocksDB分配器，希望将其转换为单元测试。 Sage希望保留Adam关于Blue Store分配器的测试工作。 其他讨论： Adam正在研究TeaDB，并发现其写放大率较低。 Nick询问了关于RocksDB的问题，希望将其集成到Ceph中。 Abhishek和Nick讨论了使用S3的App性能问题，发现PR276997会影响性能。 后续行动计划： 继续对现有的PR进行审查和合并。 探索将TeaDB集成到Ceph中的可能性。 优化S3相关的性能问题。 总结： 本周Ceph项目进展顺利，多个PR已合并，但仍有一些PR需要进一步讨论和优化。团队成员将继续努力，确保Ceph项目的稳定性和性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-18 :: Ceph Performance meeting","slug":"2019-04-18_-_-_Ceph_Performance_meeting","date":"2019-04-21T16:00:00.000Z","updated":"2019-04-22T16:00:00.000Z","comments":true,"path":"2019/04/22/2019-04-18_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/22/2019-04-18_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Adam（Ceph研发人员），其他Ceph团队成员 会议内容： 1. Pull Requests审核 新提交的Pull Requests： 一项优化了异步消息传递性能的Pull Requests，通过从用户空间而不是内核空间拉取事件，实现了性能提升。 一项优化检查UTF-8的Pull Requests，旨在提高系统性能。 已审核的PullRequests： 推迟延迟请求的PullRequests，由Jason审核。 优化默认的垃圾回收策略的PullRequests，之前存在的问题已得到解决。 2. Adam的RocksDB工作 Adam测试了将RocksDB数据库分割成多个列族对性能的影响。 测试结果表明，分割列族可以带来一定的性能提升，最高可达29%。 Adam还探讨了列族大小和写前锁对性能的影响，并发现更大的写前锁和更少的列族可以带来显著的性能提升。 3. RocksDB的压缩和扩展 团队讨论了RocksDB的压缩和扩展问题，并探讨了如何通过调整配置来优化性能。 Adam提出，通过调整写前锁大小和列族配置，可以减少数据移动，从而提高压缩效率。 4. Ceph性能和稳定性 团队讨论了Ceph的性能和稳定性问题，并探讨了如何改进系统性能和可靠性。 Adam提出，通过增加超时时间和优化超时策略，可以避免因长时间等待而导致的服务中断。 5. 其他议题 团队讨论了其他一些议题，包括： MDS缓存内存限制 内存自动调优 集群性能测试 后续行动计划： Adam将继续测试RocksDB分割列族对性能的影响，并优化相关配置。 团队将继续改进Ceph的性能和稳定性。 团队将继续关注其他议题，并制定相应的解决方案。 关键词： Pull Requests RocksDB 列族 写前锁 压缩 扩展 Ceph 性能 稳定性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-22:: Ceph Orchestration Meeting","slug":"2019-04-22_-_-_Ceph_Orchestration_Meeting","date":"2019-04-21T16:00:00.000Z","updated":"2019-04-22T16:00:00.000Z","comments":true,"path":"2019/04/22/2019-04-22_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/22/2019-04-22_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 参会人员： [所有参会人员姓名] 会议主题： Ceph 存储项目进展及讨论 会议内容： 一、Ceph 项目进展 自动发布工作： 本周将完成自动发布工作的最后几个项目，包括设置默认部署为 Nautilus 版本。 Rook 示例配置： 需要将 Rook 示例中的默认存储类型设置为 Nautilus，并在 Yama 文件中进行相应的修改。 升级指南： Blaine 撰写的升级指南正在评审中，建议其他成员阅读并提出意见。 Nautilus 升级： Nautilus 升级仍存在一些问题，需要解决，Sebastian Han 正在处理该问题。 NFS 升级： 在不重启 Rook Operator 的情况下进行设置时，NFS 等服务将自动升级。 二、讨论议题 SSH Orchestrator： Noah 尝试了 SSH Orchestrator，但遇到了一些问题。需要进一步调查和解决。 博客文章： 建议编写一篇关于 Orchestrator 的博客文章，详细说明其工作原理和使用方法。 三、决定事项 Seabastian Han 将继续解决 Nautilus 升级问题。 其他成员将阅读升级指南并提出意见。 Noah 将继续调查和解决 SSH Orchestrator 问题。 四、后续行动计划 Seabastian Han 在明天解决 Nautilus 升级问题。 其他成员在下周完成升级指南的评审。 Noah 在下周解决 SSH Orchestrator 问题。 五、其他事项 会议讨论了其他一些与 Ceph 相关的问题，但未形成具体决定。 会议结束时，所有参会人员表示对项目进展满意。 关键词： 自动发布、Nautilus、升级指南、SSH Orchestrator、Rook、NFS","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-16:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-04-16_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-16T16:00:00.000Z","updated":"2019-04-16T16:00:00.000Z","comments":true,"path":"2019/04/17/2019-04-16_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/17/2019-04-16_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [未提供具体日期，请补充] 参会人员： [未提供具体名单，请补充] 会议主题： Ceph Crimson项目进展及讨论 会议内容： 1. CFX Austin厨房支持费用问题 项目方要求支付费用以支持Crimson项目的CFX Austin厨房。 讨论了支付方式和费用问题。 2. Crimson项目进展 Crimson项目测试： 已经完成了Crimson项目的测试，测试结果显示性能有所提升。 目前正在集成，预计下周完成。 已完成Crimson编译，并进行了初步测试。 性能优化： 讨论了Crimson项目的性能优化，包括： 执行阶段优化：通过减少参数传递和任务调度，提高性能。 异步编程优化：利用Future和Continuation提高性能。 性能监控： 讨论了性能监控问题，包括： 引入新的性能计数器，用于测量批处理消息的平均大小。 开发人员将实现新的性能计数器。 3. 其他讨论 Crimson项目与经典OSD的兼容性： 讨论了Crimson项目与经典OSD的兼容性问题。 认为Crimson项目与经典OSD的兼容性是重要的。 Crimson项目与BlueStore的集成： 讨论了Crimson项目与BlueStore的集成问题。 认为短期内将采用BlueStore进行集成。 Crimson项目与RBD的集成： 讨论了Crimson项目与RBD的集成问题。 认为Crimson项目与RBD的集成是长期目标。 4. 行动计划 Crimson项目测试： 完成Crimson项目的集成，并进行测试。 性能优化： 继续进行性能优化，提高Crimson项目的性能。 性能监控： 开发新的性能计数器，用于监控Crimson项目的性能。 5. 其他 新同事Ron将加入Crimson项目团队。 讨论了Crimson项目与经典OSD的兼容性问题。 备注： 部分内容涉及Ceph相关技术，如Crimson、BlueStore、RBD等。 会议中使用了部分英文关键词，如Crimson、BlueStore、RBD、Future、Continuation等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-17 :: Ceph Testing meeting","slug":"2019-04-17_-_-_Ceph_Testing_meeting","date":"2019-04-16T16:00:00.000Z","updated":"2019-04-17T16:00:00.000Z","comments":true,"path":"2019/04/17/2019-04-17_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/17/2019-04-17_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要 会议时间： （未提及具体时间） 参会人员： （未提及具体人员） 会议内容： 1. 接口API开发与抽象 - 议题：开发者正在编写接口API，并希望对内部使用的远程进程进行更多的抽象处理。 - 讨论：开发者希望找到一种方法来改善当前接口与Rook的兼容性，并可能需要与其他城市的工作人员进行讨论。 - 决定：开发者将尝试缩小接口范围，并希望下周能够邀请更多人讨论前进的方向。 2. 烟雾测试 - 议题：烟雾测试中存在一些问题，导致测试失败。 - 讨论：测试失败可能与依赖问题或测试套件中不必要的测试有关。 - 决定：需要创建一个新的烟雾测试，该测试将允许在所有系统上运行，并检查关键功能。 - 行动计划：Sam将调查烟雾测试的问题，并尝试修复它们。 3. 部署测试 - 议题：开发者正在尝试在虚拟环境中部署Tito G Pierce，并希望了解如何将其作为PR测试添加到测试套件中。 - 讨论：需要了解如何将测试与OVH集成，并确保测试不会干扰开发环境。 - 决定：开发者将创建一个Redmine工单，并配置VPN连接以进行测试。 4. 其他 - 议题：讨论了系统D和系统B上的测试运行情况，并分析了失败的原因。 - 决定：需要清理烟雾测试，并确保测试在所有系统上运行。 后续行动计划： 开发者将继续开发接口API，并尝试缩小接口范围。 Sam将调查烟雾测试的问题，并尝试修复它们。 开发者将创建一个Redmine工单，并配置VPN连接以进行测试。 需要清理烟雾测试，并确保测试在所有系统上运行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-25:: Ceph Orchestration Meeting","slug":"2019-02-25_-_-_Ceph_Orchestration_Meeting","date":"2019-04-15T16:00:00.000Z","updated":"2019-04-16T16:00:00.000Z","comments":true,"path":"2019/04/16/2019-02-25_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/16/2019-02-25_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议地点： 线上会议 参会人员： 多位Ceph研发人员及相关人员 会议主题： 讨论Ceph相关项目的进展、问题及解决方案。 会议内容： 1. 日志格式标准 讨论了日志格式的标准化问题，建议在日志中包含状态、时间、优先级、子系统信息，并在开头添加前缀以区分不同类型的日志。 讨论了调试日志和集群日志的格式，并提出了将日志格式统一化的建议。 2. Ritchie项目 Ritchie项目的下一步计划是完成所有测试，预计在本周完成，并在之后进行最终发布。 讨论了Ritchie项目的文档编写和安装指南，并提出了编写更详细的文档和安装指南的建议。 3. Nautilus存储系统 讨论了Nautilus存储系统的ARM构建和Debian构建问题。 讨论了NFS Ganesha软件包的构建问题。 讨论了Rook与Nautilus的集成，包括内存自动调优和运行用户权限的调整。 4. Orchestrator 讨论了Orchestrator的功能，包括NFS Inertia、ServiceList等。 讨论了驱动器组规范，包括文件存储的支持和目录选择。 讨论了Orchestrator的文档编写，包括编写安装指南和教程。 5. 其他 讨论了NFS软件包的构建问题。 讨论了Ceph的CI/CD流程。 行动计划： 完成Ritchie项目的测试和发布。 完成Nautilus存储系统的ARM构建和Debian构建。 完成NFS Ganesha软件包的构建。 完成Rook与Nautilus的集成。 完成Orchestrator的功能和文档编写。 优化Ceph的CI/CD流程。 备注： 会议中提到了多个Ceph相关项目的关键词，如Ritchie、Nautilus、Orchestrator、Rook等。 会议中讨论了多个技术问题，包括日志格式、构建问题、集成问题等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-20:: Ceph Orchestration Meeting","slug":"2019-02-20_-_-_Ceph_Orchestration_Meeting","date":"2019-04-15T16:00:00.000Z","updated":"2019-04-16T16:00:00.000Z","comments":true,"path":"2019/04/16/2019-02-20_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/16/2019-02-20_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 未知 参会人员： 未知 会议主题： SSH Orchestrator相关问题及进展 会议内容： SSH Orchestrator问题修复： 昨日出现SSH Orchestrator运行失败的问题，已修复。 QA测试成功后，将进行SSH Orchestrator到Orchestrator的迁移。 开发环境： 分享了开发环境，基于Noah的集中式版本，运行在Ubuntu上，表现良好。 Orchestrator功能改进： 讨论了暂停和恢复命令处理器的执行，以优化Orchestrator性能。 讨论了错误处理，认为在权重方法中返回错误比较困难，建议仅用于操作进度。 CLI模块： 讨论了CLI模块的改进，包括： 添加--weight=false参数，使CLI返回立即。 优化CLI命令的输出格式，使其与完成对象图形相匹配。 其他议题： Tipsy： 修改Tipsy以提供TLS双向认证。 进行删除测试。 DeepSea： 启用DeepSea Orchestrator模块，并在开发环境中配置。 解决了DeepSea部署问题，通过循环检查SEF manager模块是否加载。 行动计划： 完成SSH Orchestrator到Orchestrator的迁移。 优化Orchestrator功能。 优化CLI模块。 完成Tipsy和DeepSea的改进。 备注： 会议中提到了一些关键术语，如SSH Orchestrator、CLI、Tipsy、DeepSea等。 会议讨论了多个议题，涉及Orchestrator的改进和CLI模块的优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-26:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-02-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-15T16:00:00.000Z","updated":"2019-04-16T16:00:00.000Z","comments":true,"path":"2019/04/16/2019-02-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/16/2019-02-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [会议时间] 参会人员： [参会人员名单] 会议内容： 1. Recovery State Machine - 议题：研发人员汇报了关于恢复状态机的最小实现工作，指出许多功能和特性依赖于状态机，且该状态机与scrubber、recovery等特性紧密耦合。 - 讨论：由于状态机的复杂性，预计需要更多时间进行测试和改进。 - 决定：继续推进状态机开发，并计划进行更深入的研究。 2. Ceph集群操作 - 议题：讨论了如何使用现有的OSD进行迁移测试。 - 讨论： - 使用现有的OSD进行迁移测试，需要先准备OSD，然后启动。 - 可以手动执行迁移命令，或者使用提供的图表进行操作。 - 讨论了使用现有OSD进行迁移时的潜在问题，例如错误处理和状态跟踪。 - 决定： - 继续研究使用现有OSD进行迁移的方案，并解决相关问题。 - 计划进行测试，以确保迁移过程顺利。 3. Ceph消息传递 - 议题：讨论了Ceph消息传递的性能优化。 - 讨论： - 消息传递模块已合并一些性能优化，包括协议级别抽象和队列策略优化。 - 讨论了使用CSTAR技术对消息传递模块进行优化的可能性。 - 决定： - 继续研究CSTAR技术对消息传递模块的优化。 - 计划进行性能测试，以评估优化效果。 4. 其他事项 - 议题：讨论了字幕翻译和总结工作。 - 讨论： - 翻译和总结工作进展顺利，但需要进一步优化流程。 - 决定： - 继续优化翻译和总结工作流程。 后续行动计划： Recovery State Machine： 完成状态机的最小实现，并进行测试和改进。 Ceph集群操作： 研究使用现有OSD进行迁移的方案，并解决相关问题。 Ceph消息传递： 继续研究CSTAR技术对消息传递模块的优化。 进行性能测试，以评估优化效果。 字幕翻译和总结： 优化翻译和总结工作流程。 下次会议时间： [下次会议时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-27 :: Ceph Testing meeting","slug":"2019-02-27_-_-_Ceph_Testing_meeting","date":"2019-04-15T16:00:00.000Z","updated":"2019-04-16T16:00:00.000Z","comments":true,"path":"2019/04/16/2019-02-27_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/16/2019-02-27_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： 本次会议主要讨论了Ceph项目中的两个关键议题：依赖库Coverity的测试以及Python 2.7到Python 3的迁移计划。 关键细节及讨论议题： Coverity依赖库测试： 会上提出Python库Coverity dependency的pull request，其中charcoal已批准，但需要进一步测试。 由于依赖库的更改，现有测试可能无法覆盖所有情况，需要新的测试用例。 讨论了如何进行测试，以及如何确保测试覆盖面。 Python 2.7到Python 3的迁移： 由于Python 2.7将不再支持，需要制定迁移计划。 讨论了现有的迁移方案，包括使用Alfredo的补丁来使代码仅在Python 3上运行。 讨论了如何测试迁移后的代码，以确保兼容性和稳定性。 讨论了是否需要将代码拆分为两个部分，以便在迁移过程中逐步进行。 决定事项： 将Coverity依赖库的测试用例添加到pull request中，并确保测试覆盖面。 对于Python 2.7到Python 3的迁移，将使用Alfredo的补丁，并在Nautilus版本发布后进行合并。 需要制定详细的测试计划，以确保迁移后的代码兼容性和稳定性。 后续行动计划： [请填写负责人] 将Coverity依赖库的测试用例添加到pull request中。 [请填写负责人] 跟进Python 2.7到Python 3的迁移进度，并确保测试计划。 [请填写负责人] 与QA团队合作，确保测试覆盖面。 其他事项： 讨论了Custer部署SAP的进展，以及Red Hat会议对项目的影响。 讨论了Python 3兼容性问题，以及如何解决不同库之间的兼容性问题。 备注： 会议中提到的关键术语和英文原文如下： Coverity dependency Tour de suite D code QA Suites T dollars Dettol diamo Custer Python 2.7 Python 3","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-28 :: Ceph Performance meeting","slug":"2019-02-28_-_-_Ceph_Performance_meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-15T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-02-28_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-02-28_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage, Radix, Adams, Igor 等 会议主题： Ceph 项目进展讨论 会议内容： 项目进展： Sage 表示 Nautilus 项目进展顺利，目前团队主要集中在 Nautilus 上。 本周有两个合并的 PR： Radix 提交的从缓冲区列表中移除 radix 的缓冲区（已合并）。 sea-star charred lru 相关的 PR（已关闭，可能转向其他方向）。 一些 PR 更新了 macing messenger 代码，Adams 对其中一些 PR 提出了异议。 goan 发现了 boost CEO 的问题，该问题不支持具有多个参数的函数，这可能会影响 GW。 batch handle send message 的 PR 需要进行更多测试，以验证性能改进。 降低 blue space 分配数量的 PR，关于是否在新位图分配器中实现 discard 特性存在讨论。 VLA 相关的 PR 正在测试和调试中。 Igor 的自动调优 PR 尚未完成，计划在 Nautilus 之后进行。 Igor 的 cash bidding 代码分支实现了更智能的 cash binning 和改进的 blue store trim 策略。 讨论议题： Sage 提出了关于 blue story cash 大小的疑问，认为对于 SSD，默认应为 3GB，而不是 HDD。 经过讨论，Sage 解释了当时设置 SSD 缓存大小为 HDD 的原因，但认为这是一个不好的设计。 目前 Ceph 存在双重缓存的问题，需要进一步改进。 行动计划： 继续推进 Nautilus 项目的开发。 完成未完成的 PR，并解决相关性能问题。 研究并解决双重缓存问题。 备注： 会议中提到了一些 Ceph 相关的关键词，如 Nautilus, radix, macing messenger, VLA, auto-tuning, cash bidding 等。 会议还讨论了 Ceph 的性能优化和缓存策略。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-05:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-03-05_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-15T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-05_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-05_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 未知 会议主题： Ceph分布式存储项目进展、性能测试、代码审查及后续行动计划 会议内容： 1. Ceph分布式存储项目进展 PG状态更新： 讨论了如何更新PG状态，并确保状态被正确报告给管理器。目前，更新后的LPG状态未被报告给管理器，需要进一步测试。 Rados TR通信： 讨论了Rados TR是否能够与主机在Crimson PG上的写请求进行通信。需要确保OSD映射正确，并将请求发送到正确的OSD。 未来承诺与共享承诺： 讨论了在Ceph中如何使用未来承诺和共享承诺来处理请求，并确保请求的顺序正确。 细粒度锁： 讨论了是否可以引入更细粒度的锁来提高性能，并确保数据的一致性。 日志和P锁： 讨论了PG日志恢复和P锁的使用，以及如何确保日志的一致性。 2. 性能测试 性能比较： 讨论了如何进行性能测试，并确保测试结果的准确性。需要考虑消息准备方式和客户端工作模型的影响。 消息准备： 讨论了Crimson消息和FIO消息的准备方式，并确保它们在性能测试中使用相同的方法。 3. 代码审查 FSM PR审查： 讨论了FSM PR的审查进度，并计划在RC阶段结束前完成审查。 其他PR审查： 讨论了其他PR的审查进度，并确保代码的质量和一致性。 4. 后续行动计划 完成PG状态更新和Rados TR通信的测试。 继续性能测试，并确保测试结果的准确性。 审查FSM PR和其他PR，并确保代码的质量和一致性。 考虑引入更细粒度的锁来提高性能。 解决PG日志恢复和P锁的问题。 5. 其他事项 Ceph社区活动： 讨论了Ceph社区活动的进展，并鼓励大家参与。 签证申请： 讨论了签证申请的进展，并提醒大家提前准备材料。 总结： 本次会议讨论了Ceph分布式存储项目的重要进展，并制定了后续行动计划。会议内容涵盖了性能测试、代码审查、细粒度锁、日志和P锁等多个方面，为Ceph项目的持续发展提供了重要支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-11:: Ceph Orchestration Meeting","slug":"2019-03-11_-_-_Ceph_Orchestration_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-15T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-11_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-11_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 参会人员： Travis, Natalie, Jamaica, Dipsy, Sage, Aaron, Sebastian 等 会议主题： Ceph Orchestrator 项目进展及问题讨论 关键细节： Travis 因故缺席会议。 项目进度： Travis 正在处理两个 PR，一个用于内存自动调整，另一个用于使用 miss abuser 运行服务。 Natalie 正在修改 Ansible Runner 服务以支持 TLS。 Sage 正在解决本地化配置选项的问题。 Aaron 正在处理 Nautilus 的发布候选版本。 Sebastian 正在解决 LSM 储存库版本问题。 问题讨论： REST API 访问： 在尝试在仪表板中集成 Surface Cozy 时，出现了一个问题，需要为仪表板提供不验证 SSL 证书的选项。讨论了在服务描述符类中如何存储此类信息，以及是否应该在 Orchestrator 中添加此选项。 TLS 支持： 讨论了在 Orchestrator 中支持 TLS 的必要性，并决定在 Ansible Runner 服务中实现。 LSM 储存库版本： 讨论了将 LSM 储存库的最新版本集成到 SEF 容器镜像中的必要性。 决定事项： Travis 将合并一个关于内存自动调整的 PR。 Natalie 将继续修改 Ansible Runner 服务以支持 TLS。 Sage 将继续解决本地化配置选项的问题。 Aaron 将解决 Nautilus 发布候选版本的问题。 Sebastian 将解决 LSM 储存库版本问题。 后续行动计划： 项目组成员将继续推进各自的工作，并定期在会议中汇报进展。 讨论的问题将根据需要进一步讨论并解决。 关键词： Ceph Orchestrator REST API TLS LSM 储存库 PR 发布候选版本 仪表板 Orchestrator 配置选项 安全性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-07 :: Ceph Developer Meeting","slug":"2019-03-07_-_-_Ceph_Developer_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-07_-_-_Ceph_Developer_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-07_-_-_Ceph_Developer_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [所有参会人员名单] 会议主题： Ceph分布式存储系统改进与讨论 会议内容： 一、自动错误修复 目标：使系统能够自动修复其发现的错误，从而实现更少的手动干预。 讨论内容： 自动修复的适用场景：由于外部因素（如介质错误、宇宙射线）或软件错误引起的错误。 自动修复的限制：除非我们知道如何修复错误，并且不需要从系统中获取任何信息，否则不应自动修复。 自动修复的实现：通过在OSD级别添加错误标志位，并根据错误标志位进行自动修复。 维护OSD级别统计数据：在超级块中添加字段或添加其他对象，以跟踪修复操作。 二、副本池的自动修复 目标：为副本池实现自动修复功能。 讨论内容： 当前实现：仅对记录池支持自动修复。 实现方案：将自动修复功能扩展到副本池，并在深度检查时进行修复。 三、健康警报 目标：根据修复操作的结果，调整健康警报的严重程度。 讨论内容： 修复失败：添加新的PG状态标志，用于表示修复失败。 健康警报级别：根据修复结果，调整健康警报的级别。 四、平衡器模式 目标：为新的OSD设置默认的平衡器模式。 讨论内容： 默认模式：将默认平衡器模式设置为 Crush Compat 模式，使新添加的OSD从零权重开始，逐渐增加权重。 测试与验证：需要对平衡器模式进行测试，以确保其正常工作。 五、容器中的问题 讨论内容： gcore 和 pstack 在容器中不可用。 需要一种方法来获取容器中线程的堆栈跟踪。 可能在容器外部挂载调试工具，例如 GDB。 六、崩溃记录 目标：记录崩溃信息，并生成健康警报。 讨论内容： 崩溃记录：记录崩溃发生的时间、进程、堆栈跟踪等信息。 健康警报：根据崩溃记录，生成健康警报。 重复崩溃：针对重复崩溃的情况，生成更精确的健康警报。 七、媒体错误处理 讨论内容： 对于媒体错误，应尝试自动恢复，并避免崩溃。 可以通过设置特殊的退出代码，来避免系统B尝试重启。 可以记录崩溃报告，并添加注释，以便后续分析。 八、其他 讨论内容： CephCon 会议。 容器中的问题。 后续行动计划： 完成自动修复功能的开发。 实现副本池的自动修复功能。 调整健康警报的严重程度。 测试和验证新的平衡器模式。 解决容器中的问题。 完成崩溃记录功能的开发。 改进媒体错误处理。 备注： 会议中提到的部分关键词，如 \"Crush Compat\"、\"OSD\"、\"PG\"、\"scrub\"、\"deep scrub\" 等，均为 Ceph 分布式存储系统中的关键术语。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-18:: Ceph Orchestration Meeting","slug":"2019-03-18_-_-_Ceph_Orchestration_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-18_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-18_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储项目进展及问题讨论 会议时间： 2023年某月某日 参会人员： Tim、Eric、Dr. Mercer、Nelson等 会议内容： 一、Tipsy Orchestrator模块进展 Tim提到，已经修复了scythe模块在构建过程中重复构建的问题，预计将在大约一个小时后生效。 深海Orchestrator模块的启用等待surf模块的一个修复，该修复已于八天前发布。 需要检查CI环境中的Ceph版本是否包含surf模块的修复，如果包含，则可以合并深海Orchestrator模块。 二、深海Orchestrator模块问题 get inventory函数在深海Orchestrator模块中使用SEF卷时无法正常工作，因为深海尚未合并使用SEF卷的代码。 blinky lights功能代码尚未合并，需要硬件支持进行测试。 三、其他问题 Sephardim输出和库存问题，由于依赖深海模块的某些功能，目前无法合并。 Dr. Mercer提到，需要设置一个会议时间，以便讨论Falcone项目。 Eric提到，正在处理一个关于密度方法的问题，预计本周完成。 四、行动计划 Tim将继续修复Tipsy Orchestrator模块相关的问题。 检查CI环境中的Ceph版本，如果包含surf模块的修复，则合并深海Orchestrator模块。 Nelson将在下周一提供反馈。 设置会议时间，讨论Falcone项目。 Eric将继续处理密度方法问题。 五、关键术语 Tipsy Orchestrator scythe deep-sea Orchestrator SEF volume blinky lights Sephardim density method","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-13 :: Ceph DocuBetter meeting","slug":"2019-03-13_-_-_Ceph_DocuBetter_meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-13_-_-_Ceph_DocuBetter_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-13_-_-_Ceph_DocuBetter_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [所有参会人员名单] 会议主题： Ceph文档更新与改进 会议内容： Sofia的文档更新工作： Sofia分享了她在更新Ceph 10版本文档时的一些方法和评论。 她准备了一些代码片段进行演示，并计划将其推送到仓库供大家评估。 Sofia提到，由于时间有限，她只能完成部分工作，但仍希望对文档进行改进。 她展示了如何使用脚本将master分支上的注释迁移到旧版本分支，并解决冲突。 此外，她还介绍了一个自动化构建文档的脚本，并分享了在开发过程中使用的代码片段。 文档结构： 会议讨论了文档结构的改进，包括添加下拉菜单和改进注释的可读性。 Sofia展示了如何使用JavaScript库添加下拉菜单，并解释了其工作原理。 会议成员对Sofia的工作表示赞赏，并建议将PR拆分成更小的部分，以便更容易管理和合并。 文档协作： 会议讨论了文档协作的问题，包括如何处理文档中的错误和不准确信息。 Sofia建议与Google合作，停止对旧文档的索引。 会议成员建议将文档和开发代码库分开，以便更容易维护。 决定事项： 接受Sofia的PR，并将其合并到Ceph文档中。 将PR拆分成更小的部分，以便更容易管理和合并。 考虑将文档和开发代码库分开，以便更容易维护。 继续改进文档的可读性和结构。 后续行动计划： Sofia将根据会议讨论的内容进一步完善PR。 会议成员将评估PR，并提供反馈。 Ceph文档团队将负责合并PR并更新文档。 其他事项： 会议讨论了Ceph社区的协作问题，并鼓励大家积极参与文档的改进。 会议成员对Sofia的工作表示赞赏，并感谢她的贡献。 关键词： Ceph, 文档更新, PR, 脚本, JavaScript, 下拉菜单, 注释, 可读性, 协作","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-19:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-03-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年某日 参会人员： Joan、Sam、Jim、Kim、Steve等 会议主题： 讨论Ceph分布式存储项目的最新进展，包括性能测试、代码优化、功能开发等。 关键细节： Joan： 在研究Ceph的分布式追踪，并尝试将PG和PD的等待列表建模在辅助工具中。同时，也在研究快照和克隆相关功能。 Kim： 正在修复Crimson消息传递中的问题，并尝试通过测试多个客户端驱动Crimson消息传递来模拟性能测试。 Sam： 在审查FSM（有限状态机）代码，并尝试简化PG对等状态机的实现。 Steve： 正在开发v2协议实现，并尝试将加密和认证功能集成到Crimson消息传递中。 Jim： 正在开发新的测试客户端，用于进行性能测试。 讨论的主要议题： 性能测试： 如何通过多个客户端驱动Crimson消息传递来模拟性能测试。 代码优化： 如何简化PG对等状态机的实现，以及如何利用sISTAR的consume方法来创建对齐的缓冲区。 功能开发： 如何将加密和认证功能集成到Crimson消息传递中。 决定的事项： Joan将继续研究快照和克隆相关功能。 Kim将继续修复Crimson消息传递中的问题，并尝试通过测试多个客户端来模拟性能测试。 Sam将继续审查FSM代码，并尝试简化PG对等状态机的实现。 Steve将继续开发v2协议实现，并尝试将加密和认证功能集成到Crimson消息传递中。 Jim将继续开发新的测试客户端，用于进行性能测试。 后续行动计划： Joan将发送等待列表建模的辅助工具的代码。 Kim将发送修复Crimson消息传递问题的代码。 Sam将发送简化PG对等状态机的代码。 Steve将发送v2协议实现的代码。 Jim将发送新的测试客户端的代码。 其他事项： 会议中提到的一些关键术语和英文原文： Distributed tracing：分布式追踪 FSM：有限状态机 Crimson：Crimson（Ceph的存储驱动） sISTAR：sISTAR（Ceph的存储后端） aligned buffer：对齐缓冲区","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-20 :: Ceph Testing meeting","slug":"2019-03-20_-_-_Ceph_Testing_meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-20_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-20_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要 会议时间： 未知 与会人员： 多名参与者（包括Zach、Sofia团队成员、OVH团队成员等） 会议主题： Ceph分布式存储项目进展、测试环境搭建、新特性讨论、PR审查等 会议关键细节： Pepsi项目： 参与者正在开发Pepsi项目，旨在为openSUSE发行版提供Ceph的部署和测试环境。 目前面临一些问题，如镜像配置错误导致无法登录。 讨论了使用OVH资源进行测试的可能性，并寻求社区成员的帮助。 Ceph测试环境： 讨论了使用Tautology进行Ceph测试的想法，该工具旨在自动化测试流程。 认为Tautology可能是一个有用的工具，可以改进测试过程。 Inspect特性： 讨论了Inspect特性，该特性可以分析Pepsi测试套件并生成测试用例。 认为Inspect特性可以替代describe特性。 PR审查： 讨论了多个PR，包括Pepsi项目的PR和Inspect特性的PR。 参与者对PR进行了审查，并提出了反馈意见。 讨论的主要议题： 如何改进Ceph测试流程。 如何使用Tautology和Inspect特性。 如何解决Pepsi项目中遇到的问题。 决定的事项： 继续使用Tautology和Inspect特性。 尝试使用OVH资源进行测试。 解决Pepsi项目中遇到的问题。 后续行动计划： Zach将继续开发Pepsi项目。 参与者将继续审查PR。 讨论如何使用Tautology和Inspect特性。 其他事项： 讨论了Ceph Nautilus版本的发布。 讨论了Ceph社区会议的安排。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-14 :: Ceph Performance meeting","slug":"2019-03-14_-_-_Ceph_Performance_meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-14_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-14_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目更新与讨论 会议内容： 一、PR更新与讨论 新PR： 一项关于信使应用的PR报告了显著的增长，值得进一步研究。 一项针对异步连接的优化PR，专门优化回环连接。 一项针对MDS的PR，将不必要的标准列表使用转换为标准向量。 一项更新EM时钟的PR，可能包含性能提升。 一项改进对象映射性能的PR。 一项异步信使优化PR，等待知识更新。 一项信使PR，批量处理和发送消息，但性能测试未改善。 一项Rgw性能PR，包含修复和优化。 一项Lib RB多缓存回线程PR，与PR 6.6.7.5有所重叠。 未决PR： 多个信使优化PR，正在持续优化中。 蓝办公室读取周期性丢弃功能和蓝存储PR，可能不会很快落地。 二、性能瓶颈与优化 信使线程： 在低CPU使用场景下，信使线程在日志代码中锁定，消耗大量CPU资源。 考虑减少日志记录，或使用更高效的日志记录方式。 探讨使用自旋锁替换互斥锁的可能性。 对象生命周期与内存管理： 在代码中创建和删除大量临时对象，导致性能开销。 寻找避免创建和删除对象的方法，优化对象生命周期。 三、外部库优化 外部库依赖： 讨论了Ceph对外部库的依赖，特别是加密库。 考虑使用自定义版本的加密库，以获得更好的性能。 讨论了不同平台和硬件对性能的影响。 OpenSSL优化： 探讨了使用OpenSSL异步接口和同步接口对性能的影响。 考虑使用OpenSSL的SSE4.2加速功能。 四、其他讨论 Keystone PKI令牌： 讨论了Keystone PKI令牌的使用，以及可能的替代方案。 考虑使用OpenSSL的CMS支持。 五、后续行动计划 继续跟踪和审查未决PR。 研究信使线程和对象生命周期优化方案。 探索外部库优化方案。 准备Nautilus发布。 六、会议总结 本次会议讨论了Ceph项目的最新进展，包括PR更新、性能瓶颈优化和外部库优化。会议明确了后续行动计划，并确定了下一步工作重点。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-26:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-03-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-14T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-03-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-03-26_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph 分布式存储系统性能优化与 crimson OSD 项目的进展讨论 关键细节： Crimson OSD 项目： 项目进展：已完成初步的 crimson OSD 实现，但仍有部分功能未完善。 性能测试：对比 crimson OSD 与经典 OSD 的性能，发现 crimson OSD 在某些场景下性能更优，但需要进一步优化。 优化方向：减少线程切换，提高指令缓存命中率，优化内存使用。 下一步计划：完成 crimson OSD 的全部功能，进行更全面的性能测试，并与经典 OSD 进行公平的比较。 经典 OSD 优化： 优化方向：提高 CPU 使用效率，减少内存占用。 测试方法：使用 perf stat 工具进行性能分析，观察 CPU 使用率、内存占用等指标。 下一步计划：调整 placement group 的数量，提高经典 OSD 的并行处理能力。 讨论的主要议题： Crimson OSD 性能优化： 如何减少线程切换，提高指令缓存命中率。 如何优化内存使用，减少内存占用。 如何与经典 OSD 进行公平的比较。 经典 OSD 优化： 如何提高 CPU 使用效率。 如何减少内存占用。 如何调整 placement group 的数量。 决定的事项： 完成 crimson OSD 的全部功能。 进行更全面的性能测试，并与经典 OSD 进行公平的比较。 调整 classic OSD 的 placement group 数量，提高其并行处理能力。 使用 perf stat 工具进行性能分析，观察 CPU 使用率、内存占用等指标。 后续行动计划： [请填写后续行动计划，例如：] Crimson OSD 项目负责人：完成 crimson OSD 的全部功能，并进行性能测试。 Classic OSD 项目负责人：调整 classic OSD 的 placement group 数量，并进行性能测试。 全体成员：关注 crimson OSD 和 classic OSD 的性能优化工作，提供反馈和建议。 计算机科学/ceph 相关领域英文原文关键词： crimson OSD classic OSD performance optimization profiling CPU usage memory usage placement group perf stat instruction cache data cache task switching reactor application queue staging benchmarking","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-15:: Ceph Orchestration Meeting","slug":"2019-04-15_-_-_Ceph_Orchestration_Meeting","date":"2019-04-14T16:00:00.000Z","updated":"2019-04-15T16:00:00.000Z","comments":true,"path":"2019/04/15/2019-04-15_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/15/2019-04-15_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Travis, Blaine, Alec, Jeff, 等其他相关人员 会议主题： Ceph 项目进展、Rook 升级测试、Barcelona 会议安排等 关键细节与讨论议题： 1. Orchestrator 与 Rook： Travis 分享了一个 Orchestrator 的视频，展示如何使用命令创建 OSD、更新集群自定义资源，并让 Operator 执行操作。目前，视频中的功能大部分已实现，但仍需进一步测试。 讨论了 Rook 的 CI 问题，目前 CI 构建完全受阻，需要优先修复。 讨论了 Rook 升级过程中遇到的问题，例如从 Mimic 升级到 Nautilus 后，需要运行特定命令才能启用 Messenger，否则 Operator 无法与 Mon 进行通信。 Blaine 提到正在进行的 Rook 升级测试，并计划进行文档更新。 2. Nautilus 版本： 讨论了将 Nautilus 作为默认版本的计划，以便新用户默认使用 Nautilus。 Travis 指出，下一个 Nautilus 版本已被标记，并正在进行 URI 测试，预计将与 Nautilus 的发布点一起合并。 3. Barcelona 会议： 讨论了在 Barcelona 举行会议的可能性，并计划在 Red Hat 巴塞罗那办公室进行面对面的讨论。 计划于周六下午 3:30 后举行会议，持续约 2 小时。 4. 其他议题： 讨论了 Manager Pod 故障的问题，并考虑在 Rook 中运行多个 Manager Pod。 讨论了文档更新，特别是针对 1.0 版本的升级测试和文档。 决定事项： 修复 Rook 的 CI 问题。 继续进行 Rook 的升级测试，并更新文档。 确定 Barcelona 会议的具体时间和地点。 调查 Manager Pod 故障问题。 后续行动计划： Travis 将继续修复 Rook 的 CI 问题。 Blaine 将继续进行 Rook 的升级测试，并更新文档。 相关人员将确定 Barcelona 会议的具体时间和地点。 相关人员将调查 Manager Pod 故障问题。 备注： 会议中提到的部分计算机科学/ceph相关领域英文原文的关键词包括：Orchestrator, Operator, OSD, Mon, Messenger, Rook, CI, Nautilus, Barcelona, Manager Pod 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-10 :: Ceph Testing meeting","slug":"2019-04-10_-_-_Ceph_Testing_meeting","date":"2019-04-11T16:00:00.000Z","updated":"2019-04-11T16:00:00.000Z","comments":true,"path":"2019/04/12/2019-04-10_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/12/2019-04-10_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 未知 会议主题： Ceph 存储集群测试与部署 会议内容： 1. 近期工作回顾 会议回顾了过去几周的工作情况，由于部分成员缺席，对具体工作进展了解有限。 Kiran 分享了在测试环境中的 Rock Orchestrator 部署经验，但未明确其整合方案。 2. Jenkins 测试 目前上游 Jenkins 测试主要依靠 Jenkins Slave 系统自动执行，如 Alfredo 创建的系统。 David Galloway 负责管理 Jenkins 环境。 讨论了如何将测试集成到 Jenkins 中，并触发相关操作。 3. 部署测试 讨论了将测试部署到虚拟机中的方法，包括使用电话设置虚拟机、部署集群和执行测试。 目前上游尚无直接将测试部署到虚拟机中的方案，但可以考虑参考 Jenkins 测试方案。 4. smoke 测试 讨论了 smoke 测试的执行方式，包括在 Jenkins 上运行和针对不同分支执行。 认为在 Jenkins 上运行 smoke 测试可以提供快速反馈，并减少人工干预。 5. 部署测试 讨论了在 OpenStack 上进行部署测试的方法，包括使用 OpenStack API 和创建镜像。 认为需要实现类似功能，以便在测试环境中使用 OpenStack。 6. 其他 讨论了不同测试套件的执行时间，以及如何优化测试流程。 认为需要进一步研究 smoke 测试的执行时间，以便提高测试效率。 后续行动计划： Kiran 将分享 Rock Orchestrator 部署经验。 David Galloway 将介绍 Jenkins 环境设置。 尝试将 smoke 测试集成到 Jenkins 中。 研究在 OpenStack 上进行部署测试的方法。 优化测试流程，提高测试效率。 备注： 会议中涉及部分计算机科学/ceph相关领域英文原文的关键词，如：Rock Orchestrator、Jenkins、smoke 测试、OpenStack 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-11 :: Ceph Performance meeting","slug":"2019-04-11_-_-_Ceph_Performance_meeting","date":"2019-04-11T16:00:00.000Z","updated":"2019-04-12T16:00:00.000Z","comments":true,"path":"2019/04/12/2019-04-11_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/12/2019-04-11_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： 线上会议 参会人员： Aaron, Jason, Sage, Kevin, Adam, 等等（部分人员未出席） 会议内容： 1. 本周新提交的Pull Request (PR): Aaron提交了一个PR，修改了OP Q的工作方式，这可能会改善锁竞争行为并提高性能。目前还在等待性能数据。 LaBarbera团队提交了d1 PR，Jason正在审查，需要通过QA。 Crimson团队提交了性能改进PR，这些改进每周都会定期提交。 Ian的Blue Store后端I/O引擎合并到内核中，这可能会消除一些阻塞行为并提高性能。 一些调试和性能测试工具PR被关闭。 Space Iterator工作已合并到其他PR中，用于分片工作。 OSD内存策略工作未通过测试，需要解决。 Messenger I/O操作PR和对象存储PR可能很快会合并。 2. 本周讨论的主要议题： Priority Cache Manager PR： 本PR已经通过审查，正在等待Patrick再次审查。 内存目标设置： 有用户在OSD中看到大量堆内存使用，但设置的目标内存只有4MB，而实际使用的是6GB。建议用户禁用透明大页。 Blue Store： Blue Store节点在Brock TB块缓存和Blue Store中都会获得双重缓存。希望可以禁用存储Blue Store节点的组合族的块缓存，以避免双重缓存。 对象存储后端： 目前对象存储后端使用的是自定义mm存储工作，Adam正在研究。 性能改进： 一些性能改进工作正在进行中，例如Blue Store和Crimson的性能改进。 3. 决定的事项： 继续关注Aaron的PR，等待性能数据。 审查LaBarbera团队的d1 PR，并确保通过QA。 持续关注Crimson和Blue Store的性能改进工作。 解决OSD内存策略工作的问题。 研究禁用存储Blue Store节点的组合族的块缓存的方法。 4. 后续行动计划： Aaron提供Blue Store PR的性能数据。 Jason完成LaBarbera团队的d1 PR的审查工作。 研究禁用存储Blue Store节点的组合族的块缓存的方法。 Adam提供对象存储后端的研究进展。 继续关注其他性能改进工作。 5. 其他事项： 下周可能会更新SeaStar和Adam的图表工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-27:: Ceph Orchestration Meeting","slug":"2019-03-27_-_-_Ceph_Orchestration_Meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-09T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-03-27_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-03-27_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： Tim, Brooke, Matt, Tomica 等 会议主题： Ceph Orchestrator 模块版本兼容性及测试问题讨论 会议内容： 1. 版本依赖性问题 目前 Ceph Orchestrator 模块与外部 orchestrator 之间存在版本依赖问题，可能导致兼容性问题。 例如，Rook Orchestrator 在 Nautilus 首次模块发布版本中与 Ceph Orchestrator 不兼容。 已知问题：Orchestrator 模块与外部 orchestrator 之间的依赖关系需要解决。 2. 解决方案讨论 版本检查： 在 Orchestrator 模型中添加版本检查机制，确保 Orchestrator 模块与外部 orchestrator 版本兼容。 例如，使用 Ana status 18 方法检查 Orchestrator 模型状态，并警告使用不稳定版本。 在各个模块内部实现版本检查，确保与对应 manager 模块兼容。 测试： 在 Rook CI、DeepSea CI 等环境测试 Orchestrator 模块，确保与外部 orchestrator 版本兼容。 进行 smoke test 测试 Orchestrator 模块功能。 在生产环境中，GUI 应防止更改外部 orchestrator 导致的问题。 3. 行动计划 Tim： 持续跟进 Orchestrator 模块的版本兼容性问题。 修复相关 bug，并提交 pull request。 Brooke： 研究解决版本依赖问题的方案。 Matt： 在 DeepSea 中部署 Orchestrator 模块，并打印出 IceCozy 和 Ganesha 端点 URL。 Tomica： 解决 Ansible 运行服务的问题，并修复相关 bug。 4. 其他 Tim 遇到音频连接问题，会议中部分内容可能存在遗漏。 备注： 本次会议讨论了 Ceph Orchestrator 模块的版本兼容性及测试问题，并提出了相应的解决方案和行动计划。 需要进一步测试和验证解决方案的有效性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-03-28 :: Ceph Performance meeting","slug":"2019-03-28_-_-_Ceph_Performance_meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-09T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-03-28_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-03-28_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 未知 参会人员： 未知（可能包括Ben、Adam、Casey等人） 会议主题： Ceph RGW性能优化与相关议题讨论 会议内容： RGW性能优化： Ben提到正在进行与Beast和SEO相关的异步工作，并进行了大量的重构工作以支持云服务。 讨论了QoS（服务质量）主题，特别是多站点环境下bucket动态重启的问题，这是一个难题，但Ben已经找到了一个设计方案。 讨论了CPU资源限制和加快RGW速度的问题。目前RGW的线程池默认为512个线程，但这可能不可持续。Ben认为减少线程数量可以减少内存消耗和上下文切换开销。 讨论了性能测量方法，包括使用wall clock profiler工具进行性能分析。 讨论了nvme驱动和RBD对性能的影响，以及压缩技术对RGW性能的影响。 其他议题： Ben提到默认使用debug Amos zero而不是debug iboga miss one。 讨论了librettos库中用于禁用blue store压缩的flag。 决定事项： 推进RGW性能优化工作，包括异步重构、QoS优化、减少线程数量等。 使用wall clock profiler工具进行性能分析。 默认使用debug Amos zero。 后续行动计划： Ben将继续推进RGW性能优化工作。 其他参会人员将根据各自职责推进相关工作。 备注： 会议中提到了Ceph RGW、Beast、SEO、QoS、nvme、RBD、librettos等关键词。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-02:: Crimson SeaStor OSD Weekly Meeting","slug":"2019-04-02_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-09T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-04-02_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-04-02_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Kamijo Schoen, Ricardo, Dock, 其他研发人员 会议主题： Crimson存储性能测试及改进方案讨论 关键细节： Kamijo Schoen汇报了Crimson存储性能测试结果，与经典存储相比，Crimson在4K随机读取方面性能提升约50%-60%。 测试结果显示，Crimson在处理小数据块时表现良好，但在处理大数据块时性能有所下降。 Kamijo Schoen指出，Crimson的性能瓶颈可能与日志记录和资源监控（如等待激活状态）有关。 会议讨论了Crimson与经典存储在架构上的差异，并强调避免重复经典存储的错误。 讨论的主要议题： Crimson性能提升： Kamijo Schoen分享了Crimson在4K随机读取方面的性能提升，并建议进一步测试和验证。 会议讨论了Crimson在处理不同类型数据时的性能表现，并分析了性能瓶颈的可能原因。 性能瓶颈分析： 会议分析了Crimson在日志记录和资源监控方面的性能瓶颈，并提出了改进方案。 Kamijo Schoen建议使用帧指针支持进行性能分析，并建议关注等待激活状态和资源监控。 架构差异： 会议讨论了Crimson与经典存储在架构上的差异，并强调了避免重复经典存储错误的重要性。 会议建议在巴塞罗那会议上讨论Crimson的宏观模块结构。 决定的事项： Kamijo Schoen将继续测试Crimson，并尝试优化性能。 会议建议使用帧指针支持进行性能分析，并关注等待激活状态和资源监控。 会议建议在巴塞罗那会议上讨论Crimson的宏观模块结构。 后续行动计划： Kamijo Schoen将优化Crimson性能，并尝试解决性能瓶颈。 会议将关注Crimson的架构设计，并避免重复经典存储的错误。 会议将在巴塞罗那会议上讨论Crimson的宏观模块结构。 备注： 会议中提到的关键术语包括：Crimson存储、经典存储、4K随机读取、日志记录、资源监控、帧指针支持、宏观模块结构等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-03 :: Ceph Testing meeting","slug":"2019-04-03_-_-_Ceph_Testing_meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-09T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-04-03_-_-_Ceph_Testing_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-04-03_-_-_Ceph_Testing_meeting/","excerpt":"","text":"会议纪要： 会议时间： 未知 参会人员： 未知（提及Gregory、Rick、Zach、Yuri等） 会议主题： Ceph分布式存储项目进展、代码审查流程、测试环境搭建、Python版本支持等 会议内容： Gregory出席情况： 今日会议未提及Gregory的出席情况，需进一步确认。 代码审查流程： 当前代码审查流程耗时过长，从请求到反馈需要数周时间。 GitHub支持请求代码审查的功能，但参与者响应缓慢。 建议提高代码审查的积极性，建立定期会议和测试周，鼓励参与者积极参与。 测试环境搭建： 目前缺乏统一的测试环境，需运行不同API的测试。 已有测试套件支持Ubuntu，但CentOS版本存在问题。 需要改进内部工具，实现自动上传镜像和运行测试。 Python版本支持： 讨论了Ceph项目对Python 3的支持，需明确支持的版本。 需要增加代码检查器，确保代码兼容性。 行动计划： 加大会议参与度，提高代码审查效率。 完善测试环境，确保不同API的测试运行。 明确Python版本支持，并增加代码检查器。 后续行动： 确认Gregory的出席情况。 推动代码审查流程的改进。 搭建统一的测试环境。 明确Python版本支持，并增加代码检查器。 备注： 会议中提及了Ceph项目的一些关键词，如：CPM、look into tautology、cold rooks、cube spray、PR、pull request、CI、PR测试、Python版本支持等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-01:: Ceph Orchestration Meeting","slug":"2019-04-01_-_-_Ceph_Orchestration_Meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-09T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-04-01_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-04-01_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 8月某日（具体日期未知） 参会人员： 多位Ceph研发人员及字幕翻译人员 会议主题： 讨论Ceph项目进展、问题及解决方案 关键细节： 会议安排： 由于其他会议的重要性，原定于周六的Ceph on 2009会议可能无法进行。会议参与者将关注SAGE会议，并考虑在晚些时候安排面对面会议。 系统命名服务变更： 会议讨论了Hamill重构的进展，该重构需要根据新评论进行更新。这将对LM工作产生影响，因此需要优先处理。 Rook项目进展： 讨论了Rook的CI和CSI支持，以及如何支持外部集群。 讨论了Rook的版本管理，决定在CID版本变更时更新CRT版本。 讨论了Rook与Toothpick的集成，以及如何支持Rook在Toothpick上的运行。 CI问题： 讨论了CI效率低下的问题，以及如何改进CI。 讨论了CI维护人员不足的问题，并计划在下周社区会议上提出。 讨论了如何增加CI覆盖范围，以及如何利用Susie的资源。 主要议题： 系统命名服务变更 Rook项目进展 CI问题 决定的事项： 优先处理Hamill重构。 更新Rook的CI和CSI支持。 优化Rook的版本管理。 改进CI效率。 解决CI维护人员不足的问题。 增加CI覆盖范围。 后续行动计划： 更新Hamill重构。 完成Rook的CI和CSI支持。 优化Rook的版本管理。 改进CI效率。 解决CI维护人员不足的问题。 增加CI覆盖范围。 在下周社区会议上提出CI问题。 其他： 会议讨论了Rook与Person 3的兼容性。 会议讨论了Rook与Terraform的集成。 关键词： Ceph Rook CI CSI CI Toothpick Person 3 Terraform","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-09:: Ceph Orchestration Meeting","slug":"2019-04-09_-_-_Ceph_Orchestration_Meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-09T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-04-09_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-04-09_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： [列出参会人员，包括缺失的Travis、Gemma Guerra、Jeff等] 会议主题： Ceph存储项目更新、Rook相关议题、面对面会议安排 会议内容： 1. Rook支持版本更新 - 讨论了将Nautilus加入Rook支持的版本列表，目前Nautilus已包含在支持版本中。 - 提问是否有遗漏的版本或是否可以合并PR，目前没有发现重大问题。 2. Ceph升级自动化 - 讨论了从Mimic到Nautilus的升级流程自动化问题，目前尚未明确是否在范围内。 - 提出需要自动化升级过程中的问题路由，并确认默认情况下应能处理主版本间的过渡。 3. Rook系统命名空间变更 - 讨论了Rook系统命名空间变更的PR（2720），需要Travis和Jeff的审查。 - 提出如果有人可以审查该PR，则可以加快审查速度。 4. Rook Orchestrator集成测试 - 分享了Rook Orchestrator的集成测试，已创建新的仓库以便审查。 - 请求反馈，以确保测试在开发环境中有效，并讨论了测试的潜在用途。 5. 面对面会议安排 - 由于未来不会有来自美国的参会者，会议将转变为小型会议。 - 讨论了在巴塞罗那举行面对面会议的可能性，建议在周六举行，以便与Sato的会议时间错开。 行动计划： 等待Travis对PR的审查结果。 审查Rook Orchestrator的集成测试，并提供反馈。 确定巴塞罗那面对面会议的具体日期和时间。 继续跟进Ceph升级自动化和Rook系统命名空间变更的PR。 备注： 会议中提到了“whip”和“sea ice passing plane”，但具体内容未详细讨论。 会议中提到了“quickfires review”，可能是指快速审查流程。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-04-04 :: Ceph Performance meeting","slug":"2019-04-04_-_-_Ceph_Performance_meeting","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-08T16:00:00.000Z","comments":true,"path":"2019/04/09/2019-04-04_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/2019-04-04_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Erratic、Mike、Radek、Igor、Sage、Casey、Jason Bell等 会议主题： Crimson性能测试、蓝店存储压缩、RocksDB更新等 会议内容： 一、Crimson性能测试 Erratic介绍了Crimson性能测试的最新进展，包括两种随机场景的测试结果：一种是大分支用于EM，另一种是4k用于大机会。测试结果显示，在处理大块数据时，Crimson性能显著低于经典OSD，但在处理小块数据时，两者之间存在显著差异。 Erratic提到，他在测试中使用了基于性能的剖析工具，并发现CPU占用率较高。他建议对性能进行优化，并尝试通过添加帧指针来解决问题。 Mike和Erratic讨论了性能瓶颈，并发现CPU前端存在瓶颈，导致CPU占用率较高。他们计划在单线程中继续进行基准测试，以进一步提高性能。 二、蓝店存储压缩 Igor对蓝店存储压缩进行了测试，发现压缩功能在大型写入操作中会显著降低性能。但在某些情况下，压缩功能可以提高小块顺序读取的性能。 Igor建议对压缩功能进行更深入的研究，并尝试通过剖析来找出性能瓶颈。 三、RocksDB更新 Radek介绍了RocksDB的最新更新，包括对范围删除的支持。他建议对RocksDB进行进一步调查，以确定是否可以解决性能问题。 Sage分享了Toshiba对RocksDB的分支，该分支仅对索引进行压缩，从而显著降低了I/O开销。他建议进一步研究该分支，并考虑将其作为潜在解决方案。 四、其他讨论 会议还讨论了其他一些主题，包括自动调整MDS缓存内存限制、边界代码优化、RaxDB和删除范围等。 后续行动计划： 继续优化Crimson性能，特别是处理大块数据时的性能。 对蓝店存储压缩进行更深入的研究，并尝试提高其性能。 调查RocksDB的最新更新，并考虑将其作为潜在解决方案。 对RaxDB进行进一步调查，以确定是否可以解决性能问题。 总结： 本次会议主要讨论了Crimson性能测试、蓝店存储压缩和RocksDB更新等内容。会议确定了后续行动计划，并鼓励团队成员继续努力提高Ceph的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"April 2019 :: Ceph Developer Monthly","slug":"April_2019_-_-_Ceph_Developer_Monthly","date":"2019-04-08T16:00:00.000Z","updated":"2019-04-08T16:00:00.000Z","comments":true,"path":"2019/04/09/April_2019_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/04/09/April_2019_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： - Adam（负责内存目标选项） - Shirred（负责内存目标选项） - Val（负责监控内存目标） - Mocha（负责蓝店内存管理） - Steve（负责OSD缓存） - Sebastian（负责Orchestrator） - Patrick（负责Orchestrator） - Dan（负责监控内存目标） - Jason（负责RBD MBD） - Neha（负责Octopus） - Mike（负责RBD MBD） - 其他相关人员 会议主题： 监控内存目标： 讨论了为监控设置内存目标选项的需求，类似于USD中的内存目标选项。 讨论了在蓝店中实现内存目标选项的现有方法，并考虑将其复制到监控中。 讨论了使用优先级缓存接口来管理不同内存缓存的需求。 决定由Shirred负责实现内存目标选项，并更新配置选项。 Orchestrator： 讨论了不同Orchestrator的实现现状，包括Ansible、Baroque、Kubernetes和DeepSea。 讨论了在Barcelona Ceph会议上讨论Orchestrator路线图的计划。 讨论了DeepSea和SSH Orchestrator的未来方向。 讨论了使用SSH Orchestrator进行初始化部署的方案。 遥测： 讨论了遥测模块的功能和用途。 讨论了从遥测数据中生成有用报告的需求，例如集群大小分布、安装版本分布和崩溃报告。 讨论了使用Qivana和Kibana等工具进行数据分析和可视化。 决定由End开发有用的报告，并考虑使用Qivana进行交互式查询。 RBD MBD： 讨论了RBD MBD在Kubernetes环境中的集成和优化。 讨论了使用RBD MBD CLI进行操作的需求。 讨论了在单个RBD MBD守护进程中支持多个RBD连接的需求。 讨论了使用网络接口动态添加和删除块设备的需求。 决定由Mike负责改进RBD MBD与Kubernetes的集成。 Octopus： 讨论了Octopus的待办事项列表，包括在线响应、内存优化、克隆、恢复和审计。 讨论了将部分恢复和易于恢复的功能合并到Octopus的需求。 讨论了优先级恢复和自适应恢复的需求。 讨论了将Toshiba的RocksDB Roadmap集成到Ceph的需求。 后续行动计划： Shirred实现内存目标选项并更新配置选项。 Sebastian和Patrick整理Orchestrator路线图，并在Barcelona Ceph会议上讨论。 End开发有用的遥测报告。 Mike改进RBD MBD与Kubernetes的集成。 Neha和团队完成Octopus的待办事项列表。 Adam和团队评估Toshiba的RocksDB Roadmap，并考虑集成。 其他事项： 讨论了Ceph社区的贡献和代码审查流程。 讨论了Ceph项目的长期发展方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-19:: Crimson SeaStor/OSD Weekly Meeting","slug":"2019-02-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting","date":"2019-02-23T16:00:00.000Z","updated":"2019-02-23T16:00:00.000Z","comments":true,"path":"2019/02/24/2019-02-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/24/2019-02-19_-_-_Crimson_SeaStor_OSD_Weekly_Meeting/","excerpt":"","text":"会议纪要 会议时间： （请在此处填写会议时间） 参会人员： Nonnie Riddick Delius Bulai Sepia Michael Greg 其他相关人员 会议内容： 1. 新的帧格式及加密协议： Nonnie Riddick介绍了新的消息协议和帧格式，并讨论了使用加密协议的可行性。 会议决定在内部测试加密协议，并考虑使用更友好的加密协议。 2. Ceph 集群状态： Bulai和Sepia报告了Ceph集群的状态，包括心跳支持和消息地址。 会议讨论了地址错误和连接问题，并决定在Chrome更新中修复这些问题。 3. 内存存储和恢复机制： Nonnie Riddick提到，在内存存储和恢复机制方面，需要至少部分支持早期激活PG。 会议讨论了使用队列和优先级来支持请求，并决定进一步研究这个问题。 4. OSD 架构和任务消费： 会议讨论了OSD架构和任务消费模型，包括PG和OSD请求的处理。 决定在Crimson上进行POC测试，并考虑使用现有的OS层概念和RPG层。 5. 性能优化和微基准测试： 会议讨论了性能优化和微基准测试的重要性，并决定进行更多研究。 决定在Reactor中进行微基准测试，以评估不同方案的性能。 6. 社区讨论和反馈： 会议鼓励将讨论和想法提交到社区列表，以获得更多反馈。 决定将设计讨论和问题提交到社区列表，以寻求更多意见和建议。 7. 其他事项： 讨论了Crimson和SISTAR的兼容性，并决定进行更多测试。 讨论了漫游管理器和性能优化，并决定在后续版本中实现这些功能。 后续行动计划： 进一步研究加密协议和队列优先级问题。 在Crimson上进行POC测试，评估不同方案的性能。 将设计讨论和问题提交到社区列表。 进行更多微基准测试，以评估性能优化方案。 实现漫游管理器和性能优化功能。 关键词： 分布式存储 Ceph 加密协议 内存存储 恢复机制 OSD架构 任务消费 性能优化 微基准测试 社区讨论","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-11 :: Ceph Orchestration Meeting","slug":"2019-02-11_-_-_Ceph_Orchestration_Meeting","date":"2019-02-21T16:00:00.000Z","updated":"2019-02-22T16:00:00.000Z","comments":true,"path":"2019/02/22/2019-02-11_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/22/2019-02-11_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： [请在此处列出参会人员姓名] 会议主题： 分布式存储Ceph项目会议 会议内容： 一、会议纪要 会议纪要损坏问题： 上次会议的会议纪要损坏，怀疑是因为多人同时编辑导致的。已恢复，但格式略有损失。 面对面会议安排： 下次面对面会议将于3月至6月期间举行，地点在布尔诺或纽伦堡，具体时间将通过Doodle投票确定。 设备清单刷新： 讨论了在Rook和DeepSea等 orchestrator 中触发设备清单刷新的问题。决定提供一个刷新标志，但不会在Rook或DeepSea中实现缓存，以便在需要时获取最新清单。 Cats实现： 讨论了为所有 orchestrator 实现Cats（缓存）的可行性。决定将Cats作为一个服务实现，并在需要的时候使用，而不是强制要求每个操作都使用Cats。 库存过滤器标签： 讨论了是否应该在库存过滤器中使用标签。决定将标签保留在orchestrator中，但不会在通用接口中使用，以避免与Rook和Ceph的标签使用冲突。 添加/删除主机： 讨论了是否应该在orchestrator接口中保留添加/删除主机的功能。决定保留该功能，因为某些 orchestrator（如DeepSea）可能需要它。 Rook问题： 讨论了Rook在创建OSD时出现的问题。Sebastian Han正在调查这个问题。 OpenShift安装器： 讨论了使用OpenShift安装器部署Ceph的问题。决定调查使用Ansible Runner Service的Ansible实现。 二、行动计划 Sebastian Han调查Rook创建OSD时出现的问题。 探索使用Ansible Runner Service的Ansible实现。 确定下次面对面会议的时间和地点。 三、其他事项 会议纪要已上传到会议笔记垫。 请参会人员检查会议笔记垫，并提供任何补充信息或意见。 四、会议总结 本次会议讨论了Ceph项目的多个重要议题，并制定了相应的行动计划。会议取得了积极成果，为项目的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-12:: Crimson SeaStor/OSD Meeting","slug":"2019-02-12_-_-_Crimson_SeaStor_OSD_Meeting","date":"2019-02-21T16:00:00.000Z","updated":"2019-02-22T16:00:00.000Z","comments":true,"path":"2019/02/22/2019-02-12_-_-_Crimson_SeaStor_OSD_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/22/2019-02-12_-_-_Crimson_SeaStor_OSD_Meeting/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 1. 代码支持与测试 心跳支持： 项目成员提到上周主要在支持心跳功能，目前代码已完成，但尚未经过测试。 消息传递支持： 项目成员正在工作于消息传递支持，但遇到了一些挑战，包括代码耦合性和编译错误。 PE支持： 会议中讨论了PE（Placement Engine）支持的相关问题，包括如何处理消息和连接。 2. PR审查与讨论 RFC PR： 会议中提到一个RFC PR，需要项目成员审查。 arau PR： 另一个由arau提交的PR已经由red oak审查。 3. 代码重构与优化 代码重构： 项目成员提到正在尝试重构代码，以解决一些复杂的逻辑和条件检查。 代码审查： 需要更多的代码审查和讨论，以确保代码质量和可维护性。 4. 下一阶段工作计划 代码测试： 完成代码测试，确保功能正常。 代码审查： 继续进行代码审查，优化代码质量和可维护性。 社区参与： 邀请社区成员参与代码审查和讨论。 5. 其他 虚拟消息传递： 讨论了虚拟消息传递的实现，包括抽象类和协议版本。 下周计划： 下周将进行代码审查和讨论，并邀请社区成员参与。 行动计划： 完成代码测试。 继续进行代码审查和讨论。 邀请社区成员参与代码审查和讨论。 完成虚拟消息传递的实现。 备注： 会议中提到了一些计算机科学/ceph相关领域的英文关键词，如PE、PG、OSD、message、connection、RFC、PR等。 会议中讨论了一些技术细节，可能需要进一步学习和了解。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-18:: Ceph Orchestration Meeting","slug":"2019-02-18_-_-_Ceph_Orchestration_Meeting","date":"2019-02-21T16:00:00.000Z","updated":"2019-02-22T16:00:00.000Z","comments":true,"path":"2019/02/22/2019-02-18_-_-_Ceph_Orchestration_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/22/2019-02-18_-_-_Ceph_Orchestration_Meeting/","excerpt":"","text":"会议纪要： 会议时间： [具体日期] 会议地点： [具体地点] 参会人员： [列出参会人员名单] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 1. 错误处理进展 - 项目成员汇报了上周错误处理的进展，已根据反馈进行了改进，命令行界面和异常定义方面均有提升。 - 提出在SAP解释器中传递异常并正确捕获的问题，建议使用pickle和unpickle异常。 - 希望得到更多关于最终实现的反馈。 2. SSH Orchestrator进展 - 汇报了添加Toulouse里程碑到SSH Orchestrator的进展，希望尽快合并。 - 讨论了测试模块的依赖问题，由于依赖包未在Ubuntu上提供，测试无法进行。 - 决定先合并Ansible的pull request，确保测试通过，然后再解决依赖问题。 3. Ceph状态Orchestrator - 报告了Ceph状态Orchestrator的进展，在Ubuntu上部署成功。 - 讨论了Rook的PR，包括主机标签设置和节点亲和性等问题。 - 决定先合并PR，解决兼容性问题，然后再讨论更复杂的特性。 4. Nautilus 41.0和Rook - 讨论了Nautilus 41.0和Rook的集成测试，将在Messenger 2 PR合并后进行。 - 报告了Rook模块Orchestrator模块加载问题的解决进展，预计明天将进入稳定版本。 - 讨论了Ganesha实例的扩展和收缩，以及NFS更新等问题。 5. 其他 - 讨论了集成测试平台，包括使用bootstrap集群和Behave进行测试。 - 讨论了SSH Orchestrator在OpenSUSE上的测试进展。 行动计划： 项目成员继续改进错误处理和SSH Orchestrator。 解决Rook模块的依赖问题。 合并Ceph状态Orchestrator和Nautilus 41.0的PR。 进行Nautilus 41.0和Rook的集成测试。 完成Ganesha实例的扩展和收缩，以及NFS更新。 推进集成测试平台的开发。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，如SAP interpreter, pickle, unpickle, Kubernetes, node affinity, Nautilus, Rook, Ganesha等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"February 2019 :: Ceph Developer Monthly","slug":"February_2019_-_-_Ceph_Developer_Monthly","date":"2019-02-13T16:00:00.000Z","updated":"2019-02-14T16:00:00.000Z","comments":true,"path":"2019/02/14/February_2019_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/14/February_2019_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储系统及相关服务讨论 会议内容： 一、主要议题 外部服务集成： 讨论如何将外部服务（EDS）集成到Ceph系统中，以支持演员服务，并提升用户体验。 架构设计： 探讨Ceph系统架构，包括组件、接口和实现方式。 功能扩展： 讨论Ceph系统的功能扩展，如环境健康监测、NFS管理、命令行接口等。 性能优化： 分析Ceph系统的性能瓶颈，并探讨优化方案。 文档和社区建设： 讨论Ceph文档的更新和国际化，以及社区建设计划。 二、关键细节 外部服务集成： 通过EDS将外部服务集成到Ceph系统中，支持演员服务，提升用户体验。 架构设计： 使用抽象接口实现组件之间的通信，并支持不同的实现方式。 功能扩展： 环境健康监测：使用Rock Orchestra模块连接到执行环境，并执行相关操作。 NFS管理：使用NFS网关管理NFS导出，并支持命令行接口。 命令行接口：支持使用命令行工具管理Ceph系统。 性能优化： 分析Ceph系统的性能瓶颈，并探讨优化方案。 文档和社区建设： 更新Ceph文档，并支持国际化。 拓展社区，吸引更多开发者参与。 三、决定事项 推进EDS集成项目，提升用户体验。 优化Ceph系统架构，支持更多功能。 优化Ceph系统性能，提高效率。 更新Ceph文档，并支持国际化。 拓展社区，吸引更多开发者参与。 四、后续行动计划 EDS集成项目组： 负责EDS集成项目的开发、测试和部署。 架构优化组： 负责Ceph系统架构的优化和改进。 性能优化组： 负责Ceph系统性能的分析和优化。 文档组： 负责Ceph文档的更新和国际化。 社区组： 负责拓展社区，吸引更多开发者参与。 五、备注 会议中提到的一些关键词，如“Ceph”、“Rock Orchestra”、“NFS”、“EDS”等，在后续工作中需要重点关注。 会议中提出的一些问题和建议，需要在后续工作中进一步讨论和落实。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-02-06 :: Ceph Testing Weekly","slug":"2019-02-06_-_-_Ceph_Testing_Weekly","date":"2019-02-05T16:00:00.000Z","updated":"2019-02-06T16:00:00.000Z","comments":true,"path":"2019/02/06/2019-02-06_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/06/2019-02-06_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph 项目进展及 Summer of Code 项目讨论 会议内容： 一、Ceph 项目进展 PR 检查： 会议参与者提到需要重新审视一个与 GW 2011 文档相关的 PR，该 PR 存在一些问题，需要进一步调查原因。 另一个与 tooth ology 相关的任务也存在一些输出问题，需要解决。 Summer of Code 项目： 会议讨论了 Google Summer of Code (GSoC) 和 Outreachy 项目，以及如何为实习生提供项目机会。 讨论了如何吸引学生的兴趣，包括简化申请流程，确保申请者具备基本的 Linux 和 Python 编程能力。 讨论了如何通过小规模的项目来评估学生的能力，并为他们提供更多与导师互动的机会。 二、讨论议题 tooth ology： 讨论了 tooth ology 项目的进展，目前 Zach 和 Nathan 正在研究，但尚未进行实际代码修改。 讨论了如何为学生提供与 tooth ology 相关的项目机会。 Orchestrator： 讨论了 Orchestrator 的测试和发布问题。 认为目前 Orchestrator 的测试不足，不建议发布未经测试的代码。 讨论了将 Orchestrator 代码打包到点版本发布中的可能性。 三、行动计划 PR 检查： 重新审视与 GW 2011 文档相关的 PR，找出问题并解决。 解决 tooth ology 任务的输出问题。 Summer of Code 项目： 在网站上发布更多项目，吸引更多学生的参与。 简化申请流程，确保申请者具备基本的技能。 通过小规模项目评估学生的能力。 Orchestrator： 继续测试 Orchestrator，确保其稳定性和可靠性。 考虑将 Orchestrator 代码打包到点版本发布中。 四、其他事项 参会者表示将在会议结束后继续关注项目进展，并提出更多想法和建议。 五、会议总结 本次会议主要讨论了 Ceph 项目的进展和 Summer of Code 项目的相关事宜。会议明确了下一步的工作计划，并鼓励参会者积极提出建议和想法。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-01-31 :: Ceph Performance meeting","slug":"2019-01-31_-_-_Ceph_Performance_meeting","date":"2019-02-03T16:00:00.000Z","updated":"2019-02-04T16:00:00.000Z","comments":true,"path":"2019/02/04/2019-01-31_-_-_Ceph_Performance_meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/04/2019-01-31_-_-_Ceph_Performance_meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： Sage, Ma Jian Pang, Cruising, Radek, Keefe, Braddock, Adam, Casey, Nick, Matt, French, etc. 会议主题： 确认和讨论Ceph分布式存储项目中的最新进展和问题。 讨论Ceph在容器工作负载中的性能问题，特别是创建文件系统时的延迟。 探讨Ceph-RBD的性能和未来发展方向。 关键细节和讨论议题： Ma Jian Pang的批量处理和发送消息工作： Sage表示对这项工作表示赞赏，并希望尽快进行测试。 memstore优化： Radek正在开发一个名为Science Star的memstore变体，旨在消除不必要的锁定和原子操作，并利用Crimson测试阶段的特性。与会者对此表示兴奋，并期待进一步的进展。 IObject集成： Adam正在将IObject集成到RGW中，以优化性能。与会者建议将RGW特定的更改拆分为单独的PR。 性能问题： Nick报告了在创建文件系统时遇到的问题，特别是在使用XFS的情况下。与会者讨论了可能的解决方案，例如将零填充转换为丢弃操作。 Ceph-RBD性能： Nick正在重新编写FIO CBT基准测试，以简化测试过程并提高效率。与会者讨论了Ceph-RBD的不同实现，包括RBD fuse和TCM。 决定的事项： Sage将尝试测试Ma Jian Pang的工作。 Radek将继续开发Science Star。 Adam将集成IObject到RGW。 Nick将重新编写FIO CBT基准测试。 讨论将关于操作和SMDs的讨论主题添加到下周会议议程。 后续行动计划： Sage、Radek、Adam和Nick将继续他们的工作。 将讨论操作和SMDs的议题添加到下周会议议程。 尝试使用其他文件系统（如ext4和XFS）来避免XFS的延迟问题。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，例如： batch handling send message memstore crimson science star intrusive data structures RGW IObject XFS Ceph-RBD FIO CBT benchmarks","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-01-29 :: Crimson SeaStor/OSD Meeting","slug":"2019-01-29_-_-_Crimson_SeaStor_OSD_Meeting","date":"2019-02-03T16:00:00.000Z","updated":"2019-02-04T16:00:00.000Z","comments":true,"path":"2019/02/04/2019-01-29_-_-_Crimson_SeaStor_OSD_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/04/2019-01-29_-_-_Crimson_SeaStor_OSD_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 邮件中未列出具体姓名，但涉及以下议题和讨论： Ceph分布式存储 视频会议字幕翻译和总结 性能优化和代码重构 会议关键细节 议题一：Ceph分布式存储 PGs（Placement Groups）： 讨论了在Ceph集群中创建PGs的细节，包括使用对象存储持久化PGs。 错误处理和修复： 讨论了如何实现错误修复和审查错误日志。 性能优化： 讨论了如何优化Ceph的性能，包括使用多线程、异步通信和队列管理等。 议题二：视频会议字幕翻译和总结 英译中翻译： 讨论了英译中翻译的技巧和注意事项。 总结： 讨论了如何将会议内容进行总结，以便于后续查阅。 议题三：性能优化和代码重构 消息队列： 讨论了使用消息队列来提高系统性能的方案。 Crimson消息框架： 讨论了Crimson消息框架的优缺点，并进行了性能测试。 代码重构： 讨论了如何对现有代码进行重构，以提高代码质量和可维护性。 讨论的主要议题 PGs的持久化： 如何将PGs持久化到对象存储中。 错误处理： 如何实现错误修复和审查错误日志。 性能优化： 如何优化Ceph的性能，包括使用多线程、异步通信和队列管理等。 Crimson消息框架： 如何使用Crimson消息框架提高系统性能。 代码重构： 如何对现有代码进行重构，以提高代码质量和可维护性。 决定的事项 继续推进PGs的持久化工作。 研究错误处理和修复方案。 优化Ceph的性能。 使用Crimson消息框架提高系统性能。 对现有代码进行重构。 后续行动计划 邮件中未列出具体行动计划，但涉及以下内容： 继续推进PGs的持久化工作。 研究错误处理和修复方案。 优化Ceph的性能。 使用Crimson消息框架提高系统性能。 对现有代码进行重构。 评估Crimson消息框架的性能，并与其他方案进行比较。 完成虚拟实施工作。 将代码重构方案提交给团队进行讨论。 其他事项 春节假期： 会议中提到了春节假期，提醒大家合理安排工作和假期。 Crimson消息框架的性能测试： 讨论了Crimson消息框架的性能测试结果，并与其他方案进行了比较。 总结： 本次会议主要讨论了Ceph分布式存储、视频会议字幕翻译和总结以及性能优化和代码重构等议题。会议明确了后续行动计划，并要求团队成员共同努力，提高Ceph的性能和可维护性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-01-20 :: Ceph Testing Weekly","slug":"2019-01-20_-_-_Ceph_Testing_Weekly","date":"2019-02-02T16:00:00.000Z","updated":"2019-02-02T16:00:00.000Z","comments":true,"path":"2019/02/03/2019-01-20_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/03/2019-01-20_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： [未提供具体日期] 会议地点： [未提供] 参会人员： [未提供具体姓名，但提及了Sebastian, Richard, Jessica, Tim, Dan等] 会议主题： Ceph存储系统开发、测试和部署相关讨论 关键细节： Ceph存储系统开发： 有关于Ceph存储系统的一个接口开发正在进行，但由于一些意外情况，进度有所延迟。 讨论了如何简化测试流程，包括使用“calc option”和“dry run”等选项。 讨论了在Ceph集群中运行多个make test命令的可能性，以及如何确保它们在相同的环境中产生相同的输出。 Ceph测试： 讨论了如何验证Ceph Orchestrator的功能，以确保其正常运行。 讨论了如何为Orchestrator编写测试用例，以及如何与其他组件进行集成。 讨论了如何解决Orchestrator与Rook之间的集成问题。 Ceph部署： 讨论了如何使用Rook将Ceph集群部署到Kubernetes或OpenShift等平台。 讨论了如何使用Ansible或其他工具进行Ceph集群的部署和配置。 主要议题： Ceph存储系统接口开发进度 Ceph测试用例编写和验证 Ceph集群部署和配置 决定的事项： 继续推进Ceph存储系统接口开发。 编写和验证Ceph测试用例。 探索使用Rook将Ceph集群部署到Kubernetes或OpenShift等平台。 后续行动计划： Sebastian将继续推进Ceph存储系统接口开发。 Richard将负责编写和验证Ceph测试用例。 Tim将探索使用Rook将Ceph集群部署到Kubernetes或OpenShift等平台。 其他事项： 讨论了OVH云服务的一些变化，以及它们对Ceph集群部署的影响。 讨论了Ceph社区的一些活动，以及如何吸引更多开发者参与。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson Seastar/OSD Meeting 2019-01-22","slug":"Crimson_Seastar_OSD_Meeting_2019-01-22","date":"2019-02-02T16:00:00.000Z","updated":"2019-02-02T16:00:00.000Z","comments":true,"path":"2019/02/03/Crimson_Seastar_OSD_Meeting_2019-01-22/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/03/Crimson_Seastar_OSD_Meeting_2019-01-22/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知（会议记录中未提及具体姓名） 会议主题： Ceph分布式存储系统开发进展及讨论 关键细节： Ceph存储功能开发： 成员讨论了高通过滤支持的开发进展，并表示将工作分支推送到GitHub供他人查看。 讨论了内存存储和对象存储的复制功能，以及对内存存储的优化。 讨论了OSD初始化函数的改进，以及如何将初始化代码从reactor中移除。 讨论了多进程部署模型对OSD映射缓存的影响。 讨论了RBD（Rados Block Device）的性能测试和优化。 讨论了Crimson存储功能开发，包括内存存储的重新实现和对象存储的优化。 讨论了AES加密算法在Ceph中的应用。 Ceph性能优化： 讨论了Crimson存储功能的性能测试和优化。 讨论了多进程部署模型对性能的影响。 讨论了RBD的性能测试和优化。 Ceph代码开发： 讨论了Crimson存储功能的代码开发，包括内存存储的重新实现和对象存储的优化。 讨论了RBD的代码开发，包括性能测试和优化。 讨论了OSD初始化函数的代码开发。 讨论的主要议题： Ceph存储功能开发： 如何优化内存存储和对象存储的性能。 如何改进OSD初始化函数。 如何实现多进程部署模型。 如何优化RBD的性能。 如何实现Crimson存储功能。 Ceph性能优化： 如何提高Ceph的整体性能。 如何优化Crimson存储功能的性能。 如何优化RBD的性能。 Ceph代码开发： 如何改进Ceph的代码质量。 如何实现新的功能。 决定的事项： 将工作分支推送到GitHub供他人查看。 继续优化Crimson存储功能的性能。 优化RBD的性能。 实现Crimson存储功能。 实现AES加密算法在Ceph中的应用。 后续行动计划： 成员将继续优化Crimson存储功能的性能。 成员将继续优化RBD的性能。 成员将继续实现Crimson存储功能。 成员将继续实现AES加密算法在Ceph中的应用。 成员将继续改进Ceph的代码质量。 备注： 会议记录中未提及具体姓名，仅提及了部分成员的昵称。 会议记录中保留了部分计算机科学/ceph相关领域英文原文的关键词，例如：Ceph, OSD, RBD, Crimson, AES, GCM, POSIX, etc.","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph DocuBetter Meeting 2019-01-18","slug":"Ceph_DocuBetter_Meeting_2019-01-18","date":"2019-02-01T16:00:00.000Z","updated":"2019-02-02T16:00:00.000Z","comments":true,"path":"2019/02/02/Ceph_DocuBetter_Meeting_2019-01-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/02/Ceph_DocuBetter_Meeting_2019-01-18/","excerpt":"","text":"会议纪要 会议时间： (未提及具体时间) 参会人员： (未提及具体姓名，但根据对话内容可推断参会人员包括：Ceph 文档团队成员、SEO 专家、项目实习生等) 会议主题： Ceph 文档优化与 SEO 改进 会议内容： 1. 文档结构优化： 问题： Ceph 文档覆盖多个版本，搜索引擎结果可能导致用户误入旧版本文档。 解决方案： 使用 rel canonical 标签指向主版本（如 master）作为标准版本。 考虑使用别名（如 /current）指向最新稳定版本。 自动化文档生成过程，包括生成 rel canonical 标签和 robots.txt 文件。 2. SEO 改进： 问题： 搜索引擎索引了过时的文档版本，导致用户体验不佳。 解决方案： 在 robots.txt 文件中排除旧版本文档（如 bobtail、cuttlefish 等）。 考虑使用白名单而非黑名单，以便搜索引擎仍能索引最新版本。 3. 文档生成自动化： 问题： 文档生成过程依赖人工干预，效率低下。 解决方案： 将文档生成过程集成到 Jenkins 作业中，实现自动化。 利用可读性文件自动创建链接和 rel canonical 标签。 4. 项目实习生： 问题： 需要额外的资源来优化文档和 SEO。 解决方案： 招聘实习生，负责文档编写和生成工作。 实习生参与每周会议，了解项目进展。 5. 其他： JavaScript backboards： 已合并 luminous 和 mimic 版本的 backboards， jewel 版本的 backboards 尚未完成。 行动计划： Ceph 文档团队与 SEO 专家合作，制定详细的文档优化和 SEO 改进计划。 评估 Jenkins 作业，实现文档生成自动化。 与 David Galloway 合作，优化 robots.txt 文件。 招聘实习生，负责文档编写和生成工作。 备注： 会议中提到的部分关键词：SEO、rel canonical、robots.txt、Jenkins、Sphinx、白名单、黑名单、实习生。 总结： 本次会议讨论了 Ceph 文档优化和 SEO 改进的关键问题，并制定了相应的行动计划。通过优化文档结构和搜索引擎优化，将提升用户获取和阅读 Ceph 文档的体验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance meeting 2019-01-17","slug":"Ceph_Performance_meeting_2019-01-17","date":"2019-02-01T16:00:00.000Z","updated":"2019-02-02T16:00:00.000Z","comments":true,"path":"2019/02/02/Ceph_Performance_meeting_2019-01-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/02/02/Ceph_Performance_meeting_2019-01-17/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 参会人员： Casey, Mark, Sage, John, Keith, Haeju, Jason, Peter, Orlando, Radek, Linda, Adrian 会议主题： Ceph 项目进展、问题讨论及后续行动计划 关键细节： Ceph 项目进展： Mark 提到最近在 Minneapolis F Meetup 上了解到 RGW 多站点存在分布式复制问题，数据未能正确复制，可能是静默失败。 Sage 提到最近进行了核心会议，讨论了异步和 RGW 的工作，希望 Nautilus 版本能成为默认选项。 Haeju 开发了一个新命令，可以轻松显示每个 OSD 的存储和网络 Numa 节点，并可以轻松固定。 Jason 正在重新审查代码，以优化缓存和线程。 Sage 提到已将 Cass 开源，并可以将其用于 Ceph。 Adrian 提到正在尝试重新编写 Blue Store，以支持更多存储设备。 问题讨论： Mark 询问 Sage 是否已合并新的 Numa 节点命令。 Sage 回答已合并，并提到该命令可以帮助优化参考架构。 Radek 提到正在尝试获取 Bdev 驱动程序，以支持 NVMe。 Orlando 提到正在尝试获取 Quanta 系统的报价，以获取平衡的 NVMe 系统。 Linda 提到正在尝试解决网络配置问题，以确保数据包正确路由。 Adrian 提到正在尝试获取 Quanta 系统的报价，以获取平衡的 NVMe 系统。 后续行动计划： Sage 将继续关注 RGW 多站点问题。 Haeju 将继续优化缓存和线程。 Jason 将继续审查代码。 Sage 将尝试将 Cass 开源。 Adrian 将尝试重新编写 Blue Store。 Orlando 将尝试获取 Quanta 系统的报价。 Linda 将尝试解决网络配置问题。 计算机科学/ceph相关领域英文原文关键词： RGW multi-site distributed replication OMAP asynchrony rgw Nautilus OSD Numa NVMe Bdev Cass reference architecture network configuration 总结： 本次会议讨论了 Ceph 项目的最新进展、存在的问题以及后续行动计划。参会人员就 RGW 多站点问题、异步和 RGW 的工作、Blue Store 优化等问题进行了深入讨论，并制定了相应的解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-Jan-17 :: Ceph Tech Talks - NooBaa: A data platform for distributed hybrid clouds","slug":"2019-Jan-17_-_-_Ceph_Tech_Talks_-_NooBaa_-_A_data_platform_for_distributed_hybrid_clouds","date":"2019-01-18T16:00:00.000Z","updated":"2019-01-18T16:00:00.000Z","comments":true,"path":"2019/01/19/2019-Jan-17_-_-_Ceph_Tech_Talks_-_NooBaa_-_A_data_platform_for_distributed_hybrid_clouds/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/19/2019-Jan-17_-_-_Ceph_Tech_Talks_-_NooBaa_-_A_data_platform_for_distributed_hybrid_clouds/","excerpt":"","text":"会议纪要 会议时间： 2023年1月（具体日期未提及） 会议地点： 线上会议 参会人员： 主持人、演讲者（Uber，软件架构师）、Mike（未出席）、社区成员 会议主题： Nuba分布式混合云数据平台介绍及未来发展方向 会议内容： 1. 会议开场 主持人欢迎参会人员，并简要介绍本次Tech Talk的主题和演讲者。 2. 演讲者介绍 演讲者Uber介绍了自己的背景和Nuba的发展历程。Nuba成立于2014年，最初从XenDesktop迁移而来，专注于企业存储解决方案。近期，Nuba被红帽收购，并将开源其平台。 3. 市场背景 Uber分析了当前企业面临的数据管理挑战，包括分布式混合云环境下的数据孤岛、迁移困难等问题。Nuba旨在提供数据平台，帮助企业实现数据管理和优化。 4. Nuba平台介绍 Uber详细介绍了Nuba平台的功能和架构： 灵活的数据服务： 支持本地、多云环境，通过API或本地资源访问。 端点抽象： 隐藏数据存储位置和性能差异，提供透明访问。 支持S3和Lambda API： 提供丰富的数据管理功能。 安全性： 数据加密和传输加密，确保数据安全。 5. 演示 Uber通过演示展示了Nuba平台的使用方法，包括： 数据放置： 支持多区域复制、数据本地化优化等。 数据冗余： 支持不同级别的冗余，提高数据可靠性。 对象版本控制： 支持对象版本控制，方便数据恢复。 触发器： 支持基于数据事件的函数触发，实现数据驱动的平台。 6. 未来发展方向 开源： Nuba平台将在红帽开源，并期待社区贡献。 容器化： 将Nuba平台容器化，提高灵活性和可扩展性。 OpenShift和Seafarers集成： 与OpenShift和Seafarers集成，提供更好的多云支持。 联邦： 探索联邦应用场景，实现跨平台数据管理。 7. 讨论和总结 社区成员就Nuba平台与Rados网关的集成、数据迁移、多云管理等话题进行了讨论。主持人表示，将启动一个邮件列表讨论这些话题。 行动计划： Nuba团队将开源平台，并期待社区贡献。 Nuba团队将继续开发容器化、OpenShift和Seafarers集成等功能。 社区成员将讨论Nuba平台与Rados网关的集成、数据迁移、多云管理等话题。 关键词： Nuba、分布式混合云、数据平台、S3、Lambda API、容器化、OpenShift、Seafarers、联邦","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2019-01-10","slug":"Ceph_Performance_Meeting_2019-01-10","date":"2019-01-15T16:00:00.000Z","updated":"2019-01-15T16:00:00.000Z","comments":true,"path":"2019/01/16/Ceph_Performance_Meeting_2019-01-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/16/Ceph_Performance_Meeting_2019-01-10/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： (此处应填写参会人员名单) 会议主题： Ceph分布式存储项目进展及Crimson项目讨论 会议内容： 一、Ceph项目进展 Pull Requests审查： 会议讨论了多个Pull Requests，包括Stack Streams、FS分配、优先级缓存大小调整、EC Cash等。 部分Pull Requests已合并，如优先级缓存大小调整。 需要进一步审查的Pull Requests包括EC Cash、共享LRU等。 Crimson项目讨论： Crimson项目旨在优化Ceph的性能，特别是对象存储层。 项目初期目标是验证假设，包括验证Crimson对性能的帮助。 项目设计采用简化设计，以降低维护成本和复杂性。 项目讨论了Crimson的OSD概念，包括如何实现多线程OSD。 讨论了使用mstar线程模型的可能性，以及如何与SPDK集成。 二、行动计划 Ceph项目： 继续审查和合并Pull Requests。 对EC Cash、共享LRU等Pull Requests进行进一步审查。 Crimson项目： 完成Crimson的简化设计。 与SPDK团队合作，确定最佳线程模型。 开展Crimson的测试工作。 三、后续会议 下次会议将于2023年11月X日举行，届时将讨论Crimson项目的进展和后续计划。 四、其他事项 会议中讨论了RocksDB的使用，以及如何将其与Ceph集成。 讨论了Crimson项目对性能的影响，以及如何评估其效果。 五、关键词 Pull Requests Stack Streams FS分配 优先级缓存大小调整 EC Cash 共享LRU Crimson项目 OSD mstar线程模型 SPDK","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2019-01-15","slug":"Crimson_Seastar_OSD_Meeting_2019-01-15","date":"2019-01-15T16:00:00.000Z","updated":"2019-01-16T16:00:00.000Z","comments":true,"path":"2019/01/16/Crimson_Seastar_OSD_Meeting_2019-01-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/16/Crimson_Seastar_OSD_Meeting_2019-01-15/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储系统性能优化与改进 会议内容： 1. 协议与心跳机制讨论 协议优化：会议讨论了Ceph协议的优化，特别是针对加密内容的处理。与会者认为，使用基于搜索的加密方法（Serpent）可能优于当前的方法，并建议进行性能比较。 心跳机制：讨论了心跳消息的支持，认为这是确保集群健康状态的重要机制。会议还探讨了心跳消息与心跳监测之间的关系，以及如何通过心跳消息保持集群的响应性。 2. Ceph-Rados性能分析 性能瓶颈：与会者分析了Ceph-Rados的性能瓶颈，发现Crimson消息传递器的性能可能不如预期。会议讨论了Crimson消息传递器在用户空间和内核空间中花费的时间比例，并提出了改进建议。 性能测试：会议讨论了性能测试的方法，包括使用perf工具进行CPU周期和I/O请求的统计。与会者建议使用多连接和更长的测试时间来获得更准确的结果。 3. Ceph-OSD性能优化 单线程OSD：会议讨论了单线程OSD的性能优化，包括如何将单线程OSD映射到单个核上，以及如何避免不同协议之间的冲突。 核心绑定：与会者探讨了如何通过CPU掩码将Crimson实例绑定到特定的核心上，以确保性能和稳定性。 4. 其他议题 RocksDB集成：会议讨论了将RocksDB集成到Ceph中的可能性，并探讨了如何利用RocksDB的特性来提高性能。 Crimson消息传递器改进：与会者讨论了Crimson消息传递器的改进，包括解决并发写入内存缓冲区的问题，以及支持多连接。 决定事项： 性能测试：进行更全面的性能测试，包括多连接和更长的测试时间，以评估Crimson消息传递器的性能。 Crimson消息传递器改进：修复Crimson消息传递器中的并发写入内存缓冲区问题，并支持多连接。 单线程OSD优化：将单线程OSD映射到单个核上，并确保性能和稳定性。 RocksDB集成：研究将RocksDB集成到Ceph中的可能性。 后续行动计划： 性能测试：完成性能测试，并分析结果。 Crimson消息传递器改进：提交Crimson消息传递器改进的代码，并等待合并。 单线程OSD优化：完成单线程OSD优化的代码，并等待合并。 RocksDB集成：研究RocksDB集成方案，并提交相关代码。 注意事项： Crimson消息传递器：Crimson消息传递器的性能可能不如预期，需要进一步优化。 单线程OSD：单线程OSD的性能优化需要考虑核心绑定和并发问题。 RocksDB集成：RocksDB集成需要考虑性能和兼容性问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-Jan-09 :: Ceph Testing Weekly","slug":"2019-Jan-09_-_-_Ceph_Testing_Weekly","date":"2019-01-08T16:00:00.000Z","updated":"2019-01-09T16:00:00.000Z","comments":true,"path":"2019/01/09/2019-Jan-09_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/09/2019-Jan-09_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年1月（具体日期未提及） 参会人员： Yuri, Lea, Christians, Nathan, Astron, Sebastian, Ricardo, Gregory, 等 会议主题： Ceph社区动态、测试工作进展、Pull Request (PR) 测试流程讨论 会议内容： 一、Ceph社区动态 Yuri分享了在德国旅行经历，并提及了Ceph社区成员Nathan可能因假期结束而忙碌。 Christians提到Ceph社区成员Brett和Susan可能对不进行充分测试感到疲倦，希望在下一个版本中加强测试。 Gregory提到Ceph社区已发布 Mimic 13 和 Luminous，并即将推出 Nautilus。 二、测试工作进展 Lea与QE团队负责人Mark讨论了Brooke测试流程，并计划编写接口文档供部署者参考。 Christians提到Rook Orchestrator的测试工作，并询问社区成员是否愿意共享测试资源。 Astron提到Rook Orchestrator的测试工作，并询问社区成员是否愿意集成SSH-based Orchestrator进行测试。 Ricardo提到Sousa团队也开发了Orchestrator，但主要用于开发Despot。 三、Pull Request (PR) 测试流程讨论 Sebastian询问社区是否有关于测试上游PR的文档或流程。 Christians提到社区成员Josh正在尝试自动化测试流程。 Gregory提到社区内部已创建Jenkins作业，用于测试下游PR。 Astron提到社区内部存在一些测试流程文档，但需要进一步整理和完善。 Sebastian建议在邮件列表或更高层次的讨论中继续讨论测试流程，并可能需要撰写更多文档。 后续行动计划： Lea将继续编写Brooke测试接口文档。 Christians将继续推动Rook Orchestrator的测试工作。 Astron将继续探索SSH-based Orchestrator的测试方案。 Ricardo将继续开发Sousa团队的Orchestrator。 Sebastian将继续整理和完善PR测试流程文档。 备注： 会议中多次提到Ceph社区成员和项目，如Lea, Christians, Nathan, Astron, Sebastian, Ricardo, Gregory, 等。 会议中多次提到Ceph社区项目，如Ceph, Rook, Orchestrator, 等。 会议中多次提到Ceph社区版本，如Mimic, Luminous, Nautilus, 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2019-01-08","slug":"Crimson_Seastar_OSD_Meeting_2019-01-08","date":"2019-01-08T16:00:00.000Z","updated":"2019-01-09T16:00:00.000Z","comments":true,"path":"2019/01/09/Crimson_Seastar_OSD_Meeting_2019-01-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/09/Crimson_Seastar_OSD_Meeting_2019-01-08/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员，包括负责Crimson OSD项目的人员 会议主题： Crimson OSD项目进展讨论，包括内存存储、对象存储、性能测试等议题 关键细节： Crimson OSD项目： 旨在提高Ceph的性能，特别是针对快速设备的使用。 目前重点关注1:1映射模式，并考虑未来可能转向M:N映射模式。 内存存储是Crimson OSD项目的一个重要组成部分，将用于测试性能提升。 内存存储： 正在开发内存存储，并计划使用Sister框架。 内存存储将继承自现有的对象存储接口，并实现新的方法。 内存存储将使用原子操作来避免锁的使用，以提高性能。 对象存储： 正在开发新的对象存储接口，以支持内存存储和磁盘存储。 新接口将使用Sister框架，并返回Sister future。 需要开发适配器，将现有对象存储与新的接口进行兼容。 性能测试： 将使用性能测试来评估Crimson OSD项目的性能。 将使用单线程和并发测试来评估性能。 将使用与现有OSD相同的硬件和配置进行测试。 讨论的主要议题： 1:1映射与M:N映射： 团队一致认为，目前应专注于1:1映射模式，并考虑未来可能转向M:N映射模式。 1:1映射模式更简单，更容易实现，并且可以更快地验证性能提升。 内存存储： 团队讨论了内存存储的设计和实现。 团队决定使用Sister框架，并使用原子操作来避免锁的使用。 对象存储： 团队讨论了新的对象存储接口的设计和实现。 团队决定使用Sister框架，并返回Sister future。 性能测试： 团队讨论了性能测试的计划和方法。 团队决定使用单线程和并发测试来评估性能。 决定的事项： Crimson OSD项目： 焦点放在1:1映射模式上。 开发内存存储和新的对象存储接口。 进行性能测试。 内存存储： 使用Sister框架。 使用原子操作来避免锁的使用。 对象存储： 使用Sister框架。 返回Sister future。 性能测试： 使用单线程和并发测试来评估性能。 后续行动计划： 开发内存存储和新的对象存储接口。 进行性能测试。 完成Crimson OSD项目的其他工作。 关键词： Crimson OSD 内存存储 对象存储 Sister框架 1:1映射 M:N映射 性能测试 原子操作 锁 调度器","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2019-01-02 :: Ceph Developer Monthly","slug":"2019-01-02_-_-_Ceph_Developer_Monthly","date":"2019-01-02T16:00:00.000Z","updated":"2019-01-03T16:00:00.000Z","comments":true,"path":"2019/01/03/2019-01-02_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/03/2019-01-02_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年5月19日 参会人员： Brad, David, Jeff, Southern Cal 会议主题： 分布式存储Ceph相关议题讨论 会议内容： 新Monitor添加问题： David提出在添加新Monitor时，需要指定公共地址，但当前添加Monitor时无法指定。 讨论了通过Orchestrator命令要求指定公共网络，并在CLI中实现该功能。 决定在演示中进一步讨论细节。 Ceph应用功能需求： 讨论了Ceph应用在RadosOS上构建的一些功能需求。 主要议题包括： 自定义操作： 需要定义一些自定义操作，使其具有与对象操作相同的原子性语义。 可扩展性： 需要实现可扩展的解决方案，例如在存储池级别进行对象操作的检查。 元数据管理： 需要在对象或存储池级别管理元数据，例如版本号或最小/最大值。 Skyhook应用功能需求： 讨论了Skyhook应用在Ceph存储上的一些功能需求。 主要议题包括： 集合级别锁定： 需要在集合级别进行锁定，例如表级别的锁定。 元数据管理： 需要在存储池级别管理元数据，例如版本号。 多对象操作： 讨论了在Ceph中实现多对象操作的需求。 主要议题包括： PG级别操作： 需要在PG级别进行操作，例如跟踪对象组的元数据。 原子性： 需要确保多对象操作的原子性。 返回数据： 讨论了在对象操作中返回数据的可行性。 主要议题包括： 返回数据大小： 需要限制返回数据的大小，例如16字节。 返回数据用途： 需要明确返回数据的用途，例如返回错误代码或中间结果。 后续行动计划： David将研究如何通过Orchestrator命令指定公共网络。 Jeff和Southern Cal将研究如何实现自定义操作和可扩展性解决方案。 Brad将研究如何在Skyhook中实现集合级别锁定和元数据管理。 全体参与者将继续讨论多对象操作和返回数据的需求。 备注： 会议中提到了Ceph的多个组件，包括Monitor、OSD、PG、Rados、CLI等。 会议中使用了Ceph的一些术语，例如原子性、可扩展性、元数据、集合级别锁定等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2019-01-03","slug":"Ceph_Performance_Meeting_2019-01-03","date":"2019-01-02T16:00:00.000Z","updated":"2019-01-03T16:00:00.000Z","comments":true,"path":"2019/01/03/Ceph_Performance_Meeting_2019-01-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/03/Ceph_Performance_Meeting_2019-01-03/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Crazy mm, Kieffer, Mark, Sage, Radek, Olaf, Greg, Alfredo 等 会议主题： Ceph 分布式存储系统开发讨论 关键议题： NUMA 节点状态监控： 讨论了在 NUMA 节点上添加基础设施，以确定连接的 NUMA 节点，并在对象存储后端和 NIC 上进行相同的操作。 讨论了添加新的命令或状态，以报告 OSD 的 NUMA 节点状态，并在出现不匹配时提供可视化。 讨论了重写关于前端和后端网络的老旧文档，并强调将两个 NIC 都放在前端网络上的重要性。 OSD 设计和性能： 讨论了 OSD 设计的两种方法：简单 OSD（单线程）和更强大的 OSD（多线程）。 讨论了简单 OSD 的缺点，例如需要大量 OSD 来饱和强大设备，以及可能需要更多网络连接和 OSD 映射条目。 讨论了使用 SPDK 或 QAT 等技术来提高性能和减少对内核的依赖。 讨论了数据放置决策，以及是否应该更多地依赖本地 NUMA 节点内的快速查找而不是 Crush。 Sharding 和跨核心通信： 讨论了 Sharding 在系统中的应用，以及如何处理跨核心通信和共享资源。 讨论了使用共享指针和消息传递来实现跨核心数据共享。 讨论了使用跨核心消息传递层和跨核心交叉开关的复杂性。 决定的事项： 将 NUMA 节点状态监控功能添加到开发列表。 对 OSD 设计进行进一步研究，并考虑使用 SPDK 或 QAT 等技术。 与硬件制造商合作，了解未来的硬件路线图。 在下一次 Crimson 核心团队会议中讨论 Sharding 和跨核心通信。 后续行动计划： Sage 将更新 PRS 并提供关于 NUMA 节点状态监控的更多详细信息。 Kieffer 将重写关于前端和后端网络的文档。 Radek 将与 Crimson 核心团队讨论 OSD 设计和 Sharding。 Greg 将与硬件制造商合作，了解未来的硬件路线图。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2019-01-01","slug":"Crimson_Seastar_OSD_Meeting_2019-01-01","date":"2019-01-02T16:00:00.000Z","updated":"2019-01-03T16:00:00.000Z","comments":true,"path":"2019/01/03/Crimson_Seastar_OSD_Meeting_2019-01-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/03/Crimson_Seastar_OSD_Meeting_2019-01-01/","excerpt":"","text":"会议纪要： 会议时间： 2023年1月（具体日期未提及） 参会人员： 多位Ceph研发人员及字幕翻译人员 会议主题： Ceph分布式存储系统开发与性能分析 会议内容： 会议开始： 由于部分成员未能按时加入，会议提前开始。 Monitor客户端改进： 成员讨论了Monitor客户端的改进，包括对monitor play到monitor client的更改。 提到了使用cross-reference（交叉引用）或其他机制来避免潜在的数据结构损坏问题。 讨论了关于对象分配和引用计数的问题，以及如何保证对象被正确分配。 消息传递机制： 讨论了消息传递机制（如message F）的问题，包括如何确保对象在远程端不会被修改。 提到了可能需要扩展消息引用定义的需求。 数据结构破坏： 讨论了数据结构破坏的问题，以及如何确保对象在释放前被正确销毁。 认为使用system allocator（系统分配器）可以避免段错误。 代码贡献与审查： 讨论了代码贡献和审查流程，包括如何将代码提交到上游。 讨论了使用ninja命令进行构建时遇到的问题。 性能分析： 成员分享了性能分析的经验，包括使用GDB PMP和wall clock工具进行性能分析。 讨论了消息传递机制（如sister和messenger）的性能差异。 后续行动计划： 继续改进Monitor客户端。 解决消息传递机制中存在的问题。 分析数据结构破坏的原因，并修复相关代码。 完成代码贡献和审查流程。 继续进行性能分析，并优化Ceph的性能。 关键术语： Ceph Monitor客户端 消息传递机制 数据结构 性能分析 segment fault system allocator ninja命令 GDB PMP wall clock 备注： 会议中提到了多个pull request（PR）和相关链接，但未在纪要中列出。 会议中讨论了一些具体的技术细节，但未在纪要中详细说明。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2018-12-25","slug":"Crimson_Seastar_OSD_Meeting_2018-12-25","date":"2019-01-01T16:00:00.000Z","updated":"2019-01-02T16:00:00.000Z","comments":true,"path":"2019/01/02/Crimson_Seastar_OSD_Meeting_2018-12-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2019/01/02/Crimson_Seastar_OSD_Meeting_2018-12-25/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Michael、Rico、Chris、Jim、Lucy、TJ、Piggy、Riddle等 会议主题： 讨论Ceph分布式存储中消息传递机制、连接管理、性能优化等问题。 关键细节： 消息传递机制： Michael提到在修复一些回归问题时遇到了10百万次失败，特别是在连接销毁时。 Rico指出可能需要修复一些代码，并隐藏异常。 Jim提到需要解决并发消息传递中的bug和异常。 Piggy和Riddle讨论了连接引用和数据结构的设计。 连接管理： Michael和Rico讨论了连接跨引用和数据结构的设计。 Piggy和Riddle讨论了连接引用的共享和修改。 Rico提出了使用socket和输入输出字符串进行调试的建议。 性能优化： Michael和Rico讨论了使用用户空间调度器的优缺点。 Piggy和Riddle讨论了单线程和多线程设计的选择。 Rico提出了使用共享无锁设计来提高性能。 Jim提到了使用Nvme设备时的性能优化。 后续行动计划： Michael将继续修复回归问题。 Rico将继续解决消息传递中的bug和异常。 Jim将继续调试消息传递机制。 Piggy和Riddle将继续优化连接管理。 Riddle将继续研究性能优化方案。 讨论的主要议题： 消息传递机制的设计和优化。 连接管理的设计和优化。 性能优化方案的选择。 决定的事项： 继续修复消息传递和连接管理中的bug。 优化性能。 研究单线程和多线程设计的选择。 后续行动计划： Michael修复回归问题。 Rico解决消息传递中的bug。 Jim调试消息传递机制。 Piggy和Riddle优化连接管理。 Riddle研究性能优化方案。 备注： 会议中提到了一些Ceph相关的关键词，如fulcrum、contest、mentos、shard、object store、OSD、PG、connection、socket等。 会议中涉及到的技术问题较为复杂，需要进一步研究和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2018-12-11","slug":"Crimson_Seastar_OSD_Meeting_2018-12-11","date":"2018-12-19T16:00:00.000Z","updated":"2018-12-19T16:00:00.000Z","comments":true,"path":"2018/12/20/Crimson_Seastar_OSD_Meeting_2018-12-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/12/20/Crimson_Seastar_OSD_Meeting_2018-12-11/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Michael、Divya、Riddick、Bobby等 会议主题： Ceph分布式存储系统开发讨论 关键细节： OSD服务模型： 讨论了OSD服务的模型设计，包括如何处理服务、对象存储和OSD之间的关系。提出了创建一个新的OSD服务类，用于管理OSD和对象存储。 Promise调度器： 讨论了Promise调度器的修改，以确保在磁盘操作中保证操作的顺序。 Crimson消息传递框架： 讨论了Crimson消息传递框架的集成和改进，包括日志记录、PID地址问题等。 ZooKeeper集成： 讨论了ZooKeeper集成的工作进展，包括隐私保护、Crimson对象存储实现等。 讨论的主要议题： OSD服务模型： 如何设计OSD服务模型以更好地管理服务、对象存储和OSD之间的关系。 Promise调度器： 如何修改Promise调度器以确保操作的顺序。 Crimson消息传递框架： 如何集成和改进Crimson消息传递框架，以提高系统的性能和可靠性。 ZooKeeper集成： 如何实现ZooKeeper集成，以提供更好的隐私保护和数据一致性。 决定的事项： 创建一个新的OSD服务类，用于管理OSD和对象存储。 修改Promise调度器以确保操作的顺序。 集成和改进Crimson消息传递框架。 实现ZooKeeper集成。 后续行动计划： Michael将负责设计OSD服务模型。 Divya将负责修改Promise调度器。 Riddick将负责集成和改进Crimson消息传递框架。 Bobby将负责实现ZooKeeper集成。 所有参与者将参与讨论和审查相关代码。 其他事项： 会议还讨论了其他一些技术问题，例如内存管理、缓存策略等。 会议结束后，所有参与者将分享他们的进展和遇到的问题。 关键词： OSD（对象存储守护进程） Promise调度器 Crimson消息传递框架 ZooKeeper Privacy Performance Reliability","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2018-12-18","slug":"Crimson_Seastar_OSD_Meeting_2018-12-18","date":"2018-12-19T16:00:00.000Z","updated":"2018-12-19T16:00:00.000Z","comments":true,"path":"2018/12/20/Crimson_Seastar_OSD_Meeting_2018-12-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/12/20/Crimson_Seastar_OSD_Meeting_2018-12-18/","excerpt":"","text":"会议纪要 会议时间： 未知 会议地点： 未知 参会人员： 多位（具体姓名未提及） 会议主题： Ceph 项目进展讨论，特别是 crimson 项目和 messenger 的开发 关键细节： Crimson 项目： 讨论了 crimson 项目的进展，包括与 existing CI 集成、性能提升和人员投入。 决定从零开始重新设计 crimson 项目，以更好地利用 sister 和提高性能。 讨论了 crimson 项目与现有 Ceph 代码库的兼容性，并决定在 crimson 项目中实现新的功能。 messenger： 讨论了 messenger 的性能和稳定性，并决定进行性能测试。 讨论了 buffer list 的实现，并决定对其进行优化以提高性能。 讨论了 crimson 项目中 messenger 的集成，并决定在 crimson 项目中实现新的功能。 其他： 讨论了 OSD 的 sharding 和 dispatcher 的实现。 讨论了 crimson 项目中与 monitor 和 OSD 的集成。 讨论的主要议题： Crimson 项目的重新设计 messenger 的性能和稳定性 buffer list 的实现 OSD 的 sharding dispatcher 的实现 决定的事项： 从零开始重新设计 crimson 项目 对 messenger 进行性能测试 对 buffer list 进行优化 在 crimson 项目中实现新的功能 在 crimson 项目中集成 messenger 后续行动计划： 重新设计 crimson 项目 进行 messenger 的性能测试 对 buffer list 进行优化 在 crimson 项目中实现新的功能 在 crimson 项目中集成 messenger 继续讨论 OSD 的 sharding 和 dispatcher 的实现 其他： 讨论了 crimson 项目的资源分配问题。 讨论了 crimson 项目的长期发展。 备注： 会议中提到了多个英文关键词，如 crimson、messenger、OST、PG、sharding、dispatcher 等。 会议中提到了多个代码库，如 crimson、messenger、sister 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-12-06","slug":"Ceph_Performance_Meeting_2018-12-06","date":"2018-12-06T16:00:00.000Z","updated":"2018-12-06T16:00:00.000Z","comments":true,"path":"2018/12/07/Ceph_Performance_Meeting_2018-12-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/12/07/Ceph_Performance_Meeting_2018-12-06/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位研发人员，包括皮肤线（Skin Line）、Hibi、Radek、Chuck、Sage、Adam、Casey、Jason等。 会议主题： 讨论Ceph分布式存储系统的开发进展，包括PG自动缩放器、缓冲区优化、编码基础设施优化等议题。 关键细节 1. PG自动缩放器 Sage介绍了新的PG自动缩放器模块，该模块基于John最初编写的模块，增加了新的池属性，如P基因组、目标大小字节和目标大小比率。 该模块允许用户根据预期的池大小自动调整PG数量，从而减少数据移动和优化性能。 Sage建议先合并管理接口重构的代码，然后再合并这个模块。 2. 缓冲区优化 Radek汇报了关于缓冲区跟踪基础设施的优化工作，包括缓冲区CSTR、CRC缓存和原子操作。 团队讨论了是否应该移除或禁用某些跟踪和缓存机制，以减少开销并提高性能。 Sage提出考虑移除CRC缓存，因为它在大多数情况下不会影响性能。 3. 编码基础设施优化 Sage介绍了对编码基础设施的优化工作，包括连续存储器类和零复制。 团队讨论了优化编码调用和消除不必要的汇编代码，以提高性能。 Sage建议先审查和合并这些更改。 4. 其他议题 讨论了关于在Ceph中优化原子操作的分支，以及是否应该移除XIO消息传递器。 讨论了关于优化旧编码基础设施的分支，以及是否应该继续优化这些代码。 决定事项 Sage建议先合并管理接口重构的代码，然后再合并PG自动缩放器模块。 团队决定审查和合并缓冲区优化和编码基础设施优化的代码。 讨论了是否应该移除或禁用某些跟踪和缓存机制，以及是否应该优化原子操作和编码基础设施。 后续行动计划 Sage将继续开发PG自动缩放器模块。 团队将继续审查和合并缓冲区优化和编码基础设施优化的代码。 团队将继续讨论是否应该移除或禁用某些跟踪和缓存机制，以及是否应该优化原子操作和编码基础设施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-12-05 :: Ceph Developer Monthly","slug":"2018-12-05_-_-_Ceph_Developer_Monthly","date":"2018-12-05T16:00:00.000Z","updated":"2018-12-05T16:00:00.000Z","comments":true,"path":"2018/12/06/2018-12-05_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/12/06/2018-12-05_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： [请填写具体时间] 参会人员： [请填写参会人员姓名] 会议主题： Ceph分布式存储系统相关更新与讨论 会议内容： Orchestrator更新： 会议讨论了Orchestrator的更新情况，并提供了相关的链接供参考。 Nautilus依赖问题： Nautilus版本引入了新的依赖，包括Python模块，需要解决依赖问题。 需要决定如何处理这些依赖，包括是否需要创建新的包或进行回滚。 Python模块打包： 新的Python模块需要打包，可能需要与James进行讨论。 需要确定打包方式和责任分配。 设备故障预测模块： 讨论了设备故障预测模块的新依赖，需要确定如何处理这些依赖。 需要考虑将具有额外依赖的模块打包成单独的包，以避免不必要的安装。 数据收集与模型训练： 讨论了构建开源故障数据集的必要性，以训练开源模型。 讨论了Wisconsin大学学生项目，旨在构建API端点并将数据存储到MySQL数据库。 磁盘故障检测： 讨论了使用driveutil工具检测磁盘故障的方法。 讨论了在实验室集群上部署该工具，以检测磁盘错误。 行动计划： 确定处理Nautilus依赖问题的方案。 与James讨论Python模块打包事宜。 确定设备故障预测模块的依赖处理方案。 与Wisconsin大学学生合作，构建开源故障数据集和模型。 在实验室集群上部署driveutil工具，以检测磁盘故障。 备注： 会议中提到了Ceph的某些功能和技术，如Orchestrator、Nautilus、Python模块、设备故障预测模块等。 会议中还讨论了开源数据集、模型训练和磁盘故障检测等技术问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2018-12-04","slug":"Crimson_Seastar_OSD_Meeting_2018-12-04","date":"2018-12-05T16:00:00.000Z","updated":"2018-12-05T16:00:00.000Z","comments":true,"path":"2018/12/06/Crimson_Seastar_OSD_Meeting_2018-12-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/12/06/Crimson_Seastar_OSD_Meeting_2018-12-04/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储系统开发讨论 会议内容： 1. 网络连接问题 - 由于网络连接问题，部分参会人员无法正常参与会议。 - Jim今日无法参加会议，因他今日不在办公室。 2. 功能开发与优化 - 参会人员讨论了Ceph中“finish”功能开发的进展，包括： - 修改代码以注册Kovac观察者。 - 修复OS中的一些错误。 - 优化代码以在POSIX环境下运行。 - 讨论了如何解决在跨不同分支代码合并时出现的兼容性问题。 3. crimson项目 - 讨论了crimson项目中的同步问题，包括： - crimson需要使用with sister，而synchronous messenger不需要。 - 在同一文件中同时存在两种类型的messenger，导致冲突。 - 探讨了如何将sharded crimson messenger分配到不同的shard。 4. 其他 - 参会人员讨论了以下内容： - 使用boost intrusive库时遇到的问题。 - 代码合规性检查。 - 复制bucket在sister OSD上的实现。 决定事项： 参会人员决定： 继续推进finish功能的开发。 解决crimson项目中的同步问题。 修复boost intrusive库相关的问题。 完成代码合规性检查。 后续行动计划： 参会人员将： 继续跟进finish功能的开发。 解决crimson项目中的同步问题。 修复boost intrusive库相关的问题。 完成代码合规性检查。 备注： 会议中提到了以下计算机科学/ceph相关领域英文关键词： finish Kovac observer POSIX crimson sharded crimson messenger boost intrusive compliance replicated bucket","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-11-29","slug":"Ceph_Performance_Meeting_2018-11-29","date":"2018-11-29T16:00:00.000Z","updated":"2018-11-30T16:00:00.000Z","comments":true,"path":"2018/11/30/Ceph_Performance_Meeting_2018-11-29/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/30/Ceph_Performance_Meeting_2018-11-29/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Greg, Mark, Sage, Erratic, George, Radek 等 会议主题： Ceph分布式存储项目进展及讨论 关键细节： 会议开始： 由于Mark的麦克风问题，会议开始时未能听到其声音，后来问题解决。 两周工作进展： 本次会议回顾了过去两周的Pull Requests (PRs)，并讨论了合并的PRs。 PG状态统计： 讨论了PG状态统计的合并情况，尽管某些PR已合并，但仍有部分PR需要处理。 复杂性问题： 讨论了Ceph中某些复杂性问题，特别是与Buffer List相关的性能问题。 Crimson项目： 讨论了Crimson项目的进展，该项目旨在简化Ceph的I/O路径，并使用C Star缓冲区。 LVM性能问题： 讨论了用户在LVM设备上部署Ceph时遇到性能下降的问题，可能与XFS和NVMe驱动程序有关。 Buffer List优化： 讨论了Buffer List的优化方案，包括减少共享行为和使用内存复制等。 PG日志恢复： 讨论了PG日志恢复的优化方案，包括实现不基于日志的PG，并重构相关代码。 讨论的主要议题： Buffer List的复杂性问题： 会议上重点讨论了Buffer List的复杂性问题，包括共享行为、内存复制等。 Crimson项目的进展： 讨论了Crimson项目的进展，以及如何简化Ceph的I/O路径。 LVM性能问题： 讨论了用户在LVM设备上部署Ceph时遇到性能下降的问题，并提出了可能的解决方案。 Buffer List优化方案： 讨论了多种优化Buffer List的方案，包括减少共享行为和使用内存复制等。 PG日志恢复的优化方案： 讨论了PG日志恢复的优化方案，包括实现不基于日志的PG，并重构相关代码。 决定的事项： 继续优化Buffer List： 会议决定继续优化Buffer List，包括减少共享行为和使用内存复制等。 关注Crimson项目的进展： 会议决定关注Crimson项目的进展，并评估其对Ceph性能的影响。 调查LVM性能问题的原因： 会议决定调查LVM性能问题的原因，并寻找可能的解决方案。 重构PG日志恢复相关代码： 会议决定重构PG日志恢复相关代码，以优化性能。 后续行动计划： Greg： 调查Buffer List的优化方案，并编写相关代码。 Mark： 关注Crimson项目的进展，并评估其对Ceph性能的影响。 Sage： 调查LVM性能问题的原因，并寻找可能的解决方案。 Erratic： 与其他团队成员合作，重构PG日志恢复相关代码。 备注： 会议中提到了Ceph中的一些技术术语，如PG、Buffer List、Crimson等。 会议中讨论了一些开源项目的进展，如LVM、XFS等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph code walkthrough: BlueStore cache autotuning","slug":"Ceph_code_walkthrough_-_BlueStore_cache_autotuning","date":"2018-11-29T16:00:00.000Z","updated":"2018-11-30T16:00:00.000Z","comments":true,"path":"2018/11/30/Ceph_code_walkthrough_-_BlueStore_cache_autotuning/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/30/Ceph_code_walkthrough_-_BlueStore_cache_autotuning/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Josh, Mark, Brian, Nick 会议主题： Ceph分布式存储系统中的智能存储优化 会议内容： 1. 会议开场 会议开始，参会人员互相问候，确认设备工作正常。 2. 项目目标 Mark介绍了项目目标，即使存储系统（特别是OSD）能够“智能”地工作，减少用户配置的复杂性，并优化资源使用。 3. 现状分析 目前Ceph存储系统存在大量配置选项，用户需要手动配置，导致操作复杂且容易出错。 4. 内存管理优化 Mark提出了针对OSD内存管理的优化方案，包括： 设定OSD内存目标，自动调整缓存大小以适应内存使用情况。 根据映射内存与目标内存的比例，动态调整缓存大小。 通过分析堆内存使用情况，优化缓存配置。 5. 缓存优先级管理 Mark介绍了缓存优先级管理的方案，包括： 为不同类型的缓存设置优先级，例如RocksDB块缓存中的Bloom过滤器和高优先级索引。 根据优先级分配内存，确保高优先级缓存得到足够的资源。 动态调整缓存大小，以适应不同工作负载的需求。 6. 代码实现 会议详细讨论了代码实现细节，包括： 在RocksDB中实现优先级缓存接口。 将缓存管理代码从BlueStore迁移到通用优先级缓存管理器。 实现自动缓存大小调整和缓存优先级管理。 7. 测试结果 会议展示了测试结果，包括： 自动缓存大小调整能够有效控制内存使用，并提高性能。 缓存优先级管理能够满足不同工作负载的需求。 8. 后续工作 Mark计划继续优化缓存管理，包括： 实现更复杂的缓存优先级管理，支持任意数量的优先级。 将缓存管理方案扩展到其他组件，例如Mon和OSD。 探索将类似方案应用于磁盘管理。 9. 会议总结 会议圆满结束，参会人员对项目进展表示满意，并对后续工作充满期待。 关键词： Ceph 分布式存储 OSD 内存管理 缓存 优先级 自动化 RocksDB","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Weekly 2018-11-28","slug":"Ceph_Testing_Weekly_2018-11-28","date":"2018-11-28T16:00:00.000Z","updated":"2018-11-28T16:00:00.000Z","comments":true,"path":"2018/11/29/Ceph_Testing_Weekly_2018-11-28/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/29/Ceph_Testing_Weekly_2018-11-28/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员（包括但不限于Nathan, David Galloway, Alfredo, Sebastian等） 会议主题： 讨论Ceph项目中的Python 3支持、安装器接口、Orchestrator模块以及OpenSUSE测试等议题。 会议内容： 1. Python 3支持 讨论了在Ceph项目中引入Python 3的必要性，以及如何在openSUSE上实现Python 3环境。 提到了使用Mach工具进行OpenSUSE构建的可行性，并讨论了如何解决Shaman构建工具的限制。 认为需要投入资源来支持OpenSUSE的构建，并考虑使用OBS或mock工具。 2. 安装器接口 讨论了Ceph安装器接口的改进，包括Ansible和Sensu等工具的使用。 讨论了安装器接口的抽象化，以及如何支持不同类型的安装器。 认为需要创建一个产品跟踪器（tracker），以便跟踪相关需求和问题。 3. Orchestrator模块 讨论了Orchestrator模块的设计和实现，以及其与Ceph Manager的集成。 认为Orchestrator模块可以提供统一的命令接口，支持不同类型的Orchestrator，例如Ansible、DeepSea和Rook等。 认为Orchestrator模块的开发需要与安装器接口的改进同步进行。 4. OpenSUSE测试 讨论了在OpenSUSE上测试Ceph项目的可行性，以及如何解决Shaman构建工具的限制。 认为需要投入资源来支持OpenSUSE的构建，并考虑使用OBS或mock工具。 行动计划： Nathan将继续开发Orchestrator模块，并与安装器接口的改进同步进行。 David Galloway将创建一个产品跟踪器，以便跟踪相关需求和问题。 讨论如何支持OpenSUSE的构建，并考虑使用OBS或mock工具。 关键信息： Ceph项目正在积极推动Python 3的支持。 Ceph项目正在改进安装器接口，并引入Orchestrator模块。 OpenSUSE测试是Ceph项目的一个重要目标。 备注： 会议中提到了一些技术细节，例如Mach、mock、OBS、Shaman等，这些内容对于理解会议内容可能有所帮助。 会议中提到了一些资源问题，例如构建资源、测试环境等，这些内容对于后续工作可能有所帮助。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2018-11-27","slug":"Crimson_Seastar_OSD_Meeting_2018-11-27","date":"2018-11-27T16:00:00.000Z","updated":"2018-11-28T16:00:00.000Z","comments":true,"path":"2018/11/28/Crimson_Seastar_OSD_Meeting_2018-11-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/28/Crimson_Seastar_OSD_Meeting_2018-11-27/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Tomas Michaud、Jim、John、Justice、Reed Oak、Tom等 会议主题： 讨论Ceph项目进展、问题解决及后续行动计划 会议内容： 1. Ceph项目进展 Tomas Michaud： 由于上周是感恩节假期，项目进展不多。他完成了一些配置保存的工作，并上传了补丁。 John： 尚未完成工作进度，但已上传配置保存的补丁。 Tomas Michaud： 推出了Mendel TC的原型，并上传到GitHub。 Justice： 正在编写内存测试用例，并更新POSIX线程中的翻译。 Reed Oak： 由于专注于Luminos中的febs问题，上周进展不多。 Tom： 正在解决Ceph目录结构中公共和私有头文件依赖问题。 2. 问题解决 Jim： 对Crimson PR的审查速度较慢，Tomas Michaud已发送邮件询问原因。 Tom： 在Crimson PR中遇到了一些问题，正在尝试解决。 Reed Oak： 正在解决Luminos中buffer list的依赖问题。 3. 后续行动计划 Tomas Michaud： 修订消息传递构造函数和模拟投资，并将其集成到驱动程序中。 John： 完成配置保存的工作。 Justice： 继续编写内存测试用例，并更新POSIX线程中的翻译。 Reed Oak： 解决Luminos中buffer list的依赖问题。 Tom： 解决Ceph目录结构中公共和私有头文件依赖问题。 4. 其他事项 会议中提到，一些工作进度已被移除，因为它们在Nautilus T发布前需要进一步审查。 会议结束时，大家表示期待下周的会议。 关键词： Ceph Mendel TC Crimson PR Luminos POSIX线程 buffer list Nautilus T 会议纪要","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-11-20 Crimson/Seastar OSD Meeting","slug":"2018-11-20_Crimson_Seastar_OSD_Meeting","date":"2018-11-20T16:00:00.000Z","updated":"2018-11-21T16:00:00.000Z","comments":true,"path":"2018/11/21/2018-11-20_Crimson_Seastar_OSD_Meeting/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/21/2018-11-20_Crimson_Seastar_OSD_Meeting/","excerpt":"","text":"会议纪要 会议时间： 2023年11月[具体日期待补充] 参会人员： Neha（主持人）、Mark、Casey、Emma、Free Duke等 会议主题： Ceph存储集群的维护和优化 多连接支持与性能测试 缓冲区列表的优化 内存存储的测试与改进 关键细节与讨论议题： 1. Ceph存储集群维护与优化 Neha提到正在等待Khmer Pilate的更新，并询问了项目的进展情况。 Mark分享了关于连接状态封装和协议优化的工作，Casey对此表示了关注。 Emma提到与RocksDB的新联系人交流，希望了解他们的设计并寻求合作。 2. 多连接支持与性能测试 Neha询问了关于RocksDB设计的问题，并讨论了与RocksDB的合作可能性。 Mark分享了关于多连接实现的进展，并解释了使用纯IP进行连接分片的问题。 Emma提出了使用多个IP地址进行测试的建议。 3. 缓冲区列表的优化 Casey分享了关于缓冲区列表优化的工作，并讨论了针对单线程无锁设备的应用场景。 Emma提到将后续工作转向简化路径，以便在理解了复制副本的Red Hat情况后进行。 4. 内存存储的测试与改进 Neha讨论了在Münster中进行测试时遇到的锁问题，并提出了使用TSX进行优化的建议。 Emma表示将继续工作，翻译基于Red Oak的副本关键路径分析。 决定的事项： 继续推进Ceph存储集群的维护和优化工作。 完成多连接支持与性能测试，并解决使用纯IP进行连接分片的问题。 完成缓冲区列表的优化工作，并考虑简化路径。 继续改进内存存储的测试与改进工作。 后续行动计划： Neha将跟进Khmer Pilate的更新。 Mark将继续与Casey合作，优化连接状态封装和协议。 Emma将尝试使用多个IP地址进行测试，并与RocksDB团队进行交流。 Casey将继续优化缓冲区列表，并考虑简化路径。 Emma将继续工作，翻译基于Red Oak的副本关键路径分析。 其他： 会议期间，参会人员还讨论了其他一些话题，例如配置代理、共享指针等。 会议结束后，参会人员表示将继续努力，推进Ceph存储集群的维护和优化工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-11-15","slug":"Ceph_Performance_Meeting_2018-11-15","date":"2018-11-14T16:00:00.000Z","updated":"2018-11-15T16:00:00.000Z","comments":true,"path":"2018/11/15/Ceph_Performance_Meeting_2018-11-15/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/15/Ceph_Performance_Meeting_2018-11-15/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： Radek、Alex、Ben、Jesse等 会议主题： Ceph存储项目进展及讨论 会议内容： 一、Ceph项目进展 Radek的工作： 优化buffer管理，移除pen buffer，减少不必要的原子操作。 开发hyper combined buffers，提高buffer列表迭代效率。 处理RDMA相关工作，提升性能。 优化EC striped cache功能。 开发auto-tuner改进方案，优化BlueStore缓存行为。 Alex的工作： 进行BlueStore性能测试，分析读写性能。 发现read ahead机制可能影响测试结果。 分析小随机写性能问题，探讨优化方案。 Ben的工作： 分析BlueStore性能测试结果，探讨优化方向。 探讨RocksDB调优方案，优化小随机写性能。 开发VLA优化方案，减少内存拷贝。 Jesse的工作： 完成GW的VLA优化工作。 二、讨论的主要议题 buffer优化： 优化buffer管理，减少不必要的原子操作，提高效率。 hyper combined buffers： 开发hyper combined buffers，提高buffer列表迭代效率。 RDMA优化： 提升RDMA性能。 EC striped cache优化： 优化EC striped cache功能。 BlueStore性能优化： 分析BlueStore性能测试结果，探讨优化方向，包括read ahead机制、RocksDB调优等。 VLA优化： 开发VLA优化方案，减少内存拷贝。 三、决定的事项 继续推进Radek的buffer优化和hyper combined buffers开发。 进一步分析Alex的BlueStore性能测试结果，确定优化方案。 探索RocksDB调优方案，优化小随机写性能。 完成Jesse的VLA优化工作。 四、后续行动计划 Radek：完成buffer优化和hyper combined buffers开发。 Alex：继续进行BlueStore性能测试，分析测试结果，确定优化方案。 Ben：分析RocksDB调优方案，优化小随机写性能。 Jesse：完成VLA优化工作。 五、其他事项 下周（感恩节假期）将不召开会议。 总结： 本次会议讨论了Ceph存储项目的进展和后续工作计划，重点讨论了buffer优化、hyper combined buffers、RDMA优化、EC striped cache优化、BlueStore性能优化和VLA优化等议题。会议明确了后续行动计划，为Ceph存储项目的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-NOV-07 :: Ceph Developer Monthly","slug":"2018-NOV-07_-_-_Ceph_Developer_Monthly","date":"2018-11-13T16:00:00.000Z","updated":"2018-11-14T16:00:00.000Z","comments":true,"path":"2018/11/14/2018-NOV-07_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/14/2018-NOV-07_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Tim、Sage、Yen（Intel）、Mina、Jason、Dan、Ian、Daniel、Bill Simpson 会议主题： Ceph 项目进展讨论 会议内容： 1. 深海 orchestrator 模块和 Anible Tim 和 Sage 讨论了深海 orchestrator 模块和 Anible 的进展，两者都采用了相似的方法和轨迹。 讨论了如何使用 libstorage management 调用闪烁灯，以便在 Seth 本身损坏或未安装的情况下能够控制闪烁灯。 讨论了设备状态跟踪和健康警报，以及如何记录闪烁灯的状态。 2. Ceph OSD 删除器代码 Mina 更新了 Ceph OSD 删除器代码的进展，包括单元测试和文档。 讨论了如何标记该功能为实验性，并建议进行性能测试。 3. RBD 共享缓存 Yen 更新了 RBD 共享缓存的进展，包括缓存架构、工作流程和性能测试结果。 讨论了缓存容量配置、缓存空间管理策略和与集群配置的集成。 讨论了如何将缓存演示程序与 RBD 客户端集成，以及如何处理连接问题。 4. RBD 持久性缓存 Jason 更新了 RBD 持久性缓存的进展，包括代码架构、性能目标和挑战。 讨论了持久性缓存的一致性、性能和可扩展性。 讨论了如何将持久性缓存与 SSD 集成，以及如何处理不同硬件平台的差异。 5. Orchestrator 和 Messenger 讨论了 Orchestrator 和 Messenger 的进展，包括协议 V2 的实现、地址端点管理和加密。 讨论了如何将协议 V2 与现有的 Ceph 版本兼容。 行动计划： 完成深海 orchestrator 模块和 Anible 的开发。 对 Ceph OSD 删除器代码进行性能测试。 完成 RBD 共享缓存和 RBD 持久性缓存的开发。 加快 Orchestrator 和 Messenger 的开发。 完成协议 V2 的实现和加密功能。 其他事项： 讨论了集群连接性监控和 RDMA 连接问题。 讨论了 Ceph 代码的可维护性和可扩展性。 会议总结： 本次会议讨论了 Ceph 项目的多个方面，包括 orchestrator、Anible、RBD 缓存、持久性缓存和 Orchestrator/Messenger。会议确定了下一步行动计划，并讨论了项目中的挑战和解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-11-08","slug":"Ceph_Performance_Meeting_2018-11-08","date":"2018-11-13T16:00:00.000Z","updated":"2018-11-14T16:00:00.000Z","comments":true,"path":"2018/11/14/Ceph_Performance_Meeting_2018-11-08/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/14/Ceph_Performance_Meeting_2018-11-08/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议主题： Ceph社区开发讨论 参会人员： Jesse, Radek, Casey, Adam, Mark等 会议内容： 1. Pull Request (PR) 审查进度 Jesse 仍在努力审查Pull Requests，但进度有所滞后。 Radek 介绍了为读取或副本存储池引入的新快捷方式，并进行了一些基准测试。 Casey 正在改进Dashboard服务。 Adam 正在处理RGW相关的工作，并完成了测试。 其他PR的审查情况尚不明确。 2. Vector Strings的替代方案 Jesse 提出了使用C++的Vector替代Variable Length Array (VLA)的建议。 讨论了VLA的安全性和性能影响。 大多数成员支持逐步替换VLA，并建议从RGW开始。 Jesse 将负责处理RGW中的字符串处理问题。 3. 性能测试硬件 可能会有新的性能测试硬件加入社区实验室。 成员们可以申请使用这些硬件进行测试。 4. 其他事项 Mark 提到了自适应节流和IO节流器的进展。 讨论了在Ceph中使用C++标准库的建议。 行动计划： Jesse 将负责处理RGW中的字符串处理问题。 Radek 将继续进行基准测试和性能分析。 Casey 将改进Dashboard服务。 Adam 将完成RGW相关的工作。 所有成员将继续审查Pull Requests。 后续会议： 下周将举行下一场Ceph社区开发讨论会议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastor OSD Meeting 2018-11-13","slug":"Crimson_Seastor_OSD_Meeting_2018-11-13","date":"2018-11-13T16:00:00.000Z","updated":"2018-11-14T16:00:00.000Z","comments":true,"path":"2018/11/14/Crimson_Seastor_OSD_Meeting_2018-11-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/14/Crimson_Seastor_OSD_Meeting_2018-11-13/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知 会议主题： Ceph分布式存储项目进展、性能优化、代码审查与测试 会议内容： 一、Ceph分布式存储项目进展 Vasila DB Meetup： 与Tilde团队讨论了数据库性能分析和调试方法，了解到他们使用构建指标和Twist Point进行性能分析，并探讨了如何对Ceph进行类似分析。 Rocky Beach Meetup： 参加了Rocky Beach年度Meetup，了解到一家公司正在开发新的RocksDB版本，支持多线程和异步I/O，这对Ceph的性能提升具有潜在价值。 RocksDB性能优化： 讨论了如何利用RocksDB的Fiber和单写API进行性能优化，并探讨了使用Lambda表达式进行代码优化的方法。 Ceph性能分析： 分析了Ceph的性能瓶颈，包括缓存污染、IO路径复杂度等，并讨论了如何进行性能优化。 二、代码审查与测试 代码审查： 审查了Redux PR，并尝试将Redux的简化路径翻译到Ceph中。 测试： 进行了RocksDB测试套件的测试工作，并讨论了如何使用RocksDB进行性能测试。 调试： 讨论了如何进行Ceph的调试工作，包括如何处理悬挂的Futures和崩溃报告。 三、后续行动计划 性能优化： 继续优化Ceph的性能，包括缓存、IO路径、CPU使用率等方面。 代码审查： 完成Redux PR的代码审查工作，并尝试将Redux的简化路径翻译到Ceph中。 测试： 完成RocksDB测试套件的测试工作，并评估RocksDB对Ceph性能的影响。 调试： 完成Ceph的调试工作，并解决悬挂的Futures和崩溃报告问题。 四、其他 讨论了Ceph的调试符号大小问题，并探讨了如何减少调试符号的大小。 讨论了Ceph的内存管理问题，并探讨了如何优化内存使用。 讨论了Ceph的代码结构问题，并探讨了如何优化代码结构。 五、会议总结 本次会议讨论了Ceph分布式存储项目的进展、性能优化、代码审查与测试等方面，并制定了后续行动计划。会议内容丰富，讨论深入，为Ceph项目的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD Meeting 2018-11-07","slug":"Crimson_Seastar_OSD_Meeting_2018-11-07","date":"2018-11-06T16:00:00.000Z","updated":"2018-11-07T16:00:00.000Z","comments":true,"path":"2018/11/07/Crimson_Seastar_OSD_Meeting_2018-11-07/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/07/Crimson_Seastar_OSD_Meeting_2018-11-07/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： triple penguin, Mark, Sage, Ricardo, Linda, Greg, Jim 等 会议主题： Ceph分布式存储系统性能优化与改进 会议内容： 1. 共享OSD映射或共享缓存： 讨论了避免在核心之间进行通信以避免死锁的可能性，并考虑了将连接和消息代理分散到不同核心的方法。 认为将连接和消息代理分散到不同核心可以提高性能，并简化实现。 讨论了将连接和消息代理分散到不同核心的挑战，例如客户端需要了解OSD的CPU数量和端口信息。 2. 内存复制： 讨论了内存复制的性能影响，并考虑了使用共享缓存来避免内存复制。 认为在创建新的OSD映射时进行内存复制是罕见的，因此可以接受其性能影响。 讨论了将消息代理分散到不同核心的方法，例如使用服务器-客户端架构。 3. 系统消息中的断开连接： 讨论了实现系统消息中的断开连接的可能性。 认为这需要接口更改，例如连接和消息代理。 讨论了如何处理连接和消息代理的碎片化，以及如何确保消息的完整性和可靠性。 4. PG分片： 讨论了PG分片的性能影响，并考虑了使用PG分片来提高性能。 认为PG分片可以减少客户端到PG的通信，并提高性能。 讨论了PG分片的挑战，例如客户端需要了解PG分片信息。 5. 权限路径和共享缓存： 讨论了权限路径和共享缓存的性能影响。 认为权限路径和共享缓存可以提高性能，并减少内存使用。 讨论了权限路径和共享缓存的实现方法。 6. 短路和读写路径： 讨论了短路和读写路径的性能影响。 认为短路可以提高性能，并减少开销。 讨论了短路和读写路径的实现方法。 7. 后续行动计划： 实现系统消息中的断开连接。 评估PG分片的性能影响。 实现权限路径和共享缓存。 实现短路和读写路径。 会议结论： 会议讨论了Ceph分布式存储系统性能优化和改进的多个方面。 讨论了各种方法和技术的优缺点。 确定了后续行动计划。 关键词： Ceph, 分布式存储, 性能优化, 内存复制, 共享缓存, PG分片, 权限路径, 短路, 读写路径","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2018-11-02","slug":"Ceph_Docubetter_Meeting_2018-11-02","date":"2018-11-02T16:00:00.000Z","updated":"2018-11-02T16:00:00.000Z","comments":true,"path":"2018/11/03/Ceph_Docubetter_Meeting_2018-11-02/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/03/Ceph_Docubetter_Meeting_2018-11-02/","excerpt":"","text":"会议纪要 会议时间： [请填写日期和时间] 会议地点： [请填写会议地点或在线会议平台] 参会人员： [请填写参会人员名单] 会议主题： Ceph文档改进与优化 会议内容： 文档审查进度： 目前文档审查阶段正在进行中，预计本周完成。 一旦审查完成，将进行回溯操作，确保Mimic和Luminous版本兼容。 回溯操作： 讨论了对Jewel版本进行回溯操作的可行性，考虑到其重要性，决定进行回溯。 将由专人负责回溯操作。 搜索引擎优化： 讨论了搜索引擎优化问题，包括： 建立规范参考文档。 使用robots.txt文件限制索引旧文档。 更新重定向策略。 将邀请Alfredo参与讨论，了解网站部署情况。 文档错误报告： 建立了新的文档错误报告流程，包括： GitHub编辑功能。 Etherpad报告平台。 针对非GitHub用户的手动报告方式。 鼓励用户报告Master、Mimic和Luminous版本的错误。 项目页面改进： 对项目页面进行了改进，包括： 增加了文档错误报告功能。 设置了不同的分支错误报告区域。 鼓励用户参与文档改进。 其他事项： 讨论了Ceph文档的层次结构问题，决定创建一个示例问题，并邀请相关人员进行修复。 讨论了Ceph项目跟踪器与项目页面的关系，决定在项目页面中报告简单的错误，而复杂错误仍使用跟踪器。 后续行动计划： 完成文档审查和回溯操作。 与Alfredo沟通，了解网站部署情况。 实施搜索引擎优化策略。 推广文档错误报告流程。 优化项目页面功能。 备注： 会议中提到了Ceph文档的以下关键词：PR、backport、robots.txt、canonical reference、 Etherpad、GitHub、issue tracker。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-10-23 :: Ceph Code walk-through: Consistency with OSD Peering","slug":"2018-10-23_-_-_Ceph_Code_walk-through_-_Consistency_with_OSD_Peering","date":"2018-11-01T16:00:00.000Z","updated":"2018-11-02T16:00:00.000Z","comments":true,"path":"2018/11/02/2018-10-23_-_-_Ceph_Code_walk-through_-_Consistency_with_OSD_Peering/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/02/2018-10-23_-_-_Ceph_Code_walk-through_-_Consistency_with_OSD_Peering/","excerpt":"","text":"会议纪要： 会议主题： Ceph分布式存储系统中对等状态同步（Peering）过程的讨论 会议时间： 未知 参会人员： Brad（主讲人）、Tim（提问者）及其他未具名参与者 会议内容： Peering过程概述： Peering是一个同步所有OSD（对象存储设备）对数据对象状态和元数据的过程，由主OSD驱动，主要通过状态机实现。 Peering过程主要发生在PGH（Placement Group Header）和PGCC（Placement Group Cache）中。 会议重点介绍了Peering过程中的状态机实现和相关状态转换。 Peering状态机： 状态机使用Boost State Chart库实现，嵌入在HPG（Heap）中。 Peering状态机包含多个状态，例如初始状态、重置状态、启动状态、主状态、对等状态等。 状态之间的转换由事件触发，例如激活事件、初始化事件、获取信息事件、获取日志事件等。 Peering关键步骤： 获取信息： 向其他OSD查询PG信息T结构，包括版本号、最后完成时间、最后启动时间等。 选择活动集： 根据获取的信息，选择最佳的活动集。 获取日志： 从其他OSD获取权威日志。 处理主日志： 将权威日志与本地日志合并。 获取缺失数据： 请求缺失数据集和完整日志。 激活： 创建激活事件，将状态机切换到活动状态。 确认激活： 所有副本激活并确认后，更新PG信息T结构中的历史记录。 恢复： 根据需要执行恢复操作，例如回填和日志处理。 会议讨论要点： 会议重点讨论了Peering过程中的状态机实现、状态转换、事件处理等关键细节。 讨论了选择权威日志、处理缺失数据、确认激活等关键步骤。 讨论了Peering过程中的错误处理和异常情况。 后续行动计划： Brad将提供相关文档和代码链接，方便参会者进一步学习和研究。 参会者可以在邮件、IRC等渠道向Brad提问，继续讨论Peering过程。 会议总结： 本次会议深入讨论了Ceph分布式存储系统中对等状态同步（Peering）过程，对Peering状态机、关键步骤和实现细节进行了详细讲解。会议内容有助于参会者更好地理解Peering过程，并为后续的开发和维护工作提供参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-11-01","slug":"Ceph_Performance_Meeting_2018-11-01","date":"2018-11-01T16:00:00.000Z","updated":"2018-11-02T16:00:00.000Z","comments":true,"path":"2018/11/02/Ceph_Performance_Meeting_2018-11-01/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/02/Ceph_Performance_Meeting_2018-11-01/","excerpt":"","text":"会议纪要 会议时间：万圣节之后的一天 参会人员：Mark、Nick、Josh、Sage、Igor、Radek、Adam（远程） 会议主题：Ceph分布式存储项目进展与讨论 一、会议关键细节 本次会议由于假期原因，参会人员较少，但讨论内容丰富。 会议主要围绕Ceph项目的PR（Pull Requests）进展、代码优化、性能提升等方面展开。 二、讨论的主要议题 PR进展： Radek本周提交了3个新的PRS，其中包括一个关于超合并缓冲列表的PR，受到了大家的关注。 Sage正在审查一个关于BlueFest的PRS，目前处于初步审查阶段。 Erik正在研究IO节流器，对此大家表示支持。 Josh提到CS Career项目中存在一些问题，需要进一步解决。 代码优化与性能提升： Mark提到Radek的合并缓冲列表PR可能会对代码性能产生积极影响。 Sage提出了关于原子对象PR的命名问题，目前尚无定论。 大家讨论了关于C++接口的稳定性问题，考虑放弃对C++ API的稳定性保证，以便更好地进行代码维护和优化。 Matt提到Adam的一个旧PRS最近得到了更新，值得关注。 BlueStore性能优化： Nick和Josh讨论了BlueStore的分区大小问题，认为需要调整层级结构以更好地利用SSD。 Sage提出了一种自动调整层级大小和乘数的方法，以优化使用SSD的性能。 大家探讨了将部分层级存储在SSD上的可能性，但目前尚无明确解决方案。 三、决定的事项 继续关注Radek的合并缓冲列表PR，并尝试将其应用于其他代码优化。 对C++接口的稳定性问题进行讨论，考虑放弃对C++ API的稳定性保证。 关注Adam的更新PR，并评估其价值。 进一步研究BlueStore的性能优化问题，寻找改进方案。 四、后续行动计划 Mark将继续跟进Radek的合并缓冲列表PR。 Sage将继续审查BlueFest的PRS。 大家将共同讨论C++接口的稳定性问题。 Nick和Josh将研究BlueStore的性能优化方案。 会议结束后，参会人员将就讨论内容进行进一步沟通和协作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Meeting 2018-10-31","slug":"Ceph_Testing_Meeting_2018-10-31","date":"2018-11-01T16:00:00.000Z","updated":"2018-11-01T16:00:00.000Z","comments":true,"path":"2018/11/02/Ceph_Testing_Meeting_2018-10-31/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/02/Ceph_Testing_Meeting_2018-10-31/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： [此处填写参会人员姓名] 会议主题： Ceph分布式存储项目讨论及PR（Pull Request）审查 会议内容： 1. PR审查及讨论 Orchestra或remote nutshell的PR： 已有PR提交，计划立即合并。 IP日志的PR： 由于近期有相关需求，等待进一步审查。 2. Samba测试及IPv6支持 Samba测试： 项目组询问Samba在Ceph上的测试情况，特别是是否支持IPv6。项目组成员表示目前主要使用IPv4，对IPv6支持情况不太清楚。 IPv6支持： 讨论到Ceph节点是否支持IPv6，项目组成员表示目前不确定，可能需要手动覆盖。 3. 单元测试问题 单元测试失败： 项目组成员提到单元测试失败的问题，怀疑是由于节点间名称冲突导致的。 解决方案： 计划进一步调查，并与相关人员进行沟通。 4. 其他事项 部分成员借用设备： 有成员提到借用设备进行测试，不影响项目进度。 时间调整： 提醒大家注意时差变化。 后续行动计划： 审查并合并IP日志的PR。 调查单元测试失败的原因。 关注Samba在Ceph上的测试情况，特别是IPv6支持。 备注： 会议中涉及的部分计算机科学/ceph相关领域英文关键词：PR, Orchestra, remote nutshell, Samba, IPv6, NAT, DNS, Unit test。 会议总结： 本次会议主要讨论了Ceph分布式存储项目的PR审查、Samba测试、IPv6支持以及单元测试等问题。会议明确了后续行动计划，并要求相关人员进行调查和解决。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Crimson/Seastar OSD 2018-10-30","slug":"Crimson_Seastar_OSD_2018-10-30","date":"2018-11-01T16:00:00.000Z","updated":"2018-11-01T16:00:00.000Z","comments":true,"path":"2018/11/02/Crimson_Seastar_OSD_2018-10-30/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/11/02/Crimson_Seastar_OSD_2018-10-30/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Doritos、Paul、Adam Koochick、Co her、Tara、Kelsey、Whitney、Red Oak、Mission、Rider、Dragon、Cool 等 会议主题： Ceph 分布式存储系统相关议题讨论 会议内容： 一、会议时间调整 由于时区差异，会议时间进行了调整。原定于两周后的会议将提前一周举行，并比原计划提前一小时开始。 二、Ceph 当前 OSD 优化 优化目标： 降低 OSD 逻辑复杂度，提高性能。 优化方法： 通过优化当前 OSD 中的数据依赖关系，减少不必要的路径，简化操作流程。 优化方向： 从读取操作入手，尝试在复制的存储桶中进行优化。 技术难点： 需要解决多线程访问、锁冲突等问题。 实施计划： 首先，确定需要优化的代码范围。 其次，针对读取操作进行优化，减少不必要的路径。 最后，逐步扩展到其他操作。 三、Ceph 内存存储优化 优化目标： 降低内存存储的复杂度，提高性能。 优化方法： 使用 SISTAR 等技术，简化内存存储的读写操作。 将内存存储的读写操作与 SISTAR 的调度策略相结合，提高性能。 技术难点： 需要解决多线程访问、锁冲突等问题。 需要保证数据的一致性。 实施计划： 首先，评估 SISTAR 技术的可行性。 其次，确定内存存储的读写操作与 SISTAR 的结合方式。 最后，进行测试和优化。 四、Ceph 与 RocksDB 集成 集成目标： 将 RocksDB 集成到 Ceph 中，提高 Ceph 的性能和可靠性。 集成方法： 使用 SISTAR 等技术，简化 RocksDB 的读写操作。 将 RocksDB 的读写操作与 SISTAR 的调度策略相结合，提高性能。 技术难点： 需要解决多线程访问、锁冲突等问题。 需要保证数据的一致性。 实施计划： 首先，评估 SISTAR 技术的可行性。 其次，确定 RocksDB 的读写操作与 SISTAR 的结合方式。 最后，进行测试和优化。 五、其他事项 会议频率：参会人员建议将会议频率调整为每周一次。 项目进度：各项目负责人汇报了项目进度，并讨论了后续工作计划。 后续行动计划： 各项目负责人根据会议讨论结果，制定详细的实施计划。 定期召开会议，跟踪项目进度，解决问题。 及时分享项目进展，促进团队协作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Docubetter Meeting 2018-10-26","slug":"Ceph_Docubetter_Meeting_2018-10-26","date":"2018-10-25T16:00:00.000Z","updated":"2018-10-26T16:00:00.000Z","comments":true,"path":"2018/10/26/Ceph_Docubetter_Meeting_2018-10-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/26/Ceph_Docubetter_Meeting_2018-10-26/","excerpt":"","text":"会议纪要 会议主题： Ceph文档改进项目进展及下一步计划 会议时间： 2023年11月（具体日期未提及） 参会人员： Digger, Gaurav, Neha 等 会议内容： 一、项目进展 文档编辑链接： 已完成文档编辑链接的初步实现，仅对受支持的分支显示。 目前处于模拟状态，需在master分支部署后才能完全使用。 需要处理开发版本链接问题，考虑链接到master或直接删除链接。 文档问题报告： 添加了报告文档问题的功能，链接至项目页面。 需要完善报告页面，添加用户指南。 其他功能： 讨论了版本间跳转、搜索优化等功能的优先级。 二、讨论议题 文档编辑链接的改进： 考虑链接到master或删除链接。 需要处理开发版本链接问题。 文档问题报告： 完善报告页面，添加用户指南。 版本间跳转： 考虑添加界面元素方便用户在不同版本间跳转。 搜索优化： 考虑使用 canonical links 和黑名单技术优化搜索结果。 考虑将文档URL始终重定向到最新稳定版本。 三、决定事项 文档编辑链接： 完成开发版本链接问题的处理。 完成文档问题报告页面的完善。 搜索优化： 下周五讨论搜索优化方案。 版本间跳转： 评估版本间跳转功能的可行性。 四、后续行动计划 Digger： 完成文档编辑链接和问题报告页面的改进。 阅读相关资料，为搜索优化方案做准备。 Neha： 收集用户反馈，评估版本间跳转功能的可行性。 全体成员： 积极参与文档改进项目，共同提升Ceph文档质量。 五、下次会议 下周五讨论搜索优化方案。 下周继续跟进文档改进项目进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-09-25 :: Ceph code walk-through :: ceph-objectstore-tool","slug":"2018-09-25_-_-_Ceph_code_walk-through_-_-_ceph-objectstore-tool","date":"2018-10-24T16:00:00.000Z","updated":"2018-10-25T16:00:00.000Z","comments":true,"path":"2018/10/25/2018-09-25_-_-_Ceph_code_walk-through_-_-_ceph-objectstore-tool/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/25/2018-09-25_-_-_Ceph_code_walk-through_-_-_ceph-objectstore-tool/","excerpt":"","text":"会议纪要 会议主题： Ceph对象存储工具代码审查 会议时间： 2023年11月（具体日期未提及） 参会人员： David（Ceph研发人员）、Mike（Ceph用户） 会议内容： 一、会议开场 David介绍了Ceph对象存储工具（OP）的功能和用途，OP允许用户修改对象和OSD的状态，但需要在OSD停止运行时进行。 二、OP选项和用法 选项解析： OP使用Boost选项库进行解析，支持位置参数和常规参数。原始命令使用--open参数执行所有操作，但现在可以通过指定对象名称和附加命令来执行操作。 历史遗留问题： 由于历史原因，OP的解析方式较为复杂，例如--op和对象语法不能同时使用，但list op和apply layout存在例外。 功能分类： 新增功能通常以对象或偏移为基础，例如列出对象、修改对象等。 三、OP功能示例 列出对象： 使用list命令列出所有对象的JSON信息，以便选择要操作的对象。 修改对象： 使用set bytes命令将数据写入对象，例如set bytes object_name file_path。 导出和导入PG： 使用export命令导出PG，使用import命令将对象导入到不同的存储池或集群。 四、安全注意事项 在修改对象之前，建议先导出PG，以防万一出现错误。 使用force选项删除PG时需要谨慎，可能会造成不可逆的损失。 五、代码审查 OP工具使用与OSD相同的库和函数，因此不应在此处重复OSD代码。 添加新功能时，应确保功能与OSD的对应功能一致。 六、问题解答 版本兼容性： 应使用与Ceph版本相对应的OP工具版本。 FreeBSD问题： 在FreeBSD上使用OP工具时，可能需要调整编译选项，以确保兼容性。 七、后续行动 更新内部文档，包括OP工具的使用说明和代码审查指南。 针对FreeBSD用户，提供更详细的兼容性说明。 八、会议总结 本次会议对Ceph对象存储工具进行了代码审查和功能介绍，讨论了OP的使用方法和注意事项，并解答了用户提出的问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-10-25","slug":"Ceph_Performance_Meeting_2018-10-25","date":"2018-10-24T16:00:00.000Z","updated":"2018-10-25T16:00:00.000Z","comments":true,"path":"2018/10/25/Ceph_Performance_Meeting_2018-10-25/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/25/Ceph_Performance_Meeting_2018-10-25/","excerpt":"","text":"会议时间： 2023年11月某日 会议地点： 远程会议 参会人员： Brett、Radek、Neha、Adam、Jason、Sage、Nick、Josh、Matt、Eric 等 会议主题： Ceph 项目进展及问题讨论 PR 审批及后续行动 Numa 架构优化 OMAP 性能测试 RocksDB 数据库优化 会议内容： 一、PR 审批及后续行动 Radek 的 PR： 讨论了 Radek 提交的多个 PR，包括缓冲区历史工作、性能测试、数据依赖性分析等。会议决定将大型 PR 分解成更小的部分进行审查，并讨论了简化热点路径的复杂性的方案。 其他 PR： 讨论了其他 PR 的进展，包括 gzip 压缩、stack string stream、延迟延迟、OMAP 测试等。 遗留问题： 讨论了遗留问题的处理，包括 attic、slapped allocators、临时内存池计数器等。 二、Numa 架构优化 讨论了 Numa 架构优化方案，包括 pinning Numa 节点内存、OSD 跨多个 Numa 节点分布等。 认识到 Numa 架构优化是一个复杂的问题，需要谨慎处理，并确保不会降低性能。 三、OMAP 性能测试 讨论了 OMAP 性能测试结果，包括单操作延迟、DB 大小等。 认识到 RocksDB 数据库的 DB 大小设置需要优化，以确保性能。 讨论了 OMAP 操作批处理的可能性，以提高性能。 四、RocksDB 数据库优化 讨论了 RocksDB 数据库的优化方案，包括自动调整级别大小、压缩和写放大等。 认识到 RocksDB 的级别大小设置需要优化，以确保性能。 五、其他 讨论了 Ratos Bench 的优化，以及是否将重点放在 OMAP 性能测试上。 讨论了 RocksDB 的 tombstones 问题。 行动计划： Radek：将大型 PR 分解成更小的部分进行审查，并讨论简化热点路径的复杂性的方案。 Neha 和 Adam：调查 stack string stream 中的崩溃问题。 Sage：调查 clean PG set 仍然刷新的问题。 Nick：调查 RocksDB 的 DB 大小设置问题，并尝试优化级别大小。 Josh 和 Matt：讨论 OMAP 操作批处理的可能性。 Eric：调查 RocksDB 的 tombstones 问题。 总结： 本次会议讨论了 Ceph 项目的多个重要议题，并制定了相应的行动计划。会议强调了 PR 审批、Numa 架构优化、OMAP 性能测试和 RocksDB 数据库优化的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Meeting 2018-10-24","slug":"Ceph_Testing_Meeting_2018-10-24","date":"2018-10-23T16:00:00.000Z","updated":"2018-10-24T16:00:00.000Z","comments":true,"path":"2018/10/24/Ceph_Testing_Meeting_2018-10-24/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/24/Ceph_Testing_Meeting_2018-10-24/","excerpt":"","text":"会议纪要 会议时间： 未知 参会人员： John（疑似主持人）、Greg、Austin、Adkison、Ripples、Norge、Nathan 会议内容： 1. PR审查 Greg提到有一个PR需要审查，该PR修改了OpenStack的入口脚本，涉及对测试包的安装和配置。 Adkison解释了PR的背景和目的，包括向后兼容性、OpenStack版本支持和不同平台差异。 会议讨论了PR中的一些关键点，如： 对OpenStack后端的修改可能仅影响openSUSE用户。 添加了针对openSUSE的特定选项，需要进一步支持Red Hat和Ubuntu。 需要审查测试报告的修改，确保不影响其他用户。 需要解决测试线程安全问题。 会议决定由Adkison完成PR的审查和修改，Greg将提供反馈。 2. OpenStack部署 Nathan介绍了正在进行的OpenStack部署工作，包括使用Ansible脚本和Touji工具。 会议讨论了部署过程中遇到的一些问题，如： 需要配置外部DNS，以解决OpenStack实例之间的通信问题。 需要为不同平台和区域添加Ansible角色。 会议建议使用Touji角色来管理OpenStack配置文件，并讨论了如何改进该角色的功能。 3. 测试 Norge提到了使用Jenkins进行测试的问题，包括使用较旧版本的Pillow导致测试失败。 会议讨论了以下问题： 需要定期更新依赖项版本，以避免意外中断。 需要修复Pillow中的问题，以支持较新版本。 需要改进测试的可用性，例如隔离需要资源测试用例和解决线程安全问题。 4. 其他事项 会议还讨论了以下事项： 使用Clouds模式配置OpenStack，以避免存储敏感信息。 使用Ansible角色管理不同平台和区域的配置。 后续行动计划： Adkison完成PR的审查和修改。 Nathan继续进行OpenStack部署工作。 Norge解决测试问题，并改进测试的可用性。 全体成员定期更新依赖项版本。 会议总结： 本次会议主要讨论了PR审查、OpenStack部署和测试相关的问题。会议明确了后续行动计划，并推动了相关工作的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Virtual Cluster on Blender + Python","slug":"Ceph_Virtual_Cluster_on_Blender_+_Python","date":"2018-10-23T16:00:00.000Z","updated":"2018-10-24T16:00:00.000Z","comments":true,"path":"2018/10/24/Ceph_Virtual_Cluster_on_Blender_+_Python/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/24/Ceph_Virtual_Cluster_on_Blender_+_Python/","excerpt":"","text":"会议纪要 会议主题： 分布式存储系统Ceph性能测试与优化 参会人员： Dan Garcia（主持人）及其他团队成员 会议内容： 一、项目展示 3D交互式服务器室界面： Dan展示了一个使用Blender软件制作的3D交互式服务器室界面，其中地板和通风口等细节与实际服务器室一致。 Aterna CD 10000机架介绍： 该机架由四个节点组成，包括一个管理节点和三个交换机，用于公共集群和管理节点网络。 二、Ceph性能测试 OSD状态管理： 当OSD处于非“up”状态时，相关磁盘将被移除，并在必要时重新启动。 CPU亲和性调整： 使用Linux Red Hat的CPU亲和性工具调整系统设置，并通过CPM工具调整CPU亲和性，以模拟大量瓶颈。 性能测试： 使用Rattle基准测试进行性能测试，包括吞吐量性能和延迟性能。 网络瓶颈模拟： 在虚拟环境中模拟网络瓶颈，如数据丢失和延迟，以测试集群网络的性能。 三、测试结果分析 延迟对读取性能的影响： 在添加1毫秒延迟后，读取性能从15MB/s降至60MB/s。 数据包丢失对读取性能的影响： 在公共网络中添加10%的数据包丢失会导致读取性能大幅下降。 CPU亲和性对带宽的影响： 将所有OSD分配到一个逻辑CPU核心会导致带宽下降，但将OSD线程分配到逻辑CPU可以优化性能。 特定线程行为： 通过调整CPU亲和性，可以观察特定线程的行为，从而优化性能。 四、后续行动计划 继续进行性能测试，验证不同配置对性能的影响。 优化Ceph集群配置，提高性能和稳定性。 撰写测试报告，总结测试结果和优化建议。 五、会议总结 本次会议介绍了Ceph性能测试与优化方法，并通过实际测试结果验证了不同配置对性能的影响。下一步将继续优化Ceph集群配置，以提高性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-10-11","slug":"Ceph_Performance_Meeting_2018-10-11","date":"2018-10-17T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/18/Ceph_Performance_Meeting_2018-10-11/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/18/Ceph_Performance_Meeting_2018-10-11/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Radek、Adam、Braddock、Adam（视频会议字幕翻译及总结人员）、Matt、Kyle、Nick 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、PRS进展 Radek和Adam正在开发两阶段提交机制和编码相关功能，预计将大幅提升性能，减少缓冲区指针的错误使用。 该机制将消除整数字段中的跳转检查，这对于性能调优尤为重要，尤其是在客户端动态链接的情况下。 探讨了优化缓冲区列表的几种方法，包括： 将缓冲区指针内联化，并使用编译器去除死代码。 使用连续填充器将小缓冲区指针编码到更大的对象中。 在编译时使用restrict关键字，以允许编译器进行死代码消除。 二、其他PR讨论 讨论了多个PR，包括API更改、删除不再使用的请求重定向指令、优化缓冲区列表等。 重点讨论了以下PR： 将缓冲区指针与缓冲区进行生命周期连接，并允许不同的缓冲区指针引用相同的缓冲区。 使用 intrusive 构造来管理内存，并允许在单个内存块中分配数据封装的缓冲区行、缓冲区指针和缓冲区指针。 三、分布式数据缓存PR 讨论了用于Radius GW的分布式数据缓存PR。 该PR使用关联缓存结构，并与其他缓存机制结合，以实现更好的性能和一致性。 该PR主要应用于处理Hadoop、Spark和Linux工作负载的多租户环境。 四、Numa节点优化 讨论了Numa节点优化，以及如何将进程或线程绑定到特定的Numa节点以提高性能。 讨论了以下方法： 在Crush Map中添加Numa节点级别，以允许OSD智能地映射到正确的Numa节点。 使用系统控制命令将进程绑定到特定的CPU核心。 与硬件供应商合作，以优化Numa节点布局。 五、其他事项 讨论了以下事项： Nick关于缓存模式交换的PR。 Nick关于延迟写入的PR。 Nick关于缓存命中集的PR。 行动计划： Radek和Adam继续开发两阶段提交机制和编码相关功能。 审查和合并其他PR。 讨论分布式数据缓存PR的进一步优化。 与硬件供应商合作，以优化Numa节点布局。 回复Nick关于缓存模式交换、延迟写入和缓存命中集的PR。 总结： 本次会议讨论了Ceph分布式存储项目的多个方面，包括PRS进展、其他PR讨论、分布式数据缓存PR、Numa节点优化以及其他事项。会议确定了下一步行动计划，以推动Ceph项目的进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-10-18","slug":"Ceph_Performance_Meeting_2018-10-18","date":"2018-10-17T16:00:00.000Z","updated":"2018-10-18T16:00:00.000Z","comments":true,"path":"2018/10/18/Ceph_Performance_Meeting_2018-10-18/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/18/Ceph_Performance_Meeting_2018-10-18/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月（具体日期未提及） 参会人员： Nick、Radek、Sage、Josh、Greg、Steve、Angie、Peter、Doug等 会议主题： Ceph分布式存储项目开发进展及讨论 关键细节： Pull Requests： Radek提交了一个针对边界代码的优化请求，通过减少容器分配的内存需求来提高效率。 Radek还提交了一个针对编译器优化的请求，特别是对于Ceph列表中空数据部分的优化。 Sage合并了Radek提交的字符串处理代码。 Radek提出了一个关于调试信息的讨论，包括是否应该保留调试信息以及如何减少调试信息的数量。 其他Pull Requests包括缓存大小增加、DMA问题、RBD性能优化等。 调试信息： 会议讨论了调试信息的重要性以及如何减少调试信息的数量。 一些建议包括引入缓存机制、减少不必要的字符串操作以及重新评估日志记录策略。 RocksDB： 讨论了将RocksDB缓存集成到mempool基础设施中的可行性。 讨论了关于RocksDB内存分配策略的改进。 Ceph性能： 讨论了Ceph性能优化，包括RBD性能优化、对象存储性能优化等。 讨论了如何减少CPU使用率以及如何提高性能。 决定的事项： 接受Radek提交的关于边界代码和编译器优化的Pull Requests。 继续讨论调试信息的问题，并尝试减少调试信息的数量。 将RocksDB缓存集成到mempool基础设施中。 继续优化Ceph性能。 后续行动计划： Nick将跟进关于调试信息的问题。 Radek将继续优化RBD性能。 Sage将继续合并PullRequests。 其他团队成员将继续进行Ceph性能优化工作。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，例如： Pull Requests RocksDB mempool RBD EC SSD CPU latency throughput workload","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-10-04","slug":"Ceph_Performance_Meeting_2018-10-04","date":"2018-10-17T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/18/Ceph_Performance_Meeting_2018-10-04/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/18/Ceph_Performance_Meeting_2018-10-04/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Adam, Nick, Sage, Casey, Jason, 以及其他未具名成员 会议主题： Ceph 存储系统开发进展和讨论 会议内容： 1. 新 pull requests Radek 提交的 pull request 改进了字符串处理，这是一个相对较小的改动，但效果显著。 Lebar 和 BD 共享的持久只读 RBD 缓存工作正在进行中，可能即将有新的代码提交。 2. Quick Blue Store 评估 Nick 对 Quick Blue Store 进行了实际评估，发现其性能表现良好，但存在一些问题。 优点： 压缩率约为 1.5 倍。 重写操作简单。 SSD 预测写入性能提升。 快照性能更好。 缺点： 部分用例中性能较差。 延迟写入对新对象不适用，导致性能下降。 中等大小的写入操作（64KB 到 512KB）性能较差，因为超过延迟写入阈值后，所有操作都依赖于底层磁盘速度。 缺少合并，导致磁盘利用率过高。 建议： 增加延迟写入阈值，以覆盖更大尺寸的写入操作。 考虑在 Blue Store 中使用缓存撕裂和写回技术。 使用 RAID 控制器和电池备份缓存，以改善性能。 3. ASIO 和 C++ 异步库 Adam 介绍了 ASIO 异步网络和 I/O 层，它基于反应器模式，可以减少线程数量并提高效率。 ASIO 库的目的是： 提供一个原生异步和集成到 Ceph 中的库。 避免不必要的内存分配。 提供更高级别的功能，例如命名空间和定位键。 统一 Rados 的各种线程执行上下文。 Sage 和 Casey 讨论了 ASIO 库在 RGW 中的应用，包括协程和线程池。 4. 后续行动计划 Nick 将继续对 Quick Blue Store 进行测试和评估。 Adam 将继续开发 ASIO 库，并与其他开发者合作改进其性能。 Sage 和 Casey 将探索 ASIO 库在 RGW 中的应用。 Jason Dolman 将参与性能测试和评估。 会议总结： 本次会议讨论了 Ceph 存储系统开发中的多个重要议题，包括 Quick Blue Store 的性能评估和 ASIO 异步库的开发。与会者就这些问题进行了深入讨论，并制定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Meeting 2018-10-03","slug":"Ceph_Testing_Meeting_2018-10-03","date":"2018-10-17T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/18/Ceph_Testing_Meeting_2018-10-03/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/18/Ceph_Testing_Meeting_2018-10-03/","excerpt":"","text":"会议纪要 会议时间： [此处填写会议时间] 参会人员： [此处填写参会人员名单] 会议内容： 1. 问候与自我介绍 - 会议开始，大家互相问候，并介绍了自己的工作地点和近况。 2. 主题讨论 - 议题一：Ceph 存储请求 - 有成员提到有一个存储请求（pool request）已经两周没有回应，需要跟进。 - 另一个成员提到有多个与 openSUSE 相关的池请求，建议同时测试。 议题二：Ansible 项目 有成员提到 Ansible 项目目前使用人数不多，预计在一周内处理。 有成员询问关于 openSUSE leap 的 OPR Insaf（OpenStack Provider Resource）请求，希望得到评审意见。 议题三：配置管理 有成员讨论了配置管理的问题，包括如何支持多种操作系统和版本。 提到可以使用 symbolic link 从配置集合中选取特定配置。 议题四：操作系统选择 有成员询问关于操作系统选择的问题，包括是否支持所有操作系统或随机选择。 讨论了在使用配置管理工具时如何处理操作系统配置。 议题五：Luminess 项目 有成员提到 Luminess 项目中的 sleep before teardown 特性需要重构，以便与并行和顺序执行兼容。 3. 行动计划 - 跟进存储请求，确保及时得到回应。 - 处理 Ansible 项目，在一周内完成。 - 完成openSUSE leap的 OPR Insaf 请求的评审。 - 研究操作系统选择问题，并优化配置管理。 - 重构 Luminess 项目中的 sleep before teardown 特性。 会议总结： 本次会议讨论了 Ceph 存储请求、Ansible 项目、配置管理和操作系统选择等问题，并制定了相应的行动计划。会议气氛积极，大家积极参与讨论，为项目的顺利进行提供了有力保障。 下次会议时间： [此处填写下一次会议时间]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Meeting 2018-10-10","slug":"Ceph_Testing_Meeting_2018-10-10","date":"2018-10-17T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/18/Ceph_Testing_Meeting_2018-10-10/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/18/Ceph_Testing_Meeting_2018-10-10/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph存储系统及视频会议字幕翻译相关议题讨论 关键细节： Ceph存储系统更新： Nathan不在，Zack可能需要会议。 发现两个新的PRS列表项，一个关于打包，另一个是关于 cherry-picks 的，涉及Loic和Nathan的工作，但仅用于测试仓库。 讨论了 cherry-picks 的功能，它是一个扩展安装任务，允许在配置目标后选择性使用repose，目前仅支持zipper。 强调了该功能不应影响代码的其他部分，主要是针对openSUSE的。 文件系统问题： 讨论了Ceph文件系统在13.2版本中的问题，并计划在未来一周或两周内进一步讨论。 提出了使用sahaba corpus encode和decode来防止此类问题的可能性。 视频会议字幕翻译： 讨论了subsea的更改，可以继续进行工作。 计划部署测试实例，并在Voyager上运行一些示例任务。 提出了关于病理日志的问题，特别是关于如何隐藏敏感信息。 讨论了在部署过程中可能暴露敏感变量的情况，并建议在echo环境变量时使用grep来过滤敏感变量。 讨论的主要议题： cherry-picks的功能和适用性 Ceph文件系统的问题和解决方案 视频会议字幕翻译中的敏感信息保护 决定的事项： 进一步调查和讨论Ceph文件系统的问题。 Nginx和OpenStack CLI的使用，特别是关于敏感信息保护。 检查openSUSE和上游代码，以确定敏感信息暴露的位置。 后续行动计划： [负责人] 将调查Ceph文件系统的问题，并准备下周的讨论。 [负责人] 将查找有关openSUSE和上游代码的信息，以确定敏感信息暴露的位置。 [负责人] 将尝试部署测试实例，并测试病理日志的敏感性。 其他事项： [请填写其他需要记录的事项] [会议结束]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Meeting 2018-10-17","slug":"Ceph_Testing_Meeting_2018-10-17","date":"2018-10-17T16:00:00.000Z","updated":"2018-10-18T16:00:00.000Z","comments":true,"path":"2018/10/18/Ceph_Testing_Meeting_2018-10-17/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/18/Ceph_Testing_Meeting_2018-10-17/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph 存储项目开发讨论与问题解决 会议内容： 1. 维护活动： - 讨论了是否进行维护活动，但决定可能今天不进行在线维护。 - Nathan 在线，讨论了相关的 PRs，并提到有一个 PR 已准备好合并。 2. 内部讨论： - 有关安装界面的设置讨论正在进行中，计划下周开始着手进行。 - 目前正在审查 outstanding PRs，特别是关于自定义仓库的 PR。 3. 技术问题与解决方案： - 讨论了关于大系列补丁的问题，指出这些补丁可能需要一些额外的“punch”来确保夏季级别的修复。 - 讨论了测试环境中的问题，特别是关于测试脚本 talks 的使用。 - 使用了虚拟环境来手动运行测试，因为 talks 需要从系统中安装旧的依赖项，无法升级到最新版本。 - 发现了系统中的某些问题，需要从上游获取帮助来解决。 4. Jenkins 任务： - 讨论了 Jenkins 任务的使用，特别是针对 SAP Jenkins 任务的审查。 - 发现了一个使用系统 Python 打包的设置，而不是使用自定义打包，这让人感到意外。 5. 行动计划： - Nathan 将审查自定义仓库的 PR。 - 计划下周开始设置安装界面。 - 解决测试环境中的问题，并从上游获取帮助。 - 审查 Jenkins 任务，并确保其正确性。 6. 其他事项： - 如果在开发过程中遇到问题，可以通过邮件或 CC 讨论者来寻求帮助。 - 鼓励大家更多地参与讨论。 会议总结： 本次会议讨论了 Ceph 存储项目开发中的多个问题，并制定了相应的解决方案和行动计划。会议强调了测试环境和 Jenkins 任务的正确性，并鼓励大家积极参与讨论和解决问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-09-27","slug":"Ceph_Performance_Meeting_2018-09-27","date":"2018-10-16T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/17/Ceph_Performance_Meeting_2018-09-27/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/17/Ceph_Performance_Meeting_2018-09-27/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage（缺席）、Radek、Braddock、Casey、Jason、Ilya、Dr. Lyric Easy、Nelson、Josh、Reich 会议主题： Ceph分布式存储项目讨论 会议内容： 一、新特性与改进 Sage缓存大小调整： Sage计划增加mon节点的缓存大小，尤其是ark rocks DB缓存。 讨论了自动调整缓存大小的工作，并考虑是否应该在所有地方应用这种策略。 决定提高mon节点的缓存大小，以解决之前遇到的问题。 Radek的工作： Radek正在处理向后迭代、缓冲列表等问题，以降低编码宏和常量的开销。 讨论了缓冲列表中追加操作的性能问题，并考虑了优化方案。 引入了基于共享内存的计数器，以优化内存使用。 Braddock的工作： Braddock正在优化mempool和slab分配器，以便更好地管理内存。 讨论了在C*世界中如何应用这种优化方法。 **C*内存模型**： 讨论了C*内存模型的长期方向，以及如何逐步实现。 认为采用逐步改进的策略比革命性的改变更为可行。 异步消息传递： 讨论了异步消息传递的性能问题，并考虑了优化方案。 认为通过优化消息传递组件，可以提高整体性能。 二、其他事项 Exodus默认AG账户问题： 讨论了Exodus默认AG账户导致性能问题的情况。 认为需要改进BD设备导出，以使i/o调度器做出更好的选择。 对象存储： 讨论了对象存储中的性能问题，并考虑了优化方案。 Pet Store项目： 讨论了Pet Store项目的进展，并考虑了将其迁移到主分支。 三、后续行动计划 Radek继续优化缓冲列表和异步消息传递。 Braddock继续优化mempool和slab分配器。 Dr. Lyric Easy和Adam讨论对象存储项目。 Nelson准备下周的会议议题。 四、会议总结 本次会议讨论了Ceph分布式存储项目的多个方面，包括新特性、改进方案和后续行动计划。参会人员积极参与讨论，并提出了许多有价值的建议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 20180-9-20","slug":"Ceph_Performance_Meeting_20180-9-20","date":"2018-10-16T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/17/Ceph_Performance_Meeting_20180-9-20/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/17/Ceph_Performance_Meeting_20180-9-20/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Radek、Sage、Greg、Fisher、Justin、Steph、Mark、Igor、Adrian、Marcus、Dieter、Freeman、Matt、Shelby等 会议主题： Ceph分布式存储系统开发讨论 关键细节： Pull Requests： Sage移除了一些不再使用的死代码，包括mutex性能计数器，以避免堆分配。 有关OST碎片线程提交的改进，提高了调试日志的速度，并对某些情况下的性能提升了100%。 有关容器与slab分配的优化，以及使用持久内存作为RBD持久缓存的改进。 内存分配问题： 讨论了Ceph在内存分配方面的挑战，包括buffer列表的碎片化、对象池的使用以及TC Malloc分配器。 讨论了使用对象池来优化内存分配的可行性，以及如何处理内存在不同线程之间的流动。 讨论了使用环形缓冲区来处理内存分配的可行性，以及如何与零拷贝管道兼容。 性能优化： 讨论了Ceph在性能方面的挑战，包括CPU使用率、I/O吞吐量以及内存使用率。 讨论了使用性能计数器来跟踪内存分配和释放，以及如何使用基准测试来评估性能。 讨论了使用QoS框架来优化性能，以及如何将QoS应用于不同的工作负载。 决定的事项： Sage将负责合并PRS并解释相关改进。 Mark将继续解决内存分配问题，并探索使用对象池和环形缓冲区的可行性。 Marcus将负责创建一个“邪恶列表”，列出Ceph中存在内存分配问题的代码。 Matt将负责使用性能计数器和基准测试来评估Ceph的性能。 Shelby将负责使用QoS框架来优化Ceph的性能。 后续行动计划： Sage将合并PRS并更新相关代码。 Mark将探索使用对象池和环形缓冲区的可行性，并解决内存分配问题。 Marcus将创建一个“邪恶列表”。 Matt将使用性能计数器和基准测试来评估Ceph的性能。 Shelby将使用QoS框架来优化Ceph的性能。 其他事项： 讨论了Ceph与其他存储系统的比较，以及Ceph的优势和劣势。 讨论了Ceph社区的贡献和协作。 讨论了Ceph未来的发展方向。 关键词： Pull Requests Dead code Mutex Performance counter Heap allocation MDS Shard Persistent memory Buffer list Object pool TC Malloc Memory fragmentation Performance CPU utilization I/O throughput Quality of Service (QoS) Benchmark Black box testing","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Meeting 2018-09-26","slug":"Ceph_Testing_Meeting_2018-09-26","date":"2018-10-16T16:00:00.000Z","updated":"2018-10-17T16:00:00.000Z","comments":true,"path":"2018/10/17/Ceph_Testing_Meeting_2018-09-26/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/17/Ceph_Testing_Meeting_2018-09-26/","excerpt":"","text":"会议纪要 会议时间： 2023年9月26日 参会人员： Nathan, David, Greg, Ricardo, Zach, Kier, Ron, Warren等 会议主题： Ceph分布式存储项目进展及问题讨论 关键细节： 测试问题： Nathan提出，当任务在Ceph集群中运行时，如果任务运行时间超过12小时，则会超时并被杀死，导致没有远程目录，无法收集日志，这会对调试造成困难。 讨论了两种解决方案：使用不同的信号通知Ceph开始清理过程，或者将清理工作拆分到不同的进程。 决定优先解决日志收集问题，并考虑在测试中添加超时机制。 PR处理： 讨论了多个待处理的PR，包括Nathan的before teardown和dump context等。 决定合并部分PR，并处理冲突和问题。 其他事项： 讨论了Ceph社区测试页面和Jenkins测试权限问题。 讨论了Python 3兼容性问题。 讨论了SSH pull request的合并问题。 讨论的主要议题： 如何解决Ceph测试中日志收集问题。 如何处理待处理的PR。 如何改进Ceph测试和开发流程。 决定的事项： 优先解决日志收集问题，并考虑在测试中添加超时机制。 合并部分PR，并处理冲突和问题。 改进Ceph测试和开发流程。 后续行动计划： Nathan将继续研究日志收集问题，并与团队讨论解决方案。 Greg将处理待处理的PR，并协助解决冲突和问题。 David和Zach将改进Ceph测试和开发流程。 关键词： Ceph 分布式存储 测试 日志收集 PR Jenkins Python 3 SSH","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-08-28 :: Ceph Code walk-through: MonClient/Monitor","slug":"2018-08-28_-_-_Ceph_Code_walk-through_-_MonClient_Monitor","date":"2018-10-09T16:00:00.000Z","updated":"2018-10-09T16:00:00.000Z","comments":true,"path":"2018/10/10/2018-08-28_-_-_Ceph_Code_walk-through_-_MonClient_Monitor/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/10/10/2018-08-28_-_-_Ceph_Code_walk-through_-_MonClient_Monitor/","excerpt":"","text":"会议纪要 会议时间： （未提供具体时间） 会议地点： （未提供具体地点） 参会人员： （未提供具体人员） 会议主题： Ceph 分布式存储系统架构及监控机制讨论 关键细节： 1. 屏幕共享问题： - 会议开始时，由于连接问题，屏幕共享一度出现困难，但最终得以解决。 2. 代码阅读： - 会议主要围绕 Ceph 的代码进行阅读，特别是关于集群状态监控和配置更新的部分。 3. 监控机制： - 讨论了 Ceph 的监控机制，包括集群状态、存储池状态、OSD 状态等。 - 重点关注了集群日志、PG 状态、Monitor 状态等关键指标。 4. 命令解析： - 讨论了 Ceph 的命令解析机制，包括命令格式、参数解析、命令执行流程等。 - 举例说明了 ceph osd map 和 ceph mon dump 等命令的解析和执行过程。 5. 配置更新： - 讨论了 Ceph 的配置更新机制，包括配置文件的读取、配置项的更新、配置变更的同步等。 - 重点关注了配置变更的提案、审批、执行等流程。 6. 集群选举： - 讨论了 Ceph 集群选举机制，包括 Monitor 选举、OSD 选举等。 - 重点关注了选举流程、选举条件、选举失败处理等。 讨论的主要议题： Ceph 的监控机制如何实现？ Ceph 的命令解析机制如何实现？ Ceph 的配置更新机制如何实现？ Ceph 的集群选举机制如何实现？ 决定的事项： 继续阅读 Ceph 代码，深入理解其架构和实现原理。 完善 Ceph 的监控机制，提高监控数据的准确性和实时性。 优化 Ceph 的配置更新机制，提高配置变更的效率和可靠性。 研究 Ceph 的集群选举机制，提高集群的稳定性和可用性。 后续行动计划： 参会人员将继续阅读 Ceph 代码，并整理相关文档。 参会人员将针对 Ceph 的监控、配置更新、集群选举等方面进行深入研究。 参会人员将根据研究结果，提出改进方案并实施。 其他： 会议中提到了一些 Ceph 相关的英文关键词，如： Ceph OSD Monitor PG Cluster Configuration Election Map Command Proposal Transaction Timeout Authenticate Authorize Quorum Leader Follower Peer Commit Rollback Data Metadata Pool Health Status Log Message Interface Method Class Object Record Configuration Model Cluster Map OSD Map PG Map Monitor Map MonCommand MonCommandHandler MonCommandExecutor MonCommandClient MonCommandServer MonCommandChannel MonCommandConnection MonCommandAuth MonCommandAuthHandler MonCommandAuthMethod MonCommandAuthResponse MonCommandAuthStep MonCommandAuthTimeout MonCommandAuthError MonCommandAuthSuccess MonCommandAuthFailed MonCommandAuthChallenge MonCommandAuthResponse MonCommandAuthResponseHandler MonCommandAuthResponseSuccess MonCommandAuthResponseFailed MonCommandAuthResponseTimeout MonCommandAuthResponseError MonCommandAuthResponseAuthMethod MonCommandAuthResponseAuthStep MonCommandAuthResponseAuthTimeout MonCommandAuthResponseAuthError MonCommandAuthResponseAuthSuccess MonCommandAuthResponseAuthFailed MonCommandAuthResponseAuthChallenge MonCommandAuthResponseAuthResponse MonCommandAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthChallenge MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponse MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseHandler MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseSuccess MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseFailed MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseTimeout MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseError MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthMethod MonCommandAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthResponseAuthStep MonCommandAuthResponseAuth","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing 2018-09-19","slug":"Ceph_Testing_2018-09-19","date":"2018-09-20T16:00:00.000Z","updated":"2018-09-21T16:00:00.000Z","comments":true,"path":"2018/09/21/Ceph_Testing_2018-09-19/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/09/21/Ceph_Testing_2018-09-19/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Flake分析服务介绍及讨论 会议内容： ** Flake分析服务介绍**： 该服务用于自动检测测试失败中的 flakes（虚假阳性）。 使用基于聚类和分类的机器学习算法进行检测。 用户通过 REST API 上传数据，服务端进行分析并返回结果。 分析结果包含测试失败是否为 flakes 的概率值。 讨论要点： 数据格式： 现阶段要求用户上传的数据格式需要整洁，后续将开发数据清洗工具。 特征提取： 讨论了如何从日志中提取特征，包括堆栈跟踪、错误信息、文件名、函数调用等。 false positive 定义： 用户可以自定义 false positive 的定义，例如将合并失败的测试视为 false positive。 模型训练和查询： 讨论了模型训练和查询的流程，以及如何将训练数据和查询数据分开处理。 基础设施故障： 讨论了如何识别基础设施故障，例如网络故障、硬件故障等。 数据收集： 讨论了如何收集训练数据，例如从测试失败中收集数据，并手动标记 false positive。 行动计划： 开发数据清洗工具，方便用户上传整洁的数据。 优化特征提取算法，提高检测准确率。 完善 false positive 定义，方便用户使用。 开发模型训练和查询的流程，并确保其高效运行。 收集训练数据，并进行模型训练。 后续工作： 开发数据清洗工具。 优化特征提取算法。 完善 false positive 定义。 开发模型训练和查询的流程。 收集训练数据。 其他事项： 讨论了如何将 Flake 分析服务推广到其他团队。 讨论了如何将测试结果与 bug 系统关联。 备注： 会议中提到了一些 Ceph 相关的关键词，例如：flake、machine learning、classification、training、prediction、REST API、open shift、cluster、infrastructure failure、false positive、bug 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"ceph performance 2018-09-13","slug":"ceph_performance_2018-09-13","date":"2018-09-13T16:00:00.000Z","updated":"2018-09-14T16:00:00.000Z","comments":true,"path":"2018/09/14/ceph_performance_2018-09-13/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/09/14/ceph_performance_2018-09-13/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 会议地点： 远程会议 参会人员： Sage, Radek, Matt, Patrick, Kisi, Elaine, Mark 等 会议主题： Ceph 分布式存储项目进展及讨论 会议内容： 一、Ceph 存储性能优化 页面对齐问题： 针对ARM架构的页面对齐问题，讨论了64K分配和页面对齐的必要性，认为通常情况下对齐两页是为了直接IO，因此对齐操作是多余的。 日志优化： 讨论了Patrick提出的日志优化方案，该方案旨在避免过热，目前看起来已经准备就绪。 性能测试： 讨论了Mark提出的性能测试结果，认为需要进一步测试以验证其准确性。 加密功能： 讨论了Radek提出的加密功能，目前仅完成了单元测试，需要进一步测试集群运行结果。 跟踪器性能： 讨论了Tracker性能优化方案，认为这是一个短期性能提升方案，需要进一步讨论。 二、Ceph 数据库优化 缓冲区列表： 讨论了Sage提出的缓冲区列表优化方案，包括清理旧代码、优化编码方式等。 小向量实验： 讨论了Sage提出的小向量实验结果，认为该方案未能达到预期效果，需要进一步研究。 内存分配： 讨论了内存分配优化方案，包括使用SeaStar缓冲区原语、优化引用计数等。 键值存储： 讨论了Matt提出的键值存储优化方案，认为需要研究前缀树索引结构，并考虑在CStore中实现。 三、Ceph 代码维护 代码清理： 讨论了Sage提出的代码清理方案，包括清理旧代码、优化编码方式等。 代码合并： 讨论了Sage提出的代码合并方案，包括合并OP Tracker等。 四、后续行动计划 继续推进Ceph存储性能优化和数据库优化工作。 完成Ceph代码清理和合并工作。 研究前缀树索引结构，并在CStore中实现。 探索CStore在多种环境下的应用。 五、其他事项 讨论了Ceph项目在社区中的影响力。 讨论了Ceph项目的未来发展方向。 关键词： 页面对齐、日志优化、性能测试、加密功能、跟踪器、缓冲区列表、小向量实验、内存分配、键值存储、前缀树、CStore、代码清理、代码合并","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Weekly 2018-09-12","slug":"Ceph_Testing_Weekly_2018-09-12","date":"2018-09-11T16:00:00.000Z","updated":"2018-09-12T16:00:00.000Z","comments":true,"path":"2018/09/12/Ceph_Testing_Weekly_2018-09-12/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/09/12/Ceph_Testing_Weekly_2018-09-12/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Greg, Zack, Nathan, Kier, David等 会议主题： Ceph分布式存储项目开发与测试进展讨论 关键细节与讨论议题： 人员情况： 由于地理原因和紧急家庭事务，Red Hat的同事无法参加本次会议。 Greg因产品工作和个人休假未能积极参与，但仍在跟进相关工作。 Nathan和Kier讨论了Ceph CI Ansible项目的进展和优化方案。 David分享了OpenSUSE镜像制作的情况。 Ceph CI Ansible项目： 工作流程优化： 讨论了Ceph CI Ansible项目的工作流程，包括部署测试实例、管理worker进程等。 认为当前的工作流程存在问题，需要改进。 讨论了使用Systemd服务、独立应用、Ansible模块等方式来优化工作流程。 版本控制和集成测试： 讨论了Ceph CI Ansible项目的版本控制和集成测试问题。 认为需要将Ceph、Paddle、Papito等项目拆分成独立的Python库或项目，并使用pip进行安装和管理。 讨论了使用Ansible模块、聚合仓库等方式来实现集成测试。 OpenSUSE镜像制作： 讨论了OpenSUSE镜像制作的情况，包括镜像制作工具和部署过程。 认为需要将OpenSUSE镜像提供给David，以便用于测试环境搭建。 其他议题： 讨论了Ceph项目的Python 3迁移和flake8代码风格检查工具的使用。 决定的事项： Nathan将跟进Ceph CI Ansible项目的优化工作，包括改进工作流程、实现版本控制和集成测试等。 David将尝试使用OpenSUSE镜像搭建测试环境。 讨论了使用Ansible模块、聚合仓库等方式来实现集成测试的可行性。 后续行动计划： Nathan将整理Ceph CI Ansible项目的优化方案，并与团队讨论。 David将尝试使用OpenSUSE镜像搭建测试环境，并反馈结果。 团队将讨论集成测试的实现方案。 关键词： Ceph CI Ansible Systemd 独立应用 Python库 pip OpenSUSE 集成测试 flake8","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Performance Meeting 2018-09-06","slug":"Ceph_Performance_Meeting_2018-09-06","date":"2018-09-09T16:00:00.000Z","updated":"2018-09-10T16:00:00.000Z","comments":true,"path":"2018/09/10/Ceph_Performance_Meeting_2018-09-06/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/09/10/Ceph_Performance_Meeting_2018-09-06/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Alex, auditing, TC 70, Casey, Madden, Sage, Greg, Anna, Neha, Radek, Mike, Jesse, Branislav 等 会议主题： Ceph分布式存储系统性能优化，重点关注bufferless的使用和优化 会议内容： bufferless使用情况： bufferless在Ceph中被广泛使用，但存在一些问题，例如内存碎片化、迭代器失效、缓存行争用等。 一些团队成员对使用bufferless的必要性表示质疑，认为可能存在过度使用的情况。 优化方案讨论： 探讨了使用small vector替换standard list的可能性，但测试结果并不一致，有时甚至出现性能下降。 讨论了使用bufferless的不同场景，例如编码/解码、IO操作等，并分析了不同场景对bufferless的需求。 讨论了使用bufferless时的迭代器失效和缓存行争用问题，并提出了可能的解决方案，例如使用不同的数据结构、优化工作流程等。 讨论了使用bufferless时的内存分配和释放问题，并提出了优化方案，例如预分配内存、减少不必要的内存分配等。 后续行动计划： 由Braddock负责清理bufferless接口，整理出不必要的功能，并尝试使用small vector进行优化。 由Casey、Radek和key foo负责SeaStar方面的优化，尝试将SeaStar特定缓冲区的原子引用计数改为非原子引用计数。 由其他团队成员继续探索使用vector进行优化的可能性，并使用微基准测试分析其性能影响。 由Mike和Jesse讨论OMAP和PG日志等话题。 关键信息： bufferless在Ceph中被广泛使用，但存在一些问题，需要进一步优化。 使用small vector替换standard list的优化方案需要进一步评估。 使用bufferless时需要考虑迭代器失效和缓存行争用问题。 使用bufferless时需要优化内存分配和释放。 需要进一步探索使用vector进行优化的可能性。 备注： 会议中提到了多个英文关键词，如bufferless、small vector、standard list、SeaStar、OMAP、PG日志等，这些关键词与Ceph分布式存储系统的性能优化相关。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-08-16 Ceph Performance Weekly","slug":"2018-08-16_Ceph_Performance_Weekly","date":"2018-09-05T16:00:00.000Z","updated":"2018-09-05T16:00:00.000Z","comments":true,"path":"2018/09/06/2018-08-16_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/09/06/2018-08-16_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Dan（主持人）、Sue、Casey、T、Nancy、Dovie、Radek、Riccardo等 会议主题： 讨论Ceph分布式存储系统及相关技术议题 关键细节及讨论议题： Pull Request讨论： Sue提交了一个Pull Request，涉及一些支持工作，Casey正在处理。 讨论了是否可以将某些工具或代码用于Nancy Star世界，以及如何确保代码中的锁定和加密操作。 性能优化： 讨论了优化恢复顺序，以及为BlueStore合并数组进行内存固定。 讨论了限制导出大小，以及在内存中处理大量数据时的性能问题。 讨论了切换内存分配器的成本，以及如何优化内存分配。 日志和调试： 讨论了日志记录的性能开销，以及如何减少不必要的日志信息。 讨论了调试级别和消息的显示方式，以及如何优化这些设置。 性能测试： 讨论了在性能测试中禁用调试，以及如何优化NVMe性能。 讨论了如何处理大型日志文件，以及如何优化日志处理。 Messenger协议： 讨论了Messenger协议的优化，以及与操作员的接口。 讨论了协议更改对用户的影响，以及如何通知用户。 决定事项： 对Sue提交的Pull Request进行审查和合并。 优化内存分配和性能，包括优化数据结构和算法。 减少日志记录的开销，并优化调试设置。 进行性能测试，并优化NVMe性能。 优化Messenger协议，并确保与操作员的接口兼容。 后续行动计划： Sue将更新Pull Request，并提交给Casey进行审查。 Radek将优化性能，并提交相关代码。 Riccardo将优化日志记录和调试设置。 进行性能测试，并收集测试结果。 更新Messenger协议，并提交相关代码。 其他事项： 会议中提到了一些与Ceph相关的英文关键词，如Pull Request、BlueStore、NVMe、Messenger协议等。 备注： 会议中提到了一些技术细节，可能需要进一步的技术背景知识才能理解。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Testing Weekly 2018-09-05","slug":"Ceph_Testing_Weekly_2018-09-05","date":"2018-09-05T16:00:00.000Z","updated":"2018-09-05T16:00:00.000Z","comments":true,"path":"2018/09/06/Ceph_Testing_Weekly_2018-09-05/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/09/06/Ceph_Testing_Weekly_2018-09-05/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Nathan、Greg、Helen等 会议主题： Ceph存储集群部署测试的进展与问题讨论 OpenSUSE在Ceph集群测试中的应用 Ceph集群测试工具的改进与优化 会议内容： 一、Ceph存储集群部署测试的进展与问题讨论 Nathan提到在尝试将Ceph集群部署到OpenSUSE时遇到了问题，原因是缺少必要的脚本和配置。 Greg了解到Nathan之前曾向Zach寻求帮助，但脚本链接已失效。 会议决定由Nathan通过邮件联系Zach，获取相关脚本，以便自动化部署。 二、OpenSUSE在Ceph集群测试中的应用 Nathan提出将OpenSUSE作为Ceph集群测试的额外支持发行版。 Greg表示需要创建Fog镜像和OVH镜像，以便在OpenSUSE上运行测试。 会议决定由Nathan与David Galloway联系，寻求帮助创建Fog镜像。 三、Ceph集群测试工具的改进与优化 Nathan提到在OpenSUSE上运行Ceph集群测试时遇到的问题，包括单元测试失败等。 Greg建议尝试在Ubuntu环境中运行测试，并询问是否已在Ubuntu环境中运行测试。 会议决定进一步调查测试失败的原因，并尝试在Ubuntu环境中运行测试。 四、其他事项 Helen提到Red Hat团队正在使用flake工具分析Ceph代码库，并计划在下周会议上分享他们的发现。 行动计划： Nathan通过邮件联系Zach，获取相关脚本。 Nathan与David Galloway联系，寻求帮助创建Fog镜像。 尝试在Ubuntu环境中运行Ceph集群测试，并调查测试失败的原因。 准备下周会议，讨论flake工具的分析结果。 备注： 会议中提到了Ceph集群测试工具的一些关键术语，如CML、Ceph-ansible、Jenkins、Tox等。 会议中提到了Ceph集群测试的一些关键功能，如集群部署、验证、单元测试、集成测试等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-08-22 Ceph Testing Weekly","slug":"2018-08-22_Ceph_Testing_Weekly","date":"2018-08-22T16:00:00.000Z","updated":"2018-08-23T16:00:00.000Z","comments":true,"path":"2018/08/23/2018-08-22_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/08/23/2018-08-22_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议主题： Ceph 在容器化环境下的测试策略和框架 参会人员： (未提及具体姓名，以下以“参会者”代指) 会议内容： 背景： 随着Ceph向容器化环境的迁移，测试策略和框架的更新变得尤为重要。会议主要讨论了在容器化环境下如何进行大规模测试，并确保Ceph的行为符合预期。 主要议题： 测试框架的选择： 是否使用现有的Tautology测试框架，或开发新的测试框架。 如何在容器化环境下运行Tautology，以及如何与Rook等工具集成。 测试环境： 是否需要在实验室中部署Kubernetes集群，以及如何管理多个集群。 如何实现测试的隔离性，以及如何测试不同版本的Rook。 测试策略： 如何进行升级测试，以及如何测试跨版本的兼容性。 如何测试Rook在不同版本的Kubernetes集群上的兼容性。 讨论结果： 测试框架： 推荐使用现有的Tautology测试框架，并对其进行改进以支持容器化环境。 需要开发一个通用接口，允许Tautology与不同的部署平台（如Rook、OpenStack等）集成。 测试环境： 可以考虑在实验室中部署Kubernetes集群，但需要考虑成本和复杂性。 可以使用节点标签来实现测试的隔离性。 测试策略： 需要制定详细的测试计划，包括测试用例、测试环境、测试工具等。 需要确保测试覆盖不同版本的Rook和Kubernetes集群。 行动计划： 短期： 确定测试框架的改进方向和具体方案。 开发通用接口，允许Tautology与不同的部署平台集成。 确定测试环境的配置和管理方案。 长期： 完善测试框架，使其能够支持更多的部署平台和测试场景。 建立完善的测试流程，确保Ceph在容器化环境下的稳定性和可靠性。 关键术语： Tautology：Ceph的测试框架 Rook：Ceph的容器化存储解决方案 Kubernetes：容器编排平台 OpenStack：云计算平台 CI/CD：持续集成/持续部署 其他： 会议中提到了多个关于测试环境的方案，包括使用实验室集群、云平台等。 会议还讨论了与Rook的集成，以及如何实现Rook在不同版本的Kubernetes集群上的兼容性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-08-23 Ceph Performance Weekly","slug":"2018-08-23_Ceph_Performance_Weekly","date":"2018-08-22T16:00:00.000Z","updated":"2018-08-23T16:00:00.000Z","comments":true,"path":"2018/08/23/2018-08-23_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/08/23/2018-08-23_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 未知（根据对话内容推测，应为工作日下午） 参会人员： Mark, Radek, Casey, Neha, Jason, Sage, Danie, Adam, Matt 会议主题： Ceph性能优化 Ceph性能监控系统改进 Ceph内存管理优化 Ceph与SeaStar的兼容性 主要议题： Ceph性能优化： Radek提交了关于性能计数的PR，该PR移除了计数器验证，并将其移至编译时，以提高性能。 Mark讨论了绑定缓存（bindle cache）的工作，该缓存可以根据使用情况动态平衡缓存，并显示与预期一致的性能。 Sage讨论了使用小向量替换标准列表和缓冲区列表的工作，但发现性能略有下降。 Ceph性能监控系统改进： Mark讨论了将性能计数器分组到健康计数器（health counters）中的工作，以提高效率和速度。 Ceph内存管理优化： Sage讨论了内存分配器开销的问题，并提出了改进内存管理模式的建议。 Mark和Radek讨论了使用栈分配来减少内存分配器开销的可能性。 Ceph与SeaStar的兼容性： Sage提到他正在研究SeaStar缓冲区实现，并与现有编码/解码代码兼容。 会议讨论了将SeaStar与Ceph集成，并可能为现有OSD提供潜在的帮助。 决定事项： 继续优化Ceph性能，并关注内存管理问题。 考虑将性能计数器分组到健康计数器中，以提高效率和速度。 研究SeaStar与Ceph的兼容性，并探索潜在集成。 后续行动计划： Radek将继续优化性能计数器。 Mark将继续测试绑定缓存，并研究内存管理问题。 Sage将继续研究SeaStar缓冲区实现，并与团队讨论集成方案。 团队将继续关注Ceph性能和内存管理问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-08-01 Ceph Developer Monthly","slug":"2018-08-01_Ceph_Developer_Monthly","date":"2018-08-02T16:00:00.000Z","updated":"2018-08-02T16:00:00.000Z","comments":true,"path":"2018/08/03/2018-08-01_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/08/03/2018-08-01_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员 会议主题： 讨论Ceph分布式存储系统中的多个功能改进和优化方案。 主要议题及决定事项： 1. Ceph存储池权限控制 议题： 现有权限控制机制较为粗粒度，无法满足更细粒度的访问控制需求。 解决方案： 引入更细粒度的角色和权限控制，例如存储管理员和普通用户。 使用Ceph存储池命名空间支持，实现租户级别的图像隔离。 开发新的配置文件，允许创建、删除、调整图像大小等操作，并限制用户仅对图像进行读写操作。 行动计划： 设计新的角色和权限模型。 开发命名空间支持功能。 开发新的配置文件和权限控制机制。 2. Ceph容器存储接口（CSI） 议题： Ceph CSI需要改进，以支持更灵活的存储管理。 解决方案： 将Ceph CSI客户端模块迁移到Ceph Manager模块，以统一存储管理。 开发新的命令行工具，支持创建和删除存储卷。 开发REST API，提供更灵活的存储管理接口。 行动计划： 设计新的Ceph CSI客户端模块。 开发新的命令行工具和REST API。 3. Ceph文件系统 议题： Ceph文件系统需要改进，以支持更高效的存储和数据共享。 解决方案： 将Ceph文件系统中的文件系统称为“卷”，将子文件系统称为“子卷”。 允许多个文件系统共享相同的数据池。 改进Ceph文件系统的性能和可扩展性。 行动计划： 设计新的文件系统架构。 开发新的文件系统功能。 4. Ceph MDS工作负载分析 议题： 需要改进Ceph MDS的性能和可扩展性。 解决方案： 收集更多MDS性能指标，例如目录大小直方图、目录访问模式等。 开发新的工具，用于分析MDS工作负载并生成模拟工作负载。 改进Ceph MDS的缓存机制。 行动计划： 收集更多MDS性能指标。 开发新的工具，用于分析MDS工作负载。 改进Ceph MDS的缓存机制。 5. Ceph OSD同步问题 议题： Ceph OSD在处理多个并发操作时可能会出现性能问题。 解决方案： 将PG锁从互斥锁改为读写锁。 实现同步读取功能。 行动计划： 设计新的PG锁机制。 实现同步读取功能。 总结： 本次会议讨论了Ceph分布式存储系统的多个功能改进和优化方案，涉及权限控制、存储管理、文件系统、MDS工作负载分析、OSD同步等多个方面。会议明确了各个议题的解决方案和行动计划，为Ceph的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph code walk-through: OSD (async) recovery","slug":"Ceph_code_walk-through_-_OSD_async_recovery","date":"2018-07-30T16:00:00.000Z","updated":"2018-07-31T16:00:00.000Z","comments":true,"path":"2018/07/31/Ceph_code_walk-through_-_OSD_async_recovery/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/07/31/Ceph_code_walk-through_-_OSD_async_recovery/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： Ceph分布式存储系统中异步恢复机制的介绍和讨论 参会人员： Neha（主讲人）、其他Ceph研发人员 会议内容： 1. 会议背景与动机 传统的Ceph恢复过程是同步的，这会阻塞写操作，影响集群可用性。 为了解决这个问题，团队引入了异步恢复机制，允许在后台恢复对象，而不会阻塞写操作。 2. 异步恢复的关键概念 异步恢复目标： 恢复那些仅在某些非活跃OSD上缺失的对象。 选择异步恢复目标： 基于日志差异、对象大小和恢复成本等因素。 OST异步恢复最小PG日志条目： 用于确定是否允许同步恢复的阈值。 保持主副本大小： 只有当有足够的主副本可用时，才考虑同步恢复。 3. 异步恢复的代码实现 选择活跃OSD： 修改了选择活跃OSD的算法，使其能够识别异步恢复目标。 处理写操作： 修改了写操作的代码，使其在异步恢复目标上不会阻塞。 更新元数据： 在异步恢复过程中，需要更新元数据结构，以确保恢复的准确性。 4. 恢复操作 启动恢复操作： 使用PGRecovery::run函数启动恢复操作。 恢复副本： 恢复操作会尝试从副本恢复丢失的对象。 5. 讨论与后续行动 会议讨论了异步恢复的代码实现细节，并提出了改进建议。 团队计划制作一个流程图，以更直观地展示异步恢复的工作原理。 团队将根据讨论结果进一步改进异步恢复机制。 关键词： 异步恢复 同步恢复 非活跃OSD 日志差异 恢复成本 选择活跃OSD 写操作 元数据 恢复操作 副本 总结： 本次会议介绍了Ceph分布式存储系统中异步恢复机制的原理和实现方法。通过异步恢复，可以减少恢复过程中对写操作的阻塞，提高集群可用性。团队将继续改进异步恢复机制，并制作流程图以便更好地理解其工作原理。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Code walk-through: new developers","slug":"Code_walk-through_-_new_developers","date":"2018-07-30T16:00:00.000Z","updated":"2018-07-31T16:00:00.000Z","comments":true,"path":"2018/07/31/Code_walk-through_-_new_developers/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/07/31/Code_walk-through_-_new_developers/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： Ceph 源代码组织结构及关键组件介绍 会议内容： Ceph 源代码组织结构： Ceph 源代码主要分为以下几个部分： 顶层目录： 包含许可证、编码风格文件、提交补丁流程等文档。 源代码目录： 包含所有源代码，包括各种守护进程、库、工具等。 文档目录： 包含使用文档和开发文档。 测试目录： 包含测试脚本和测试用例。 重要目录： common： 包含通用代码和库，供所有守护进程和客户端使用。 global： 包含只适用于守护进程和命令行工具的代码。 message： 包含消息传递相关的代码，包括消息类、消息格式、消息发送和接收等。 osd： 包含 OSD 守护进程的代码，包括对象存储、数据复制、数据恢复等。 mon： 包含 MON 守护进程的代码，负责集群管理。 rgw： 包含 RGW 守护进程的代码，负责对象网关。 librados： 包含 librados 库的代码，提供与对象存储交互的 API。 librgw： 包含 librgw 库的代码，提供与 RGW 交互的 API。 重要组件： 消息传递： Ceph 使用消息传递机制在守护进程之间进行通信。消息传递组件包括消息类、消息格式、消息发送和接收等。 对象存储： Ceph 使用对象存储来存储数据。对象存储组件包括对象存储类、对象存储接口、对象存储后端（如文件存储、块存储、内存存储等）等。 守护进程： Ceph 包含多个守护进程，如 OSD、MON、RGW 等，负责不同的功能。 librados： librados 库提供与对象存储交互的 API，用于读取、写入、删除对象等操作。 数据完整性： Ceph 通过多种方式保证数据完整性，包括： 网络层： 使用 CRC 检查确保数据在传输过程中不被损坏。 后端存储： 根据后端存储类型（如文件存储、块存储、内存存储等）使用不同的机制保证数据完整性。 对象存储： Ceph 使用对象存储来存储数据，对象存储组件包括： 对象存储类： 封装对象存储接口。 对象存储接口： 定义对象存储操作。 对象存储后端： 实现对象存储接口，提供不同的存储后端（如文件存储、块存储、内存存储等）。 行动计划： 将会议内容整理成文档，并在 Ceph 社区网站上发布。 持续举办类似的技术分享会，帮助开发者更好地了解 Ceph。 备注： 本次会议纪要仅供参考，具体内容请以会议录音或视频为准。 会议中提到的英文关键词包括：source code organization, Ceph, message passing, object storage, OSD, MON, RGW, librados, data integrity, attribute, object store, backend, message, messenger, dispatcher, protocol, configuration, context, transaction, operation, read, write, cache, CRC, checksum, RocksDB, Luminous, BlueStore, PG, pool, placement group, backend, replication, erasure coding, data integrity, object context, object info, transaction ID, payload, callback, context, lambda, C++11, OSD client, object ER, transaction, lease, lock, profile system, client API, kernel, RBAC, authentication, Kerberos, class, Lua, journal, transaction, key-value database, LevelDB, RocksDB, MDB, transaction, in-memory benchmarking, shared library, wrapper, library, interface, API, read, write, object, collection, metadata, object store interface, object store backend, file store, block store, memory store, key-value store, object info, key-value pair, byte stream, attribute, OMAP, object context, object info, CRC, checksum, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object table, RocksDB, transaction, write, flush, object context, cache, attribute, read, write, object store, RocksDB, SST, index, key-value pair, BlueStore, object store, RocksDB, SST, index, cache, bloom filter, cache miss, transaction log, commit, disk, flush, metadata, object","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-07-11 Ceph Developer Monthly","slug":"2018-07-11_Ceph_Developer_Monthly","date":"2018-07-18T16:00:00.000Z","updated":"2018-07-18T16:00:00.000Z","comments":true,"path":"2018/07/19/2018-07-11_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/07/19/2018-07-11_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： 线上会议 参会人员： Pavani（实习生）、Lonnie、Josh、VG等 会议主题： SOFI Fest Shell演示： Pavani介绍了她开发的SOFI Fest Shell，这是一个简化访问文件系统的工具，用户可以通过脚本执行简单操作，无需手动挂载。 Backfill优化： 讨论了针对快速设备进行Backfill优化的问题，并提出了使用布隆过滤器、Merkle树等技术方案。 健康检查历史记录： 讨论了将健康检查历史记录发布到Insights的问题，并提出了使用订阅功能和结构化日志等解决方案。 会议详情： SOFI Fest Shell演示： Pavani介绍了SOFI Fest Shell的功能，包括文件列表、目录树复制、自动完成、系统命令等。 与会人员对SOFI Fest Shell的功能表示赞赏，并提出了改进建议，例如支持命令行执行、匹配参数顺序等。 Backfill优化： 讨论了Backfill优化的问题，特别是针对快速设备时的效率问题。 提出了使用布隆过滤器、Merkle树等技术方案，以减少数据传输量和计算量。 讨论了布隆过滤器的实现细节，包括时间窗口、内存占用等。 讨论了Merkle树的实现细节，包括数据结构、版本控制等。 讨论了其他优化方案，例如并行处理、增量更新等。 健康检查历史记录： 讨论了将健康检查历史记录发布到Insights的问题，并提出了使用订阅功能和结构化日志等解决方案。 讨论了健康检查历史记录的格式和内容。 讨论了如何将健康检查历史记录与SNMP模块等模块进行整合。 后续行动计划： SOFI Fest Shell： Pavani将继续完善SOFI Fest Shell，并根据反馈进行改进。 与会人员将测试SOFI Fest Shell，并提出反馈意见。 Backfill优化： 与会人员将研究布隆过滤器和Merkle树等技术方案，并评估其可行性。 与会人员将讨论并行处理和增量更新等优化方案。 健康检查历史记录： 与会人员将研究订阅功能和结构化日志等解决方案，并评估其可行性。 与会人员将讨论如何将健康检查历史记录与SNMP模块等模块进行整合。 关键词： SOFI Fest Shell Backfill 布隆过滤器 Merkle树 健康检查 Insights SNMP模块","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-07-12 Ceph Performance Weekly","slug":"2018-07-12_Ceph_Performance_Weekly","date":"2018-07-18T16:00:00.000Z","updated":"2018-07-18T16:00:00.000Z","comments":true,"path":"2018/07/19/2018-07-12_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/07/19/2018-07-12_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 未知（Josh、Sage、Braddock、Alec、Murph、Kevin、Howard、Peng等） 会议主题： Ceph分布式存储项目开发讨论 会议内容： 参会人数： 由于Josh和Sage未能参加会议，参会人数较少。 议程： Aaron 85提交的关于数据编码条带缓存的新PR。 Bend LRU缓存相关PR的更新。 Peng正在研究的K be finalized线程的延迟问题。 两个新的PR： 将RocksDB的LRU缓存集成到Ceph中，并修改了高优先级池的使用方式。 分析OSD使用的堆内存和未映射内存，用于动态调整Blue Store缓存的大小。 讨论重点： Bend LRU缓存： 该缓存功能表现良好，需要进一步验证并合并。 RocksDB LRU缓存集成： 该PR将RocksDB的LRU缓存集成到Ceph中，并修改了高优先级池的使用方式，以优化缓存性能。该PR可能需要一些修改才能回滚到Luminous版本。 内存使用优化： 通过分析OSD使用的堆内存和未映射内存，可以动态调整Blue Store缓存的大小，以优化OSD的RSS内存使用。该功能有助于在内存受限的情况下更好地管理OSD的内存使用。 行动计划： 合并Bend LRU缓存相关PR。 评估RocksDB LRU缓存集成PR，并根据需要做出修改。 测试并验证内存使用优化功能。 讨论并解决回滚到Luminous版本时可能遇到的问题。 其他事项： 会议中提到了一些计算机科学/ceph相关领域英文关键词，例如： PR (Pull Request) LRU (Least Recently Used) RocksDB Ceph OSD (Object Storage Daemon) Blue Store RSS (Resident Set Size) Backport (回滚到旧版本) 总结： 本次会议讨论了Ceph分布式存储项目的多个开发议题，并制定了后续的行动计划。会议内容涵盖了缓存优化、内存使用优化等方面，有助于提升Ceph的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-07-19 Ceph Performance Weekly","slug":"2018-07-19_Ceph_Performance_Weekly","date":"2018-07-18T16:00:00.000Z","updated":"2018-07-19T16:00:00.000Z","comments":true,"path":"2018/07/19/2018-07-19_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/07/19/2018-07-19_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 参会人员： Josh, Greg, Neha, Sage, Mafia, Peng, Jason, Adams, 等 会议主题： Ceph性能会议纪要 会议内容： 1. 代码审查及进展 PRs： Greg提交的优化MDS中最大导出大小的PR。 Erratic的uptracker工作，以及Retic的clamp以避免在主日志PG中额外的引用计数。 Neha的PR限制PG日志长度，已被合并。 EC条带现金PR，尚未审查。 Lib标准C++运行时问题的PR。 Mafia和Peng提交的多个PR。 移除异步恢复的PR，引起大量讨论。 其他进展： Adams正在休假，但在休假前正在研究实现一种模型来模拟不同类型的蓝色鳄鱼的碎片化。 Jason在Hats实验室对BD工作负载进行了测试，发现位图分配器在利用空闲连续区域或随机区域时做得更好。 2. 讨论主题 缓存平衡： Josh正在继续工作，对缓存平衡进行重构和清理，并尝试确定当前状态下的合理默认值。 他提出了一个关于mallik+放置的新方案，用于一次性分配结构内存，而不是使用传统的分配方式。 内存分配器： Josh提出减少PG日志条目使用的内存，并讨论了在内存池中可能存在的额外内存使用。 他建议关注内存分配器，并尝试使内存分配模式更友好，以提高性能和减少内存碎片。 PGs限制： 一位参与者遇到了EG过度使用和内存保护的问题，他们遇到了PG/OST限制。 讨论了将PG/OST限制从默认的200增加到600，以避免用户遇到此问题。 3. 行动计划 Josh： 继续工作，对缓存平衡进行重构和清理。 调查mallik+放置方案。 关注内存分配器，并尝试使内存分配模式更友好。 其他参与者： 审查EC条带现金PR。 解决Lib标准C++运行时问题。 审查移除异步恢复的PR。 4. 下次会议 下次会议将于2023年X月X日举行。 备注： 会议中讨论了一些关于PGs限制和内存分配器的重要问题，需要进一步研究和解决。 建议将PG/OST限制从默认的200增加到600，以避免用户遇到EG过度使用和内存保护问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-28 :: Ceph Performance Weekly","slug":"2018-Jun-28_-_-_Ceph_Performance_Weekly","date":"2018-06-27T16:00:00.000Z","updated":"2018-06-28T16:00:00.000Z","comments":true,"path":"2018/06/28/2018-Jun-28_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/28/2018-Jun-28_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 参会人员： 大部分研发人员（Sage缺席） 会议主题： 分布式存储Ceph项目进展和讨论 关键细节及讨论议题： 内存分配器： 讨论了不同内存分配器的性能和碎片化问题，包括stupid allocator、bitmap allocator和libc malloc。 通过测试发现，libc malloc在内存使用上表现不佳，而TC malloc和J malloc在性能和内存使用上更优。 讨论了优化libc malloc的方法，如禁用fast bins和增加TLB缓存计数。 决定继续使用TC malloc或J malloc作为Ceph的默认内存分配器。 KVS线程和finisher线程： 讨论了KVS线程和finisher线程的行为，以及Majin pang提出的改进方案。 Majin pang表示，他的改进方案在提高高并发情况下的性能方面表现良好。 决定进一步研究Majin pang的改进方案，并评估其在生产环境中的效果。 其他议题： 讨论了其他几个pull request，包括静态链接、 bitmap分配器碎片化、异步恢复、大页内存等。 讨论了make check性能优化，以及缓存利用率的提高。 讨论了app tracker优化和分区优化。 讨论了libc malloc的性能测试结果。 决定事项： 继续使用TC malloc或J malloc作为Ceph的默认内存分配器。 进一步研究Majin pang的KVS线程和finisher线程改进方案。 优化make check性能，提高缓存利用率。 集成p2t wrapper，优化app tracker。 考虑使用libc malloc的优化方法，如禁用fast bins和增加TLB缓存计数。 后续行动计划： Majin pang将提供更多关于KVS线程和finisher线程改进方案的信息。 进行libc malloc的优化测试，并评估其效果。 对其他讨论的pull request进行评估和合并。 继续优化Ceph的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-27 :: Ceph Testing Weekly","slug":"2018-Jun-27_-_-_Ceph_Testing_Weekly","date":"2018-06-26T16:00:00.000Z","updated":"2018-06-27T16:00:00.000Z","comments":true,"path":"2018/06/27/2018-Jun-27_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/27/2018-Jun-27_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： [未提及具体时间] 参会人员： Ally, Rick, Ashley, Zach (远程度假), Ali, Yuri, Teresa 会议主题： 项目进展、技术问题讨论、行动计划 关键细节： 人员缺席： Zach 由于度假缺席本次会议。 文档准备： Ali 已经完成文档撰写，需要将文档推送到 GitHub 分支，并处理一个关于目录路径变更的评论。 单元测试： Ashley 在尝试运行单元测试时遇到问题，无法理解如何跟踪 GUnit 测试。Yuri 提供了解决方案，并解释了 PI-to-7 集成测试的添加情况。 依赖问题： 由于依赖项的更新，Yuri 遇到一些依赖问题，需要从上游获取一些 PR。 集成测试： 会议讨论了集成测试的运行情况，并指出由于环境限制，某些测试可能会被跳过。 开发环境： 开发者主要在 macOS 上进行开发，并讨论了测试环境配置的问题。 讨论的主要议题： 单元测试： 如何正确运行和跟踪单元测试。 依赖问题： 如何处理依赖项更新带来的问题。 集成测试： 如何优化集成测试的运行。 决定的事项： Ali 将处理 GitHub 分支中的目录路径变更问题，并尽快完成 PR。 Yuri 将解决依赖问题，并从上游获取必要的 PR。 开发者将再次检查集成测试，并优化测试流程。 后续行动计划： Ali：处理 GitHub 分支中的目录路径变更问题，并完成 PR。 Yuri：解决依赖问题，并从上游获取必要的 PR。 所有开发者：检查集成测试，并优化测试流程。 备注： 会议中提到的技术关键词包括：GUnit 测试、PI-to-7 集成测试、依赖项、集成测试、OpenStack 等。 会议中提到的其他内容包括：GitHub、分支、PR、上游等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-June-26 :: Ceph Code Walkthrough: BlueStore part 2","slug":"2018-June-26_-_-_Ceph_Code_Walkthrough_-_BlueStore_part_2","date":"2018-06-26T16:00:00.000Z","updated":"2018-06-26T16:00:00.000Z","comments":true,"path":"2018/06/27/2018-June-26_-_-_Ceph_Code_Walkthrough_-_BlueStore_part_2/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/27/2018-June-26_-_-_Ceph_Code_Walkthrough_-_BlueStore_part_2/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储系统关键组件解析与性能优化 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知 会议内容： 一、会议背景 本次会议主要针对Ceph分布式存储系统中的一些关键组件进行解析，并探讨如何优化其性能。 二、关键组件解析 缓存机制： Ceph使用内存缓存来存储频繁访问的数据，提高访问效率。 缓存分为LRU缓存和2Q缓存两种，2Q缓存具有更高的缓存命中率。 缓存中的数据按照状态进行管理，包括空闲、清洁、写入中等状态。 对象存储： 对象存储使用Onode来表示对象，并使用Blob来表示数据块。 Blob可以共享，即多个对象可以引用同一个Blob。 共享Blob的引用计数由共享Blob结构管理。 事务处理： Ceph使用事务来确保数据的一致性。 事务处理流程包括准备、提交、完成和清理等阶段。 事务处理过程中，会进行数据写入、数据读取和延迟I/O等操作。 写入操作： 写入操作会根据数据块大小进行优化，以减少I/O次数。 写入操作会考虑数据压缩、校验和等特性。 延迟I/O： 延迟I/O用于处理小于块大小的写入操作。 延迟I/O可以合并多个I/O操作，提高I/O效率。 三、性能优化 缓存优化： 使用更高效的缓存算法，如2Q缓存。 根据数据访问模式调整缓存大小。 事务优化： 优化事务处理流程，减少延迟。 使用更高效的锁机制，减少锁竞争。 写入优化： 优化写入操作，减少I/O次数。 使用更高效的压缩算法。 延迟I/O优化： 优化延迟I/O合并策略，提高I/O效率。 四、后续行动计划 对Ceph分布式存储系统进行性能测试，评估优化效果。 根据测试结果，进一步优化Ceph分布式存储系统。 撰写技术文档，记录优化过程和结果。 五、会议总结 本次会议对Ceph分布式存储系统中的关键组件进行了深入解析，并探讨了性能优化方法。通过优化缓存机制、事务处理、写入操作和延迟I/O等关键组件，可以有效提高Ceph分布式存储系统的性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-21 :: Ceph Performance Weekly","slug":"2018-Jun-21_-_-_Ceph_Performance_Weekly","date":"2018-06-20T16:00:00.000Z","updated":"2018-06-21T16:00:00.000Z","comments":true,"path":"2018/06/21/2018-Jun-21_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/21/2018-Jun-21_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： [请列出参会人员姓名] 会议主题： 讨论Ceph分布式存储系统中的关键技术优化，包括RBD、Blue Store、PG日志等。 关键细节： RBD优化： 讨论了RBD在磁盘上的性能表现，并对比了不同硬件配置下的性能差异。 讨论了PG日志对性能的影响，并提出了优化方案，例如将PG日志存储在更快的存储设备上。 Blue Store优化： 讨论了Blue Store缓存大小对OSD内存使用的影响，并提出了自动调整缓存大小的方案。 讨论了如何设置缓存大小优先级，并确保缓存大小与OSD内存目标一致。 讨论了如何处理内存压力下的缓存调整，并提出了使用RSS内存作为目标的方法。 PG日志优化： 讨论了PG日志对性能的影响，并提出了优化方案，例如将PG日志存储在更快的存储设备上。 讨论了不同类型数据在RocksDB中的存储方式，并提出了针对不同数据类型设置不同压缩策略的方案。 讨论的主要议题： 如何优化RBD在磁盘上的性能表现。 如何优化Blue Store缓存大小对OSD内存使用的影响。 如何优化PG日志对性能的影响。 决定的事项： 将PG日志存储在更快的存储设备上，例如NVM Express (NVMe)。 开发自动调整Blue Store缓存大小的方案。 研究针对不同数据类型设置不同压缩策略的方案。 后续行动计划： 进行更多测试，以验证优化方案的可行性。 开发自动调整Blue Store缓存大小的代码。 与RocksDB团队合作，讨论针对不同数据类型设置不同压缩策略的方案。 其他事项： 讨论了Ceph性能计数器的优化。 讨论了Ceph OpTracker的优化。 讨论了Ceph的存储目标优化。 备注： 会议中提到了一些计算机科学/ceph相关领域英文原文的关键词，例如： RBD (Rados Block Device) Blue Store PG日志 RocksDB NVM Express (NVMe) OpTracker 性能计数器 会议总结： 本次会议讨论了Ceph分布式存储系统中的关键技术优化，并提出了相应的解决方案。这些优化方案将有助于提高Ceph的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-20 :: Ceph Testing Weekly","slug":"2018-Jun-20_-_-_Ceph_Testing_Weekly","date":"2018-06-19T16:00:00.000Z","updated":"2018-06-20T16:00:00.000Z","comments":true,"path":"2018/06/20/2018-Jun-20_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/20/2018-Jun-20_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Zack、Mike、Robley、Anitra、Jenny、Paul、Greg等 会议主题： 讨论Ceph存储系统中Telltale测试框架的更新与改进，包括测试环境搭建、测试流程优化、开发模式探索等。 关键细节： Telltale测试框架现状： 目前Telltale测试框架依赖于OpenStack基础设施，测试环境搭建复杂，维护成本高，且测试覆盖率有限。 测试环境搭建： 使用OVH实例搭建测试环境，以支持Telltale测试框架的测试。 使用Jenkins进行测试任务调度，并尝试停止部分Jenkins任务以运行部署。 创建特定测试套件，如smoke test和fault test，以验证Telltale的基本功能。 使用Ceph smoke test来测试Telltale测试框架的功能和接口。 测试流程优化： 更新Telltale测试套件，提高测试覆盖率。 探索使用分支或标签来管理Telltale的版本，以便更好地控制测试环境。 引入更智能的调度器，以优化测试资源的分配。 考虑将Telltale拆分为多个模块，以提高可测试性和可开发性。 开发模式探索： 探索使用Web应用程序来管理Telltale的测试和部署，以提高用户体验。 研究使用其他测试框架或工具来替代Telltale的部分功能。 探索与其他社区合作，共享测试资源和经验。 决定的事项： 使用OVH实例搭建测试环境。 使用Jenkins进行测试任务调度。 创建特定测试套件，如smoke test和fault test。 更新Telltale测试套件，提高测试覆盖率。 探索使用分支或标签来管理Telltale的版本。 引入更智能的调度器，以优化测试资源的分配。 考虑将Telltale拆分为多个模块。 探索使用Web应用程序来管理Telltale的测试和部署。 研究使用其他测试框架或工具来替代Telltale的部分功能。 探索与其他社区合作，共享测试资源和经验。 后续行动计划： Zack将继续开发libcloud后端，以便在OpenStack中创建临时的Telltale部署。 Mike将尝试运行Telltale测试套件，并查看其是否能够正常运行。 Greg将整理会议中讨论的所有想法，并将其记录在etherpad中。 所有参会人员将继续探讨Telltale测试框架的改进方案。 关键词： Telltale、OpenStack、Jenkins、测试套件、测试覆盖率、智能调度器、Web应用程序、测试框架、社区合作","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-13 :: Ceph Testing Weekly","slug":"2018-Jun-13_-_-_Ceph_Testing_Weekly","date":"2018-06-18T16:00:00.000Z","updated":"2018-06-19T16:00:00.000Z","comments":true,"path":"2018/06/19/2018-Jun-13_-_-_Ceph_Testing_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/19/2018-Jun-13_-_-_Ceph_Testing_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph社区成员，包括Zach、Greg、Rick、Ally、Tatiana、Yuri等。 会议主题： 检查上次会议的行动项完成情况 讨论Ceph测试框架Tautology的改进和扩展 探索使用Libcloud进行测试的可能性 讨论Ceph RGW功能测试的改进 讨论Ceph安全仪表板的测试 关键细节： 上次会议行动项： 红帽工程师创建的Redmine工单尚未创建。 需要更多PR以便进行审查和测试。 需要为Tautology编写开发指南文档。 需要为Tautology集成测试环境编写Ansible脚本。 Tautology改进： 讨论了将Asuza的OpenStack后端补丁合并到Tautology中，并使用Libcloud进行测试。 讨论了使用Tautology进行测试时的节点分配问题。 讨论了为Tautology编写文档，以帮助开发者编写任务。 讨论了将Tautology部署到Jenkins以进行测试。 Ceph RGW功能测试： 讨论了使用Tautology对RGW进行测试，包括S3测试和RGW管理员套件测试。 讨论了为RGW测试编写Ansible脚本。 讨论了使用Tautology进行升级测试，例如将Ceph集群从Luminous升级到Mimic。 Ceph安全仪表板的测试： Tatiana介绍了Red Hat的Ceph安全仪表板（Set Metrics），并讨论了如何对其进行测试。 决定的事项： 红帽工程师将继续创建Redmine工单。 红帽工程师将审查和合并更多PR。 红帽工程师将为Tautology编写开发指南文档。 红帽工程师将为Tautology集成测试环境编写Ansible脚本。 红帽工程师将与社区成员合作，改进和扩展Tautology。 红帽工程师将使用Tautology进行Ceph RGW功能测试和升级测试。 红帽工程师将探索使用Libcloud进行测试的可能性。 后续行动计划： 红帽工程师将在下次会议之前完成上述行动项。 红帽工程师将参加RGW站立会议，讨论Ceph RGW功能测试的改进。 红帽工程师将与社区成员合作，改进和扩展Tautology。 其他： 会议中讨论了一些其他话题，例如Ceph社区会议的安排和Ceph安全仪表板的开发。 会议结束时，红帽工程师将整理会议纪要并发送给参会人员。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-14 :: Ceph Performance Weekly","slug":"2018-Jun-14_-_-_Ceph_Performance_Weekly","date":"2018-06-17T16:00:00.000Z","updated":"2018-06-17T16:00:00.000Z","comments":true,"path":"2018/06/18/2018-Jun-14_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/18/2018-Jun-14_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 参会人员： Ron, Christian, [其他参会人员] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 1. 页面错误处理 Ron汇报了关于页面错误的处理进展。他提交了一个包含改进的pull request，并进行了额外的性能分析。结果显示，通过使用大页（huge pages）技术，页面错误的数量减少了三分之二。 发现文件写入器是导致页面错误的主要原因。此外，RocksDB中的某些方法也引发了页面错误。 讨论了RocksDB在内存分配器（allocator）上的问题，特别是大页的支持。RocksDB的内存分配器是多层的，只有底层支持大页。 决定与RocksDB开发者沟通，以确保我们了解正确的路径。 2. 事务注册 讨论了事务注册（registration）的问题，特别是与解锁操作相关的竞争（contention）。 认为需要进一步测试和优化事务注册部分，特别是涉及信使线程（messenger threads）的场景。 3. 其他议题 讨论了与Pythons相关的支持请求。 提到了bitmap分配器（bitmap allocator）的改进工作，包括修改单元测试以模拟更多分配场景并评估碎片化问题。 行动计划： Ron将继续优化页面错误处理，并与RocksDB开发者沟通。 团队将进行事务注册的测试和优化。 继续改进bitmap分配器。 会议总结： 本次会议主要讨论了Ceph分布式存储项目的页面错误处理和事务注册等关键问题。团队将按照既定计划继续推进项目进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Jun-7 :: Ceph Performance Weekly","slug":"2018-Jun-7_-_-_Ceph_Performance_Weekly","date":"2018-06-06T16:00:00.000Z","updated":"2018-06-07T16:00:00.000Z","comments":true,"path":"2018/06/07/2018-Jun-7_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/07/2018-Jun-7_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Igor、Adam、Radek、Josh、Igor、Sade等 会议主题： 讨论Ceph分布式存储系统开发进展，特别是内存分配器优化、缓存策略调整等议题。 关键细节与议题： 内存分配器优化： Igor持续在位图分配器上进行改进工作，Adam正在对其进行审查。 讨论了新的“cash balance”工作，该工作对内存进行优化，以提高性能。 提出了针对优先队列的优化建议，以减少内存分配的开销。 讨论了Intel和AMD处理器的安全补丁对性能的影响。 探讨了使用自旋锁、测试优化和Intel TSX事务性内存来提高性能的方案。 缓存策略调整： Igor介绍了基于优先级的缓存分配方案，该方案根据数据缓存、元数据和键值缓存的优先级进行内存分配。 讨论了基于年龄的缓存分箱方案，该方案可以动态调整内存分配，以适应不同的使用场景。 讨论了将缓存策略应用于其他数据结构（如RocksDB缓存）的可行性。 其他议题： 讨论了性能测试和基准测试的重要性。 讨论了针对不同工作负载的优化策略。 决定事项： 继续优化内存分配器和缓存策略。 对现有代码进行性能测试和基准测试，以评估优化效果。 探索使用TSX事务性内存来提高性能的方案。 后续行动计划： Igor继续改进位图分配器和缓存策略。 Adam继续审查Igor的工作。 Radek探索优化优先队列的方案。 Josh和Igor讨论将缓存策略应用于RocksDB缓存的可行性。 所有参会人员定期进行会议，讨论进展和问题。 备注： 会议中提到了Ceph的多个组件和术语，如Rados、BlueStore、RBD、RocksDB、优先队列、缓存、内存分配器、TSX等。 会议中讨论了性能优化和内存管理的多个方面，包括自旋锁、互斥锁、事务性内存、缓存策略等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-JUN-06 :: Ceph Developer Monthly","slug":"2018-JUN-06_-_-_Ceph_Developer_Monthly","date":"2018-06-05T16:00:00.000Z","updated":"2018-06-06T16:00:00.000Z","comments":true,"path":"2018/06/06/2018-JUN-06_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/06/2018-JUN-06_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年11月 (具体日期未提及) 参会人员： Careful, Tanglin, Pat, Jeff, Lenz, Greg, Stefan, etc. 会议内容： 一、Ceph-RBD性能优化 讨论了Ceph-RBD的性能优化方案，包括： 使用多个Tanglin进行独立操作，共享DPDK网络卡。 使用RCU技术实现共享数据结构，提高并发访问效率。 优化日志记录和内存使用，减少性能开销。 二、NFS Ganesha集群化 Jeff介绍了NFS Ganesha集群化的工作进展，包括： 使用Rados作为存储后端，实现NFS Ganesha的集群化。 引入“grace period”机制，防止节点重启后状态冲突。 使用Rados对象存储恢复数据库，实现节点故障恢复。 三、REST API &amp; Dashboard API 讨论了Ceph REST API和Dashboard API的发展方向，包括： 使用Swagger生成API文档，提高API的易用性。 引入角色和用户权限管理，提高安全性。 在Nautilus版本中正式推出REST API。 四、智能预测设备故障 讨论了智能预测设备故障的项目进展，包括： 收集SMART指标，预测设备故障。 使用外部服务进行设备故障预测。 实现设备故障自动化处理。 五、智能故障报告 讨论了智能故障报告的功能需求，包括： 在崩溃时生成崩溃目录报告。 将崩溃报告上传到Manager。 在Manager中存储崩溃报告。 六、跨云文件系统 讨论了跨云文件系统的实现方案，包括： 使用快照和同步机制实现跨云数据备份。 使用版本控制技术实现跨云数据冲突解决。 将RGW作为访问外部存储的网关。 七、其他议题 讨论了其他议题，例如： CephFS的元数据复制。 RGW的云同步功能。 Ceph的日志记录和跟踪。 后续行动计划： 各项议题的负责人将根据会议讨论结果，制定详细的开发计划和时间表。 定期召开会议，跟踪项目进展。 鼓励社区成员参与项目开发。 关键词： Ceph-RBD, RCU, SMART, REST API, Dashboard API, NFS Ganesha, 跨云文件系统, 智能故障报告","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-31 :: Ceph Performance Weekly","slug":"2018-May-31_-_-_Ceph_Performance_Weekly","date":"2018-05-31T16:00:00.000Z","updated":"2018-06-01T16:00:00.000Z","comments":true,"path":"2018/06/01/2018-May-31_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/06/01/2018-May-31_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Matt、Adam Emerson、Josh、Igor、Keef、Bratislava、Peter、Paige、Greg、Mark、Nick、Stasia 等 会议主题： Ceph 项目进展讨论 会议内容： 一、Beast 项目进展 Beast 项目进展顺利，Adam Emerson 正在将兼容 I/O 接口集成到 Beast 中。 会议强调需要关注接口兼容性问题，确保与解放应用程序的兼容性。 会议鼓励大家积极审查 Adam 提交的 PR。 二、Ceph 项目其他进展 Rocky CB1 Mark： 会议讨论了该 PR 的视频功能，认为其对性能提升有限，但不会造成负面影响。 Adam 提交的多个 PR： 会议审查了 Adam 提交的多个 PR，包括 hash pull requests、liberty supporting throttling、iOS Rattler 等。 内存使用优化： 会议讨论了 OS memory usage 的问题，希望实现内存使用量的动态调整，并根据优先级分配内存。 会议探讨了如何获取内存分配的统计数据，并考虑使用 malloc_usable_size 等接口。 会议讨论了内存碎片化问题，并希望获取相关统计数据。 会议讨论了使用 heap profiler 获取内存分配信息的方法。 锁优化： 会议讨论了 scrubbing 期间锁的竞争问题，并分析了可能的锁冲突原因。 会议建议使用 GDB wall clock profiler 或 Adams wall clock profiler 进行分析。 会议讨论了调整 scrubbing 步长大小以改善性能的可能性。 三、后续行动计划 Adam Emerson 继续推进 Beast 项目，并提交相关 PR。 会议参与者积极审查 Adam 提交的 PR。 会议参与者继续关注内存使用优化工作，并尝试获取相关统计数据。 会议参与者尝试使用 GDB wall clock profiler 或 Adams wall clock profiler 分析 scrubbing 期间锁的竞争问题。 会议参与者尝试调整 scrubbing 步长大小以改善性能。 四、其他事项 会议讨论了 rocksdb buffer size 动态调整的可能性。 会议鼓励大家积极分享经验和反馈。 总结： 本次会议讨论了 Ceph 项目的多个进展，并制定了后续行动计划。会议氛围积极，参与者积极参与讨论，为 Ceph 项目的持续发展贡献力量。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-29 :: Ceph Code Walkthrough: BlueStore part 1","slug":"2018-May-29_-_-_Ceph_Code_Walkthrough_-_BlueStore_part_1","date":"2018-05-29T16:00:00.000Z","updated":"2018-05-29T16:00:00.000Z","comments":true,"path":"2018/05/30/2018-May-29_-_-_Ceph_Code_Walkthrough_-_BlueStore_part_1/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/30/2018-May-29_-_-_Ceph_Code_Walkthrough_-_BlueStore_part_1/","excerpt":"","text":"会议纪要 会议主题： Blue Store 源码解析 参会人员： 未知 会议时间： 未知 会议地点： 未知 会议内容： Blue Store 简介： Blue Store 是 Ceph 对象存储后端，负责实现对象存储接口。 Blue Store 主要包含两个操作类别：同步阻塞的读操作和基于事务的写操作。 Blue Store 使用 RocksDB 作为元数据存储，并使用 BlueFS 作为文件系统。 BlueFS： BlueFS 是 Blue Store 的文件系统实现，直接消费原始块设备。 BlueFS 使用 RocksDB 的文件系统接口，并将所有文件存储在 BlueFS 目录中。 BlueFS 提供简单的文件操作，如创建文件、读取文件、写入文件和删除文件。 块设备接口： 块设备接口提供对块设备的低级抽象，包括读取、写入、预读和预写操作。 Blue Store 使用内核设备作为块设备接口的实现，它直接与内核的异步 I/O 接口交互。 Blue Store 的分配器： 分配器负责决定磁盘上哪些部分可以使用。 Blue Store 使用两种分配器实现：Stupid Allocator 和 Bitmap Allocator。 Bitmap Allocator 更高效、更确定，并且内存占用更少。 Blue Store 的磁盘结构： Blue Store 使用多种类型来表示磁盘结构，包括块设备标签、对象、集合、范围和 blob。 块设备标签包含有关设备的信息，例如 OSD 的 UID、大小、创建时间和描述。 对象是磁盘上存储的数据单元，由 blob 组成。 集合是类似于目录的对象组。 范围是对象的一部分，由 blob 表示。 Blob 是磁盘上存储数据的物理区域。 读取路径： 读取路径首先查找对象的元数据，然后从 RocksDB 中读取 blob。 如果 blob 是压缩的，则需要解压缩它。 最后，将读取的数据组装成最终结果。 行动计划： 将本次会议内容录制并发布到 YouTube。 计划进行后续会议，深入探讨写入路径的实现。 备注： 会议中提到了许多计算机科学/ceph 领域的英文关键词，如对象存储、RocksDB、BlueFS、块设备接口、分配器、磁盘结构、读取路径等。 会议内容涵盖了 Blue Store 的主要功能和实现细节，对于想要了解 Blue Store 的研发人员来说非常有价值。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-24 :: Ceph Performance Weekly","slug":"2018-May-24_-_-_Ceph_Performance_Weekly","date":"2018-05-27T16:00:00.000Z","updated":"2018-05-27T16:00:00.000Z","comments":true,"path":"2018/05/28/2018-May-24_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/28/2018-May-24_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 会议记录者（疑似研发人员）、Mohammed、Layton、Radek、Peter、Igor、Adams、Gifu、Josh、Mark、Saij、Tony等 会议内容： 一、Pull Requests讨论 Mohammed的Pull Request： 将单调时钟切换为单调时钟，但需要避免使用课程时钟。 Radek的Pull Request： 更改加密解密调用，使用不使用bufferless的变体，提高签名计算速度。 Peter的Pull Request： 日志子系统缓冲写入，而不是为每个条目调用单独的sis调用，提高效率。 Igor的Pull Request： 新的位图分配器，替换旧实现，提高性能。 Adams的Pull Request： 使用散列技巧，修复用户看到的某些问题。 Gifu的Pull Request： 清理旧版AES密钥处理器，但最终未实施。 Mark的Pull Request： 定期丢弃功能，存在一些问题。 Art的Pull Request： 等待Chabot工作的重新设计。 Power of Two优化： 讨论了使用2的幂次优化配置选项和性能的可行性。 二、性能优化 SSD缓冲： 讨论了将数据同时写入HDD和SSD以提高性能的方案，并分享了一个性能提升30%的测试结果。 内存使用： 讨论了BlueStore缓存和其他组件的内存使用情况，并分析了内存泄漏和碎片化问题。 RocksDB缓存： 讨论了RocksDB缓存的内存使用情况和优化方案。 内存分配器： 讨论了内存分配器优化和碎片化问题，并考虑使用不同的内存池来分配内存。 三、其他议题 锁优化： 讨论了使用C++锁优化和编译器支持的锁优化方案。 BlueFS文件写入： 讨论了BlueFS文件写入的缓冲区循环和优化方案。 四、行动计划 对Pull Requests进行评审和合并。 对性能优化方案进行测试和评估。 对内存使用和分配器问题进行进一步分析和优化。 对锁优化方案进行实施和测试。 五、后续会议 下次会议将讨论性能优化方案的测试结果和内存分配器优化方案的实施情况。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-24 :: Ceph Tech Talks","slug":"2018-May-24_-_-_Ceph_Tech_Talks","date":"2018-05-27T16:00:00.000Z","updated":"2018-05-28T16:00:00.000Z","comments":true,"path":"2018/05/28/2018-May-24_-_-_Ceph_Tech_Talks/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/28/2018-May-24_-_-_Ceph_Tech_Talks/","excerpt":"","text":"会议纪要 会议主题： Rook 简介、开发环境搭建及未来规划 会议时间： 2023年11月（具体日期未提及） 参会人员： 会议主持人及多位Rook团队成员 会议内容： 一、Rook简介 Rook 是 Kubernetes 的存储编排器，旨在将存储作为 Kubernetes 的一等公民。 Rook 的目标是简化存储集成、管理和自动化，将文件、块和对象存储引入 Kubernetes。 Rook 通过 Operator 管理集群，确保集群健康并运行所需状态。 二、Rook 开发环境搭建 使用 GitHub 上的测试文件夹中的说明，可以快速搭建 Rook 开发环境。 通过运行 make cube 脚本，可以启动一个单节点 Kubernetes 集群（MiniCube）。 在 MiniCube 中添加磁盘，可以运行 OSD。 使用 Rook Operator 启动 Ceph 集群，包括 Mon、OSD 和 Manager。 Rook Operator 会自动创建命名空间、Pod、服务等资源。 三、Rook 使用示例 使用 Rook 创建文件系统，包括元数据池和数据池。 使用 Rook 创建对象存储，包括元数据池和数据池。 使用 Rook 的工具箱 Pod 进行故障排除。 Rook 支持动态存储卷，方便在 Kubernetes 中使用 Ceph 存储卷。 四、Rook 路线图 Rook 的目标是使 Ceph 集群达到生产就绪状态。 Rook 将支持 CSI 插件，以便与其他编排器集成。 Rook 将支持多个后端存储，包括 MinIO、CockroachDB 等。 Rook 将提供更智能的升级策略，简化升级过程。 Rook 将提供简化版的 Ceph 管理界面，方便用户管理集群。 五、后续行动计划 继续完善 Rook 的功能，使其更加稳定和易用。 推动CSI插件和多个后端存储的支持。 与社区合作，推动 Rook 的发展。 六、讨论要点 如何使用 Rook 消费存储？ Rook 如何处理故障？ Rook 的升级策略是什么？ Rook 是否支持IPv6？ 七、总结 本次会议介绍了 Rook 的功能、开发环境搭建和使用示例，并讨论了 Rook 的未来规划。Rook 是一个很有潜力的 Kubernetes 存储解决方案，值得进一步关注和研究。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-17 :: Ceph Performance Weekly","slug":"2018-May-17_-_-_Ceph_Performance_Weekly","date":"2018-05-16T16:00:00.000Z","updated":"2018-05-17T16:00:00.000Z","comments":true,"path":"2018/05/17/2018-May-17_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/17/2018-May-17_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： （此处应填写会议具体时间） 参会人员： （此处应填写参会人员名单） 会议主题： 本周 pull requests 汇报及优先级缓存设计讨论 会议内容： 1. 本周 pull requests 汇报 新提交的 pull requests： 与 Sage 商量后，本周未收到 Sage 的回复，可能存在冲突，会议继续进行。 提交了一个关于 Blue Store 优先级缓存的 pull requests，旨在简化用户设置内存使用比例的过程，并允许自动调优。 已合并的 pull requests： Igor 的 alligator pruning 修复 pull requests。 Async messenger pull requests，改进了锁定行为，可能对延迟相关场景有益。 Overwrite apps 恢复优化 pull requests，未合并，作者已关闭。 Igor 的新位图分配器 pull requests，Sage 已审查，希望替换旧代码。 lib RBD throttle pull requests，更新情况不明。 Radice Slavs 的 crypto SSL pull requests，正在测试和修复中。 未合并的 pull requests： Peter 的 disc right coalescing pull requests。 Adam 的哈希相关 pull requests，Sage 的版本正在工作，可能不需要 Adam 原始提案中那么多工作。 Peter 的减少 buffer list 重构的 pull requests。 Redick 的 huge pages pull requests。 Adam 的更多 pull requests。 其他： 讨论了 AES 和加密相关的 pull requests。 2. 优先级缓存设计讨论 问题： 目前，用户难以调整缓存设置，且设置比例难以确定。 当 Blue Store 和 RocksDB 的缓存冲突时，性能会下降。 RocksDB 默认会扩展块缓存，可能会超过用户指定的比例，导致索引和过滤器被清除。 解决方案： 提交的 pull requests 旨在简化用户设置内存使用比例的过程，并允许自动调优。 通过优先级方案，可以根据工作负载调整缓存分配。 未来工作包括： 使用基于时间的优先级缓存，根据工作负载动态调整缓存分配。 在 OSD 级别进行缓存管理，考虑更多内存使用情况。 为不同的列族创建多个缓存，或为不同的前缀设置不同的优先级。 决定事项： 继续推进优先级缓存设计，并解决相关问题和改进。 关注 RocksDB 的行为，并寻找解决方案以避免索引和过滤器被清除。 继续进行测试，并评估性能改进。 后续行动计划： 与 Sage 商量，确认参会情况。 继续开发优先级缓存功能。 修复 RocksDB 相关问题。 进行更多测试和评估。 会议总结： 本次会议讨论了本周 pull requests 和优先级缓存设计，并确定了后续行动计划。会议内容丰富，讨论深入，对 Ceph 的性能优化具有重要意义。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-10 :: Ceph Performance Weekly","slug":"2018-May-10_-_-_Ceph_Performance_Weekly","date":"2018-05-09T16:00:00.000Z","updated":"2018-05-10T16:00:00.000Z","comments":true,"path":"2018/05/10/2018-May-10_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/10/2018-May-10_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Peter、Igor、Chief、Adam、Nick、Josh等 会议主题： 分布式存储Ceph相关研发讨论 会议内容： 1. 代码审查与Pull Request Peter提出一个关于Blue Store的新位图定位器，旨在提高对话场景中的性能。该设计通过减少空间占用，提高查找速度，并支持并发请求处理。 Igor展示了关于Blue Store位图定位器的性能比较，结果显示位图定位器在所有测试案例中都优于现有定位器，尤其是在随机分配场景下。 Adam提交了一个代码审查请求，涉及一些可能影响性能的更改。目前正在进行进一步调查，以确定其可行性。 Chief关闭了两个Pull Request，其中一个涉及Rgw，另一个原因不明。 Nick提出了关于PG数量和OSD性能的问题，讨论了如何处理大容量驱动器和高速I/O驱动器对集群性能的影响。 2. 位图定位器设计 Igor详细介绍了新位图定位器的设计，包括数据结构、内存占用和性能优势。 讨论了位图定位器在连续分配场景下的局限性，以及如何通过优化内存表示来减少内存消耗。 讨论了与现有B树定位器的比较，以及位图定位器在大型存储设备上的优势。 3. PG数量和OSD性能 Nick提出关于PG数量和OSD性能的问题，讨论了如何处理大容量驱动器和高速I/O驱动器对集群性能的影响。 Josh表示，大容量硬盘并不会显著提高I/O性能，因为随机写入速度较慢。 讨论了使用混合布局来优化硬盘性能的想法，例如在硬盘的前端使用更细粒度的布局。 4. 其他议题 讨论了XFS日志对性能的影响，并建议进行更多测试。 讨论了在RBD级别实现日志接口的想法，以提高并行性。 后续行动计划： 继续研究Adam提交的代码审查请求。 对位图定位器进行更多测试，包括连续分配场景和大型存储设备。 研究混合布局对硬盘性能的影响。 进行更多测试，以了解XFS日志对性能的影响。 考虑在RBD级别实现日志接口。 会议总结： 本次会议讨论了Ceph分布式存储的相关研发工作，包括位图定位器设计、PG数量和OSD性能等问题。会议达成了多项共识，并确定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-MAY-02 :: Ceph Developer Monthly","slug":"2018-MAY-02_-_-_Ceph_Developer_Monthly","date":"2018-05-02T16:00:00.000Z","updated":"2018-05-03T16:00:00.000Z","comments":true,"path":"2018/05/03/2018-MAY-02_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/03/2018-MAY-02_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2018年5月 会议主题： Ceph社区开发月度会议 参会人员： Ceph社区开发人员 会议内容： 一、会议纪要 多节点存储会议： 通知了即将举办的软件定义存储会议，鼓励社区成员提交论文。 Ceph用户调查： 鼓励社区成员完成用户调查，以帮助改进Ceph。 Mimic版本： 介绍了Mimic版本的开发进度，预计将在三到四周内发布。 Nautilus版本： 讨论了Nautilus版本的开发计划，包括消息协议更改、Kerberos集成和PD合并等。 RBD命名空间： 讨论了RBD命名空间的设计，包括命名空间的隔离和访问控制。 快照修剪： 讨论了快照修剪的性能和安全性问题。 日志记录： 讨论了Ceph日志记录的性能和可扩展性问题，并提出了使用LTTng进行结构化日志记录的方案。 二、讨论的主要议题 Mimic版本发布： 讨论了Mimic版本的发布计划和功能特性。 Nautilus版本开发： 讨论了Nautilus版本的开发计划和重点功能。 RBD命名空间： 讨论了RBD命名空间的设计和实现方案。 快照修剪： 讨论了快照修剪的性能和安全性问题。 日志记录： 讨论了Ceph日志记录的性能和可扩展性问题，并提出了使用LTTng进行结构化日志记录的方案。 三、决定的事项 继续推进Mimic版本的发布工作。 继续推进Nautilus版本的开发工作。 设计并实现RBD命名空间。 优化快照修剪的性能和安全性。 使用LTTng进行结构化日志记录。 四、后续行动计划 继续跟踪Mimic版本的发布进度。 继续跟踪Nautilus版本的开发进度。 完成RBD命名空间的设计和实现工作。 优化快照修剪的性能和安全性。 实现使用LTTng进行结构化日志记录的方案。 五、其他 鼓励社区成员积极参与Ceph的开发和维护工作。 鼓励社区成员分享经验和知识，共同推动Ceph的发展。 关键词： Mimic版本、Nautilus版本、RBD命名空间、快照修剪、日志记录、LTTng","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-May-03 :: Ceph Performance Weekly","slug":"2018-May-03_-_-_Ceph_Performance_Weekly","date":"2018-05-02T16:00:00.000Z","updated":"2018-05-03T16:00:00.000Z","comments":true,"path":"2018/05/03/2018-May-03_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/05/03/2018-May-03_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 参会人员： 部分人员因故缺席，包括一位身体状况不佳的成员。 会议主题： Ceph社区更新、讨论关键议题、行动计划 关键细节： 社区更新： Peter提交了一个新的PR，旨在减少在BlueFS中执行日志记录时的无缓冲树构建，这可能对性能产生积极影响。 Josh关闭了一些与CBT相关的PR，Neha正在努力修复这些问题。 Redick关闭了一些旧的PR，旨在改进与NSS相关的功能，并可能转向OpenSSL。 Atom提交了两个PR，一个关于限制页面错误，另一个关于哈希。 缓存自动调优： 讨论了在BlueFS中启用缓冲写入的利弊，以及自动调优缓存的不同行为。 发现缓冲写入在某些情况下可能会降低性能，但可能在其他情况下有所帮助。 目前正在收集更多数据以评估自动调优的效果。 日志记录： 讨论了当前日志记录的性能影响，以及未来可能采用的新日志记录方法。 讨论的主要议题： 缓存自动调优的效果和最佳实践。 在BlueFS中启用缓冲写入的利弊。 日志记录的性能影响和改进方法。 决定的事项： 继续收集缓存自动调优的数据，并评估其效果。 进一步研究在BlueFS中启用缓冲写入的最佳实践。 观察和讨论日志记录的性能影响和改进方法。 后续行动计划： Josh和Neha将继续修复CBT相关的问题。 Redick将继续改进与NSS相关的功能。 Atom将继续研究限制页面错误和哈希的问题。 社区成员将关注缓存自动调优和日志记录的讨论，并提供反馈。 备注： 会议中提到的关键术语包括：BlueFS、CBT、OSS、OpenSSL、页面错误、哈希等。 会议中提到的PR编号和作者未在纪要中列出。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Apr-26 :: Ceph Performance Weekly","slug":"2018-Apr-26_-_-_Ceph_Performance_Weekly","date":"2018-04-25T16:00:00.000Z","updated":"2018-04-26T16:00:00.000Z","comments":true,"path":"2018/04/26/2018-Apr-26_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/26/2018-Apr-26_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 参会人员： Josh, Sage, CJ, Igor, Adam, Virata 等 会议主题： Ceph 分布式存储项目进展讨论 会议内容： 1. 编译与代码问题 Josh 分享了代码编译过程中遇到的问题，并提到在修复编译错误后，系统似乎运行良好，但他对此感到怀疑，担心可能存在更复杂的问题。 2. 项目进展 Osteen Mapping Encoding： Sage 介绍了 Osteen Mapping Encoding 的进展，该功能即将合并，但需要回滚到 Luminous 版本。 Slav Pull Requests： Sage 提到了 Slav 的几个 pull requests，旨在加快加密操作，并提到正在使用 OpenSSL 进行更大规模的更改。 其他合并项： 包括 Creek assist 和 Shin 等功能。 Blue Store： 讨论了 Blue Store 的巨大页面使用情况，以及如何优化内存使用和减少同步开销。 Recovery Optimization： Josh 表示该功能尚未准备好，将联系 Young 了解更多信息。 OpenSSL： CJ 认为使用 OpenSSL 的改动很有前景。 内存分配和释放列表管理： Igor 正在研究新的位图分配方法，Adam 正在研究碎片化问题。 Blue Store Cash Balancing： John 讨论了 Blue Store Cash Balancing 的设置方式，认为当前的设置不够直观，并建议简化缓存调整过程。 3. 决定事项 将 Osteen Mapping Encoding 功能回滚到 Luminous 版本。 关注 Slav 的 pull requests，并跟踪 OpenSSL 改动的进展。 进一步优化 Blue Store 的巨大页面使用。 跟踪 Recovery Optimization 和内存分配相关问题的进展。 简化 Blue Store Cash Balancing 的设置过程。 4. 后续行动计划 Josh 将联系 Young 了解 Recovery Optimization 的进展。 CJ 将关注 OpenSSL 改动的进展。 John 将准备相关 pull requests，以简化 Blue Store Cash Balancing 的设置过程。 5. 其他事项 会议讨论了其他一些议题，但没有形成明确的行动计划。 会议结束。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Averting crisis at multi-petabyte scale - Piotr Dałek","slug":"Averting_crisis_at_multi-petabyte_scale_-_Piotr_Da_ek","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Averting_crisis_at_multi-petabyte_scale_-_Piotr_Da_ek/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Averting_crisis_at_multi-petabyte_scale_-_Piotr_Da_ek/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储系统问题分析与解决方案讨论 会议关键细节： 问题概述： 遇到性能问题，客户无法访问数据或数据访问非常缓慢。 存储系统出现故障，导致数据恢复时间过长，影响用户体验。 用户误操作或恶意行为导致资源消耗过大，影响系统性能。 解决方案： 将存储节点规模缩小，将单节点容量从PB级降至TB级，降低故障影响范围。 增加日志记录，收集情报，定位问题根源。 使用自定义工具修改内部数据库，修复数据结构错误。 提高监控能力，及时发现异常行为。 优化资源管理，避免资源浪费。 讨论的主要议题： 性能优化： 通过缩小节点规模，降低故障影响范围。 优化资源分配，避免资源浪费。 提高监控能力，及时发现异常行为。 故障处理： 及时发现故障并进行修复。 确保数据安全性，避免数据丢失。 提高故障恢复速度，减少对用户体验的影响。 用户行为管理： 防止用户误操作或恶意行为。 对用户行为进行监控，及时发现异常行为。 提供用户培训，提高用户操作水平。 决定的事项： 实施存储节点规模缩小策略。 增加日志记录，收集情报，定位问题根源。 使用自定义工具修复数据结构错误。 提高监控能力，及时发现异常行为。 优化资源管理，避免资源浪费。 后续行动计划： 制定详细的实施计划，明确责任人和时间节点。 对相关人员进行培训，确保方案顺利实施。 定期跟踪方案实施情况，及时调整和优化。 关键词： Ceph 分布式存储 性能优化 故障处理 用户行为管理 资源管理 日志记录 情报收集 数据结构 监控 资源浪费","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Basic and Advanced Analysis of Ceph Volume Backend Driver in Cinder - John Haan","slug":"Basic_and_Advanced_Analysis_of_Ceph_Volume_Backend_Driver_in_Cinder_-_John_Haan","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Basic_and_Advanced_Analysis_of_Ceph_Volume_Backend_Driver_in_Cinder_-_John_Haan/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Basic_and_Advanced_Analysis_of_Ceph_Volume_Backend_Driver_in_Cinder_-_John_Haan/","excerpt":"","text":"会议纪要 会议主题 Cinder块存储服务在Model公司的应用与实践 参会人员 Jan Man（Model公司存储团队负责人） 其他存储领域相关人员 会议内容 1. Model公司背景介绍 - Model公司是一家韩国游戏公司，专注于移动游戏开发和云服务。 - 2017年，Model公司从2016年的传统生产环境转型至基于Cinder的分布式存储环境，这对游戏服务产生了重大影响。 2. Cinder块存储服务架构 - Model公司目前拥有8个Cinder集群，存储约PB级数据。 - 其中，3个集群用于玩家B/D及两个区域，4个集群用于Ingress和Block存储。 - Cinder集群中，有一个对象存储池作为服务的主存储，容量利用率达到22%。 3. Cinder块存储服务特点 - Cinder提供多种资源管理选项，如RBD（块设备）、Cinder卷等。 - Cinder支持数据生命周期管理，包括快照、克隆等功能。 - Cinder支持快照复制，用于数据备份和灾难恢复。 4. Cinder快照与克隆 - Cinder支持快照和克隆功能，可以方便地创建和管理数据副本。 - 快照是基于原始数据的静态快照，克隆是基于快照或原始数据的动态副本。 - Cinder支持增量快照，可以减少数据传输量。 5. Cinder块存储服务的优化 - Model公司使用不可变镜像功能，提高了从镜像创建卷的性能。 - 使用图像缓存卷，减少了数据传输量，提高了性能。 6. Cinder块存储服务的应用 - Model公司在Stack Overflow应用程序中使用了Cinder块存储服务。 - Cinder块存储服务在Model公司的游戏服务和云服务中发挥着重要作用。 决定事项 继续优化Cinder块存储服务，提高性能和可靠性。 探索Cinder块存储服务的更多应用场景。 后续行动计划 Model公司将密切关注Cinder块存储服务的最新动态，不断优化和改进服务。 与社区合作，共同推动Cinder块存储技术的发展。 关键词 Cinder块存储 RBD 快照 克隆 数据生命周期 可变镜像 图像缓存 Stack Overflow","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Management and Monitoring with Dashboard v2 - Lenz Grimmer","slug":"Ceph_Management_and_Monitoring_with_Dashboard_v2_-_Lenz_Grimmer","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Ceph_Management_and_Monitoring_with_Dashboard_v2_-_Lenz_Grimmer/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Ceph_Management_and_Monitoring_with_Dashboard_v2_-_Lenz_Grimmer/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议关键细节 参会人员对团队及项目表达了欢迎和期待。 介绍人员回顾了其加入团队前所在公司（Open Attic）的历史和项目背景。 讨论了Open Attic项目与Salt和DeepSea的关系，以及未来发展方向。 探讨了将Open Attic功能迁移到Dashboard的可行性及实施计划。 回应了关于Dashboard与其他工具（如Calamari）的比较问题。 讨论的主要议题 项目背景及历史： 介绍人员回顾了其在Open Attic项目的工作经历，并介绍了Open Attic项目的起源和目标。 讨论了Open Attic项目与Salt和DeepSea的关系，以及项目迁移到Dashboard的原因。 功能迁移： 探讨了将Open Attic中的NFS共享管理功能（Ganesha）和目标管理功能（Iscsi）迁移到Dashboard的可行性。 由于Salt和DeepSea的存在，直接迁移这些功能存在一定的难度，需要进一步讨论解决方案。 Dashboard与Open Attic： 讨论了Dashboard作为Open Attic的替代品，以及未来开发方向。 确定了将Open Attic的功能逐步迁移到Dashboard的计划。 与其他工具的比较： 回应了关于Dashboard与其他工具（如Calamari）的比较问题。 强调了Dashboard的设计理念是提供最实用的功能，并鼓励用户提出功能建议。 决定的事项 将Open Attic的功能逐步迁移到Dashboard。 进一步讨论如何解决Salt和DeepSea带来的迁移难题。 鼓励用户提出功能建议，并积极贡献代码。 后续行动计划 团队将继续开发Dashboard，并逐步迁移Open Attic的功能。 针对迁移过程中的问题，团队将进行技术讨论和方案设计。 鼓励用户参与Dashboard的开发和功能完善。 其他事项 [请在此处填写其他需要记录的事项]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph QoS: How to support QoS in distributed storage system - Taewoong Kim","slug":"Ceph_QoS_-_How_to_support_QoS_in_distributed_storage_system_-_Taewoong_Kim","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Ceph_QoS_-_How_to_support_QoS_in_distributed_storage_system_-_Taewoong_Kim/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Ceph_QoS_-_How_to_support_QoS_in_distributed_storage_system_-_Taewoong_Kim/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议地点： （未提及） 参会人员： Tim King（SK Telecom），其他与会人员 会议主题： SK Telecom在Ceph存储系统上的研发工作及未来计划 会议内容： 一、介绍与背景 Tim King代表SK Telecom介绍其公司在Ceph存储系统上的研发成果和相关工作。 SK Telecom作为韩国领先的电信公司，旗下拥有SK Broadband和SK Hynix等子公司，分别提供互联网服务和存储解决方案。 SK Telecom希望通过与OpenStack Ceph社区的协作，实现ICT公司之间的协同效应，并利用其子公司SK Hynix提供的SSD来优化Ceph存储环境。 二、Ceph存储系统优化 针对Ceph存储系统在虚拟化环境下的资源竞争和性能问题，SK Telecom提出了以下优化方案： 资源分配方法： 引入优先级队列，根据不同用户的请求进行资源分配，以满足不同用户的需求。 调度算法： 引入基于最小-最大权重算法的调度算法，实现更精细的资源分配。 服务质量保证： 通过预留和限制控制，以及比例共享QoS控制，确保关键业务的服务质量。 三、Ceph功能增强 SK Telecom计划在Ceph中引入以下功能增强： US（用户空间）功能： 通过US功能，实现更细粒度的资源分配和调度。 去重功能： 提高存储空间的利用率，降低存储成本。 私有云和虚拟桌面： 利用Ceph构建私有云和虚拟桌面，为企业用户提供便捷的存储服务。 四、未来计划 SK Telecom将继续参与Ceph社区的开发工作，并计划在以下方面进行拓展： 支持更多存储系统： 扩展Ceph的功能，支持更多存储系统，如文件系统、元数据服务器等。 社区合作： 与Ceph社区紧密合作，共同推动Ceph的发展。 五、讨论与总结 与会人员就Ceph存储系统的优化和功能增强进行了讨论，并提出了以下建议： DM Clock： 将DM Clock应用于其他SEFs项目，如文件系统中的元数据服务器，以提供更好的服务质量。 US功能： 进一步完善US功能，支持更多存储系统，如视频墙和目录服务器等。 后续行动计划： SK Telecom将继续参与Ceph社区的开发工作，并推动Ceph存储系统的优化和功能增强。 与Ceph社区保持紧密合作，共同推动Ceph的发展。 关键词： Ceph OpenStack 虚拟化 资源分配 调度算法 QoS US功能 去重功能 私有云 虚拟桌面","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph and the future of Open Source Storage - Land Lu","slug":"Ceph_and_the_future_of_Open_Source_Storage_-_Land_Lu","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Ceph_and_the_future_of_Open_Source_Storage_-_Land_Lu/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Ceph_and_the_future_of_Open_Source_Storage_-_Land_Lu/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 参会人员： [请填写参会人员名单] 会议主题： 讨论Ceph分布式存储系统近期工作进展及字幕翻译项目进展。 关键细节： 会议开始以一段音乐作为引子，随后进入正式讨论。 与会人员就Ceph系统的性能优化和稳定性进行了深入探讨。 字幕翻译项目方面，讨论了英译中的具体实施方法和翻译质量保证。 讨论的主要议题： Ceph系统性能优化： 讨论了在867端口上Ceph系统的性能表现，并确认了其稳定性和可用性。 对Ceph系统的IPC（内部进程通信）进行了评估，以确保其高效性。 字幕翻译项目： 确定了英译中翻译的具体方法和流程。 讨论了如何保证翻译质量，包括对翻译人员的培训和翻译内容的审核。 决定的事项： Ceph系统： 继续关注867端口上Ceph系统的性能表现，并根据实际情况进行优化。 加强IPC通信的监控和优化，确保系统的高效运行。 字幕翻译项目： 制定详细的翻译流程和标准，确保翻译质量。 对翻译人员进行定期培训和考核，提高翻译水平。 后续行动计划： Ceph系统： 制定具体性能优化计划，并跟踪实施进度。 定期收集系统性能数据，进行分析和调整。 字幕翻译项目： 开展翻译人员培训，提高翻译质量。 定期对翻译内容进行审核，确保翻译准确无误。 [请注意，以上纪要内容仅为示例，具体内容需根据实际会议情况进行调整。]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph for Big Science - Dan van der Ster","slug":"Ceph_for_Big_Science_-_Dan_van_der_Ster","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Ceph_for_Big_Science_-_Dan_van_der_Ster/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Ceph_for_Big_Science_-_Dan_van_der_Ster/","excerpt":"","text":"会议纪要 会议主题： CERN使用Ceph进行大规模科学存储 会议时间： 2023年11月（具体日期未提及） 参会人员： CERN代表、Ceph社区成员 会议内容： 一、CERN背景介绍 CERN是世界上最大的粒子加速器，位于瑞士日内瓦。 CERN拥有约300PB的存储和230,000个CPU核心，是全球LHC计算网格的一部分。 CERN使用Ceph进行大规模科学存储，包括实验数据存储、虚拟文件系统等。 二、Ceph在CERN的应用 SEF存储集群： 2013年开始使用SEF进行存储集群建设，目前已拥有8个生产集群。 主要用于OpenStack Cinder和Glance，存储量接近6PB。 也用于CFS、物理数据存储和S3对象存储。 SEF文件系统： 使用SEF文件系统（SFS）替代虚拟NFS文件系统，提供高可用性和可扩展性。 已在OpenShift和Kubernetes中使用，并计划添加Kubernetes插件。 使用多MDS功能提高性能和可靠性。 SEF块设备： 使用SEF块设备（RBD）存储Glance镜像和Cinder卷。 提供不同质量服务（QoS）的卷类型。 正在开发备份驱动程序，将RBD数据备份到S3。 超融合SEF： 在云和HPC计算节点上测试超融合SEF。 需要解决存储和计算团队之间的协作问题。 三、Ceph改进建议 块设备： 开发RBD性能监控工具，识别最活跃的卷。 支持微秒级延迟和千兆IOPS。 支持客户端端加密。 在超融合集群中，使用OpenStack工具确保用户获得接近其运行机器的卷。 SEF文件系统： 改善并行I/O性能，提高HPC存储性能。 开发数据复制工具，跨集群复制大量数据。 开发备份工具，支持多用户备份。 RAIDoS： 支持池级别对象备份，例如从副本复制到快照。 其他： 解决大型集群的配置和升级问题。 支持大型企业级数据库和大规模批处理。 四、未来展望 CERN预计在2020年代将产生数百PB的数据，需要更强大的存储系统。 CERN正在与Ceph社区合作，进行大规模测试，验证Ceph的扩展性。 CERN希望将Ceph用于更多存储场景，包括全球数据湖。 五、行动计划 CERN将继续与Ceph社区合作，推动Ceph的改进。 CERN将进行更多测试，验证Ceph在大型集群中的性能和可靠性。 CERN将探索将Ceph用于更多存储场景的可能性。 关键词： CERN、SEF、Ceph、OpenStack、Cinder、Glance、S3、RBD、SFS、HPC、超融合、数据湖","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph's journey at SUSE - Lars Marowsky Brée, Marc Koderer","slug":"Ceph_s_journey_at_SUSE_-_Lars_Marowsky_Bree_Marc_Koderer","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Ceph_s_journey_at_SUSE_-_Lars_Marowsky_Bree_Marc_Koderer/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Ceph_s_journey_at_SUSE_-_Lars_Marowsky_Bree_Marc_Koderer/","excerpt":"","text":"会议纪要： 会议主题： Ceph 分布式存储产品回顾与发展展望 会议时间： 2023年（具体日期未提及） 参会人员： Ceph 社区成员、SUSE 公司代表、客户代表等 会议内容： 一、会议回顾与挑战 SUSE 公司在 Linux 领域拥有超过 25 年的经验，与 Ceph 合作已有 4-5 年。 传统存储系统在可扩展性、成本和适应性方面存在不足，无法满足数据增长的需求。 数据保护和管理成为挑战，需要高可用性和冗余。 二、Ceph 的优势与选择原因 Ceph 是一个开源的分布式存储系统，具有可扩展性、高可用性和数据保护等优点。 SUSE 选择 Ceph 的原因包括： Ceph 是开源的，可以持续发展。 Ceph 社区活跃，贡献者众多。 Ceph 支持多种平台和架构。 Ceph 具有良好的可管理性和监控能力。 三、SUSE 与 Ceph 的合作 SUSE 自 2012 年起就开始提供 Ceph 的产品和服务。 SUSE 是 Ceph 社区的积极贡献者，参与多个项目。 SUSE 提供 Ceph 的认证和咨询服务。 四、Ceph 的未来发展方向 Ceph 将继续发展，包括： 提高可扩展性和性能。 改善用户体验和管理能力。 与容器和云原生技术集成。 利用人工智能和机器学习技术。 五、客户案例 SAP 公司使用 Ceph 作为其云原生平台的核心存储解决方案。 SAP 的案例展示了 Ceph 在大规模物联网工作负载中的应用。 六、行动计划 SUSE 将继续支持 Ceph 社区，并推动 Ceph 的发展。 SUSE 将提供更多 Ceph 产品和服务，以满足客户需求。 关键词： Ceph、分布式存储、SUSE、开源、可扩展性、高可用性、数据保护、云原生、物联网","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph, the future of Storage - Sage Weil","slug":"Ceph_the_future_of_Storage_-_Sage_Weil","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Ceph_the_future_of_Storage_-_Sage_Weil/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Ceph_the_future_of_Storage_-_Sage_Weil/","excerpt":"","text":"会议纪要 会议时间 [请填写会议日期] 会议地点 北京 参会人员 主持人：Ceph社区代表 与会嘉宾：Ceph社区成员、开发者、用户及赞助商代表 会议内容 1. 开场致辞 主持人对参会人员的到来表示感谢，并介绍了会议的赞助商和主办方。 强调了Ceph作为统一存储系统的特点，包括支持对象、块和文件工作负载。 2. Ceph简介 Ceph是一个统一的存储系统，提供对象存储、块存储和文件存储服务。 Ceph基于Rados，提供可靠的分布式存储、弹性、冗余等功能。 Ceph的优势在于其开源、可靠、可扩展性和灵活性。 3. Ceph社区发展 Ceph社区每九个月发布一个主要版本，并维护社区版本长达两年。 最新版本为Luminous，下一个版本为Mimic。 Luminous版本引入了BlueStore后端和RBD的纠删码支持等新特性。 Mimic版本将带来PG合并、自动缩放、集中配置管理等功能。 4. 未来发展方向 性能：Ceph将优化OSD代码，以充分利用NVMe闪存等新一代存储设备。 新平台：Ceph将加强与OpenStack、Kubernetes等平台的集成，并支持新兴的工作负载，如数据湖、人工智能和机器学习。 易用性：Ceph将改善用户体验，简化部署和管理，并引入新的Web界面。 可扩展性：Ceph将支持更大规模的集群和跨数据中心的数据迁移。 5. 参与方式 参会人员可以通过Ceph官网、邮件列表、IRC和GitHub等途径参与Ceph社区。 决定事项 Ceph社区将继续致力于提升性能、易用性和可扩展性。 Ceph将加强与新兴平台和工作的负载的集成。 Ceph社区将积极招募新的贡献者。 后续行动计划 举办Ceph技术研讨会和开发者会议。 发布Ceph的新版本和特性。 招募新的贡献者，壮大Ceph社区。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Common Support Issues And How To Troubleshoot Them - Michael Hackett, Vikhyat Umrao","slug":"Common_Support_Issues_And_How_To_Troubleshoot_Them_-_Michael_Hackett_Vikhyat_Umrao","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Common_Support_Issues_And_How_To_Troubleshoot_Them_-_Michael_Hackett_Vikhyat_Umrao/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Common_Support_Issues_And_How_To_Troubleshoot_Them_-_Michael_Hackett_Vikhyat_Umrao/","excerpt":"","text":"会议纪要 会议主题： Ceph存储常见支持问题和故障排除 参会人员： - Rob，Red Hat存储软件维护工程师 - Nick，Red Hat存储软件维护工程师 会议内容： 一、慢请求问题 问题描述： 慢请求是指Ceph检测到请求处理时间过长的情况，默认为30秒，可调整。 可能原因： 硬件问题：磁盘驱动器老化、控制器驱动或固件问题、主机内核配置不当等。 网络问题：网络设备配置错误、网络拥塞、网络延迟等。 系统负载：CPU、RAM或OS过度使用。 Ceph内部问题：OSD恢复、深度清洗、压缩和分割操作等。 故障排除方法： 检查Ceph状态和详细日志。 使用Linux工具（如iostat、perf）分析性能指标。 检查网络性能和吞吐量。 分析Ceph日志文件，使用Ceph日志解析器等工具辅助诊断。 二、OSD抖动问题 问题描述： OSD抖动是指OSD频繁上下线，导致集群不稳定。 可能原因： 大量对象导致索引键值对过多。 删除操作导致数据碎片化。 Ceph内部问题：压缩、分割操作等。 故障排除方法： 确保索引池使用NVMe或SSD存储。 检查对象大小，避免过大的对象。 使用离线压缩移除碎片数据。 考虑迁移到RocksDB存储引擎。 三、会议决定事项 加强对Ceph存储常见问题的培训和故障排除指导。 开发Ceph日志解析器等工具，辅助故障排除。 探索RocksDB存储引擎的优化方案。 四、后续行动计划 Rob和Nick将整理一份详细的故障排除指南，并在Red Hat社区进行分享。 Red Hat将继续优化Ceph存储性能和稳定性。 关键词： 慢请求、OSD抖动、Ceph、故障排除、RocksDB","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"DeepSea: Deployment and Management of Ceph with Salt - Joshua Schmid","slug":"DeepSea_-_Deployment_and_Management_of_Ceph_with_Salt_-_Joshua_Schmid","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/DeepSea_-_Deployment_and_Management_of_Ceph_with_Salt_-_Joshua_Schmid/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/DeepSea_-_Deployment_and_Management_of_Ceph_with_Salt_-_Joshua_Schmid/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写会议地点] 参会人员： [请填写所有参会人员名单] 会议主题： Ceph 部署管理框架 DeepSea 的介绍和功能 会议内容： 1. 介绍与背景 主讲人介绍：Josh，德国软件工程师，专注于部署和管理框架。 DeepSea 简介：DeepSea 是一个基于 Salt 的 Ceph 部署和管理框架，旨在简化 Ceph 集群的部署和管理。 Salt 简介：Salt 是一个开源配置管理和远程执行引擎，具有 minion 和 master 架构，支持并发和可扩展性。 2. DeepSea 的功能 集群管理：DeepSea 支持自动部署和管理 Ceph 集群，包括节点角色分配、配置管理、监控等。 自动化：DeepSea 提供自动化脚本和工具，简化集群部署和管理流程。 可扩展性：DeepSea 支持大规模集群部署，可扩展性强。 可定制性：DeepSea 支持用户自定义集群配置和部署流程。 3. DeepSea 的架构 Minion 和 Master 架构：DeepSea 基于 Salt 的 minion 和 master 架构，实现远程执行和配置管理。 Grains 和 Pillar：DeepSea 使用 grains 和 pillar 来存储节点信息和用户定义数据。 State 和 Orchestration：DeepSea 使用 state 和 orchestration 来定义集群配置和部署流程。 4. DeepSea 的部署流程 阶段 0：预部署：同步模块、更新软件包、配置网络接口等。 阶段 1：信息收集：收集集群信息，创建目录结构和 pillar 数据。 阶段 2：部署：执行部署脚本，安装软件包、配置节点角色等。 阶段 3：验证：验证集群配置和部署结果。 阶段 4：监控：配置监控工具，监控集群状态。 5. DeepSea 的未来计划 用户界面：计划开发用户界面，提高用户体验。 支持更多平台：计划支持更多操作系统和硬件平台。 功能扩展：计划扩展 DeepSea 的功能，例如存储池管理、性能优化等。 6. 总结 DeepSea 是一个功能强大的 Ceph 部署和管理框架，可以帮助用户简化 Ceph 集群的部署和管理。DeepSea 具有自动化、可扩展性和可定制性等特点，是 Ceph 集群管理者的理想选择。 后续行动计划： [请填写后续行动计划，例如：继续跟进 DeepSea 的开发、评估 DeepSea 的适用性等。]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Doing QoS Before Ceph Cluster QoS is available - David Byte, Alex Lau","slug":"Doing_QoS_Before_Ceph_Cluster_QoS_is_available_-_David_Byte_Alex_Lau","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Doing_QoS_Before_Ceph_Cluster_QoS_is_available_-_David_Byte_Alex_Lau/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Doing_QoS_Before_Ceph_Cluster_QoS_is_available_-_David_Byte_Alex_Lau/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： 分布式存储Ceph相关议题及视频会议字幕翻译讨论 会议内容摘要： 本次会议主要围绕以下议题展开讨论： Ceph存储技术讨论： 会议中提到了Ceph存储系统的多个级别和对抗者，以及如何处理不同级别的挑战。 讨论了Ceph在处理大量数据（如葡萄干）时的效率和性能。 提到了ANS（自动节点分割）等关键技术。 视频会议字幕翻译： 会议涉及到英译中的字幕翻译工作，讨论了翻译过程中的难点和解决方案。 提到了Spivak 2等翻译工具的使用。 行动计划： 确定了对Ceph存储技术的进一步研究和优化计划。 安排了字幕翻译工作的具体分工和时间节点。 关键细节： Ceph相关关键词： Ceph, 分布式存储, 自动节点分割 (ANS), 对抗者 (adversaries), 葡萄干 (raisins) 字幕翻译关键词： 英译中, Spivak 2, 翻译工具 决定事项： 对Ceph存储系统进行深入研究，以提高其性能和效率。 安排字幕翻译人员，确保视频会议字幕的准确性和及时性。 后续行动计划： [具体日期]： 完成Ceph存储系统性能优化方案。 [具体日期]： 确定字幕翻译人员并分配任务。 [具体日期]： 定期召开会议，跟踪项目进度。 备注： 会议中多次出现音乐和掌声，表明会议氛围活跃。 部分内容可能涉及隐私或敏感信息，请妥善处理。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Email Storage with Ceph - Danny Al Gaaf","slug":"Email_Storage_with_Ceph_-_Danny_Al_Gaaf","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Email_Storage_with_Ceph_-_Danny_Al_Gaaf/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Email_Storage_with_Ceph_-_Danny_Al_Gaaf/","excerpt":"","text":"会议纪要 会议主题： 电子邮件存储解决方案评估与实施计划 参会人员： Sam、Danny、RFC、Letitia、Celia、Mr. Dan Elraf、电信部门代表 会议内容： 一、当前电子邮件存储现状 现有平台： 使用传统和网络附加存储，性能不佳，NFS操作效率低下。 存储需求： 系统包含4900万用户账户，存储约1.3PB的电子邮件，约6.7亿封邮件，且数据量持续增长。 性能瓶颈： 存储空间利用率低，NFS操作存在大量不必要的修正和操作，系统性能需优化。 二、解决方案评估 传统文件系统： POSIX兼容性要求高，复杂度高，不适合电子邮件存储。 对象存储： 存储效率高，但安全性不足，且无法直接访问存储网络。 Ceph： 兼具自动自愈、高性能、低成本等优点，适合电子邮件存储。 三、解决方案选择 Harvey Sense： 自主开发，基于Ceph，支持混合存储架构，包含邮件索引和缓存功能。 硬件选型： 使用Luminous版本Ceph，采用HP标准硬件，包括双10G网络接口、SSD和HDD存储。 四、实施计划 测试阶段： 进行功能测试、性能测试和可靠性测试。 生产部署： 将Harvey Sense集成到现有邮件系统中，逐步迁移用户数据。 五、后续工作 性能优化： 优化存储性能，降低I/O开销。 安全加固： 加强数据安全防护。 社区参与： 积极参与Ceph社区，贡献代码和文档。 六、结论 Harvey Sense项目有望解决当前电子邮件存储的痛点，提高存储效率，降低成本，并提升用户体验。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Erasure Code at Scale - Thomas William Byrne","slug":"Erasure_Code_at_Scale_-_Thomas_William_Byrne","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Erasure_Code_at_Scale_-_Thomas_William_Byrne/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Erasure_Code_at_Scale_-_Thomas_William_Byrne/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 英国牛津郡Rutherford Appleton实验室 参会人员： Ceph研发人员 大型强子对撞机（LHC）实验相关人员 高能物理研究所（IHEP）相关人员 会议主题： Ceph在大型强子对撞机（LHC）实验中的存储应用 Ceph集群的性能优化和问题解决 Ceph社区对纠删码的支持 会议内容： 一、Ceph在LHC实验中的应用 LHC实验每年产生约50PB的数据，需要大规模存储系统进行存储和分析。 Rutherford Appleton实验室负责存储和分析工作，拥有超过30PB的磁盘存储和约10PB的磁带存储。 研究人员正在使用Ceph替换原有的磁盘存储系统，以提供更高的性能和可扩展性。 二、Ceph集群的性能优化 Ceph集群使用纠删码进行数据保护，并采用较大的存储节点（每个节点30+驱动器）。 研究人员使用Liberator Stripper插件来优化数据分布和性能。 研究人员通过调整CRUSH映射和放置组大小来优化集群性能。 三、Ceph集群的问题解决 研究人员遇到了一些问题，例如： 纠删码放置组回填导致的性能问题。 不一致的放置组导致的数据可用性问题。 磁盘坏道导致的数据损坏问题。 研究人员通过以下方式解决了这些问题： 更新Ceph版本以修复已知问题。 调整集群配置以优化性能。 使用手动CRUSH映射编辑来管理集群。 四、Ceph社区的支持 研究人员对Ceph社区在纠删码支持方面的进展感到满意。 研究人员希望Ceph社区能够继续改进纠删码的性能和稳定性。 五、后续行动计划 研究人员将继续使用Ceph存储系统，并评估其性能和稳定性。 研究人员将继续与Ceph社区合作，解决集群中存在的问题。 研究人员将评估Ceph的新功能，并将其应用于集群中。 关键词： Ceph 纠删码 CRUSH映射 放置组 放置组回填 不一致的放置组 磁盘坏道 数据损坏","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Everything You Wanted to Know About RadosGW - Orit Wassermann, Matt Benjamin","slug":"Everything_You_Wanted_to_Know_About_RadosGW_-_Orit_Wassermann_Matt_Benjamin","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Everything_You_Wanted_to_Know_About_RadosGW_-_Orit_Wassermann_Matt_Benjamin/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Everything_You_Wanted_to_Know_About_RadosGW_-_Orit_Wassermann_Matt_Benjamin/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储系统更新与未来规划 会议时间： 2023年10月10日 会议地点： 远程 参会人员： Joseph Lanza、Benjamin、Matthew、其他研发人员 会议内容： 一、对象存储概述 对象存储位于块存储和文件系统之间，专为大规模对象和大量数据设计。 对象组织在桶或容器中，桶不能包含其他桶。 对象不可变，允许多副本存储，提高扩展性。 支持版本控制和生命周期管理，方便数据恢复和存储优化。 二、Ceph 对象存储（RGW）功能 支持S3接口，使用REST API进行访问。 支持多部分上传，提高大文件上传效率。 支持版本控制，方便数据恢复。 支持生命周期管理，自动清理旧版本数据。 支持多地域复制，提高数据可用性和容错性。 三、Ceph RGW 未来规划 多地域复制： 支持跨不同地域的数据同步。 支持数据转换和格式转换。 支持双向同步。 性能优化： 使用异步I/O提高性能。 引入调度器，智能管理流量。 优化桶索引结构，提高查询效率。 一致性保证： 改进缓存一致性机制。 支持跨集群一致性保证。 安全特性： 支持基于令牌的认证。 支持Kerberos认证。 支持桶级访问控制。 四、行动计划 继续推进多地域复制功能。 优化Ceph RGW性能。 改进数据一致性保证。 加强安全特性。 完善文档和测试。 五、其他 会议还讨论了Ceph RGW与其他组件的集成，例如CephFS和Ceph Mon。 会议强调了持续集成和持续部署的重要性。 关键词： 对象存储、Ceph RGW、多地域复制、性能优化、一致性保证、安全特性、异步I/O、调度器、桶索引、缓存一致性、令牌认证、Kerberos认证、桶级访问控制","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Extending Ceph's Reach - Tushar Gohad, Zhong Xin","slug":"Extending_Ceph_s_Reach_-_Tushar_Gohad_Zhong_Xin","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Extending_Ceph_s_Reach_-_Tushar_Gohad_Zhong_Xin/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Extending_Ceph_s_Reach_-_Tushar_Gohad_Zhong_Xin/","excerpt":"","text":"会议纪要 会议主题： 分布式存储Ceph的扩展与应用 会议时间： 2023年11月（具体日期未提及） 参会人员： 李浩，Tushar Goel（英特尔首席工程师），以及其他来自英特尔、红帽、思杰等公司的代表 会议内容： 1. 会议开场 李浩首先对与会嘉宾表示感谢，并介绍了本次会议的演讲者Tushar Goel，他是英特尔的首席工程师，专注于软件定义存储领域已有五年以上。 2. Ceph存储的未来 Tushar Goel指出，随着数据量的激增，存储需求也在不断增长。英特尔致力于扩展Ceph存储的覆盖范围，将新的工作负载引入到Ceph中。他强调了开源社区的重要性，并介绍了英特尔在Ceph社区中的贡献。 3. 数据增长趋势 Tushar Goel分析了数据增长的来源，包括普通互联网用户、智能工厂、智能汽车等。他指出，中国是这一增长故事的重要组成部分。 4. Ceph用户案例 Tushar Goel展示了Ceph的一些用户案例，如Wall Street Journal、Facebook、Salesforce等，这些公司都在使用Ceph存储数据。 5. Ceph技术发展 Tushar Goel介绍了英特尔在Ceph技术方面的贡献，包括性能优化、管理性提升等。他重点介绍了以下三个方面： 非易失性内存（NVM）： 英特尔正在与社区合作，将NVM编程模型应用于异步OSD，以降低延迟，提高性能。 数据缓存： 英特尔正在优化数据缓存策略，将数据更接近应用程序，减少网络延迟。 压缩和加密： 英特尔正在支持压缩和加密功能，以保护数据安全。 6. 存储趋势 Tushar Goel探讨了存储领域的三个趋势： 非易失性内存： 随着NVM的普及，存储系统软件的延迟将越来越低，需要重新思考软件堆栈的设计。 解耦： 通过解耦计算、存储和网络资源，可以提高数据中心的效率和可扩展性。 管理性： 随着工作负载的增长，需要提高Ceph的管理性，包括监控、调优和故障排除。 7. Ceph在公益领域的应用 Tushar Goel分享了Ceph在公益领域的应用案例，如National Center for Missing and Exploited Children。该组织使用Ceph存储大量数据，并取得了显著成效。 8. 总结与展望 Tushar Goel总结了本次会议的主要内容，并展望了Ceph存储的未来。他强调，英特尔将继续与社区合作，推动Ceph存储的发展，并为更多用户带来价值。 后续行动计划： 继续优化Ceph性能和管理性。 推动Ceph在更多领域的应用。 加强与社区的合作，共同推动Ceph存储的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Experiences building a distributed shared log on RADOS - Noah Watkins","slug":"Experiences_building_a_distributed_shared_log_on_RADOS_-_Noah_Watkins","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Experiences_building_a_distributed_shared_log_on_RADOS_-_Noah_Watkins/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Experiences_building_a_distributed_shared_log_on_RADOS_-_Noah_Watkins/","excerpt":"","text":"会议纪要 会议时间： [此处应填写会议具体时间] 会议地点： [此处应填写会议具体地点] 参会人员： [此处应填写参会人员姓名及职位] 会议主题： 本次会议主要围绕Ceph分布式存储技术及视频会议字幕翻译与总结工作展开。 会议内容： 一、Ceph分布式存储技术讨论 议题： 讨论Ceph存储系统的最新进展、性能优化及潜在问题。 讨论要点： 引入了一些关于Ceph系统性能提升的探讨，如优化存储节点配置、调整集群规模等。 讨论了Ceph集群中数据一致性、故障恢复等关键问题的解决方案。 分析了Ceph在处理大数据场景下的性能瓶颈，并探讨了可能的优化方案。 二、视频会议字幕翻译与总结工作 议题： 讨论视频会议字幕翻译的流程、质量及效率。 讨论要点： 分析了英译中翻译过程中可能遇到的问题，如专业术语、文化差异等。 讨论了提高字幕翻译效率的方法，如使用机器翻译辅助人工翻译等。 强调了字幕翻译质量的重要性，并提出了相应的质量保证措施。 决定事项： Ceph分布式存储技术： 将继续关注Ceph社区的最新动态，跟踪性能优化方案。 对现有Ceph集群进行性能评估，根据评估结果制定相应的优化方案。 视频会议字幕翻译与总结工作： 优化字幕翻译流程，提高翻译效率。 加强对翻译质量的监控，确保翻译准确无误。 后续行动计划： Ceph分布式存储技术： 制定详细的性能优化方案，并在测试环境中验证其效果。 定期组织Ceph技术分享会，提升团队成员的技术水平。 视频会议字幕翻译与总结工作： 评估现有字幕翻译工具，选择合适的工具提高翻译效率。 定期对翻译人员进行培训，提高翻译质量。 其他事项： [此处可填写会议中讨论的其他事项或后续需要关注的问题]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Global Deduplication for Ceph - Myungwon Oh","slug":"Global_Deduplication_for_Ceph_-_Myungwon_Oh","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Global_Deduplication_for_Ceph_-_Myungwon_Oh/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Global_Deduplication_for_Ceph_-_Myungwon_Oh/","excerpt":"","text":"会议纪要 会议时间： 2011年10月6日或7日 参会人员： Luis Terry Jones Efe Louis Justin Turner Washington Testino Forlán Yang Ming Sánchez Jobson Ashton Carlin Lows Garmin 会议主题： 讨论多领域项目进展、创意合作以及未来规划。 关键细节与议题： 项目进展与创意合作： Luis介绍了自己的音乐项目，并强调了对音乐的热爱。 Terry Jones分享了关于“光之死”的故事，探讨了爱与牺牲的主题。 Efe和Louis讨论了音乐创作的心得，强调创作过程中的情感投入。 Justin Turner分享了自己在巴黎的绘画灵感，以及对城市与自然的感悟。 Washington Testino和Forlán展示了他们的舞台表演，并讨论了与Yang Ming的合作。 Sánchez提出了关于生活与创作的想法，强调了项目与生活的紧密联系。 Jobson介绍了自己的工作，并分享了关于媒体与艺术的见解。 Ashton和Carlin讨论了他们的音乐创作，并探讨了艺术与生活的融合。 Lows分享了关于舞蹈与音乐的想法，并探讨了艺术与生活的关系。 Garmin介绍了自己的工作，并分享了关于科技与艺术的见解。 未来规划： 会议讨论了未来合作的可能性，包括音乐、艺术、科技等多个领域。 参会人员表示愿意相互学习、交流，共同推动项目发展。 决定的事项： 各参会人员将继续关注各自领域的项目进展，并积极寻求合作机会。 将在适当的时候组织线下交流活动，促进项目合作。 后续行动计划： 各参会人员将整理会议讨论内容，形成书面文件。 定期召开线上或线下会议，跟踪项目进展。 积极寻求与更多领域的合作伙伴，共同推动项目发展。 关键词汇（计算机科学/ceph相关领域）： 无（会议内容未涉及计算机科学/ceph相关领域）","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Making Ceph Awesome on Kubernetes with Rook - Bassam Tabbara","slug":"Making_Ceph_Awesome_on_Kubernetes_with_Rook_-_Bassam_Tabbara","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Making_Ceph_Awesome_on_Kubernetes_with_Rook_-_Bassam_Tabbara/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Making_Ceph_Awesome_on_Kubernetes_with_Rook_-_Bassam_Tabbara/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： Rook项目介绍及Ceph在Kubernetes上的应用 会议内容： 一、会议关键细节 主讲人：Bassam 主题：Rook项目介绍及Ceph在Kubernetes上的应用 Rook是一个云原生存储编排器，旨在将Ceph等存储系统与Kubernetes集成，简化存储管理。 二、讨论的主要议题 Kubernetes概述： Bassam介绍了Kubernetes的基本概念，强调其在容器编排和资源管理方面的作用，并指出Kubernetes的广泛应用和持续增长。 Ceph与Kubernetes的集成： Bassam解释了Ceph作为分布式存储系统在Kubernetes上的应用，并介绍了Rook项目如何通过自动化部署、配置和生命周期管理，使Ceph在Kubernetes上运行更加高效。 Rook的功能： 自动化部署和管理Ceph集群 提供存储集群、存储池、对象存储和文件系统等资源 监控集群状态并进行故障恢复 Rook的优势： 简化存储管理 提高Ceph集群的可用性和可靠性 与Kubernetes无缝集成 三、决定的事项 推广Rook项目，鼓励更多人参与贡献 加强Rook的性能测试，确保其在生产环境中的稳定性 推动Ceph在Kubernetes上的应用，推动社区共识 四、后续行动计划 Rook项目团队将继续开发和完善Rook功能 社区将共同推动Ceph在Kubernetes上的应用 定期举行社区会议，分享经验和最佳实践 五、其他 会议期间，参会人员就Rook的性能、稳定性、部署方式等问题进行了讨论。 Bassam表示，Rook项目仍在开发中，预计将在六个月内达到生产就绪状态。 关键词： Kubernetes、Ceph、Rook、存储系统、容器编排、资源管理、自动化部署、生命周期管理","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Optimized Scatter/Gather Support for Parallel Storage - Carlos Maltzahn","slug":"Optimized_Scatter_Gather_Support_for_Parallel_Storage_-_Carlos_Maltzahn","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Optimized_Scatter_Gather_Support_for_Parallel_Storage_-_Carlos_Maltzahn/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Optimized_Scatter_Gather_Support_for_Parallel_Storage_-_Carlos_Maltzahn/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议具体地点] 参会人员： [请填写参会人员名单] 会议主题： 分布式存储Ceph技术讨论及字幕翻译工作总结 会议内容： 一、Ceph技术讨论 关键议题： 讨论了Ceph存储系统中因数据溢出导致的性能问题。 讨论要点： 由于数据在各个存储节点之间的溢出，导致系统性能下降。 需要进一步分析数据溢出的原因，并寻找解决方案。 探讨了通过优化数据分布和存储策略来减少数据溢出的可能性。 二、字幕翻译工作 关键议题： 总结了视频会议字幕翻译及总结工作。 讨论要点： 翻译过程中遇到的主要问题，如专业术语理解、文化差异等。 总结了翻译过程中的经验教训，以及如何提高翻译质量。 讨论了后续翻译工作的改进方向。 三、行动计划 Ceph技术方面： 对Ceph存储系统进行性能测试，分析数据溢出的原因。 优化数据分布和存储策略，减少数据溢出。 持续关注Ceph社区的更新，学习新技术，提高系统性能。 字幕翻译方面： 加强对专业术语的学习，提高翻译准确性。 结合文化背景，提高翻译的流畅性和可读性。 优化翻译流程，提高工作效率。 四、其他事项 [请填写其他需要讨论的事项] [请填写其他需要跟进的事项] 五、下次会议时间及主题 [请填写下次会议时间及主题] 备注： 本次会议纪要仅供参考，具体内容以实际情况为准。 请各位参会人员根据会议内容，及时跟进相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Performance tuning in BlueStore & RocksDB - Li Xiaoyan","slug":"Performance_tuning_in_BlueStore_RocksDB_-_Li_Xiaoyan","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Performance_tuning_in_BlueStore_RocksDB_-_Li_Xiaoyan/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Performance_tuning_in_BlueStore_RocksDB_-_Li_Xiaoyan/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 会议地点： [具体地点] 参会人员： [列出参会人员姓名] 会议主题： Ceph分布式存储系统架构和性能优化讨论 会议内容： 一、Ceph系统架构概述 Ceph概述： Ceph是一个高性能、可扩展的分布式存储系统，适用于对象存储、块存储和文件系统。 Ceph组成部分： 包括管理组件、存储组件、监控组件和服务组件。 Ceph存储层： 由对象存储层（Blobstore）和存储池（Pool）组成，对象存储层支持数据的持久化和高效访问。 二、Blobstore架构 Blobstore特性： 支持不可变对象存储，提供高效的读写性能。 内存缓存： 使用内存缓存来加速数据访问，缓存大小可配置。 数据持久化： 数据在内存中处理完毕后，写入磁盘存储。 三、数据流和性能优化 数据流： 客户端请求数据，经过缓存、处理和写入磁盘的过程。 性能优化： 内存管理： 通过调整内存表大小和数量来优化性能。 数据写入： 使用写入优化策略，减少磁盘I/O压力。 数据读取： 使用缓存和数据预取技术提高读取性能。 四、测试结果和分析 测试场景： 对4K随机读取和16K随机读取进行测试。 测试结果： 分析了不同配置下的性能表现，包括内存表大小、缓存策略等。 优化建议： 调整内存表大小和数量，优化内存使用效率。 使用更有效的缓存策略，提高数据访问速度。 优化数据写入和读取过程，减少磁盘I/O压力。 五、后续行动计划 代码优化： 根据测试结果，对Ceph代码进行优化。 性能测试： 对优化后的代码进行性能测试，验证性能提升效果。 文档更新： 更新Ceph文档，介绍新的性能优化策略。 六、会议总结 本次会议讨论了Ceph分布式存储系统的架构和性能优化，提出了相应的优化策略和后续行动计划。通过优化，可以提高Ceph的性能和稳定性，满足用户的需求。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Pinpoint Ceph Bottleneck Out of Cluster Behavior Mists - Yingxin Cheng","slug":"Pinpoint_Ceph_Bottleneck_Out_of_Cluster_Behavior_Mists_-_Yingxin_Cheng","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Pinpoint_Ceph_Bottleneck_Out_of_Cluster_Behavior_Mists_-_Yingxin_Cheng/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Pinpoint_Ceph_Bottleneck_Out_of_Cluster_Behavior_Mists_-_Yingxin_Cheng/","excerpt":"","text":"会议纪要 会议主题：Ceph分布式存储性能分析及优化 会议时间：[请填写会议时间] 会议地点：[请填写会议地点] 参会人员：[请填写参会人员名单] 会议内容： 会议开场： 介绍：由Intel的软件工程师Changing开场，他主要负责Ceph性能分析。 性能分析的重要性： 性能问题可能导致用户体验差，影响系统响应速度。 识别瓶颈对于性能优化至关重要。 Ceph性能分析工具： 介绍了一种基于分布式追踪的性能分析方法，能够快速定位瓶颈。 使用事件之间的“发生之前”关系和事件间的成本（如跨线程、跨主机关系）来分析性能。 性能概念： 性能是二维概念，包括延迟和吞吐量。 需要关注并发请求的性能，并使用新的可视化技术。 性能可视化： 通过绘制吞吐量和延迟的关系图，可以直观地展示性能。 将关键路径堆叠并聚合成本，以展示并发请求的性能。 瓶颈识别： 瓶颈通常表现为整个流程中的最低性能部分。 可以通过分析不同步骤的延迟来识别瓶颈。 性能优化： 识别瓶颈的根本原因并解决它们。 考虑物理因素（如系统配置、硬件）和逻辑因素（如参数、算法、架构）。 使用增量分析来识别不同因素对性能的影响。 案例演示： 通过一个Ceph集群中的IBD图像请求示例，展示了性能分析工具的使用。 使用数据驱动分析工具（如Jupiter）进行可视化分析。 会议总结： 强调了性能分析在Ceph系统中的重要性。 介绍了基于分布式追踪的性能分析方法。 展示了性能可视化和瓶颈识别的技术。 鼓励使用增量分析进行性能优化。 后续行动计划： [请填写后续行动计划，如：继续优化性能分析工具、推广使用该工具等]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Petabyte Scale Object Storage Service Using Ceph in A Private Cloud - Varada Kari","slug":"Petabyte_Scale_Object_Storage_Service_Using_Ceph_in_A_Private_Cloud_-_Varada_Kari","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Petabyte_Scale_Object_Storage_Service_Using_Ceph_in_A_Private_Cloud_-_Varada_Kari/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Petabyte_Scale_Object_Storage_Service_Using_Ceph_in_A_Private_Cloud_-_Varada_Kari/","excerpt":"","text":"会议纪要 会议时间 [请填写会议具体时间] 会议地点 [请填写会议地点] 参会人员 Barda（Flipkart） Flipkart 团队成员 会议主题 Flipkart 与 Ceph 的合作历程 Ceph 在 Flipkart 内部部署与使用 面临的挑战及解决方案 Ceph 的 QoS 机制与集群监控 会议内容 一、Flipkart 公司介绍 Flipkart 是印度最大的电子商务公司，拥有 8000 万产品，70 多个产品目录，10 万卖家，每日访问量达 3000 万人次，每月发货量达 800 万件。 Flipkart 使用 Ceph 作为对象存储服务，已部署近三年，拥有两个数据中心，每个数据中心约 20000 台主机，完全虚拟化基础设施。 二、Ceph 部署与使用 Flipkart 使用 Ceph 作为对象存储服务，主要关注数据持久性和可靠性。 部署了三个不同类型的工作负载： 低延迟平台：用于存储小对象，关注低延迟。 备份平台：用于备份关键数据库，优化带宽。 归档平台：用于存储需要长期保存的数据，优化性能和容量。 使用多个集群，每个集群包含多个节点，包括 Mon、OSD、MDS 和 RGW。 三、挑战与解决方案 写入压力过大：通过将日志迁移到 SSD 和引入写回缓存来缓解。 元数据问题：通过手动分片和禁用日志池来解决。 应用错误：通过引入速率限制和检查桶创建请求来解决。 数据丢失：通过开发离线工具来查找和删除丢失的对象。 升级问题：从 Hammer 升级到 Luminous 过程中遇到了挑战，目前正在寻找解决方案。 四、QoS 机制 使用四层保障机制确保服务质量： 负载均衡器：平衡负载。 Nginx 层：分离读写请求。 速率限制器：限制用户请求。 分区：将节点物理隔离。 五、集群监控 使用 OpenTSDB 和 Grafana 进行监控，收集系统统计信息、数据库统计信息和 I/O 统计信息。 使用警报系统来通知集群问题。 后续行动计划 继续优化 Ceph 集群，解决升级问题。 开发更多工具来提高集群可靠性和性能。 探索端到端 QoS 机制。 总结 Flipkart 使用 Ceph 作为其核心存储解决方案，取得了显著的成果。然而，仍面临一些挑战，需要进一步改进和优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RBD: What will the future bring? - Jason Dillaman","slug":"RBD_-_What_will_the_future_bring_-_Jason_Dillaman","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/RBD_-_What_will_the_future_bring_-_Jason_Dillaman/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/RBD_-_What_will_the_future_bring_-_Jason_Dillaman/","excerpt":"","text":"会议纪要 会议时间： [具体日期] 会议地点： [具体地点] 参会人员： [参会人员名单] 会议主题： 分布式存储Ceph相关议题及字幕翻译总结 一、会议关键细节 本次会议主要讨论了Ceph分布式存储的最新进展、字幕翻译工作进展以及总结工作情况。 二、讨论的主要议题 Ceph分布式存储进展： 会议中提到了Ceph分布式存储的技术细节，但具体内容未详细展开。 关键词：Ceph, 分布式存储, 技术 字幕翻译工作： 会上讨论了英译中字幕翻译的具体情况，包括翻译质量、进度等。 关键词：字幕翻译, 英译中 总结工作： 讨论了总结工作的进展，包括总结内容、格式等。 关键词：总结工作 三、决定的事项 确定Ceph分布式存储进展的详细讨论将在下一轮会议中进行。 视频会议字幕翻译工作将按照原有计划继续推进。 总结工作将按照既定格式完成。 四、后续行动计划 研发团队将针对Ceph分布式存储技术细节进行深入研究，并在下一轮会议中进行汇报。 字幕翻译团队将按照计划完成英译中字幕翻译工作。 总结团队将按照要求完成总结工作，并在下一轮会议前提交。 五、备注 会议中部分内容可能涉及个人隐私，请注意保密。 请参会人员按照会议决定的事项落实相关工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RADOS improvements and roadmap - Greg Farnum, Josh Durgin, Kefu Chai","slug":"RADOS_improvements_and_roadmap_-_Greg_Farnum_Josh_Durgin_Kefu_Chai","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/RADOS_improvements_and_roadmap_-_Greg_Farnum_Josh_Durgin_Kefu_Chai/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/RADOS_improvements_and_roadmap_-_Greg_Farnum_Josh_Durgin_Kefu_Chai/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： 分布式存储Ceph项目进展及字幕翻译工作讨论 一、会议关键细节 会议开始以一段音乐作为背景，随后进入正式讨论。 会议中涉及了多个议题，包括能源、法律、家庭和工作等多个方面。 二、讨论的主要议题 分布式存储Ceph项目进展： 项目组成员汇报了近期工作进展，包括功能开发、性能优化和稳定性测试等方面。 讨论了项目中遇到的技术难题，如数据一致性、故障恢复等。 字幕翻译及总结工作： 负责英译中的翻译人员分享了翻译过程中的经验和心得。 讨论了如何提高翻译质量，包括术语一致性、语境理解等。 能源和环境问题： 讨论了国外新能源技术的进展，以及我国在环保方面的政策。 强调了可持续发展的重要性。 法律和道德问题： 讨论了法律与道德的关系，以及在工作中如何平衡两者。 强调了诚信和责任的重要性。 家庭和工作： 分享了个人在家庭和工作中的平衡经验。 讨论了如何提高工作效率，以及如何保持身心健康。 三、决定的事项 分布式存储Ceph项目： 继续推进功能开发，重点关注数据一致性和故障恢复。 加强技术交流和合作，共同解决技术难题。 定期召开项目进展会议，及时沟通和调整。 字幕翻译及总结工作： 提高翻译质量，确保术语一致性。 加强与翻译人员的沟通，及时了解翻译需求。 定期总结翻译经验，分享给其他团队成员。 其他事项： 关注国内外能源和环境问题，积极推动可持续发展。 增强法律意识，维护公司利益。 平衡家庭和工作，保持身心健康。 四、后续行动计划 分布式存储Ceph项目： [具体人员]负责跟进功能开发和性能优化。 [具体人员]负责技术交流和合作。 [具体人员]负责召开项目进展会议。 字幕翻译及总结工作： [具体人员]负责提高翻译质量，确保术语一致性。 [具体人员]负责加强与其他团队成员的沟通。 其他事项： [具体人员]负责关注国内外能源和环境问题。 [具体人员]负责维护公司利益。 [具体人员]负责平衡家庭和工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RGW S3: Features Vs Deep Compatibility -  Robin Johnson","slug":"RGW_S3_-_Features_Vs_Deep_Compatibility_-_Robin_Johnson","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/RGW_S3_-_Features_Vs_Deep_Compatibility_-_Robin_Johnson/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/RGW_S3_-_Features_Vs_Deep_Compatibility_-_Robin_Johnson/","excerpt":"","text":"会议纪要 会议时间 （请填写会议具体时间） 会议地点 （请填写会议具体地点） 参会人员 （请填写参会人员名单） 会议议程 一、Ceph存储相关讨论 议题：讨论Ceph存储中AWS S3接口的实现和兼容性问题。 关键点： AWS S3接口存在多种实现和版本，导致兼容性问题。 Ceph的RGW组件需要更好地处理AWS S3的异常和变更。 需要加强对AWS S3接口的测试，确保Ceph的兼容性和稳定性。 行动计划： 完善Ceph的测试套件，增加对AWS S3接口的测试覆盖率。 分析AWS S3接口的变更记录，及时调整Ceph的实现。 与AWS S3团队沟通，寻求更好的兼容性解决方案。 二、视频会议字幕翻译及总结讨论 议题：讨论视频会议字幕翻译和总结的流程和优化。 关键点： 英译中字幕翻译需要考虑语境和文化差异。 总结需要提炼会议关键信息，并保持简洁。 行动计划： 建立字幕翻译和总结的标准流程。 使用翻译工具和人工智能技术提高翻译和总结的效率。 定期评估翻译和总结的质量，持续改进。 三、其他事项 议题：讨论Ceph存储的版本兼容性问题、数据安全性和服务质量（QoS）。 关键点： Ceph存储需要保持与现有数据的兼容性。 需要加强对数据安全的监控和保护。 QoS的实现需要考虑用户需求和系统负载。 行动计划： 制定Ceph存储的版本兼容性策略。 加强数据安全防护措施。 优化QoS的实现方案。 会议总结 本次会议主要讨论了Ceph存储的AWS S3接口兼容性、视频会议字幕翻译和总结流程优化以及其他相关事项。参会人员就相关问题进行了深入讨论，并制定了相应的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Reconsidering tracing in Ceph - Mohamad Gebai","slug":"Reconsidering_tracing_in_Ceph_-_Mohamad_Gebai","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Reconsidering_tracing_in_Ceph_-_Mohamad_Gebai/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Reconsidering_tracing_in_Ceph_-_Mohamad_Gebai/","excerpt":"","text":"会议纪要： 一、会议主题 本次会议主要讨论了Ceph中缓冲列表（buffer list）后端数据结构改进的可行性，并探讨了如何使用跟踪（tracing）技术进行性能分析。 二、会议内容 缓冲列表后端数据结构改进的背景 当前Ceph使用链表实现缓冲列表，存在内存不连续的问题，可能影响性能。 有建议将缓冲列表改用连续内存的向量（vector）结构。 使用跟踪技术进行性能分析 通过在插入操作前后添加跟踪点（trace point），记录相关性能指标。 分析缓存未命中、指令数、分支预测错误等数据，评估不同数据结构的性能。 实验结果分析 链表在内存足够的情况下指令数稳定，但缓存未命中较多。 向量在内存不足时指令数较多，但缓存友好。 双端队列在平均情况下表现较好。 日志记录优化 将日志记录改为跟踪点，提高效率。 分析结果显示，日志记录的性能瓶颈主要在字符串操作。 跟踪工具介绍 介绍Trace Compass工具，展示如何进行性能分析。 展示Ceph进程的运行状态、系统调用、关键路径等信息。 三、后续行动计划 1. 继续完善跟踪分析，确定最佳缓冲列表后端数据结构。 2. 优化日志记录，提高性能。 3. 探索其他跟踪工具，提高性能分析效率。 四、其他事项 1. 感谢与会成员的积极参与。 2. 感谢相关人员的支持和帮助。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Running Ceph on Flashcache - Paweł Sadowski","slug":"Running_Ceph_on_Flashcache_-_Pawe_Sadowski","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Running_Ceph_on_Flashcache_-_Pawe_Sadowski/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Running_Ceph_on_Flashcache_-_Pawe_Sadowski/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未知） 与会人员： Prabhav Sikka（OVH DevOps工程师），其他与会者姓名未提及 会议主题： Ceph分布式存储在OVH的使用经验及优化方案 关键细节： OVH使用Ceph作为其完全托管服务的一部分，拥有约150个集群，运行在1150台服务器上，存储容量约为44PB，使用2PB NVMe和超过70,000个SSD实例。 Prabhav Sikka分享了他们在使用Ceph过程中遇到的问题及解决方案。 讨论的主要议题及决定的事项： 议题一：缓存优化 问题： Ceph在执行深度清理（deep scrub）等操作时，会读取所有数据填充缓存，导致缓存数据无效，影响性能。 解决方案： 引入PID黑名单功能，允许禁用特定I/O的缓存。 使用跳过顺序阈值，跳过对大块连续读写的缓存。 决定： 推进PID黑名单功能的开发，并测试跳过顺序阈值的效果。 议题二：块大小匹配 问题： 客户端在执行快照操作时，由于未删除快照，导致大量数据需要保存到X属性中，影响性能。 解决方案： 修改Ceph配置，使块大小与存储层匹配，减少数据转换和冲突。 决定： 将此解决方案合并到Ceph文档中。 议题三：平缓曲线死锁 问题： 部分服务器出现随机冻结现象，导致I/O阻塞。 解决方案： 分析内核数据，发现死锁问题，并在XFS中修复。 决定： 将修复后的XFS版本部署到服务器上。 后续行动计划： 继续测试和优化Ceph性能。 推进PID黑名单功能的开发。 跟进跳过顺序阈值的效果。 部署修复后的XFS版本。 探索Ceph与其他存储技术的结合方案。 其他事项： OVH正在寻找Buster的替代方案，并正在测试Intel Ceph加速软件。 Prabhav Sikka认为Ceph是一个功能强大且值得信赖的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Status and Future of the Ceph File System - Patrick Donnelly","slug":"Status_and_Future_of_the_Ceph_File_System_-_Patrick_Donnelly","date":"2018-04-22T16:00:00.000Z","updated":"2018-04-23T16:00:00.000Z","comments":true,"path":"2018/04/23/Status_and_Future_of_the_Ceph_File_System_-_Patrick_Donnelly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/23/Status_and_Future_of_the_Ceph_File_System_-_Patrick_Donnelly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： Patrick Donnelly（Red Hat，Ceph SFS团队负责人） 会议主题： Ceph SFS（Ceph文件系统）的状态与未来 会议内容： 1. Ceph SFS简介 Ceph SFS是一个POSIX兼容的分布式文件系统，可以替代本地文件系统，并在多个系统间共享。 它由客户端、元数据服务器和数据存储组成。 客户端可以是FUSE客户端或内核客户端，后者通常提供更好的性能。 Ceph SFS支持一致缓存，确保客户端读取的是最新的数据。 客户端直接读取和写入数据，无需通过元数据服务器，提高性能和可扩展性。 2. Ceph SFS Luminous版本新特性 多活动元数据服务器： 允许线性扩展元数据负载，提高性能和可靠性。 子树固定： 允许手动分区文件系统，防止负载不平衡。 目录碎片化： 允许将大型目录分割成更小的部分，提高性能和可扩展性。 内存缓存限制： 允许限制元数据服务器的内存使用，避免内存溢出。 快照： 允许创建目录的快照，方便备份和版本控制。 3. Ceph SFS Mimic版本即将发布的特性 快照： 支持创建目录的快照，方便备份和版本控制。 内核配额支持： 支持内核配额，限制目录或子目录的大小。 缓存限制改进： 提高缓存利用率，减少内存使用。 NFS网关： 集成NFS网关，方便通过NFS访问Ceph SFS。 4. 其他讨论 快照的成本和数量： 快照成本相对较低，可以创建多个快照。 I/O锁： I/O锁仅控制对元数据服务器的串行访问，不影响多活动元数据服务。 行动计划： Red Hat将继续开发Ceph SFS，并计划在Mimic版本中发布更多新特性。 用户应关注Ceph社区和Red Hat的公告，了解Ceph SFS的最新动态。 关键词： Ceph SFS 分布式文件系统 POSIX兼容 一致缓存 多活动元数据服务器 子树固定 目录碎片化 内存缓存限制 快照 内核配额 缓存限制 NFS网关","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Apr-19 :: Ceph Performance Weekly","slug":"2018-Apr-19_-_-_Ceph_Performance_Weekly","date":"2018-04-18T16:00:00.000Z","updated":"2018-04-19T16:00:00.000Z","comments":true,"path":"2018/04/19/2018-Apr-19_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/19/2018-Apr-19_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间：2023年4月19日 会议主题：性能会议 会议关键细节： 目前Mimic版本处于冻结状态，ARS活动较少。 讨论了Blue Store Alligator策略的优化，Mike Market建议增加更多统计信息以更好地了解其工作情况。 讨论了收集分配器所需统计信息的方法，以了解其在生产环境中的工作方式和用途模式。 讨论了避免连续空间的需求，以及将BlueFS重构为与Sparks扩展兼容的方法。 讨论了异步信使的性能问题，特别是与CBT相关的 contention 和锁争用。 讨论的主要议题： Blue Store Alligator策略的优化： 收集更多统计信息，包括分配和释放的快照，以了解其在生产环境中的使用情况。 考虑重构BlueFS以避免连续空间的需求。 异步信使的性能问题： 优化异步信使的性能，特别是与CBT相关的 contention 和锁争用。 考虑禁用CBT以进行性能测试。 决定的事项： 收集Blue Store Alligator的统计信息，包括分配和释放的快照。 考虑重构BlueFS以避免连续空间的需求。 优化异步信使的性能，特别是与CBT相关的 contention 和锁争用。 后续行动计划： Mike Market将提交一个包含更多统计信息的TR。 评估重构BlueFS以避免连续空间的需求。 优化异步信使的性能，特别是与CBT相关的 contention 和锁争用。 关键词： Blue Store Alligator 统计信息 连续空间 异步信使 contention 锁争用 CBT","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Apr-12:: Ceph Performance Weekly","slug":"2018-Apr-12_-_-_Ceph_Performance_Weekly","date":"2018-04-11T16:00:00.000Z","updated":"2018-04-12T16:00:00.000Z","comments":true,"path":"2018/04/12/2018-Apr-12_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/12/2018-Apr-12_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： （此处应填写会议具体时间） 参会人员： （此处应填写参会人员名单） 会议主题： 本次会议主要讨论了Ceph存储系统在性能优化、功能开发以及相关技术问题。 关键细节： Pull Requests： 讨论了etherpad加载问题，并建议开始处理Pull Requests。 RocksDB2： 更新了RocksDB2的当前上游版本，并讨论了相关bug和性能测试。 Beast： 讨论了将CivetWeb替换为Beast的方案，以优化性能和资源消耗。 性能测试： 讨论了性能测试的重要性，并分享了相关测试结果。 Buffer List： 讨论了Buffer List的优化方案，包括使用Small Vector和改进内存管理。 CRC优化： 讨论了CRC优化方案，并建议移除Buffer List中的CRC相关功能。 C-Store： 讨论了C-Store的规划，包括对象存储接口和事务协议。 Seastar： 讨论了Seastar的性能优化和功能开发。 讨论的主要议题： 性能优化： 讨论了Ceph存储系统中各个组件的性能优化方案，包括RocksDB、Buffer List、网络协议等。 功能开发： 讨论了Ceph存储系统中新功能的开发，例如C-Store、对象存储接口等。 技术问题： 讨论了Ceph存储系统中遇到的技术问题，例如Buffer List的内存管理、CRC优化等。 决定的事项： 开始处理Pull Requests。 更新RocksDB2的当前上游版本，并进行相关测试。 将CivetWeb替换为Beast，优化性能和资源消耗。 对Buffer List进行优化，包括使用Small Vector和改进内存管理。 移除Buffer List中的CRC相关功能。 制定C-Store的规划，包括对象存储接口和事务协议。 继续优化Seastar的性能和功能。 后续行动计划： 各参会人员根据会议讨论内容，继续进行相关开发工作。 定期召开会议，跟踪项目进展情况。 其他事项： 讨论了Ceph存储系统中各个组件的优化方向和目标。 讨论了Ceph存储系统中遇到的技术难题和解决方案。 讨论了Ceph存储系统的未来发展方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Apr-05 :: Ceph Performance Weekly","slug":"2018-Apr-05_-_-_Ceph_Performance_Weekly","date":"2018-04-05T16:00:00.000Z","updated":"2018-04-06T16:00:00.000Z","comments":true,"path":"2018/04/06/2018-Apr-05_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/06/2018-Apr-05_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage, Josh, Adam, Lisa, Alex, Stanley, Nate等 会议内容： 一、新功能与改进 新Pull Request： Sage提到有一个新的Pull Request，涉及加密相关功能。 Neha提交了多个测试用例，用于夜间测试，进展良好。 O Stream功能已合并，Chrome标签页中的异步锁问题也已解决。 Recovery优化功能在QA环境中表现不佳，需要更多工作。 QAT功能持续更新中，有望尽快合并。 蓝鲸快照功能添加了巨大页面支持，提高了性能。 对atopic T比较器进行了优化，提高了效率。 修复了引用计数问题，简化了代码。 DW添加了列出非排序上下文的能力，提高了效率。 PG日志优化： Sage提出了一种通过注释掉PG日志来优化性能的方法，但效果有限。 讨论了是否值得继续推进这一方案，并决定进行更多测试以获取更多数据。 认为在RocksDB中进行Bloom过滤器计算等额外操作是导致性能下降的主要原因。 认为需要针对不同工作负载进行测试，以确定最佳的优化方案。 创建PD的优化： 讨论了通过创建单个PG并分割成多个副本来优化PD创建过程的方法。 认为这种方法可以减少竞争条件，提高效率。 认为Manager更适合负责这一功能，因为它不会与自动调优功能冲突。 蓝鲸存储内存优化： 讨论了如何根据数据访问时间优先级分配内存，以提高性能。 认为可以使用时间戳或标记来区分不同优先级的缓存。 认为需要进一步测试以确定最佳的实现方案。 蓝鲸FS磁盘分配优化： 讨论了将磁盘分配大小调整为最大值以提高性能的方法。 认为这种方法可以减少内存碎片，提高效率。 缓冲列表优化： 讨论了将缓冲列表从链表改为向量的方法来提高性能。 认为这种方法可以减少内存碎片，提高效率。 认为需要进一步测试以确定最佳的实现方案。 二、后续行动计划 Sage将进行更多测试，以确定PG日志优化方案的最佳实现方式。 Josh将研究创建PD的优化方案，并与John讨论具体实现方式。 Sage将研究蓝鲸存储内存优化方案的最佳实现方式。 Alex将研究蓝鲸FS磁盘分配优化方案的最佳实现方式。 Sage将研究缓冲列表优化方案的最佳实现方式。 三、其他事项 Sage请求Sage帮助解决CRC不匹配错误问题。 讨论了其他一些技术细节和问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-APR-04 :: Ceph Developer Monthly","slug":"2018-APR-04_-_-_Ceph_Developer_Monthly","date":"2018-04-04T16:00:00.000Z","updated":"2018-04-04T16:00:00.000Z","comments":true,"path":"2018/04/05/2018-APR-04_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/04/05/2018-APR-04_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年4月20日 会议主题： Ceph 存储系统开发者月度会议，讨论了可用性改进、健康状态改进、集群管理、测试和发布流程等方面。 关键细节： 可用性讨论： 探讨了 ceph osd caps 命令的易用性问题，提出了交互式编辑功能，并讨论了是否需要改进命令行交互性。 讨论了为 Ceph CLI 添加普通和专家模式，以隐藏复杂的子命令。 讨论了在删除存储池时提供交互式提示，以避免意外删除。 讨论了 ceph osd crush freeze 命令的用例，以暂停数据迁移或重新平衡，并讨论了如何实现该功能。 讨论了改进健康状态报告，包括可配置的健康阈值和静音功能。 讨论了改进 ceph fs volume 的输出，并提出了批处理准备功能。 讨论了模块化客户端的概念，以及如何实现可选功能。 健康状态改进： 讨论了改进健康状态报告，包括可配置的健康阈值和静音功能。 讨论了 ceph osd crush freeze 命令的用例，以暂停数据迁移或重新平衡，并讨论了如何实现该功能。 集群管理： 讨论了为 Ceph CLI 添加普通和专家模式，以隐藏复杂的子命令。 讨论了在删除存储池时提供交互式提示，以避免意外删除。 讨论了改进 ceph fs volume 的输出，并提出了批处理准备功能。 讨论了模块化客户端的概念，以及如何实现可选功能。 测试： 讨论了建立大规模 Ceph 测试环境，以进行正确性和性能测试。 讨论了测试的资源和数据库解决方案。 讨论了测试的优先级和目标。 发布流程： 讨论了改进 Ceph 发布流程，包括测试包发布和测试环境。 决定的事项： 将继续讨论可用性改进，包括交互式编辑、普通/专家模式和交互式提示。 将改进健康状态报告，包括可配置的健康阈值和静音功能。 将改进 ceph fs volume 的输出，并实现批处理准备功能。 将讨论模块化客户端的概念，并确定如何实现可选功能。 将建立大规模 Ceph 测试环境，以进行正确性和性能测试。 将改进 Ceph 发布流程，包括测试包发布和测试环境。 后续行动计划： 继续讨论可用性改进的具体实现方案。 实现健康状态改进功能。 实现 ceph fs volume 的改进功能。 探索模块化客户端的实现方案。 制定大规模 Ceph 测试计划。 改进 Ceph 发布流程。 其他： 讨论了 Ceph 仪表板的发展情况，包括新的功能、UI 改进和 API。 讨论了 Ceph 管理器 Python 接口，以及如何与各种编排工具集成。 讨论了 Ceph 测试环境，以及如何改进测试流程。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-Mar-15 :: Ceph Performance Weekly","slug":"2018-Mar-15_-_-_Ceph_Performance_Weekly","date":"2018-03-15T16:00:00.000Z","updated":"2018-03-15T16:00:00.000Z","comments":true,"path":"2018/03/16/2018-Mar-15_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/03/16/2018-Mar-15_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Aaron、Robbie、Mike、Patrick、Adams、Jesse、Mark、Lu、Casey、Ricardo、Maurice等 会议主题： Ceph社区开发进展、技术讨论及后续行动计划 会议内容： 1. 开发进展 DeMatha补丁： 修改了不同数据类型的哈希行为，解决了用户缺失和哈希冲突问题。 FUSE变更： Patrick正在审查的变更，修复了Luminous构建中未正确启用FAS RC功能的问题。 CRC问题： 每隔六个月都会发现CRC问题，讨论了可能的解决方案。 OSD批处理列表改进： 已合并，提高了assert效率。 同步消息： 有一个减少锁意向的请求，看起来很好。 丢弃操作： 线程丢弃已合并到master，周期性丢弃正在审查。 优化操作跟踪器： 有一个工作正在进行中，以提高效率。 移除读写互斥锁： 讨论了移除互斥锁的优化方案。 单线程失败： 讨论了由于2701和2662导致的头失败问题。 I/O节流器： 讨论了游戏时钟I/O节流器的等待问题。 2. 技术讨论 互斥锁： 讨论了将互斥锁切换到标准库的方案，并讨论了新的Texas Tech技术。 消息传递器： 讨论了多个OSD、核心、消息传递器和端口之间的组织结构。 自动调优： 讨论了在BlueStore和RocksDB之间自动调整不同缓存大小的方案。 3. 行动计划 测试DeMatha补丁： 在测试通过后合并到master。 修复CRC问题： 找出解决方案并修复。 审查FUSE变更： 审查并合并。 合并OSD批处理列表改进： 已合并。 审查同步消息请求： 审查并合并。 合并丢弃操作： 合并线程丢弃，审查周期性丢弃。 完成优化操作跟踪器： 完成工作并合并。 移除读写互斥锁： 完成优化方案并合并。 重新测试单线程失败： 重新测试并修复。 解决I/O节流器问题： 与相关方沟通并解决问题。 切换互斥锁： 完成切换互斥锁的方案并实施。 研究消息传递器组织结构： 研究并确定最佳方案。 实施自动调优方案： 完成测试并实施。 4. 其他事项 讨论了Ceph社区开发的其他事项，包括Scylla DB架构和Linux内核迁移。 总结： 本次会议讨论了Ceph社区的开发进展、技术讨论及后续行动计划。会议内容涵盖了多个方面，包括补丁合并、技术讨论、行动计划等。会议旨在提高Ceph社区的协作效率，推动Ceph项目的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-MAR-08 :: Ceph Performance Weekly","slug":"2018-MAR-08_-_-_Ceph_Performance_Weekly","date":"2018-03-08T16:00:00.000Z","updated":"2018-03-09T16:00:00.000Z","comments":true,"path":"2018/03/09/2018-MAR-08_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/03/09/2018-MAR-08_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 与会人员： [列出与会人员姓名] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 1. 项目进展 Pull Requests (PRs) 讨论： 新增了减少内存消耗的 batch_list_objects PR，希望获取相关统计信息。 async_messenger PR，旨在减少锁争用，并显示出了显著的延迟降低效果。 stupid_allocator_discard PR，已由 Igor 审查，可能带来改进。 op_tracker 工作正在顺利进行，已展示出在 ARM 和 cling 内存方面的优势。 cracker 优化取得显著成果。 已关闭的 PR： 两个 PR 已关闭，其中一个是关于 cash 活动的最小化跟踪，另一个是关于优化 mock/q 的。 更新的 PR： 有几个 PR 需要进一步关注和测试。 用户问题： 一位用户从文件存储迁移到蓝存储后，发现存在大量后台工作，导致性能问题。通过启用缓冲读取，问题得到了一定程度的缓解。讨论了使用自适应读取前向功能的可能性。 2. 新功能开发 缓存重新平衡机制： 开发者正在研究在蓝存储和 RocksDB 中实现缓存重新平衡机制，以提高缓存利用率。 计划使用 RocksDB 中的高优先级池和 BlueStore 的 mempool 线程来实现。 目标是提供更灵活的缓存管理，并根据不同工作负载进行智能决策。 3. 其他讨论 锁实现： 讨论了来自 GBC 的互斥锁实现，该实现不进行自旋，并尝试使用原子值检查锁定状态。 讨论了尝试锁（adoption_grad）的概念，它结合了自旋锁和互斥锁的特性。 4. 后续行动计划 继续关注和测试新的 PR。 完成缓存重新平衡机制的代码开发。 评估自适应读取前向功能对性能的影响。 关注和讨论锁实现的相关问题。 5. 会议总结 本次会议讨论了 Ceph 分布式存储项目的最新进展，并提出了新的功能开发计划。与会人员就项目进展、用户问题和开发计划进行了深入讨论，并制定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-MAR-07 :: Ceph Developer Monthly","slug":"2018-MAR-07_-_-_Ceph_Developer_Monthly","date":"2018-03-07T16:00:00.000Z","updated":"2018-03-08T16:00:00.000Z","comments":true,"path":"2018/03/08/2018-MAR-07_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/03/08/2018-MAR-07_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年3月20日 参会人员： 未知 会议主题： 开发者月度会议，讨论Ceph社区最新进展和计划。 会议内容： 1. Ceph存储功能改进 对象变更日志： 讨论了为Ceph对象存储（RGW）添加对象变更日志功能的需求。该功能旨在记录特定区域或桶中对象的变化，以便外部工具（如备份系统）可以轻松访问这些日志。 多区域同步模块： 讨论了多区域同步模块的改进，该模块允许在多个区域之间同步数据。目前，该模块已经实现了回调机制，用于在对象更改时跟踪更改并确保不遗漏任何更改。 合并更新： 讨论了合并更新功能，该功能允许将两个或多个存储池合并为一个。该功能仍在开发中，但仍处于早期阶段。 2. 配置历史记录 配置历史记录： 讨论了为Ceph配置添加历史记录功能的需求。该功能允许用户查看配置更改的历史记录，并回滚到以前的配置版本。该功能已经实现，但仍需要改进。 3. Ceph存储集群测试 Ceph存储集群测试： 讨论了Ceph存储集群测试的改进，包括测试用例和测试框架。 4. 其他 配置管理： 讨论了Ceph配置管理的改进，包括使用外部配置管理工具。 Ceph存储集群性能： 讨论了Ceph存储集群的性能改进，包括优化存储池和OSD的性能。 决定事项： 对象变更日志： 继续开发对象变更日志功能，并考虑使用S3日志接口。 合并更新： 继续开发合并更新功能，并考虑使用自动缩放器。 配置历史记录： 改进配置历史记录功能，包括使用标签和回滚功能。 Ceph存储集群测试： 改进Ceph存储集群测试，包括测试用例和测试框架。 配置管理： 探索使用外部配置管理工具的选项。 后续行动计划： 对象变更日志： 完成对象变更日志功能的开发，并提交给Ceph社区。 合并更新： 完成合并更新功能的开发，并提交给Ceph社区。 配置历史记录： 完成配置历史记录功能的改进，并提交给Ceph社区。 Ceph存储集群测试： 完成Ceph存储集群测试的改进，并提交给Ceph社区。 配置管理： 探索使用外部配置管理工具的选项，并提交给Ceph社区。 备注： 会议中讨论了多个Ceph存储功能改进，包括对象变更日志、合并更新、配置历史记录和Ceph存储集群测试。 会议还讨论了Ceph配置管理和Ceph存储集群性能的改进。 会议决定了后续行动计划，包括开发新功能、改进现有功能和探索新选项。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-MAR-01 :: Ceph Performance Weekly","slug":"2018-MAR-01_-_-_Ceph_Performance_Weekly","date":"2018-02-28T16:00:00.000Z","updated":"2018-03-01T16:00:00.000Z","comments":true,"path":"2018/03/01/2018-MAR-01_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/03/01/2018-MAR-01_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Mark、Sarah、Peter、David、Ian 等多位研发人员 会议主题： 讨论Ceph分布式存储系统中元数据管理、缓存策略、性能优化等问题。 主要议题及讨论内容： 1. 元数据管理 RocksDB元数据空间占用： 会议讨论了不同工作负载下RocksDB元数据空间占用情况，发现元数据空间占用与对象数量密切相关，特别是对于RGW对象，元数据空间占用较大。 缓存策略： 讨论了RocksDB和BlueStore的缓存策略，包括缓存大小、缓存优先级等。目前，Ceph默认将50%的内存分配给BlueStore，50%分配给RocksDB。会议认为，这种分配方式在大多数情况下是合理的，但对于特定场景可能需要调整。 缓存优化： 讨论了如何优化缓存策略，例如根据对象数量和键值对数量动态调整缓存大小，以及利用RocksDB接口查询索引和过滤器大小以分配缓存内存。 2. 性能优化 压缩优化： 讨论了RocksDB的压缩优化，包括是否在RocksDB中压缩块缓存，以及如何平衡压缩带来的CPU开销和存储空间占用。 日志优化： 讨论了日志优化，包括减少日志条目数量，以及是否禁用日志操作。 锁优化： 讨论了锁优化，包括减少锁争用，以及使用无锁数据结构。 3. 其他 Ceph Star： 讨论了Ceph Star的进展情况，以及如何将Ceph Star与现有存储引擎集成。 性能回归： 讨论了性能回归问题，以及如何避免性能回归。 决定的事项： 元数据管理： 继续使用默认的50/50缓存分配策略。 根据对象数量和键值对数量动态调整缓存大小。 利用RocksDB接口查询索引和过滤器大小以分配缓存内存。 性能优化： 进行压缩优化，平衡CPU开销和存储空间占用。 进行日志优化，减少日志条目数量。 进行锁优化，减少锁争用。 其他： 加快Ceph Star的进展。 避免性能回归。 后续行动计划： Mark： 发布RocksDB元数据空间占用测试数据。 尝试根据对象数量和键值对数量动态调整缓存大小。 Sarah： 进行RocksDB压缩优化。 进行日志优化。 Peter： 进行锁优化。 David： 继续推进Ceph Star相关工作。 总结： 本次会议讨论了Ceph分布式存储系统中元数据管理、缓存策略、性能优化等问题，并制定了相应的解决方案和后续行动计划。会议认为，通过优化元数据管理、缓存策略和性能，可以提高Ceph的效率和性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-FEB-22 :: Ceph Performance Weekly","slug":"2018-FEB-22_-_-_Ceph_Performance_Weekly","date":"2018-02-25T16:00:00.000Z","updated":"2018-02-26T16:00:00.000Z","comments":true,"path":"2018/02/26/2018-FEB-22_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/26/2018-FEB-22_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Peter, Mark, Assaf, David, John, Josh, 等 会议主题： Ceph分布式存储性能优化与问题解决 关键细节： 性能优化： Peter修复了OP Tracker缓慢的问题，性能提升明显。 Mark对标记压缩进行优化，提高了插入和删除效率。 Assaf对RBD进行优化，避免了不必要的内存分配。 John对PG日志进行优化，提高了性能。 David发现并修复了与流调试相关的性能问题。 Josh对个人对象恢复进行优化。 问题解决： Peter通过减少缓存修剪频率，提高了性能。 Mark优化了BlueStore缓存，减少了内存占用。 Mark对BlueStore进行重构，简化了代码结构。 Peter合并了配置归一化检查和配置选项观察者。 Assaf优化了对象映射，提高了性能。 John对BlueStore后端进行更新。 Josh对BlueStore缓存进行优化。 讨论议题： BlueStore缓存： 目前BlueStore缓存存在复杂性和性能问题。 讨论了是否应该移除BlueStore缓存，仅使用RocksDB缓存进行元数据存储。 认为需要更多数据来了解RocksDB缓存中Bloom过滤器的大小和内存占用。 认为应该禁用PG元项的Bloom过滤器，并部署测试集群来获取数据。 缓存配置： 讨论了缓存配置的复杂性和用户理解难度。 认为应该简化缓存配置，并提供一个用户友好的设置。 认为可以尝试使用简单的启发式方法或更复杂的在线优化模型。 其他： 讨论了FIO瓶颈和异步消息传递的性能问题。 讨论了编码/解码和CRC计算的优化。 决定的事项： Peter将继续测试和优化OP Tracker性能。 Mark将继续优化标记压缩和BlueStore缓存。 Assaf将继续优化对象映射。 John将继续优化PG日志。 Josh将继续优化个人对象恢复。 讨论了BlueStore缓存的移除和RocksDB缓存的优化。 讨论了缓存配置的简化。 讨论了FIO瓶颈和异步消息传递的性能优化。 后续行动计划： Peter将测试和优化OP Tracker性能。 Mark将测试和优化标记压缩和BlueStore缓存。 Assaf将测试和优化对象映射。 John将测试和优化PG日志。 Josh将测试和优化个人对象恢复。 讨论BlueStore缓存的移除和RocksDB缓存的优化。 讨论缓存配置的简化。 讨论FIO瓶颈和异步消息传递的性能优化。 收集更多数据来了解RocksDB缓存中Bloom过滤器的大小和内存占用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-FEB-15 :: Ceph Performance Weekly","slug":"2018-FEB-15_-_-_Ceph_Performance_Weekly","date":"2018-02-20T16:00:00.000Z","updated":"2018-02-20T16:00:00.000Z","comments":true,"path":"2018/02/21/2018-FEB-15_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/21/2018-FEB-15_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 参会人员： [此处列出参会人员姓名] 会议主题： Ceph存储性能优化与调试 会议内容： 一、性能优化 Retta Slav 在读性能测试中发现了两个主要问题： 通过MD config T访问配置选项速度过慢，已提交PR进行优化。 在非调试模式下填充流（oh streams）导致性能下降，已提交PR进行修复。 作者 在PTO期间发现memstore性能较慢，通过使用基于向量的对象存储和性能修复，显著提高了性能。 作者 发现pg log对CPU消耗影响较大，尤其是在使用in-memory vector-based存储时，CPU消耗从5个核心降至约3个核心。 作者 认为需要进一步优化pg log，并考虑使用PG ring buffers来提高性能。 二、调试设施 作者 发现mutex和perf counters对性能影响较大，特别是在finisher thread和OSD操作中。 作者 认为需要优化mutex的使用，并考虑使用更高效的机制。 作者 发现lock depth参数对性能影响较大，建议默认设置为none。 三、其他 作者 提出了一个新的object store playground项目，名为pet store，用于测试不同的性能优化方案。 作者 认为需要进一步优化object info T结构和PG info结构。 Adam 正在尝试使用off FFI编译Ceph，以验证性能表现。 后续行动计划： 作者 将继续优化pg log和性能相关代码。 作者 将进一步优化mutex的使用，并考虑使用更高效的机制。 Adam 将继续测试使用off FFI编译Ceph的性能表现。 全体成员 将继续关注Ceph的性能优化和调试工作。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，如：performance pull requests, MD config T, memstore, pg log, mutex, perf counters, lock depth, off FFI等。 总结： 本次会议讨论了Ceph存储性能优化和调试的相关问题，并提出了后续行动计划。会议强调了优化pg log和mutex使用的重要性，并建议继续探索新的性能优化方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day German - Ceph Management and Monitoring with openATTIC","slug":"Ceph_Day_German_-_Ceph_Management_and_Monitoring_with_openATTIC","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_German_-_Ceph_Management_and_Monitoring_with_openATTIC/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_German_-_Ceph_Management_and_Monitoring_with_openATTIC/","excerpt":"","text":"会议纪要 会议时间： [此处应填写会议的具体时间] 会议地点： [此处应填写会议的具体地点] 参会人员： Ivana（Fuli公司代表） [其他参会人员姓名] 会议主题： Ceph分布式存储系统管理进展及未来规划 关键细节： Ivana介绍了Ceph的发展历程和关键组件： - Ceph自2000年开始发展，经历了多个版本的迭代。 - Ceph的核心组件包括OSD（对象存储设备）、Mon（监控节点）和MDS（元数据服务器）。 - Ceph支持多种存储类型，包括块存储、文件存储和对象存储。 Ivana介绍了Ceph未来的发展方向： - Ceph将专注于自动化管理，提高易用性。 - Ceph将引入新的UI界面，提供更加直观的操作体验。 - Ceph将加强监控和故障排除功能。 Ivana介绍了Ceph的O Matic管理工具： - O Matic是一个自动化部署和管理Ceph集群的工具。 - O Matic支持并行执行，提高部署效率。 - O Matic支持多种部署场景，包括物理机、虚拟机和容器。 Ivana介绍了Ceph的OpenEdit Suite工具： - OpenEdit Suite是一个提供自动化运维功能的工具集。 - OpenEdit Suite支持状态管理、监控和故障排除等功能。 - OpenEdit Suite支持多种Ceph功能，包括CRUSH规则、监控和存储池管理。 讨论的主要议题： Ceph的未来发展方向 O Matic管理工具的改进 OpenEdit Suite工具的扩展 Ceph的自动化管理 决定的事项： 继续推进Ceph的自动化管理功能。 优化O Matic管理工具，提高部署效率。 扩展OpenEdit Suite工具，提供更多自动化运维功能。 后续行动计划： Ivana将提供O Matic和OpenEdit Suite工具的演示。 参会人员将提供反馈，帮助改进工具。 Ceph团队将根据反馈进行工具的改进和功能扩展。 其他事项： [此处可填写其他需要记录的事项]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day German - Five years of Ceph and Outlook","slug":"Ceph_Day_German_-_Five_years_of_Ceph_and_Outlook","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_German_-_Five_years_of_Ceph_and_Outlook/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_German_-_Five_years_of_Ceph_and_Outlook/","excerpt":"","text":"会议纪要 会议时间： 2023年10月27日 参会人员： 项目负责人、技术专家、市场人员等 会议主题： Ceph分布式存储项目进展、技术挑战及未来规划 会议内容： 一、企业数据存储挑战 传统存储系统在安全性、可扩展性、数据保护等方面存在局限性。 随着数据量的快速增长，单一存储系统难以满足需求。 数据中心需要应对物联网、交易数据、电子邮件、医疗数据等多种类型的数据。 二、Ceph分布式存储项目 Ceph是一个开源的分布式存储系统，具有高可靠性、可扩展性、高性能等特点。 Ceph项目由社区推动，吸引了众多贡献者。 Ceph项目经历了多个版本迭代，功能不断完善。 三、Ceph的优势 开源：不受商业利益驱动，更加透明和可信赖。 可扩展性：支持海量数据存储，可无缝扩展。 高可靠性：具备数据冗余、故障转移等功能，保证数据安全。 高性能：支持多种存储协议，满足不同应用场景的需求。 四、Ceph的挑战 技术复杂性：Ceph技术架构复杂，学习曲线较陡峭。 管理和维护：Ceph需要专业的技术支持，成本较高。 生态系统：Ceph生态系统相对较小，缺乏成熟的第三方工具。 五、Ceph的未来规划 国际化和本地化：支持更多语言，满足全球用户需求。 管理和监控：改进管理界面，提供更便捷的监控功能。 集成和兼容性：与其他存储系统、网络设备等实现集成。 安全性：加强安全性，抵御潜在的安全威胁。 六、行动计划 完善Ceph文档，降低学习门槛。 加强社区建设，吸引更多开发者参与。 推动Ceph生态系统的建设，提供更多第三方工具和解决方案。 与其他开源项目合作，共同推动开源存储技术的发展。 七、其他事项 Ceph社区将于3月22-23日在亚太地区举办Ceph Day活动。 Ceph项目将于11月在柏林举办Ceph Summit活动。 关键词： Ceph、分布式存储、开源、可扩展性、可靠性、国际化和本地化、生态系统","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - 10 ways to break your Ceph cluster","slug":"Ceph_Day_Germany_-_10_ways_to_break_your_Ceph_cluster","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_10_ways_to_break_your_Ceph_cluster/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_10_ways_to_break_your_Ceph_cluster/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储系统部署与维护经验分享 会议时间： 2023年（具体日期未提及） 参会人员： 未知 会议内容： 一、会议背景 主持人介绍了自己在存储领域，尤其是 Ceph 存储系统的经验，强调在部署和维护过程中需要注意的细节和常见问题。 二、讨论的主要议题 系统部署与维护经验： 强调在系统部署前进行充分的测试和验证，避免因配置错误导致系统故障。 提醒在系统运行过程中，要关注监控指标，及时发现并解决问题。 分享了多个实际案例，包括： 客户误操作导致系统崩溃，通过回滚操作恢复系统。 系统升级导致性能下降，通过优化配置解决。 磁盘故障导致数据丢失，通过备份数据恢复。 常见问题与解决方案： 系统崩溃：通过回滚操作、优化配置等方式解决。 性能下降：通过优化配置、增加资源等方式解决。 数据丢失：通过备份数据恢复。 权限问题：通过检查权限设置、修复权限问题等方式解决。 最佳实践： 在系统部署前进行充分的测试和验证。 关注监控指标，及时发现并解决问题。 定期备份数据。 使用可靠的存储介质。 三、决定的事项 无 四、后续行动计划 无 五、其他 主持人分享了多个 Ceph 存储系统的最佳实践，包括： 使用可靠的存储介质。 定期备份数据。 关注监控指标，及时发现并解决问题。 使用 Ceph 的功能特性，例如快照、克隆等。 关键词： Ceph、存储系统、部署、维护、监控、备份、故障、权限、性能、容量","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - Ceph Luminous is out what's in it for you","slug":"Ceph_Day_Germany_-_Ceph_Luminous_is_out_what_s_in_it_for_you","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_Ceph_Luminous_is_out_what_s_in_it_for_you/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_Ceph_Luminous_is_out_what_s_in_it_for_you/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： Ceph 分布式存储系统最新进展及未来规划 一、会议关键细节 Ceph 版本更新： 会议介绍了 Ceph 的版本更新情况，包括不同版本的特性、改进和问题。 术语解释： 对 Ceph 中的关键术语进行了解释，例如 Monitors、OSDs、MDSs 等。 性能优化： 讨论了 Ceph 在性能方面的优化，包括读写性能、副本机制、故障恢复等。 管理工具： 介绍了 Ceph 的管理工具，例如 Ceph Manager、Ceph Dashboard 等。 安全性： 讨论了 Ceph 的安全性改进，例如身份验证、访问控制等。 二、讨论的主要议题 Ceph 版本更新： 介绍了 Ceph 的新版本特性，例如支持新的存储设备、优化性能、增强安全性等。 讨论了不同版本之间的兼容性问题和升级策略。 性能优化： 分析了 Ceph 的性能瓶颈，并提出了相应的优化方案。 讨论了如何提高读写性能、副本机制效率和故障恢复速度。 管理工具： 介绍了 Ceph 的管理工具，并讨论了如何提高管理效率和用户体验。 安全性： 讨论了 Ceph 的安全性问题，并提出了相应的解决方案。 介绍了身份验证、访问控制等安全机制。 三、决定的事项 版本更新： 继续推进 Ceph 的版本更新，并确保版本之间的兼容性。 性能优化： 优化 Ceph 的性能，提高读写性能、副本机制效率和故障恢复速度。 管理工具： 改进 Ceph 的管理工具，提高管理效率和用户体验。 安全性： 加强 Ceph 的安全性，确保数据安全和系统稳定。 四、后续行动计划 版本更新： 制定详细的版本更新计划，包括时间表、任务分配和测试方案。 与社区合作，收集反馈意见，不断完善版本更新工作。 性能优化： 分析 Ceph 的性能瓶颈，制定相应的优化方案。 对优化方案进行测试和验证，确保其有效性。 管理工具： 改进 Ceph 的管理工具，提高管理效率和用户体验。 开发新的管理功能，满足用户需求。 安全性： 加强 Ceph 的安全性，确保数据安全和系统稳定。 定期进行安全评估和漏洞修复。 备注： 会议中提到了一些关键术语，例如 Monitors、OSDs、MDSs、Ceph Manager、Ceph Dashboard 等，请参考相关资料进行了解。 会议中提到的性能优化方案和安全性改进措施需要进一步研究和验证。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - Ceph Performance on New Intel Platforms and SSDs","slug":"Ceph_Day_Germany_-_Ceph_Performance_on_New_Intel_Platforms_and_SSDs","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_Ceph_Performance_on_New_Intel_Platforms_and_SSDs/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_Ceph_Performance_on_New_Intel_Platforms_and_SSDs/","excerpt":"","text":"会议纪要 会议主题：团队协作与目标设定 会议时间：2023年11月26日之后 会议地点：线上会议 参会人员：全体团队成员 会议关键细节： 团队协作的重要性：会议强调了互联网作为团队沟通的脉搏，对于团队成员来说至关重要。 目标设定与一致性：讨论了在网球比赛中，一致性如同成本，是衡量一年成绩的关键。团队的目标是确保成本可控，同时保持高效的服务。 服务与成本控制：提到其他服务器在成本控制方面做得很好，但需要进一步优化。 用户沟通系统：讨论了用户通信系统，包括互联网或其他方式，确保信息传达的准确性。 团队参与与挑战：提到今年团队在Volksoper和世界精英的挑战下，仍然保持积极的态度，并准备迎接挑战。 讨论的主要议题： 团队协作与沟通：如何通过互联网等工具更好地进行团队协作和沟通。 成本控制与效率提升：如何优化成本控制，提高工作效率。 用户服务与满意度：如何提升用户服务水平，满足用户需求。 决定的事项： 加强团队内部沟通，确保信息传达的准确性。 优化成本控制措施，提高资源利用率。 提升用户服务水平，提高用户满意度。 后续行动计划： 定期召开团队会议，讨论工作进展和问题。 制定详细的成本控制计划，并跟踪执行情况。 定期收集用户反馈，改进用户服务。 其他： 会议中提到了一些计算机科学/CEPH相关领域的英文关键词，如“consistent”、“Vienna energy”、“Hedge funds”等，但未进行详细讨论。 会议中穿插了一些音乐，营造了轻松愉快的氛围。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - Ceph at SAP: How to build a cattle cloud","slug":"Ceph_Day_Germany_-_Ceph_at_SAP_-_How_to_build_a_cattle_cloud","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_Ceph_at_SAP_-_How_to_build_a_cattle_cloud/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_Ceph_at_SAP_-_How_to_build_a_cattle_cloud/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储架构与优化 会议时间： [未提供] 参会人员： [未提供] 会议内容： 一、会议背景 本次会议主要讨论了Ceph分布式存储的架构、优化方案以及部署过程。会议重点分析了Ceph在保证数据安全、提升性能和简化管理方面的特点和优势。 二、Ceph架构与原理 架构概述： Ceph采用分散式存储架构，由多个存储节点组成，通过Paxos算法保证数据一致性。 数据保护： Ceph通过复制和校验机制保证数据安全，支持数据冗余和容错。 性能优化： Ceph通过优化数据访问路径、缓存机制和负载均衡等技术提升性能。 三、Ceph部署与优化 部署过程： 使用Saltstack进行自动化部署，简化部署流程。 通过MoM进行集群管理，实现集中式管理。 利用Ceph-deploy工具进行部署，支持多种部署模式。 性能优化： 优化数据访问路径，减少数据传输延迟。 使用缓存机制，提高数据访问速度。 负载均衡，均衡各节点负载。 安全性： 使用AES加密算法保证数据安全。 实施访问控制，防止未授权访问。 四、Ceph应用案例 Ceph在Harvard的部署： Harvard使用Ceph作为对象存储，存储大量数据，包括视频、音频和文档等。 Ceph的高可用性和可扩展性满足了Harvard的需求。 Ceph在Tech Park的部署： Tech Park使用Ceph作为分布式存储，存储大量数据，包括虚拟机镜像、数据库等。 Ceph的可靠性保证了Tech Park业务的稳定运行。 五、后续行动计划 继续优化Ceph性能，提升用户体验。 探索Ceph在其他领域的应用。 加强Ceph社区建设，促进技术交流。 六、关键词 分布式存储 Ceph Paxos算法 数据一致性 可扩展性 高可用性 Saltstack MoM Ceph-deploy AES加密 七、总结 本次会议深入讨论了Ceph分布式存储的架构、优化方案和部署过程。Ceph作为一种高性能、高可用、可扩展的分布式存储系统，在各个领域都得到了广泛应用。未来，Ceph将继续优化性能，拓展应用领域，为用户提供更加优质的服务。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - Ceph for Big Science","slug":"Ceph_Day_Germany_-_Ceph_for_Big_Science","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_Ceph_for_Big_Science/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_Ceph_for_Big_Science/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 与会人员： CERN存储团队，Ceph社区开发者 会议主题： CERN在Ceph存储上的使用经验及反馈 会议内容： 一、CERN存储架构概述 CERN位于瑞士日内瓦，拥有两个数据中心，分别位于瑞士和布达佩斯。 使用Ceph存储系统进行数据存储，包括文件存储、块存储和对象存储。 当前运行着两个生产集群，其中最大的集群容量为5.5PB，另一个数据中心容量为0.5PB。 还有一个测试集群和一个超融合集群。 二、Ceph存储应用案例 物理实验数据存储： 使用Ceph存储CMS、ALICE、ATLAS和LHCb等实验数据，每年存储约50PB数据。 物理分析： 使用Ceph存储分析批处理目标数据，并使用Ceph作为虚拟化NFS文件系统。 S3存储： 使用Ceph作为S3存储后端，提供S3服务。 HPC： 使用Ceph存储HPC模拟数据，并使用Ceph作为NFS文件系统。 三、Ceph存储使用经验及反馈 Ceph性能： Ceph在I/O吞吐量方面表现良好，但在元数据性能方面存在一些问题。 Ceph稳定性： Ceph在Luminous版本中表现出良好的稳定性，但需要进一步优化。 Ceph可扩展性： Ceph的可扩展性较好，但需要改进某些功能，例如替换OSD。 Ceph管理： Ceph的管理较为复杂，需要进一步简化。 Ceph工具： Ceph提供的工具需要改进，例如osdmap工具和scrub工具。 四、后续行动计划 与Ceph社区合作，改进Ceph的元数据性能和可扩展性。 开发Ceph管理工具，简化Ceph的管理。 开发Ceph存储的备份工具。 探索Ceph在更多场景下的应用。 五、会议总结 CERN在Ceph存储上的使用经验表明，Ceph是一个功能强大且可扩展的存储系统，但在某些方面仍需改进。CERN将与Ceph社区合作，共同推动Ceph的发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - Development update Ceph mgr and Kubernetes","slug":"Ceph_Day_Germany_-_Development_update_Ceph_mgr_and_Kubernetes","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_Development_update_Ceph_mgr_and_Kubernetes/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_Development_update_Ceph_mgr_and_Kubernetes/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储与容器编排的整合以及相关技术讨论 会议时间： [时间] 参会人员： [参会人员名单] 会议内容： 一、Ceph 存储与容器编排 Ceph 存储现状： 目前 Ceph 存储在容器编排方面存在一些挑战，如服务编排、包安装、集群管理等问题。 容器编排工具： Kubernetes： 作为容器编排的流行工具，Kubernetes 提供了远程执行集群任务的能力，并提供了额外的功能，如监控、资源管理和调度。 Ceph Container Orchestrator (CephCO)： CephCO 是一个专门用于 Ceph 存储的容器编排工具，旨在简化 Ceph 存储的部署和管理。 CephCO 的优势： 简化部署： CephCO 可以简化 Ceph 存储的部署和管理，降低运维成本。 提高效率： CephCO 可以自动执行一些重复性任务，提高运维效率。 灵活性： CephCO 支持多种部署模式，满足不同场景的需求。 二、CephCO 的应用 CephCO 与其他工具的集成： CephCO 可以与其他工具集成，如 Prometheus、Grafana、PrestoDB 等，实现更全面的监控和管理。 CephCO 与 Kubernetes 的集成： CephCO 可以与 Kubernetes 集成，实现 Ceph 存储的自动化部署和管理。 CephCO 的未来： CephCO 将继续发展，提供更多功能，如自动化升级、故障恢复等。 三、Brook 项目 Brook 简介： Brook 是一个用于简化容器存储的框架，可以将各种存储系统（如 Ceph、NFS、iSCSI 等）抽象为统一的接口。 Brook 的优势： 简化存储管理： Brook 可以简化存储管理，降低运维成本。 提高效率： Brook 可以自动执行一些存储操作，提高效率。 兼容性： Brook 支持多种存储系统，提高兼容性。 Brook 的挑战： Brook 的语法相对复杂，容易出错。 四、行动计划 CephCO 的开发： 继续开发 CephCO，提供更多功能，提高易用性。 Brook 的改进： 改进 Brook 的语法，降低使用难度。 CephCO 与其他工具的集成： 与其他工具（如 Prometheus、Grafana 等）集成，实现更全面的监控和管理。 CephCO 的推广： 推广 CephCO，让更多用户了解和使用。 五、会议总结 本次会议讨论了 Ceph 存储与容器编排的整合以及相关技术，明确了 CephCO 和 Brook 项目的优势和发展方向，并制定了相应的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - Everyone can Build and Maintain a Ceph Cluster with croit","slug":"Ceph_Day_Germany_-_Everyone_can_Build_and_Maintain_a_Ceph_Cluster_with_croit","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_Everyone_can_Build_and_Maintain_a_Ceph_Cluster_with_croit/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_Everyone_can_Build_and_Maintain_a_Ceph_Cluster_with_croit/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 参会人员： [参会人员名单] 会议主题： 分布式存储Ceph的管理解决方案及实施细节讨论 会议内容： 一、Ceph管理解决方案概述 解决方案特点： 该解决方案旨在提供全面的管理功能，覆盖部署的各个阶段，具有定制化和实践性。 公司背景： 大约一年前，一位前军事人员创立了一家新公司，该公司开发了基于Rust的Ceph管理工具。 客户案例： 自去年4月以来，公司已经与一位专业人士客户合作，并从那时起，客户数量稳步增长。 二、Ceph管理解决方案功能 交易管理： 该解决方案支持交易管理，交易成本相对较低，约90毫秒。 数据存储： 用户可以存储各种类型的数据，并保证数据的一致性和可靠性。 监控与统计： 提供丰富的监控和统计功能，包括性能监控、资源使用情况等。 安全性： 支持SSH密钥管理、权限控制等功能，确保数据安全。 三、实施细节 自定义配置： 用户可以根据需求进行自定义配置，例如网络设置、服务配置等。 自动化部署： 支持自动化部署，用户可以轻松创建和管理池和存储集群。 故障恢复： 提供故障恢复机制，确保数据安全。 性能优化： 通过优化配置和资源分配，提高系统性能。 四、讨论议题 性能优化： 如何进一步提高系统性能，减少延迟。 安全性： 如何加强安全性，防止数据泄露。 用户体验： 如何优化用户界面，提高用户体验。 五、决定事项 持续优化性能和安全性。 收集用户反馈，不断改进产品。 加强市场推广，扩大客户群体。 六、后续行动计划 研发团队： 优化代码，提高系统性能。 市场团队： 开展市场推广活动，吸引更多客户。 客户支持团队： 提供优质的客户服务，解决客户问题。 七、备注 会议中提到了一些计算机科学/ceph相关领域英文关键词，如transaction、data storage、monitoring、statistics、security等。 会议重点讨论了Ceph管理解决方案的功能、实施细节、性能优化和安全性等问题。 会议决定将持续优化产品，提高用户体验，扩大客户群体。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Germany - SSD only Performance with Ceph","slug":"Ceph_Day_Germany_-_SSD_only_Performance_with_Ceph","date":"2018-02-13T16:00:00.000Z","updated":"2018-02-14T16:00:00.000Z","comments":true,"path":"2018/02/14/Ceph_Day_Germany_-_SSD_only_Performance_with_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/14/Ceph_Day_Germany_-_SSD_only_Performance_with_Ceph/","excerpt":"","text":"会议纪要 会议主题： Ceph存储性能优化讨论及解决方案探讨 与会人员： 存储研发团队、字幕翻译及总结人员 会议关键细节： 会议主要讨论了Ceph存储在性能方面的优化问题，以及针对不同场景的解决方案。 研究了使用SSD作为存储介质对性能提升的影响，并分析了传统存储架构在性能上的局限性。 讨论了Ceph在多节点、高并发场景下的性能表现，并提出了相应的优化策略。 讨论的主要议题： SSD存储介质对性能的影响： 使用SSD作为存储介质可以显著提升Ceph存储的性能，但成本较高。 传统存储架构的局限性： 传统存储架构在性能上存在瓶颈，难以满足高并发、大规模存储的需求。 Ceph在多节点、高并发场景下的性能表现： Ceph在多节点、高并发场景下表现出色，但存在性能瓶颈。 优化策略： 通过优化Ceph配置、使用SSD存储介质、改进网络架构等方式提升性能。 决定的事项： 优化Ceph配置： 对Ceph配置进行优化，以提升性能。 使用SSD存储介质： 在适当场景下使用SSD存储介质，以提升性能。 改进网络架构： 改进网络架构，以降低网络延迟，提升性能。 测试不同解决方案： 对不同解决方案进行测试，以验证其有效性。 后续行动计划： 研究Ceph配置优化方案，并进行测试验证。 评估SSD存储介质的使用成本和性能提升效果。 改进网络架构，降低网络延迟。 对不同解决方案进行测试，并选择最优方案。 其他事项： 会议中提到了Ceph与其他存储解决方案的比较，以及Ceph在不同场景下的适用性。 会议还讨论了Ceph在数据安全、可靠性等方面的优势。 关键词： Ceph SSD 存储性能 多节点 高并发 优化 配置 网络 数据安全 可靠性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-FEB-01 :: Ceph Performance Weekly","slug":"2018-FEB-01_-_-_Ceph_Performance_Weekly","date":"2018-02-12T16:00:00.000Z","updated":"2018-02-13T16:00:00.000Z","comments":true,"path":"2018/02/13/2018-FEB-01_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/13/2018-FEB-01_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： [请填写会议日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储项目进展讨论 会议内容： 1. 核心请求更新 会议讨论了Ceph核心请求的最新进展，但没有提供最新的请求列表。 重点讨论了文件存储和对象存储的改进工作。 Sloth提交了一个大型的pull request，为Blue Store添加了同步读取支持，并对OSD进行了一些更改以使其工作，但考虑到复杂性，建议等待重构和清理后再进行合并。 2. OSD性能优化 讨论了OSD同步基础设施的性能问题，指出某些操作过于冗余，导致性能下降。 讨论了使用稀疏映射来提高性能的可能性，但需要进一步研究和测试。 讨论了将存储设备进行分片以提高性能的可能性，但需要考虑数据迁移和命名空间管理等问题。 3. 执行上下文分析 讨论了执行上下文在代码中的作用，并提出了创建调用图来分析执行上下文使用情况的想法。 讨论了使用性能分析工具来帮助识别性能瓶颈。 4. 其他议题 讨论了与Blue Store相关的性能问题，特别是视频流吞吐量过高的问题。 讨论了如何改进MBConfigT结构，使其支持原子读取。 讨论了如何改进字符串比较的性能。 后续行动计划： Sloth将继续优化Blue Store和OSD的性能。 讨论稀疏映射和存储设备分片的可能性。 进行执行上下文分析，并使用性能分析工具识别性能瓶颈。 研究改进MBConfigT结构和字符串比较性能的方法。 备注： 会议中提到了一些计算机科学/ceph相关领域英文关键词，如：pull request, file store, object store, OSD, synchronous infrastructure, sparse mapping, execute context, performance profiling, MBConfigT, string comparison等。 总结： 本次会议讨论了Ceph分布式存储项目的多个关键议题，并制定了后续行动计划。会议气氛积极，参会人员就各自负责的工作进行了深入的交流和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-FEB-07 :: Ceph Developer Monthly","slug":"2018-FEB-07_-_-_Ceph_Developer_Monthly","date":"2018-02-12T16:00:00.000Z","updated":"2018-02-12T16:00:00.000Z","comments":true,"path":"2018/02/13/2018-FEB-07_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/13/2018-FEB-07_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2018年2月某日 会议地点： 德国 参会人员： 自动化团队、Ceph社区成员 会议主题： Dashboard v2： 自动化团队正在开发Dashboard v2，目标是替代现有的Dashboard。 使用Angular 2作为前端框架，后端与现有Dashboard相似，使用CherryPy加载到Manager中。 目前已完成后端开发，正在开发前端页面，包括健康页面和其他页面。 计划在下周结束前提交可审查的代码。 未来将与其他功能集成，例如自动监控。 OpenStack Swift与Ceph的集成： 自动化团队正在开发OpenStack Swift与Ceph的集成。 使用Ansible进行部署，不使用SaltStack或其他工具。 计划集成自动监控功能，但需要手动设置图表和配置Dashboard。 Ceph Messenger v2： Messenger v2正在进行开发，包括身份验证和传输加密。 计划使用GSSAPI进行身份验证和加密，支持Kerberos和其他认证协议。 目前正在进行Kerberos的集成工作。 Ceph集群级别复制： 讨论了集群级别复制的架构和实现细节。 使用日志条目和操作缓存来管理复制操作。 引入了新的模块来处理复制工作。 讨论了复制暂停和恢复机制。 行动计划： 自动化团队继续开发Dashboard v2和OpenStack Swift与Ceph的集成。 Ceph社区成员继续讨论和改进集群级别复制的实现。 Messenger v2团队继续进行身份验证和加密的集成工作。 其他事项： 讨论了Ceph社区的最新动态和未来发展方向。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-FEB-08 :: Ceph Performance Weekly","slug":"2018-FEB-08_-_-_Ceph_Performance_Weekly","date":"2018-02-12T16:00:00.000Z","updated":"2018-02-13T16:00:00.000Z","comments":true,"path":"2018/02/13/2018-FEB-08_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/02/13/2018-FEB-08_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月某日 参会人员： 多位Ceph研发人员 会议主题： 讨论和审查Ceph项目的代码提交、性能优化以及相关技术问题。 关键细节： 代码审查： 讨论了多个代码提交，包括优化D级性能的PR（PR 2029），MD配置的Kasher，以及更改OathStreams的PR等。 对于MD配置的Kasher，讨论了使用静态声明的第二个补丁，并同意将静态声明改为更合适的方法。 对于更改OathStreams的PR，讨论了减少CPU使用率的优化，并建议进行更深入的分析。 讨论了indirection layers for a shorted op work queue的PR，并建议等待合并tiny vector PR后再进行合并。 讨论了EC后端使用本地读取路径的PR，以及延迟PG统计计算的PR。 性能优化： 讨论了配置值观察者的优化，建议使用更高效的方法来更新观察者。 讨论了get_val函数的性能优化，建议避免不必要的键规范化。 讨论了reactor的性能优化，建议减少任务的大小以适应微架构缓存。 其他： 讨论了使用reactor进行任务分组的可能性。 讨论了micro-op流水线的性能优化。 决定的事项： 对多个代码提交进行审查和合并。 对性能优化方案进行进一步的分析和测试。 考虑使用reactor进行任务分组。 后续行动计划： 继续审查和合并代码提交。 进行性能优化方案的测试和评估。 考虑使用reactor进行任务分组。 计算机科学/ceph相关领域英文原文关键词： pull request D out pass MD config OathStreams indirection layers EC back-end PG stats calculations config value observer get_val reactor micro-op task grouping","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-JAN-18 :: Ceph Performance Weekly","slug":"2018-JAN-18_-_-_Ceph_Performance_Weekly","date":"2018-01-19T16:00:00.000Z","updated":"2018-01-19T16:00:00.000Z","comments":true,"path":"2018/01/20/2018-JAN-18_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/01/20/2018-JAN-18_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Ron, Adam, Jason, Igor, Josh, Greg, Mark, Chimay, Stephanie, Avi, Georgia, 以及其他相关人员 会议主题： Ceph 存储系统最新进展 VPP 集成方案探讨 性能优化策略讨论 Specter 漏洞影响评估 会议内容： 1. Ceph 存储系统最新进展 代码合并与优化： Jason 审核并合并了 Igor 的几个小优化，包括近似眼睛（aprox eyes）功能。 Jason 还将一个 pull request 合并，该 pull request 通过优化读取操作来提高性能。 Ron 正在考虑完全消除对象存储接口中的 applied 回调，并使用跟踪和快速操作。 Ron 还关闭了旧的同步请求，因为他已经完成了读操作的一半工作，但不确定是否要继续进行写操作。 性能优化： Ron 正在考虑使用构建购买概念来测试性能影响。 Josh 提交了一个 pull request，用于将随机拆分阈值随机化，以提高 Jewel 版本的性能。 Ron 提到了一个 QAT 等级类，但不确定其最新更新。 2. VPP 集成方案探讨 VPP 简介： Stephanie 介绍了 VPP（虚拟包处理）软件栈，该软件栈提供了一种高效的网络处理方式。 VPP 支持多种接口，包括 VPP 通信库、TCL API 和 DPDK 内存接口。 Stephanie 使用了预加载模式，即 VPP 库钩子到 POSIX 套接字层，从而在用户空间中处理网络操作。 集成方案讨论： Ron 认为直接使用 VPP API 可能更合适，因为它可以提供更好的性能和异步操作。 讨论了 VPP 与 CStar 网络编程框架的兼容性，以及如何使用 CStar API 与 VPP 通信。 *讨论了将 VPP 作为 RGW 插件的可能性。 3. 性能优化策略讨论 Boost 优化： Mark 总结了 Boost 优化方案的测试结果，发现一些优化方案对性能提升有限，例如批处理事务和跳表。 Ron 认为使用多个提示符（hints）的 RocksDB 内部功能可能有助于提高性能，但需要进一步测试。 Specter 漏洞影响评估： Ron 认为 Specter 漏洞可能会对 Intel 处理器的性能产生严重影响，尤其是在进行大量 CPU 密集型操作时。 Red Hat 性能团队正在研究 Specter 漏洞的解决方案。 4. 其他讨论 Wall Clock Profiler： Adam 介绍了 Wall Clock Profiler 工具，该工具可以模拟 Marc 的 Wall Clock Profiler 的行为，并提供更快的采样率。 Adam 还表示，他愿意将 Wall Clock Profiler 集成到 CBT 中，以便在测试过程中进行性能分析。 New Store 与 Blue Store 比较： Ron 回顾了 New Store 和 Blue Store 的性能比较，发现 Blue Store 在大写和随机写操作方面表现更好。 Ron 认为读取预取在 Blue Store 中非常重要。 EC Bug Regression： Ron 讨论了对象存储层中未读回调的问题，并提出了一种简化代码的方案。 行动计划： VPP 集成： 与 Avi 和 Georgia 讨论将 VPP 集成到 Ceph 的可能性。 对 VPP 进行性能测试，并评估其与 CStar 的兼容性。 性能优化： 进一步测试 RocksDB 内部功能，并评估其对性能的影响。 研究 Specter 漏洞的解决方案，并评估其对 Ceph 性能的影响。 代码简化： 简化对象存储接口，以消除未读回调和锁。 将 Wall Clock Profiler 集成到 CBT 中。 总结： 本次会议讨论了 Ceph 存储系统的最新进展、VPP 集成方案、性能优化策略和 Specter 漏洞影响评估。会议确定了行动计划，并推动了 Ceph 存储系统的进一步发展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-JAN-11 :: Ceph Performance Weekly","slug":"2018-JAN-11_-_-_Ceph_Performance_Weekly","date":"2018-01-11T16:00:00.000Z","updated":"2018-01-11T16:00:00.000Z","comments":true,"path":"2018/01/12/2018-JAN-11_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/01/12/2018-JAN-11_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： Josh、David、Peter、Igor、Nick、Mark、Matt、Adam等 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 1. Pull Request进展： Josh正在回补文件存储的随机分割阈值随机化功能。 David的简化字符工作已完成，所有数据结构将移入一个大类，最终可能使用全局锁。 Peter的CRC缓存更改已提交。 David的简化工作已完成，将数据结构移动到一个大类别中。 Igor的容器清理工作正在测试分支中测试。 已撤销aproxice功能，因为它与标准列表大小调用冲突。 eager的pull request已准备好合并到luminous，修复了amenity溢出问题。 2. 新功能进展： 第二轮qit加速已添加对Intel处理器加速压缩的支持，但需要解决一些问题。 Nick正在讨论加密加速问题。 Igor的容器清理工作已合并，并在测试分支中测试。 3. 问题讨论： Josh提出了关于BlueStore异步读取的优化问题。 讨论了共享独占锁定PG的问题，以及它对读性能的影响。 讨论了PG日志问题，包括日志大小、存储和性能影响。 讨论了使用不同的键值存储引擎来改进BlueStore的潜力。 4. 行动计划： Josh将继续优化BlueStore的异步读取功能。 Nick将研究加密加速问题。 Igor将解决qit加速问题。 Adam将研究RocksDB的批处理I/O完成工作，并将其合并到主分支中。 Nick将研究RocksDB的Fsync问题。 5. 其他事项： 讨论了SSL漏洞的影响，以及如何进行性能测试。 讨论了AIoT读取性能问题。 会议总结： 本次会议讨论了Ceph分布式存储项目的多个方面，包括Pull Request进展、新功能进展、问题讨论和行动计划。会议还讨论了一些与性能和安全相关的问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-JAN-04 :: Ceph Performance Weekly","slug":"2018-JAN-04_-_-_Ceph_Performance_Weekly","date":"2018-01-10T16:00:00.000Z","updated":"2018-01-11T16:00:00.000Z","comments":true,"path":"2018/01/11/2018-JAN-04_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/01/11/2018-JAN-04_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 新年后的首次会议 参会人员： 多位研发人员 会议内容： 一、关键细节 会议开始，大家相互问候，并庆祝新年。 会议主要讨论了Ceph项目的多个pull request，包括新增的QAT支持、Blue Store的异步读取优化、CRC缓存补丁等。 会议还讨论了Ceph的性能优化，特别是针对随机读写操作的性能回归问题。 会议最后讨论了Ceph的存储后端接口（OST）的异步化改造。 二、讨论的主要议题 QAT支持补丁： 补丁已提交，正在审查中。 Blue Store异步读取： 补丁已提交，但存在性能回归问题，需要进一步调查。 需要考虑在特定情况下使用传统的同步方式，以避免性能问题。 CRC缓存补丁： 补丁简单且有效，已标记为QA测试。 性能优化： 针对随机读写操作的性能回归问题，需要进一步调查原因。 需要关注缓存对性能的影响。 OST异步化： 讨论了如何将OST接口异步化，以及如何处理事务和同步操作。 需要进一步研究并确定最佳方案。 三、决定的事项 继续调查Blue Store异步读取的性能回归问题。 对CRC缓存补丁进行QA测试。 进一步研究OST异步化方案。 四、后续行动计划 相关研发人员将继续调查Blue Store异步读取的性能回归问题，并找出解决方案。 QA团队将对CRC缓存补丁进行测试。 相关人员将继续研究OST异步化方案，并制定详细的实施计划。 五、计算机科学/ceph相关领域英文原文关键词 QAT (Quick Assist Technology) Blue Store async read CRC cache performance regression object store (OST) transaction API unification","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2018-JAN-03 :: Ceph Developer Monthly","slug":"2018-JAN-03_-_-_Ceph_Developer_Monthly","date":"2018-01-03T16:00:00.000Z","updated":"2018-01-03T16:00:00.000Z","comments":true,"path":"2018/01/04/2018-JAN-03_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2018/01/04/2018-JAN-03_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2018年1月（具体日期未提及） 会议地点： CPM（可能为Ceph社区项目会议） 参会人员： Sage、Quentin、Jason、Dan、Mark、Kenda等 会议主题： Ceph配置管理系统（mod）更新 Kubernetes集群部署Ceph（Rook项目） Easy Clones功能改进 Ceph OSD性能优化 Ceph存储后端（C Store）开发 OpenStack测试平台（Technology）使用 会议内容： 1. Ceph配置管理系统（mod）更新 mod配置管理功能已基本完成，包括配置存储、解析、验证和展示等。 配置管理功能支持通过命令行、配置文件和监控器等多种方式获取配置。 配置管理功能支持验证配置选项，并提供详细的错误信息。 配置管理功能支持展示运行中的配置与监控器配置的差异。 配置管理功能支持通过监控器获取监控器配置，但当前未进行身份验证。 2. Kubernetes集群部署Ceph（Rook项目） Rook项目已成为Ceph在Kubernetes集群中部署的首选工具。 Rook项目支持创建自定义控制器，以满足Ceph特定的需求。 Rook项目支持自动化集群部署、升级和运维等操作。 Rook项目预计将与Ceph Mimic版本同步发布。 3. Easy Clones功能改进 Easy Clones功能旨在简化RBD克隆和快照操作。 Easy Clones功能支持通过OSD能力（caps）控制克隆和快照操作。 Easy Clones功能支持将快照移动到“已删除但仍有引用”的命名空间，以防止误删除。 4. Ceph OSD性能优化 Ceph OSD性能优化项目旨在提高Ceph在高速存储设备上的性能。 优化方案包括： 使用C Star框架重构OSD。 使用异步框架改进OSD性能。 开发针对高速存储设备的新的对象存储后端。 5. Ceph存储后端（C Store）开发 C Store项目旨在开发一种新的存储后端，以支持高速存储设备。 C Store项目将使用Seastar框架，并可能使用SPDK库。 C Store项目将提供日志结构化的存储格式，以提高性能。 6. OpenStack测试平台（Technology）使用 Technology平台可以用于测试OpenStack与Ceph的集成。 Technology平台支持在OVH云环境中运行OpenStack测试。 Technology平台可以用于验证Ceph功能，并确保其兼容性。 后续行动计划： 完成配置管理功能的身份验证功能。 完成Rook项目的开发工作，并确保其与Ceph Mimic版本同步发布。 完成Easy Clones功能的开发工作。 完成Ceph OSD性能优化项目的开发工作。 开发Ceph存储后端（C Store）。 探索使用Technology平台进行Ceph测试。 其他事项： 会议中讨论了Ceph配置选项的敏感性、Ceph存储后端缓存策略等问题。 会议中讨论了Ceph存储后端（C Store）的命名问题，建议使用“C Store”或“C18 Store”。 总结： 本次会议讨论了Ceph社区的多个重要项目，并确定了后续行动计划。Ceph社区将继续努力改进Ceph的性能和功能，以满足用户的需求。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-DEC-06 :: Ceph Developer Monthly","slug":"2017-DEC-06_-_-_Ceph_Developer_Monthly","date":"2017-12-18T16:00:00.000Z","updated":"2017-12-19T16:00:00.000Z","comments":true,"path":"2017/12/19/2017-DEC-06_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/12/19/2017-DEC-06_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年11月（具体日期未提及） 参会人员： Josh、Greg、Leo、Eric、Derek、Casey、Adam 等 会议主题： Ceph 项目进展及未来规划 会议内容： 一、Ceph 路线图概述 存储技术发展趋势： 硬盘容量增加，NVMe 成为主流，闪存部署增加，未来将全面转向闪存。 性能重构： 为了充分利用 NVMe 等高性能设备，需要进行性能重构，主要方向包括： 采用 DPDK 和 SPDK 进行网络和存储 IO。 对 OSD 进行大量重构，使其更加模块化、异步和事件驱动。 探索使用未来编程框架，以简化代码并提高可维护性。 代码轻量化： 减少数据结构和数据复制，避免不必要的内存分配，提高 CPU 利用率。 撕裂 (Tearing)： 讨论了撕裂技术的改进方案，包括： 用更传统的撕裂模型替换现有的缓存撕裂模型。 使用完整的索引和基础层，简化代码并提高灵活性。 不同类型的存储池： 探索实现不同类型的存储池，例如： 非复制池，直接写入 SBDK。 并行写入多个副本的池，具有不同的一致性和容错模型。 适用于 fabrics 的池，直接在 fabrics 上写入所有副本。 二、其他议题 消息传递协议： 讨论了改进消息传递协议，以提高效率和性能。 CephOSD 重构： 探索使用 C++ 协程或其他异步编程框架重构 CephOSD。 PT 合并： 讨论了解决 PT 合并问题的方案，包括： 使 PT 在合并前靠近彼此。 对齐 PT 日志，以便进行合并。 确保合并过程的可逆性。 三、行动计划 继续探索 DPDK、SPDK、未来编程框架等技术的应用。 对 CephOSD 进行重构，以提高性能和可维护性。 实现不同类型的存储池。 改进撕裂技术和 PT 合并。 探索使用 C++ 协程或其他异步编程框架重构 CephOSD。 定期讨论 CephOSD 重构和 PT 合并问题。 四、其他 提到了 Red Hat 正在进行的 Ceph 仪表板开发项目。 提到了 Ceph 对象存储网关 (RGW) 的云同步功能。 总结： 本次会议讨论了 Ceph 项目的多个重要议题，包括性能重构、撕裂技术改进、不同类型的存储池等。会议明确了后续行动计划，并鼓励大家积极参与相关开发工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-NOV-01 :: Ceph Developer Monthly","slug":"2017-NOV-01_-_-_Ceph_Developer_Monthly","date":"2017-12-17T16:00:00.000Z","updated":"2017-12-18T16:00:00.000Z","comments":true,"path":"2017/12/18/2017-NOV-01_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/12/18/2017-NOV-01_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： CEM开发者月度会议 参会人员： Greg, Josh, Sage, Mark, Adam, Casey 等 会议主题： Ceph PG 日志问题： 讨论了在 Ceph 中使用 SSD 时，PG 日志导致的性能问题，并提出了改进方案。 快照修剪问题： 分析了快照修剪过程中存在的问题，并提出了改进方案。 C++17 async 库的使用： 讨论了在 Ceph 中使用 C++17 async 库进行代码重构的可能性。 关键细节： 1. Ceph PG 日志问题 问题： 在使用 SSD 时，PG 日志导致的性能问题，主要体现在写放大、CPU 和内存开销等方面。 改进方案： 将 PG 日志存储在一个环形缓冲区中，以减少写放大和 CPU 开销。 使用 FIFO 压缩模式，以简化数据结构并提高效率。 将 PG 日志与 Ceph 的其他内部元数据分开存储，以减少内存占用。 2. 快照修剪问题 问题： 快照修剪过程中存在效率低下、数据结构复杂等问题。 改进方案： 使用增量数据结构，以减少 CPU 开销。 优化快照修剪算法，以提高效率。 将快照修剪与缓存淘汰分开处理。 3. C++17 async 库的使用 目的： 使用 C++17 async 库进行代码重构，以提高代码的可读性和可维护性。 方案： 将 Ceph 的部分代码从阻塞模式改为异步模式。 使用 C++17 async 库提供的功能，简化代码结构。 决定的事项： 将 PG 日志存储在一个环形缓冲区中，并使用 FIFO 压缩模式。 优化快照修剪算法，并使用增量数据结构。 开始使用 C++17 async 库进行代码重构。 后续行动计划： 完成环形缓冲区和 FIFO 压缩模式的实现。 优化快照修剪算法，并使用增量数据结构。 完成代码重构，并评估其效果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Promo Video 2017","slug":"Ceph_Promo_Video_2017","date":"2017-11-05T16:00:00.000Z","updated":"2017-11-06T16:00:00.000Z","comments":true,"path":"2017/11/06/Ceph_Promo_Video_2017/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/11/06/Ceph_Promo_Video_2017/","excerpt":"","text":"会议纪要 会议主题： SEF 存储解决方案介绍及未来存储技术探讨 关键细节： SEF 简介： SEF 是一种高效的存储解决方案，能够以极低的成本提供强大的存储功能。它基于 Ceph 技术，提供对象存储、块存储和分布式文件系统等多种存储服务。 SEF 工作原理： 对象存储： SEF 的最低级别是对象存储，使用 Rados 技术实现可靠的、自管理的分布式对象存储。Rados 负责将数据安全地分布式和复制到多个服务器或机架，并在集群变化时进行数据迁移。 OSD： 数据存储在 OSD（对象存储守护进程）上，每个 OSD 都是一个运行在物理硬盘或 SSD 上的软件进程，负责处理读写请求并与其他 OSD 进行数据复制、迁移和校验。 Monitor： Monitor（监控器）是集群的“空中交通控制器”，负责协调 OSD 的操作，确保数据的一致性和可靠性。 Ceph Manager： Ceph Manager 是一个相对较新的组件，负责处理分析 API 和管理功能，使 Monitor 能够专注于关键集群状态，并支持极大规模的集群。 SEF 接口： Rados Gateway： Rados Gateway 是一个对象存储接口，支持类似于 Amazon S3 或 OpenStack Swift 的功能，提供大规模横向扩展、基于访问控制列表的认证和跨数据中心、地理位置的集群联合。 Rados Block Device (RBD)： RBD 是一种精简配置的块设备，允许用户将设备挂载为存储，类似于使用物理硬盘。RBD 支持快照和数据复制，并提供高性能、可靠性和持久性。 SEF File System (SFS)： SFS 是一个 POSIX 兼容的分布式文件系统，允许用户使用分层文件和目录与 Ceph 对象存储进行交互。 librados 库： SEF 使用 librados 库实现接口与集群的通信，用户可以使用此库构建自定义接口。 讨论的主要议题： SEF 的功能和优势 SEF 的工作原理和架构 SEF 的接口和应用场景 SEF 在不同领域的应用案例 决定的事项： 推广 SEF 存储解决方案 加强 SEF 技术研发 拓展 SEF 应用场景 后续行动计划： 加强 SEF 技术培训 搭建 SEF 示例项目 与更多合作伙伴合作推广 SEF 总结： SEF 是一种高效、可靠、可扩展的存储解决方案，能够满足不同场景下的存储需求。随着技术的不断发展，SEF 将在更多领域发挥重要作用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-SEP-06 :: Ceph Developer Monthly","slug":"2017-SEP-06_-_-_Ceph_Developer_Monthly","date":"2017-09-11T16:00:00.000Z","updated":"2017-09-11T16:00:00.000Z","comments":true,"path":"2017/09/12/2017-SEP-06_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/09/12/2017-SEP-06_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议主题： SAP 开发者月度会议 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知 会议内容： 一、Ceph 存储集群优化 跨数据中心复制： 讨论了实现跨数据中心复制时维护全局顺序的挑战。 提出了使用时间切片和定时器来同步客户端操作的机制。 讨论了如何确保在 OSD 故障时复制的一致性。 讨论了如何处理客户端操作的复制问题。 保证复制正确性： 讨论了在发生 OSD 故障时保证复制正确性的方法。 提出了使用原始操作日志和快照来保证对象正确性的方法。 讨论了在恢复和回填阶段如何保证复制正确性。 共享 RBD 客户端缓存： 讨论了共享 RBD 客户端缓存的设计。 提出了使用共享内存和 IPC 机制来实现缓存共享。 讨论了如何处理 VM 迁移和 VM 故障。 讨论了如何处理文件系统或 SSD 错误。 统一 PG 日志修剪： 讨论了优化 PG 日志管理的方法。 提出了使用时间戳和全局 LRU 来修剪 PG 日志。 讨论了如何处理 PG 日志的并发访问和合并。 去重： 讨论了在 Ceph 存储集群中实现数据去重的方法。 提出了使用对象映射和内容地址存储池来实现去重。 讨论了如何处理去重过程中的并发访问和失败。 删除快照： 讨论了优化删除快照性能的方法。 提出了从 OSD 映射中移除已删除快照的方法。 讨论了如何处理请求中包含已删除快照的情况。 二、其他议题 统一 QoS： 讨论了在 Ceph 存储集群中实现统一 QoS 的方法。 提出了使用 QoS 策略和 QoS 表来实现 QoS 控制。 讨论了如何处理 QoS 策略的动态更新和同步。 M Clock： 讨论了优化 M Clock 性能的方法。 提出了使用分片和线程池来提高 M Clock 性能。 讨论了如何处理 M Clock 中的重量控制和数据行插入。 三、行动计划 继续优化跨数据中心复制和保证复制正确性的方法。 实现共享 RBD 客户端缓存和统一 PG 日志修剪。 推进去重和删除快照的功能。 实现统一 QoS 和 M Clock 优化。 四、总结 本次会议讨论了 Ceph 存储集群的多个优化方案，并制定了后续行动计划。这些优化方案将有助于提高 Ceph 存储集群的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-AUG-02 :: Ceph Developer Monthly","slug":"2017-AUG-02_-_-_Ceph_Developer_Monthly","date":"2017-08-28T16:00:00.000Z","updated":"2017-08-28T16:00:00.000Z","comments":true,"path":"2017/08/29/2017-AUG-02_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/08/29/2017-AUG-02_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年8月（具体日期未提及） 会议地点： SAP开发者月度会议 参会人员： Leonardo Vas（Leo，SAP社区经理）、John、Pam、Celia、Ricardo、Jason、Matt、Holden、SiO、Char、Mina、John、Yarn、Chanyeol等 会议主题： Ceph Luminous版本发布准备情况 Ceph功能更新与改进 Ceph性能优化 Ceph与其他技术的集成 会议内容： 一、Ceph Luminous版本发布准备情况 Leo表示，Ceph Luminous版本即将发布，目前正在进行最后的bug修复工作。 Josh和Leo在早上发现了一个bug，但已经修复了一半，预计下周可以发布。 二、Ceph功能更新与改进 Web仪表板： John介绍了Ceph的新Web仪表板，它提供了一个简单直观的界面，用于监控和管理Ceph集群。 服务映射： John介绍了Ceph的新服务映射功能，它允许用户从命令行或模块中访问服务信息。 应用程序标签： John介绍了Ceph的新应用程序标签功能，它允许用户将标签应用于存储池，以便更好地管理存储资源。 日志改进： John介绍了Ceph的日志改进，包括新的日志消息和JSON格式。 状态模块： John介绍了Ceph的新状态模块，它提供了一个友好的界面，用于查看Ceph集群的状态。 配置选项： John介绍了Ceph的配置选项改进，包括新的帮助命令和diff命令。 平衡器模块： John介绍了Ceph的新平衡器模块，它允许用户轻松地进行数据平衡操作。 自动调整P基因组： John和Ricardo讨论了自动调整P基因组的功能，以便用户无需手动管理P基因组。 速率限制： Roland介绍了Ceph的速率限制功能，它允许用户限制特定账户的I/O操作。 快速失败请求： Roland介绍了Ceph的快速失败请求功能，它可以在OSError或高延迟时快速失败请求。 跨集群复制： Ricardo介绍了Ceph的跨集群复制功能，它允许用户在不同集群之间复制数据。 共享读取缓存： Char介绍了Ceph的共享读取缓存功能，它允许用户缓存读取数据，以提高性能。 阵列代码： Mina介绍了Ceph的阵列代码改进，包括添加新的子块功能。 Prometheus： John和Yarn讨论了Ceph与Prometheus的集成，包括如何将Ceph指标暴露给Prometheus。 三、行动计划 Leo将继续进行Ceph Luminous版本的bug修复工作。 John将继续开发Ceph的新功能。 Roland将继续改进Ceph的速率限制功能。 Ricardo将继续改进Ceph的跨集群复制功能。 Char将继续开发Ceph的共享读取缓存功能。 Mina将继续改进Ceph的阵列代码。 John和Yarn将继续改进Ceph与Prometheus的集成。 四、会议总结 本次会议讨论了Ceph Luminous版本发布准备情况以及Ceph功能更新与改进。会议气氛热烈，参会人员积极讨论，为Ceph的发展做出了贡献。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-JUN-07 :: Ceph Developer Monthly","slug":"2017-JUN-07_-_-_Ceph_Developer_Monthly","date":"2017-06-21T16:00:00.000Z","updated":"2017-06-21T16:00:00.000Z","comments":true,"path":"2017/06/22/2017-JUN-07_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/06/22/2017-JUN-07_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年6月（具体日期未提及） 会议主题： Ceph开发者月度会议 参会人员： Ceph社区开发者 会议内容： 一、RBD持久缓存更新 现阶段PR基于Jason的草图，包含基于文件的缓存框架，通过boss进行缓存逻辑处理。 缓存逻辑包括：日志存储、缓存事件存储和元存储。 当前性能表现不佳，IOPS下降。 下一步计划： 优化缓存策略，例如使用更智能的刷新策略。 支持unicast和scatter-gather功能。 学习更多内存缓存模块。 二、存储池标签元数据 目的：提高存储池可识别性和易用性。 方案：为存储池添加标签功能，将元数据与存储池关联。 讨论点： 是否使用“应用”标签，还是使用更通用的元数据映射。 是否强制要求标签，还是提供健康警告。 如何处理兼容性问题。 结论： 添加“应用”标签和元数据映射，但不强制要求。 提供健康警告，提示未标记的存储池。 使用升级路径处理兼容性问题。 三、系统D改进 目的：简化集群部署和配置。 问题：系统D对自定义集群名称的支持不完整，且存在兼容性问题。 讨论点： 是否移除系统D对自定义集群名称的支持。 如何处理兼容性问题。 结论： 移除系统D对自定义集群名称的支持。 使用升级路径处理兼容性问题。 四、集群默认工具 问题：集群创建时默认安装的工具过多，且部分工具未启用SSO。 讨论点： 是否移除默认安装的工具。 如何处理SSO问题。 结论： 移除默认安装的工具。 对SSO进行改进。 五、SethOSD部署工具 目的：简化OSD部署和配置。 问题：SethOSD部署工具过于复杂，且对LVM支持不完整。 讨论点： 是否使用LVM作为部署工具。 如何简化部署流程。 结论： 使用LVM作为部署工具。 简化部署流程，例如使用标签识别设备。 六、BlueStore元数据 问题：BlueStore元数据过多，导致性能下降。 讨论点： 是否使用LMDB作为元数据存储后端。 如何优化元数据存储。 结论： 尝试使用LMDB作为元数据存储后端。 继续研究优化元数据存储的方法。 后续行动计划： 完成RBD持久缓存优化。 实现存储池标签功能。 移除系统D对自定义集群名称的支持。 简化SethOSD部署工具。 尝试使用LMDB作为元数据存储后端。 总结： 本次会议讨论了多个Ceph相关议题，包括RBD持久缓存、存储池标签、系统D、SethOSD和BlueStore元数据等。会议达成了多项共识，并制定了后续行动计划，以进一步改进Ceph的性能和易用性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-JUN-01 :: Ceph Performance Weekly","slug":"2017-JUN-01_-_-_Ceph_Performance_Weekly","date":"2017-06-20T16:00:00.000Z","updated":"2017-06-21T16:00:00.000Z","comments":true,"path":"2017/06/21/2017-JUN-01_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/06/21/2017-JUN-01_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 未知（会议记录中未提及具体人员姓名） 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、Ceph项目进展 Polar Quest： 将trim操作移动到mem thread线程，以提高内存使用效率。 内存优化： 通过优化inline memory功能，提高内存使用效率。 缓存管理： 新增5个缓存池，用于BlueStore，提高数据可见性和跟踪。 B-Tree优化： 使用B-Tree替代STL map，提高PG temp mapping效率。 BlueStore限流优化： 通过消除无用计算和清理代码，提高BlueStore性能。 内存复用： 通过rocksdb glue API，实现内存复用，提高性能。 同步提交： 实现同步提交功能，提高事务提交效率。 二、讨论议题 新存储引擎： 随着元数据增长，BlueStore性能出现瓶颈。讨论了通过增加缓存大小、优化内存管理等方案来提高性能。 SSD选择： 讨论了SSD选择和性能问题，以及如何应对SSD寿命和性能之间的权衡。 数据丢失问题： 讨论了RBD数据丢失问题，以及如何通过优化复制机制和更新语义来提高数据可靠性。 RocksDB后端： 讨论了使用RocksDB作为后端存储的可行性，以及如何简化更新语义和复制逻辑。 三、决定事项 继续优化BlueStore性能，包括增加缓存大小、优化内存管理等。 考虑使用RocksDB作为后端存储，简化更新语义和复制逻辑。 提交相关PR，并进行测试验证。 四、后续行动计划 继续关注BlueStore性能问题，并进行相关优化。 研究RocksDB后端存储的可行性，并提交相关PR。 跟踪RBD数据丢失问题的修复进度。 五、其他事项 讨论了PVC构建问题，以及如何解决PowerPC优化和编译问题。 讨论了RTC分支和同步提交功能，以及其适用场景。 总结： 本次会议主要讨论了Ceph分布式存储项目的进展和未来发展方向。会议确定了优化BlueStore性能、简化更新语义和复制逻辑等关键任务，并制定了相应的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-JUN-08 :: Ceph Performance Weekly","slug":"2017-JUN-08_-_-_Ceph_Performance_Weekly","date":"2017-06-20T16:00:00.000Z","updated":"2017-06-21T16:00:00.000Z","comments":true,"path":"2017/06/21/2017-JUN-08_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/06/21/2017-JUN-08_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： Ceph分布式存储项目讨论 参会人员： Sage, Greg, Josh, James, Peter, Mohammad 等 会议内容： 一、CDM会议回顾 昨天的CDM会议讨论了多个可用性操作（usability op）问题，包括缓存、日志、扩展器重硬等问题。 已合并的请求包括：scrub作业优先级调整、日志条目、扩展器重硬避免重叠、动态重硬、空批次事务提交、统计信息、unshare blob等。 性能方面，luminous版本性能表现良好，parpc fast zero功能听起来很有潜力，但需要进一步优化。 二、监控器日志 新增一个监控器命令，用于显示集群日志中最新的日志条目，并防止重复条目。 已合并相关代码。 三、元数据缓存 当前元数据缓存配置为1GB，建议根据硬件配置进行调整。 讨论了提高元数据缓存大小对性能的影响，并考虑了Blue Store Cache和RocksDB Cache的配置。 建议在Luminous版本之后重新审视12062号PR，该PR基于void bags工作，用于处理NVMe等存储设备上的同步提交。 四、PG日志 讨论了PG日志长度对性能和恢复时间的影响。 建议将PG日志长度配置为内存占用量，而不是固定长度。 讨论了从PG日志中借用内存给Blue Store的可能性。 五、Blue Store和RocksDB缓存 调查了Blue Store和RocksDB缓存之间的交互，并考虑了压缩和未压缩缓存的影响。 建议测试不同缓存配置对性能的影响。 六、白名单回退设置 讨论了白名单回退设置对性能的影响，并考虑了硬盘和SSD的设置。 建议根据硬盘和SSD的性能差异进行调整。 七、其他 讨论了lmdb和buffer list的优化。 讨论了使用SDVector替换SDList的可能性。 行动计划： Sage将测试不同缓存配置对性能的影响。 Josh将调查从PG日志中借用内存给Blue Store的可能性。 Peter将审查parpc fast zero功能。 James将调查白名单回退设置对性能的影响。 Mohammad将进行buffer list的基准测试。 后续会议： 将在下周进行后续会议，继续讨论以上议题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-JUN-15 :: Ceph Performance Weekly","slug":"2017-JUN-15_-_-_Ceph_Performance_Weekly","date":"2017-06-20T16:00:00.000Z","updated":"2017-06-21T16:00:00.000Z","comments":true,"path":"2017/06/21/2017-JUN-15_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/06/21/2017-JUN-15_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年6月15日 会议主题： Ceph分布式存储项目进展及讨论 参会人员： 研发人员、项目经理、测试人员 会议内容： 一、Ceph项目进展 新功能与优化： 合并了降低AC传输成本的代码，并进行了测试。 优化了BBQ流程。 正在测试中，合并了处理高优先级任务的代码，但仍在等待关于“点亮”提交的共识。 开放了一个新的PR，修改了文件存储中回调函数的顺序，但之前决定不修改。 讨论了调整缓存大小的代码，允许通过整体蓝鲸或铸币大小来配置Rocks缓存大小。 讨论了提升缓存大小的内存使用，计划将其提升至3-4GB。 性能优化： 正在测试中，发现了一个与Rocks存储层相关的bug，需要进一步分析。 讨论了在Rocks缓存中存储已编码数据的性能影响，以及是否需要进一步的压缩。 讨论了是否可以通过优化编码速度来提高性能。 其他： 介绍了OmniDB项目，正在尝试恢复LDPR（Log-Driven Replication）功能。 讨论了是否需要缩短本周的会议时间。 二、行动计划 继续测试和优化新功能与性能优化。 分析Rocks存储层相关的bug，并修复。 进一步研究Rocks缓存中存储已编码数据的性能影响。 优化编码速度，提高性能。 恢复LDPR功能，并评估其性能。 三、后续会议 下次会议将根据测试结果和bug修复情况确定。 四、其他事项 无。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAY-18 :: Ceph Performance Weekly","slug":"2017-MAY-18_-_-_Ceph_Performance_Weekly","date":"2017-05-25T16:00:00.000Z","updated":"2017-05-25T16:00:00.000Z","comments":true,"path":"2017/05/26/2017-MAY-18_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/26/2017-MAY-18_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多名开发人员，包括Dave、Mark、Laurens、Igor、Nick、Stage、Marlon、Peter等。 会议主题： 讨论Ceph存储系统相关的开发进展、性能优化、bug修复以及后续行动计划。 会议内容： 一、关键进展 BlueStore优化： 探讨了将关键事务工作异步化的可行性，但认为与BlueStore的设计方向不符。 讨论了异步消息传递对减少锁争用的好处，并计划进行测试。 讨论了避免内存复制的优化，并计划进行测试。 讨论了优化管理器和BlueStore的优化，并计划进行测试。 讨论了BlueFS同步选项的bug修复，并计划合并。 其他优化： 讨论了锁优化，并决定不合并当前的PR。 讨论了CRC计算优化，并计划进行测试。 讨论了BlueStore的blob标记和修改，并计划进行调试和修复。 讨论了KB sink PR，并计划进行测试。 讨论了scale优化，并计划进行测试。 讨论了BlueStore的同步提交，并计划进行测试。 Katie finisher： 讨论了Katie finisher的性能改进，并计划进行进一步测试。 讨论了异步消息传递锁争用问题。 讨论了BlueStore的随机写性能。 其他议题： 讨论了deferred right的优化。 讨论了BlueStore的I/O性能。 讨论了RocksDB同步问题。 讨论了PowerPC平台的优化。 讨论了CRC计算优化。 讨论了BM IJ eraser代码的PowerPC优化。 二、决定事项 对BlueStore进行异步消息传递和锁优化测试。 对CRC计算优化进行测试。 对KB sink PR进行测试。 对Katie finisher进行进一步测试。 对deferred right进行优化。 对BlueStore的I/O性能进行优化。 对RocksDB同步问题进行修复。 对PowerPC平台的优化进行讨论。 对CRC计算优化进行讨论。 对BM IJ eraser代码的PowerPC优化进行讨论。 三、后续行动计划 各开发人员将继续进行代码开发和测试。 定期召开会议，讨论开发进展和问题。 及时更新文档和代码库。 四、其他 会议中还讨论了一些其他议题，例如RBD的优化、OSD的优化等。 总结： 本次会议讨论了Ceph存储系统开发的相关议题，并制定了后续的行动计划。开发人员将继续努力，优化Ceph的性能和功能，为用户提供更好的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAY-25 -- Ceph Tech Talk: Ceph on ARM","slug":"2017-MAY-25_--_Ceph_Tech_Talk_-_Ceph_on_ARM","date":"2017-05-25T16:00:00.000Z","updated":"2017-05-25T16:00:00.000Z","comments":true,"path":"2017/05/26/2017-MAY-25_--_Ceph_Tech_Talk_-_Ceph_on_ARM/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/26/2017-MAY-25_--_Ceph_Tech_Talk_-_Ceph_on_ARM/","excerpt":"","text":"会议纪要 会议主题： Ceph on ARM 工作进展及未来计划 会议时间： 2023年11月（具体日期未提及） 参会人员： Sage Weil（Red Hat） Steve Capper（dom） Pankaj Brijwasi（Cavium） Vikram（Cavium） Davey (SUSE) Danny (Deutsche Telekom) Jeff Chu（ARM） 会议内容： 1. 上游构建和基础设施现状 Sage 介绍了 Ceph on ARM 的历史和现状，包括 ARM 32 位和 ARM 64 位支持。 目前，Ceph on ARM 的上游构建和测试主要依赖于社区贡献的硬件和 Jenkins 服务器。 由于缺乏足够的硬件和 Jenkins 服务器资源，目前还没有进行大规模的 ARM 构建和测试。 2. 社区工作进展 Steve Capper 介绍了 dom 公司在 Ceph on ARM 领域的工作，包括 OpenStack Swift 与 Radars 网关集成、内核参数和设置参数优化等。 Pankaj Brijwasi 介绍了 Cavium 公司在 Ceph on ARM 领域的工作，包括基于 ARM 平台的数据中心处理器、Cavium ARM 服务器等。 Davey 介绍了 SUSE 公司在 Ceph on ARM 领域的工作，包括提供 ARM 64 位平台上的 Ceph 企业存储产品。 Danny 介绍了 Deutsche Telekom 公司在 Ceph on ARM 领域的工作，包括性能测试、构建 Luminous 平台、安全性等。 3. 下一步行动计划 Sage 提出了以下行动计划： 完善上游 Ceph on ARM 构建，使其成为每个发布版本的一部分。 在 Jenkins 上设置 CI/CD 流程，以测试每个 pull request 和 master 分支。 提供可用的 ARM 二进制文件。 探索使用 OpenStack 作为构建和测试平台的可能性。 Jeff Chu 提出了以下行动计划： 建立一个协调机制，以了解社区中正在进行的工作。 鼓励社区成员参与 ARM 构建和测试工作。 探索在 ARM 平台上实现架构特定优化的机会。 4. 其他讨论 会议讨论了以下问题： 是否应该继续支持 ARM 32 位构建？ 如何提高 ARM 构建和测试的效率？ 如何鼓励更多社区成员参与 Ceph on ARM 的工作？ 5. 会议总结 本次会议讨论了 Ceph on ARM 的工作进展和未来计划，并确定了下一步行动计划。社区成员对 Ceph on ARM 的兴趣和投入令人鼓舞，相信在大家的共同努力下，Ceph on ARM 将会取得更大的进步。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAY-25 :: Ceph Performance Weekly","slug":"2017-MAY-25_-_-_Ceph_Performance_Weekly","date":"2017-05-25T16:00:00.000Z","updated":"2017-05-25T16:00:00.000Z","comments":true,"path":"2017/05/26/2017-MAY-25_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/26/2017-MAY-25_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年5月25日 参会人员： 拉奇（Rach）、马克（Mark）、肖恩（Sean）、艾略特（Elliott）、伊戈尔（Igor）、马西莫（Massimo）、凯尔（Kael）、萨奇（Sage）、KB、KB红、KB蓝 会议主题： Ceph分布式存储项目进展及讨论 关键细节： 1. 代码审查及合并： 合并了多个pull request，包括锁机制优化、CRC计算阈值调整、Zipkin分支关闭等。 KB同步线程的迭代改进，性能提升约10%。 仍在审查中的pull request包括事务队列、避免内存复制的优化、批量节流等。 2. 蓝存储（Blue Store）： 测试表明，将金属块大小设置为16k在NVMe上可能并不总是比4k快。 发现内存泄漏问题，需要进一步调查。 正在研究避免在写操作中使用内存复制的优化方法。 3. 异步消息传递器（Async Messenger）： 优化了锁机制，减少了锁争用。 消息传递器性能在Tesla上有所提升。 4. 其他进展： 在CERN部署了一个包含200个主机的临时集群，用于测试新代码。 解决了内存使用问题，通过使用B树优化了索引结构。 计划在未来一周内进行简短的电话会议。 决定的事项： 继续优化蓝存储性能，并解决内存泄漏问题。 完成异步消息传递器的优化。 在CERN的集群上继续测试新代码，并解决遇到的问题。 后续行动计划： 拉奇将重新审查代码，并解决KB同步线程和事务队列的pull request。 马克将继续测试蓝存储，并调查内存泄漏问题。 艾略特将继续优化异步消息传递器。 伊戈尔将继续在CERN的集群上测试新代码。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-APR-12 :: Ceph Developer Monthly","slug":"2017-APR-12_-_-_Ceph_Developer_Monthly","date":"2017-05-16T16:00:00.000Z","updated":"2017-05-16T16:00:00.000Z","comments":true,"path":"2017/05/17/2017-APR-12_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/17/2017-APR-12_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： REST API 的讨论： 讨论了将 REST API 添加到 Ceph Manager 的 pull request。 分析了 Calamari API 和当前 pull request 的异同，并讨论了 Calamari API 中一些长运行操作的处理问题。 讨论了 REST API 的用户需求，以及是否应该将其作为 Luminous 版本的一部分添加。 讨论了 OpenStack Swift 使用 REST API 的需求，并探讨了将其集成到 Manager 的可能性。 决定将 REST API 作为 Luminous 版本的一部分添加，并保持其作为实验性功能的状态，以便在后续版本中进行改进。 配置选项注释： 讨论了为配置选项添加注释的必要性，以帮助用户更好地理解其用途和影响。 讨论了配置选项的属性，例如描述、类型、验证函数、默认值、影响范围等。 讨论了配置选项的级别，例如基本、高级、开发等，以及如何使用这些级别来帮助用户管理配置选项。 讨论了配置选项的标签和影响范围，以及如何使用这些信息来帮助用户更好地理解选项的作用。 决定将配置选项注释作为 Luminous 版本的一部分添加，并使用文档生成工具自动生成文档。 其他议题： 讨论了为配置选项添加弃用标记的必要性。 讨论了为配置选项添加重启标记的必要性。 讨论了为配置选项添加“替换选项”的必要性。 行动计划： 将 REST API 作为 Luminous 版本的一部分添加，并保持其作为实验性功能的状态。 为配置选项添加注释，并使用文档生成工具自动生成文档。 为配置选项添加弃用标记、重启标记和“替换选项”。 完成其他议题的讨论和决策。 备注： 会议中讨论了多个议题，以上仅为部分总结。 会议中提到的 pull request 和文档链接请参考会议记录原文。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-APR-27 :: Ceph Performance Weekly","slug":"2017-APR-27_-_-_Ceph_Performance_Weekly","date":"2017-05-16T16:00:00.000Z","updated":"2017-05-16T16:00:00.000Z","comments":true,"path":"2017/05/17/2017-APR-27_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/17/2017-APR-27_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： （未提及具体日期，请根据实际会议时间填写） 参会人员： Paige（主持人）、Mark、Alan、Mercia、John、Andrey、Igor、Victor、Josh等。 会议主题： Ceph分布式存储系统开发讨论，包括功能请求、代码审查、性能优化、问题解决等。 主要议题： 1. 功能请求与代码审查 discard功能：讨论了discard功能的实现和性能问题，决定暂时不启用该功能。 数据上传限制：讨论了数据上传限制的实现和性能影响，决定进一步研究。 strata选项清理：讨论了strata选项清理的pull request，认为已完成或接近完成。 编码优化：讨论了多个编码优化pull request，包括避免重复CPU计算、减少锁竞争等。 性能优化：讨论了减少锁获取、同步路径上下文切换延迟等性能优化方案。 2. 性能优化 统一限速策略：讨论了统一限速策略的实现和性能影响，决定进一步研究。 磁盘队列深度：讨论了磁盘队列深度对性能的影响，决定进一步研究。 同步写操作：讨论了同步写操作的性能问题，决定尝试同步写优化方案。 RocksDB性能问题：讨论了RocksDB在压缩过程中的性能问题，决定进一步研究。 3. 问题解决 XFS文件系统问题：讨论了XFS文件系统在高负载下的性能问题，决定进一步研究。 Ceph集群恢复：讨论了Ceph集群恢复的问题，决定进一步研究。 决定事项： 继续研究discard功能、数据上传限制、统一限速策略、磁盘队列深度等问题。 尝试同步写优化方案。 进一步研究RocksDB在压缩过程中的性能问题。 进一步研究XFS文件系统在高负载下的性能问题。 进一步研究Ceph集群恢复的问题。 后续行动计划： 各参会人员根据会议讨论结果，继续进行代码开发和性能优化工作。 定期召开会议，讨论项目进展和问题解决情况。 其他事项： 邀请RocksDB开发人员参与讨论RocksDB性能问题。 邀请XFS文件系统开发人员参与讨论XFS文件系统性能问题。 邀请Ceph集群恢复开发人员参与讨论Ceph集群恢复问题。 总结： 本次会议讨论了Ceph分布式存储系统的多个重要议题，包括功能请求、代码审查、性能优化、问题解决等。参会人员对讨论结果进行了深入分析和讨论，并制定了后续行动计划。本次会议对Ceph项目的开发进展具有重要意义。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAY-04 :: Ceph Performance Weekly","slug":"2017-MAY-04_-_-_Ceph_Performance_Weekly","date":"2017-05-16T16:00:00.000Z","updated":"2017-05-16T16:00:00.000Z","comments":true,"path":"2017/05/17/2017-MAY-04_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/17/2017-MAY-04_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： Chris, Mark, James (Alibaba), Josh, Sage, Andy (kestrels), Stu, Ali (Alibaba), Johnson (Alibaba) 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 1. Ceph性能优化 RocksDB读前加速： Mark介绍了通过启用RocksDB读前加速功能，在压缩过程中提高性能的方法。该功能将压缩线程的读取时间从95%降低到18%，并将等待时间从82%降低到18%，从而提高了压缩效率。 编码/解码框架迁移： Sage提交了一个PR，用于移除旧编码/解码代码并迁移到新框架，以提高性能和可维护性。 BlueStore优化： Sage提交了一个PR，用于将BlueStore放置在共享设备中间，以优化性能。讨论了将数据放置在磁盘中间或外圈的位置对性能的影响。 锁优化： 讨论了锁优化，包括消除重复块位置和锁冲突。 CRC缓存： Andy (kestrels) 提交了一个PR，用于改进CRC缓存，以提高性能。讨论了CRC缓存的有效性和优化方向。 自适应限流： 讨论了自适应限流机制，以优化性能和降低延迟。 2. Ceph恢复 阿里巴巴团队： 阿里巴巴团队分享了他们的恢复优化工作，包括同步恢复和部分恢复。讨论了性能提升和优化方向。 异步恢复： Josh分享了他们的异步恢复工作，并讨论了与阿里巴巴团队的协作。 3. 其他 OST性能优化： Johnson (Alibaba) 提出了优化OST性能的方案，包括将某些函数移至对象内部线程执行，以减少锁争用。 游戏时钟： 讨论了游戏时钟的实现和性能。 行动计划： Mark将继续优化RocksDB读前加速功能。 Sage将继续改进BlueStore和CRC缓存。 Andy (kestrels) 将完善CRC缓存PR。 Josh将优化异步恢复机制。 Johnson (Alibaba) 将继续优化OST性能。 阿里巴巴团队将继续优化Ceph恢复功能。 下次会议： 时间：2023年11月X日 内容：Ceph分布式存储项目进展及讨论 备注： 会议中提到了一些计算机科学/ceph相关领域英文原文的关键词，如RocksDB, BlueStore, CRC, PG, OST, RBD等。 会议纪要仅供参考，具体细节可能需要查阅相关PR和邮件。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAY-11 :: Ceph Performance Weekly","slug":"2017-MAY-11_-_-_Ceph_Performance_Weekly","date":"2017-05-16T16:00:00.000Z","updated":"2017-05-16T16:00:00.000Z","comments":true,"path":"2017/05/17/2017-MAY-11_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/17/2017-MAY-11_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 会议主持人 Ceph社区成员 阿里巴巴工程师（Mark、Jesse、Gem、Cliff） 其他Ceph社区成员 会议内容： 一、Ceph社区近期工作 Poll请求： 启用sink rights以提高小IO性能，但对大IO性能可能有所影响。 对manager进行优化，提高demon state index效率。 scrubbing功能已合并。 cache miss rate优化已合并。 blue store compaction read ahead优化已合并。 使用新的编码和修复方案。 blue FS sync right选项添加。 关闭work的讨论。 CRC计算优化。 blue FS在共享设备中的放置讨论。 combining call backup committed功能已合并。 adaptive throttle工作仍在进行中。 Kvsync线程拆分讨论。 Purple请求： 优化RBD性能。 异步消息传递工作。 二、Ceph社区未来工作 RBD性能优化： 分析RBD client-side瓶颈，考虑禁用BD cache。 评估RBD与文件系统的性能对比。 blue store优化： blue store compaction read ahead优化。 Kvsync线程拆分。 3x replication与blue store erasure coding性能对比。 可能的partial reads优化。 其他工作： CRC计算优化。 blue FS在共享设备中的放置。 adaptive throttle工作。 Kvsync线程拆分。 三、阿里巴巴工程师工作 Commit majority功能： 实现了commit majority功能，提高了平均延迟和延迟抖动。 将继续在客户端和收集器端实现commit majority功能。 与Ceph社区的协作： 邀请Ceph社区成员对commit majority功能进行审查。 与Ceph社区合作，优化Ceph性能。 四、行动计划 Ceph社区成员将继续关注RBD性能优化、blue store优化等工作。 阿里巴巴工程师将与Ceph社区合作，优化Ceph性能。 Ceph社区成员将参与commit majority功能的审查工作。 五、其他 会议中讨论了RBD与文件系统性能对比的问题。 会议中讨论了blue store在共享设备中的放置问题。 会议中讨论了adaptive throttle工作。 六、会议总结 本次会议讨论了Ceph社区近期工作和未来工作计划，并邀请阿里巴巴工程师参与Ceph性能优化工作。会议气氛热烈，讨论深入。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-APR-12 :: Ceph Performance Weekly","slug":"2017-APR-12_-_-_Ceph_Performance_Weekly","date":"2017-05-15T16:00:00.000Z","updated":"2017-05-16T16:00:00.000Z","comments":true,"path":"2017/05/16/2017-APR-12_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/05/16/2017-APR-12_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 1:00 参会人员： Sage, Igor, Bob, Ryu, Mark, Nick, Erik等 会议内容： 一、Ceph Pull Requests讨论 Igor的工作： 合并了修复小文件性能问题的pull request，提高了系统的鲁棒性。 提交了参数调整和添加硬盘SSD变体的pull request，需要进一步审查。 检测到蓝存储在NVMe上的性能下降，需要进一步分析。 提交了将blob转换为blob的pull request，需要单独测试。 Brightest Law的工作： 合并了速度表优化和限流模型优化的pull request，用户现在在蓝存储中只有一个限流指标。 下一个pull request将测试自动调整限流，基于目标延迟进行调整。 其他pull requests： 一些pull requests正在审查中，包括文件顺序调整和回调合并等。 二、蓝存储性能问题 蓝存储缓存测试失败： 需要重新运行测试，检查是否有问题。 分离PVC线程： 将线程分为两部分可能有助于提高性能。 蓝存储文件系统优化： 将蓝存储文件系统放置在硬盘中间可以减少臂运动，提高性能。 文件系统检查内存使用： 需要进一步分析内存使用情况，确保没有未计数的内存使用。 三、其他议题 墙钟分析： 讨论了墙钟分析工具的选择，包括gdb、py-cpu-profiler等。 libunwind问题： 讨论了libunwind在信号处理中的问题。 四、行动计划 Igor： 审查和合并参数调整和硬盘SSD变体的pull request。 分析蓝存储在NVMe上的性能下降问题。 Brightest Law： 测试自动调整限流的pull request。 Mark： 重新运行蓝存储缓存测试，检查是否有问题。 Nick： 分析文件系统检查内存使用情况。 所有人员： 关注墙钟分析工具的选择和libunwind问题。 五、下次会议时间 下次会议将于X月X日星期四举行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-APR-05 :: Ceph Performance Weekly","slug":"2017-APR-05_-_-_Ceph_Performance_Weekly","date":"2017-04-05T16:00:00.000Z","updated":"2017-04-06T16:00:00.000Z","comments":true,"path":"2017/04/06/2017-APR-05_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/04/06/2017-APR-05_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 未知（根据会议内容推测，可能为太平洋时间上午8点） 参会人员： 多位Ceph社区成员，包括Nick、Mark、Ashley、Joe、Mario等。 会议主题： Ceph社区近期PR进展和讨论 Ceph性能优化和改进 Ceph社区会议时间调整 其他相关议题 关键细节： 1. PR进展和讨论 本周社区合并了多个PR，包括BlueStore性能优化、CRC计算优化、RBD性能改进等。 Nick分享了BlueStore性能测试结果，并讨论了如何进一步提高性能。 Mark介绍了Zipkin追踪框架的进展，以及如何将其集成到Ceph中。 2. Ceph性能优化和改进 讨论了如何通过调整队列深度和延迟来提高Ceph性能。 讨论了如何通过优化缓存行对齐来提高性能。 讨论了如何通过优化编码和解码函数来减少内存使用。 3. Ceph社区会议时间调整 由于时区差异，社区成员对会议时间提出了不同的意见。 讨论了将会议时间调整为周四上午11点（UTC时间）的可能性。 4. 其他相关议题 讨论了如何优化Ceph的依赖关系处理。 讨论了如何进一步优化Ceph的编码和解码功能。 决定的事项： 将Ceph社区会议时间调整为周四上午11点（UTC时间）。 继续关注Ceph性能优化和改进的相关议题。 进一步推进Zipkin追踪框架的集成工作。 后续行动计划： Nick将继续进行BlueStore性能测试，并分享测试结果。 Mark将继续推进Zipkin追踪框架的集成工作。 社区成员将继续关注Ceph性能优化和改进的相关议题。 社区成员将讨论如何优化Ceph的依赖关系处理和编码和解码功能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAR-22 :: Ceph Performance Weekly","slug":"2017-MAR-22_-_-_Ceph_Performance_Weekly","date":"2017-04-05T16:00:00.000Z","updated":"2017-04-06T16:00:00.000Z","comments":true,"path":"2017/04/06/2017-MAR-22_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/04/06/2017-MAR-22_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 全体研发人员 会议主题： 讨论Ceph分布式存储的最新进展和待办事项 关键细节 新特性与需求： Igor的PR清理： 对Ashley基于早期PR的清理工作，旨在将kV sinks red和blue store分成两部分，以提高性能。目前编译存在问题，需要进一步定义和测试。 零拷贝工作： 持续进行DM和nascent messenger的零拷贝工作，预计将有更多相关工作。 PG重映射： Sage提出的PG重映射功能，允许用户在PG已映射后重新映射，以优化分布。这是一个长期需求的解决方案。 SSD对齐： 忘记设置Alexey SSD对齐为16KB，考虑将其降低到8KB或4KB，以减少内存和数据库压力。 固定延迟权限： 合并了固定延迟权限的修复，可能改善性能并解决一系列问题。 RC锁定机制： RC锁定机制的改进可能不会带来显著性能提升，已被移出热路径。 LP T&amp;G工作： LP T&amp;G工作分为两部分：在BOS D中引入大量tracing和直接messenger / men's store，以分离代码并专注于找到延迟。 性能改进： 讨论了如何通过改进OSD性能来提高RTW性能。 Brothersoft性能： 讨论了Brothersoft性能优化，包括减少内存拷贝和动态内存分配。 静态指针： 讨论了静态指针的概念，以及在OSD客户端接口中使用静态指针的潜在优势。 BlueStore优化： 讨论了BlueStore中与大量对象和元数据相关的性能问题，包括压缩和锁定问题。讨论了将大型对象键分区到数据库以减少压缩的可行性。 CRC32 for PVC架构： 讨论了CRC32在PVC架构中的应用。 X to be arm range Keys operator interface： Sage正在测试X to be arm range Keys operator interface。 技术讨论： 数据结构： 讨论了Brewster中使用的数据结构，包括顺序结构和动态结构，以及它们对性能的影响。 编码/解码： 讨论了编码/解码的性能优化，以及如何将多个值编码/解码在单个操作中。 内存分配器： 讨论了内存分配器的性能优化，以及如何减少内存碎片和锁定问题。 决定事项 继续推进Igor的PR清理工作，并解决编译问题。 继续进行零拷贝工作，并关注未来更多的相关工作。 推进PG重映射功能，并解决编译问题。 调整SSD对齐设置，以减少内存和数据库压力。 合并固定延迟权限的修复，并进一步测试性能。 移除RC锁定机制的改进，并关注其他性能优化方法。 继续推进LP T&amp;G工作，并关注分离代码和找到延迟。 推进性能改进工作，特别是OSD性能优化。 推进Brothersoft性能优化，包括减少内存拷贝和动态内存分配。 探索静态指针在OSD客户端接口中的应用。 优化BlueStore性能，包括减少元数据和压缩。 探索将大型对象键分区到数据库以减少压缩的可行性。 评估CRC32在PVC架构中的应用。 测试X to be arm range Keys operator interface。 优化数据结构，以提高性能。 优化编码/解码性能，并探索将多个值编码/解码在单个操作中。 优化内存分配器，以减少内存碎片和锁定问题。 后续行动计划 Igor：解决PG重映射PR的编译问题。 Sage：测试X to be arm range Keys operator interface。 全体研发人员：关注并参与上述各项工作的推进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAR-23 -- Ceph Tech Talks: Ceph at Scale & Writing Applications with Language Bindings","slug":"2017-MAR-23_--_Ceph_Tech_Talks_-_Ceph_at_Scale_Writing_Applications_with_Language_Bindings","date":"2017-04-05T16:00:00.000Z","updated":"2017-04-06T16:00:00.000Z","comments":true,"path":"2017/04/06/2017-MAR-23_--_Ceph_Tech_Talks_-_Ceph_at_Scale_Writing_Applications_with_Language_Bindings/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/04/06/2017-MAR-23_--_Ceph_Tech_Talks_-_Ceph_at_Scale_Writing_Applications_with_Language_Bindings/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： Ceph 部署技巧与应用开发 参会人员： Chris Wholey（Canonical 高级存储负责人）、Chris Jones（Ceph Rust 绑定开发者）以及其他与会者 会议内容： 一、Ceph 部署技巧 Juju 工具介绍： Chris Wholey 介绍了 Canonical 开发的 Juju 工具，该工具通过 Charm（钩子）的方式，简化了 Ceph 集群的部署和配置过程。 Charm 优势： Charm 允许用户轻松地将应用程序与其他应用程序进行集成，并提供丰富的配置选项，例如磁盘分区、文件系统格式、加密等。 自动化升级： Chris Wholey 展示了如何使用 Juju 工具进行自动化升级，包括如何升级 Ceph 集群和 OSD 设备。 跨平台部署： Juju 工具支持在物理机、虚拟机和容器等多种平台上部署 Ceph 集群。 二、Ceph Rust 绑定 Rust 语言优势： Chris Jones 介绍了 Rust 语言在 Ceph 开发中的应用，Rust 语言具有内存安全、并发性能高等优点。 Ceph Rust 绑定： Chris Jones 展示了 Ceph Rust 绑定的开发过程，该绑定提供了对 Ceph 库的访问，并使用 Rust 的安全特性进行封装。 示例应用： Chris Jones 展示了如何使用 Ceph Rust 绑定编写一个简单的应用程序，该应用程序连接到 Ceph 集群并打印出集群的使用情况。 三、后续行动计划 完善 Ceph Rust 绑定： Chris Jones 和 Chris Wholey 将继续完善 Ceph Rust 绑定，并提供更多功能。 推广 Ceph Rust 绑定： 将 Ceph Rust 绑定推广给更多开发者，并鼓励其在 Ceph 应用开发中使用。 四、其他 Q&amp;A环节： 会议期间，与会者就 Ceph 部署技巧、Rust 语言应用等问题进行了提问和讨论。 下一次会议： 下一次 SEF 技术研讨会将于 4 月 27 日举行。 关键词： Ceph、Juju、Charm、Rust、内存安全、并发性能、自动化升级、跨平台部署","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAR-29 :: Ceph Performance Weekly","slug":"2017-MAR-29_-_-_Ceph_Performance_Weekly","date":"2017-04-05T16:00:00.000Z","updated":"2017-04-06T16:00:00.000Z","comments":true,"path":"2017/04/06/2017-MAR-29_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/04/06/2017-MAR-29_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 参会人员： [请填写参会人员名单] 会议主持人： [请填写主持人姓名] 会议主题： Ceph分布式存储项目进展及讨论 会议内容： 一、项目进展 Boost请求优化： Igor最近实现了Blob重用和扩展，对性能有显著提升。 当前正在进行内存利用率和内存分配器的改进。 KB Sink模块进行了重构，预期将带来性能提升。 缓存优化： Bluestar正在进行缓存优化测试，目前效果良好。 如果RocksDB的缓存行为得到改善，将考虑去除相关更改。 运行到完成分支： 计划基于新功能实现运行到完成分支，以提高墙设备性能。 需要对此分支进行测试和验证。 编码优化： 对Barrington编码进行了优化，性能提升明显。 讨论了使用前几位字节表示数据长度的优化方案，但需要格式更改。 计划对其他编码方式进行类似优化。 二、讨论议题 Barrington编码优化： 讨论了优化Barrington编码的方案，包括使用前几位字节表示数据长度。 认为该方案可行，但需要格式更改。 编码优化方案： 讨论了将所有编码方式进行统一优化，以提高代码可读性和可维护性。 运行到完成分支： 讨论了运行到完成分支的实现和测试方案。 三、决定事项 对Barrington编码进行优化，并提交相关Pull Request。 计划对其他编码方式进行类似优化。 计划对运行到完成分支进行测试和验证。 四、后续行动计划 Bluestar继续进行缓存优化测试。 Andrey完成运行到完成分支的实现和测试。 Nick提交Barrington编码优化Pull Request。 对其他编码方式进行优化。 五、其他 讨论了Crush布局优化和显式映射功能。 认为这些功能将进一步提高Ceph的性能和可扩展性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAR-01 :: Ceph Performance Weekly","slug":"2017-MAR-01_-_-_Ceph_Performance_Weekly","date":"2017-03-14T16:00:00.000Z","updated":"2017-03-14T16:00:00.000Z","comments":true,"path":"2017/03/15/2017-MAR-01_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/03/15/2017-MAR-01_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 会议主持人、研发人员、测试人员等 会议内容： 一、主要议题 代码审查与Pull Request 研发人员汇报了近期的工作进展，包括对代码库的拆分、修复Hanoi的bug、处理来自Narratives团队的Pull Request等。 讨论了关于使用Wheless内存和清理代码的建议，以及与Boyd bag关于使用RAM作为日志存储的测试。 针对一些低优先级的补丁，建议进行初步审查，但不必深入。 测试与性能 进行了简单的覆盖测试，并对Blue Store进行了测试，结果显示Boost在EC和RVD文件存储方面表现可接受。 讨论了在测试中可能需要关注的性能问题，例如缓存缺失和位图分配器阻塞。 其他 讨论了关于测试GIF文件的问题，以及硬件设备的准备情况。 讨论了关于性能测试的建议，包括对锁定PR和位图分配器提示的测试。 二、决定事项 对Pull Request进行初步审查，并重点关注性能问题。 对位图分配器阻塞进行测试。 准备硬件设备，进行实际测试。 对锁定PR和位图分配器提示进行性能测试。 三、后续行动计划 研发人员继续进行代码审查和Pull Request处理。 测试人员负责进行性能测试和位图分配器阻塞测试。 准备硬件设备，进行实际测试。 对锁定PR和位图分配器提示进行性能测试。 四、会议总结 本次会议主要讨论了代码审查、测试和性能等方面的问题。会议明确了后续行动计划，并要求相关人员按照计划推进工作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-MAR-08 :: Ceph Performance Weekly","slug":"2017-MAR-08_-_-_Ceph_Performance_Weekly","date":"2017-03-14T16:00:00.000Z","updated":"2017-03-14T16:00:00.000Z","comments":true,"path":"2017/03/15/2017-MAR-08_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/03/15/2017-MAR-08_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： 所有Ceph研发人员 会议主题： Ceph存储系统性能优化与改进 会议内容： 一、蓝店（BlueStore）性能优化 RocksDB范围删除操作优化： 将RocksDB接口更改为使用RocksDB范围删除操作，以提高蓝店性能。该操作在删除大量数据时效率更高，但可能比其他操作慢。计划在不久的将来实施，并可能添加配置选项以控制是否使用该操作。 位图内存使用优化： 优化位图内存使用，以减少内存消耗并提高性能。计划将位图区域直接嵌入到RaceGo中，以提高CPU缓存效率。 蓝店启动优化： 优化蓝店启动速度，减少初始化时间。计划通过优化初始化过程和批处理延迟写入操作来实现。 延迟写入操作优化： 优化延迟写入操作，以提高性能。计划在重写延迟写入代码时实现灵活的批处理策略。 二、其他性能优化 CRC32优化： 优化CRC32计算，提高性能。计划使用Intel指令集，以提高计算速度。 内存使用优化： 优化内存使用，减少内存消耗。计划在BlueStore中使用连续内存区域，以减少内存碎片。 对象存储性能优化： 优化对象存储性能，减少L3缓存缺失。计划使用缓存和优化编译器内联，以提高性能。 三、其他议题 RocksDB缓存失效问题： 研究RocksDB缓存失效导致的随机读取问题，并寻求解决方案。 对象存储分层存储： 与UC Santa Cruz研究人员合作，探索对象存储分层存储技术，以提高性能。 OSD分布优化： 研究OSD分布优化，以实现更均匀的数据分布。 四、行动计划 蓝店性能优化： 完成蓝店性能优化工作，包括RocksDB范围删除操作优化、位图内存使用优化、蓝店启动优化和延迟写入操作优化。 其他性能优化： 完成其他性能优化工作，包括CRC32优化、内存使用优化和对象存储性能优化。 RocksDB缓存失效问题： 研究RocksDB缓存失效问题，并寻求解决方案。 对象存储分层存储： 与UC Santa Cruz研究人员合作，探索对象存储分层存储技术。 OSD分布优化： 研究OSD分布优化，并制定实施计划。 五、后续会议 下次会议将讨论蓝店性能优化工作的进展以及其他性能优化议题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-FEB-22 :: Ceph Performance Weekly","slug":"2017-FEB-22_-_-_Ceph_Performance_Weekly","date":"2017-02-27T16:00:00.000Z","updated":"2017-02-27T16:00:00.000Z","comments":true,"path":"2017/02/28/2017-FEB-22_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/02/28/2017-FEB-22_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage（缺席）、Howai、Nick、Ju、Hae（Nokia） 会议主题： Ceph社区动态、性能测试、RBD性能优化、RGW性能测试 会议内容： 一、Ceph社区动态 P Request进展： 位图分配器锁定问题： 已有P Request关注位图分配器在高随机写负载下的锁定和解锁问题，期待后续进展。 RDMA功能： Howai在RDMA异步消息传递方面取得进展，包括添加性能计数器和零拷贝代码，并讨论了更好的RDMA缓冲区默认值。 缓存优化： Sage提交了一个基本的PR来优化缓存，以解决某些场景下性能问题。 快速调度： Sage与Greg合作进行快速调度工作，Greg已进行大量审查，Sage将进行性能测试。 同步提交事务PR： 等待Sage审查几个补丁。 其他： Nick分享了RBD性能优化的工作，包括调整写回节流设置以平衡吞吐量和读延迟。 二、性能测试 Blue Store测试： Nick使用CBT和getput基准测试工具进行Blue Store测试，并与File Store进行了比较。 测试结果表明，对于大型对象写入，Blue Store比File Store快约两倍，并且性能更稳定。 对于小对象，Blue Store的性能优于File Store，并且随着对象数量的增加，性能下降更少。 NVMe测试： Nick使用NVMe驱动器进行测试，发现网络成为瓶颈，特别是在使用单个RGW服务器时。 尽管性能很高，但CPU使用率也很高，这可能是由于线程模型导致的。 三、RBD性能优化 写回节流设置： Nick发现默认写回节流设置偏向于吞吐量，而牺牲了读延迟。 通过调整写回节流设置，可以平衡吞吐量和读延迟。 四、后续行动计划 Sage将审查同步提交事务PR中的补丁。 Nick将继续测试Blue Store和File Store的性能，并探索优化方案。 Sage将调查RBD中频繁读取的原因。 五、其他 Hae（Nokia）询问了RBD中频繁读取的问题，怀疑与RocksDB压缩和Blue Store有关。 Nick建议增加RocksDB数据分区的大小，以解决读取问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-FEB-23 -- Ceph Tech Talks: Big Data Analytics","slug":"2017-FEB-23_--_Ceph_Tech_Talks_-_Big_Data_Analytics","date":"2017-02-27T16:00:00.000Z","updated":"2017-02-27T16:00:00.000Z","comments":true,"path":"2017/02/28/2017-FEB-23_--_Ceph_Tech_Talks_-_Big_Data_Analytics/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/02/28/2017-FEB-23_--_Ceph_Tech_Talks_-_Big_Data_Analytics/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： 使用Luxio加速SAP上的大数据分析 会议参与者： Alexio项目工程师（姓名未提及）、参会者 会议内容： 主讲人介绍： 主讲人是Luxio项目的软件工程师，毕业于卡内基梅隆大学，曾参与分布式和存储系统的研究。 Luxio介绍： Luxio是一个开源项目，是大数据领域增长最快的开源项目之一。 它可以将任何应用程序连接到任何存储系统，以内存速度在任何规模上运行。 Luxio通过虚拟化不同的存储系统，在一个统一的命名空间下提供统一的存储接口。 它支持多种存储系统，如HDFS、Swift等。 Luxio优势： 统一不同的存储系统。 提供内存速度的性能。 节省成本。 提供灵活的存储和计算分离。 案例分析： 使用Luxio加速SAP上的大数据分析。 通过将数据缓存到Luxio内存中，可以显著提高数据访问速度。 案例：百度使用Luxio加速从Baidu文件系统集群访问数据，性能提升超过30倍。 演示： 使用Spark和Swift存储系统进行演示。 展示了使用Luxio加速数据访问的示例，包括简单的计数操作和单词计数操作。 结果表明，Luxio可以显著提高数据访问速度，尤其是在重复访问数据时。 后续行动： 发布Luxio和Swift的集成指南。 继续优化Luxio的性能和功能。 关键细节： Luxio是一个开源项目，可以连接任何应用程序到任何存储系统。 Luxio可以显著提高数据访问速度，尤其是在重复访问数据时。 Luxio支持多种存储系统，如HDFS、Swift等。 Luxio可以与Spark等计算框架集成。 讨论的主要议题： Luxio的架构和功能。 Luxio的性能优势。 Luxio的应用场景。 决定的事项： 发布Luxio和Swift的集成指南。 继续优化Luxio的性能和功能。 后续行动计划： 发布Luxio和Swift的集成指南。 继续优化Luxio的性能和功能。 探索Luxio在其他场景中的应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-FEB-15 :: Ceph Performance Weekly","slug":"2017-FEB-15_-_-_Ceph_Performance_Weekly","date":"2017-02-16T16:00:00.000Z","updated":"2017-02-17T16:00:00.000Z","comments":true,"path":"2017/02/17/2017-FEB-15_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/02/17/2017-FEB-15_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 会议地点： 线上会议 参会人员： Jeanne、Nick、Sage、Igor、Jaime、Ernesto 等 会议内容： 一、本周工作进展 Sage： 对快速调度代码进行了拆分，成功移除了一些代码，有望提升性能。 Igor： 正在研究减少镜像使用，以降低存储开销。 Jaime： 正在测试Ceph存储集群，发现快照删除时存在延迟问题。 Ernesto： 发现Ceph存储集群内存使用过高，可能是缓存配置问题。 二、主要议题 快照删除延迟问题： 原因： 快照在删除时进行trim操作，导致IO性能下降。 解决方案： 降低快照trim操作的并发度。 调整相关参数，例如right-back-off和snap_trim_max_concurrent。 考虑使用Lucifer优化快照删除性能。 Ceph存储集群内存使用过高： 原因： 可能是缓存配置问题或程序bug。 解决方案： 调整缓存大小。 使用mem_cache_debug参数进行调试，找出内存使用过高的原因。 FastDispatch优化： 目标： 提升Ceph存储集群的性能。 方案： 优化get reserved maps和release maps调用。 优化FastDispatch代码。 审计OSD中等待maps的代码，确保其合理性。 三、后续行动计划 Sage： 继续优化快速调度代码。 Igor： 继续研究减少镜像使用。 Jaime： 继续测试Ceph存储集群，并优化快照删除性能。 Ernesto： 调整缓存大小，并找出内存使用过高的原因。 所有人员： 优化FastDispatch代码，并审计OSD中等待maps的代码。 四、其他 会议中还讨论了Ceph存储集群的日志性能、BlueStore缓存、缓存驱逐策略等问题。 五、总结 本周Ceph存储集群的开发工作主要集中在性能优化和bug修复方面。下周将继续推进相关工作，并关注新的问题和挑战。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-FEB-08 :: Ceph Performance Weekly","slug":"2017-FEB-08_-_-_Ceph_Performance_Weekly","date":"2017-02-07T16:00:00.000Z","updated":"2017-02-08T16:00:00.000Z","comments":true,"path":"2017/02/08/2017-FEB-08_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/02/08/2017-FEB-08_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： 研发人员：多位，包括负责Ceph的分布式存储人员 字幕翻译及总结人员：多位 其他相关人员：多位 会议内容： 一、会议开始及技术问题 会议开始时，由于技术问题，部分参会人员无法正常加入会议。 会议主持人解释了技术问题的原因，并尝试解决问题。 二、Ceph项目进展 Ceph存储性能优化： 项目成员在Ceph存储性能优化方面取得了一些进展，包括： 优化了硬盘驱动器性能测试。 优化了RGW存储性能。 优化了快速调度功能。 项目成员分享了他们在性能优化方面的经验和发现。 Ceph存储功能开发： 项目成员汇报了Ceph存储功能开发方面的进展，包括： 优化了Ceph存储性能测试。 开发了新的Ceph存储功能。 项目成员讨论了新功能的需求和实现方案。 三、Ceph存储性能测试 Ceph存储性能测试进展： 项目成员汇报了Ceph存储性能测试进展，包括： 优化了Ceph存储性能测试工具。 进行了Ceph存储性能测试。 分析了测试结果。 项目成员讨论了测试结果，并提出了改进建议。 四、Ceph存储功能开发 Ceph存储功能开发进展： 项目成员汇报了Ceph存储功能开发进展，包括： 开发了新的Ceph存储功能。 优化了现有Ceph存储功能。 项目成员讨论了新功能的需求和实现方案。 五、其他议题 Ceph存储性能优化： 项目成员讨论了Ceph存储性能优化方案，包括： 优化Ceph存储性能测试。 优化Ceph存储功能。 优化Ceph集群管理。 Ceph存储功能开发： 项目成员讨论了Ceph存储功能开发计划，包括： 开发新的Ceph存储功能。 优化现有Ceph存储功能。 六、后续行动计划 项目成员将继续优化Ceph存储性能。 项目成员将继续开发Ceph存储功能。 项目成员将继续进行Ceph存储性能测试。 项目成员将定期召开会议，汇报项目进展。 七、会议总结 本次会议讨论了Ceph存储性能优化、Ceph存储功能开发、Ceph存储性能测试等相关议题，并制定了后续行动计划。会议取得了预期效果，为Ceph项目的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-FEB-01 :: Ceph Performance Weekly","slug":"2017-FEB-01_-_-_Ceph_Performance_Weekly","date":"2017-02-06T16:00:00.000Z","updated":"2017-02-07T16:00:00.000Z","comments":true,"path":"2017/02/07/2017-FEB-01_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/02/07/2017-FEB-01_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储性能优化及测试讨论 会议内容： 一、Ceph性能优化 部分重启优化： 团队正在测试Blue Store的部分重启功能，但测试结果尚不明确，需要进一步观察其效果。 AIO读取优化： 已合并AIO读取的优化，Bassam进行了回退以解决相关问题。 Blue Store性能提升： Blue Store的性能有所提升，特别是对于顺序读取和对象存储，但随机写入性能仍有待提高。 RestMap优化： Igor进行了RestMap的优化，简化了计数和分配单元，有望大幅提升性能。 新的I/O请求： 提交了新的I/O请求，用于提高小I/O读取的性能。 二、测试结果分析 顺序读取性能提升： 测试结果显示，顺序读取性能显著提升，这对于对象存储应用来说是一个好消息。 随机写入性能： 随机写入性能有所提升，但仍有改进空间。特别是在使用16KB块大小的SSD进行4KB随机写入时，性能可能更好。 Flock和Bitmap Alligator问题： 测试过程中出现了Flock和Bitmap Alligator问题，需要进一步调查其影响。 同步写入性能： 同步写入性能有待提高，特别是对于SSD存储介质。 压缩性能： 压缩过程中性能有所下降，需要进一步优化。 三、后续行动计划 继续测试： 继续进行性能测试，特别是针对随机写入和同步写入性能。 调查Flock和Bitmap Alligator问题： 深入调查Flock和Bitmap Alligator问题，确定其影响并寻求解决方案。 优化压缩性能： 优化压缩性能，减少性能下降。 与Nokia合作： 与Nokia合作，共同解决性能问题。 四、其他 Blue Store缓冲I/O： 讨论了Blue Store缓冲I/O的问题，并确定了相关设置。 RocksDB性能优化： 讨论了RocksDB性能优化，并提出了建议。 五、会议总结 本次会议讨论了Ceph分布式存储的性能优化和测试结果。团队将继续进行测试，并针对发现的问题进行优化。与Nokia的合作将有助于解决性能问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2017-JAN-26 -- Ceph Tech Talk: Getting Started with Ceph Development","slug":"2017-JAN-26_--_Ceph_Tech_Talk_-_Getting_Started_with_Ceph_Development","date":"2017-01-26T16:00:00.000Z","updated":"2017-01-26T16:00:00.000Z","comments":true,"path":"2017/01/27/2017-JAN-26_--_Ceph_Tech_Talk_-_Getting_Started_with_Ceph_Development/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/27/2017-JAN-26_--_Ceph_Tech_Talk_-_Getting_Started_with_Ceph_Development/","excerpt":"","text":"会议纪要 会议时间： 2017年 会议主题： Ceph 开发入门 参会人员： Ceph 社区成员 会议内容： 会议背景： 这是 Ceph 社区 2017 年的首场技术研讨会，旨在帮助新成员了解 Ceph 的开发流程。 主要议题： 如何获取 Ceph 源代码 如何编译和构建 Ceph 如何修复 Ceph 中的 bug 如何进行单元测试和集成测试 如何提交 pull request Ceph 的 QA 测试流程 关键细节： Ceph 源代码托管在 GitHub 上，可以通过 fork 和 clone 方式获取。 使用 install-deps 脚本安装编译依赖。 使用 make-tree 脚本设置构建环境。 使用 make 命令编译 Ceph。 使用 vstart 脚本启动测试集群。 使用 blue store 作为存储后端。 使用 git 进行版本控制。 使用 git gui 进行提交操作。 使用 hub 工具创建 pull request。 使用 pathology 工具进行 QA 测试。 决定事项： 新成员应熟悉 Ceph 的开发流程。 新成员应积极参与 Ceph 的开发。 新成员应使用 git gui 和 hub 工具进行开发。 后续行动计划： 新成员应阅读 Ceph 的官方文档。 新成员应参加 Ceph 社区的邮件列表和聊天室。 新成员应积极向 Ceph 社区提交代码和反馈。 计算机科学/ Ceph 相关领域英文关键词： Ceph GitHub Git SSH Build dependencies CMake Compilation Unit tests Integration tests Pull request QA Pathology SEPPA 总结： 本次会议为新成员提供了 Ceph 开发的全面指南，帮助他们快速上手 Ceph 开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-DEC-07 :: Ceph Performance Weekly","slug":"2016-DEC-07_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-DEC-07_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-DEC-07_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年10月27日 会议地点： 线上会议 参会人员： Steve、Margie、Peng、Tom、NASA、Sage、Sam、Oakland、Mark、Say、Dora等 会议主题： Ceph分布式存储系统性能优化 RBD（RADOS Block Device）性能测试 ZetaScale存储性能测试 IO路径中关键功能的跟踪点分析 会议内容： 一、关键功能跟踪点分析 Steve提交了一个PR，用于添加IO路径中关键功能的跟踪点，这将有助于进行更好的性能分析。 目前正在讨论如何改进缓冲区列表以避免不必要的复制。 Sage和Sam正在测试ZetaScale存储性能，并尝试将其集成到测试套件中。 二、RBD性能测试 Steve进行了RVD（RADOS erasure coding）与EC（Erasure Coding）的性能测试，结果显示RVD在大型顺序写操作中表现优异。 对于小型随机写操作，RVD性能较差，这可能是由于读取操作需要从主节点获取数据，而常规复制则不需要。 建议开发一个功能，允许客户端直接从各个碎片读取数据，以减少读取操作的延迟。 三、ZetaScale存储性能测试 Sage和Sam正在测试ZetaScale存储性能，并尝试将其集成到Ceph中。 目前正在测试一个使用单个kv线程的版本和一个使用多个kv线程的版本。 预计ZetaScale可以减少RocksDB的压缩开销，并提高大型数据集的性能。 四、IO路径性能分析 Say提交了一个PR，用于生成LTTng跟踪点，以跟踪函数级延迟和OID跟踪点，以跟踪操作ID的飞行路径。 分析结果显示，网络延迟和DQ（dispatch queue）操作是影响性能的关键因素。 建议优化IO准备、IO队列和线程上下文切换，以减少延迟。 五、后续行动计划 继续进行RVD和ZetaScale的性能测试，并优化相关功能。 分析LTTng跟踪点数据，以识别性能瓶颈。 优化IO路径，减少延迟。 在下一个会议上分享更多测试结果。 会议总结： 本次会议讨论了Ceph分布式存储系统性能优化的多个方面，包括关键功能跟踪点分析、RBD和ZetaScale存储性能测试以及IO路径性能分析。会议明确了后续行动计划，并期待在下一个会议上分享更多测试结果。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-DEC-14 :: Ceph Performance Weekly","slug":"2016-DEC-14_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-DEC-14_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-DEC-14_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Igor, Mark, Alan, Sam, 等 会议主题： Ceph分布式存储项目更新，包括OSD优化、性能测试、日志存储引擎选择等议题。 关键细节： OSD优化： Sage提交了一个OSD优化补丁，用于提升性能。 进行了RBD在EC覆盖测试，结果显示BlueStore在大型顺序写操作中表现良好，但在小随机写操作和文件存储中表现较差。 计划优化小写操作，提高效率。 开始在Red Hat进行BlueStore的缩放测试。 性能测试： 使用新的对象存储性能基准进行测试，Igor正在测试并提供反馈。 预计在Crackit发布后会有所进展。 日志存储引擎选择： 讨论了使用RocksDB作为日志存储引擎的优缺点。 分析了其他存储引擎，如WiredTiger、TokuDB等，并评估了其适用性。 认为在Luminous版本中，RocksDB是最合适的选择，但需要进一步改进。 其他议题： 讨论了Fast Dispatch优化。 讨论了DPDK的使用情况。 讨论了RDMA的工作进展。 决定的事项： 继续使用RocksDB作为日志存储引擎，并对其进行改进。 优化BlueStore，提高其在小随机写操作和文件存储中的性能。 进行更多的性能测试，以评估不同存储引擎的适用性。 继续关注RDMA和RDMA的工作进展。 后续行动计划： Igor将继续测试新的对象存储性能基准，并提供反馈。 Mark将继续优化Fast Dispatch。 Alan将继续关注BlueStore的性能和优化。 其他团队成员将继续进行相关工作。 总结： 本次会议讨论了Ceph分布式存储项目的多个关键议题，并制定了后续行动计划。会议重点强调了OSD优化、性能测试和日志存储引擎选择等重要议题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-NOV-09 :: Ceph Performance Weekly","slug":"2016-NOV-09_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-NOV-09_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-NOV-09_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Lonnie、Adam、Dan、Sage、Mark、Igor等 会议主题： Ceph分布式存储项目进展、RocksDB性能测试及优化 会议内容： 一、Ceph分布式存储项目进展 内存池调整： 部分请求正在将数据移动到蓝存储（Blue Store）的独立内存池中，以便更好地跟踪内存使用情况。 Crush锁移除： Adam提交的请求可能有助于移除Crush锁，提高性能。 RocksDB优化： Dan正在进行的RocksDB相关工作值得期待。 Blue Store性能优化： 已合并新的Rocks TBE配置应用程序设置，使用更大的缓冲区以减少RocksDB的写入压力。 并行事务提交： Blue Store的并行事务提交功能正在开发中。 性能回归： 由于RocksDB编译时优化导致的性能下降已修复。 二、RocksDB性能测试及优化 RocksDB与Jetta Scale对比： 进行了RocksDB和Jetta Scale的性能对比测试，发现RocksDB在非稳定状态下性能更好，但在稳定状态下性能较差。 Sharding逻辑问题： 发现Sharding逻辑存在错误，导致性能下降。 RocksDB优化方向： 减少数据集大小，降低压缩频率。 优化读取操作，提高全读场景下的性能。 考虑使用更小的对象大小，减少碎片化。 三、后续行动计划 继续进行RocksDB与Jetta Scale的性能对比测试，包括多OST和全读场景。 修复Sharding逻辑错误。 优化RocksDB的读取操作和对象大小设置。 探索其他RocksDB优化方案。 四、其他事项 预计将在今年内尝试使用RDMA进行数据同步。 邀请其他团队成员分享性能测试数据。 五、会议总结 本次会议讨论了Ceph分布式存储和RocksDB的进展和优化方向，并制定了后续行动计划。会议内容涵盖了内存池调整、Sharding逻辑问题、RocksDB优化等多个方面，为Ceph项目的进一步发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-NOV-16 :: Ceph Performance Weekly","slug":"2016-NOV-16_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-NOV-16_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-NOV-16_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议主题： Ceph分布式存储项目进展及讨论 参会人员： （此处列出参会人员名单） 会议内容： 一、本周进展 Polar请求： 优化搜索计算的请求，通过获取零缓冲区（0 1）来提升性能。 40副本缓冲列表的请求，Kiku和Matt正在审查，期待进行微基准测试以验证效果。 改进Booster Cache中元数据的使用，可能有助于提升性能。 Blue Store改进： 将更多内容引入MemCaches，以更好地跟踪和提升用户体验。 其他改进工作，包括回调功能、移除Crush Lock请求等。 RocksDB相关： 使用RocksDB TVL families，已基本实现，但存在一些bug，如Cupid分配器问题。 通过RocksDB TVL families进行压缩统计，发现约三分之一的压缩流量来自Omap，约三分之二来自元数据操作。 在启用column families时，RocksDB TVL的性能表现较好，特别是随机小写操作。 二、讨论议题 RocksDB TVL families的bug： Cupid分配器问题导致数据错误地进入B树。 Commit start断言错误，原因不明。 需要进一步调查这两个问题是否相关。 RocksDB TVL families的性能： 在启用column families时，RocksDB TVL的性能表现较好，特别是随机小写操作。 需要进一步测试和优化。 三、决定事项 继续调查RocksDB TVL families的bug，并修复相关问题。 进一步测试和优化RocksDB TVL families的性能。 四、后续行动计划 Kiku和Matt将继续审查40副本缓冲列表的请求，并进行微基准测试。 团队将继续关注RocksDB TVL families的bug，并修复相关问题。 团队将进行更多测试，以验证RocksDB TVL families的性能，并进一步优化。 五、其他事项 下周会议将讨论RCU（Read-Copy-Update）相关议题。 如有其他议题需要讨论，请提前提交至会议议程。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-NOV-23 :: Ceph Performance Weekly","slug":"2016-NOV-23_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-NOV-23_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-NOV-23_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Sage, Ben Jenkins (Nokia首席视频架构师), M (Nokia开发团队), Mark (Ceph社区成员) 会议主题： Ceph BlueStore 测试与讨论 会议内容： 一、Sage 报告 RTC 工作进展： Sage 介绍了 RTC 工作进展，包括同步写入事务到 BlueStore，以及修复相关问题的补丁。 BlueStore 性能优化： Sage 提到，BlueStore 在使用 NVMe 存储和适当配置的情况下，可以显著提高性能。同时，他也提到，在有 I/O 的情况下，无法同步执行 I/O，需要进行进一步的修改。 BlueStore 与列族： Sage 指出，使用列族可能会降低性能，特别是在大容量卷上。他建议使用位图分配器来提高性能。 二、Ben 和 M 报告 Nokia 公司介绍： Ben 介绍了 Nokia 公司的业务范围和主要产品，特别是云 DVR 产品，该产品使用了 BlueStore。 云 DVR 工作原理： Ben 解释了云 DVR 的工作原理，包括内容导入、存储、管理和内容输出等环节。 BlueStore 性能测试： Ben 和 M 分享了他们在 BlueStore 上的性能测试结果，包括读写性能、稳定性、可靠性等方面。 BlueStore 与纠删码： Ben 和 M 讨论了 BlueStore 与纠删码的使用，包括性能、可靠性和恢复等方面。 未来计划： Ben 和 M 表示，他们将继续测试 BlueStore，并希望将其作为 Luminous 版本的官方后端存储。 三、讨论与决定 关于删除操作优先级： Sage 提到，在大量删除操作时，OSD 上的队列可能会过载，导致性能下降。建议增加删除操作的优先级设置。 关于纠删码： Ben 和 M 指出，纠删码可能会导致性能下降，尤其是在大型对象写入时。建议尝试使用 6+2 纠删码来解决这个问题。 关于 VFS 缓存压力： Sage 提到，VFS 缓存压力可能会影响性能，尤其是在冷数据访问时。建议降低 VFS 缓存压力。 四、行动计划 Sage 将继续修复 BlueStore 中的问题，并优化性能。 Ben 和 M 将继续测试 BlueStore，并与其他 Ceph 社区成员合作，共同改进 BlueStore。 Ceph 社区成员将关注删除操作优先级、纠删码和 VFS 缓存压力等问题，并寻求解决方案。 五、其他 Ben 和 M 表示，他们愿意与 Ceph 社区成员合作，共同推动 BlueStore 的发展。 会议结束后，Ben 和 M 将将测试结果和反馈提交给 Ceph 社区。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-OCT-12 :: Ceph Performance Weekly","slug":"2016-OCT-12_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-OCT-12_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-OCT-12_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Ramesh, Dan Lambright, Kevin, Alan, Sage, Tim, 等 会议主题： Ceph分布式存储系统，特别是BlueStore的性能优化 会议内容： 一、本周工作进展 Ramesh 在进行内存数据库存储接口的改进工作，将键值存储从B树实现切换到通用映射，以提高性能。 Dan Lambright 尝试使用Ceph的PG映射功能，为PG信息提供了一种新的实现方式，有望提高性能。 BlueStore性能优化： 本周关闭了许多与BlueStore相关的请求，主要集中在减少内存结构的大小，以降低对缓存节点的内存需求。 Kevin上周重点研究了减少内存结构大小的工作。 Sage提出了一种更新PG信息的方法，可以显著减少数据写入量和提高性能。 Tim正在尝试将快速编码功能合并到BlueStore中，但存在冲突。 二、讨论议题 BlueStore与文件存储的对比： BlueStore在随机读取方面存在性能问题，尤其是在IOPS大小为32时。 Sage提出了可能的解决方案，包括异步支持一次从Ceph MO数据结构中检索多个扩展，以及进行序列化操作。 需要进一步研究异步消息传递和快速调度器，以提高性能。 RocksDB的写前日志（WAL）优化： 目前测试实验室出现问题，无法进行长时间测试。 初步结果显示，增加日志数量或日志大小可以提高性能。 需要进一步研究如何区分WAL数据与元数据，以及如何量化这些行为。 其他议题： Ramesh正在研究将键值存储从B树实现切换到通用映射。 Dan Lambright正在尝试使用Ceph的PG映射功能。 Sage正在研究改进BlueStore的随机写入性能。 三、决定事项 继续关注BlueStore的性能优化，特别是随机读取和序列读取性能问题。 进一步研究RocksDB的WAL优化，包括增加日志数量或日志大小。 完成Ramesh和Dan Lambright的工作，以提高性能。 Sage继续研究改进BlueStore的随机写入性能。 四、后续行动计划 Ramesh和Dan Lambright继续进行相关工作。 Sage研究改进BlueStore的随机写入性能。 Tim解决快速编码功能的合并冲突。 Kevin继续研究减少内存结构大小的工作。 五、其他 会议中讨论了BlueStore的分配策略，以及如何减少写放大和压缩。 讨论了如何使用RocksDB的WAL来提高性能。 讨论了如何使用更多的工具和指标来分析Ceph的性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-OCT-16 :: Ceph Performance Weekly","slug":"2016-OCT-16_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-OCT-16_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-OCT-16_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Alan、Ben、Igor、Sage、Somnath等 会议主题： Ceph社区近期工作进展及讨论 一、关键进展 内存管理： Alan提交了实现slab containers的PR，这将有助于减少内存碎片，并识别代码中存在的低效操作，从而更好地管理内存分配。 BlueStore： Sage对BlueStore进行重构，预计将带来性能提升。 Igor开始为异步消息传递实现RDMA，这是XIO消息传递开发的一个替代方案。 优化了RocksDB的日志设置，可能对BlueStore产生积极影响。 移除了BlueStore的事务提交，提高了性能。 Sage进行了异步消息传递的性能优化，性能提升了40%。 PG级别的快照和事务性能得到提升。 BlueStore的紫色压缩设置和快速编码功能已合并。 RocksDB： Sage对RocksDB进行优化，减少了IO元数据更新的频率，提高了性能。 压缩设置已合并。 其他： RC锁定工作进展顺利。 Zipkin跟踪工作有望合并。 Slab容器工作继续进行。 Sandisk的ZetaScale集成工作取得进展，已在4K随机I/O方面超越了BlueStore。 二、讨论的主要议题 RocksDB行为： Sage对RocksDB的行为进行了深入研究，并分享了测试结果。结果表明，使用大缓冲区可以提高性能，尤其是在使用NVMe设备时。 文件系统性能： Ben分享了使用Ceph BlueStore和RocksDB进行性能测试的结果，并提出了关于文件描述符限制的问题。 ZetaScale： Sage介绍了Sandisk的ZetaScale集成工作，并分享了测试结果。 三、决定的事项 继续优化RocksDB和BlueStore。 对异步消息传递进行更多测试和评估。 对ZetaScale集成工作进行更多研究。 四、后续行动计划 Alan将进一步完善slab containers的PR。 Sage将继续优化RocksDB和BlueStore。 Ben将调查文件描述符限制问题。 Igor将继续开发RDMA异步消息传递。 Ben将分享更多性能测试结果。 Sage将分享更多关于ZetaScale集成工作的信息。 五、其他 会议中提到了一些计算机科学/ceph相关领域英文原文的关键词，例如： slab containers memory fragmentation RDMA async messenger RocksDB compaction file descriptors ZetaScale","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-SEP-14 :: Ceph Performance Weekly","slug":"2016-SEP-14_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-SEP-14_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-SEP-14_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage, Ellen, Sam, Alan, Leo, Lucy, Ian, Marge, Aver等 会议主题： Ceph分布式存储项目进展及问题讨论 会议内容： 一、主要进展 Sage提交了新的编解码方案PR： 该方案基于Ellen和Sam的工作，经过初步评估，性能至少与之前方案相当，甚至可能更好。目前团队正在探讨如何将其集成到BlueStore中，并利用其优势。 Zipkin追踪工作取得进展： 相关PR已提交，主要基于现有工作，进一步优化了OSD中的map搜索。 Sharding性能提升： 上周合并的sharding extent map改进了小随机写入性能，与filestore相比，在5分钟测试中性能提高了约20-25%。但测试表明，性能在测试初期比后期好，可能需要进一步调查。 RocksDB空间使用增加： 随着随机写入到现有对象，RocksDB空间使用量逐渐增加，需要关注是否存在内存泄漏或空间使用不当的情况。 Bitmap分配器性能问题： 之前性能下降的问题已基本排除，目前团队正在重新测试并分析性能数据。 RocksDB分析工具： Ian提出开发一个简单的RocksDB分析工具，用于统计不同键空间的键数量和平均大小等数据，以便更好地了解内存使用情况。 二、讨论议题 Sharding性能问题： 需要进一步调查Sharding性能在测试初期比后期好的原因，可能需要调整shard大小或优化相关代码。 RocksDB空间使用问题： 需要分析RocksDB空间使用量增加的原因，并采取措施防止内存泄漏或空间使用不当。 Bitmap分配器性能问题： 需要重新测试并分析性能数据，找出性能下降的原因，并进行优化。 RocksDB分析工具： 开发一个简单的RocksDB分析工具，以便更好地了解内存使用情况。 三、行动计划 Sage继续优化编解码方案，并探讨其集成到BlueStore中的方法。 团队继续测试和优化Sharding性能，并关注空间使用情况。 团队重新测试并分析Bitmap分配器性能数据，找出性能下降的原因，并进行优化。 Ian开发RocksDB分析工具，以便更好地了解内存使用情况。 四、其他事项 Marge将合并漏查修复分支。 Aver将对漏查修复分支进行测试。 团队将继续关注RGW性能问题，并在适当的时候进行评估。 五、会议总结 本次会议讨论了Ceph分布式存储项目的最新进展和问题，并制定了相应的行动计划。团队将继续努力优化项目性能，并确保项目的稳定性和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-SEP-07 :: Ceph Performance Weekly","slug":"2016-SEP-07_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-SEP-07_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-SEP-07_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 会议地点： 线上会议 参会人员： Sage, Percival, Charlie, Omar, Adam, Rich, Alan, Sila, Ken, etc. 会议主题： 讨论Ceph项目中的优化工作，包括BlueStore的改进、编码优化、以及Page统计的优化。 关键细节： BlueStore改进： Sage在BlueStore的Short Extent Map方面取得了进展，并进行了相关演示。 P Odors的CRUSH优化为Straw带来了性能提升。 IO Engine for object store即将合并。 Canada end of it page更新。 编码优化： 探讨了使用Group Barrington编码进行空间优化，以减少数据冗余。 讨论了针对特定数据类型和应用场景进行编码优化的方法。 认为算法优化比微优化更重要，应优先考虑。 认为Page统计的优化是下一个空间优化的关键点。 Page统计优化： 讨论了将Page统计更新分成两部分，分别针对频繁更新和不频繁更新的字段。 认为可能需要使用merge operator来处理向后兼容性问题。 认为将Page统计更新分割成单独的数据结构可能是一个可行的方案。 讨论的主要议题： 如何优化BlueStore的性能。 如何进行编码优化以减少数据冗余。 如何优化Page统计以减少空间占用。 决定的事项： Sage将审查P Odors的CRUSH优化代码，并与Sam一起审查。 将进行BlueStore的Short Extent Map的测试。 将进行Page统计的优化工作，并考虑使用merge operator来处理向后兼容性问题。 后续行动计划： Sage将审查P Odors的CRUSH优化代码，并与Sam一起审查。 进行BlueStore的Short Extent Map的测试。 进行Page统计的优化工作，并考虑使用merge operator来处理向后兼容性问题。 探索使用Group Barrington编码进行空间优化的方法。 分析Page统计中频繁更新和不频繁更新的字段，并考虑将其分割成单独的数据结构。 其他事项： 确定了Page统计中的一些字段可能不需要在每次事务中进行更新，可以懒加载或使用不同的数据结构进行处理。 认为将编码优化和Page统计优化进行排序，优先处理已知可以带来性能提升的优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-SEP-21 :: Ceph Performance Weekly","slug":"2016-SEP-21_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-SEP-21_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-SEP-21_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Mark、Sage、Paige、David、Peter、Nick、Ben、Josh等 会议主题： Ceph项目进展报告 Pull Requests讨论 性能优化 测试与监控 会议内容： 1. Pull Requests进展 Sage介绍了两个新的压缩Pull Requests，其中Igor的Pull Request已经完成审查并准备进行QA测试。 Paige提交了一个Pull Request，旨在减少在脏元数据写入时写入的数据量。 David的Pull Request旨在减少深度清理对正常操作的影响。 Sage提到FIO引擎已合并，可用于进行Blue Store测试和其他对象存储测试。 Sage还提到Fast Dean代码已经通过初步的功能和性能测试，预计将很快合并。 2. 性能优化 Mark指出，随机读取性能出现了50%的回归，经过分析发现是由于合并了默认ASIC Messenger导致的。 Sage提到Blue Store性能有所提升，这得益于编码/解码工作以及减少数据传输的工作。 Sage指出，除了异步Messenger之外，剩余的主要问题是顺序读取性能，需要进一步关注。 Sage还提到，在bitmap alligator中，阻塞降速是一个值得关注的问题。 3. 测试与监控 Nick分享了新的测试结果，包括不同大小的OSD节点所需的CPU资源。 Sage提到，CBT（Ceph Benchmarking Tool）将开始添加更多关于恢复的数据点，例如恢复的不同阶段、出现时间等。 Ben提到，他正在为CBT开发一个更可配置的监控框架，以支持不同的监控工具。 Josh提到，他正在研究将CBT的恢复功能与新的监控框架相结合。 4. 其他 Sage建议将CBT的代码库拆分，以减少连接问题并提高性能。 Sage提到，CBT的基准测试需要改进，以支持更复杂的测试场景。 行动计划： Sage将继续跟进Pull Requests的审查和测试工作。 Sage将继续关注性能优化问题，并寻找解决方案。 Nick将继续进行测试工作。 Ben将完成CBT监控框架的开发工作。 Josh将研究CBT与新的监控框架的结合。 下次会议： 预计下周将合并新的编码/解码代码，并了解更多关于异步Messenger的信息。 备注： 会议中提到了一些Ceph相关领域的英文关键词，例如Pull Requests、FIO、Blue Store、ASIC Messenger、bitmap alligator、CBT等。 会议纪要中保留了部分关键词的英文原文。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-SEP-28 :: Ceph Performance Weekly","slug":"2016-SEP-28_-_-_Ceph_Performance_Weekly","date":"2017-01-10T16:00:00.000Z","updated":"2017-01-11T16:00:00.000Z","comments":true,"path":"2017/01/11/2016-SEP-28_-_-_Ceph_Performance_Weekly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2017/01/11/2016-SEP-28_-_-_Ceph_Performance_Weekly/","excerpt":"","text":"会议纪要 会议时间： [未提供具体时间] 参会人员： [未提供具体人员姓名] 会议主题： Ceph分布式存储项目进展、内存管理讨论、性能优化议题 会议内容： 一、Ceph项目进展 代码提交与Pull Requests： 项目本周提交了大量Pull Requests，包括bug修复、性能提升等。 重点提及了以下PR： 优化部分重叠blob的垃圾收集，减少读取和写入开销。 Sages ER，降低频繁更新某些PG和protease stat的更新量。 使用RocksDB TV迭代器代替自定义范围迭代器，提高性能。 将blue store的key vsync线程拆分为两部分，提高随机读写性能。 将guard搜索从线性搜索改为二分搜索，提高效率。 测试与回归： 最近版本的Pull Request中存在 aged random reads 或 aged system 的随机读写性能下降问题，需要进一步调查和修复。 其他一些Pull Requests被其他工作替代或关闭。 二、内存管理讨论 Ice Age项目： 讨论了Ice Age项目的内存管理需求，包括如何进行内存预算分配和资源管理。 提出使用Ceph可配置参数来定义RocksDB的内存使用量，并根据总缓存大小进行动态调整。 讨论了OSD中PG日志的内存使用情况和MDS的内存管理问题。 内存分配器： 讨论了是否需要编写自定义内存分配器，以及如何进行内存统计和资源管理。 提出使用现有的内存分配器，并添加一层会计功能来跟踪内存使用情况。 讨论了使用原子操作和线程本地存储来优化内存分配和释放的效率。 三、性能优化 Fast Info： Fast Info功能已准备好进行测试，预计将显著减少元数据负载。 Aged Random Read Regression： 需要调查最近版本Pull Request中 aged random read 或 aged system 的随机读写性能下降问题。 异步消息传递： 讨论了异步消息传递的性能问题，并提出了可能的优化方案。 四、后续行动计划 继续讨论Ice Age项目的内存管理方案。 调查aged random read regression问题。 优化异步消息传递的性能。 继续进行性能测试和代码审查。 五、其他事项 讨论了使用现有的内存分配器，并添加一层会计功能来优化内存管理。 讨论了使用原子操作和线程本地存储来提高内存分配和释放的效率。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-OCT-05 :: Ceph Developer Monthly","slug":"2016-OCT-05_-_-_Ceph_Developer_Monthly","date":"2016-10-17T16:00:00.000Z","updated":"2016-10-18T16:00:00.000Z","comments":true,"path":"2016/10/18/2016-OCT-05_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/10/18/2016-OCT-05_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Sage、Adam、Erika、Nitin、Josh等 会议主题： 分布式存储Ceph的开发进展、讨论议题及后续行动计划 一、主要议题 内存池分配器信息 Sage介绍了新的内存池分配器，通过宏定义实现对象在正确内存池中的分配，并支持在编译时开启调试模式以追踪对象分配情况。 该分配器旨在解决内存碎片化问题，并通过统计内存分配情况来实现内存压力管理。 目前已将部分类型转换为使用该分配器，并计划进行性能分析以确保没有引入额外开销。 Boost Pool和Slop Containers Sage提到Boost Pool和Slop Containers已基本准备好合并，它们使用了类似内存池分配器的技术。 合并后，需要确定在哪些地方使用它们以优化内存分配。 BD设备查询接口 Nitin介绍了为BD设备添加查询接口的计划，该接口将用于在RBD接口中查询BD设备的唯一ID等信息。 该接口的实现需要涉及libceph库、RBD类方法、OSD等方面的修改。 服务质量（QoS）更新 Josh介绍了使用DM Block算法实现QoS的计划，旨在为不同客户端提供服务质量保证。 目前主要关注区分背景I/O和客户端I/O，以及集群恢复过程中的I/O操作。 Erika正在对该算法进行性能测试，并计划分享测试结果。 二、决定事项 继续推进内存池分配器的开发，并进行性能分析。 合并Boost Pool和Slop Containers，并确定使用场景。 推进BD设备查询接口的开发。 继续推进QoS算法的开发，并进行性能测试。 三、后续行动计划 Sage负责内存池分配器的性能分析。 Sage和Boost Pool/Slop Containers的开发者确定使用场景。 Nitin负责BD设备查询接口的开发。 Erika和Josh继续推进QoS算法的开发和性能测试。 四、其他事项 会议将持续关注蓝鲸存储（Blue Store）的开发进展。 鼓励开发者积极参与蓝图讨论，并提前在Wiki上进行讨论。 五、下次会议 下次SEF开发者月度会议将于2023年11月2日举行，时间为东部时间晚上9点。会议将重点关注蓝图讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-SEP-07 :: Ceph Developer Monthly","slug":"2016-SEP-07_-_-_Ceph_Developer_Monthly","date":"2016-09-07T16:00:00.000Z","updated":"2016-09-07T16:00:00.000Z","comments":true,"path":"2016/09/08/2016-SEP-07_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/09/08/2016-SEP-07_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年10月（具体日期未提及） 会议主题： Ceph开发者月度会议 参会人员： Jeans、Sage、Victor、Jason、Marcus、Dan、Alfredo、Basam、Vera、Sam等 会议内容： 一、RBD快照和一致性组 Sage提出了RBD快照和一致性组的设计方案，包括： 在现有快照设计中添加“快照类型”字段，以区分用户快照和一致性组快照。 在图像类中添加“快照创建”函数，并添加“快照类型”参数，以指定创建的是用户快照还是一致性组快照。 创建内部函数“创建图像快照”和“创建一致性组快照”，以支持并行创建快照。 添加“获取快照ID”、“获取图像ID”和“获取快照信息”等功能，以方便用户获取快照信息。 讨论了以下问题： 如何处理快照创建过程中的异常情况，例如无法打开图像或获取独占锁失败。 如何处理快照创建失败的情况，例如部分快照已创建但无法提交。 如何区分用户快照和一致性组快照，以及如何处理命名冲突。 二、Kerberos认证 讨论了使用Kerberos进行Ceph集群认证的方案，包括： 定义新的认证类型“Kerberos 5”，直接与libkrb5库交互。 在监控器中实现认证逻辑，将用户身份映射到Ceph用户数据库。 考虑使用“混合令牌”机制，将用户身份与Ceph身份结合。 讨论了以下问题： 使用Kerberos认证的必要性。 Kerberos与其他认证方式的兼容性。 Kerberos认证的配置和管理。 三、simd指令集检测 Basam提出了在EC库中实现simd指令集检测的方案，以支持不同处理器的优化。 讨论了以下问题： 如何实现simd指令集检测。 如何处理不同指令集之间的兼容性问题。 如何迁移现有集群以使用新的simd指令集。 四、其他议题 讨论了以下议题： Messenger 2计划。 Seth deploy、Seth anible和Seth installer的更新计划。 新的编码和解码功能。 AutoMake的升级。 行动计划： Sage将进一步完善RBD快照和一致性组的设计方案，并与团队讨论细节。 Dan将负责Kerberos认证的实现。 Basam将负责simd指令集检测的实现。 其他团队成员将继续推进各自的工作计划。 后续会议： 下次Ceph开发者月度会议将于2023年10月5日举行。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-AUG-25 -- Ceph Tech Talk: Unified CI","slug":"2016-AUG-25_--_Ceph_Tech_Talk_-_Unified_CI","date":"2016-08-31T16:00:00.000Z","updated":"2016-09-01T16:00:00.000Z","comments":true,"path":"2016/09/01/2016-AUG-25_--_Ceph_Tech_Talk_-_Unified_CI/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/09/01/2016-AUG-25_--_Ceph_Tech_Talk_-_Unified_CI/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储的构建和发布流程优化 参会人员： Alfredo Lisa，其他相关人员 会议内容： 一、会议背景 Alfredo Lisa 自过去一年半以来负责 Ceph 的构建和发布工作。 早期使用 Jenkins 进行构建，但随着团队和贡献者数量的增长，构建流程变得复杂，效率低下。 二、当前构建系统存在的问题 构建效率低下： 每次构建都需要花费数天时间，难以满足需求。 可扩展性差： 现有的构建系统难以扩展，无法支持更多构建任务。 构建过程复杂： 构建过程涉及许多环节，难以自动化。 依赖管理问题： 依赖管理不透明，难以跟踪和管理。 资源管理问题： 构建资源管理困难，难以应对资源故障。 三、优化方案 基于 Jenkins 的构建系统： 优化 Jenkins 构建任务，提高构建效率。 弹性扩展： 利用 Docker 容器和 Kubernetes 进行弹性扩展，满足更多构建任务的需求。 自动化构建： 实现构建过程的自动化，减少人工干预。 依赖管理： 使用 Nexus 或 Artifactory 等工具进行依赖管理，提高透明度。 资源管理： 使用 Ansible 等工具进行资源管理，提高资源利用率。 四、关键技术和工具 Jenkins： 用于自动化构建任务。 Docker： 用于容器化构建环境。 Kubernetes： 用于容器编排和弹性扩展。 Nexus 或 Artifactory： 用于依赖管理。 Ansible： 用于资源管理。 五、后续行动计划 完成构建系统的优化和部署。 与相关团队合作，实现构建过程的自动化。 开发依赖管理和资源管理工具。 制定文档和培训材料，提高团队对构建系统的使用效率。 六、会议总结 本次会议讨论了 Ceph 构建和发布流程的优化方案，明确了后续行动计划。通过优化构建系统，可以提高构建效率，降低成本，提高资源利用率，从而提升 Ceph 的开发效率和产品质量。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-AUG-03 :: Ceph Developer Monthly","slug":"2016-AUG-03_-_-_Ceph_Developer_Monthly","date":"2016-08-02T16:00:00.000Z","updated":"2016-08-03T16:00:00.000Z","comments":true,"path":"2016/08/03/2016-AUG-03_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/08/03/2016-AUG-03_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议时间： 2023年11月（具体日期未提及） 会议主题： Ceph 社区开发者月度会议 参会人员： Alan Samuels（SanDisk）、Michael Silla（UCSC）、Jason、John、Sam、Marcel、David 等 会议内容： 1. 新的编码/解码框架和 Blue Store onode 序列化 Alan Samuels 介绍了新的编码/解码框架和 Blue Store onode 序列化改进，旨在降低 CPU 成本和提高性能。 通过优化缓冲区操作和迭代器，减少代码层级和冗余，从而减少编码/解码过程中的开销。 引入标志位来指示常见的优化，例如无空洞或所有数据都在一个物理扩展中。 对物理扩展的引用进行优化，减少序列化过程中的冗余，从而降低存储空间需求。 2. MDS 元数据负载均衡器（Mantle） Michael Silla 介绍了 Mantle，一种用于 MDS 元数据负载均衡器的设计。 Mantle 通过 Lua 脚本注入来控制负载均衡策略，将策略与机制分离。 设计文档和代码已发布在 Etherpad 上，社区成员可进行讨论和反馈。 Mantle 使用 Lua 作为脚本语言，可灵活地更改负载均衡策略。 Mantle 目前处于实验阶段，不建议在生产环境中使用。 3. RBD 镜像横向扩展 Jason 介绍了 RBD 镜像横向扩展的方案，旨在提高高可用性和横向扩展性。 方案分为三个阶段： 第一阶段：实现活动/被动故障转移，通过锁机制实现高可用性。 第二阶段：实现每图像横向扩展，通过 RPC 消息分配负载。 第三阶段：实现热点能力扩展，通过收集指标来平衡负载。 方案旨在提高 RBD 镜像的可靠性和性能。 4. RBD 客户端持久缓存 Jason 介绍了 RBD 客户端持久缓存的设计，旨在将负载从集群卸载到本地缓存。 缓存可以存储读取和写入数据，并支持克隆图像的共享读取缓存。 缓存使用稀疏文件或 Blue Store 实例来存储数据。 缓存管理器负责分配缓存槽位和垃圾回收。 5. Manager 和 PG 状态 John 介绍了 Manager 和 PG 状态的进展。 Manager 是一个可选组件，用于存储 PG 状态和统计信息。 PG 状态将在 Luminous 版本中从 Monitor 移动到 Manager。 Kraken 版本中将提供实验性的 Manager 支持。 6. EC 覆写 Sam 介绍了 EC 覆写的进展。 工作正在进行中，包括持久化缺失集合、缓存和哈希基础设施更改。 代码重构正在进行中，以提高代码的可维护性和可读性。 7. DDO Marcel 介绍了 DDO（数据去重）的进展。 已完成 Python 原型，并计划将其重写为 C++。 DDO 可用于存储内容地址对象，并具有数据去重功能。 8. 改进的 Scrub 接口 David 介绍了改进的 Scrub 接口，旨在提高错误报告的准确性。 通过比较每个分片的对象信息，可以更准确地识别损坏的对象。 提供了 JSON 输出，以便用户和脚本可以轻松地识别和修复损坏的对象。 后续行动计划： 社区成员继续讨论和反馈 Mantle 和 DDO 设计。 推进 RBD 镜像横向扩展和 RBD 客户端持久缓存的工作。 完成 Manager 和 PG 状态的迁移。 继续改进 EC 覆写和 DDO。 准备 Kraken 和 Luminous 版本的发布。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-JUN-23 -- Ceph Tech Talks: OpenATTIC","slug":"2016-JUN-23_--_Ceph_Tech_Talks_-_OpenATTIC","date":"2016-07-21T16:00:00.000Z","updated":"2016-07-22T16:00:00.000Z","comments":true,"path":"2016/07/22/2016-JUN-23_--_Ceph_Tech_Talks_-_OpenATTIC/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/07/22/2016-JUN-23_--_Ceph_Tech_Talks_-_OpenATTIC/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Lens Scrimer（Open Attic），会议主持人 会议主题： Open Attic与Ceph的集成 会议内容： Open Attic介绍： Open Attic是一个开源的存储管理平台，旨在简化企业级存储的部署和管理。 它支持多种存储协议和文件系统，包括NFS、iSCSI、CIFS和ZFS等。 Open Attic提供Web界面和RESTful API，方便用户进行管理和自动化。 Open Attic与Ceph的集成： Open Attic正在积极开发Ceph管理功能，以满足用户对大规模存储的需求。 集成工作主要集中在以下几个方面： Ceph集群管理： 使用Librados和LibRBD API进行集群管理，包括池、OSD和RBD的管理。 集群健康和性能监控： 使用Nagios和RRDtool进行监控，并提供图形化的仪表板。 自动化： 使用Saltstack进行远程节点管理，并支持自动化任务执行。 用户界面： 开发新的Ceph管理仪表板，提供更直观的用户体验。 开发计划： Open Attic将继续每月发布新版本，并逐步完善Ceph管理功能。 下周，Open Attic团队将与SUSE开发者一起进行Hack Week，专注于Ceph特定功能的开发。 欢迎用户反馈和建议，共同推动Open Attic的发展。 行动计划： Open Attic团队将继续开发Ceph管理功能，并定期发布新版本。 用户可以访问Open Attic官网和GitHub仓库，获取最新信息和代码。 用户可以参与Open Attic社区，提供反馈和建议。 关键词： Open Attic Ceph 分布式存储 存储管理 RESTful API Nagios RRDtool Saltstack Hack Week","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-JUN-21 -- Ceph Tech Talks: Bluestore","slug":"2016-JUN-21_--_Ceph_Tech_Talks_-_Bluestore","date":"2016-06-22T16:00:00.000Z","updated":"2016-06-22T16:00:00.000Z","comments":true,"path":"2016/06/23/2016-JUN-21_--_Ceph_Tech_Talks_-_Bluestore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/06/23/2016-JUN-21_--_Ceph_Tech_Talks_-_Bluestore/","excerpt":"","text":"会议纪要 会议时间： 2023年11月 (具体日期未提及) 会议主题： SEF Tech Talks - Blue Store 后端存储介绍 参会人员： Sage (主讲人) 及其他 SEF 团队成员 会议内容： 一、会议背景 SEF 是一个可扩展、高性能的分布式存储系统，提供对象、块和文件存储接口。 SEF 的存储后端是 Rados，它使用文件系统来存储数据。 传统的文件存储方式存在性能瓶颈和复杂性，因此需要新的存储后端。 二、讨论的主要议题 文件存储的局限性： POSIX 接口限制，无法提供原子性事务。 文件系统遍历效率低，不适合大量对象存储。 需要使用复杂的目录结构来模拟对象存储。 新存储 (New Store)： 使用 RocksDB 作为键值数据库来存储元数据。 对象数据存储在 POSIX 文件中。 存在日志和文件系统日志的双重开销，性能不佳。 蓝存储 (Blue Store)： 结合了新存储和块设备的特点。 使用 RocksDB 存储元数据。 对象数据直接写入块设备。 提供原子性事务、高效的对象枚举、克隆和压缩功能。 三、决定的事项 将 Blue Store 作为 Rados 的候选存储后端。 在 Jewel 和最新 master 版本中提供 Blue Store 的实验性支持。 进行性能测试和优化。 将 Blue Store 集成到 Kraken 版本中，作为默认存储后端。 四、后续行动计划 完善元数据编码效率。 支持 ZetaScale 作为 RocksDB 的替代方案。 优化压缩和检查和功能。 添加池级别属性，支持不同的数据存储策略。 开发 SMR 硬盘支持。 支持 SPDK，优化 NVMe 设备性能。 五、关键术语 SEF (Seth) Rados RocksDB POSIX Blue Store New Store 原子性事务 对象枚举 克隆 压缩 检查和 六、总结 Blue Store 是 SEF 的新存储后端，它提供了更高的性能、更低的复杂性以及丰富的功能。Blue Store 将在未来的版本中得到进一步的开发和优化，并最终成为 SEF 的默认存储后端。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-JUN-01 -- Ceph Developer Monthly","slug":"2016-JUN-01_--_Ceph_Developer_Monthly","date":"2016-06-01T16:00:00.000Z","updated":"2016-06-02T16:00:00.000Z","comments":true,"path":"2016/06/02/2016-JUN-01_--_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/06/02/2016-JUN-01_--_Ceph_Developer_Monthly/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Sage, Marcus, Yuda, Greg, John, Sam 等 会议主题： Blue Store 缓存设计 Messenger 2 协议 一、Blue Store 缓存设计 讨论要点： I/O 路径更新： 自 Juwel 版本发布以来，I/O 路径已完全重写，元数据结构略有不同，引入了逻辑引用和 Blob，Blob 可压缩或非压缩，可能包含校验数据。 缓存设计： Blue Store 需要高效地修剪，并管理自己的缓冲区缓存。主要问题是如何在 Blue Store 中实现缓存，以及使用哪种缓存替换算法。 缓存结构： 全局缓存： 简单易实现，但可能导致缓存争用和性能下降。 按集合缓存： 每个集合拥有独立的缓存，但需要额外的锁和复杂的缓存大小调整机制。 分片缓存： 将缓存分成多个分片，每个分片由不同的 CPU 核心访问，可以提高并发性和性能。 缓存替换算法： LRU 算法： 简单易实现，但可能导致热点数据被替换。 MultiQ 算法： 基于多个 LRU 列表，可以根据数据的热度进行分层，提高缓存利用率。 决定事项： 采用分片缓存结构。 使用 MultiQ 算法作为缓存替换算法。 后续行动计划： 完善缓存管理代码。 评估 MultiQ 算法的性能。 二、Messenger 2 协议 讨论要点： 降级攻击： 如何防止在 Exchange 中删除消息时影响加密等操作。 Calamari 项目： 讨论了 Calamari 项目的未来发展方向，包括与 Seth Manager 的集成。 协议设计： 签名： 在消息头中添加签名，以增强安全性。 协商： 客户端和服务器协商支持的协议版本和功能。 连接： 建立连接并进行身份验证。 消息传递： 交换消息。 断开连接： 断开连接并清理资源。 决定事项： 在消息头中添加签名。 客户端和服务器协商支持的协议版本和功能。 使用简洁的协议设计。 后续行动计划： 完善协议实现。 评估协议性能和安全性。 三、其他事项 讨论了其他一些议题，包括性能优化、安全性等。 总结： 本次会议讨论了 Blue Store 缓存设计和 Messenger 2 协议，并做出了相应的决策和行动计划。会议内容丰富，讨论深入，为后续工作奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-MAY-26 -- Ceph Tech Talks: Ceph Benchmarking Tool","slug":"2016-MAY-26_--_Ceph_Tech_Talks_-_Ceph_Benchmarking_Tool","date":"2016-05-26T16:00:00.000Z","updated":"2016-05-26T16:00:00.000Z","comments":true,"path":"2016/05/27/2016-MAY-26_--_Ceph_Tech_Talks_-_Ceph_Benchmarking_Tool/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/05/27/2016-MAY-26_--_Ceph_Tech_Talks_-_Ceph_Benchmarking_Tool/","excerpt":"","text":"会议纪要 会议主题： Ceph 基准测试工具（CBT）介绍 会议时间： 2023年5月（具体日期未提及） 参会人员： - 主讲人：Kyle Bader - 主持人：Patrick - 其他参会者 会议内容： 一、会议背景 自上次会议以来，已有几个月未进行面对面交流。 本次会议主要介绍 Ceph 基准测试工具（CBT）。 二、CBT 简介 CBT 是一个基于 Python 的基准测试框架，用于定义测试计划。 它不直接生成负载，而是通过并行 SSH 登录到系统中的不同客户端来执行不同的基准测试工具。 CBT 最初是上游工程基准测试工具，由 Mark Nelson 开发，现在被广泛用于 Ceph 社区。 三、CBT 架构 头节点： 负责配置集群、执行测试计划、收集数据。 客户端： 负责生成负载，可以是物理机、虚拟机或容器。 OSD 和 Monitor： Ceph 集群的常规组件。 四、支持的基准测试工具 RBD 基准测试： 使用 FIO 工具对 RBD 进行测试。 文件系统基准测试： 使用 FIO 工具对文件系统进行测试。 对象存储基准测试： 使用 ceph-bench 工具进行 S3 或 Swift 测试。 五、CBT 功能 自动创建集群。 测试不同配置的集群。 收集节点监控信息。 分析测试结果。 六、测试方法 网络测试： 使用 iperf 测试网络性能。 微基准测试： 运行多次迭代以建立标准偏差。 客户端扫描： 逐步增加客户端数量以确定最大吞吐量。 七、使用方法 定义测试计划（mo 文件）。 运行测试计划。 分析结果。 八、后续行动计划 修复 CBT 中的错误。 开发更强大的数据分析工具。 招募更多开发者参与 CBT 的开发。 九、其他 会议中提到了一些关于网络配置和 KVM 测试的注意事项。 会议最后介绍了 CBT 的邮件列表和 YouTube 频道。 十、会议总结 本次会议详细介绍了 CBT 的功能和用法，为 Ceph 社区提供了宝贵的参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Promo Video","slug":"Ceph_Promo_Video","date":"2016-03-29T16:00:00.000Z","updated":"2016-03-30T16:00:00.000Z","comments":true,"path":"2016/03/30/Ceph_Promo_Video/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/03/30/Ceph_Promo_Video/","excerpt":"","text":"会议纪要 会议主题： 介绍SAP（SimpliStor Extended Framework）分布式存储系统 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议内容： 一、背景介绍 随着科技的发展，数据存储需求呈爆炸式增长。传统的单功能专有存储系统已无法满足日益增长的需求。SAP系统应运而生，它将日常硬件与开源软件相结合，形成了一种新的存储范式。 二、SAP系统特点 智能高效： SAP系统采用先进的算法，如CRUSH，确保集群中硬件的最佳利用。 灵活扩展： 一个集群可支持对象、块和文件工作负载，满足所有数据存储需求。 自动均衡： SAP系统在集群发生变化时，能够自动智能地重新平衡数据，无需人工干预或大量数据迁移。 可伸缩性： SAP系统可水平扩展，满足从小型集群到数以亿计存储的需求。 高可靠性： SAP系统设计无单点故障，能够承受各种挑战。 开源免费： SAP系统开源免费，任何人都可以参与改进，以适应未来需求。 三、会议讨论 SAP系统的适用场景： 参会人员讨论了SAP系统在各个领域的应用，包括视频会议、大数据处理、云计算等。 SAP系统的优势： 与其他存储系统相比，SAP系统在智能、灵活、扩展性、可靠性等方面具有明显优势。 SAP系统的未来发展方向： 参会人员探讨了SAP系统在开源社区、技术创新等方面的未来发展方向。 四、决定事项 推广SAP系统，提高其在各领域的应用。 加强SAP系统的技术创新，提升系统性能和可靠性。 拓展SAP系统的开源社区，吸引更多开发者参与。 五、后续行动计划 制定SAP系统推广计划，包括培训、技术支持等。 组织SAP系统技术研讨会，分享最佳实践。 关注SAP系统开源社区动态，及时跟进技术发展。 关键词： 分布式存储、SAP、CRUSH、智能、灵活、扩展性、可靠性、开源、开源社区","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-MAR-02 :: Ceph Developer Monthly","slug":"2016-MAR-02_-_-_Ceph_Developer_Monthly","date":"2016-03-02T16:00:00.000Z","updated":"2016-03-03T16:00:00.000Z","comments":true,"path":"2016/03/03/2016-MAR-02_-_-_Ceph_Developer_Monthly/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/03/03/2016-MAR-02_-_-_Ceph_Developer_Monthly/","excerpt":"","text":"会议主题： Ceph 开发者月度会议（APAC 版） 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位 Ceph 开发者，包括 Sage、Marcus、Patrick、Noah 等。 会议内容： 1. 网络加密： 讨论了为 Ceph 添加网络加密的需求，特别是考虑到当前的政治气候。 提出通过扩展当前的消息协议来实现加密，使用现有的会话密钥进行加密。 讨论了加密对消息吞吐量的影响，以及如何利用处理器加速功能来提高加密效率。 将该功能建议添加到 Google 夏季代码项目中。 2. 同步消息协议： 介绍了新的同步消息协议设计，主要支持在后台处理消息。 讨论了该设计如何与 DPDK 和 liburing 等库集成，以实现高性能网络通信。 讨论了多 OSD 宿主机环境下的性能优化问题，以及如何避免锁竞争。 讨论了与现有异步消息协议的兼容性，以及如何逐步迁移。 3. 发布开发支持版本： 讨论了发布开发支持版本的流程，以及如何简化发布过程。 讨论了使用 Jenkins 构建 Ceph 软件包的可行性，以及如何与现有的 Git 构建器兼容。 4. Paddle 和 Pulpito： 讨论了为 Paddle 添加问题和评论字段的需求，以方便跟踪测试结果。 讨论了为 Pulpito 添加新的查询功能，以支持对特定 SHA 和作业描述的查询。 5. Lua 支持： 讨论了为 Ceph OSD 添加 Lua 支持的需求，以及如何确保安全性。 讨论了使用白名单机制来限制 Lua 类的加载，以及如何将 Lua 库打包成独立的软件包。 6. 其他事项： 讨论了 Ceph Jel 的状态，以及即将到来的 RC 版本。 介绍了 Ceph Hackathon 的相关信息，包括时间、地点和主题。 行动计划： Sage 将收集 Ceph Hackathon 的主题建议。 Marcus 将将同步消息协议的幻灯片发送给 Adam 和 Casey。 其他开发者将继续推进各自的开发工作。 会议总结： 本次会议讨论了多个 Ceph 开发相关的议题，包括网络加密、同步消息协议、发布流程、Paddle 和 Pulpito、Lua 支持等。与会者就相关议题进行了深入讨论，并制定了后续的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-FEB-25 -- Ceph Tech Talks: CephFS","slug":"2016-FEB-25_--_Ceph_Tech_Talks_-_CephFS","date":"2016-02-24T16:00:00.000Z","updated":"2016-02-25T16:00:00.000Z","comments":true,"path":"2016/02/25/2016-FEB-25_--_Ceph_Tech_Talks_-_CephFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/02/25/2016-FEB-25_--_Ceph_Tech_Talks_-_CephFS/","excerpt":"","text":"会议纪要 会议主题： SEFS（Ceph 文件系统）更新及未来规划 会议时间： 2016年第二季度 参会人员： SEFS 开发人员、技术爱好者 会议内容： 一、会议回顾 上次会议回顾：上次会议探讨了使用 Postgres、Aurora 和 Docker 在 Ceph 上的应用。 本次会议重点：SEFS 更新，预计将是下一个主要版本 Jewel 的最后一个重要更新。 二、SEFS 简介 SEFS 是 Ceph 文件系统接口，是 Ceph 集群提供的三个应用程序接口之一。 SEFS 是 POSIX 文件系统，提供比传统 NFS 或 SMB 文件系统更高的数据一致性。 SEFS 将数据直接存储在 Rados 集群中，无需通过任何中间服务器。 三、SEFS 新特性 文件系统擦除和修复： 新增擦除和修复工具，用于检测和修复元数据损坏，例如对象丢失或损坏。 提供在线和离线修复功能，以应对不同类型的损坏。 旨在提高 SEFS 的稳定性和可靠性，使其更适合生产环境。 改进的授权： 扩展了授权功能，允许更细粒度地控制客户端对元数据的访问权限。 可以限制客户端只能访问特定路径或使用特定用户 ID。 改进的文件布局： 支持将文件指向特定的 Rados 命名空间，从而实现更细粒度的数据隔离。 与 OpenStack Manila 集成，提供共享文件系统功能。 多个文件系统： 支持在单个 Ceph 集群中创建多个文件系统，以提高可扩展性和容错性。 可用于隔离工作负载、灾难恢复或提高可靠性。 四、后续行动计划 继续改进 SEFS 的稳定性和可靠性。 完善多文件系统功能，包括元数据命名空间和授权。 推进 SEFS 与 OpenStack Manila 的集成。 鼓励用户评估和测试 SEFS，并提供反馈。 五、会议总结 本次会议介绍了 SEFS 的新特性和未来规划，展示了 SEFS 在文件存储领域的潜力和发展前景。SEFS 的不断改进将为用户提供更稳定、可靠和可扩展的文件存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2016-JAN-26 -- Ceph Tech Talks: High-Performance Production Databases on Ceph","slug":"2016-JAN-26_--_Ceph_Tech_Talks_-_High-Performance_Production_Databases_on_Ceph","date":"2016-01-27T16:00:00.000Z","updated":"2016-01-28T16:00:00.000Z","comments":true,"path":"2016/01/28/2016-JAN-26_--_Ceph_Tech_Talks_-_High-Performance_Production_Databases_on_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2016/01/28/2016-JAN-26_--_Ceph_Tech_Talks_-_High-Performance_Production_Databases_on_Ceph/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知 会议主题： 高性能数据库在Ceph上的运行实践 会议内容： 公司背景： Medallia公司自2010年起，从70名员工发展到700名，致力于为全球客户提供实时数据分析服务。 问题与挑战： 现有数据库部署在数百台服务器上，服务器配置分散，缺乏统一管理。 数据库服务器维护成本高，升级风险大。 需要构建一个可扩展、高可用、高性能的数据库平台。 解决方案： 采用Ceph作为存储层，实现数据存储的可靠性和可扩展性。 使用Docker进行容器化部署，简化运维流程。 利用OpenStack进行资源调度和自动化部署。 实现网络自动化，降低网络故障风险。 关键技术： Ceph： 作为分布式存储系统，提供高可用、可扩展的存储服务。 Docker： 实现应用容器化，简化部署和运维。 OpenStack： 实现资源管理和自动化部署。 OSPF： 实现网络自动化和IP地址管理。 Flocker： 实现容器存储的持久化和迁移。 性能测试： 网络延迟：约5微秒。 单流TCP性能：22或38 Gbps。 多流TCP性能：接近40 Gbps。 单流I/O性能：550 MB/s。 多流I/O性能：接近4 GB/s。 未来计划： 推出基于Ceph的数据库容器化解决方案。 优化性能，降低延迟。 推广开源技术。 行动计划： 完成基于Ceph的数据库容器化解决方案。 优化性能，降低延迟。 推广开源技术。 会议总结： Medallia公司通过采用Ceph、Docker、OpenStack等开源技术，成功构建了一个高性能、高可用的数据库平台。该平台具有以下特点： 高可用： 数据存储在Ceph集群中，实现数据冗余和故障转移。 可扩展： 可根据需求动态添加节点，提高性能和容量。 高性能： 网络延迟低，I/O性能高。 易于运维： 自动化部署和运维，降低运维成本。 该方案为其他企业构建高性能数据库平台提供了参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Melbourne Promo","slug":"Ceph_Day_Melbourne_Promo","date":"2015-11-16T16:00:00.000Z","updated":"2015-11-16T16:00:00.000Z","comments":true,"path":"2015/11/17/Ceph_Day_Melbourne_Promo/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/17/Ceph_Day_Melbourne_Promo/","excerpt":"","text":"会议纪要 会议主题： Ceph社区交流与备份存储性能提升探讨 会议时间： 2023年[具体日期] 会议地点： IMATS ft 和 Monash University in Melbourne 参会人员： - Patrick McGarry：Ceph社区总监，负责Ceph上游社区相关事务 - Brad Hubbub：Red Hat支持交付部门员工 - Steve Gwinnett：Monash大学研究部副总监 会议内容： 背景介绍： 会议由Monash大学组织，旨在探讨Ceph社区及备份存储性能提升。 Patrick McGarry介绍了Ceph社区的现状和参与方式，强调了社区在邮件列表、故障排除方面的互动。 Ceph社区体验： 参会者分享了在Ceph社区中的体验，普遍认为社区非常友好，提供了丰富的交流平台和问题解答渠道。 Steve Gwinnett表示，Ceph社区非常欢迎新成员，论坛等交流平台让参与者能够互相交流、提问。 Monash大学Ceph部署情况： Monash大学正在部署Ceph备份存储，旨在提升存储性能。 参会者表示，Ceph在存储 consolidation 方面表现出色，能够支持多种应用。 讨论议题： 如何进一步提升Ceph备份存储的性能？ 如何加强Ceph社区的互动与合作？ 行动计划： Monash大学将继续优化Ceph备份存储配置，探索性能提升方案。 Ceph社区将加强内部交流，提升社区活跃度。 关键词： Ceph社区、备份存储、性能提升、存储 consolidation、邮件列表、故障排除","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Brad Hubbard -- Troubleshooting Ceph","slug":"Brad_Hubbard_--_Troubleshooting_Ceph","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Brad_Hubbard_--_Troubleshooting_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Brad_Hubbard_--_Troubleshooting_Ceph/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： Brad (Red Hat 支持团队)，Andrew (主持人)，以及其他相关团队成员 会议主题： Ceph 分布式存储系统中 SEF (Simplified Erasure Coding) 问题调试 会议内容： 一、性能问题 性能基准： 建立性能基准对于了解性能下降至关重要。可以使用以下工具进行基准测试： rados bench：用于快速基准测试。 ost bench：对每个 OSD 的存储进行简单的写入基准测试。 librados：Ceph 存储引擎，可使用 librbd 直接与存储通信。 prroute：测试网络段，包括公共网络、集群网络、OSD 客户端等。 DD：测试吞吐量。 PCP：收集系统统计信息。 SEF benchmarking tool：正在开发中的工具，可运行所有内部操作并捕获统计信息。 性能下降： 如果出现性能下降，请确保集群健康，并使用以下工具进行检查： gore：检查日志中的警告或错误。 slow requests：检查长时间请求。 perf：收集性能计数器。 perf dump：收集性能计数器。 二、挂起 挂起检测： 使用 strace 和 ps 检测挂起进程。 线程状态： 使用 strace 检查线程状态，确保所有线程都在前进。 堆栈跟踪： 使用 gdb 脚本或系统 tap 探针获取运行程序的详细信息。 三、崩溃 崩溃日志： 查看崩溃日志以获取有关崩溃的详细信息。 assertion： 查找崩溃日志中的 assertion 信息，了解崩溃原因。 内存访问错误： 查找内存访问错误，并提交 bug 报告。 四、意外行为 行为分析： 分析预期行为和实际行为之间的差异。 日志分析： 分析日志，查找错误或异常。 调试日志： 使用调试日志选项获取更多详细信息。 五、其他资源 Ceph 社区： 在邮件列表或 IRC 频道寻求帮助。 Ceph bug 跟踪器： 查找已知问题。 Ceph 文档： 查阅 Ceph 文档和调试文档。 Red Hat 知识库： 联系 Red Hat 支持团队。 行动计划： 建立性能基准： 使用相关工具建立性能基准。 监控性能： 定期监控性能，确保集群健康。 分析问题： 当出现问题时，分析问题原因并采取措施解决。 学习资源： 学习 Ceph 文档和调试资源，提高问题调试能力。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ceph Day Melbourne Roundtable Q&A","slug":"Ceph_Day_Melbourne_Roundtable_Q_A","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Ceph_Day_Melbourne_Roundtable_Q_A/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Ceph_Day_Melbourne_Roundtable_Q_A/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储系统讨论会 会议时间： 2023年11月（具体日期未提及） 参会人员： Ceph 开发者、用户、技术专家等 会议内容： 1. 损坏编码（Erasure Coding） 讨论了损坏编码中奇偶校验块的数量，以及如何确定最佳配置。 强调了在不同存储介质（如闪存）上的性能差异。 讨论了地理复制（Geo Replication）和异步复制（Asynchronous Replication）在实现高可用性和性能方面的作用。 2. 地理复制（Geo Replication） 讨论了在真实公共互联网上进行地理复制的情况。 提到了一些正在尝试地理复制的组织，例如马来西亚政府。 讨论了如何实现最终一致性（Eventual Consistency）以及如何选择合适的工作负载。 3. 多租户（Multi-tenancy）和命名空间 讨论了多租户和命名空间在 Ceph 中的实现，以及如何隔离不同用户或应用程序的数据。 强调了安全性和性能方面的挑战。 4. Ceph 存储集群的配置 讨论了如何配置 Ceph 存储集群以处理不同类型的工作负载，例如对象存储、块设备存储和文件系统存储。 强调了 Ceph 架构的优势，例如并行化工作负载和灵活的配置选项。 5. Ceph 的监控和管理 讨论了 Ceph 的监控和管理工具，例如 Calamari、Roma 和 USM。 强调了社区开发工具的重要性，以及如何选择合适的工具。 6. 自动化部署 讨论了 Ceph 的自动化部署工具，例如 Ceph Deploy 和其他编排工具（如 Puppet、Ansible 等）。 讨论了不同工具的优缺点，以及如何选择合适的工具。 后续行动计划： 继续开发和完善 Ceph 的监控和管理工具。 探索地理复制和最终一致性的实现。 支持更多用户和应用程序的多租户需求。 优化 Ceph 存储集群的配置和性能。 关键词： 损坏编码（Erasure Coding） 地理复制（Geo Replication） 多租户（Multi-tenancy） 命名空间（Namespaces） 监控和管理（Monitoring and Management） 自动化部署（Automation Deployment） Ceph Deploy Puppet Ansible","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Patrick McGarry -- Ceph Community Update","slug":"Patrick_McGarry_--_Ceph_Community_Update","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Patrick_McGarry_--_Ceph_Community_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Patrick_McGarry_--_Ceph_Community_Update/","excerpt":"","text":"会议纪要 会议时间： 2015年SEF Day 参会人员： Patrick（社区猴子，负责社区维护）、Gary（社区成员）、Red Hat及社区其他成员 会议内容： 一、社区发展 社区活动： SEF社区活动丰富，包括SEF Day、Hackathon等，明年计划举办更多活动。 社区指标： VectorGia公司提供的SEF指标平台，帮助社区了解性能、调优和硬件配置等信息。 用户委员会： 用户委员会由社区成员自发组织，负责社区基础设施、Meetup、Swag等事务。 Google Summer of Code： SEF社区已连续两年参与Google Summer of Code项目，为社区培养新人才。 ** Outreach Program**： SEF社区参与Outreach Program，帮助社区成员进行wiki迁移等任务。 二、技术发展 Ceph： SEF项目（Ceph）是一个开源的分布式存储系统，具有对象、块和文件存储功能。 Liberapay： SEF提供Liberapay库，可直接访问对象存储，提高性能并暴露一些酷炫的API。 Ceph S： Ceph S预计明年推出，为社区提供更多功能。 对象类： Ceph支持对象类，允许在存储节点上执行代码，例如图像缩略图处理、日志清理等。 部署和编排： SEF支持多种部署和编排框架，如Ansible、Chef、Puppet等，并支持Docker容器化。 测试集群： SEF社区提供公用的测试集群，方便社区成员进行测试。 三、治理 董事会： SEF社区成立董事会，由10名成员组成，负责社区治理。 项目领导： Sage为SEF项目领导，负责项目方向和技术决策。 非商业成员： 董事会包含非商业成员，代表用户、学术界和商业利益。 四、行动计划 举办更多社区活动： 计划举办更多SEF Day、Hackathon等活动。 优化社区指标平台： 完善SEF指标平台，提供更多性能和调优信息。 加强用户委员会建设： 支持用户委员会工作，提升社区服务质量。 推进Ceph S项目： 加快Ceph S项目开发，为社区提供更多功能。 完善对象类功能： 推广对象类功能，促进社区创新。 加强社区治理： 完善社区治理机制，确保社区健康发展。 五、其他 Ceph社区邮件列表： 欢迎社区成员加入Ceph社区邮件列表，参与社区讨论。 Ceph YouTube频道： 欢迎关注Ceph YouTube频道，获取最新社区资讯和技术分享。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Steve Quenette/Blair Bethwaite -- Servicing the Fabric and the Workshop","slug":"Steve_Quenette_Blair_Bethwaite_--_Servicing_the_Fabric_and_the_Workshop","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Steve_Quenette_Blair_Bethwaite_--_Servicing_the_Fabric_and_the_Workshop/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Steve_Quenette_Blair_Bethwaite_--_Servicing_the_Fabric_and_the_Workshop/","excerpt":"","text":"会议纪要 会议时间： （请在此处填写会议具体时间） 会议地点： （请在此处填写会议具体地点） 参会人员： （请在此处填写参会人员名单） 会议主题： 探讨ICT技术在科研和企业应用中的差异，以及如何通过Ceph等分布式存储技术实现大规模和性能提升。 关键细节： 科研与企业的ICT差异： 科研ICT更注重规模和性能，需要构建支持研究者构建事物的平台。 企业ICT更关注长尾用户，追求成本最低化。 科研ICT需要同时支持峰值用户和长尾用户。 渗透性： 渗透性指的是组织与外部组织互动，共同实现目标。 科研ICT需要具备渗透性，与其他组织合作，实现共同目标。 多学科研究： 多学科研究是科研的重要趋势，跨学科合作能带来突破性发现。 发现范式： 发现范式受技术驱动，经历了显微镜、物理定律、计算和大数据四个阶段。 第四范式以数据为中心，需要强大的计算和存储能力。 Ceph在科研中的应用： Ceph作为分布式存储技术，能够满足科研对规模和性能的需求。 Ceph支持自服务、多租户、质量服务等特性。 Ceph与OpenStack等软件定义存储技术结合，构建灵活的科研基础设施。 讨论的主要议题： 科研ICT与企业的ICT差异 渗透性在科研ICT中的应用 多学科研究对科研基础设施的需求 发现范式对科研技术的影响 Ceph在科研中的应用和挑战 决定的事项： 继续推进Ceph在科研中的应用，并解决相关挑战。 加强与OpenStack等软件定义存储技术的结合。 与其他组织合作，共同推动科研ICT的发展。 后续行动计划： 深入研究Ceph的性能优化和故障处理。 开发针对科研场景的Ceph解决方案。 推动Ceph社区发展，吸引更多科研机构加入。 其他： 会议中提到Ceph集群的部署和性能优化经验。 会议中讨论了Ceph与其他存储技术的比较。 会议中分享了一些科研ICT的案例。 关键词： ICT 科研 企业 Ceph 分布式存储 OpenStack 软件定义存储 渗透性 多学科研究 发现范式 规模 性能 自服务 多租户 质量服务","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Sudarshan Ramachandran -- When 10GbE is Not Enough","slug":"Sudarshan_Ramachandran_--_When_10GbE_is_Not_Enough","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Sudarshan_Ramachandran_--_When_10GbE_is_Not_Enough/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Sudarshan_Ramachandran_--_When_10GbE_is_Not_Enough/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 会议地点： [请填写具体地点] 参会人员： Sudha（Mellanox区域负责人）、市场营销团队、研发团队、IT团队 会议主题： Mellanox产品介绍及在存储领域的应用 会议内容： 一、Mellanox公司介绍 Mellanox是一家拥有约32,000名员工的以色列公司，总部位于美国，年收入约50亿美元，年增长率约40%。 Mellanox提供从网络适配器到交换机、线缆和硅芯片的端到端解决方案，支持10G、40G、25G、50G和Hunter G等速度。 Mellanox的产品广泛应用于高性能计算、云计算、Web 2.0、高频交易等领域。 二、Mellanox在存储领域的应用 Mellanox的产品在存储领域主要应用于高性能计算、云计算和Web 2.0等场景，旨在提高吞吐量、降低延迟和简化基础设施。 Mellanox的解决方案包括： 提供高带宽和低延迟的网络连接，提高IOPS和吞吐量。 简化基础设施，提高系统可靠性。 通过网络卸载技术，释放CPU资源，提高系统性能。 三、Mellanox产品介绍 Mellanox提供多种网络适配器、交换机和线缆，支持10G、40G、25G和50G等速度。 Mellanox的交换机具有低功耗、高线速、高可靠性等特点。 Mellanox的RDMA和RoCE技术可以将网络延迟降低到微秒级别，提高系统性能。 四、案例展示 会议中展示了Mellanox在OpenStack summit上的视频演示，展示了40G网络和RDMA技术在实际应用中的性能提升。 五、行动计划 Mellanox将继续加强与Ceph社区的沟通，推动RDMA和RoCE技术在Ceph中的应用。 Mellanox将提供更多的参考架构和解决方案，帮助用户构建高性能的Ceph存储系统。 六、讨论事项 参会人员就Mellanox产品在存储领域的应用进行了深入讨论，并提出了相关建议。 七、后续行动 Mellanox将根据会议讨论结果，进一步完善产品方案，并加强与Ceph社区的沟通合作。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Venkat Kolli -- Ceph on All-Flash Storage","slug":"Venkat_Kolli_--_Ceph_on_All-Flash_Storage","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Venkat_Kolli_--_Ceph_on_All-Flash_Storage/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Venkat_Kolli_--_Ceph_on_All-Flash_Storage/","excerpt":"","text":"会议纪要 会议时间： 未知 参会人员： Venkat Kali（Sandisk 产品经理）、Simon（负责产品相关问题）、Andrews（主持人）、其他与会人员 会议主题： Sandisk 无限闪存系统与 Ceph 的结合及优化 会议内容： 一、会议背景 Sandisk 于两年半前开始研发无限闪存系统，主要针对 Seth 和 OpenStack。 无限闪存系统旨在提供高性能、大容量的全闪存存储解决方案，特别适用于大数据、大媒体存储等场景。 二、无限闪存系统介绍 无限闪存系统采用 3U 机箱，可容纳 512TB 闪存。 系统基于 SAS 接口，提供高密度、高容量存储。 系统支持热插拔，具备高可靠性。 系统不包含服务器和计算资源，可与其他服务器连接。 三、Ceph 与无限闪存系统的结合 Sandisk 对 Ceph 进行了优化，使其在无限闪存系统上运行更加高效。 优化主要集中在数据路径、锁优化、队列优化等方面。 通过优化，Ceph 在无限闪存系统上的性能提升了 10 倍以上。 四、性能测试 Sandisk 对 Ceph 在无限闪存系统上的性能进行了测试，结果显示： 读取性能：约 250 万 IOPS 写入性能：约 100 万 IOPS 延迟：约 2 毫秒 测试结果表明，Ceph 在无限闪存系统上具有极高的性能。 五、未来计划 Sandisk 将继续优化 Ceph，使其在无限闪存系统上运行更加高效。 Sandisk 将与社区合作，推动 Ceph 在全闪存存储领域的应用。 Sandisk 将开源其开发的 Key-Value 存储引擎，并将其集成到 Ceph 中。 六、其他讨论 Sandisk 与 Mellanox 合作，优化 Ceph 的网络性能。 Sandisk 开发了新的 Key-Value 存储引擎，用于优化全闪存存储性能。 Sandisk 将提供 Ceph 的安装和配置工具，降低用户的使用门槛。 七、行动计划 Sandisk 将继续优化 Ceph，提升其在无限闪存系统上的性能。 Sandisk 将与社区合作，推动 Ceph 在全闪存存储领域的应用。 Sandisk 将开源其开发的 Key-Value 存储引擎，并将其集成到 Ceph 中。 八、会议总结 本次会议介绍了 Sandisk 无限闪存系统与 Ceph 的结合及优化情况，展示了 Ceph 在无限闪存系统上优异的性能。Sandisk 将继续优化 Ceph，推动其在全闪存存储领域的应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Tomohiko Kimura -- Walk Through a Software-Defined Everything PoC","slug":"Tomohiko_Kimura_--_Walk_Through_a_Software-Defined_Everything_PoC","date":"2015-11-12T16:00:00.000Z","updated":"2015-11-13T16:00:00.000Z","comments":true,"path":"2015/11/13/Tomohiko_Kimura_--_Walk_Through_a_Software-Defined_Everything_PoC/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/13/Tomohiko_Kimura_--_Walk_Through_a_Software-Defined_Everything_PoC/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： - Tamiko（软件定义网络和可视化专家） - Me Da Cunha（网络虚拟化代理开发工程师） - 其他参与者（未提及姓名） 会议主题： 本次会议主要讨论了使用软件定义网络（SDN）和OpenStack Newton环境进行的一次Proof of Concept（POC）项目，旨在实现计算、存储和网络资源的抽象化管理和自动化部署。 关键细节： 项目背景： 欧洲某大型学术研究实验室希望简化开发流程，实现资源的集中管理和监控，并提高开发效率。 技术选型： 软件定义网络：使用MidoNet实现网络虚拟化，分离控制平面和数据平面，提高网络的可扩展性和容错性。 存储系统：使用Ceph作为存储解决方案。 OpenStack管理平台：使用Red Hat OpenStack管理平台。 硬件管理：使用XCat进行硬件管理。 使用案例： 网络虚拟化：使用MidoNet创建虚拟网络，实现跨物理网络的隔离和连接。 存储虚拟化：使用Ceph实现存储虚拟化，提高存储资源的利用率。 OpenStack管理：使用OpenStack管理平台进行资源管理和自动化部署。 硬件管理：使用XCat进行硬件配置和监控。 经验和教训： 需要提前规划网络配置和IP地址分配等细节。 MidoNet和Ceph的配置比较复杂，需要一定的技术积累。 OpenStack和XCat的默认配置可能需要调整。 网络性能和存储性能需要根据实际情况进行优化。 主要议题： 软件定义网络的原理和应用。 MidoNet和Ceph的配置和使用。 OpenStack和XCat的集成。 网络性能和存储性能的优化。 决定的事项： 将POC项目的结果进行总结和分享。 对POC项目进行改进和优化。 推广软件定义网络和OpenStack技术的应用。 后续行动计划： 总结POC项目的经验和教训，形成文档。 优化POC项目的配置，提高性能和稳定性。 推广软件定义网络和OpenStack技术的应用，帮助更多企业实现数字化转型。 关键词： - 软件定义网络（SDN） - MidoNet - Ceph - OpenStack - XCat - 网络虚拟化 - 存储虚拟化 - 资源管理 - 自动化部署","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Samual Just -- Recovery erasure coding cache tiering","slug":"Samual_Just_--_Recovery_erasure_coding_cache_tiering","date":"2015-11-09T16:00:00.000Z","updated":"2015-11-10T16:00:00.000Z","comments":true,"path":"2015/11/10/Samual_Just_--_Recovery_erasure_coding_cache_tiering/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/11/10/Samual_Just_--_Recovery_erasure_coding_cache_tiering/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 会议地点： 线上会议 参会人员： Sam, Jeff, Reyes (PTL), 等其他相关人员 会议主题： Ceph存储系统技术讨论 会议内容： 一、Reyes集群介绍 Reyes集群架构： Reyes集群采用分布式存储架构，由多个OSD (Object Storage Device) 组成，OSD之间通过CRUSH算法进行数据分布和冗余。 Reyes集群特性： 支持强一致性，简化应用开发。 支持多种数据访问方式，包括RBD、Rados Gateway等。 支持用户自定义元数据。 支持对象存储和块存储。 支持数据迁移和备份。 二、数据分布和冗余 CRUSH算法： Reyes集群使用CRUSH算法进行数据分布和冗余，确保数据的高可用性和可靠性。 数据放置策略： Reyes集群支持多种数据放置策略，例如： 按数据类型放置：将不同类型的数据放置在不同的存储池中。 按性能需求放置：将需要高性能的数据放置在SSD上。 按访问频率放置：将经常访问的数据放置在更靠近客户端的存储池中。 三、故障处理 故障检测： Reyes集群通过心跳机制检测OSD的故障状态。 故障恢复： Reyes集群支持自动故障恢复，将故障OSD上的数据迁移到其他OSD上。 数据一致性： Reyes集群通过Raft协议保证数据一致性。 四、新特性介绍 缓存池： Reyes集群支持缓存池功能，将热点数据缓存到SSD上，提高系统性能。 快照： Reyes集群支持快照功能，可以创建数据的快照，方便数据备份和恢复。 克隆： Reyes集群支持克隆功能，可以创建数据的副本，方便数据备份和恢复。 五、讨论 Reyes集群与RBD的兼容性： Reyes集群与RBD完全兼容，可以无缝迁移RBD数据到Reyes集群。 缓存池的性能优化： 需要进一步优化缓存池的性能，提高系统性能。 快照和克隆的性能优化： 需要进一步优化快照和克隆的性能，提高系统效率。 六、行动计划 优化缓存池性能： 对缓存池进行性能优化，提高系统性能。 优化快照和克隆性能： 对快照和克隆进行性能优化，提高系统效率。 测试Reyes集群与RBD的兼容性： 测试Reyes集群与RBD的兼容性，确保数据无缝迁移。 七、其他 Reyes集群的稳定性测试： 对Reyes集群进行稳定性测试，确保系统稳定可靠。 Reyes集群的性能测试： 对Reyes集群进行性能测试，评估系统性能。 关键词： Reyes集群、CRUSH算法、数据分布、冗余、故障处理、缓存池、快照、克隆、RBD","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-SEP-24 -- Ceph Tech Talks: Reference Architectures","slug":"2015-SEP-24_--_Ceph_Tech_Talks_-_Reference_Architectures","date":"2015-09-23T16:00:00.000Z","updated":"2015-09-24T16:00:00.000Z","comments":true,"path":"2015/09/24/2015-SEP-24_--_Ceph_Tech_Talks_-_Reference_Architectures/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/09/24/2015-SEP-24_--_Ceph_Tech_Talks_-_Reference_Architectures/","excerpt":"","text":"会议纪要 会议时间： 2023年X月X日 会议主题： 构建SEF参考架构 参会人员： Brent Compton, Kyle Vader, Patrick等 会议内容： 一、会议背景 本次会议主要讨论了如何构建SEF参考架构，并分享了构建过程中的关键考虑因素和设计要点。 二、讨论的主要议题 构建参考架构的目的： 基于实证数据而非传闻回答客户关于软件定义存储的问题。 在合作伙伴实验室进行各种基准测试和负载测试，以获取数据来支持问题解答。 参考架构的构建模块： 分布式存储：网络是基础模块，10G以太网和40G以太网的使用对性能有显著影响。 存储服务器：近年来，基于x86的服务器类型和容量发生了爆炸式增长。 参考架构的类型： 基础架构：如性能和尺寸指南。 如何集成指南：如Red Hat Enterprise Linux OpenStack平台参考架构。 构建参考架构的考虑因素： 1. 扩展存储的需求： 确定是否需要扩展存储。 2. 设计工作负载I/O： 根据工作负载I/O模式（如IOPS优化、吞吐量优化、成本容量优化）进行设计。 3. 存储访问方法： 确定存储访问方法，如Rados块设备。 4. 识别容量： 确定容量需求，并考虑故障域风险。 5. 数据保护方案： 选择数据保护方案，如复制和纠错编码。 6. 服务器故障域： 确定服务器故障域，并确保最小服务器故障域推荐。 4x3矩阵： 用于识别针对不同工作负载I/O类别的候选架构。 包括IOPS优化、吞吐量优化、成本容量优化、读/写混合、纠错编码池与复制池等。 性能和尺寸指南： 主要关注性能和尺寸优化。 使用Rados、Fio和CIS基准测试工具进行测试。 发布了与Supermicro、Cisco和Scalable Informatics合作发布的性能和尺寸指南。 社区资源： 构建社区资源，如性能基准测试库和集群组成统计信息。 通过metric.se.com提供交互式格式。 三、决定的事项 继续关注性能和尺寸优化，并发布更多性能和尺寸指南。 建立社区资源，如性能基准测试库和集群组成统计信息。 与MySQL MariaDB社区合作，构建更高级的参考架构。 四、后续行动计划 发布更多性能和尺寸指南。 建立社区资源，如性能基准测试库和集群组成统计信息。 与MySQL MariaDB社区合作，构建更高级的参考架构。 收集社区反馈，改进参考架构和社区资源。 五、关键词 软件定义存储（SDS） 分布式存储 网络带宽 存储服务器 扩展存储 工作负载I/O 存储访问方法 容量 数据保护方案 服务器故障域 性能和尺寸优化 基准测试 社区资源","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-AUG-27 -- Ceph Tech Talks: Ceph Performance","slug":"2015-AUG-27_--_Ceph_Tech_Talks_-_Ceph_Performance","date":"2015-08-26T16:00:00.000Z","updated":"2015-08-27T16:00:00.000Z","comments":true,"path":"2015/08/27/2015-AUG-27_--_Ceph_Tech_Talks_-_Ceph_Performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/27/2015-AUG-27_--_Ceph_Tech_Talks_-_Ceph_Performance/","excerpt":"","text":"会议纪要： 会议时间： 2023年11月（具体日期未提及） 会议主题： Red Hat Ceph 社区技术研讨会，主题为 Ceph 性能调优 参会人员： Mark Nelson（Red Hat 首席性能工程师）、社区成员 会议内容： 会议背景： 本次会议为红帽 Ceph 社区技术研讨会，旨在深入探讨 Ceph 性能调优的相关技术。 Mark Nelson 将分享 Red Hat 在性能测试和调优方面的经验和最近的研究成果。 测试工具： Red Hat 使用多个工具进行性能测试，包括： Toothology： 夜间功能测试框架，用于运行回归测试和性能测试。 CBT： 轻量级性能基准测试工具，用于在已配置的节点上运行测试。 CollectL： 监控工具，用于收集性能统计数据。 Valgrind： 内存调试和分析工具。 Perf： 性能分析工具。 硬件环境： 红帽最近获得了来自英特尔的高性能节点，这些节点配备了 NVMe SSD，用于进行性能测试。 测试案例： 在最近的黑客松活动中，Red Hat 使用 CBT 在高性能集群上进行了测试，包括： 随机写、随机读、顺序写、顺序读、混合 I/O 测试。 小 I/O 测试（4KB）。 测试结果： 使用 Jemalloc 作为内存分配器可以显著提高性能，特别是在小 I/O 测试中。 Jemalloc 的内存占用比默认的 TCMalloc 高，但在恢复过程中可以更快地完成恢复操作。 需要进一步研究以降低内存占用或提高性能。 后续工作： Red Hat 将继续研究 Jemalloc 和 TCMalloc，以优化性能和内存占用。 将探索使用自定义内存分配器来提高性能。 将继续研究其他性能优化方法，例如 CPU 资源管理、缓存层优化等。 会议总结： 本次会议介绍了 Red Hat 在 Ceph 性能测试和调优方面的最新研究成果。通过使用各种工具和硬件环境，Red Hat 发现了 Jemalloc 可以显著提高性能，但也需要进一步研究以优化内存占用。Red Hat 将继续努力提高 Ceph 的性能，以满足用户的需求。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Cache Tiering","slug":"CDS_Jewel_--_Cache_Tiering","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Cache_Tiering/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Cache_Tiering/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： 线上会议 参会人员： Alan、Anja King（Intel）、Welt、Narendra、Sage、Mark、Sam等 会议主题： Ceph分布式存储缓存层优化及策略讨论 会议内容： 一、缓存层优化 缓存穿透问题： 针对缓存穿透问题，Sam提出了一种实验方案，即仅在11%的情况下进行缓存更新，以测量缓存未命中成本。 该方案发现，对于复制池的随机读取，性能表现良好，因为之前较差的性能是由于不必要的更新消耗了缓存吞吐量。 建议通过更明确地跟踪最近的操作，并分配一些内存来跟踪最近的操作，从而专注于频繁访问的对象。 由于缓存未命中集的粒度有限，建议添加一个队列NM r uq，并从该队列的头部触发sinker oceans，以控制更新的数量。 缓存驱逐算法优化： Alan和Anja King提出，当前的缓存驱逐算法基于对象年龄，导致驱逐决策不准确。 他们提出了以下改进方案： 使用时间戳来计算对象的年龄，并持久化到磁盘。 使用重用距离算法，根据对象访问的频率和间隔来计算驱逐决策。 使用最近最少使用（LRU）列表和重用距离算法来优化驱逐决策。 与会人员讨论了各种方案的优缺点，并认为LRU列表和重用距离算法是可行的解决方案。 二、策略引擎 Sandisk提出策略引擎： Sandisk提出了一个策略引擎，用于管理缓存层策略，并支持用户定义的缓存策略，例如驱逐和提升调度。 策略引擎将与RGW通信，以确定要执行的策略，并通过HTTP头部将策略应用于对象。 策略引擎将支持基于对象、存储桶、池和全局的规则。 三、后续行动计划 缓存穿透优化： Sam将根据讨论结果，进一步完善缓存穿透优化方案，并提交相关patch。 缓存驱逐算法优化： Alan和Anja King将根据讨论结果，选择合适的缓存驱逐算法优化方案，并提交相关patch。 策略引擎开发： Sandisk将根据讨论结果，进一步完善策略引擎设计方案，并提交相关patch。 持续讨论： 与会人员将继续在邮件列表和IRC上进行讨论，并跟踪相关patch的进展。 总结： 本次会议讨论了Ceph分布式存储缓存层优化和策略引擎开发的相关问题，并提出了多个可行的解决方案。与会人员将根据讨论结果，进一步完善相关方案，并提交相关patch。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- CephFS fsck progress","slug":"CDS_Jewel_--_CephFS_fsck_progress","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_CephFS_fsck_progress/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_CephFS_fsck_progress/","excerpt":"","text":"会议纪要 会议主题： 文件系统检查进度讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Johnson, Ellie, Patrick 等 会议内容： 1. 文件系统检查进度 Johnson汇报了文件系统检查和修复工具的进展，包括CFS数据扫描工具，该工具可以扫描数据池中的对象，并尝试从数据池中恢复元数据。 目前，该工具还处于开发阶段，需要进一步完善，包括处理快照、修复目录碎片等。 会议讨论了如何将新工具与现有系统集成，并提高其性能和可扩展性。 2. 修复工具 CFS数据扫描工具分为两个阶段：第一阶段是扫描数据池中的所有对象，并记录元数据；第二阶段是使用这些元数据来修复元数据树。 工具会尝试找到对象的反向跟踪，并利用这些信息来修复元数据树。 工具会记录修复过程中的错误，并提供一种机制来清理这些错误。 3. 元数据修复 会议讨论了如何处理元数据修复过程中的各种情况，例如： 处理目录碎片 处理快照 处理元数据树中的断开连接 会议提出了使用标记来标识已修复的inode，并使用这些标记来优化修复过程。 4. 后续行动计划 完善CFS数据扫描工具，并解决其性能和可扩展性问题。 实现元数据修复的详细方案，包括处理目录碎片、快照和元数据树中的断开连接。 开发一种机制来标记已修复的inode，并使用这些标记来优化修复过程。 开发一种机制来处理元数据树中的断开连接。 5. 其他 会议讨论了快照处理和损坏表等议题。 会议还讨论了如何将代码从MDS中分离出来，以便在其他环境中使用。 总结： 本次会议讨论了文件系统检查和修复工具的进展，并提出了后续行动计划。会议强调了性能和可扩展性，以及如何处理元数据修复过程中的各种情况。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- CephFS starter tasks","slug":"CDS_Jewel_--_CephFS_starter_tasks","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_CephFS_starter_tasks/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_CephFS_starter_tasks/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储系统开发任务讨论 会议内容： 一、DCFS任务 任务概述： 由于DCFS跟踪器中的任务众多，对于新加入的开发者来说难以入手。因此，会议讨论了几个适合经验较少的开发者开始的任务。 具体任务： 缓存状态导出： 通过mds_cache_dump函数导出整个缓存状态，可以根据需要添加参数进行过滤。 目录碎片对象检查工具： 创建一个工具用于检查目录碎片对象，需要读取磁盘上的对象并解析。 特定客户端的缓存状态导出： 扩展现有功能，允许导出特定客户端或inode的缓存状态。 缓存驱逐支持： 支持缓存驱逐功能，以便在测试时将inode从缓存中移除。 二、客户端任务 任务概述： 讨论了几个客户端相关的开发任务。 具体任务： 异步接口集成： 将Samba的异步接口集成到Ceph客户端中。 性能计数器扩展： 扩展客户端性能计数器，包括请求数量、缓存大小等。 文件回溯支持： 实现文件回溯功能，将文件路径和版本信息写入对应的对象中。 FS al南抽象层测试： 为NFS Ganesha演示项目编写测试用例，并配置测试环境。 三、其他任务 MDS类型拆分： 将MDS中使用的结构体拆分为内部类型和客户端共享类型，以提高构建速度和简化链接打包过程。 四、行动计划 任务分配： 将上述任务分配给相关开发人员。 进度跟踪： 定期召开会议，跟踪任务进度。 代码审查： 对提交的代码进行审查。 五、总结 本次会议讨论了Ceph分布式存储系统的多个开发任务，并制定了相应的行动计划。希望开发团队能够高效地完成这些任务，进一步提升Ceph的性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Ceph Mesos","slug":"CDS_Jewel_--_Ceph_Mesos","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Ceph_Mesos/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Ceph_Mesos/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 会议地点： 线上会议 参会人员： Joey（Intel上海），John Kuhn，Duncan（同事），以及其他参会者 会议主题： 介绍Intel上海开发的Ceph Mesos框架Seth Mesos 会议内容： 1. Seth Mesos框架介绍 由Intel上海开发的Seth Mesos框架，用于在Apache Mesos上扩展Ceph集群。 该框架由调度器和执行器组成，可以管理Ceph集群的部署和扩展。 目标是支持Ceph的不同组件，如OSD、Mon、Gateway等。 2. Apache Mesos架构 Apache Mesos由框架、Master和Slave三个组件组成。 框架负责资源管理和任务调度，Master负责集群管理，Slave负责资源报告和任务执行。 3. Seth Mesos应用场景 用于在Mesos集群中部署Ceph集群，实现资源隔离和动态扩展。 可以与现有的Mesos框架（如Marathon、Mesos DC/OS等）集成，提供更丰富的应用场景。 4. Seth Mesos功能 支持Ceph集群的部署和扩展，包括OSD、Mon、Gateway等。 支持Ceph集群的自动伸缩，根据负载动态调整资源。 支持Ceph集群的故障转移和恢复。 支持Ceph集群的监控和管理。 5. Seth Mesos挑战 目前只支持单个主机上的OSD部署，不支持多个OSD共享同一块磁盘。 数据流量通过10GB或更高网络，网络选择和CIDR选择功能正在开发中。 支持Ceph集群的动态伸缩和故障转移功能正在开发中。 6. 行动计划 继续开发和优化Seth Mesos框架，增加更多功能和支持。 与社区合作，推动Ceph和Mesos的集成。 开展大规模测试，验证Seth Mesos框架的性能和稳定性。 会议总结： Seth Mesos框架是一个很有潜力的Ceph集群管理工具，可以帮助用户更方便地部署、管理和扩展Ceph集群。未来将继续改进和完善该框架，为用户提供更好的服务。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Messenger, Priorities for Client","slug":"CDS_Jewel_--_Messenger_Priorities_for_Client","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Messenger_Priorities_for_Client/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Messenger_Priorities_for_Client/","excerpt":"","text":"会议纪要 会议主题： 客户端消息优先级讨论 参会人员： 多位研发人员，包括负责Ceph分布式存储、视频会议字幕翻译和总结的成员。 会议内容： 一、议题概述 本次会议主要讨论了客户端消息优先级的问题，旨在解决当前Ceph系统中存在的负载不均衡和性能问题。 二、讨论的主要议题 当前问题： 客户端之间负载不均衡，导致部分客户端响应时间过长。 系统中存在性能瓶颈，需要优化。 解决方案： 引入简单的/优先模型，通过优先级队列来分配负载。 优化现有PD Cream模型，考虑性能问题。 调整FL Journal Queen的优先级，提高性能。 技术方案： 使用Token Bucket算法来控制客户端的优先级。 通过修改现有代码，实现优先级队列。 考虑在文件存储层进行优先级控制。 三、决定的事项 评估Token Bucket算法的适用性，并考虑在现有代码中实现优先级队列。 优化PD Cream模型，提高性能。 调整FL Journal Queen的优先级，提高性能。 探讨在文件存储层进行优先级控制的方案。 四、后续行动计划 研发团队进一步研究Token Bucket算法，并评估其在Ceph系统中的应用。 优化PD Cream模型，并进行测试。 调整FL Journal Queen的优先级，并观察性能变化。 探索在文件存储层进行优先级控制的方案，并进行可行性分析。 五、其他 讨论了Ceph系统中客户端连接数限制的问题，并提出了可能的解决方案。 讨论了Ceph系统中资源分配的问题，并提出了可能的优化方案。 关键词： Ceph、分布式存储、消息优先级、Token Bucket、PD Cream、FL Journal Queen","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Ceph 0 day for performance regression","slug":"CDS_Jewel_--_Ceph_0_day_for_performance_regression","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Ceph_0_day_for_performance_regression/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Ceph_0_day_for_performance_regression/","excerpt":"","text":"会议纪要 会议主题： 分布式存储Ceph性能回归分析及改进 会议时间： 2023年11月某日 参会人员： Ceph研发团队、集群管理员 会议内容： 一、关键议题 性能回归问题： 讨论了Ceph在性能方面的潜在回归问题，包括蜘蛛权限、鱼饼性能认证等。 发现某些性能改进可能产生了反效果，例如在Hammer版本更新后，性能并未如预期提升。 分析了不同配置对性能的影响，以及不同硬件对性能的影响。 性能测试框架： 讨论了如何构建一个自动化性能测试框架，用于评估Ceph的性能。 提出了使用测试集群进行基准测试，并收集系统性能数据（CPU、内存、磁盘I/O等）。 讨论了使用fio、Chef、Ghost等工具进行性能测试。 性能测试方法： 讨论了使用SEF、小I/O基准测试等工具进行性能测试。 提出了将性能测试集成到Ceph的日常测试中，并使用Cot Vinci进行测试。 性能测试结果分析： 讨论了如何分析性能测试结果，并找出性能回归的原因。 提出了使用Google Sheets等工具进行数据分析和可视化。 二、决定事项 建立一个自动化性能测试框架，用于评估Ceph的性能。 使用测试集群进行基准测试，并收集系统性能数据。 使用fio、Chef、Ghost等工具进行性能测试。 将性能测试结果集成到Ceph的日常测试中，并使用Cot Vinci进行测试。 分析性能测试结果，并找出性能回归的原因。 三、后续行动计划 研发团队负责构建自动化性能测试框架。 集群管理员负责配置测试集群和收集性能数据。 研发团队和集群管理员共同分析性能测试结果，并找出性能回归的原因。 定期进行性能测试，并跟踪性能变化。 四、其他事项 讨论了使用SEF、小I/O基准测试等工具进行性能测试的便利性。 讨论了将性能测试集成到Ceph的日常测试中的可行性。 讨论了使用Google Sheets等工具进行数据分析和可视化的效果。 五、关键词 性能回归 性能测试 自动化测试 测试集群 fio Chef Ghost Cot Vinci Google Sheets","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Hadoop over Ceph RGW","slug":"CDS_Jewel_--_Hadoop_over_Ceph_RGW","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Hadoop_over_Ceph_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Hadoop_over_Ceph_RGW/","excerpt":"","text":"会议纪要： 会议主题： Hadoop over Ceph RGW 状态更新 会议时间： 未提及 参会人员： Patrick、Yawn、Jen、Earning（远程） 会议内容： 1. Hadoop over Ceph RGW 设计回顾 该方案包括三个主要组件：Rgw Skidaway FS（Hadoop 兼容文件系统插件）、Rgw Skidaway Web Proxy（基于 Restful 服务的代理）、Rgw Skidaway with SSD Cache（使用 SSD 缓存的后端存储）。 设计流程：调度器请求数据位置，Rgw Skidaway Web Proxy 返回最近的数据节点，调度器在数据节点附近的服务器上分配任务，任务尝试从最近的数据节点访问数据。 2. 自 Infiniscale 以来更新 Rgw Skidaway Web Proxy：已完成基于 Pass whiskey 模块的演示，可以通过 Restful 请求获取数据位置。 Rgw Skidaway File System：已完成 70% 的代码开发，实现了与多个 Rgw Skidaway 实例的通信，并添加了块级位置信息，提高了读取性能。 性能测试：与 HDFS 和 Swift 进行了基准性能测试，Swift 读取性能比 HDFS 低约 20%。 3. Rgw Skidaway File System 详细更新 新的文件系统 URL 将以 GW 前缀开头，可以使用该协议让 Hadoop 访问 Rgw Skidaway 集群。 已添加块级概念，基于块级位置信息提高读取性能。 存在问题：对于大于 5GB 的对象，存在零字节清单文件和大量小块，需要进一步解决。 4. Rgw Skidaway Proxy 详细更新 使用 Lister API 获取清单文件，查找每个块的节点位置。 使用 Oil API 跟踪 crush map，获取每个块的节点位置。 根据节点位置查找最近的 Rgw Skidaway 实例。 5. Rgw Skidaway File System 性能测试 使用 HDFS 和 Swift 进行了基准性能测试，Swift 读取性能比 HDFS 低约 20%。 分析了性能差异的原因，发现 Swift 重命名操作较为复杂。 6. 下一步计划 完成代码开发，进行基准性能测试。 解决大于 5GB 对象的零字节清单文件和小块问题。 研究复制实现，以解决性能问题。 将代码开源。 7. 其他讨论 讨论了禁用桶索引功能以提高性能的可能性。 讨论了网络瓶颈的可能性。 讨论了增加 Rgw Skidaway 与后端之间的连接数以提高性能的可能性。 行动计划： Yawn 和 Jen 继续开发代码。 Earning 进行基准性能测试。 研究复制实现和性能问题。 将代码开源。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Optimize newstore for massive small object storage","slug":"CDS_Jewel_--_Optimize_newstore_for_massive_small_object_storage","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Optimize_newstore_for_massive_small_object_storage/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Optimize_newstore_for_massive_small_object_storage/","excerpt":"","text":"会议纪要 会议主题： 优化大规模小对象存储 会议时间： [请填写具体时间] 参会人员： [请填写参会人员名单] 会议内容： 一、问题背景 当前Ceph存储在处理大量小对象时存在性能瓶颈，尤其在读取和写入方面。 小对象存储场景在用户数据存储、日志存储等领域广泛存在。 现有解决方案如使用Key-Vega缓存、合并小对象为大文件等，都存在一定局限性。 二、讨论议题 小对象存储性能瓶颈分析： 小对象频繁读写导致随机I/O增加，影响性能。 小对象在Ceph中的存储结构（如X-attr）导致额外开销。 优化方案探讨： 合并小对象为大文件： 将多个小对象合并为大文件，减少随机I/O，提高性能。 改进X-attr存储结构： 优化X-attr的存储方式，减少额外开销。 使用缓存： 使用缓存技术减少对底层存储的访问频率，提高性能。 改进数据放置策略： 根据小对象的特点，优化数据放置策略，提高性能。 三、决定事项 评估合并小对象为大文件的方案： 考虑将多个小对象合并为64MB的大文件，类似于TFS的实现。 研究如何实现小对象的引用计数，以便在删除时释放空间。 考虑使用PG锁来优化并发访问。 改进X-attr存储结构： 评估优化X-attr存储结构的方法，减少额外开销。 使用缓存： 考虑使用缓存技术减少对底层存储的访问频率，提高性能。 研究缓存策略，确保缓存的有效性。 四、后续行动计划 新存储团队： 在新存储中实现合并小对象为大文件的方案。 评估优化X-attr存储结构的方法。 研究使用缓存技术。 其他团队： 评估改进数据放置策略的方法。 研究使用librados直接访问底层存储的方法。 五、会议总结 本次会议针对大规模小对象存储性能优化进行了深入讨论，并提出了多种优化方案。下一步将根据讨论结果进行技术评估和方案实施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RADOS metadata-only journal mode","slug":"CDS_Jewel_--_RADOS_metadata-only_journal_mode","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_RADOS_metadata-only_journal_mode/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_RADOS_metadata-only_journal_mode/","excerpt":"","text":"会议纪要： 会议主题： Ceph分布式存储系统中元数据仅日志模式的讨论与决策 关键细节： 讨论了在Ceph中实现元数据仅日志模式（metadata-only journal mode）的两种算法，旨在优化性能并减少写操作中的延迟。 第一种算法在写操作中先将对象数据写入最终位置，然后将元数据提交到日志中。这种方法的优点是实现简单，但在特定情况下可能导致不一致性。 第二种算法在写操作中先提交元数据到日志，然后写入对象数据。这种方法更复杂，但可以保证数据一致性，并能更好地处理不一致性情况。 讨论的主要议题： 不一致性问题： 第一种算法在特定情况下可能导致对象数据不一致，而第二种算法可以保证数据一致性。 性能影响： 两种算法都会增加写操作的开销，但第二种算法的开销更大。 适用场景： 第一种算法适用于某些特定场景，而第二种算法更通用。 实现复杂性： 第二种算法的实现更复杂，需要更多的代码和逻辑。 决定的事项： 将进行仿真测试，以确定哪种算法更适用于Ceph系统。 如果第二种算法的性能优于第一种算法，则将选择第二种算法进行实现。 将考虑引入标记机制，以区分元数据仅日志模式和不一致性的操作。 后续行动计划： 进行仿真测试，比较两种算法的性能。 根据测试结果选择合适的算法进行实现。 设计并实现标记机制，以区分元数据仅日志模式和不一致性的操作。 对Ceph代码进行修改，以支持元数据仅日志模式。 关键词： 元数据仅日志模式（metadata-only journal mode） 写操作（write operation） 数据一致性（data consistency） 不一致性（inconsistency） 性能（performance） 实现复杂性（implementation complexity） 仿真测试（simulation test）","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RADOS multi-object transaction support","slug":"CDS_Jewel_--_RADOS_multi-object_transaction_support","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_RADOS_multi-object_transaction_support/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_RADOS_multi-object_transaction_support/","excerpt":"","text":"会议纪要 会议主题： RatOS多对象事务支持审批 参会人员： Lee（RatOS研发人员）、Ratos团队 会议内容： 主要议题： RatOS多对象事务支持： Lee介绍了RatOS的多对象事务支持机制，该机制基于两阶段提交协议，旨在简化客户端内部客户端的设计。 该机制支持客户端定义事务主体，引用对象列表以及对象上的RatOS操作。 事务处理流程包括预提交、准备、提交和回滚阶段。 错误处理和死锁检测： 讨论了错误处理和死锁检测的挑战，包括OSD映射变化和事务信息丢失。 提出了在事务处理过程中引入超时机制的建议，以处理潜在的死锁和错误情况。 客户端事务控制： 讨论了客户端如何指定事务的锁依赖关系，以及如何处理潜在的死锁问题。 提出了将对象操作划分为不同死锁类别的建议，以简化锁依赖关系的管理。 性能优化： 讨论了使用元数据日志和RatOS集群通信协议优化事务处理性能的可能性。 决定事项： 审批RatOS多对象事务支持机制。 设计和实现事务处理流程中的错误处理和死锁检测机制。 确定客户端事务控制策略。 评估性能优化方案。 后续行动计划： Lee将根据讨论结果完善RatOS多对象事务支持机制的文档。 团队将开始设计和实现事务处理流程中的错误处理和死锁检测机制。 客户端研发人员将确定客户端事务控制策略。 团队将评估性能优化方案的可行性。 关键术语： RatOS 两阶段提交协议 锁依赖关系 死锁检测 元数据日志 RatOS集群通信协议","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Scrub Repair","slug":"CDS_Jewel_--_Scrub_Repair","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_Scrub_Repair/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_Scrub_Repair/","excerpt":"","text":"会议纪要 会议时间： （此处应填写会议具体时间） 参会人员： （此处应填写参会人员名单） 会议主题： Ceph分布式存储系统中的数据修复与一致性检查 关键细节： 会议讨论了Ceph系统中数据修复（scrub）和一致性检查（repair）的优化问题。 当前修复过程存在效率低下、错误猜测等问题。 需要改进OSD（对象存储守护进程）的智能程度，以便更准确地识别和修复不一致的对象。 讨论的主要议题： 修复流程重构： 重新设计修复流程，使其能够对单个对象进行修复操作。 在修复模式下，scrub应能够对单个对象执行修复操作。 不一致对象查询： 允许客户端查询不一致的PG（存储池）。 在librettos中实现查询不一致PG的方法。 不一致对象信息获取： 获取PG中不一致对象的信息，并确保信息可持久化。 可考虑将信息存储为临时对象或隐藏元数据对象。 智能修复： 允许通过预准备的现有对象进行有针对性的修复。 使用JSON格式存储不一致信息，以便实现向后兼容性。 决定的事项： 修复流程优化： 优化修复流程，使其能够对单个对象进行修复。 重新设计scrub操作，使其能够执行单个对象的修复操作。 不一致对象查询与信息获取： 在librettos中实现查询不一致PG的方法。 获取PG中不一致对象的信息，并确保信息可持久化。 智能修复： 允许通过预准备的现有对象进行有针对性的修复。 使用JSON格式存储不一致信息。 后续行动计划： 开发与测试： 开发并测试修复流程优化方案。 开发并测试不一致对象查询与信息获取功能。 开发并测试智能修复功能。 文档与培训： 编写相关文档，介绍修复流程优化方案。 对相关人员进行培训，确保他们了解新功能的使用方法。 反馈与迭代： 收集用户反馈，并根据反馈进行迭代优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- add IOHints in CephFS","slug":"CDS_Jewel_--_add_IOHints_in_CephFS","date":"2015-08-03T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/04/CDS_Jewel_--_add_IOHints_in_CephFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/04/CDS_Jewel_--_add_IOHints_in_CephFS/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储项目会议 会议时间： 未知 参会人员： 多名Ceph研发人员，包括John、Alan等 会议内容： 一、会议议程调整 由于Greg休假且会议进度提前，本次会议将调整议程，由参会人员讨论IO提示功能（IO hint）相关内容。 二、BP（BluePrint，蓝图）讨论 BP提案： 讨论了基于Cedar Spring提案的通用框架，用于实现控制数据生命周期、识别数据重要性和分配策略等功能。 模型选择： 讨论了多种模型，包括DePaul模型和Cassandra模型，用于优化数据存储和访问。 缓存策略： 讨论了缓存数据、可用数据和非可用数据之间的标识和策略，以及如何在未来扩展框架以支持更多标识。 API和数据处理： 讨论了API和数据处理的相关问题，包括数据泄露处理、异常处理和性能优化等。 缓存框架： 讨论了使用缓存框架提高性能，并考虑了使用其他软件工具（如DSS）来实现框架的扩展。 三、后续行动计划 继续完善BP提案： 完善模型选择、缓存策略和API设计等方面的内容。 实现缓存框架： 开发并实现缓存框架，提高性能和数据处理效率。 扩展框架： 考虑使用其他软件工具或方法扩展框架，以支持更多功能和场景。 四、其他讨论 数据隔离： 讨论了如何实现数据隔离，以满足不同用户和场景的需求。 性能优化： 讨论了如何优化性能，提高数据访问和处理速度。 兼容性： 讨论了如何与其他RFS（文件系统）兼容。 五、会议总结 本次会议主要讨论了Ceph分布式存储项目中IO提示功能的相关内容，并明确了后续行动计划。参会人员对BP提案、缓存框架和性能优化等方面进行了深入讨论，为项目的发展提供了有益的参考。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-JUL-30 -- Ceph Tech Talks: CephFS","slug":"2015-JUL-30_--_Ceph_Tech_Talks_-_CephFS","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/2015-JUL-30_--_Ceph_Tech_Talks_-_CephFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/2015-JUL-30_--_Ceph_Tech_Talks_-_CephFS/","excerpt":"","text":"会议纪要 会议主题： Ceph 文件系统（CephFS）概述及最新进展 会议时间： 2023年11月（具体日期未提及） 参会人员： Ceph 社区成员、开发者、用户等 会议内容： 一、CephFS 简介 CephFS 是 Ceph 存储系统的一个组件，提供 POSIX 兼容的文件系统接口。 CephFS 具有高可用性、可扩展性、分布式存储等特性。 CephFS 使用 Rados 作为后端存储，提供数据持久化和冗余。 二、CephFS 架构 客户端：负责与 CephFS 交互，执行文件操作。 Metadata Server (MDS)：负责存储和管理文件系统的元数据，如目录、文件属性等。 Object Storage Daemons (OSD)：负责存储文件数据。 三、CephFS 特性 POSIX 兼容：支持标准的文件操作，如 ls、cp、rm 等。 高可用性：MDS 和 OSD 都支持高可用性，确保文件系统稳定运行。 可扩展性：可以水平扩展存储容量和性能。 分布式存储：数据分散存储在多个节点上，提高数据可靠性和性能。 四、CephFS 最新进展 改进健康检查：MDS 提供了更详细的健康检查信息，方便用户诊断问题。 故障恢复工具：开发了一系列故障恢复工具，例如数据扫描工具、日志工具等，帮助用户恢复数据。 性能优化：对缓存、锁等机制进行了优化，提高文件系统性能。 访问控制：增强了访问控制功能，支持基于路径的访问控制、root squash 等。 测试和 QA：增加了功能测试和 QA 工具，提高文件系统稳定性。 五、行动计划 完成文件系统检查和修复工具的开发。 进一步完善访问控制功能。 支持更多云和容器环境。 加强与第三方测试机构的合作。 六、总结 CephFS 是一个功能强大的分布式文件系统，具有高可用性、可扩展性、分布式存储等特性。Ceph 社区正在不断改进 CephFS，使其更加稳定和易用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Calamari/API/Storage/Hardware","slug":"CDS_Jewel_--_Calamari_API_Storage_Hardware","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_Calamari_API_Storage_Hardware/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_Calamari_API_Storage_Hardware/","excerpt":"","text":"会议纪要 一、硬件API规划与实现 会议主题： 讨论并规划Calamari硬件API的规划和实现。 主要议题： 动机： 通过提供硬件API，使Calamari能够了解其背后的存储，以便在硬件出现问题时，能够分析影响并帮助管理员识别合适的硬件进行更换。 API设计： 提出了一些潜在的API端点和字段，包括设备ID、驱动器信息、制造商、版本、序列号等。 讨论了如何使用全球ID作为持久标识符，并确保其在不同场景下的一致性。 讨论了如何处理智能数据（Smart Data），包括存储位置、频率和缓存策略。 讨论了如何与现有工具（如libblockid）集成。 决定事项： 将智能数据存储在Calamari中，并定期查询设备以获取数据。 使用libblockid等现有工具进行智能数据查询。 考虑使用缓存机制以避免频繁查询设备。 后续行动计划： 完成API的设计和实现。 在Calamari中集成智能数据。 测试API的功能。 二、Calamari包发布 会议主题： 讨论Calamari包的发布和计划。 主要议题： 已发布包： Calamari的最新稳定版本已发布，并可在download.com/calamari下载。 安装指南： 提供了Calamari的安装指南，并链接到aether pad和GitHub的readme文件。 支持的平台： 目前支持SUSE、Ubuntu和CentOS。 未来计划： 推出Fedora 21+的包。 探索其他发行版的支持。 决定事项： 发布Calamari包。 提供安装指南。 探索其他发行版的支持。 后续行动计划： 发布Fedora 21+的包。 探索其他发行版的支持。 三、Calamari故障排除 会议主题： 讨论如何改进Calamari的故障排除。 主要议题： salt问题： Calamari使用salt进行自动化，但salt的最新版本可能会与Calamari冲突。 故障排除文档： 需要改进故障排除文档，使其更易于使用。 简化Calamari： 简化Calamari的依赖关系，使其更易于安装和使用。 决定事项： 改进故障排除文档。 简化Calamari的依赖关系。 后续行动计划： 改进故障排除文档。 简化Calamari的依赖关系。 四、其他讨论 测试框架： 讨论了Calamari测试框架的设置和运行。 Calamari的未来方向： 讨论了Calamari的未来发展方向，包括集成其他工具和功能。 总结： 本次会议讨论了Calamari硬件API的规划和实现、Calamari包的发布、Calamari的故障排除以及Calamari的未来发展方向。会议确定了后续行动计划，并讨论了相关技术问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- CephX brute-force protection","slug":"CDS_Jewel_--_CephX_brute-force_protection","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_CephX_brute-force_protection/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_CephX_brute-force_protection/","excerpt":"","text":"会议纪要： 会议主题： 安全讨论，特别是关于暴力破解保护和安全措施。 关键细节： 讨论背景： 近几个月与Sage关于安全性的讨论。 主要议题： 如何检测和防止系统内的暴力破解尝试。 实现自动黑名单机制，针对频繁尝试错误认证的用户。 如何识别攻击者，是否使用IP地址或TCP连接。 是否应该在集群启动时或在系统重启时实施黑名单机制。 是否应该有一个带有过期时间的黑名单机制。 是否应该将管理网络与公共网络隔离。 监视器是否应该对OSD映射进行签名，以增强安全性。 决定的事项： 优先处理黑名单机制的实现，包括： 改进日志记录，以便检测尝试使用错误密钥进行认证的情况。 实现自动黑名单机制，针对频繁尝试错误认证的用户。 使用IP地址或TCP连接来识别攻击者。 考虑在系统重启时或在系统运行一段时间后实施黑名单机制，并设置过期时间。 对管理网络进行隔离的讨论暂时搁置，因为可能会带来额外的复杂性而收益有限。 考虑对OSD映射进行签名，以提高安全性。 后续行动计划： 研究和实现黑名单机制。 考虑如何识别攻击者，并确定使用IP地址或TCP连接。 研究在系统重启时或在系统运行一段时间后实施黑名单机制。 考虑对OSD映射进行签名。 关键词： 暴力破解 黑名单 日志记录 认证 攻击者 集群 OSD映射 签名","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Non-Functional Tests","slug":"CDS_Jewel_--_Non-Functional_Tests","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_Non-Functional_Tests/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_Non-Functional_Tests/","excerpt":"","text":"会议纪要 会议主题： 非功能性测试在Ceph开发过程中的应用 与会人员： Ceph研发人员、视频会议字幕翻译及总结人员 会议内容： 1. 讨论背景 介绍者自我介绍：UC Santa Cruz的博士研究生，Red Hat的暑期实习生，负责Ceph的非功能性测试项目。 非功能性测试的定义：评估系统整体质量而非特定行为的测试，例如可扩展性、性能等。 2. 项目目标 将非功能性测试纳入Ceph开发流程。 使用集成测试、基准测试和验证测试相结合的方法。 通过性能指标和验证断言来评估系统质量。 3. 技术方案 利用cgroup资源限制来控制测试环境。 使用验证语言和验证引擎来定义和执行验证测试。 使用tautology作为基准测试工具。 开发maestro任务来部署和配置Ceph集群。 开发rattles任务来运行基准测试。 开发a verte任务来验证测试结果。 4. 验证测试 定义验证语句来评估系统质量，例如可扩展性、性能、可用性等。 使用验证引擎来执行验证语句。 通过分析日志和性能指标来验证系统质量。 5. 后续行动 开发验证语句。 完成tautology任务的开发。 集成验证测试到Ceph开发流程。 6. 讨论要点 如何量化非功能性测试结果。 如何应对硬件非确定性。 如何定义验证测试。 如何将验证测试集成到Ceph开发流程。 7. 其他 讨论了使用rattles、fio等工具进行基准测试的优缺点。 讨论了使用验证语言和验证引擎进行验证测试的可行性。 总结： 本次会议讨论了在Ceph开发过程中引入非功能性测试的方案，并提出了相应的技术实现。通过本次会议，与会人员对非功能性测试在Ceph开发中的重要性有了更深入的理解，并为后续工作提供了指导。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Peering Speed Improvements","slug":"CDS_Jewel_--_Peering_Speed_Improvements","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_Peering_Speed_Improvements/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_Peering_Speed_Improvements/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储性能讨论，特别是对等速度提升和一致性模型下的映射变更处理。 关键细节： 讨论议题： 在映射变更时，如何减少对等过程中的延迟。 当前对等过程涉及多个步骤，包括获取信息、获取日志和获取缺失数据集。 需要优化对等过程，以减少往返次数和提升性能。 主要议题： 优化对等过程： 建议优化对等过程中的步骤，例如缓存信息以避免重复获取。 可以利用历史信息来预测上一次间隔的正确性，从而减少对等过程。 可以通过优化日志提交过程来减少对等过程中的往返次数。 一致性模型： 讨论了在映射变更时，如何确保数据一致性。 强调了在读取对象之前，需要确保其他副本已经提交了日志。 决定的事项： 优化对等过程，以减少往返次数和提升性能。 考虑使用历史信息来预测上一次间隔的正确性。 优化日志提交过程，以减少对等过程中的往返次数。 后续行动计划： 评估优化对等过程的具体方案。 实现并测试优化后的对等过程。 监控优化后的性能，并根据需要进行调整。 其他要点： 讨论了在映射变更时，如何处理不同的场景，例如 OSD 故障和节点重启。 讨论了优化对等过程可能带来的挑战，例如代码复杂性和调试难度。 关键词： Ceph 分布式存储 对等 性能 一致性 映射变更 日志 缺失数据集 往返次数 优化","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RADOS QoS","slug":"CDS_Jewel_--_RADOS_QoS","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_RADOS_QoS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_RADOS_QoS/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储服务质量（QoS）策略讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Ray、Clark、Sam、Josh 等 会议内容： 一、QoS策略概述 会议首先讨论了Ceph分布式存储中的服务质量（QoS）策略，旨在为不同类型的存储请求提供差异化的服务质量。 当前Ceph的I/O调度器采用公平共享调度器，但需要进一步优化以支持QoS策略。 二、QoS策略实现方案 基于EM算法的I/O调度器优化： 通过引入EM算法，为客户端提供最小IOPS和最大IOPS的配置选项。 当客户端的IOPS请求超过最大限制时，系统将进行限制。 当最小IOPS得到保证时，超出部分将按照公平共享原则进行分配。 资源预留与容量控制： 需要引入资源预留机制，以确保高优先级客户端的IOPS需求得到满足。 可以通过配置选项或管理工具来设置资源预留策略。 性能自动检测： 需要引入性能自动检测机制，以实时评估存储集群的性能。 可以通过辅助工具或自研代码进行性能测试。 三、相关讨论 网络QoS： 讨论了网络QoS对存储系统的影响，并探讨了如何将网络QoS与存储QoS相结合。 OSD性能自动检测： 讨论了如何自动检测OSD的性能，并提出了基于OSD操作性能进行检测的方案。 客户端信任度： 讨论了如何处理不信任的客户端，并提出了限制IOPS或拒绝QoS配置的方案。 四、后续行动计划 Ray将继续开发基于EM算法的I/O调度器优化方案。 Sam将研究性能自动检测机制。 Clark将探讨网络QoS与存储QoS的结合方案。 全体成员将继续讨论客户端信任度问题。 五、关键术语 QoS： 服务质量 I/O调度器： Input/Output scheduler EM算法： Expectation-Maximization algorithm OSD： Object Storage Device PG： Placement Group RBD： RADOS Block Device 六、总结 本次会议讨论了Ceph分布式存储中的QoS策略，并提出了多种实现方案。后续将进行进一步的研究和开发，以提升Ceph存储系统的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RADOS Tail Latency Improvements","slug":"CDS_Jewel_--_RADOS_Tail_Latency_Improvements","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_RADOS_Tail_Latency_Improvements/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_RADOS_Tail_Latency_Improvements/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储性能优化讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Sam、Mark、Guang、Anakin、Castle 等 会议内容： 一、低延迟改进 心跳优化： Sam 提出通过发送消息给监控器来主动声明自身死亡，从而提高失败检测的效率，减少延迟。 慢 OSD 自动检测： 讨论了自动检测慢速 OSD 并将其标记为不可用，以避免整个集群速度下降。 读取优化： 讨论了通过并行读取多个副本来提高读取速度，并考虑使用新的存储引擎来优化性能。 二、存储引擎优化 文件存储优化： 讨论了文件存储的复杂性，并考虑使用新的存储引擎来优化性能。 LevelDB 和 RocksDB： 讨论了 LevelDB 和 RocksDB 在压缩过程中的性能问题，并考虑使用 RocksDB 来替代 LevelDB。 三、其他讨论 OSD 性能统计： 讨论了收集 OSD 性能统计数据，以便更好地了解性能瓶颈。 优先级处理： 讨论了请求优先级处理，确保来自主节点的请求优先处理。 数据分区： 讨论了确保数据在 OSD 之间均匀分布，以避免性能瓶颈。 四、行动计划 Sam 将继续优化心跳机制和慢 OSD 检测。 Guang 将研究并行读取多个副本来提高读取速度。 Castle 将研究新的存储引擎，并考虑使用 RocksDB 替代 LevelDB。 Sam 和 Guang 将收集 OSD 性能统计数据。 五、关键术语 Ceph 分布式存储 低延迟 慢 OSD 文件存储 LevelDB RocksDB 数据分区 总结： 本次会议讨论了 Ceph 分布式存储性能优化方案，包括心跳优化、慢 OSD 自动检测、读取优化、存储引擎优化等方面。会议确定了后续行动计划，并明确了关键术语。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Passive Monitors","slug":"CDS_Jewel_--_Passive_Monitors","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_Passive_Monitors/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_Passive_Monitors/","excerpt":"","text":"会议纪要 会议主题 讨论被动监控器在Ceph集群中的应用，包括其设计理念、潜在问题和解决方案。 关键细节 被动监控器：一种监控器，它不是Quorum的活跃参与者，不需要确认或接受提案，但会接收到所有提案。 目的：提高集群的可用性和灾难恢复能力。 设计理念：在Quorum中至少有一个被动监控器，以便在需要时可以快速将其转换为活跃监控器，参与Quorum。 讨论的主要议题 如何将被动监控器转换为活跃监控器：需要设计一种机制来安全地将被动监控器加入到活跃监控器集合中。 如何避免脑裂问题：当集群分布在多个房间时，如何防止不同房间中的监控器同时认为自己是Quorum的一部分。 被动监控器的更新：如何确保被动监控器与Quorum的状态保持同步，同时避免过度负载活跃监控器。 被动监控器的角色：被动监控器是否应该参与选举，以及是否应该处理客户端请求。 决定的事项 初步方案：将被动监控器作为Quorum的备份，由管理员手动将其提升为活跃监控器。 长期方案：研究如何自动将被动监控器提升为活跃监控器，同时避免脑裂问题。 被动监控器的更新：将被动监控器与一个活跃监控器绑定，以便接收更新。 后续行动计划 设计和实现被动监控器的初步方案。 研究和解决脑裂问题。 评估被动监控器参与选举和处理客户端请求的可行性。 撰写相关文档和代码注释。 关键术语 被动监控器：Passive Monitor Quorum：Quorum 脑裂：Split Brain 活跃监控器：Active Monitor 客户端请求：Client Requests","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- PMStore","slug":"CDS_Jewel_--_PMStore","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_PMStore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_PMStore/","excerpt":"","text":"会议纪要 会议主题： P.M. Store 新型 OSD 后端方案讨论 会议时间： 2023年11月某日 参会人员： Lucas, Nora, Bob, 等 会议内容： 1. 项目背景与目标 - Lucas 和 Nora 介绍了 P.M. Store，这是一个针对非易失性存储的新实验性 SD Back-end。 - 该方案旨在利用开源 p.m. 库，专门设计用于与非易失性存储设备（如 SSD）协同工作。 - 目标是提高存储性能，同时保持与现有存储代码库和对象处理集成的兼容性。 2. 技术方案 - 使用内存映射文件存储对象，文件分为固定大小的块以应对碎片化。 - 利用内存映射库处理块，默认数据块大小为1MB，元数据块大小为8KB。 - 对象中包含指向块的 ID 和读写方法的向量。 - 使用内存映射文件，通过简单的内存复制操作进行读写。 - 读取性能目前相当不错，基本实现已完成，并计划开源。 3. 挑战与解决方案 - 发现一些边缘情况，正在通过生命周期测试进行修复。 - 优化键序列化，以更有效地处理块更新。 - 使用事务性用户空间块设备，允许通过 futon 内存策略进行目录读写。 - 对象和集合的索引存储在内存中，启动时从每个块的元数据重建。 4. 性能与测试 - Lucas 指出，对于 4TB 的 OSD 磁盘，如果其容量为 60%，则扫描整个 OSD 存储所需时间可能在几分钟到几小时之间。 - 讨论了将元数据持久化存储在磁盘上的可能性，以及如何优化零拷贝操作。 5. 后续计划 - Lucas 将在 GitHub 上开源 P.M. Store 代码，并邀请大家测试。 - 讨论了可能的优化，例如异步读写接口和改进的锁定机制。 6. 其他讨论 - 讨论了对象存储接口的回调机制，以及是否支持异步读写。 - 讨论了扩展地址顺序阶段，以支持同步和异步版本。 会议结论： - P.M. Store 是一个很有潜力的项目，有望提高 Ceph 的存储性能。 - 需要进一步优化和测试，以提高性能和稳定性。 - Lucas 将开源代码，并邀请大家参与测试和讨论。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RBD Journal","slug":"CDS_Jewel_--_RBD_Journal","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_RBD_Journal/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_RBD_Journal/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： 线上会议 参会人员： Jason、Hank、John、Vanessa等 会议主题： RBD Journal Blueprint设计讨论 会议内容： RBD Journal Blueprint概述 Jason介绍了RBD Journal Blueprint的设计，该设计旨在支持RBD镜像跨数据中心复制。 该设计目标是实现通用性，不仅适用于lib rbd，未来也可能适用于MDS或其他客户端。 设计基于liberated us API，与现有RBD代码和Journaling代码有所不同。 设计决策 使用RNG算法将日志条目分散到多个对象上，提高效率。 引入软最大大小限制，当日志对象满时，将关闭整个活动集，而不是单个对象。 支持多读者和潜在的多写者，例如RBD镜像多磁盘的场景。 引入新的工具来帮助恢复损坏的日志对象。 与RBD的集成 新的RBD功能代码将允许动态启用和禁用日志记录功能。 所有可变I/O操作（例如读写、快照操作）都将记录到日志中。 首次打开镜像时，将进行回放模式，以同步日志。 后续行动 Jason将提供代码链接，供大家查看和讨论。 团队将继续改进和优化RBD Journal Blueprint。 关键术语： RBD (RADOS Block Device) Journaling (日志记录) MDS (Metadata Server) OSD (Object Storage Device) liberate us API RNG (随机数生成器) Soft maximum size Replay mode 总结： 本次会议讨论了RBD Journal Blueprint的设计和实现，并就相关技术细节进行了深入探讨。该设计旨在提高RBD镜像的可靠性和可用性，为跨数据中心复制提供支持。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RGW Multisite Configuration","slug":"CDS_Jewel_--_RGW_Multisite_Configuration","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_RGW_Multisite_Configuration/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_RGW_Multisite_Configuration/","excerpt":"","text":"会议纪要 会议主题： 分布式存储Ceph新特性讨论 会议时间： 2023年（具体日期未提及） 参会人员： Chuck, Yehuda, Ricky, Eden, Beth等 会议内容： 一、新多站点配置概述 区域（Zone）： 由多个球和网关组成，位于同一集群，服务于相同的数据。 区域组（Zone Group）： 由多个区域组成，共享相同的用户桶命名空间，用于在不同的集群中创建不同的跨区域传输。 域（Realm）： 由多个区域组组成，共享相同的存储桶命名空间和存储策略。 时期（Period）： 指一段时间内，特定配置生效，包括区域配置、域配置和区域映射。 元数据服务器： 负责处理所有元数据更新，每个区域都有一个元数据主服务器。 二、配置结构 区域映射： 包含整个系统的映射，包括区域和区域组之间的关系以及其他配置信息。 时期映射： 包含特定时期的UID、前一个时期的版本向量、元数据日志等。 域映射： 包含域的名称、ID、元数据主服务器、存储策略等。 区域组映射： 包含区域组的名称、ID、访问URL、存储策略等。 三、配置管理 动态配置： 可以在运行时动态更改配置，无需重启网关。 配置简化： 通过命令行和JSON对象简化配置过程。 版本控制： 可以查看不同时期的配置。 四、后续行动计划 完善配置文档，提供详细的配置步骤。 开发新的API，支持配置的获取和更新。 改进配置界面的用户体验。 五、讨论要点 配置复杂度： 与会人员讨论了配置的复杂度，认为新配置结构将大大简化配置过程。 版本控制： 讨论了时期和版本控制的重要性，以及如何处理配置更改。 API设计： 讨论了API的设计，以及如何提供灵活的配置管理。 总结： 本次会议讨论了Ceph新多站点配置的特性，包括区域、区域组、域、时期等概念，以及配置结构和管理方式。与会人员对新配置结构表示认可，并提出了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RGW Multisite Sync","slug":"CDS_Jewel_--_RGW_Multisite_Sync","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_RGW_Multisite_Sync/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_RGW_Multisite_Sync/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储多站点配置改进 会议时间： 未提及 参会人员： 未提及 会议内容： 一、多站点配置蓝图概述 新区域（Realm）： 新增区域概念，但并非关键部分，当前系统可视为单个区域，未来可创建多个区域。 新周期（Period）： 新增周期概念，确保在达到 Must Run 区域时，不会丢失数据和信息。 元数据同步： 在主节点上执行元数据操作，并锁定在元数据文档中。 从节点将不再直接应用更改，而是从主节点捕获日志信息，并在特定区域上应用。 在每个区域中创建主节点元数据日志的副本，并在应用更改前进行同步。 为每个元数据条目保留两个对象：不可变对象（包括元数据条目及其版本）和当前主要数据键对象。 在每个周期中保留元数据版本向量，记录周期开始时的元数据日志版本信息，并在切换周期时记录版本信息。 数据同步： 使用与元数据同步相同的方法进行数据同步。 可选方案：只在一个区域进行全量同步，或通过共享信息进行快速同步。 目前的方案需要目标节点列出所有条目，然后逐个同步，效率较低。 主动-主动复制（Active-Active Replication）： 在网关内部实现主动-主动复制。 支持跨多个区域进行复制。 使用相同的网关处理来自不同区域的更改包和索引日志。 对于相同对象的更改，使用时间戳作为优先级，如果时间戳相同，则使用名称作为决断条件。 网关代理： 移除网关代理，将代理功能集成到网关中，提高效率并简化配置。 网关代理将直接处理数据同步和元数据同步。 推送通知： 添加推送通知功能，将最近发生的更改立即通知相关区域。 使用 RESTful API 实现通知功能。 二、讨论的主要议题 元数据同步和数据同步的改进方案。 主动-主动复制的设计和实现。 网关代理的集成和功能优化。 三、决定的事项 采用新周期概念，确保数据同步的可靠性。 在网关内部实现主动-主动复制。 移除网关代理，将代理功能集成到网关中。 添加推送通知功能，提高数据同步的效率。 四、后续行动计划 完成元数据同步和数据同步的改进方案设计。 开发主动-主动复制功能。 集成网关代理功能。 实现推送通知功能。 五、其他 需要进一步讨论和解决以下问题： 如何处理不同区域之间的冲突。 如何保证数据的一致性。 如何优化数据同步的效率。 需要制定详细的开发计划和时间表。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- RGW Multitenancy","slug":"CDS_Jewel_--_RGW_Multitenancy","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_RGW_Multitenancy/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_RGW_Multitenancy/","excerpt":"","text":"会议纪要 会议主题： RGW（Rados Gateway）多租户功能讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位Ceph研发人员 会议内容： 多租户功能需求： 现有的RGW方案类似于S3，只有一个全局的用户名空间，所有用户共享同一套用户名和存储桶。 新的多租户方案要求用户能够在RGW中创建不同的租户，每个租户拥有独立的命名空间、用户和存储桶。 租户可以创建多个子用户，共享同一数据，但不同子用户看到的存储桶列表不同。 需要考虑如何处理不同租户之间的数据访问权限和统计信息收集。 多租户方案实现： 需要修改现有的数据结构和API，将存储桶和用户标识符从字符串改为结构体，以区分不同的租户。 需要修改对象类和网关构建中的代码，以支持多租户功能。 需要为每个租户创建一个租户实体，存储租户信息，如默认放置目标、配额、DNS名称等。 需要考虑如何处理不同租户之间的数据访问权限和统计信息收集。 与Keystone集成： RGW已经支持Keystone认证，Keystone中存在租户概念。 可以考虑将Keystone租户映射到RGW租户，实现更高级别的多租户功能。 需要考虑现有系统的兼容性和新配置的引入。 行动计划： 评估现有代码库，确定修改范围和所需工作量。 设计新的数据结构和API。 修改对象类和网关构建中的代码。 实现租户实体和相关的管理功能。 考虑Keystone集成方案。 关键术语： RGW (Rados Gateway) S3 Keystone 租户 (Tenant) 子用户 (Subuser) 命名空间 (Namespace) 存储桶 (Bucket) 统计信息 (Statistics) 总结： 本次会议讨论了RGW多租户功能的需求和实现方案，并制定了后续行动计划。该功能将提高RGW的灵活性和安全性，满足更广泛的应用场景。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Jewel -- Sloppy Reads","slug":"CDS_Jewel_--_Sloppy_Reads","date":"2015-08-02T16:00:00.000Z","updated":"2015-08-03T16:00:00.000Z","comments":true,"path":"2015/08/03/CDS_Jewel_--_Sloppy_Reads/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/08/03/CDS_Jewel_--_Sloppy_Reads/","excerpt":"","text":"会议纪要 会议时间：[具体时间] 会议地点：[具体地点] 参会人员：[参会人员名单] 会议主题：Ceph存储系统性能优化与一致性模型讨论 一、会议关键细节 近期对降低读取延迟的需求增加，讨论了现有架构对延迟保证的挑战。 讨论了在特定场景下，允许客户端从非活动OSD读取数据以减少延迟的可能性。 分析了在特定使用场景下，如创建唯一名称且不修改的对象，允许读取可能有益。 讨论了引入新的存储池类型或参数以支持这种读取优化。 讨论了对于需要使用快照的场景，如何保证读取的一致性。 二、讨论的主要议题 读取延迟优化：讨论了在不同场景下如何优化读取延迟，包括使用非活动OSD读取数据等。 一致性模型：讨论了Ceph当前的一致性模型，以及如何支持多种一致性级别。 快照一致性：讨论了在快照场景下如何保证读取的一致性。 数据保护：讨论了在优化读取性能时，如何保护数据一致性不被破坏。 三、决定的事项 读取优化：将考虑引入新的存储池类型或参数，以支持从非活动OSD读取数据。 一致性模型：将探索支持多种一致性级别的方法，但可能需要重新设计部分系统。 快照一致性：将研究在快照场景下保证读取一致性的方法。 四、后续行动计划 读取优化：Sam将研究如何实现从非活动OSD读取数据的功能，并与其他成员讨论实现细节。 一致性模型：Ron将研究如何支持多种一致性级别，并与其他成员讨论实现方案。 快照一致性：Mia将研究在快照场景下保证读取一致性的方法，并与其他成员讨论实现细节。 数据保护：所有成员将共同讨论在优化读取性能时，如何保护数据一致性不被破坏。 备注： 会议中提到的关键计算机科学/ceph相关领域英文原文关键词包括：latency, consistency model, OSD, replica, snapshot, read-after-write guarantee, quorum group。 会议中未提及具体的时间、地点和参会人员名单，请根据实际情况补充。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-MAY-27 -- Ceph Tech Talks: Placement Groups","slug":"2015-MAY-27_--_Ceph_Tech_Talks_-_Placement_Groups","date":"2015-05-26T16:00:00.000Z","updated":"2015-05-27T16:00:00.000Z","comments":true,"path":"2015/05/27/2015-MAY-27_--_Ceph_Tech_Talks_-_Placement_Groups/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/05/27/2015-MAY-27_--_Ceph_Tech_Talks_-_Placement_Groups/","excerpt":"","text":"会议纪要 会议主题： Ceph 技术讨论会 - 位置组深入解析 会议时间： 2023年11月（具体日期未提及） 参会人员： 汇聚了 Ceph 社区的开发人员、用户和技术爱好者。 会议内容： 会议背景： Ceph Tech Talk 是一个每月一次的技术讨论会，旨在深入探讨 Ceph 的内部工作原理，提升对 Ceph 技术的理解。 主讲人： Florian Azadi，Ceph 社区的长期朋友和支持者。 主题： 位置组（Placement Groups）是 Ceph 分布式存储系统中用于数据分布和复制的机制。本次会议重点介绍了位置组的工作原理、优势、使用方法以及状态查询。 关键内容： 传统存储系统与 Ceph 的数据放置： 传统存储系统依赖于中心化的查找服务，而 Ceph 则采用去中心化的方式，每个组件都参与数据放置。 位置组的优势： 位置组可以有效地平衡数据分布，减少迁移，提高系统可扩展性。 位置组的实现： 通过将数据分散到多个“桶”中，并使用简单的算法进行分配，可以实现可重复的数据放置。 位置组的状态查询： 可以使用 set health、set pg dump、set pg query 和 set osd map 等命令来查询位置组的状态。 位置组的状态： 包括正常、降级、恢复、不完整、不一致和故障等状态。 讨论议题： 如何使用位置组？ 如何查询位置组的状态？ 如何处理位置组故障？ 行动计划： 使用位置组优化 Ceph 集群。 查询并监控位置组的状态。 及时处理位置组故障。 后续行动： 欢迎大家继续关注 Ceph 社区，参与技术讨论。 查阅 Ceph 官方文档，了解位置组的详细信息。 使用 Ceph 集群配置工具，优化位置组配置。 关键词： 位置组、数据放置、分布式存储、Ceph、OSD、PG、状态查询","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-APR-23 -- Ceph Tech Talks: Calamari","slug":"2015-APR-23_--_Ceph_Tech_Talks_-_Calamari","date":"2015-05-03T16:00:00.000Z","updated":"2015-05-03T16:00:00.000Z","comments":true,"path":"2015/05/04/2015-APR-23_--_Ceph_Tech_Talks_-_Calamari/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/05/04/2015-APR-23_--_Ceph_Tech_Talks_-_Calamari/","excerpt":"","text":"2015-APR-23_--Ceph_Tech_Talks-_Calamari 会议纪要 会议概述 本次会议是每月一次的SEF技术讲座，由Gregory主持，主题围绕calamari和Ramona项目，这两个项目分别是Ceph的管理API和图形用户界面（GUI）。 主要议题 Calamari和Ramona的介绍 Calamari：作为API，提供所有信息，支持用户界面操作。 Ramona：作为管理监控仪表板，提供Ceph集群的概览，包括集群状态、OSD状态、集群管理功能等。 Calamari后端架构 架构概览：从左至右依次为仪表板、Django REST框架应用、Salt服务、Ceph集群。 关键组件： Django REST框架：通过Python提供API服务。 Thulu服务：作为缓存层，快速响应API请求。 数据库：用于持久化存储用户信息和集群状态历史。 Graphite数据存储：收集并展示集群的性能数据。 Calamari的未来发展 硬件状态监控：计划增加对底层硬件状态的监控，如硬盘健康状态、热插拔支持等。 API扩展：考虑增加更多管理功能，如集群部署、OSD管理等。 社区合作：欢迎社区反馈和合作，特别是在硬件监控和API扩展方面。 决定事项 硬件监控功能的开发：计划在下一个版本中增加对硬件状态的监控和管理。 API功能的扩展：将持续扩展Calamari的API功能，以支持更多Ceph集群的管理操作。 后续行动计划 硬件监控功能的实现：开发并测试硬件监控模块，确保其准确性和稳定性。 API扩展的规划：根据社区反馈，确定API扩展的具体功能和优先级。 社区合作：加强与社区的沟通，鼓励社区成员参与Calamari的开发和测试。 其他讨论 包装和部署：讨论了Calamari的包装和部署问题，欢迎社区帮助改进。 上游贡献：提到了一些需要上游贡献的组件，如Diamond，希望社区能参与讨论和贡献。 会议结束 会议在讨论了所有议题和问题后结束，感谢Gregory的分享和所有参与者的参与。下次会议将于5月27日举行。### 会议纪要 会议概述 本次会议是每月一次的SEF技术讲座，由Gregory Meredith主讲，主题是关于Calamari和Romana的管理API和GUI。会议详细介绍了这两个项目的架构、功能以及未来的发展方向。 主要议题 Calamari和Romana简介 Calamari：作为API，为管理Ceph集群提供后端支持。 Romana：作为仪表盘，提供Ceph集群的管理和监控界面。 后端架构 Calamari的后端架构包括Django REST框架、Thulu服务（用于状态缓存）、数据库（用于持久化存储）和Graphite数据存储。 Thulu服务通过Salt和Salt的ZeroMQ消息总线与Ceph集群上的代理进行通信，收集集群状态信息。 前端界面 Romana是一个基于AngularJS的单页应用，通过Apache服务器提供服务，主要功能是可视化Calamari API的数据。 未来发展方向 计划增加对硬件状态的监控，包括硬盘、SSD等存储设备的智能监控（SMART）。 探讨如何通过API与Nagios、Sensu等事件和警报框架集成。 考虑增加更多的管理功能，如集群部署、OSD管理等。 决定事项 确认将继续开发Calamari的硬件监控功能，并探索与其他监控系统的集成可能性。 讨论了Calamari的打包和部署问题，希望社区能提供帮助。 后续行动计划 继续开发和完善Calamari的硬件监控功能。 与社区合作，改进Calamari的打包和部署流程。 探索与Nagios、Sensu等系统的集成方法。 其他讨论 讨论了Calamari与CBT（Ceph Benchmarking Tool）的潜在集成，以优化集群性能。 讨论了Calamari的打包问题，特别是与系统包管理器（如yum和apt）的兼容性。 会议结束 会议在讨论了所有议题和问题后结束，下一次SEF技术讲座定于5月27日，由Florian Haas主讲关于PG（Placement Groups）的深入探讨。 本次会议纪要由专业的存储领域分布式存储Ceph研发人员和视频会议字幕总结人员共同完成，确保了内容的准确性和专业性。### 会议纪要 会议主题： 月度SEF技术讲座 主讲人： Gregory Meiste 日期： [具体日期未提供] 地点： [具体地点未提供] 主要议题： 介绍Calamari和Romana Calamari：作为API，为管理Ceph集群提供后端支持。 Romana：作为前端仪表盘，提供Ceph集群的管理和监控界面。 架构概述 后端架构：使用Django REST框架，通过Salt和SaltStack的消息总线与Ceph集群中的代理进行通信。 前端架构：基于AngularJS的单页应用，通过Apache服务器提供服务。 功能展示 Romana仪表盘：展示集群状态、OSD状态、集群管理操作（如创建/删除池）。 Calamari API：提供详细的JSON输出，支持集群状态查询和管理操作。 未来发展方向 硬件监控：计划增加对底层硬件状态的监控，如磁盘健康状态。 集成其他工具：考虑与Nagios、Sensu等监控工具的集成。 管理功能扩展：计划增加更多Ceph管理功能，如集群部署、OSD管理等。 决定事项： 硬件监控功能：将在下一版本中增加对硬件状态的监控和报告。 管理功能扩展：将继续扩展Calamari的管理功能，以覆盖更多Ceph操作。 后续行动计划： 硬件监控实现：开始设计和实现硬件监控功能，包括与硬件供应商的合作。 管理功能扩展：评估和实现更多Ceph管理功能，特别是集群部署和OSD管理。 社区反馈：鼓励社区成员提供反馈和建议，特别是在硬件监控和管理功能方面。 会议结束语： 感谢Gregory Meiste的精彩演讲和所有参与者的积极参与。下次会议将在5月27日举行，届时Florian Haas将讨论PG映射的深入分析。### 会议纪要 会议概述 本次会议是每月一次的SEF技术讲座，由Gregory Meredith主讲，主题是关于Ceph管理API和GUI的介绍，具体涉及Calamari和Ramona两个项目。 主要议题 Calamari和Ramona的介绍 Calamari：作为API，为管理Ceph集群提供后端支持。 Ramona：作为仪表盘，提供Ceph集群的管理和监控界面。 Calamari后端架构 使用Django REST框架，通过Python模块与Ceph集群通信。 利用Salt和ZeroMQ消息总线进行集群状态的收集和管理。 数据存储使用PostgreSQL，支持用户信息和集群状态历史的持久化。 Ramona的功能展示 提供集群状态的概览，包括OSD状态、集群使用情况等。 允许用户通过界面进行集群管理操作，如创建和删除存储池。 未来发展方向 计划增加对硬件状态的监控，包括硬盘健康状态等。 探索与Nagios、Sensu等监控框架的集成。 考虑增加更多的管理功能，如集群部署和OSD管理。 决定事项 确认将继续开发和完善Calamari和Ramona的功能。 计划增加硬件监控功能，并探索与其他监控系统的集成。 后续行动计划 继续优化Calamari的API功能，增加更多Ceph管理命令的支持。 开发硬件监控模块，并与社区合作，收集反馈和建议。 改进软件包管理，使其更易于部署和维护。 其他讨论 讨论了与CBT工具的潜在集成，以优化集群性能。 探讨了软件包管理和部署的问题，寻求社区的帮助和建议。 会议结束 会议在讨论了所有议题和问题后结束，下一次SEF技术讲座定于5月27日，Florian Haas将讨论PG映射的深入分析。### 会议纪要 会议概述 本次会议是每月一次的SEF技术讲座，由Gregory Meredith主讲，主题为“Calamari与Romana：管理API与GUI”。会议主要讨论了Calamari的后端架构、Romana的功能以及未来发展方向。 主要议题 Calamari与Romana简介 Calamari：作为API，为管理Ceph集群提供后端支持。 Romana：作为仪表盘，提供Ceph集群的管理和监控界面。 Calamari后端架构 架构概览：从左至右依次为仪表盘、Django REST框架应用、Bulu服务（负责收集和缓存集群状态）、Ceph集群及其代理。 技术细节：使用Salt和Salt的ZeroMQ消息总线进行双向通信，通过Python模块与Ceph集群交互。 Romana功能展示 界面概览：提供集群状态的概览，包括OSD状态、集群使用情况等。 管理功能：允许用户进行集群状态的修改，如移动OSD、设置集群标志、创建/删除存储池等。 未来发展方向 硬件状态监控：计划扩展功能，监控底层硬件状态，如硬盘健康状况，并提供相应的API。 集成与扩展：考虑与Nagios、Sensu等监控框架集成，以及如何更好地支持新硬件技术。 决定事项 硬件监控功能：将作为下一版本的重点开发内容，旨在提供更详细的硬件状态信息和预警。 API扩展：计划扩展Calamari的API，使其包含Ceph CLI的所有功能，以便通过API进行完整的集群管理。 后续行动计划 硬件监控API设计：开始设计硬件监控API，并征求社区反馈。 功能扩展：继续扩展Calamari的API功能，特别是管理功能，以支持更多Ceph操作。 社区合作：鼓励社区成员参与Calamari的开发，特别是在硬件监控和API扩展方面。 其他讨论 包装与部署：讨论了Calamari的包装和部署问题，特别是与Yum和Apt等包管理器的兼容性。 上游贡献：提到了将某些功能（如Diamond的Ceph特定统计信息）贡献给上游项目的计划和挑战。 会议结束 会议在讨论了所有议题和问题后结束，并预告了下一次SEF技术讲座的日期和主题。### 会议纪要 会议概述 本次会议是每月一次的SEF技术讲座，由Gregory Meredith主讲，主题是关于Calamari和Romana，这两个项目分别作为Ceph的管理API和GUI。 主要议题 Calamari和Romana的介绍 Calamari：作为API，提供所有在Romana GUI中显示的信息，用户可以通过API执行所有在GUI中可执行的操作。 Romana：作为管理监控仪表板，为用户提供Ceph集群的基本状态概览，包括集群的健康状况、资源使用情况等。 Calamari后端架构 架构从左至右依次为：仪表板、Django REST框架应用（通过Apache提供服务）、Bulu服务（用于收集和缓存集群状态）、Ceph集群上的代理。 Bulu服务通过Salt和Salt的零MQ消息总线与集群上的代理进行通信，实现双向通信。 数据库用于持久化存储用户信息和集群状态历史。 Romana用户界面 基于AngularJS的单页应用，通过Apache提供服务，主要功能是可视化Calamari API的数据。 未来发展方向 计划增加对硬件状态的监控，包括硬盘、SSD等存储设备的智能监控（如SMART）。 考虑集成更多的管理功能，如集群的自动部署和管理，以及与Nagios、Sensu等监控框架的集成。 决定事项 将继续扩展Calamari的API功能，使其能够覆盖Ceph CLI的所有功能。 将重点发展硬件状态监控功能，特别是与存储设备相关的监控。 后续行动计划 完善Calamari的API文档，确保新功能自动更新到文档中。 与社区合作，收集关于新功能开发的需求和反馈。 解决现有包装和部署的问题，特别是与系统包管理器（如yum和apt）的兼容性问题。 其他讨论 讨论了与CBT（Ceph Benchmarking Tool）的潜在集成，以优化集群的等待策略。 探讨了Calamari的包装和部署策略，特别是如何更好地支持主流的Linux发行版。 结论 Gregory Meredith对Calamari和Romana的未来发展表示了积极的展望，并邀请社区成员参与讨论和贡献。会议在感谢和期待下一次技术讲座的氛围中结束。### 会议纪要 会议概述 本次会议是每月一次的SEF技术讲座，由Gregory Meredith主讲，主题是关于Calamari和Romana，这两个项目分别是Ceph的管理API和GUI。 主要议题 Calamari和Romana的介绍 Calamari：作为API，提供所有在Romana GUI中展示的信息，并且可以通过API进行集群状态的修改。 Romana：作为管理监控仪表板，提供对多个Ceph集群的监控和管理功能。 Calamari后端架构 使用Django REST框架，通过Salt和Salt的ZeroMQ消息总线与Ceph集群上的代理进行通信。 使用Thulu服务作为缓存层，快速响应API请求。 数据持久化通过PostgreSQL实现，存储用户信息和集群状态历史。 Romana前端架构 使用AngularJS实现的单页应用，通过Apache服务器提供服务。 未来发展方向 计划增加对硬件状态的监控，包括硬盘、SSD等存储设备的智能监控。 探索与Nagios、Sensu等事件和警报框架的集成。 决定事项 将继续开发Calamari的API，以实现更多的Ceph管理功能。 将重点放在硬件监控上，特别是存储设备的智能监控。 后续行动计划 完善Calamari的API文档，鼓励社区成员参与开发和测试。 继续讨论和规划硬件监控的具体实现方式和API设计。 探索与现有监控和警报系统的集成可能性。 其他讨论 讨论了Calamari的打包和部署问题，特别是与yum和apt等包管理器的兼容性。 提到了与CBT（Ceph Benchmarking Tool）的潜在集成，以优化Ceph集群的性能。 会议结束 感谢Gregory Meredith的精彩演讲和所有参与者的积极参与。下次会议将在5月27日举行，Florian Haas将讨论Ceph性能优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-MAR-26 -- Ceph Tech Talks: RGW","slug":"2015-MAR-26_--_Ceph_Tech_Talks_-_RGW","date":"2015-03-29T16:00:00.000Z","updated":"2015-03-29T16:00:00.000Z","comments":true,"path":"2015/03/30/2015-MAR-26_--_Ceph_Tech_Talks_-_RGW/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/30/2015-MAR-26_--_Ceph_Tech_Talks_-_RGW/","excerpt":"","text":"会议纪要 会议主题： Ceph Rados Gateway（RGW）架构与工作原理 参会人员： Yehuda（技术负责人）、Patrick（主持人）、Eric、Lucas、Derek、Tyler、Abhishek 等 会议内容： Ceph 架构概述： Ceph 是一个可扩展的分布式存储系统，核心包含对象存储（Rados）、块存储（RBD）和文件系统（CephFS）。RGW 作为 Ceph 的对象存储网关，提供 S3 和 Swift 兼容接口。 RGW 工作原理： RGW 利用 Librados 接口与 Ceph 存储集群通信，通过多个进程处理 S3 或 Swift 请求。 RGW 支持多种前端，包括 FastCGI 服务器和 CivetWeb 内置服务器。 RGW 内部模块包括：前端、RESTful API、执行层、数据管理、用户管理、认证、垃圾回收等。 RGW 对象存储与传统对象存储在对象大小、可变性、索引等方面有所不同。 RGW 使用对象类（Object Class）扩展功能，例如桶索引维护、使用情况记录、垃圾回收、建议锁定等。 RGW 支持多区域配置，包括主区域、副本区域和灾难恢复区域。 RGW 支持数据同步、元数据同步和用户管理。 未来工作计划： 多区域配置的主动架构 多租户支持 对象过期功能 通过 NFS 导出 RGW 对象 探索其他功能，例如元数据缓存、对象类扩展等。 讨论要点： CivetWeb 服务器是否可用于生产环境：CivetWeb 服务器已准备好用于生产，性能和稳定性良好。 不同版本的 RGW 和 Ceph 是否兼容：完全解耦于 Librados，理论上应兼容不同版本的 Ceph，但建议使用相同版本以获得最佳性能。 RGW 实例数量限制：RGW 实例数量过多可能导致性能问题，建议根据实际情况进行调整。 列出非所有者桶的功能：目前 S3 接口不支持此功能，但可以通过管理员元数据 API 列出所有桶。 上传对象时生成 MD5 校验和：目前没有计划实现此功能，但可以使用提供的 ETag 作为校验和。 将 RGW 作为 OpenStack Swift 的替代方案：RGW 可以作为 OpenStack Swift 的替代方案，但可能存在一些功能差异。 行动计划： Yehuda 将继续完善 RGW 的功能和性能。 社区成员将参与测试和反馈，推动 RGW 的发展。 下一期技术研讨会将于 4 月 23 日举办，主题为 Calamari。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- OSD: Transactions","slug":"CDS_Infernalis_Day_2.2_--_OSD_-_Transactions","date":"2015-03-06T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/07/CDS_Infernalis_Day_2.2_--_OSD_-_Transactions/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/07/CDS_Infernalis_Day_2.2_--_OSD_-_Transactions/","excerpt":"","text":"会议纪要 会议主题： Ceph Rados Gateway的Hadoop文件接口设计与讨论 参会人员： SE Patrick，其他相关研发人员 会议内容： 1. 背景介绍 项目旨在为Hadoop提供基于SEFS的参考解决方案，基于Stack Sahara项目，该项目基于Swift和UFS。 由于存储服务器与Hadoop集群位于隔离网络，无法使用Hadoop与FFS插件，因此采用SEF Ros Gateway作为连接器。 利用Caching Tier技术，在Rados Skateway服务器中使用SSD缓存数据。 2. 解决方案概述 方案包含四个组件：Rgw FS、RW Proxy、RW Cluster和Caching Tier。 Rgw FS作为Hadoop插件，使Hadoop可以与Rados Skateway目录通信。 RW Proxy类似于HDFS的NameNode，负责获取数据块位置。 RW Cluster使用Caching Tier技术，将数据缓存到SSD中。 3. 关键技术讨论 RW Proxy： 负责获取数据块位置，需要理解Ros Gateway对象到Ros对象的映射关系。 需要监控RW实例，以便进行故障转移。 可以通过增加Gateway管理RESTful命令来实现。 Caching Tier： 使用SSD缓存数据，提高读取性能。 需要配置专门的chunk size和RW Max chunk size。 数据读取流程： Hadoop作业通过RW FS读取数据。 RW Proxy根据数据位置选择最接近的RW实例。 RW实例从Caching Tier读取数据。 数据写入流程： Hadoop作业通过RW Proxy写入数据。 RW Proxy将数据写入Caching Tier。 RW实例将数据写入Ros集群。 4. 讨论与决定 RW Proxy： 可以通过增加Gateway管理RESTful命令来实现故障转移。 可以使用多个副本来提高读取性能。 Caching Tier： 需要配置专门的chunk size和RW Max chunk size。 数据写入： Hadoop作业写入数据时，不会覆盖现有对象，需要配置新的对象名称。 5. 后续行动计划 完成RW Proxy和Caching Tier的实现。 对RW FS进行优化，减少对头对象的读取。 将解决方案集成到Stack Sahara项目中。 6. 其他讨论 讨论了使用Hadoop直接访问CFS的性能问题。 认为在RW和Swift之间引入中间件可以提高性能。 总结： 本次会议讨论了Ceph Rados Gateway的Hadoop文件接口设计方案，并确定了后续的行动计划。该方案旨在提高Hadoop在Ceph存储系统上的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- CephFS && OpenStack","slug":"CDS_Infernalis_Day_1_--_CephFS_OpenStack","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_CephFS_OpenStack/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_CephFS_OpenStack/","excerpt":"","text":"会议纪要 会议主题： SEFS 多租户特性及 OpenStack 相关议题 会议时间： 2023年11月（具体日期未提及） 参会人员： Sage、Danny、Josh、Mark 等 会议内容： 一、OpenStack 相关议题 第三方测试： 目前 OpenStack 代码库中缺乏第三方测试支持，需要为 OpenStack 集群搭建测试环境，并在每次提交或代码审查时进行测试。 建议由 Red Hat OpenStack 团队、Marantis、Canonical 等已拥有 OpenStack 测试环境的组织承担测试工作，并将 SEFS 测试集成到其测试中。 SEFS for Manila： Manila 是 OpenStack 中用于共享文件的组件，目前有几种方法可以将 SEFS 与 Manila 集成： 使用默认驱动程序，将卷映射到 Manila VM，并导出 NFS。 使用 Ganesha 驱动程序，将现有共享文件系统重新导出为 NFS。 开发原生驱动程序，使客户机直接映射 SEFS 文件系统。 使用 9p 协议，将客户机文件系统映射到主机文件系统。 建议使用 Ganesha 驱动程序，因为它提供了网络隔离和多租户支持。 需要解决 Manila 对共享文件系统功能的要求，例如快照和克隆，以及与 Swift 对象存储兼容性问题。 Swift 兼容性： 目前 SEFS 与 Swift 的兼容性存在一些差距，例如命名空间处理、对象版本和过期等。 建议更新 Swift 测试套件，并修复 Swift 兼容性相关的缺陷。 可以考虑实现 Swift 对象版本，但优先级较低。 二、多租户特性 安全： 需要实现以下安全特性： 读取权限 根权限限制 基于路径的挂载限制 数据路径安全 命名空间隔离 性能： 需要优化性能，例如减少网络跳数和优化数据路径。 三、行动计划 搭建 OpenStack 测试环境，并集成 SEFS 测试。 开发 Ganesha 驱动程序，并将其集成到 Manila 中。 更新 Swift 测试套件，并修复 Swift 兼容性缺陷。 实现多租户安全特性。 优化 SEFS 性能。 四、其他 需要收集用户对多租户功能的需求，以便确定优先级。 需要考虑在多租户环境下共享数据的问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Ceph && Containers","slug":"CDS_Infernalis_Day_1_--_Ceph_Containers","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Ceph_Containers/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Ceph_Containers/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： Sebastian、[其他参会人员] 会议主题： Ceph 分布式存储 Docker 集成工作及 Ceph 作为容器存储提供商的讨论 会议内容： 一、Ceph Docker 集成工作 Sebastian 介绍了 Ceph Docker 集成工作的最新进展，包括： 基于 GitHub 上的 soccer SF 项目进行了改进，并将其移至 get-up-st 环境中。 提供了官方的 Ceph Docker 镜像，包括监控器、OSD、MDS、Rgw 等组件。 支持 Ceph Web 界面（CIT）在 Rgw 上的集成，并已合并。 使用 etcd 进行分布式配置，方便快速部署 Ceph 集群。 考虑使用 comd 生成模板，以便在 console 和 etcd 中重用。 目前已有一些基于 Firefly 的镜像，计划创建更多分支以支持不同版本。 已解决 Docker 镜像中的 bug，并有人提出了自己的解决方案。 讨论了 Ceph Docker 镜像的版本问题，以及如何支持不同版本。 讨论了 Ceph 与其他存储解决方案（如 Coros）的兼容性问题。 二、Ceph 作为容器存储提供商 讨论了如何将 Ceph 作为存储提供商集成到 Docker 和 Kubernetes 中。 讨论了 Docker 中的存储抽象（volume）模型，以及如何使用 Ceph 作为后端存储。 讨论了 Ceph 在 Kubernetes 中的集成方案，包括使用 csi 驱动程序。 讨论了在 Atomic 操作系统上集成 Ceph 的挑战，以及如何解决命名空间问题。 讨论了 Ceph 与其他存储解决方案（如 Coros）的兼容性问题。 三、行动计划 Sebastian 将继续推进 Ceph Docker 集成工作，并创建更多分支以支持不同版本。 讨论了 Ceph 与其他存储解决方案的兼容性问题，并计划进一步研究。 讨论了 Ceph 作为容器存储提供商的集成方案，并计划进一步研究。 四、其他 讨论了 Fedora 21 的发布计划，以及 Ceph 在 Fedora 21 上的支持。 讨论了 Ceph 在 Kubernetes 中的集成方案，并计划进一步研究。 五、总结 本次会议讨论了 Ceph 分布式存储 Docker 集成工作和 Ceph 作为容器存储提供商的讨论，并制定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Accelio XIO Integration with kernel RBD","slug":"CDS_Infernalis_Day_1_--_Accelio_XIO_Integration_with_kernel_RBD","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Accelio_XIO_Integration_with_kernel_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Accelio_XIO_Integration_with_kernel_RBD/","excerpt":"","text":"会议纪要 会议主题： Ceph 存储系统中加速器 YIO 与 RBD 客户端集成 会议时间： 2023年11月（具体日期未提及） 参会人员： Raju（视频会议字幕翻译及总结人员）、Roger（Colonel 端 XIO 传送协议开发者）、Patrick（讨论主持人） 会议内容： 1. 项目背景与目标 - 项目旨在将加速器 YIO 与 Ceph 存储系统中的 RBD 客户端进行集成，以提高 I/O 性能。 - 目前，Colonel 端的 XIO 传送协议已经实现，但缺少与 RBD 客户端的集成。 2. 项目进展 - Roger 已完成 XIO 传送协议的内核端开发，并实现了与 Safe 集群的通信。 - Roger 对当前 Colonel 客户端进行了修改，增加了动态加载新传送协议的支持，并提供了新的选项供用户指定使用哪种传送协议。 - 为了兼容现有代码，Roger 将现有的基于 TCP 的传送协议作为默认选项。 3. 关键技术 - XIO 传送协议：一种高效的 I/O 传送协议，可以替代 TCP 进行数据传输。 - 动态加载传送协议：允许用户在运行时加载不同的传送协议，以适应不同的场景。 - RBD 客户端：Ceph 存储系统中用于访问 RBD 对象的客户端。 4. 后续行动计划 - Roger 将在几周内完成代码清理和测试，并将补丁提交给评审。 - 进行性能测试，确保 RBD 函数和视频操作（克隆、快照等）正常工作。 - 探索 XIO 传送协议的性能瓶颈，并寻求优化方案。 - 将 XIO 传送协议集成到 Ceph 存储系统中，并确保与其他组件兼容。 5. 其他讨论 - 关于 XIO 传送协议的多协议支持，需要进一步研究。 - 需要确定如何标记不同类型的地址，以便区分 XIO 和 TCP/IP 地址。 - 需要与其他团队协作，确保 XIO 传送协议能够顺利集成到 Ceph 存储系统中。 备注： - 会议中提到的部分技术术语如下： - XIO：一种高效的 I/O 传送协议。 - RBD：Ceph 存储系统中用于存储数据的对象存储系统。 - TCP：传输控制协议，一种广泛使用的网络协议。 - IP：互联网协议，一种用于数据传输的网络协议。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Clustered SCSI Target using RBD","slug":"CDS_Infernalis_Day_1_--_Clustered_SCSI_Target_using_RBD","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Clustered_SCSI_Target_using_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Clustered_SCSI_Target_using_RBD/","excerpt":"","text":"会议纪要 会议时间： [请填写具体时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph分布式存储集群Scuzzy目标使用RBD状态更新及讨论 会议内容： Scuzzy目标使用RBD状态更新 Mike Christie介绍了Scuzzy目标使用RBD状态的进展，主要包括以下五个方面的完成情况： 配置和设备状态分发：计划使用Pacemaker进行配置和设备状态分发。 设备资源代理修改：已完成对现有iscsi和scsi目标以及设备资源代理的修改，以支持主动-主动模式。 LIO存储管理修改：与LIO存储管理团队合作修改其库、插件和工具，以创建目标。 RBD设备池的概念：正在研究如何从RBD设备中创建RBD设备池的概念，以支持多种目标。 持久组和预留：使用dlm和coral sync提供集群锁定，并保护pgr元数据。 比较和右支持：为ESX提供原子测试和设置命令，以支持其VA功能。 Scy任务管理和统一关注：需要解决命令超时和处理程序失败的问题。 任务管理和设备重置 讨论了处理任务管理和设备重置的方案，包括： 主动-主动模式：通过Pacemaker设置目标，并使用各种管理工具进行配置。 设备重置：在大多数情况下，等待所有命令完成以进行设备重置。 错误恢复：在失败的情况下，进行高级错误恢复，如注销会话。 超时和IO挂起 讨论了IO挂起和超时的问题，包括： OSD检测超时：OSD检测超时为20秒，IO可能需要30秒或更长时间。 超时处理：在30秒到1分钟内未完成的命令将发送中止任务，中止任务超时为5秒到1分钟。 IO挂起处理：需要研究在OSD或类似层中如何解除IO挂起。 跨集群通信 讨论了跨集群通信的方案，包括： 轻量级会话转换：如果网关都未失败，则通过轻量级会话转换进行会话转换，避免进行fencing。 Pacemaker监控：在每个节点上检测网关状态，并在监控调用中检查Scuzzy层或iscsi层是否运行。 RBD命令：使用Pacemaker用户空间监控调用RBD命令，以检测RBD层是否运行。 通知和缓存 讨论了通知和缓存的方案，包括： RBD头部通知：使用RBD头部进行通知，以便在设置元数据后通知其他节点。 缓存更新通知：实现缓存更新通知，以便在节点更新缓存后通知其他节点。 行动计划： Mike Christie将继续研究Scuzzy任务管理和设备重置的解决方案。 与LIO存储管理团队合作修改其库、插件和工具。 研究跨集群通信的方案，并实现轻量级会话转换。 实现通知和缓存更新通知。 后续会议： [请填写后续会议时间及主题]","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Calamari Discussion","slug":"CDS_Infernalis_Day_1_--_Calamari_Discussion","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Calamari_Discussion/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Calamari_Discussion/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： [请填写参会人员名单] 会议主题： Calamari 客户端重命名及高级故事实现讨论 会议内容： 1. Calamari 客户端重命名 由于“Calamari”名称容易引起混淆（指代API或UI），决定将其重命名为“Rana”。 “Rana”将成为上游仓库，并作为UI的参考实现。 “Rana”将继续使用MIT许可证，并按与Calamari相同的节奏发布版本。 预计在“Hammer”版本发布后约一个月推出“Rana”的第一个版本。 2. 高级故事实现 讨论了如何在智能API中实现高级故事，并通过Calamari API的现有功能进行深入分析。 以“管理员可以不中断I/O扩展存储池的PG数”为例，展示了如何通过API进行更新操作。 分析了Calamari架构中涉及的各个组件，包括： Calamari REST API：负责处理HTTP请求和验证。 Thulu服务：负责将REST请求映射到Seth命令。 Salt：用于节点控制和配置管理。 Python模块：用于与Seth集群交互。 3. 其他议题 讨论了如何实现“管理员收到OSD可能失败的警报”的功能。 提出了使用Smartmon工具或其他工具来实现此功能的想法。 鼓励社区成员加入邮件列表或提交问题跟踪器，以提供反馈和贡献。 行动计划： Gregory将创建问题跟踪器条目，以跟踪Calamari客户端重命名和高级故事实现的工作。 社区成员可以加入邮件列表或提交问题跟踪器，以提供反馈和贡献。 讨论了如何实现“管理员收到OSD可能失败的警报”的功能，并鼓励社区成员提供反馈。 备注： 会议中提到的关键概念和技术包括： Calamari Rana REST API Thulu服务 Salt Python模块 Seth集群 Smartmon工具 总结： 本次会议讨论了Calamari客户端的重命名和高级故事实现，并介绍了Calamari架构和实现细节。会议还讨论了其他相关议题，并制定了行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- OSD: Less Intrusive Scrub","slug":"CDS_Infernalis_Day_1_--_OSD_-_Less_Intrusive_Scrub","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_OSD_-_Less_Intrusive_Scrub/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_OSD_-_Less_Intrusive_Scrub/","excerpt":"","text":"会议纪要 会议时间： 2023年某月某日 会议地点： 线上 参会人员： Sam（主持人）、其他研发人员 会议主题： 讨论并优化Ceph中OSD的scrub选项，减少其对系统性能的影响。 关键细节： scrub优化目标： 减少scrub操作对系统性能的影响，提高效率。 主要议题： 减少scrub对性能的影响： 通过随机化scrub调度时间、选择更细粒度的scrub操作、提高scrub操作优先级等措施来减少scrub对系统性能的影响。 统一工作队列： 完成统一工作队列的实现，以便更好地管理scrub操作。 scrub调度策略： 优化scrub调度策略，使其更加智能，例如根据负载情况进行动态调整。 优先级问题： 解决优先级反转问题，确保scrub操作在关键时刻能够获得足够的资源。 scrub窗口大小： 调整scrub窗口大小，例如将窗口大小设置为单个对象，以减少调度开销。 决定的事项： 完成统一工作队列的实现。 随机化scrub调度时间，例如将深度scrub间隔设置为一周加减四天。 选择更细粒度的scrub操作，例如在chunk级别进行决策。 提高scrub操作优先级，确保其在关键时刻能够获得足够的资源。 调整scrub窗口大小，例如将窗口大小设置为单个对象。 实现scrub操作限制，例如限制scrub操作的速度（例如每秒处理的对象数量或每秒处理的字节数）。 添加健康警告，当无法在指定时间内完成scrub操作时，向管理员发出警告。 后续行动计划： Sam将负责完成统一工作队列的实现。 其他研发人员将根据会议讨论结果，进一步优化scrub操作。 添加健康警告功能。 评估scrub操作限制的效果。 关键词： scrub OSD unified work queue priority inversion throttling quality of service","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- OSD: Erasure Coding Pool Overwrite Support","slug":"CDS_Infernalis_Day_1_--_OSD_-_Erasure_Coding_Pool_Overwrite_Support","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_OSD_-_Erasure_Coding_Pool_Overwrite_Support/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_OSD_-_Erasure_Coding_Pool_Overwrite_Support/","excerpt":"","text":"会议纪要 会议主题： Erasure Coding 池覆盖支持讨论 会议时间： 系列会议第二天 参会人员： 多位 Ceph 开发者，具体姓名未提及 会议内容： 主要议题： 讨论了在 Erasure Coding (EC) 池中实现覆盖支持的可能性，尤其是针对 Rados Block Device (RBD) 的应用。 分析了不同实现方案的优缺点，包括： 回滚日志： 在写入数据时，同时将旧数据写入回滚日志，以便在发生错误时恢复。 两阶段提交： 在所有副本确认后，再应用更新，并确保读取操作在写入提交之前被阻塞。 不支持覆盖： 保留现有的只追加写入方式，不提供覆盖支持。 改进 RBD 数据布局： 将数据以固定块的形式存储，并使用日志记录未提交的更新。 缓存层实现： 在缓存层中实现部分对象覆盖，以避免在 EC 池中直接实现。 讨论结果： 两阶段提交： 被认为是一个值得尝试的方案，因为它具有确定性、可预测性和与 RAID 类似的行为。 回滚日志： 由于需要额外的写入操作，可能引入较大的延迟，因此被认为不如两阶段提交方案。 不支持覆盖： 被认为是最简单的方法，但可能无法满足某些应用的需求。 改进 RBD 数据布局： 被认为是一个可行的方案，但需要进一步研究和评估。 缓存层实现： 被认为是一个复杂的方案，但可能能够避免其他方案的缺点。 行动计划： 由参会者之一负责实现两阶段提交方案或原型。 进一步研究其他方案的可行性和实现细节。 在决定最终方案之前，进行更多的讨论和评估。 其他要点： 实现覆盖支持需要修改 Ceph 的某些核心组件，例如 PG 信息和 OSD 类。 在实现覆盖支持之前，需要考虑数据一致性和可用性等问题。 需要评估不同方案的性能和可扩展性。 关键词： Erasure Coding (EC) 覆盖支持 Rados Block Device (RBD) 回滚日志 两阶段提交 PG 信息 OSD 类","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- OSD: Scrub and Repair","slug":"CDS_Infernalis_Day_1_--_OSD_-_Scrub_and_Repair","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_OSD_-_Scrub_and_Repair/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_OSD_-_Scrub_and_Repair/","excerpt":"","text":"会议纪要： 会议主题： OSD 岛屿马拉松会议，讨论 scrub 和 repair 功能的蓝图。 会议关键细节： 议题： 开发一个 Rados 接口，用于查询 PG 的修复状态。 创建一个命令行工具，可以查询不一致的对象和 PG，并决定如何处理。 接口包含以下功能： 查询不一致的 PG。 获取不一致对象的信息。 使用 PDT 修复不一致对象。 该接口目前不适用于纠删码 PG，但对于红帽 TG 应该足够。 讨论的主要议题： 如何记录不一致信息，并将其持久化存储。 如何处理不一致信息的更新和过期。 如何在修复过程中读取特定副本或碎片。 如何处理不一致对象的修复。 决定的事项： 开发一个 Rados 接口，用于查询 PG 的修复状态。 创建一个命令行工具，可以查询不一致的对象和 PG，并决定如何处理。 将不一致信息记录在一个临时对象中，并使用 omap 进行管理。 在修复过程中读取特定副本或碎片。 修复不一致对象时，首先尝试修复，如果失败则重写。 后续行动计划： David 负责编写不一致信息的记录和查询代码。 David 负责编写命令行工具。 David 负责编写修复不一致对象的代码。 其他成员协助开发测试代码。 其他事项： 讨论了使用多个碎片导入功能的重要性。 讨论了修复未找到对象的方案。 讨论了修复不一致对象时需要传播哪些元数据。 关键词： OSD scrub repair PG Rados omap PDT *纠删码 红帽 TG 未找到对象 元数据","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- RBD: Async Mirroring","slug":"CDS_Infernalis_Day_1_--_RBD_-_Async_Mirroring","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_RBD_-_Async_Mirroring/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_RBD_-_Async_Mirroring/","excerpt":"","text":"会议纪要 会议主题： 异步镜像机制的设计与讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Josh（主持人）、Jason、Lars、LS 等 会议内容： 1. 会议背景与目标 目前Ceph的RBD镜像支持在集群内同步复制，但缺乏灾难恢复能力。本次会议旨在讨论并设计一种异步镜像机制，实现RBD镜像在不同数据中心或地理位置的复制，保证数据一致性和灾难恢复能力。 2. 设计方案 异步镜像机制： 基于RBD镜像的完整日志，实现数据异步复制。 日志存储： 使用对象存储池存储日志，可配置为与RBD存储池相同或不同。 日志模式： 支持写入回模式（writeback）和写入透传模式（writethrough）。 日志管理： 通过Journal header记录日志信息，包括填充策略、前缀、flush位置、不同站点/区域的复制位置等。 复制粒度： 可在单个RBD镜像或整个存储池级别进行配置。 3. 关键技术 日志记录： 使用独占锁确保日志写入的原子性。 数据一致性： 通过完整数据日志保证复制数据的完整性。 性能优化： 通过缓存机制减少写操作对性能的影响。 4. 讨论与决策 日志存储位置： 可配置为与RBD存储池相同或不同，以提高性能。 复制粒度： 可在单个RBD镜像或整个存储池级别进行配置。 一致性组： 可支持多个RBD镜像共享同一个日志，提高效率。 后续工作： 设计并实现日志模块。 实现异步复制功能。 优化性能。 5. 行动计划 Josh：负责设计日志模块。 Jason：负责实现异步复制功能。 Lars：负责性能优化。 LS：负责测试。 总结： 本次会议讨论了Ceph异步镜像机制的设计方案，明确了关键技术、讨论了相关技术问题，并制定了后续行动计划。该方案将为Ceph提供强大的灾难恢复能力，提高数据安全性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Community && Governance","slug":"CDS_Infernalis_Day_1_--_Community_Governance","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Community_Governance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Community_Governance/","excerpt":"","text":"会议纪要 会议主题： Ceph 项目治理讨论及 SEF 用户委员会更新 会议时间： 2023年11月（具体日期未提及） 参会人员： 项目领导 Sage、SEF 用户委员会主席 Eric、其他 Ceph 社区成员 会议内容： 一、SEF 用户委员会更新 SEF 用户委员会由 Sage 创立，最初目的是让用户对 Ceph 社区拥有实际的控制权。 用户委员会负责发布说明、组织会议等活动，是 Ceph 社区的重要组成部分。 目前，Eric 担任 SEF 用户委员会主席，负责推动委员会的发展。 二、Ceph 项目治理 Ceph 项目的治理结构将包括三个主要部分：董事会、技术委员会和用户委员会。 董事会：负责社区推广、宣传、营销、品牌管理、冲突解决等。 技术委员会：由组件技术负责人组成，负责技术决策和实现。 用户委员会：负责用户需求、反馈和建议，并参与项目决策。 项目领导：负责制定项目方向，并协调各个委员会的工作。 其他角色：包括执行董事、学术联络人等。 三、自我治理 自我治理的目标是建立一个开放、参与式、透明的治理结构。 强调透明度，确保所有决策都在公共场合进行并记录在案。 鼓励社区成员参与治理，并提供反馈和建议。 四、其他讨论 IP 管理和品牌政策：Ceph 项目将建立一个 IP 管理和品牌政策，以确保 Ceph 版权和品牌得到妥善管理。 社区资源：Red Hat 将为社区提供更多资源，包括测试实验室、硬件等。 用户委员会发展：将推动用户委员会的发展，并赋予其更多职责。 五、后续行动计划 在 Ceph Ether pad 上发布治理结构和商标政策的文档，供社区成员讨论和反馈。 推动自我治理的实施，确保社区有更强的代表性和参与度。 六、关键点 Ceph 项目治理结构将更加开放和透明。 社区成员将参与治理，并提供反馈和建议。 Red Hat 将为社区提供更多资源和支持。 七、关键词 Ceph 治理 自我治理 用户委员会 董事会 技术委员会 IP 管理 品牌政策 社区资源","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Ceph Plugins","slug":"CDS_Infernalis_Day_1_--_Ceph_Plugins","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Ceph_Plugins/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Ceph_Plugins/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： Luik、Verada、Mike、Josh等 会议主题： 在Ceph中添加私有键值存储作为可插拔模块，并讨论插件安装和升级的一般支持。 关键细节： 现有插件系统： Ceph目前有两个插件系统，一个是CLS插件系统，用于在OSD上运行二进制程序；另一个是Azure代码插件系统，用于加载插件并在OSD上运行。 新插件系统： SanDisk希望创建一个新的对象存储键值存储抽象，该抽象能够加载实现此抽象的插件，但可能不包含在Ceph中。这引发了对更通用插件系统的需求。 插件集成测试： 引入插件需要集成测试来验证其与现有集群的兼容性，以确保在升级过程中不会出现问题。 插件分发： 插件应以操作系统包的形式分发，并使用标准分发工具进行安装和升级，以避免重复造轮子。 插件版本控制： 插件版本字符串应与OSD版本严格匹配，以确保兼容性。 插件加载机制： 需要一个机制，使OSD和Monitor能够同意一个插件白名单，以便在创建存储池时使用。 插件接口： 插件接口应以C++虚拟类形式定义，以便动态加载和实现。 讨论的主要议题： 插件集成测试： 如何简化插件集成测试过程，确保插件与现有集群兼容。 插件分发： 如何使用标准分发工具分发插件，并确保其兼容性和稳定性。 插件版本控制： 是否需要放松插件版本字符串与OSD版本匹配的要求。 插件加载机制： 如何实现一个通用的插件加载机制，使OSD和Monitor能够同意一个插件白名单。 插件接口： 是否使用C++虚拟类定义插件接口，以及如何处理C++接口的兼容性问题。 决定的事项： 插件集成测试： 将讨论如何简化插件集成测试过程。 插件分发： 将使用标准分发工具分发插件，并确保其兼容性和稳定性。 插件版本控制： 将继续使用严格匹配的插件版本字符串与OSD版本。 插件加载机制： 将讨论如何实现一个通用的插件加载机制。 插件接口： 将使用C++虚拟类定义插件接口，并考虑使用C接口作为中间层。 后续行动计划： Luik将更新Pad笔记，并提供更多关于通用插件系统实现方案的详细信息。 Team将讨论如何简化插件集成测试过程。 Team将研究如何使用标准分发工具分发插件，并确保其兼容性和稳定性。 Team将讨论如何实现一个通用的插件加载机制。 Team将讨论如何处理C++接口的兼容性问题。 备注： 会议中讨论了C++接口的兼容性问题，并提出了使用C接口作为中间层的方案。 会议中讨论了使用标准分发工具分发插件的方案，并强调了其重要性和优势。 会议中讨论了如何简化插件集成测试过程，并强调了其对于确保插件兼容性的重要性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- RGW: Active/Active Arch","slug":"CDS_Infernalis_Day_1_--_RGW_-_Active_Active_Arch","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_RGW_-_Active_Active_Arch/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_RGW_-_Active_Active_Arch/","excerpt":"","text":"会议纪要 会议主题： RGW（Rados Gateway）的Active-Active架构讨论 参会人员： Yehuda（会议主持人）、其他研发人员 会议内容： 1. 当前架构概述 介绍当前RGW的多区域、多区域架构，包括区域（Region）、区域组（Zone Group）、区域（Zone）等概念。 解释了区域组的灾难恢复机制，即每个区域组内有一个主区域和一个或多个辅助区域，用于数据备份和恢复。 2. Active-Active架构的挑战 区域概念混淆： “区域”一词容易与数据中心混淆，建议将“区域”更名为“区域组”，以避免混淆。 单区域写入问题： 当前架构下，每个区域组内仅有一个可写入的区域，限制了读写操作的灵活性。 同步机制： 需要改进同步机制，使数据在不同区域组之间保持一致性。 对象版本控制： 需要改进对象版本控制机制，以支持多区域环境。 3. 解决方案 区域组名称变更： 将“区域”更名为“区域组”，以避免混淆。 多区域写入： 支持每个区域组内的多个区域进行读写操作，提高读写性能和可用性。 改进同步机制： 每个区域维护自己的日志，以便跟踪其他区域的变化。 同步代理（Sync Agent）负责同步区域之间的日志，并执行相关命令。 需要处理不同区域上的同一对象上的更改冲突。 对象版本控制： 使用计数器和时间戳的组合来替换当前的Epoch方案，以保持对象版本顺序。 需要处理同一时间戳上的更改冲突。 4. 其他讨论 同步代理的改进：需要改进同步代理，使其能够处理多个区域，并支持更复杂的同步策略。 失败切换：需要改进失败切换机制，以便在切换到辅助区域时保持数据一致性。 时间同步：需要确保区域组之间的时间同步，以避免时间漂移问题。 5. 后续行动计划 进一步完善Active-Active架构的设计方案。 修改RGW代码，以实现Active-Active架构。 进行测试，验证Active-Active架构的可行性和性能。 关键词： Active-Active架构、区域组、区域、同步、对象版本控制、同步代理、失败切换、时间同步","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- RGW: NFS","slug":"CDS_Infernalis_Day_1_--_RGW_-_NFS","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_RGW_-_NFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_RGW_-_NFS/","excerpt":"","text":"会议纪要 会议时间： 2023年[具体日期] 会议地点： [具体地点或线上会议平台] 参会人员： [参会人员名单] 主持人： [主持人姓名] 会议主题： Rados Gateway (RGW) 新功能：通过NFS导出数据 会议内容： 议题背景： 讨论了RGW的新功能，即通过NFS导出数据。 目前RGW无法直接进行NFS导出，需要通过抽象层或第三方工具实现。 讨论方案： 方案一： 创建librgw库，提供数据访问接口，连接Ganisha。 优点：利用现有框架，降低开发难度。 缺点：需要处理用户权限和上下文，可能需要修改Ganisha代码。 方案二： 创建更高层次的RGW库，在请求处理层面进行操作。 优点：实现简单，易于实现。 缺点：效率可能低于方案一。 方案选择： 与会人员倾向于选择方案二，即创建更高层次的RGW库。 需要进一步研究其他系统（如Swift、FS Gateway）的NFS导出实现方式，以获取参考。 行动计划： 收集其他系统的NFS导出实现方式，了解用户需求和期望。 设计并实现更高层次的RGW库。 与Ganisha团队沟通，探讨可能的合作方式。 关键词： Rados Gateway, NFS, librgw, Ganisha, S3FS, 用户权限, 请求处理 备注： 会议中提到S3FS和Ganisha的兼容性问题，需要进一步研究解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- RGW: Multitenancy","slug":"CDS_Infernalis_Day_1_--_RGW_-_Multitenancy","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_RGW_-_Multitenancy/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_RGW_-_Multitenancy/","excerpt":"","text":"会议纪要 会议主题： RGW 多租户功能讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位 Ceph 领域研发人员及相关技术人员 会议内容： 一、多租户功能概述 会议首先回顾了 RGW（Rados Gateway）的多租户功能，指出当前 RGW 用户模块采用全局命名空间，所有用户和存储桶共享同一命名空间。 为实现多租户功能，会议提出了以下方案： 每个 RGW 用户将拥有一个租户属性，每个存储桶也将拥有一个租户属性。 所有现有用户将位于全局租户中，而新用户（属于不同租户）将继承其租户属性。 存储桶在不同租户之间无需唯一，只需在租户内部唯一。 用户可以通过租户引用，例如“租户列用户”，来引用用户，存储桶也可以通过租户引用。 二、与 S3 协议的兼容性 会议讨论了多租户功能与 S3 协议的兼容性。 对于 S3 协议，会议提出了以下方案： 用户可以通过指定租户来访问特定存储桶，如果未指定租户，则默认使用用户所属的租户。 可以通过不同的域名来区分不同租户的存储桶，例如使用二级域名或完全不同的域名。 三、其他功能和扩展 会议讨论了多租户功能的进一步扩展，包括： 在租户级别配置存储策略、放置目标、配额等。 为租户提供统计信息。 实现租户管理员功能。 四、与 Keystone 的集成 会议讨论了多租户功能与 Keystone 的集成。 目前，Keystone 租户映射到 RGW 用户，会议提出了两种方案： 保持当前映射方式。 将 Keystone 用户映射到租户，将 Keystone 租户映射到 RGW 用户。 五、角色认证 会议讨论了基于角色的认证方案。 用户在特定租户中仅拥有特定权限。 六、S3 API 中的租户概念 会议讨论了是否将租户概念添加到 S3 API 中。 会议决定将租户概念添加到 S3 API 中，包括 Swift。 七、子用户概念 会议讨论了子用户概念的利弊。 会议认为子用户概念是一个“Hack”，应该被废弃，但可能需要考虑其他替代方案。 八、下一步行动 实施多租户功能的初步方案。 与 Swift API 用户进行交流，了解其对多租户功能的反馈。 完善测试用例，确保多租户功能正常工作。 九、会议总结 会议对 RGW 多租户功能进行了深入的讨论，并制定了下一步行动计划。 多租户功能将为 Ceph 提供更好的多租户支持，并提高系统的可扩展性和安全性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- Cache Tier Improvements","slug":"CDS_Infernalis_Day_2.2_--_Cache_Tier_Improvements","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_Cache_Tier_Improvements/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_Cache_Tier_Improvements/","excerpt":"","text":"会议纪要 会议主题： Cash Tier改进与Proxy机制讨论 会议时间： [请填写会议具体时间] 参会人员： [请填写参会人员名单] 会议内容： 一、Cash Tier改进 现状与问题： Intel团队在Hammer周期内对Cash Tier进行了大量改进，主要集中在读操作上，避免了不必要的提升（Promotion）。 然而，对于写操作的Proxy机制仍需测试和完善。 当最终决定提升时，仍需阻塞写操作，因为对象尚未提升到Cache层面。 改进方向： 基于现有基础设施，根据读操作和写操作进行更合理的提升决策，以减少在Base Tier和Cash Tier之间推送数据的次数。 引入“最近性”概念，类似读操作的策略，对写操作进行优化。 具体方案： 跟踪不同类型的I/O操作： 区分读和写操作，以及顺序读和顺序写操作。 基于I/O类型进行提升决策： 例如，对于大量读操作但从未写入的对象，可能不需要提升；对于只写入但无读操作的对象，根据性能指标可能需要提升。 使用近似计数Bloom过滤器： 用于跟踪冷数据，而将热数据存储在哈希表中，以便进行精确计数。 二、Hit Set改进 现状与问题： Hit Set目前只能覆盖固定时间间隔（例如1小时），且只能告知是否有一个或多个I/O操作，无法提供具体数量。 无法区分对象在1小时内被读取一次和被读取100,000次的情况。 改进方向： 使用混合哈希表和布隆过滤器，捕获热点数据和非热点数据。 使用近似计数Bloom过滤器，以更精确地跟踪数据。 具体方案： 哈希表和布隆过滤器结合： 哈希表用于存储热点数据，布隆过滤器用于存储非热点数据。 近似计数Bloom过滤器： 用于跟踪对象的热度，并决定何时将对象从哈希表移动到布隆过滤器。 三、行动计划 完成写操作的Proxy机制测试。 实现基于I/O类型的提升决策。 研究并确定实现频繁项和数据流查找的最佳方法。 实现近似计数Bloom过滤器。 四、后续工作 [请填写后续工作安排，例如：分配任务、确定时间节点等。] 五、备注 会议中提到的技术词汇，如“Hit Set”、“Promotion”、“Bloom filter”等，请参考相关资料进行了解。 会议中提到的相关论文和资料，请参考以下链接： Approximate Counting Bloom Filters Min-Mis Rate Curves","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 1) -- Simple ceph-mon dm-crypt key management","slug":"CDS_Infernalis_Day_1_--_Simple_ceph-mon_dm-crypt_key_management","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_1_--_Simple_ceph-mon_dm-crypt_key_management/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_1_--_Simple_ceph-mon_dm-crypt_key_management/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： Milanis, Sam, Simulon, Dr. Bras, Danny 会议主题： Ceph存储系统中OSD的dm-crypt密钥管理方案讨论 关键细节： 当前方案： 使用theftdisk配置dm-crypt，加密密钥存储在etsy和csf keys中，但安全级别较低。 目标： 设计一个比etsy keys更安全的密钥管理方案。 方案讨论： Lux： 使用Lux存储实际dm-crypt密钥，并存储其他信息（如UUID）。 密钥存储方式： 将密钥存储在监控器中，使用另一个密钥允许获取它。 使用Linux密钥系统，将密钥加密存储在磁盘上。 使用UID作为密钥，但需要确保其安全性。 密钥撤销： 需要一个可撤销的密钥，以便在磁盘丢失或损坏时撤销访问权限。 Lux vs. 密钥存储： 讨论了Lux对密钥管理的贡献，以及是否可以将其与密钥存储方案结合使用。 密钥存储位置： 讨论了密钥存储的最佳位置，例如Lux头文件或监控器。 加密方式： 讨论了使用AES或其他加密算法对密钥进行加密。 CLI会话加密： 讨论了在CLI与监控器之间启用加密会话的重要性。 决定的事项： 初步方案：使用Lux存储密钥，并使用另一个密钥允许获取它。 后续行动计划： 完善Lux头文件的使用，确保其安全性。 设计一个可撤销的密钥，以便在磁盘丢失或损坏时撤销访问权限。 实现CLI会话加密，确保命令的安全性。 其他事项： 讨论了Lux与密钥存储方案的结合使用，以及Lux对密钥管理的贡献。 讨论了CLI会话加密的重要性。 讨论了磁盘丢失或损坏时的密钥管理方案。 备注： 需要进一步讨论Lux头文件的使用，以确保其安全性。 需要设计一个可撤销的密钥，以便在磁盘丢失或损坏时撤销访问权限。 需要实现CLI会话加密，确保命令的安全性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- LMDB backend for Ceph","slug":"CDS_Infernalis_Day_2.2_--_LMDB_backend_for_Ceph","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_LMDB_backend_for_Ceph/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_LMDB_backend_for_Ceph/","excerpt":"","text":"会议纪要： 会议主题： SEF（Storage Efficiency Framework）的LMDB键值存储后端方案讨论 参会人员： Patrick、John（Intel）、Shinin、会议主持人 会议内容： 方案概述： John介绍了LMDB（Lightning Memory-Mapped Database）作为SEF的键值存储后端方案的蓝图。 目前SEF的QAL（Quota and Accounting Layer）实现存在一些问题，例如读写放大率较高，且需要将日志写入R Disc。 该方案将包括三个部分： 实现rmdb存储类，继承自qdb，实现基本操作如get、delete和put。 集成rmdb作为子模块，支持自动配置和自动生成。 精炼QB接口，集成一些高级API，如合并操作、前缀迭代器等。 方案讨论： 会议认为尝试LMDB是值得的，可以了解其在键值存储中的表现。 目前SSD设置的性能问题主要在于RSM的压缩和读写放大。 会议建议不要过于依赖文件存储和键值存储的对比，因为它们的应用场景和性能特点不同。 新存储方案的目标是通用性，可以在磁盘和SSD上良好运行，但可能不适合PCI附加的快速闪存等特定场景。 行动计划： 尝试实现LMDB和LMDB接口，以便了解其在键值存储中的表现。 考虑将LMDB集成到监控器中，特别是读取方面。 使用现有的OSD测试工具进行测试，而不是尝试模拟OSD的工作负载。 其他讨论： 讨论了在liberatus中是否需要构建键值接口，以及如何实现。 讨论了如何测试监控器特定的数据库，以及是否可以使用现有的测试工具。 结论： 会议认为尝试LMDB作为SEF的键值存储后端方案是值得的，并制定了相应的行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- OSD: Peering / Latency","slug":"CDS_Infernalis_Day_2.2_--_OSD_-_Peering_Latency","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_Peering_Latency/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_Peering_Latency/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储优化：更快的数据对等连接和降低尾部延迟 会议时间： 2023年11月（具体日期未提及） 参会人员： Sam Guang、Sage、以及其他未具名的研发人员 会议内容： 主要议题： 更快的数据对等连接： 当前Ceph在对等连接过程中，存在多个往返延迟，主要步骤包括： 构建需要通信的OSD列表。 向OSD请求pg notify信息。 确定具有权威pg信息的OSD。 从OSD获取信息并调整日志。 向所有OSD发送info消息，激活它们。 会议讨论了以下优化方案： 基于历史间隔，预先确定具有权威日志的OSD，从而减少获取日志的步骤。 仅请求活动集的缺失日志和日志，而不是请求所有OSD的缺失日志和日志。 在启动对等连接时，如果活动集没有变化，则跳过某些步骤。 在启动对等连接时，如果活动集需要更改，则立即激活并异步等待pg temp重新映射。 降低尾部延迟： 当OSD长时间处于非活动状态时，某些请求可能需要数十秒才能完成，导致尾部延迟。 会议讨论了以下优化方案： 通过在系统启动时预填充pg temp，减少启动时间。 在OSD标记为up后，将其primary affinity设置为0，以避免不必要的IO等待。 在OSD发生崩溃时，立即将其标记为down，而不是等待心跳超时。 客户端驱动读取，允许客户端直接从不同主机读取数据，从而减少网络延迟。 决定事项： 将将“更快的数据对等连接”和“降低尾部延迟”两个蓝图合并为一个。 探索使用客户端驱动读取来解决尾部延迟问题。 考虑在启动对等连接时跳过某些步骤，以减少往返延迟。 考虑将primary affinity设置为0，以避免不必要的IO等待。 探索使用系统启动时预填充pg temp来减少启动时间。 探索在OSD崩溃时立即将其标记为down的方法。 后续行动计划： Sam Guang将更新蓝图，以包含上述讨论的优化方案。 Sage将研究客户端驱动读取的实现方案。 其他研发人员将探索使用客户端驱动读取来解决尾部延迟问题。 团队将评估将primary affinity设置为0的可行性。 团队将评估使用系统启动时预填充pg temp的可行性。 团队将评估在OSD崩溃时立即将其标记为down的可行性。 关键词： Ceph 数据对等连接 尾部延迟 pg temp primary affinity 客户端驱动读取","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- Ceph Performance","slug":"CDS_Infernalis_Day_2.2_--_Ceph_Performance","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_Ceph_Performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_Ceph_Performance/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议主题： Ceph性能分析框架标准化 参会人员： - 来自Intel的同事 - Mark Nelson - 会议主持人及参与者 会议内容： 一、Ceph性能基准测试工具（CBT）与COSBench集成 背景： 目前的Ceph性能基准测试主要依赖于CBT工具，但CBT不支持对象存储基准测试。 因此，COSBench（云对象存储基准测试工具）被提出作为补充。 方案： 将COSBench集成到CBT中，使其能够支持对象存储基准测试。 通过插件模型，将COSBench配置文件转换为CBT可识别的格式，并执行性能测试。 将COSBench测试结果集成到CBT结果中。 讨论： 如何在CBT中实现COSBench的部署和配置。 如何确保COSBench和CBT之间的数据一致性。 二、Ceph性能分析框架（Tracepoint）改进 背景： 现有的Ceph性能分析框架在追踪性能瓶颈方面存在困难。 部分Tracepoint缺乏语义，导致分析过程复杂且耗时。 方案： 使用LTTng和Block和Blockzip作为工具进行性能分析。 引入语义化的Tracepoint，并使用统一的标识符跟踪单个I/O请求。 实现一个通用的Tracepoint框架，包括最重要的Tracepoint和可视化工具。 讨论： 如何解决服务器系统时间差的问题。 如何在Zipkin中实现更清晰的性能分析结果。 三、行动计划 将COSBench集成到CBT中，并实现插件模型。 实现一个通用的Tracepoint框架，并引入语义化的Tracepoint。 将Andrew的Tracepoint补丁合并到Ceph代码库中。 优化Zipkin的Web界面，使其能够更清晰地展示性能分析结果。 四、其他 会议中讨论了COSBench对RGW性能的影响，以及如何检测性能退化。 讨论了在Tracepoint中添加不同级别的追踪功能。 五、总结 本次会议讨论了Ceph性能分析框架的标准化方案，包括CBT与COSBench的集成和Tracepoint框架的改进。会议达成了初步的共识，并制定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- OSD: Newstore","slug":"CDS_Infernalis_Day_2.2_--_OSD_-_Newstore","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_Newstore/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_Newstore/","excerpt":"","text":"会议纪要 会议主题： 新存储后端OSD讨论 会议时间： 未知 参会人员： Sage、其他研发人员 会议内容： 1. 新存储后端OSD的动机和目标 现有的文件存储系统经过多年开发，功能复杂，难以修改和优化。 目标是创建一个新的内部对象存储接口实现，以替换现有的对象存储，并支持多种后端。 新实现将适用于硬盘和SSD，或两者的组合。 主要目标是避免对新对象的重复写入和顺序写入，从而消除当前日志记录带来的开销，并提高小写操作的效率。 2. 新存储后端OSD的技术方案 使用键值数据库（如LevelDB或RocksDB）进行事务和键值数据管理。 使用POSIX文件系统（如XFS）进行块管理。 工作流程： 接收写请求，根据请求类型（新对象、追加到现有对象）打开或创建文件，并将数据写入文件。 使用fsync提交事务，并将文件系统同步到磁盘。 在fsync完成后，将对象大小或存在性信息提交到键值数据库。 对于小写操作，使用写前日志（write-ahead log）进行管理。 3. 技术细节和讨论 同步和异步提交： 当前实现中，事务提交是同步的，可能会增加延迟。计划改为异步提交，以提高性能。 写前日志： 对于小写操作，可以考虑将写前日志项也存储在键值数据库中，以减少磁盘I/O。 优化： 可以利用XFS的特性，例如使用open by handle接口，以减少路径遍历。 测试和评估： 需要对新存储后端进行基准测试，以评估其性能和效率。 4. 行动计划 完成omap的实现。 将事务提交改为异步。 对新存储后端进行基准测试。 考虑使用LMDB作为键值数据库。 5. 其他讨论 使用ODIR/O_SYNC进行同步。 使用检查点方法进行同步。 使用AIO进行异步I/O。 总结： 本次会议讨论了新存储后端OSD的方案和实施细节，并制定了后续行动计划。该方案旨在提高存储性能和效率，并支持多种后端。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- OSD: RADOS I/O Hints","slug":"CDS_Infernalis_Day_2.2_--_OSD_-_RADOS_I_O_Hints","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_RADOS_I_O_Hints/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_RADOS_I_O_Hints/","excerpt":"","text":"会议纪要 会议主题： OSD I/O 提升方案讨论 会议时间： 2023年X月X日 参会人员： John, Ping, 研发团队 会议内容： 议题一：OSD I/O 提升方案 John介绍了在Ceph中实现OSD I/O提升的方案，主要目标是提高客户端使用Ceph的效率。 该方案利用了Ceph的认证框架、Live RBD和RBD库支持，并通过手动修改代码来实现。 方案中使用了CodeBunch作为I/O优化器，并通过手动修改代码来支持文件系统操作。 目标是通过优化内存使用和减少磁盘读取操作，提高系统吞吐量和内存利用率。 议题二：IO hints的应用 讨论了IO hints在Ceph中的应用，包括： 在文件系统中使用mount选项来控制I/O缓存行为。 在RBD中使用不同的缓存策略，如不缓存、使用代理读取等。 在后台操作中使用no-catch选项来避免缓存热点数据。 讨论了IO hints的局限性，例如： Linux内核不支持无缓存读取操作。 需要考虑多客户端同时访问同一对象时的缓存策略。 需要权衡缓存和性能之间的平衡。 议题三：后续行动计划 继续在Hammer版本中实现IO hints框架，并在Live Lab中进行测试。 评估并实现更多IO hints选项，例如： 物理设备缓存选项。 虚拟设备缓存选项。 后台操作缓存选项。 优化IO hints的实现，解决Linux内核不支持无缓存读取操作的问题。 决定事项： 继续推进IO hints的实现，并评估更多应用场景。 在Hammer版本中实现IO hints框架，并在Live Lab中进行测试。 优化IO hints的实现，解决Linux内核不支持无缓存读取操作的问题。 后续行动计划： 研发团队将根据会议讨论结果，继续推进IO hints的实现。 研发团队将与内核社区合作，解决Linux内核不支持无缓存读取操作的问题。 研发团队将定期更新会议纪要，并汇报项目进展。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- OSD: Tiering","slug":"CDS_Infernalis_Day_2.2_--_OSD_-_Tiering","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_Tiering/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_OSD_-_Tiering/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议具体地点] 参会人员： - Sam A. - Shikang - 其他Intel研发人员 会议主题： - Ceph分布式存储系统中的分层存储和动态数据迁移 会议内容： 一、分层存储 背景： 目前Ceph支持分层存储，包括热层、温层和冷层。 会议讨论了如何扩展分层存储功能，使其能够将冷数据迁移到更便宜的存储系统中，例如不同数据中心的其他Ceph集群或S3。 讨论： 插件接口： Sam A. 提出创建一个插件系统，允许将冷数据迁移到指定的插件存储系统中。 该接口应仅支持追加操作，不允许修改对象名称，以简化后端实现。 需要考虑慢速后端（如Glacier或磁带机）的处理，可能需要实现进度指示和错误代码传播。 元数据管理： 需要在Ceph元数据中记录迁移信息，以便在恢复时使用。 需要考虑快照和写操作对迁移的影响。 决定： 开始实现插件接口，并考虑慢速后端的支持。 在插件接口中添加进度指示和错误代码传播功能。 在元数据中记录迁移信息。 二、动态数据迁移 背景： 会议讨论了在Ceph中实现动态数据迁移的功能，以便在分层存储之间动态迁移数据。 讨论： 多级分层存储： Shikang 提出在Ceph中实现多级分层存储，包括热层、温层、冷层和更冷的存储系统。 需要考虑如何管理元数据和对象迁移。 手动和自动迁移： 可以通过命令行工具手动迁移数据，也可以实现自动迁移功能。 可以使用现有的pin和unpin功能来实现数据迁移。 决定： 开始实现多级分层存储功能。 添加手动和自动数据迁移功能。 三、其他 插件接口的智能性： 讨论了是否需要将插件接口设计得更加智能，例如支持部分覆盖操作。 认为对于冷数据存储，部分覆盖操作的优势不大。 认为在支持部分覆盖操作时，需要考虑复杂性和性能问题。 后续行动计划： 实现分层存储插件接口。 实现多级分层存储功能。 添加手动和自动数据迁移功能。 在邮件列表上收集更多反馈。 备注： 会议讨论了分层存储和动态数据迁移的多个方面，包括插件接口、元数据管理、数据迁移策略等。 需要根据实际需求和反馈进一步完善设计方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- RBD: Kernel RBD client supports copy-on-read","slug":"CDS_Infernalis_Day_2.2_--_RBD_-_Kernel_RBD_client_supports_copy-on-read","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_RBD_-_Kernel_RBD_client_supports_copy-on-read/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_RBD_-_Kernel_RBD_client_supports_copy-on-read/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员：Lee, Yin Chen, [其他参会人员] 会议主题：RBD（Rados Block Device）相关功能改进讨论 会议内容： RBD差异导出功能： Lee提出了导出RBD克隆和父块差异的功能。 目前该功能尚未实现，需要进一步开发。 讨论了使用协作列表（collab list）提高性能的方案，并计划添加回调请求到类中。 性能改进： 提出使用状态机技术优化RBD复制和写入操作，以便更好地支持未来功能，如对象映射支持。 讨论了在内核中使用与用户空间相同的状态机技术。 计划分两步进行：首先重构现有复制和写入代码，其次优化查找和跟踪操作。 对象映射： 讨论了使用哈希表（hash table）和查找列表（lookup list）优化对象映射的性能。 认为使用哈希表可能比查找列表性能更好。 计划在实现复制和写入操作后，再进行优化。 异步操作： 讨论了使用异步操作（AIO）提高性能。 认为AIO操作在内核中比用户空间更灵活。 计划进一步研究AIO操作在RBD中的应用。 用户空间工具： 讨论了将通用选项传递给rdmap的方案。 认为无需修改用户空间工具，只需在RBD模块中添加复制和还原功能即可。 后续行动计划： Lee和Yin Chen负责实现RBD差异导出功能。 进一步研究使用状态机技术优化RBD复制和写入操作。 优化对象映射性能。 研究AIO操作在RBD中的应用。 将通用选项传递给rdmap。 备注： 讨论中涉及到的计算机科学/ceph相关领域英文关键词：RBD, clone, parent, diff, collab list, callback, state machine, object map, AIO, kernel, user space, hash table, lookup list。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- RBD: Add metadata mechanism to LibRBD","slug":"CDS_Infernalis_Day_2.2_--_RBD_-_Add_metadata_mechanism_to_LibRBD","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_RBD_-_Add_metadata_mechanism_to_LibRBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_RBD_-_Add_metadata_mechanism_to_LibRBD/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： [请填写参会人员名单] 会议主题： 为Li RBD添加元数据机制 会议内容： 议题概述： 会议主要讨论了为Li RBD添加元数据机制的蓝图，旨在解决不同场景下RBD卷配置不一致的问题，并提高配置的灵活性。 关键细节： 通过添加元数据机制，用户可以为每个RBD镜像配置不同的配置视图，例如不同的配置文件、快照集或快照方法模块。 元数据可以存储在图像头部，并以键值对的形式存在。 元数据可以用于存储配置信息，例如配置视图、密钥对等。 元数据可以存储在池级别，也可以存储在图像级别。 元数据可以通过RBD命令行工具进行操作，例如rbd meta put、rbd meta list等。 讨论的主要议题： 如何在保持配置一致性的同时，提高配置的灵活性。 元数据的存储位置和格式。 元数据的操作方式。 元数据与现有配置选项的兼容性。 决定的事项： 实现元数据机制，并支持配置视图、密钥对等配置信息的存储。 元数据存储在图像头部，以键值对的形式存在。 提供RBD命令行工具进行元数据的操作。 后续行动计划： 开发人员将根据讨论结果，设计和实现元数据机制。 测试团队将进行测试，确保元数据机制的稳定性和可靠性。 文档团队将更新相关文档，介绍元数据机制的使用方法。 关键词： Li RBD，元数据，配置视图，密钥对，RBD命令行工具","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Infernalis (Day 2.2) -- RBD: export diff between clone/parent","slug":"CDS_Infernalis_Day_2.2_--_RBD_-_export_diff_between_clone_parent","date":"2015-03-05T16:00:00.000Z","updated":"2015-03-06T16:00:00.000Z","comments":true,"path":"2015/03/06/CDS_Infernalis_Day_2.2_--_RBD_-_export_diff_between_clone_parent/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/03/06/CDS_Infernalis_Day_2.2_--_RBD_-_export_diff_between_clone_parent/","excerpt":"","text":"会议纪要 会议主题 本次会议主要讨论了Ceph中OSD事务的实现方案，以及多对象事务在liberados系统中的应用。 关键议题 OSD事务实现：会议重点讨论了如何实现多对象事务，并确保事务的原子性、一致性、隔离性和持久性。 事务协调：讨论了事务协调器的选择、事务的提交和回滚机制。 死锁检测与避免：讨论了如何检测和避免事务中的死锁问题。 事务日志：讨论了事务日志的存储位置和格式。 决定事项 事务模型：采用两阶段提交模型，将事务发送到主节点，由主节点协调事务的执行。 事务日志：将事务日志存储在内部对象空间中，与headset对象类似，以便持久化。 死锁检测：通过比较事务涉及的对象集合来检测死锁，并在冲突时回滚事务。 读事务：支持读事务，通过在主节点上获取读锁来保证一致性。 后续行动计划 实现多对象事务：开发人员将实现多对象事务的功能，并进行测试。 优化事务性能：评估事务性能，并进行优化。 文档编写：撰写相关文档，说明多对象事务的实现和使用方法。 讨论要点 事务协调：主节点负责协调事务的执行，确保事务的原子性和一致性。 死锁检测：通过比较事务涉及的对象集合来检测死锁，并在冲突时回滚事务。 事务日志：将事务日志存储在内部对象空间中，以便持久化。 读事务：支持读事务，通过在主节点上获取读锁来保证一致性。 其他 会议中提到了liberados系统在实现多对象事务时的局限性，以及如何通过优化现有协议来提高性能。 会议还讨论了多对象事务在liberados系统中的应用场景，例如垃圾收集和元数据更新。 关键词 OSD事务 两阶段提交 事务协调 死锁检测 事务日志 liberados 原子性 一致性 隔离性 持久性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-FEB-26 -- Ceph Tech Talks: RBD","slug":"2015-FEB-26_--_Ceph_Tech_Talks_-_RBD","date":"2015-02-26T16:00:00.000Z","updated":"2015-02-27T16:00:00.000Z","comments":true,"path":"2015/02/27/2015-FEB-26_--_Ceph_Tech_Talks_-_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/02/27/2015-FEB-26_--_Ceph_Tech_Talks_-_RBD/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： Josh Durgan（技术深度解析）、Patrick（主持人） 会议主题： Ceph存储系统中的RBD（Rados Block Device）技术解析 会议内容： 1. RBD概述 RBD是Ceph系统中的一个块设备，常用于虚拟机存储。 RBD可以通过用户空间库（如libvirt）或Linux内核模块与Ceph集群交互。 RBD支持快照和克隆功能，可用于数据备份和恢复。 2. RBD内部机制 RBD基于Rados系统构建，利用Rados的原子操作和事务处理功能。 RBD使用RBD对象存储数据，每个对象由多个数据块组成。 RBD支持稀疏对象，即数据块可以不连续存储。 3. RBD I/O路径 虚拟机通过页缓存进行I/O操作，然后由hypervisor调用RBD。 RBD可以缓存数据，提高I/O性能。 RBD支持快照和克隆，用于数据备份和恢复。 4. RBD快照 RBD快照通过Rados的复制和写入机制实现。 RBD使用快照上下文跟踪快照信息。 RBD快照可以异步删除。 5. RBD克隆 RBD克隆基于快照创建，可以写入数据。 RBD克隆使用复制和写入机制实现。 RBD克隆可以与快照分离，提高性能。 6. RBD使用 使用RBD需要配置密钥和连接信息。 RBD可以通过libvirt等虚拟化管理工具使用。 RBD可以通过内核模块直接在主机上使用。 7. RBD未来计划 RBD将支持同步复制，用于灾难恢复。 RBD将支持主从高可用架构。 RBD将支持对象映射，提高性能。 行动计划： 收集RBD性能数据，优化RBD性能。 开发RBD同步复制功能。 开发RBD主从高可用架构。 总结： 本次会议深入解析了Ceph存储系统中的RBD技术，介绍了RBD的内部机制、使用方法和未来计划。RBD是一款功能强大的块设备，可以用于虚拟机存储、数据备份和恢复等场景。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"2015-JAN-22 -- Ceph Tech Talk: RADOS","slug":"2015-JAN-22_--_Ceph_Tech_Talk_-_RADOS","date":"2015-01-22T16:00:00.000Z","updated":"2015-01-23T16:00:00.000Z","comments":true,"path":"2015/01/23/2015-JAN-22_--_Ceph_Tech_Talk_-_RADOS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/01/23/2015-JAN-22_--_Ceph_Tech_Talk_-_RADOS/","excerpt":"","text":"会议纪要 会议主题：ROS分布式存储系统介绍及内部架构解析 会议时间：[请填写具体日期和时间] 会议地点：[请填写会议地点] 参会人员：[请填写参会人员名单] 会议内容： ROS概述 ROS（Rados Object Storage）是Ceph分布式存储系统的一部分，提供统一的存储解决方案。 ROS支持对象存储、虚拟块存储和POSIX文件系统。 ROS设计遵循以下原则：横向扩展、无单点故障、自管理、开源。 ROS组件及工作原理 rados gateway：提供S3接口，将S3请求转换为librados请求。 RBD：提供块接口，由librbd处理块读取和写入操作。 SEFS：提供POSIX文件系统接口，由librados处理文件数据操作。 所有服务都基于librados，由ROS管理数据存储、复制和放置。 librados接口 支持对象存储、块存储和文件系统接口。 支持部分覆盖对象、原子读写事务和用户定义的X附加器。 使用对象映射（object map）存储元数据。 Ceph集群组件 OSD：负责存储数据、处理复制和恢复。 Monitor：维护集群映射，处理节点添加、删除和故障。 Pool：数据存储单元，具有不同的放置规则和复制级别。 对象放置 使用CRUSH算法计算对象放置位置，支持自定义放置策略。 放置组（PG）作为排序和锁定单元。 缓存分层 支持缓存分层，允许使用不同硬件和动态调整热冷数据比例。 使用librados缓存池实现缓存分层。 Erasure Coding 支持纠删码，降低存储开销。 使用纠删码插件，支持不同的纠删码算法。 未来工作 支持纠删码的乐观客户端读取。 改进缓存分层和Erasure Coding的性能。 会议结论： 本次会议介绍了ROS分布式存储系统的内部架构和工作原理，包括组件、接口、集群组件、对象放置、缓存分层和纠删码等。会议内容对理解ROS的工作原理和性能特点具有重要意义。 后续行动： 将会议内容发布在YouTube和SlideShare。 在邮件列表和IRC上回答相关问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"IBM @ Ceph Day London","slug":"IBM_@_Ceph_Day_London","date":"2015-01-13T16:00:00.000Z","updated":"2015-01-13T16:00:00.000Z","comments":true,"path":"2015/01/14/IBM_@_Ceph_Day_London/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/01/14/IBM_@_Ceph_Day_London/","excerpt":"","text":"会议纪要 会议主题： IBM 研究部门在软件定义存储（SDFS）领域的工作及未来规划 会议时间： 2023年11月（具体日期未提及） 参会人员： IBM 研究部门代表，SDFS 社区成员 会议内容： 一、IBM 研究部门在 SDFS 领域的工作 IBM 研究实验室： 作为 IBM 开设的第二家研究实验室，拥有大量物理学家，IT 人员较少。云解决方案小组专注于大规模存储和云计算解决方案，为研究人员提供本地数据中心和存储资源。 软件定义存储： 利用 OpenStack 和 SDFS 技术，为研究人员提供可定制的虚拟机和存储资源，满足其特殊需求。 SDFS 部署： 初期使用 3 个计算节点和 14TB SSD 存储，连接双 10G 网络带宽。 第二次迭代：采用 6 个节点，每个节点配备 12TB 硬盘，配置 1:4 的 SSD 与 HDD 混合存储。 未来计划：扩展存储容量，采用更多 SSD 和 HDD。 二、SDFS 在 SoftLayer 的应用 SoftLayer： 作为 IBM 的云服务平台，提供托管、管理和维护服务。 SDFS 服务： 提供基于 SDFS 的托管、管理私有云存储服务。 用户可选择存储容量和计算资源。 提供 1G 或 10G 网络连接。 采用双副本复制机制，保证数据可靠性。 三、SDFS 未来规划 增强安全性： 引入虚拟机级别的 SDFS 认证机制，防止密钥泄露。 优化性能： 提高虚拟机快照性能，减少数据传输时间。 支持异步复制，提高跨数据中心灾备能力。 多数据中心管理： 引入数据中心语义管理，方便跨数据中心资源分配和调度。 支持跨数据中心 SDFS 集群管理。 四、行动计划 IBM 研究部门将继续优化 SDFS 技术，并将其应用到更多场景中。 与 SDFS 社区合作，推动 SDFS 技术的进一步发展。 推出更多基于 SDFS 的云服务，满足用户需求。 关键词： 软件定义存储（SDFS）、OpenStack、SoftLayer、云计算、大规模存储、虚拟化、数据中心、灾备","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Wido @ Ceph Day London","slug":"Wido_@_Ceph_Day_London","date":"2015-01-13T16:00:00.000Z","updated":"2015-01-13T16:00:00.000Z","comments":true,"path":"2015/01/14/Wido_@_Ceph_Day_London/","link":"","permalink":"https://sean10.github.io/VideoSummary/2015/01/14/Wido_@_Ceph_Day_London/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 与会人员： Weo（荷兰SEF社区成员、咨询公司421的CTO） 会议主题： Ceph存储系统部署经验分享与最佳实践 会议内容： 一、Weo个人介绍及背景 Weo来自荷兰，是SEF社区的早期成员，自2009年底开始参与SEF项目。 他不仅是荷兰一家托管公司的共同所有者和CTO，还拥有自己的SEF咨询公司，提供培训和咨询服务。 他帮助众多组织部署SEF，包括小型公司、大型企业和政府机构。 二、SEF部署关键点 关注I/O性能而非存储容量： 许多组织在部署SEF时只关注存储容量，而忽略了I/O性能。Weo强调，在设计SEF系统时，应优先考虑I/O性能，选择合适的硬盘和配置。 使用SSD而非HDD： SSD具有更高的I/O性能和更低的延迟，建议使用SSD作为存储介质。 优化硬件配置： 选择合适的硬件配置，例如使用多盘位系统、分配足够的内存和CPU资源。 测试恢复操作： 在部署SEF系统时，应进行恢复操作测试，确保系统在硬件故障时能够正常恢复。 使用专用硬件： 对于监控节点，应使用专用硬件，确保其性能稳定。 三、案例分析 比利时政府项目： 该项目部署了16个节点，使用SSD进行日志记录，并使用19个1TB HDD和2.5英寸SSD作为存储介质。Weo帮助客户节省了约90万欧元。 荷兰ISP项目： 该项目使用OCFS2作为共享存储，并使用SSD进行部署。Weo分享了OCFS2在RBD上的使用经验。 四、最佳实践 设计系统时关注I/O性能： 选择合适的硬盘和配置，确保系统具有足够的I/O性能。 使用SSD作为存储介质： SSD具有更高的I/O性能和更低的延迟。 优化硬件配置： 选择合适的硬件配置，例如使用多盘位系统、分配足够的内存和CPU资源。 测试恢复操作： 在部署SEF系统时，应进行恢复操作测试，确保系统在硬件故障时能够正常恢复。 使用专用硬件： 对于监控节点，应使用专用硬件，确保其性能稳定。 避免创建过多的放置组： 过多的放置组会消耗CPU和内存资源。 不要试图超越SEF： SEF本身非常智能，应让SEF自行处理恢复操作。 不要购买最昂贵的硬件： SEF设计用于硬件故障，应购买更便宜的硬件，并将节省的资金用于购买更多节点。 五、后续行动 持续关注SEF社区的动态，学习最新的SEF技术和最佳实践。 与SEF社区成员交流，分享自己的经验和心得。 在自己的项目中应用SEF的最佳实践，不断提升系统性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Dell @ Ceph Day London","slug":"Dell_@_Ceph_Day_London","date":"2014-12-21T16:00:00.000Z","updated":"2014-12-21T16:00:00.000Z","comments":true,"path":"2014/12/22/Dell_@_Ceph_Day_London/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/12/22/Dell_@_Ceph_Day_London/","excerpt":"","text":"会议纪要 会议主题： Dell 对 Red Hat OpenStack 的赞助及 Ceph 存储解决方案的讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Paul（Dell 代表）、Steve Smith（HPC 业务负责人）、Ross（主持人） 会议内容： 一、Dell 对 Red Hat OpenStack 的赞助 Dell 对 Red Hat OpenStack 的赞助源于三年前在 World Hosting Day 会议上的交流。 Dell 认识到 OpenStack 在存储领域的潜力，并希望通过赞助活动推广 OpenStack。 Dell 认为OpenStack 允许客户以更低的成本实现更多功能，符合 Dell 的业务理念。 二、Ceph 存储解决方案 Dell 强调 Ceph 作为 OpenStack 的一部分，在存储领域的重要性。 Steve Smith 从 HPC 业务的角度，分享了 Ceph 在高性能计算领域的应用。 会议讨论了以下关键议题： 业务目标和规模： 在部署 Ceph 之前，需要明确业务目标和系统规模，包括存储容量、IOPS、吞吐量等。 架构设计： 需要考虑数据冗余、可靠性、可扩展性等因素，并选择合适的硬件和软件配置。 硬件配置： 推荐使用 Intel Xeon E5-2620/2630/2640 V3 处理器、64GB 内存、近线 SAS 硬盘等。 网络配置： 前端网络使用 10G 网络即可，后端网络需要至少 10G 网络，并支持 40G 或 100G 网络。 软件配置： 使用 Ceph 存储软件，并注意配置文件和参数优化。 三、挑战与机遇 会议讨论了 Ceph 存储在数据存储、安全、可靠性等方面的挑战。 Dell 强调 Ceph 具备应对这些挑战的能力，并鼓励客户尽早部署 Ceph。 Dell 认为，随着数据量的不断增长，Ceph 将成为存储领域的重要解决方案。 四、行动计划 Dell 将继续推广 Ceph 存储解决方案，并提供相关培训和支持。 Dell 将与 Inktank 合作，共同推动 Ceph 生态系统的建设。 五、其他 会议还讨论了以下内容： Ceph 在研究数据存储中的应用 Ceph 与其他存储解决方案的比较 Ceph 的未来发展趋势 总结： 本次会议深入讨论了 Ceph 存储解决方案，并分享了 Dell 的相关经验。会议强调了 Ceph 在存储领域的重要性和潜力，并鼓励客户尽早部署 Ceph。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Mellanox @ Ceph Day London","slug":"Mellanox_@_Ceph_Day_London","date":"2014-12-21T16:00:00.000Z","updated":"2014-12-21T16:00:00.000Z","comments":true,"path":"2014/12/22/Mellanox_@_Ceph_Day_London/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/12/22/Mellanox_@_Ceph_Day_London/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： Richard Hasty（Melanox 企业业务发展总监），以及其他与会人员 会议主题： Melanox 与 Ceph 的合作，高性能互连在网络中的重要性，以及 RDMA 技术的应用 会议内容： 一、Melanox 公司介绍 Richard Hasty 介绍了 Melanox 公司，强调其为一家端到端连接性公司，提供从交换机、电缆、光学元件到软件、管理层的全栈式解决方案。Melanox 拥有自主知识产权，能够在芯片级别进行创新。 二、互连和网络的重要性 Richard 指出，随着数据量的激增，存储系统需要能够应对不断增长的需求。Melanox 的产品能够提供高性能的互连，支持存储资产的扩展和性能提升。 三、Ceph 集群的扩展 Richard 解释了 Ceph 集群的扩展方式，包括规模扩展和规模扩展。Melanox 的互连产品支持规模扩展，并能够与软件、处理能力、操作系统、驱动器和网络等组件一起扩展。 四、互连在网络性能中的作用 Richard 强调，互连是 Ceph 集群性能的关键因素。通过将前端网络和后端网络分离，可以提高性能并实现更好的可扩展性。 五、Melanox 的解决方案 Melanox 提供了多种解决方案，包括： 40G 网络连接节点，同时保持 10G 网络连接客户端： 这可以提高性能并实现更好的可扩展性。 RDMA 技术： Melanox 正在开发支持 RDMA 的 Ceph 集群，以进一步提高性能。 六、未来计划 Melanox 将继续与 Ceph 团队合作，推动 RDMA 技术的应用，并开发更多高性能的互连产品。 七、问答环节 会议最后进行了问答环节，与会人员就 Melanox 的解决方案和 RDMA 技术的应用等问题进行了交流。 后续行动： Melanox 将继续与 Ceph 团队合作，推动 RDMA 技术的应用。 Melanox 将开发更多高性能的互连产品。 Ceph 团队将改进代码，提高性能。 关键词： Melanox、互连、网络、Ceph、RDMA、规模扩展、性能、可扩展性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Ross Turk @ Ceph Day London","slug":"Ross_Turk_@_Ceph_Day_London","date":"2014-12-21T16:00:00.000Z","updated":"2014-12-21T16:00:00.000Z","comments":true,"path":"2014/12/22/Ross_Turk_@_Ceph_Day_London/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/12/22/Ross_Turk_@_Ceph_Day_London/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 伦敦 参会人员： Ceph 社区开发者和用户，Red Hat、Dell、Melanox、Hiso 等公司代表 会议议程： 欢迎和开场介绍 Ceph 生态系统概述 Ceph 未来发展方向 Ceph 最新功能和进展 Ceph 社区和开发者活动 Ceph 性能优化 Ceph 与其他存储解决方案的比较 问答环节 会议关键细节： Ceph 社区发展： Ceph 自 2004 年开源以来，已经走过 10 年的发展历程，社区规模不断扩大，吸引了众多开发者和用户参与。 Ceph 最新版本： Ceph Firefly 版本于 2014 年 5 月发布，引入了擦除编码池、现金池等新特性，提高了存储效率和性能。 Ceph 未来发展方向： Ceph 将重点关注性能优化、简化部署和管理、扩展应用场景等方面，并致力于成为下一代存储解决方案。 Ceph 社区和开发者活动： Ceph 社区定期举办开发者峰会，鼓励社区成员参与 Ceph 的开发和维护。此外，Ceph 还积极参与 Google Summer of Code 等开源项目。 Ceph 性能优化： Ceph 将持续优化性能，支持更多硬件平台，并提供更完善的性能分析工具。 Ceph 与其他存储解决方案的比较： Ceph 与 Gluster 等其他存储解决方案各有优势，适用于不同的场景。 讨论的主要议题： Ceph 的最新功能和进展 Ceph 的未来发展方向 Ceph 的性能优化 Ceph 社区发展 Ceph 与其他存储解决方案的比较 决定的事项： 持续优化 Ceph 的性能和功能 简化 Ceph 的部署和管理 拓展 Ceph 的应用场景 加强 Ceph 社区建设 后续行动计划： Ceph 社区将持续关注性能优化，提高 Ceph 的性能和可靠性。 Ceph 社区将继续举办开发者峰会，鼓励社区成员参与 Ceph 的开发和维护。 Ceph 社区将积极参与 Google Summer of Code 等开源项目。 Ceph 社区将加强与 Red Hat、Dell、Melanox、Hiso 等公司的合作，共同推动 Ceph 的发展。 关键词： Ceph 分布式存储 擦除编码 现金池 性能优化 社区发展 开发者峰会 Google Summer of Code","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Florian Haas @ Ceph Day London","slug":"Florian_Haas_@_Ceph_Day_London","date":"2014-11-20T16:00:00.000Z","updated":"2014-11-20T16:00:00.000Z","comments":true,"path":"2014/11/21/Florian_Haas_@_Ceph_Day_London/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/11/21/Florian_Haas_@_Ceph_Day_London/","excerpt":"","text":"会议纪要 会议时间： 2023年11月X日 参会人员： Floren Hos（专业服务公司代表），Inktank合作伙伴，负责Ceph性能优化项目。 会议主题： Ceph性能优化与基准测试 会议内容： Ceph性能优化的重要性： Floren强调了理解Ceph性能的重要性，特别是在部署和优化Ceph集群时。他提出，性能优化需要关注多个维度，包括延迟、吞吐量和IOPS，并应根据具体应用场景选择合适的指标。 Ceph性能影响因素： 硬件： 包括OSD的本地块存储（如硬盘或SSD）和网络性能。 软件： 包括文件系统（如XFS）、OSD配置、网络连接和客户端堆栈（如RBD、CephFS、rados gateway）。 Ceph性能基准测试工具： DD工具： 用于测试块设备的吞吐量。 FIO工具： 用于模拟Ceph OSD Journal的写入负载。 netperf工具： 用于测试网络性能。 Ceph OSD bench： 用于测试OSD性能。 Ceph rados bench： 用于测试RBD性能。 FIO RBD引擎： 用于测试RBD性能，并支持缓存测试。 restbench工具： 用于测试rados gateway性能。 其他文件系统基准测试工具： 如iozone和Bonnie Plus+。 性能优化建议： 在部署Ceph集群之前，对硬件进行基准测试。 根据应用场景选择合适的性能指标。 优化OSD配置和文件系统参数。 确保网络性能满足需求。 使用合适的基准测试工具评估性能。 行动计划： Floren将分享他的Ceph性能优化和基准测试幻灯片，供参会者参考。 参会者将根据会议内容，评估自己的Ceph集群性能，并进行优化。 备注： 会议中提到了Ceph的多个组件，包括OSD、Journal、Filestore、Rados、RBD、CephFS和rados gateway。 会议强调了性能优化需要关注多个维度，并根据具体应用场景选择合适的指标。 会议介绍了多种Ceph性能基准测试工具，并提供了使用建议。 关键词： Ceph 性能优化 基准测试 硬件 软件 延迟 吞吐量 IOPS OSD Journal Filestore Rados RBD CephFS rados gateway FIO netperf Ceph OSD bench Ceph rados bench FIO RBD引擎 restbench iozone Bonnie Plus+","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Yann Dupont @ Ceph Day Paris","slug":"Yann_Dupont_@_Ceph_Day_Paris","date":"2014-11-10T16:00:00.000Z","updated":"2014-11-11T16:00:00.000Z","comments":true,"path":"2014/11/11/Yann_Dupont_@_Ceph_Day_Paris/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/11/11/Yann_Dupont_@_Ceph_Day_Paris/","excerpt":"","text":"会议纪要： 会议主题： Ceph分布式存储在生产环境中的应用实践分享 参会人员： 来自法国布列塔尼的University City of N的IT服务部门代表 会议内容： 一、背景介绍 大学城N拥有21个学院和约5万名学生员工。 IT服务部门（IRT）负责管理校园网络、电话系统、存储等服务。 由于存储系统过于集中，存在数据丢失和系统故障的风险。 二、Ceph存储解决方案的引入 经过多次尝试，IRT决定采用Ceph作为存储解决方案。 初始部署时，由于缺乏最佳实践和指导，遇到了一些问题，如硬件选择不当、配置错误等。 通过学习Ceph的规则和最佳实践，IRT逐步优化了部署。 三、部署架构 部署了5个独立的Ceph集群，分别用于不同用途，如实验、生产、备份等。 使用LXC容器技术，将OSD部署在物理服务器上，提高了资源利用率。 采用10GB网络带宽，并使用特定VLAN进行网络隔离。 部署了3代硬件，根据性能需求选择不同的配置。 四、性能优化 调整CRUSH规则，确保数据在不同数据中心之间分布。 使用SSD进行日志存储，提高性能。 使用Bcache进行数据缓存，减少IO压力。 使用OpenStack等工具进行自动化管理。 五、经验教训 避免使用硬件RAID，选择可靠的硬件和软件。 选择合适的Ceph版本和配置。 关注Ceph的社区和邮件列表，及时了解最新动态。 定期进行测试和评估，确保系统稳定可靠。 六、未来计划 测试Ceph的存储性能和可扩展性。 探索Ceph的新功能，如数据迁移、快照等。 与Ceph社区合作，共同推动Ceph的发展。 七、总结 Ceph是一个功能强大、可扩展的分布式存储系统，适用于各种场景。通过合理的规划和配置，可以构建高性能、高可靠的Ceph存储解决方案。 关键词： Ceph 分布式存储 CRUSH规则 LXC SSD Bcache OpenStack 可扩展性 高可靠性","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Loic Dachary @ Ceph Day Paris","slug":"Loic_Dachary_@_Ceph_Day_Paris","date":"2014-11-09T16:00:00.000Z","updated":"2014-11-10T16:00:00.000Z","comments":true,"path":"2014/11/10/Loic_Dachary_@_Ceph_Day_Paris/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/11/10/Loic_Dachary_@_Ceph_Day_Paris/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储中Erasure Code（纠删码）技术的介绍与讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： - 会议主讲人：Ceph Erasure Code开发人员 - 与会者：Ceph社区成员、开发人员 会议内容： 一、Erasure Code介绍 Erasure Code功能： Erasure Code是一种节省空间的特性，旨在减少存储需求，提高存储效率。 社区驱动： Erasure Code的开发是社区驱动的，主讲人最初并非Red Hat员工，但最终在Red Hat的支持下完成了这项工作。 背景： 主讲人拥有30年的开源软件背景，对开源社区充满热情。 二、Erasure Code工作原理 空间节省： 与传统复制模型相比，Erasure Code可以在不牺牲数据安全性的前提下，减少存储空间占用。 角色扮演： 通过模拟存储节点（OSD）和数据存储过程，展示了Erasure Code如何实现数据冗余和恢复。 数学原理： Erasure Code基于数学公式进行计算，通过编码操作将数据分割成多个编码块，并在不同OSD上存储。 三、Erasure Code的优势与挑战 优势： 减少存储空间占用，降低成本。 提高数据恢复效率。 支持多数据中心部署。 挑战： 实现复杂，需要大量计算资源。 恢复过程中可能出现单点故障。 四、Erasure Code的应用 Steering机制： 通过Steering机制，可以将不再活跃的数据迁移到Erasure Code存储池，实现透明存储。 本地恢复： 新的本地恢复功能可以在不跨越数据中心边界的情况下，快速恢复丢失的数据块。 ISA插件： 基于Intel处理器优化的插件，可以提升Erasure Code的运行效率。 五、未来计划 ARM优化： 支持ARM处理器上的优化，进一步提升Erasure Code的性能。 Hammer版本： 下一个版本将支持新的优化功能，包括ARM优化和本地恢复。 六、总结 Erasure Code是Ceph分布式存储中的一项重要技术，可以有效地降低存储成本，提高数据恢复效率。随着技术的不断优化和发展，Erasure Code将在未来得到更广泛的应用。 七、行动计划 与会者继续关注Erasure Code的发展，积极参与社区讨论。 Red Hat和Ceph社区将持续优化Erasure Code技术，提升其性能和可靠性。 未来版本将引入更多优化功能，满足用户需求。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Patrick McGarry @ Ceph Day Paris","slug":"Patrick_McGarry_@_Ceph_Day_Paris","date":"2014-11-09T16:00:00.000Z","updated":"2014-11-10T16:00:00.000Z","comments":true,"path":"2014/11/10/Patrick_McGarry_@_Ceph_Day_Paris/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/11/10/Patrick_McGarry_@_Ceph_Day_Paris/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议主题： Ceph 社区更新、开发里程碑、未来方向 参会人员： Ceph 社区成员、开发者、红帽员工 会议内容： 一、社区现状 红帽收购后的情况： 红帽对 Ceph 社区持支持态度，提供额外资源，并逐渐将 Ceph 社区融入红帽生态系统。 Ceph 发行版支持： Ceph 社区将继续支持 Ubuntu 和 SUSE，并专注于红帽发行版，特别是 CentOS 和 Fedora。 Ceph 与 Gluster 的协同： 红帽将同时支持 Ceph 和 Gluster，确保两个社区都不会被边缘化。 二、社区活动 Ceph Days： Ceph Days 将更加注重开发者活动，并鼓励社区成员参与。 社区指标： Ceph 社区将扩展 metrics.ceph.com 网站，收集和分析社区指标，并与社区分享。 用户委员会： 用户委员会将负责 Ceph 社区的治理，包括 Ceph.com、博客等。 Google Summer of Code： Ceph 社区将继续参与 Google Summer of Code，为学生提供项目机会。 CentOS： Ceph 社区将与 CentOS 合作，推动 Ceph 在 CentOS 上的应用。 三、开发进展 Giant 版： Giant 版已进入功能冻结阶段，即将发布 0.85 版本，其中包括 RDMA 支持、SSD 改进、CivetWeb 前端等。 RBD： RBD 将默认开启客户端缓存，并支持与 Eucalyptus 集成。 RGW： RGW 将改进 CivetWeb 前端，并处理桶限制问题。 CFS： CFS 将获得更多资源支持，并逐渐进入生产环境。 部署和编排： Ceph 支持多种编排和部署工具，如 Chef、Puppet、Ansible 等。 四、行动计划 继续支持 Ubuntu 和 SUSE 发行版。 加强与 CentOS 合作。 持续改进 Ceph 功能和性能。 扩大 Ceph 社区规模。 加强 Ceph 社区的治理。 五、后续行动 Ceph 社区成员积极参与 Ceph Days、用户委员会等活动。 关注 Ceph 开发者 summit 和 blueprint 调查。 提供反馈和建议，帮助改进 Ceph。 关键词： Ceph、红帽、Giant、Ceph Days、用户委员会、Google Summer of Code、CentOS、CFS、部署、编排","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Peter Chadwick @ Ceph Day Paris","slug":"Peter_Chadwick_@_Ceph_Day_Paris","date":"2014-11-09T16:00:00.000Z","updated":"2014-11-10T16:00:00.000Z","comments":true,"path":"2014/11/10/Peter_Chadwick_@_Ceph_Day_Paris/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/11/10/Peter_Chadwick_@_Ceph_Day_Paris/","excerpt":"","text":"会议纪要： 会议主题： OpenStack云基础设施中使用Ceph作为主要存储方案 参会人员： （未提及具体人员） 会议内容： OpenStack技术介绍： OpenStack是一个开源项目，旨在帮助客户部署基础设施以服务云。 它包含多个组件，如Nova（计算控制器）、Glance（虚拟机镜像存储）、Cinder（块存储）等。 OpenStack还提供用户界面和API，支持虚拟机的高级控制和管理。 Ceph与OpenStack的集成： Ceph是一个开源的分布式存储系统，支持对象存储、块存储和文件系统。 Ceph与OpenStack集成良好，支持多种存储用例，包括： 存储即服务： 如Dropbox、Amazon S3等。 计算即服务： 如OpenStack Glance、Cinder等。 对象存储： 如OpenStack Swift。 Ceph提供高性能、可扩展性和高可用性，适合云环境。 Ceph在OpenStack中的应用： Ceph可以作为OpenStack Glance的后端存储，用于存储虚拟机镜像和操作系统模板。 Ceph可以作为OpenStack Cinder的后端存储，提供持久性块存储服务。 Ceph可以通过RESTful API或Swift API访问，支持与Amazon S3的兼容性。 Souza Cloud 4： Souza Cloud 4是一个基于OpenStack的企业级云平台。 它支持Ceph作为存储解决方案，并提供完整的安装和管理功能。 Souza Cloud 4支持多种硬件和虚拟化平台，并确保OpenStack服务的可用性。 行动计划： 继续推进Ceph与OpenStack的集成工作。 优化Ceph的性能和可扩展性。 推广Ceph在云环境中的应用。 关键信息： Ceph是OpenStack云环境中理想的存储解决方案。 Ceph与OpenStack集成良好，支持多种存储用例。 Souza Cloud 4提供完整的Ceph集成和管理功能。 后续行动： 与Ceph社区合作，推动Ceph的发展。 优化Ceph的性能和可扩展性。 推广Ceph在云环境中的应用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"Sebastian Han @ Ceph Day Paris","slug":"Sebastian_Han_@_Ceph_Day_Paris","date":"2014-11-09T16:00:00.000Z","updated":"2014-11-10T16:00:00.000Z","comments":true,"path":"2014/11/10/Sebastian_Han_@_Ceph_Day_Paris/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/11/10/Sebastian_Han_@_Ceph_Day_Paris/","excerpt":"","text":"会议纪要 会议主题： Ceph与OpenStack的集成状态、Juno周期进展及Ceph部署 参会人员： Sebastian（Innovance/Red Hat Cloud架构师） 会议时间： 未提供 会议内容： 一、Ceph与OpenStack集成状态 DevStack Self： Sebastian成功将SEF集成到DevStack中，简化了Ceph集群的配置过程。通过配置文件，可以轻松设置集群大小、副本数量等参数。 OpenStack支持： Nova：支持从Ceph复制和克隆虚拟机镜像，提高了虚拟机启动速度和效率。 Cinder：支持Ceph存储后端，并实现了Cinder备份功能。 Nova：支持Ceph存储后端的实时迁移，提高了灾备能力。 Nova：使用Ceph集群统计报告磁盘使用情况，提高了虚拟机启动的准确性。 Cinder：支持自定义RBD卷的条带大小，提高了性能。 正在进行中的工作： Nova：修复了Ceph存储后端的灾备功能。 Cinder：实现Ceph存储后端的卷迁移功能。 Nova：优化了快照功能，提高效率。 二、Anible与Ceph部署 Anible架构和版本支持： Anible支持部署Ceph集群，包括Monitor、OSD、MDS、RGW等组件，并支持虚拟机、物理机等多种部署环境。 Anible功能： 支持部署Ceph集群的各种组件。 支持配置Ceph集群的各种参数。 支持虚拟机、物理机等多种部署环境。 支持多种OSD部署场景，包括OSD和Journal同盘部署、分离部署等。 支持使用目录作为OSD部署路径。 支持滚动升级和清理Ceph集群。 Anible扩展： 支持安装Anible。 支持滚动升级Ceph集群。 支持清理Ceph集群。 三、后续行动计划 继续完善Ceph与OpenStack的集成，包括灾备、快照等功能。 完成Cinder存储后端的卷迁移功能。 优化Anible的部署流程和功能。 四、会议总结 本次会议介绍了Ceph与OpenStack集成状态、Juno周期进展及Ceph部署。会议内容丰富，涵盖了Ceph与OpenStack的各个方面，为Ceph用户提供了 valuable 的信息。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - CephFS: Forward Scrub","slug":"CDS_Hammer_Day_2_-_CephFS_-_Forward_Scrub","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_CephFS_-_Forward_Scrub/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_CephFS_-_Forward_Scrub/","excerpt":"","text":"会议纪要 会议时间： 2023年（具体日期未提及） 会议主题： SEFS 前向清理和反向清理（修复）的进展讨论 参会人员： Craig、Greg、John、Sage等 会议内容： 1. 前向清理进展 Craig 和 Greg 负责的前向清理工作已进行一年半，目前已开始实际工作。 前向清理通过从文件系统层次结构的根开始，递归地检查所有元数据，以确保其自洽性。 已提交代码审查，包括将 MDS 内部操作提升为与客户端请求相同级别的操作，以及验证单个 iode 的代码和 admin socket 接口。 正在开发“scrub 栈”，将算法转换为实际可工作的代码，但尚未准备好提交 PR。 2. 反向清理进展 John 和 Sage 讨论了反向清理的多个组件，包括： 通过 pgls 过滤器查找丢失的目录对象，并将恢复的路径直接插入到后端存储。 在运行中的 MDS 中插入恢复的元数据，避免关闭整个文件系统。 创建一个对象类来处理清理过程中的对象。 在开始清理之前备份元数据池，以便在失败时回滚。 使用 Rados 导出和导入工具或池快照进行备份。 3. 清理错误处理 讨论了如何向管理员展示清理错误，以便他们进行修复。 提出使用健康检查系统来跟踪错误，并使用结构化日志记录错误信息。 讨论了使用内存中的数据结构来跟踪错误，并避免覆盖已知的正确数据。 4. 下一步行动 John 和 Sage 继续开发反向清理的代码。 Craig 和 Greg 完成前向清理代码的审查和提交。 所有参与者继续讨论如何处理清理错误，并确保系统稳定性和数据完整性。 关键词： SEFS 前向清理 反向清理 修复 MDS iode pgls 过滤器 Rados 健康检查 结构化日志","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - Calamari Localization","slug":"CDS_Hammer_Day_2_-_Calamari_Localization","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_Calamari_Localization/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_Calamari_Localization/","excerpt":"","text":"会议纪要 会议主题： Calamari 本地化工作进展及后续计划 参会人员： Lee, Jen, Greg, Dan, John 等 会议内容： Calamari 本地化进展： Lee 和 Jen 已完成了 Calamari Dashboard 的本地化工作，将部分英文翻译为中文，并尝试了多语言切换功能。 目前只完成了 Dashboard 的本地化，其他 Calamari 客户端应用（如 Manage）尚未开始本地化。 Lee 遇到了一些技术难题，例如如何支持 AngularJS 2.0 和框架的本地化。 Greg 指出需要将翻译后的字符串移动到相应的资源文件中，并建议使用 AngularJS 1.3 来简化本地化工作。 Dan 提供了帮助，解释了如何将字符串提取到资源文件中，并建议先完成 Dashboard 的本地化。 后续行动计划： Lee 将继续完成 Dashboard 的本地化工作，并将翻译后的字符串移动到相应的资源文件中。 Lee 将尝试使用 AngularJS 1.3 来简化本地化工作。 Greg 将与 Dan 合作，确定如何修改 Manage 应用以支持本地化。 Greg 将调查 AngularJS 1.3 的本地化支持情况。 Dan 将提供帮助，解释如何将字符串提取到资源文件中。 John 建议将 Calamari 代码库中的提交拆分为多个部分，以便更容易地跟踪和审查。 其他讨论： 如何处理来自 Calamari 服务器的字符串本地化问题。 如何设置 Accept-Language 头部信息。 如何处理错误消息的本地化问题。 关键信息： Calamari Dashboard 的本地化工作已初步完成，但仍需进行一些调整。 其他 Calamari 客户端应用尚未开始本地化。 需要进一步调查 AngularJS 1.3 的本地化支持情况。 需要确定如何处理来自 Calamari 服务器的字符串本地化问题。 备注： 会议中提到了一些计算机科学/ Ceph 相关领域英文原文的关键词，例如：Calamari, localization, AngularJS, l20n framework, message catalog, etc.","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - CephFS: Hadoop Support","slug":"CDS_Hammer_Day_2_-_CephFS_-_Hadoop_Support","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_CephFS_-_Hadoop_Support/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_CephFS_-_Hadoop_Support/","excerpt":"","text":"会议纪要： 会议主题： Ceph分布式存储与Hadoop集成的进展及问题讨论 参会人员： Noah（Ceph研发人员），其他与会者 会议内容： 一、Hadoop支持现状 Ceph已支持Hadoop集成，但存在一些问题。 当前主要问题包括： HDFS语义理解不明确，导致适配困难。 测试套件中存在一些失败的测试用例，需要修复。 文件重命名功能存在一些问题，需要调整。 集成测试需要完善，考虑使用Bigtop进行自动化测试。 二、解决方案 已有团队对HDFS语义进行了详细定义，并提供了相关文档。 正在修复测试套件中的失败用例，并调整文件重命名功能。 考虑使用Bigtop进行自动化集成测试。 三、其他讨论 时钟同步问题已解决，不再出现相关错误。 快照和配额功能已支持。 客户端关闭问题已解决，但仍需进一步优化。 性能问题正在分析中，将通过性能分析工具进行诊断。 四、行动计划 继续修复测试套件中的失败用例。 调整文件重命名功能。 完善集成测试。 分析性能问题，并进行优化。 五、关键术语 HDFS（Hadoop Distributed File System） Bigtop POSIX Yarn OSD（Object Storage Device） IO 总结： 本次会议讨论了Ceph与Hadoop集成的进展和问题，并制定了相应的解决方案和行动计划。下一步将重点解决测试和性能问题，以确保Ceph与Hadoop的稳定集成。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - Fixed Memory Layout for Message/Op Passing","slug":"CDS_Hammer_Day_2_-_Fixed_Memory_Layout_for_Message_Op_Passing","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_Fixed_Memory_Layout_for_Message_Op_Passing/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_Fixed_Memory_Layout_for_Message_Op_Passing/","excerpt":"","text":"会议纪要： 会议主题： Maya 固定内存布局的消息和输出传递方案讨论 会议关键细节： 讨论了消息管理，特别是对于消息的编码和解码过程。 分析了当前消息编码和解码的优缺点，以及如何优化性能。 提出了创建一个新的消息类型 mosd_client_sub-op，专门用于复制客户端操作，以简化消息结构并提高效率。 讨论的主要议题： 消息多样性： 消息种类繁多，直接优化所有消息结构不切实际。 优化目标： 针对消息处理速度较快的路径进行优化，例如 mosd up 和回复消息。 优化方法： 使用固定内存布局，避免解码操作。 减少消息中不必要的数据，例如 PG stats 和 Snapshots。 创建新的消息类型，只包含必要的字段，例如 mosd_client_sub-op。 优化 mosd sub-op reply 中的 OSD Apps 字段。 决定的事项： 创建一个新的消息类型 mosd_client_sub-op，用于复制客户端操作。 优化现有消息结构，去除不必要的数据和字段。 优化 mosd sub-op reply 中的 OSD Apps 字段。 后续行动计划： 由研发人员根据会议讨论结果，修改代码实现新的消息类型和优化措施。 对现有代码进行测试，确保优化措施有效且兼容性良好。 计算机科学/ceph 领域英文原文关键词： fixed memory layout messaging out passing object store transaction encoding message management decoded auto store buffer list STL object info locator object ID PG stats Snapshots sub-op EC code replicated back end OSD Apps","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - OSD: Update Transaction Encoding","slug":"CDS_Hammer_Day_2_-_OSD_-_Update_Transaction_Encoding","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Update_Transaction_Encoding/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Update_Transaction_Encoding/","excerpt":"","text":"会议纪要 会议主题： OSD事务编码更新 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议内容： 背景介绍： 会议讨论了OSD事务编码的更新，旨在提高编码和解码效率，并简化现有后端存储。 更新的动机来自于希望编写更好的文件存储系统，但发现现有的事务结构难以实现。 主要议题： 优化编码和解码： 通过避免重复指定相同的集合和对象，并使用单一调用获取对象句柄，简化编码和解码过程。 缓冲区管理： 引入缓冲区ID，以便在操作中使用，简化后端对缓冲区负载的基于条件的行为。 文件存储优化： 对于大缓冲区，考虑将其写入单独的文件，并使用元数据指针机制。 事务编码兼容性： 确保新的编码方案与现有的事务格式兼容，并考虑向后兼容性。 讨论细节： 编码和解码方案： 使用固定大小的结构体和缓冲区列表，简化解码过程，并提高性能。 后端实现： 后端存储需要支持新旧两种编码方案，以便兼容旧事务。 测试和验证： 需要编写全面的测试，确保新旧事务格式之间的转换正确无误。 决定事项： 接受提出的更新方案，并开始实施。 编写全面的测试，确保新旧事务格式之间的转换正确无误。 考虑将事务编码方案应用于其他后端存储，例如键值存储。 后续行动计划： [请填写后续行动计划，例如分配任务、设定时间表等] 关键词： OSD事务编码、文件存储、缓冲区、兼容性、测试、验证、后端存储 备注： 会议讨论了多个选项，并最终选择了最佳方案。会议强调了测试和验证的重要性，以确保新旧事务格式之间的转换正确无误。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - OSD: Scrub and Repair","slug":"CDS_Hammer_Day_2_-_OSD_-_Scrub_and_Repair","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Scrub_and_Repair/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Scrub_and_Repair/","excerpt":"","text":"会议纪要 会议主题： OSD 扫描修复方案讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Samuel, Guang, Jason, 其他相关人员 会议内容： 主要议题： 讨论并优化 OSD 扫描修复方案，旨在提高扫描效率和修复准确性。 关键细节： 当前扫描修复方案过于保守且不够智能，无法有效识别和修复损坏的副本。 讨论了通过 Calamari 或其他工具向用户展示不一致性的详细信息，并允许用户指定修复方式。 讨论了如何通过 Liberator 接口或 JSON 接口暴露相关信息，以便用户查询和操作。 讨论了异步读取在复制副本中的实现，以及如何将异步读取应用于对象存储接口。 讨论了读取原始数据分片的需求，以及如何通过新的接口实现。 决定事项： 将扫描结果存储在 Perftest scratch 对象中，并在对等重置期间清除。 通过 Liberator 接口提供查询不一致副本和修复对象的命令。 实现异步读取并应用于对象存储接口。 提供读取原始数据分片的接口。 后续行动计划： Guang 将提交一个关于将保守第一步改为将 EIO 读取等同于 scrub 获取 I/O 并标记 pg 不一致的 pull request。 实现异步读取并应用于复制副本。 实现读取原始数据分片的接口。 开发一个工具，帮助用户查询和操作不一致副本和修复对象。 关键词： OSD, 扫描修复, Liberator, JSON, 异步读取, 数据分片, Calamari, Perftest, Liberator 接口, JSON 接口","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - OSD (Tiering): Fine-Grained Promotion Unit","slug":"CDS_Hammer_Day_2_-_OSD_Tiering_-_Fine-Grained_Promotion_Unit","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_OSD_Tiering_-_Fine-Grained_Promotion_Unit/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_OSD_Tiering_-_Fine-Grained_Promotion_Unit/","excerpt":"","text":"会议纪要 会议主题： OSD分层讨论——细粒度提升单元 会议时间： 2023年11月（具体日期未提及） 参会人员： 未知 会议内容： 一、背景及议题 本次会议主要讨论了Ceph存储系统中OSD分层策略的优化，特别是针对细粒度提升单元（fine grain promotion units）的讨论。会议重点分析了当前分层策略的优缺点，并探讨了改进方案。 二、主要议题 现有分层策略分析： 会议分析了不同分层策略（如全闪存、混合分层、无分层）的性能表现，指出在随机读和写操作中，分层策略可能导致性能下降。 会议指出，当前分层策略在处理随机分布的数据时，由于缓存过小，导致缓存命中率低，从而影响性能。 细粒度提升单元： 会议讨论了使用细粒度提升单元（如4K页）进行提升的可行性。 会议指出，细粒度提升单元可以提高缓存命中率，但同时也增加了复杂性，特别是在与快照交互时。 优化方案： 改进提升策略： 在提升过程中，将读取操作转发到后端存储，避免读取操作阻塞提升过程。 在提升操作完成后，将读取操作代理到提升后的数据，进一步提高性能。 优化提升单元粒度： 使用更小的提升单元（如4K页）进行提升，提高缓存命中率。 但需注意，细粒度提升单元会增加复杂性，尤其是在与快照交互时。 三、行动方案 短期： 优化提升策略，将读取操作转发到后端存储，避免读取操作阻塞提升过程。 研究代理读取操作的可能性，进一步提高性能。 中期： 评估细粒度提升单元的可行性，并研究其在与快照交互时的复杂性。 研究使用更小的提升单元进行提升的方案。 长期： 优化Ceph存储系统中的OSD分层策略，提高系统整体性能。 四、其他 会议指出，当前分层策略在处理随机分布的数据时，可能导致性能下降。 会议讨论了使用细粒度提升单元进行提升的可行性，并探讨了改进方案。 会议提出了短期、中期和长期行动方案，以优化Ceph存储系统中的OSD分层策略。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - OSD: Add Flexible Cache Control of Object Data","slug":"CDS_Hammer_Day_2_-_OSD_-_Add_Flexible_Cache_Control_of_Object_Data","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Add_Flexible_Cache_Control_of_Object_Data/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Add_Flexible_Cache_Control_of_Object_Data/","excerpt":"","text":"会议纪要 会议主题： OSD 添加灵活缓存控制对象数据（IO 指示）的提案讨论 参会人员： J（inar 项目成员）、其他 Ceph 开发人员 会议内容： 提案概述： J 从 inar 项目提出了一个基于 SES 之前提案的框架，旨在更好地控制 OSD 的操作，特别是针对具有特殊对齐能力和特定对象大小要求的操作。该框架将客户端的指示转换为 OSD，使 OSD 能够在内存和磁盘使用上执行智能迁移。会议讨论了以下四个好处： 减少文件系统碎片： 通过在相同 SI 上集中放置 RBD 映像，减少使用随机访问时可能产生的碎片，从而提高性能。 减少内存使用： 通过将大对象从缓存中移除，为其他对象（如小文件元数据）保留更多内存。 提高响应时间： 通过缓存小对象，提高响应时间。 扩展性： 框架可以轻松扩展到不同的用例。 背景和挑战： 大量小文件会导致文件查找时的开销增加，因为每个操作都需要读取对象信息。 使用 XFS 作为后端时，过多的元数据操作会导致性能下降。 使用 Fadvise 可能会引入大量 Red M dat 操作，降低性能。 解决方案： 提供客户端设置的 IO 指示，并通过 LaOS 传递给 OSD。 根据不同的后端存储（如文件存储、内存存储、K 库存储）进行相应的处理。 在 RBD 模型、RBD 读取网关等客户端使用该框架。 使用 Fadvise 等指示来控制缓存行为。 在特定情况下（如小对象读取后）释放缓存。 决策事项： 实现该提案，并提交相关补丁。 首先实现 API 变更，以便进行审查。 与 inar 项目团队合作，确保提案的顺利实施。 后续行动计划： J 将继续与 inar 项目团队合作，完成补丁的编写和提交。 其他 Ceph 开发人员将审查代码，并提供反馈。 确保提案按时完成，以便在 Hammer 版本中实施。 关键细节： 该提案旨在通过控制 OSD 的缓存行为来提高性能和效率。 框架可以扩展到不同的用例，并与其他功能集成。 需要与其他 Ceph 开发人员合作，确保提案的顺利实施。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - OSD: Scrub / SnapTrim IO Prioritization","slug":"CDS_Hammer_Day_2_-_OSD_-_Scrub_SnapTrim_IO_Prioritization","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Scrub_SnapTrim_IO_Prioritization/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_OSD_-_Scrub_SnapTrim_IO_Prioritization/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： Samuel（主讲人），其他研发人员 会议主题： 分布式存储Ceph的 scrub 和 snap trim IO优先级优化 会议内容： 背景介绍： Ceph中的所有操作都在线程池中执行，但不同线程池之间的相对优先级由操作系统决定，这可能导致不理想的优先级分配。 为了优化IO优先级，提议将所有可能的IO操作整合到一个队列中，并使用更高效的队列管理方式。 主要议题： OSD内部机制： OSD的绝大多数操作都在线程池中执行，但线程池之间的优先级分配存在问题。 IO优先级： 需要优化scrub、snap trim 和恢复等操作的IO优先级。 恢复线程池： 当前恢复线程池的线程数量与其他客户端线程数量相比过少，需要调整。 优先级标记： 在后台工作中添加IO优先级标记，将优先级管理提升到更高级别。 关键细节： 使用更高效的队列管理方式，提高队列效率。 调整恢复线程池的线程数量，优化恢复操作。 将所有可能的IO操作整合到一个队列中，并使用优先级标记进行管理。 将操作分解成更小的粒度，提高效率。 决定事项： 将所有可能的IO操作整合到一个队列中，并使用优先级标记进行管理。 调整恢复线程池的线程数量，优化恢复操作。 将操作分解成更小的粒度，提高效率。 后续行动计划： Samuel将在下个月完成相关代码调整。 检查Lucerne，确认使用tagged union或boost variant。 优化恢复操作，考虑使用更细粒度的操作分解。 备注： 会议中提到的“Firefly”和“boost variant”是Ceph相关的技术术语，分别指Ceph的一个版本和一种编程库。 关键词： scrub、snap trim、IO优先级、OSD、线程池、恢复操作、优先级标记、tagged union、boost variant","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - RBD: Copy-on-Read for Clones in Kernel RBD Clients","slug":"CDS_Hammer_Day_2_-_RBD_-_Copy-on-Read_for_Clones_in_Kernel_RBD_Clients","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_RBD_-_Copy-on-Read_for_Clones_in_Kernel_RBD_Clients/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_RBD_-_Copy-on-Read_for_Clones_in_Kernel_RBD_Clients/","excerpt":"","text":"会议纪要 会议主题： RBD（RADOS Block Device）克隆的“读复制”功能开发讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Minchen, Lee Wong, Josh, 以及其他未提及的成员 会议内容： 1. RBD克隆的“读复制”功能概述 Minchen 和 Lee Wong 介绍了 RBD 克隆在内核 RBD 客户端的“读复制”功能。 该功能通过在客户端进行复制操作，减少了与 RADOS 之间的交互，提高了读取效率。 客户端在读取克隆对象之前，会先从父对象中读取数据，并将数据缓存到内存中。 2. 对象映射功能 对象映射功能有助于优化复制过程，通过告知客户端对象是否存在，可以避免额外的往返操作。 该功能与复制功能是独立的，可以同时使用。 3. 核心实现与用户空间实现 用户空间实现尚未合并，需要提交用户空间构建请求以供审查。 核心实现需要等待用户空间实现合并后才能提交。 4. 问题与讨论 关于等待请求完成的问题，需要进一步考虑，因为目前对读写请求的处理并不完善。 需要分离读写请求的处理，以便在处理错误和刷新时停止 I/O，而无需取消映射图像。 对象映射功能和复制功能具有不同的目的，因此可以同时使用。 5. 行动计划 Minchen 和 Lee Wong 将继续开发“读复制”功能。 Josh 将提交用户空间实现请求，以便合并。 核心实现团队将等待用户空间实现合并后，再提交核心实现代码。 备注： 会议中提到了 Chrome 浏览器误报 ad.sap.com 为钓鱼网站的问题，但已确认该警告为误报。 会议中讨论了关于 RBD 的其他功能，如“高级条带化”，但未涉及具体细节。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - OSD (Tiering): Reduce R/W Latencies on Cache Tier Miss","slug":"CDS_Hammer_Day_2_-_OSD_Tiering_-_Reduce_R_W_Latencies_on_Cache_Tier_Miss","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_OSD_Tiering_-_Reduce_R_W_Latencies_on_Cache_Tier_Miss/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_OSD_Tiering_-_Reduce_R_W_Latencies_on_Cache_Tier_Miss/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储优化讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： 多位 Ceph 开发人员 会议内容： 一、讨论要点 读取优化： 当前代码中，当读取请求缺失缓存时，会进行提升操作，并将对象复制到所有 OSD 实例。 提议首先服务读取请求，然后在提升操作完成后进行复制，以减少读取延迟。 针对异步读取，建议在读取操作可以完全由一个数据块满足时，使用该策略。 写入优化： 在写入操作中，可以将提升的对象数据复制到所有 OSD 实例，并更新对象属性。 建议避免进行不必要的复制操作，以提高效率。 对于完全覆盖对象的情况，可以只提升对象属性，而不是数据。 复制优化： 在复制操作中，可以将提升的对象数据复制到所有 OSD 实例，并更新对象属性。 建议避免进行不必要的复制操作，以提高效率。 二、关键决策 读取优化： 实施异步读取策略，并在满足条件时使用读取优化策略。 评估读取优化策略的有效性，并根据实际工作负载进行调整。 写入优化： 实施写入优化策略，避免不必要的复制操作。 评估写入优化策略的有效性，并根据实际工作负载进行调整。 复制优化： 实施复制优化策略，避免不必要的复制操作。 评估复制优化策略的有效性，并根据实际工作负载进行调整。 三、后续行动计划 读取优化： 实现异步读取策略。 评估读取优化策略的有效性，并根据实际工作负载进行调整。 写入优化： 实现写入优化策略。 评估写入优化策略的有效性，并根据实际工作负载进行调整。 复制优化： 实现复制优化策略。 评估复制优化策略的有效性，并根据实际工作负载进行调整。 数据收集： 使用 Adam 开发的 RBD 跟踪捕获工具收集实际工作负载数据。 分析数据，以确定读取优化和写入优化策略的有效性。 四、其他 会议中提到了 RBD 的跟踪捕获工具，该工具可以捕获实际工作负载的跟踪数据。 会议讨论了 RBD 的写入操作，包括完整覆盖对象的情况。 会议讨论了 Ceph 的优化策略，包括异步读取、写入优化和复制优化。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - Quota Discussion","slug":"CDS_Hammer_Day_2_-_Quota_Discussion","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_Quota_Discussion/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_Quota_Discussion/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储系统中CFS配额支持的讨论以及配额与子树的关系 会议时间： 2023年11月（具体日期未知） 参会人员： Sage, Yanchon, Josh, John Craig, Lee（通过聊天室） 会议内容： 1. 配额支持讨论 Sage介绍了CFS配额支持的实现方案，包括如何在目录创建时集成文件 parents，并查找所有配额信息和状态。 Sage提到，在客户端配额超出之前，操作员将被阻止，并返回配额信息。 但是，当创建操作频繁发生时，配额可能会被超限，因为MTS需要在两个客户端之间推送信息。 目前，配额的实现可能不够精确，需要进一步改进。 2. 子树配额跟踪 Sage指出，目前子树配额跟踪存在一些问题，例如在文件重命名时，配额信息不会更新，导致配额无法正确执行。 Sage建议使用“subtree”概念来跟踪文件属于哪个配额，以确保检查正确的配额。 John Craig提出了使用更严格的目录结构（如标记目录和子目录）来限制配额的方法。 3. 配额与子卷 Josh提出了将配额与子卷结合的想法，以便在目录上设置配额并创建快照。 Josh建议使用现有的“snap realm”数据结构来跟踪inode成员资格，并使用“sub volume”概念来限制操作。 Sage担心将快照与子卷结合可能会引入复杂性，并建议先实现基本的配额和子卷功能。 4. 测试和改进 Sage建议添加测试用例来验证配额功能，并确保它能够在达到配额限制时阻止写入操作。 Sage还建议对配额实现进行改进，例如处理截断操作和优化统计信息传播。 John Craig建议使用更严格的目录结构来限制配额，并使用标记目录和子目录来区分配额。 5. 决策 会议最终决定将配额与子卷结合，并使用现有的“snap realm”数据结构来跟踪inode成员资格。 会议还决定添加测试用例来验证配额功能，并对配额实现进行改进。 后续行动计划： Sage将添加测试用例来验证配额功能。 Sage将对配额实现进行改进，例如处理截断操作和优化统计信息传播。 John Craig将研究使用更严格的目录结构来限制配额的方法。 关键词： CFS配额 subtree sub volume snap realm inode MTS quota enforcement truncate operation","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 2) - librbd: Shared Flag, Object Map","slug":"CDS_Hammer_Day_2_-_librbd_-_Shared_Flag_Object_Map","date":"2014-10-29T16:00:00.000Z","updated":"2014-10-30T16:00:00.000Z","comments":true,"path":"2014/10/30/CDS_Hammer_Day_2_-_librbd_-_Shared_Flag_Object_Map/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/30/CDS_Hammer_Day_2_-_librbd_-_Shared_Flag_Object_Map/","excerpt":"","text":"会议纪要 会议时间： 2023年XX月XX日 参会人员： Maya, Josh, Jason, Foreign 会议主题： Ceph RBD（Rados Block Device）的独占锁特性和对象映射功能讨论 关键细节： 独占锁特性： RBD新增独占锁特性，默认情况下，除非标记为共享，否则所有图像都将应用此新功能位，表示它支持独占锁定。 当独占锁定功能位启用时，任何对图像的写操作或可变操作都将导致RBD尝试获取对图像的独占权锁。 通过watch notify系统，客户端可以请求获取锁，并从当前锁持有者那里获取锁或通知释放锁。 维护操作（如快照、扁平化、调整大小）也可以通过watch notify系统请求当前独占锁持有者执行。 对象映射： 对象映射通过Rados中的类方法进行操作，用于加载、更改映射中对象的状态等。 映射状态为三态：不存在、可能存在、待删除。 当客户端请求对RBD图像中给定对象的写操作时，如果该对象当前未标记为不存在，则客户端将更新对象映射并将其提交到磁盘，然后继续进行radius操作。 通过检查对象映射，可以优化对磁盘的任何读请求。 讨论的主要议题： 独占锁特性和对象映射功能的实现细节。 对象映射中“可能存在”状态的使用场景和问题。 对象映射的存储和更新效率。 与老版本客户端的兼容性问题。 决定的事项： 确认独占锁特性和对象映射功能的实现细节。 优化对象映射的存储和更新效率。 考虑与老版本客户端的兼容性问题，并寻找解决方案。 后续行动计划： 继续完善独占锁特性和对象映射功能。 优化对象映射的存储和更新效率。 研究与老版本客户端的兼容性问题，并寻找解决方案。 其他： 讨论了关于扩展RBD头部以支持不同类型的权限位，例如读写权限位。 讨论了使用Delta字节而不是完整映射来更新对象映射的可能性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Buffer Encoding","slug":"CDS_Hammer_Day_1_-_Buffer_Encoding","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Buffer_Encoding/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Buffer_Encoding/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储缓冲编码优化讨论 会议时间： 2023年某月某日 参会人员： Sam、Matt、Alan 等 会议内容： 一、会议背景 在 Ceph 分布式存储集群的负载分析中，缓冲编码和编解码过程被指出是性能瓶颈之一。 二、讨论议题 缓冲编码性能问题： 缓冲列表追加路径深度，导致性能损耗。 编码和编解码过程中存在函数调用开销。 编码和编解码路径存在重复计算和冗余操作。 优化方案： 微优化： 尝试内联代码，减少函数调用开销。 优化代码路径，减少重复计算和冗余操作。 尝试减少缓冲追加和编码操作的次数。 重构消息结构： 将消息结构重构为固定大小，减少内存拷贝。 使用内存映射技术，将内存表示与网络表示统一。 使用 flat buffers 等库进行序列化。 兼容性问题： 重构消息结构可能影响向后兼容性。 三、决定事项 优先进行微优化： 对现有结构进行微优化，观察效果。 了解缓冲列表拷贝操作调用频率，优化相关代码。 研究 flat buffers： 研究 flat buffers 的应用，考虑其在 Ceph 中的适用性。 继续研究消息结构重构： 研究消息结构重构的可行性，评估其对向后兼容性的影响。 四、后续行动计划 Matt 和 Sam 继续研究缓冲编码优化方案，并在邮件列表上分享进展。 Sam 和其他成员研究 flat buffers 的应用，评估其在 Ceph 中的适用性。 Alan 研究消息结构重构的可行性，评估其对向后兼容性的影响。 五、其他事项 会议期间讨论了 Ceph 分布式存储的内存对齐问题。 Matt 提到了正在进行的优化方案，包括优化缓冲指针和共享策略。 六、会议总结 本次会议讨论了 Ceph 分布式存储缓冲编码优化方案，明确了后续行动计划。会议强调了微优化和消息结构重构的重要性，并要求团队成员继续研究相关技术。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Import/Export // Local Import","slug":"CDS_Hammer_Day_1_-_Import_Export_Local_Import","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Import_Export_Local_Import/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Import_Export_Local_Import/","excerpt":"","text":"会议纪要 会议主题： Rados 导出/导入功能改进 会议时间： 未知 参会人员： Danny, Mike, John, Tara 等 会议内容： 一、Rados 导出/导入功能现状 目前 Rados 导出功能存在性能瓶颈，尤其是数据量大时，导出速度慢，且在不同文件系统上导出失败率较高。 导入功能也存在问题，将数据重新导入新集群的速度较慢。 二、改进方案 导出功能： 将 Rados 导出功能改为类似 RBD 导出和 RBD 差分的流式导出，提高灵活性。 支持快照导出，导出特定快照状态的数据。 支持分片导出，将对象空间划分为多个部分，并行导出。 添加指纹验证功能，确保导出的数据完整性。 导入功能： 改进导入性能，提高数据导入速度。 支持从快照中恢复数据。 支持分片导入，并行导入数据。 其他： 支持复制池功能，将池状态导出并复制到另一个池。 添加 RBD 命令支持导入差分到本地文件，方便创建新镜像。 三、行动计划 Danny 负责改进导出/导入功能代码。 Mike 负责设计指纹验证功能。 John 和 Tara 负责测试改进后的功能。 四、后续讨论 讨论了快照导出的具体实现方式。 讨论了分片导出/导入的实现细节。 讨论了指纹验证功能的实现方案。 五、会议总结 本次会议讨论了 Rados 导出/导入功能的改进方案，并制定了相应的行动计划。改进后的功能将提高 Rados 的数据迁移和备份能力。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Accelio RDMA Messenger","slug":"CDS_Hammer_Day_1_-_Accelio_RDMA_Messenger","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Accelio_RDMA_Messenger/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Accelio_RDMA_Messenger/","excerpt":"","text":"会议纪要 会议时间： 未知 会议地点： 未知 参会人员： Matt、El、Melanox 团队、Ceph 团队 会议主题： Accelio RDMA Messenger 工作讨论 会议内容： Accelio RDMA Messenger 最新进展： Melanox 团队在 Accelio 中增加了多传输支持，并使 TCP 传输更加功能丰富。 他们正在开发新的显式流控制接口，以允许应用程序更好地控制 XIO 消耗的资源。 他们正在将不同的 RDMA 内存模型、传输内存模型和缓冲区模型集成到 Accelio 中。 Ceph 团队刚刚完成对 XL Messenger 的重大重构，以提高效率。 他们正在开发新的会话管理功能，以支持更多的 Messenger 接口。 Ceph 团队的工作： 他们正在开发一个新的内存缓冲区模型，以提高效率。 他们正在开发新的流控制机制，以避免内存池耗尽。 他们正在开发一个新的测试套件，以测试不同的 Messenger 实现。 后续行动计划： Ceph 团队将在未来几周内提交相关代码更改。 他们将与其他团队合作，以确保代码的兼容性和稳定性。 他们将开发新的测试套件，以测试 Messenger 实现。 关键细节： Accelio RDMA Messenger： 用于 Ceph 分布式存储的 RDMA Messenger。 多传输支持： 支持多种传输协议，例如 TCP 和 RDMA。 流控制： 用于控制资源使用和避免资源耗尽。 内存缓冲区模型： 用于管理内存缓冲区。 会话管理： 用于管理 Messenger 会话。 讨论的主要议题： Accelio RDMA Messenger 的最新进展。 Ceph 团队的工作。 代码集成和测试。 决定的事项： Ceph 团队将在未来几周内提交相关代码更改。 他们将与其他团队合作，以确保代码的兼容性和稳定性。 他们将开发新的测试套件，以测试 Messenger 实现。 后续行动计划： Ceph 团队将在未来几周内提交相关代码更改。 他们将与其他团队合作，以确保代码的兼容性和稳定性。 他们将开发新的测试套件，以测试 Messenger 实现。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Calamari API Roadmap","slug":"CDS_Hammer_Day_1_-_Calamari_API_Roadmap","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Calamari_API_Roadmap/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Calamari_API_Roadmap/","excerpt":"","text":"会议纪要 会议时间： 2014年（具体日期未提及） 会议主题： Calamari API 路线图概述 参会人员： Gregory（Dr. Mino）、Dan、Armando、Tim、James 等 会议内容： 一、Calamari API 概述 Calamari 重新定义： 将 Calamari 定位为后端服务层和 API 层，去除图形用户界面（GUI），以便更聚焦于 API 本身及其功能。 Calamari 目标： 实现与 Rados、RBD 和 RGW 命令行工具的功能对等，提供一致的 RESTful 接口，并支持异步操作。 Calamari 优势： 提供一致的 RESTful 接口，方便开发者使用。 支持异步操作，提高用户体验。 与其他 Ceph 管理、监控工具兼容。 二、Calamari 目标用户 Ceph 社区成员 Red Hat 社区成员 开源社区项目 OpenStack 等云平台 三、Calamari 当前状态 已实现约 30 个 Rados 命令的功能。 已覆盖 OSD 和 Pool 相关功能。 对 Mon 和 Metadata Server 的支持较少。 四、Calamari 1.3 版本计划 改进 Crush 支持功能，包括管理节点和规则。 在 GUI 中展示多集群功能。 引入基于角色的授权机制。 五、社区参与机会 贡献文档 报告新功能需求 参与邮件列表讨论 开发和打包 Calamari 贡献代码 六、行动计划 完成Calamari 1.3 版本开发。 推动Calamari 在更多发行版中打包。 加强社区参与和沟通。 七、其他 讨论了与其他 Ceph 管理、监控工具的兼容性。 讨论了 Calamari GUI 的命名问题。 讨论了 Calamari 依赖包的打包问题。 总结： 本次会议对 Calamari API 的现状、目标和未来计划进行了详细的讨论，并明确了社区参与的机会。Calamari 作为 Ceph 的一个重要管理工具，将在 Ceph 社区中发挥越来越重要的作用。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - OSD: Opportunistic Whole-Object Checksums","slug":"CDS_Hammer_Day_1_-_OSD_-_Opportunistic_Whole-Object_Checksums","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_OSD_-_Opportunistic_Whole-Object_Checksums/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_OSD_-_Opportunistic_Whole-Object_Checksums/","excerpt":"","text":"会议纪要 会议主题： OSD 的机会主义全对象校验和 会议时间： 2023年11月（具体日期未提及） 参会人员： Marcel、Sam、Sage、Heather、David、Craig 等 会议内容： 1. 会议背景 目前 Ceph 存储系统中，对存储在磁盘上的数据进行校验和计算较为昂贵，因此通常不进行校验。 现有的机会主义校验和机制仅对块级别进行校验，且仅在读取或覆盖完整块时更新和验证。 本次会议讨论了在 Ceph 中引入机会主义全对象校验和的方案。 2. 方案概述 该方案的核心思想是在进行数据清理（scrub）时，记录每个对象的完整校验和，并将其存储在对象信息（object info）结构中。 当后续读取对象时，将计算出的校验和与存储的校验和进行比较，若不一致则触发错误，并记录相关信息以便后续修复。 3. 讨论要点 校验和类型： 目前方案中使用 CRC32 进行校验和计算，讨论了是否引入更强大的校验和算法，如 CRC32C 或 SHA。 认为目前使用 CRC32 已能满足需求，且计算速度快，对随机位翻转的检测能力较强。 校验和存储位置： 讨论了将校验和存储在对象信息结构中还是作为单独的属性。 最终决定将校验和存储在对象信息结构中，以便于后续修改和扩展。 校验和更新时机： 讨论了在校验和更新过程中，如何处理对象的修改和损坏。 认为只有当所有副本都保持一致时，才进行校验和更新，以降低风险。 与现有功能的兼容性： 认为该方案与现有功能（如 scrub、repair）兼容，且不会对性能产生显著影响。 4. 行动计划 完善方案设计，并确定具体实现细节。 在 Ceph 中实现机会主义全对象校验和功能。 对现有功能进行测试和验证。 5. 其他事项 讨论了是否引入更通用的校验和表示方式，以方便后续扩展。 认为目前使用 CRC32 已能满足需求，且引入通用表示方式会增加复杂度。 总结： 本次会议讨论了在 Ceph 中引入机会主义全对象校验和的方案，并确定了具体实现细节。该方案有助于提高 Ceph 存储系统的可靠性和可维护性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Clustered SCSI Target Using RBD","slug":"CDS_Hammer_Day_1_-_Clustered_SCSI_Target_Using_RBD","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Clustered_SCSI_Target_Using_RBD/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Clustered_SCSI_Target_Using_RBD/","excerpt":"","text":"会议纪要 会议主题： Ceph分布式存储集群中RBD（RADOS Block Device）的集群化目标（Scuzzy Targets）实现方案讨论 会议时间： 2023年11月某日 参会人员： Christy（提案人）、Mike、Jason、Josh等 会议内容： 1. 当前状态与问题 目前开源的Linux HBA目标设备支持主动/被动模式，广泛支持Pacemaker，但仅支持无级别的故障转移。 这些实现主要依赖于虚拟端口，当主机故障时，被动端口的IP会接管。 单节点持久保留支持存在，但缺乏持久保留的主动/被动节点故障转移支持，导致数据损坏风险。 2. 集群化目标（Scuzzy Targets）方案 提出实现主动/主动HBA支持，简化启动支持和故障恢复，简化设置，支持多种传输协议。 主动/主动方案的缺点是目标实现更复杂，需要修改内核以进行分布式处理和命令执行设置。 3. 实现挑战 请求执行和同步： 需要解决请求执行和同步问题，例如比较和设置（Compare and Set）命令。 持久保留支持： 需要支持持久保留，包括注册、查询、动态更改等。 任务管理： 需要处理任务管理请求，例如设备重置。 4. 实现方案 请求执行和同步： 使用GLM（Global Lock Manager）或降低到底层设备进行锁定。 持久保留支持： 将持久保留作为RBD图像属性持久化，或使用CephFS存储持久化信息。 任务管理： 使用CephFS或用户空间代理处理任务管理请求。 5. 后续行动计划 完成RBD代码实现比较和设置命令。 研究持久保留支持的最佳方案。 实现任务管理功能。 设计和管理集群化目标的配置和管理接口。 会议结论 本次会议讨论了Ceph集群中RBD的集群化目标实现方案，明确了实现挑战和解决方案，并制定了后续行动计划。会议认为，实现集群化目标将提高RBD的可用性和可靠性，为Ceph集群提供更强大的功能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - RGW: Object Versioning // Object Snapshots","slug":"CDS_Hammer_Day_1_-_RGW_-_Object_Versioning_Object_Snapshots","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_RGW_-_Object_Versioning_Object_Snapshots/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_RGW_-_Object_Versioning_Object_Snapshots/","excerpt":"","text":"会议纪要 会议主题： Rados Gateway 对象版本化及后续议题讨论 参会人员： Mike Bryant（蓝图负责人及实现人员）、其他研发人员 会议内容： 一、Rados Gateway 对象版本化 项目背景： 对象版本化是实现数据保护和版本控制的重要功能。 实现方法： 采用 S3 对象版本化方案，通过 RESTful API 实现。 关键技术： 列表对象及其版本 读取和删除特定版本的对象 避免访问每个对象的 bucket index，提高效率 使用 bucket index 作为决策者，保证版本顺序和一致性 对象版本使用命名规范，添加版本号 修改 R Gateway，使用结构体存储对象名称和实例信息 项目进展： 已完成主要功能开发，但存在一些 bug，如超时处理和多区域支持尚未实现。 测试计划： 创建测试 S3 客户端，进行手动测试，并考虑使用现有的 S3 测试套件。 二、Rados Gateway 快照 项目背景： Rados Gateway 快照可用于数据保护和灾难恢复。 讨论内容： 快照粒度：是否按 bucket 或集群进行快照？ 快照触发方式：由管理员还是用户触发？ 快照数据存储：如何存储快照数据？ 快照一致性：如何保证快照的一致性？ 结论： 采用集群级别的快照，由管理员触发，使用现有的快照机制存储数据，并保证快照的一致性。 三、Bucket 生命周期管理 项目背景： Bucket 生命周期管理可以自动处理对象过期、迁移到低成本存储等操作。 讨论内容： 与 Swift 和 S3 的差异：Swift 采用对象级别的过期策略，S3 采用 bucket 级别的生命周期管理。 实现方案：采用 S3 的解决方案，实现 bucket 级别的生命周期管理。 功能需求：支持对象过期、迁移到低成本存储、生命周期策略管理等。 结论： 首先实现支持低冗余存储的 S3 API，并完善相关文档。 四、其他议题 存储策略： 将 Swift 存储策略与 R Gateway 桥接，实现桶放置目标。 文档： 完善相关文档，提高易用性。 后续行动计划： Mike Bryant 修复 Rados Gateway 对象版本化的 bug。 完善测试计划，进行测试验证。 实现 Rados Gateway 快照功能。 实现 Bucket 生命周期管理功能。 完善相关文档。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - librados: Expose Checksums","slug":"CDS_Hammer_Day_1_-_librados_-_Expose_Checksums","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_librados_-_Expose_Checksums/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_librados_-_Expose_Checksums/","excerpt":"","text":"会议纪要 会议主题 讨论如何实现端到端数据完整性检查，特别是针对LibreOSD的校验和暴露。 关键细节 议题背景：目前Ceph存储系统中，数据完整性校验的接口不足，导致无法在客户端生成数据时进行校验，从而在数据传输过程中可能发生损坏。 解决方案：通过在LibreOSD中实现校验和暴露，使得客户端在数据生成时即可进行校验，并将校验信息传递至OSD，确保数据完整性。 讨论的主要议题 校验和暴露的实现方式： 建议扩展libretos.h和Dot HPP文件，添加写和读接口，以便在数据传输过程中传递校验信息。 定义一个结构体来描述校验和，包括校验类型和校验值。 使用CRC32等校验算法进行校验。 接口使用： rgw和RBD等客户端可以使用该接口进行数据完整性校验。 在OSD中进行校验，确保数据在存储过程中的完整性。 校验和类型： 可以使用不同的校验算法，例如CRC32、SHA等。 校验和类型可以根据应用场景进行调整。 决定的事项 实现LibreOSD的校验和暴露，并扩展libretos.h和Dot HPP文件。 定义一个结构体来描述校验和，包括校验类型和校验值。 使用CRC32等校验算法进行校验。 接口使用：rgw、RBD等客户端可以使用该接口进行数据完整性校验。 后续行动计划 完成LibreOSD的校验和暴露实现。 定义校验和结构体，并集成到Ceph系统中。 测试校验和暴露功能，确保其有效性和可靠性。 根据反馈优化校验和暴露功能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - RGW: Bucket Index Scalability","slug":"CDS_Hammer_Day_1_-_RGW_-_Bucket_Index_Scalability","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_RGW_-_Bucket_Index_Scalability/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_RGW_-_Bucket_Index_Scalability/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储项目讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： 未提及具体姓名，但提到了 Guang、Patrick 等人 会议内容： 一、bucket 可扩展性 背景： bucket 可扩展性是 Ceph 分布式存储项目的一个重要议题，涉及 bucket 索引的扩展性。 进展： 目前该功能进展顺利，已经完成了大部分工作，但与多区域、多区的功能集成尚未完成。主要问题在于后台索引中存在一些日志，需要确保多区域环境下一切正常工作。 解决方案： 可以通过使用不同类型的标记来实现多区域下的 bucket 索引，或者在 bucket 列表中使用标记来识别不同 bucket 的位置。 下一步： 等待 Guang 回来后，进一步讨论该功能的细节。 二、list 命令 讨论： 讨论了添加两个不同的 list 命令：传统的有序 list 命令和新的无序 list 命令。 进展： 无序 list 命令尚未实现，但应该比较容易添加。 问题： 位置标识符需要从键名对象改为元组，以支持无序 list 命令。 三、multi-object 上传的原子性 讨论： 讨论了 multi-object 上传的原子性问题。 结论： multi-object 上传需要所有条目都在同一个 bucket 中，因此不会影响原子性。 四、blind buckets 讨论： 讨论了 blind buckets 的实现情况。 结论： 目前没有实现 blind buckets，因为它会牺牲多区域、多区和对象版本化等功能。 五、object engine 分支 讨论： 讨论了 object engine 分支与 bucket 可扩展性功能的冲突。 结论： 由于两个功能没有涉及到相同的代码区域，因此不太可能存在冲突。 六、radi Gateway agent 讨论： 讨论了 Guang 是否会继续工作在 radi Gateway agent 上。 结论： 希望有新加入的成员能够帮助 Guang 工作。 七、bucket 分片 讨论： 讨论了 bucket 分片的实现方式。 结论： 可以通过以下步骤实现 bucket 分片： 在 bucket 创建之前进行分片。 对于已经存在的 bucket，可以将其转换为新的分片 bucket。 八、行动计划 等待 Guang 回来后，进一步讨论 bucket 可扩展性功能的细节。 实现无序 list 命令。 完成radi Gateway agent 的开发工作。 实现bucket 分片功能。 九、会议总结 本次会议讨论了 Ceph 分布式存储项目的多个议题，包括 bucket 可扩展性、list 命令、multi-object 上传、blind buckets、object engine 分支、radi Gateway agent 和 bucket 分片等。会议明确了下一步的行动计划，并希望新加入的成员能够为项目贡献力量。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Towards Ceph Cold Storage","slug":"CDS_Hammer_Day_1_-_Towards_Ceph_Cold_Storage","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Towards_Ceph_Cold_Storage/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Towards_Ceph_Cold_Storage/","excerpt":"","text":"会议纪要 会议主题： 冷存储在 Ceph 中的应用探讨 参会人员： Matthias Gravenka（美因茨大学）、Marcelo（前帕拉多大学）、Ceph 社区成员 会议内容： 一、背景 Matthias 和 Marcelo 提出了关于将 Ceph 应用于冷存储的蓝图，并希望通过本次会议讨论其可行性及实施方案。 二、主要议题 冷存储需求： 能量感知的放置策略 数据迁移最小化 数据持久性 可扩展性 方案探讨： 能量感知的放置策略： 通过桶类型实现，了解 OSD 的电源状态，并根据时间进行动态切换。 在 OSD 映射层实现，而非 CRUSH 层。 数据迁移最小化： 在 CRUSH 规则中添加插件功能，实现更灵活的映射方案。 标记对象属性，实现冷数据、热数据的分层存储。 引入对象重定向功能，将冷数据指向外部存储。 数据持久性： 引入归档守护进程，实现冷数据的生命周期管理。 可扩展性： 通过时间切片等方法，实现数据的分层存储。 三、讨论结果 能量感知的放置策略： 该方案可行，但需要考虑 CRUSH 映射表更新的开销。 可以通过在 OSD 映射层实现，避免修改 CRUSH 算法。 数据迁移最小化： 可以通过 CRUSH 规则中的插件功能实现更灵活的映射方案。 可以标记对象属性，实现冷数据、热数据的分层存储。 对象重定向功能尚未实现，但已有原型。 数据持久性： 归档守护进程的实现需要结合对象重定向功能。 可扩展性： 通过时间切片等方法，实现数据的分层存储。 四、后续行动计划 Matthias 和 Marcelo 将继续完善其蓝图，并撰写论文和硕士论文。 Ceph 社区成员将继续讨论并评估该方案的可行性。 一旦方案得到认可，将着手进行代码开发。 五、关键术语 冷存储 冷数据 热数据 CRUSH 算法 OSD 映射 对象重定向 归档守护进程","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS Hammer (Day 1) - Tuethology","slug":"CDS_Hammer_Day_1_-_Tuethology","date":"2014-10-28T16:00:00.000Z","updated":"2014-10-29T16:00:00.000Z","comments":true,"path":"2014/10/29/CDS_Hammer_Day_1_-_Tuethology/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/10/29/CDS_Hammer_Day_1_-_Tuethology/","excerpt":"","text":"会议纪要 会议时间：[请填写会议时间] 会议地点：[请填写会议地点] 参会人员：[请填写参会人员名单] 记录人：[请填写记录人姓名] 一、会议议程 介绍与讨论 文档更新与改进 功能更新与开发计划 打包与发布流程 管理与维护 二、会议内容 文档更新与改进 目前文档更新困难，需要改进。 将安装说明单独成文，并保持更新。 记录设置toothy栈的过程，包括锁服务器和队列的设置。 Alfredo DEA协助生成HTML文档，并上传至se.com。 讨论如何自动发布文档的Jenkins作业。 功能更新与开发计划 Q替换：计划在部署新实验室后进行Q替换。 长期目标：将toothy转换为基于Web的界面，使用API与Web服务通信。 打包：toothy在Python包索引中版本过旧，需要建立发布流程。 打包与发布流程 建立发布流程，包括版本号管理、变更日志等。 建议使用Jenkins自动发布文档。 管理与维护 讨论toothy的安装情况，包括Susa、SanDisk等。 讨论使用OpenStack API后端部署测试机器的可行性。 讨论使用容器（如Docker）进行测试的可行性。 讨论插件架构，以支持不同的资源分配后端。 讨论改进队列和作业调度机制，提高可靠性和可管理性。 三、行动计划 完善文档，包括设置toothy栈的过程。 实施Q替换。 建立发布流程。 研究使用容器进行测试的可行性。 设计插件架构，以支持不同的资源分配后端。 改进队列和作业调度机制。 四、会议总结 本次会议讨论了toothy项目的文档更新、功能更新、打包发布流程以及管理维护等方面的问题。会议明确了下一步的工作计划和行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Asaf Wachtel MELLANOX","slug":"RH_InkTank_Ceph_Day_Sessions_Asaf_Wachtel_MELLANOX","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Asaf_Wachtel_MELLANOX/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Asaf_Wachtel_MELLANOX/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： Asaf（Melanox企业及云业务发展负责人） [其他参会人员姓名] 会议议程： 1. 介绍与背景 Asaf介绍了Melanox公司，作为高性能服务器、存储和连接解决方案的领先提供商，Melanox提供从网络适配器到交换机、从10Gbps到56Gbps的全套产品。 公司业务始于1999年，现有约1500名员工，年收入约5亿美元，最初服务于高性能计算（HPC）领域，后扩展到存储、云计算、Web 2.0等行业。 2. 网络在Ceph世界中的作用 Asaf指出，随着新一代应用产生海量数据，需要下一代网络来承载这些数据。 Ceph作为分布式存储系统，其性能和可用性高度依赖于高性能网络。 高性能网络的关键要素包括：无损、高带宽、低延迟和CPU卸载。 3. Ceph部署案例 Asaf分享了一个8.5PB Ceph集群部署案例，该集群用于Web环境，对性能要求极高。 该案例中，后端网络采用40Gbps以太网，前端网络采用10Gbps和40Gbps以太网，以支持SSD的使用。 4. 高性能网络部署指南 Melanox提供了一份关于高性能网络部署的指南，详细介绍了所需硬件和配置。 指南中包含了两个用例：10Gbps以太网公共网络和40Gbps以太网公共网络。 5. Hadoop与Ceph的协同 Melanox一直在研究如何优化Hadoop的网络配置，以提高性能。 他们发现，将HDFS替换为Ceph的SEFS可以提供统一的存储体验，并提高性能。 他们还进行了一项研究，展示了SEFS在Terasort基准测试中的性能提升。 6. 硬件优化 Melanox开发了Excelo API，用于简化RDMA编程，并支持多种传输方式。 Excelo API可以帮助应用更容易地集成RDMA，并提高性能。 7. 总结 Ceph对高性能网络的需求很高，Melanox提供了一系列解决方案，包括高性能网络设备和软件。 Melanox将继续致力于优化Ceph的性能和可用性。 后续行动计划： [请填写后续行动计划，例如：与客户合作部署高性能网络、优化Excelo API、参与Ceph社区等] 关键词： Ceph 分布式存储 高性能网络 40Gbps以太网 56Gbps以太网 RDMA Excelo API 高性能计算 云计算 Hadoop","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Mario Blandini HGST","slug":"RH_InkTank_Ceph_Day_Sessions_Mario_Blandini_HGST","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Mario_Blandini_HGST/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Mario_Blandini_HGST/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 未提及 参会人员： HGST代表Mario，Karanvir Singh，以及Ceph社区成员 会议主题： HGST的开放以太网驱动架构及其在Ceph中的应用 会议内容： 一、HGST公司介绍 HGST是一家专注于存储解决方案的硬件公司，其产品包括硬盘驱动器、固态硬盘、PCIe闪存和软件。 HGST认为，随着数据量的不断增长，需要新的技术创新来满足存储需求。 二、开放以太网驱动架构 HGST提出了开放以太网驱动架构，该架构旨在将数据存储服务移动到更靠近存储介质的位置。 该架构具有以下特点： 开放：采用开源软件和硬件，以支持创新和可扩展性。 以太网：利用以太网连接，简化管理和监控。 驱动：基于硬盘驱动器，提供高性能和可扩展性。 架构：作为软件定义数据中心的基础构件。 三、硬件设计 HGST展示了其参考设计方案，该方案包括： 3.5英寸硬盘驱动器，具有SAS连接器和内置以太网。 60个硬盘驱动器的机架式服务器。 集成交换机。 10千兆以太网端口。 四、软件支持 HGST的开放以太网驱动架构支持Ceph、Gluster和OpenStack等开源软件。 HGST展示了Ceph集群和Gluster集群的运行情况，并进行了数据传输演示。 五、未来展望 HGST计划进一步优化其开放以太网驱动架构，以提高性能和可扩展性。 HGST将积极与Ceph社区合作，共同推动开源存储技术的发展。 六、行动计划 HGST将继续与Ceph社区合作，共同推动开源存储技术的发展。 HGST将探索将开放以太网驱动架构应用于更多场景。 HGST将积极寻求与软件开发商合作，共同开发基于该架构的创新解决方案。 七、关键术语 开放以太网驱动架构（Open Ethernet Drive Architecture） 软件定义存储（Software-defined Storage） Ceph Gluster OpenStack 八、总结 HGST的开放以太网驱动架构为Ceph等开源存储解决方案提供了一种新的解决方案，有助于提高性能、可扩展性和可管理性。该架构具有广阔的应用前景，值得Ceph社区关注。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Casey Bodley COHORTFS","slug":"RH_InkTank_Ceph_Day_Sessions_Casey_Bodley_COHORTFS","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Casey_Bodley_COHORTFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Casey_Bodley_COHORTFS/","excerpt":"","text":"会议纪要 会议时间： [请填写具体日期和时间] 参会人员： Casey, Hassan 等 会议主题： 可扩展的NFS上的元数据 会议内容： 一、会议背景 Casey介绍了NFS（网络文件系统）的优势，包括其作为IETF标准、广泛的应用、成熟的技术和可扩展性。 讨论了如何利用NFS的扩展性来提高数据存储的效率，例如通过RAD、对象条带化和Crush算法来优化数据放置。 二、主要议题 Parallel NFS (pnfs)：介绍pnfs的概念，它允许pnfs客户端直接与存储设备通信，并支持不同的布局类型，包括黑色卷设备（osds）和文件布局。 元数据扩展性：讨论了现有元数据扩展技术的局限性，如Seth的分布和负载均衡技术，以及NFS在当前版本中缺乏利用这些技术的手段。 pnfs metastripe：介绍了一种将pnfs思想应用于元数据的新技术，允许客户端通过初始元数据服务器获取布局信息，并直接访问其他元数据服务器。 三、讨论要点 布局类型：pnfs metastripe定义了两种布局类型：文件条带布局和目录条带布局，用于确定文件和目录条带的位置。 操作优化：通过并行读取、并行目录修改和布局提交，pnfs metastripe提高了元数据操作的效率。 原型实现：Casey介绍了基于开源NFS连接服务器和piNFS测试套件的pnfs metastripe原型。 四、决定事项 继续推进pnfs metastripe的IETF草案。 优化布局提交和M时间一致性。 支持Seth frag trees。 五、后续行动计划 完成pnfs metastripe的IETF草案。 实现布局提交和M时间一致性。 支持Seth frag trees。 评估和改进原型性能。 六、其他事项 会议中未提及具体的时间表和责任人。 总结： 本次会议讨论了NFS在元数据扩展性方面的挑战和解决方案，介绍了pnfs metastripe技术，并确定了后续行动计划。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Jeff Darcy REDHAT","slug":"RH_InkTank_Ceph_Day_Sessions_Jeff_Darcy_REDHAT","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Jeff_Darcy_REDHAT/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Jeff_Darcy_REDHAT/","excerpt":"","text":"会议纪要 会议时间： [请填写会议具体时间] 会议地点： [请填写会议具体地点] 参会人员： [请填写参会人员名单] 会议主题： Gluster与Ceph技术结合的实验性探索 会议内容： 会议背景： 介绍者分享了在Inktank收购后，关于将Gluster和Ceph技术结合的实验性想法，这一想法已有两年之久。 强调这是一个科学探索，而非工程应用，目的在于发现可能性，而非满足特定需求。 关键点说明： 针对市场上关于收购后Gluster和Ceph技术将被拆分的传闻，澄清了这是实验性的探索，并非官方路线图。 介绍者试图通过混合匹配组件，了解liberatos API和组件对性能、故障处理等方面的贡献。 个人背景： 介绍者拥有丰富的分布式网络集群和文件系统经验，曾运行过多种分布式文件系统，包括extremeFS、mooseFS、HDFS等。 Gluster工作原理： Gluster的核心概念是“翻译器”，它接收I/O请求并转换为相同的I/O请求形式。 Gluster使用一系列翻译器处理请求，包括文件系统、NFS、libGF API等。 Gluster使用DHT进行数据分布，并使用AFR进行数据复制。 实验设计： 将Gluster与Ceph的Rados存储系统结合，观察数据I/O性能和其他行为。 将Gluster文件和相应的Rados对象关联，实现数据在不同存储系统之间的切换。 实验结果： 在64k顺序写入测试中，GLaDOS版本在低线程计数时性能较差，但在高线程计数时逐渐赶上。 在4K同步随机写入测试中，GLaDOS版本在性能上优于Ceph文件系统（SEFS）。 后续行动： 对低线程计数时性能较差的问题进行进一步调查。 探索GLaDOS版本在性能上优于SEFS的原因。 将实验代码分享到GitHub或Gluster Forge。 会议结论： Gluster与Ceph技术的结合是一个有趣的实验性探索，有助于了解两种技术的性能差异和潜在优势。 需要进一步研究低线程计数时性能较差的问题，并探索GLaDOS版本在性能上优于SEFS的原因。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Kamesh Pemmaraju DELL","slug":"RH_InkTank_Ceph_Day_Sessions_Kamesh_Pemmaraju_DELL","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Kamesh_Pemmaraju_DELL/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Kamesh_Pemmaraju_DELL/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： - Kamesh Pemeraju，戴尔公司高级产品经理，专注于OpenStack - [其他参会人员] 会议主题： Ceph与OpenStack的结合，Ceph在不同场景下的应用，以及案例研究 会议内容： 一、Ceph与OpenStack的结合 Ceph在OpenStack中的应用： Ceph与OpenStack的Swift API和Cinder API兼容，可提供对象存储和块存储服务。 Ceph可以作为OpenStack的底层存储平台，支持OpenStack的Glance、Nova等服务。 Ceph的应用场景： 开源云存储：可以作为纯对象存储使用，类似于Swift集群。 Web应用：提供高性能、可扩展的存储解决方案。 大数据：可以作为HDFS的替代方案，提供高性能的文件系统。 Ceph的架构考虑： 可靠性：考虑冗余和故障域，确保数据安全。 存储池：根据需求选择SSD池或容量池。 监控节点：考虑监控节点的故障域，确保集群稳定运行。 二、案例研究：阿拉巴马大学 背景： 阿拉巴马大学在癌症和基因组研究方面有大量数据，数据分散在各个设备上，管理困难。 解决方案： 使用Ceph和OpenStack构建可扩展的存储云，集中管理数据。 使用Crowbar进行集群部署，简化部署过程。 效果： 提高数据管理效率，降低成本。 研究人员可以访问更大的数据集，提高工作效率。 三、后续行动计划 戴尔和红帽将推出预配置的Ceph和OpenStack解决方案，简化部署过程。 继续与客户合作，推动Ceph和OpenStack的广泛应用。 四、讨论要点 Ceph与OpenStack的结合为用户提供了灵活的存储解决方案。 Ceph在不同场景下具有广泛的应用前景。 部署Ceph和OpenStack需要考虑多个因素，包括可靠性、性能和成本。 案例研究表明，Ceph和OpenStack可以为用户提供有效的存储解决方案。 五、结束语 本次会议深入探讨了Ceph与OpenStack的结合以及Ceph在不同场景下的应用，并分享了阿拉巴马大学的成功案例。相信随着Ceph和OpenStack的不断发展，它们将为用户带来更多的价值。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Matt Benjamin COHORTFS","slug":"RH_InkTank_Ceph_Day_Sessions_Matt_Benjamin_COHORTFS","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Matt_Benjamin_COHORTFS/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Matt_Benjamin_COHORTFS/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 会议地点： [请填写会议地点] 参会人员： Matt Benjamin（CTO of Word and），其他与会人员 会议主题： Ceph项目进展及Accelio集成 会议内容： 一、项目背景 Word and是一家位于密歇根州安阿伯的初创公司，专注于将新功能引入并行NFS，以应对新的应用工作负载。 该项目最初由NSF资助，后来扩展到SAP存储堆栈，以增强其功能。 二、Accelio集成 Accelio是一个高性能异步和可靠的消息库，支持硬件加速，旨在构建高性能RPC传输。 该项目与Melanox合作，将Ceph代码库与Accelio集成，以实现高效的传输和消息传递。 该项目的主要目标是提高Ceph的性能，特别是在单位级别的高性能I/O性能。 三、Accelio关键特性 支持RMA传输，未来将支持多种传输。 支持请求/响应协议和单向协议，支持多种交付语义。 支持零拷贝，内部消息路径几乎无锁。 优化线程/CPU并行，减少应用参与度。 支持高达三百万个应用程序，能够饱和单个端口。 四、XIO Messenger XIO Messenger是Accelio的适配器，用于将Ceph网络或消息传递映射到Infiniband。 它是一个可插入的替代品，可以与当前的TCP消息封装一起使用。 XIO Messenger旨在实现零拷贝和线程级别的并行。 五、Ceph代码库重构 为了更好地集成Accelio，Ceph代码库正在进行重构。 重构的目标是提取通用代码，以便所有消息传递器都可以使用。 六、性能测试 使用Accelio进行性能测试，结果表明其性能良好。 在64k消息大小下，几乎饱和了XIO的可用带宽。 七、项目状态 XIO Messenger堆栈已完成，已集成到Ceph中。 项目正在进行中，旨在使Ceph集群能够在XIO上运行。 项目代码可在Accelio和Ceph的GitHub仓库中找到。 八、后续行动计划 继续优化Ceph代码库。 完成Ceph集群在XIO上的测试和验证。 将XIO集成到Ceph的主要分支中。 九、其他事项 项目团队将继续关注Ceph和Accelio的最新动态，以确保项目的顺利进行。 总结： 本次会议介绍了Ceph项目进展和Accelio集成的情况。项目团队正在努力提高Ceph的性能，并使其能够支持更高效的消息传递。项目进展顺利，预计将在未来推出全新的Ceph版本。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"RH InkTank Ceph Day Sessions Sage Weil REDHAT","slug":"RH_InkTank_Ceph_Day_Sessions_Sage_Weil_REDHAT","date":"2014-07-24T16:00:00.000Z","updated":"2014-07-25T16:00:00.000Z","comments":true,"path":"2014/07/25/RH_InkTank_Ceph_Day_Sessions_Sage_Weil_REDHAT/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/07/25/RH_InkTank_Ceph_Day_Sessions_Sage_Weil_REDHAT/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 未知 参会人员： Ceph 项目负责人及团队成员，以及外部合作伙伴和开发者 会议主题： Ceph 项目发展历程、当前工作重点及未来规划 会议内容： 一、Ceph 项目发展历程 研究阶段： Ceph 项目起源于加州大学圣克鲁兹分校，旨在为高性能计算构建高可扩展性的文件系统。该阶段主要关注可扩展性、可靠性和性能，目标是实现每秒写入数以TB计的数据。 孵化阶段： 项目在 Dreamhost 公司孵化，并开源。期间，Ceph 团队致力于构建一个功能强大的统一存储平台，包括对象存储、块存储和分布式文件系统。 Inktank 阶段： 成立 Inktank 公司，专注于 Ceph 的商业化推广和支持。期间，Ceph 项目取得了快速发展，并得到了红帽等公司的支持。 红帽阶段： Red Hat 收购 Inktank，Ceph 成为红帽公司的一部分，进一步提升了 Ceph 项目的知名度和影响力。 二、当前工作重点 分层存储： 通过引入缓存池和分层架构，实现热数据和冷数据的分离，提高存储效率和性能。 纠删码： 支持纠删码，降低存储成本，提高数据可靠性。 多数据中心： 实现跨数据中心的异步复制和灾难恢复，满足企业级需求。 文件系统： 提升文件系统的稳定性和性能，使其达到生产级标准。 三、未来规划 治理结构： 完善项目治理结构，加强社区建设，吸引更多开发者参与。 技术路线： 持续改进 Ceph 项目的功能和性能，满足更多用户需求。 生态建设： 加强与 OpenStack、KVM 等开源项目的合作，推动 Ceph 在更多场景下的应用。 企业级市场： 拓展企业级市场，满足企业级用户的需求。 四、行动计划 完善治理结构： 建立项目委员会，明确项目发展方向和决策流程。 加强社区建设： 举办开发者峰会，促进社区交流与合作。 持续改进技术： 优先解决社区反馈的问题，持续提升 Ceph 项目的功能和性能。 拓展应用场景： 与合作伙伴共同开发解决方案，推动 Ceph 在更多场景下的应用。 五、会议总结 Ceph 项目在过去十年中取得了显著的成绩，未来将继续致力于构建一个功能强大、可扩展、可靠的分布式存储平台，为用户提供更好的存储解决方案。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - Calamari Localization","slug":"CDS_G_H_Day_2_-_Calamari_Localization","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_Calamari_Localization/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_Calamari_Localization/","excerpt":"","text":"会议纪要 会议时间： [会议时间] 会议主题： Calamari 本地化讨论 参会人员： Jen（Calamari 本地化项目负责人） Xi'an（Calamari 本地化讨论主持人） Lee（可能稍后加入） 其他相关人员 会议内容： 1. Calamari 本地化项目介绍 Jen 介绍了 Calamari 本地化项目的背景和目标，旨在将 Calamari 的界面和功能翻译成中文，提高用户体验。 目前 Calamari 提供了监控视图、OSD 管理、信息等功能，但界面内容尚未本地化。 2. 本地化方法讨论 使用 Gettext 工具进行本地化，该工具可以将要翻译的消息封装在函数中，然后通过模板进行翻译。 讨论了本地化过程中需要注意的问题，例如： 确保本地化内容易于复制和推广。 选择哪些内容需要翻译，哪些内容可以保留英文。 与社区合作，提供翻译资源。 3. 本地化资源文件 讨论了如何创建本地化资源文件，例如 po 文件，用于存储翻译后的内容。 确定首先从界面元素开始翻译，例如用户名、密码、登录按钮等。 4. 本地化工具和协作 使用 Google Drive 或 Google Docs 进行协作，共享截图和标注。 确定由 Jen 和 Gregory 负责整理和标注界面截图。 5. Calamari 功能讨论 讨论了 Calamari 的功能需求，例如： 支持更多 OSD 节点。 提供更多 OSDD 统计信息。 提供更详细的错误报告。 6. 行动计划 Jen 和 Gregory 负责整理界面截图并进行标注。 社区成员参与翻译工作。 Gregory 将参与本地化项目，提供技术支持。 关键词： Calamari 本地化 Gettext 翻译 界面 OSD 统计信息 错误报告","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - CephFS: file creation & object-level backtraces","slug":"CDS_G_H_Day_2_-_CephFS_-_file_creation_object-level_backtraces","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_CephFS_-_file_creation_object-level_backtraces/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_CephFS_-_file_creation_object-level_backtraces/","excerpt":"","text":"会议纪要 会议主题： Ceph 文件系统（CFS）讨论：文件创建和对象级回溯 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议内容： 一、主要议题 文件创建和对象级回溯问题： 用户 Alexander 投诉客户端回溯信息过多，导致 OSD 集群负载过重。 回溯信息目前仅在日志段被修剪时写入，导致性能问题。 讨论了将回溯信息写入元数据池或键值存储的可行性。 提出将回溯信息作为能力机制的一部分通过客户端进行更新的方案。 异步文件创建： 讨论了异步文件创建的可行性，包括如何处理客户端失败和确保文件属性正确。 提出使用未分配的inode队列来实现异步创建的方案。 回溯信息存储： 讨论了回溯信息的存储方式，包括是否将其存储在元数据池、键值存储或数据池。 认为将回溯信息存储在数据池中可能更高效，但需要考虑如何处理数据池迁移的情况。 二、决定事项 将文件创建和对象级回溯问题的解决方案作为单独的工单提交到跟踪器，并优先处理。 研究异步文件创建的可行性，并评估其性能和可靠性。 探索回溯信息存储的最佳方案，并考虑数据池迁移的情况。 三、后续行动计划 [开发人员] John 将研究异步文件创建的方案，并评估其可行性。 [开发人员] Greg 将研究回溯信息存储的最佳方案，并考虑数据池迁移的情况。 [开发人员] Alexander 将将文件创建和对象级回溯问题的解决方案作为单独的工单提交到跟踪器。 四、关键术语 CFS： Ceph 文件系统 OSD： 块设备 MDS： 元数据服务器 inode： 文件系统中的节点，包含文件属性和指针 back trace： 回溯信息，用于从inode号查找文件位置 五、备注 会议中讨论的方案需要进一步研究和评估，以确保其可行性和性能。 异步文件创建和回溯信息存储的优化将有助于提高 Ceph 文件系统的性能和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - RBD: Copy-on-read for clones in kernel RBD client","slug":"CDS_G_H_Day_2_-_RBD_-_Copy-on-read_for_clones_in_kernel_RBD_client","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_RBD_-_Copy-on-read_for_clones_in_kernel_RBD_client/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_RBD_-_Copy-on-read_for_clones_in_kernel_RBD_client/","excerpt":"","text":"会议纪要 会议时间： 2023年11月[具体日期] 会议地点： 线上会议 参会人员： Min、Ostensibly Lee、Josh、Elia等 会议主题： RBD（Radial Bulletproof Disk）的复制和读取克隆功能实现讨论 会议内容： Min介绍了其蓝图： 在RBD客户端中实现RBD克隆的复制和读取功能，降低读取非克隆对象时的延迟。他提出使用Carbon读取邻居BD的算法，并使用escrow覆盖方法将数据写入克隆。 讨论实现位置： Josh建议在处理RBD图像对象请求提交的功能中实现Carbon读取，这是启动最高级别操作的函数。 Elia提到用户空间客户端不支持驱动程序版本2，因此无需担心用户空间中的额外条带化操作。 配置方式： 关于配置方式，讨论了是否在映射图像时添加选项，以及如何与现有选项机制兼容。 用户空间复制和读取功能： Josh提到用户空间复制和读取功能的v2 pull request仍存在问题，需要进一步改进。 复杂性问题： 讨论了在内核侧实现复杂条带化可能遇到的挑战，以及是否应先实现复制和读取功能。 同步与异步： 讨论了在满足读取请求之前是否应先执行整个提升操作，以及是否应使用同步或异步方式。 RBD客户端稳定性： 确认RBD客户端非常稳定，但Min提到liberty覆盖与窃取相关的错误问题。 锁机制： 讨论了当多个客户端访问同一图像时如何避免冲突，以及如何处理锁定。 数据传输： 讨论了rbd_image_object_callback如何将数据返回给bio和vfs。 obj_i_eq和device_flags： 讨论了obj_i_eq和device_flags的作用，以及如何区分页面列表和bio列表。 决定事项： 继续推进RBD克隆的复制和读取功能实现。 将技术问题发送至邮件列表和irc进行讨论。 在接下来的一个月或两个月内，加快复制和读取功能的开发。 后续行动计划： Min将完善RBD克隆复制和读取功能的实现方案。 Josh和Elia将协助解决用户空间复制和读取功能的问题。 所有参会人员将积极参与邮件列表和irc讨论，共同推进RBD克隆功能的开发。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - RBD: Database Performance","slug":"CDS_G_H_Day_2_-_RBD_-_Database_Performance","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_RBD_-_Database_Performance/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_RBD_-_Database_Performance/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 会议地点： 线上会议 参会人员： JYG, MT Wong, Luke, inkten, sam, josh, 等 会议主题： Ceph数据库性能优化及测试方案 会议内容： 1. 会议背景 旨在探讨如何在Ceph上运行数据库，尤其是RBD上的数据库性能优化。 希望通过优化，实现跨广域网络的数据库运行，而非多站点复制。 2. 讨论议题 数据库性能问题： 使用Ceph作为后端存储的数据库（如PostgreSQL、MySQL等）性能不如预期。 原因可能包括： RBD的striping策略导致小写入操作堆积在单个对象上，影响性能。 数据库的写前日志（WAL）可能导致性能瓶颈。 网络延迟和复制开销。 优化方案： 调整RBD的striping策略，优化小写入操作的处理。 将WAL存储在独立的设备上，例如SSD。 使用RBD缓存来提高性能。 调整Ceph和数据库的配置参数。 使用SSD作为OSD的存储介质。 测试方案： 使用firefly进行性能测试，对比不同配置下的性能表现。 使用block trace和sequencer等工具进行性能分析。 与社区分享测试结果和最佳实践。 3. 决定事项 成立一个工作组，负责Ceph数据库性能优化和测试。 工作组将制定详细的测试方案，并开始进行测试。 工作组将定期分享测试结果和最佳实践。 4. 后续行动计划 工作组将制定详细的测试方案，包括测试环境、测试用例、测试工具等。 工作组将开始进行测试，并记录测试结果。 工作组将分析测试结果，并找出性能瓶颈。 工作组将根据分析结果，提出优化方案。 工作组将分享测试结果和最佳实践，并与社区进行讨论。 5. 关键词 RBD PostgreSQL MySQL WAL Striping SSD Cache Performance Benchmark Test Community","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - CephFS: forward scrub","slug":"CDS_G_H_Day_2_-_CephFS_-_forward_scrub","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_CephFS_-_forward_scrub/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_CephFS_-_forward_scrub/","excerpt":"","text":"会议纪要 会议主题： 分布式存储Ceph文件系统一致性检查系统（forward scrub）方案讨论 会议时间： 2023年11月某日 参会人员： （此处应列出参会人员名单） 会议内容： 议题背景： 会议讨论了Ceph文件系统一致性检查系统（forward scrub）的方案，该方案旨在确保文件系统的数据一致性。 该方案分为两部分：第一部分是forward scrub，从文件系统的根节点开始，向下检查所有文件和目录的一致性；第二部分是反向检查，检查所有rados pool中的对象是否与文件系统相关联。 forward scrub方案细节： forward scrub将创建一个独立的scrub线程，运行在MJS（Metadata Server）上。 scrub线程从scrub iode函数开始，维护一个inode栈，用于记录需要检查的inode。 scrub node函数会检查inode，如果是文件，则检查其元数据一致性；如果是目录，则检查目录内容与元数据的一致性。 对于远程inode（硬链接），需要验证其存在性和链接计数正确性。 scrub过程中，会对inode设置scrub start stamp和scrub start version，用于记录scrub的开始时间和版本。 scrub完成后，会标记scrub finish，并记录scrub结束时间和版本。 讨论要点： scrub过程中如何处理远程inode的链接计数问题。 是否有必要在内存中设置scrub start stamp和scrub start version。 是否可以将scrub分为阻塞和非阻塞两种模式。 是否可以将scrub分为不同的级别，例如快速内存scrub和完整文件scrub。 行动计划： 进一步完善forward scrub方案，包括处理远程inode链接计数问题和scrub级别划分。 制定详细的技术方案和实施计划。 在Ceph社区中讨论和评估该方案。 关键词： forward scrub, distributed SE FS, consistency check, scrub thread, MJS, inode, metadata, rados pool, object, link count, scrub start stamp, scrub start version, scrub finish, block, non-block, scrub level","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - CephFS: security & multiple instances in a single RADOS cluster","slug":"CDS_G_H_Day_2_-_CephFS_-_security_multiple_instances_in_a_single_RADOS_cluster","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_CephFS_-_security_multiple_instances_in_a_single_RADOS_cluster/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_CephFS_-_security_multiple_instances_in_a_single_RADOS_cluster/","excerpt":"","text":"会议纪要 会议主题： Ceph集群中支持多个FFS文件系统的可能性探讨 会议时间： 未知 参会人员： 未知 会议内容： 一、会议背景 近期，开发人员讨论了在单个Raiders集群中添加对多个FFS文件系统支持的可行性。目前，关于如何实现这一功能存在两种不同的方法，它们在安全性、便利性和保证方面有所不同。 二、讨论的主要议题 多种文件系统支持的两种方法： 方法一： 倡导由Sage提出的方案，允许集群中存在任意数量的文件系统，通过多个MDS映射来指定每个文件系统的数据和元数据池。这种方法在文件系统代码上更为简单，但在监视器方面需要更多的工作。它能够提供有效的多租户功能，但每个文件系统都需要独立的元数据服务器和Rados池，无法实现负载均衡。 方法二： 倡导将多个文件系统作为文件系统中的目录实现，并提供一些语法糖来简化操作。这种方法不需要修改监视器，可以利用客户端之间的负载均衡，但需要稳定的MDS实现和文件系统安全设置。 安全性期望： 如果通过多个MDS实现的多租户功能不足以保证安全性，那么实现这一功能的吸引力会降低。可能需要实施一个强大的安全系统，而不是对监视器进行大量更改。 两种方法都需要解决客户端与服务器协议之间的信任问题，以防止潜在的安全漏洞。 三、决定的事项 邀请用户提供用例，以便更好地了解不同方法的优势和优先级。 进一步讨论安全性期望，以确保满足用户的需求。 四、后续行动计划 收集用户用例，并进行分析。 继续讨论安全性期望，并制定相应的解决方案。 根据用户需求和安全性期望，选择合适的实现方法。 五、关键术语 FFS：文件系统 MDS：元数据服务器 Rados：Ceph的分布式存储系统 Raiders：Ceph集群 MDS映射：将文件系统映射到特定的MDS 负载均衡：将工作负载分配到多个服务器 多租户：允许多个用户或组织共享同一资源 六、总结 本次会议探讨了在Ceph集群中支持多个FFS文件系统的可能性。会议讨论了两种不同的实现方法，并强调了安全性期望的重要性。后续行动计划包括收集用户用例、讨论安全性期望并选择合适的实现方法。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - RBD: testing overview & strategy","slug":"CDS_G_H_Day_2_-_RBD_-_testing_overview_strategy","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_RBD_-_testing_overview_strategy/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_RBD_-_testing_overview_strategy/","excerpt":"","text":"会议纪要 会议主题： RBD 测试概述及策略 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议内容： 一、会议背景 本次会议主要针对 Ceph RBD（RADOS 块设备）的测试策略进行讨论，旨在提高 RBD 的稳定性和可靠性。会议内容涵盖了测试框架的统一、测试用例的扩展、新特性的测试等方面。 二、主要议题 测试框架的统一： 目前 RBD 的用户空间和内核空间测试使用不同的框架，存在重复测试和测试不全面的问题。 建议使用统一的测试框架，例如借鉴 FSX（文件系统测试工具）的设计，实现内核空间和用户空间测试的统一。 测试用例的扩展： 针对克隆、快照、条带化等特性，需要补充相应的测试用例，确保功能的正确性和稳定性。 针对快照和克隆的特性，需要关注重叠、一致性等问题，并进行针对性的测试。 针对镜像和条带化特性，需要关注性能和兼容性问题，并进行相应的测试。 新特性的测试： 针对位图、镜像复制、日志记录、镜像镜像等新特性，需要制定相应的测试策略，确保功能的正确性和稳定性。 针对镜像复制功能，需要测试故障转移和日志回放的正确性。 针对日志记录功能，可以开发工具模拟客户端重启，验证日志回放的正确性。 测试工具的选择： XFS 测试工具在压力测试方面表现良好，但存在可复现性差的问题。 可以考虑使用其他压力测试工具，例如 XFS 测试工具的 MPI 版本，或者在内核 RBD 上运行 FSX 测试。 三、决定事项 统一测试框架，借鉴 FSX 的设计，实现内核空间和用户空间测试的统一。 扩展测试用例，针对克隆、快照、条带化等特性补充相应的测试用例。 制定新特性的测试策略，确保功能的正确性和稳定性。 选择合适的测试工具，例如 XFS 测试工具的 MPI 版本或其他压力测试工具。 四、后续行动计划 开发统一的测试框架，实现内核空间和用户空间测试的统一。 补充测试用例，针对克隆、快照、条带化等特性进行测试。 制定新特性的测试策略，并实施测试。 选择合适的测试工具，并使用工具进行测试。 五、备注 会议中提到的测试工具和框架，如 FSX、XFS 测试工具等，均为计算机科学/ceph 领域的关键词。 会议中提到的测试策略和行动计划，将有助于提高 RBD 的稳定性和可靠性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - ​RBD: Shared flag, object map","slug":"CDS_G_H_Day_2_-_RBD_-_Shared_flag_object_map","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_RBD_-_Shared_flag_object_map/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_RBD_-_Shared_flag_object_map/","excerpt":"","text":"会议纪要 会议时间： 2023年11月（具体日期未提及） 参会人员： 多名Ceph研发人员 会议主题： 讨论RBD（Rados Block Device）对象索引优化方案，以提高存储性能和效率。 关键议题： 优化RBD性能： 通过创建对象索引，加速RBD操作，例如空间使用情况分析、图像删除、克隆等。 对象索引实现： 使用全局索引记录整个图像的对象存在情况，可能存储为一个单独的对象和RBD头部信息。 使用位图（bitmap）表示对象的存在状态。 根据一致性标志，客户端在打开图像时可以读取头部信息，获取位图并设置一致性标志。 更新位图时，将其保存在内存中，并在关闭图像时保存。 共享写入和克隆： 对于共享写入和克隆，需要考虑多个客户端同时访问图像的情况，并确保位图的正确性和一致性。 使用锁机制来控制对图像的访问，并确保只有一个客户端负责更新位图。 在进行克隆操作时，可以跳过读取父图像，直接从子图像读取。 与现有功能的兼容性： 需要考虑与现有RBD功能的兼容性，例如快照、缩放等。 对于快照，需要在快照创建时更新位图，并确保快照的一致性。 对于旧版本客户端，可能需要提供重建位图的功能。 决定事项： 研发团队将进一步研究位图索引的实现细节，并制定具体的实现方案。 将讨论位图索引与现有RBD功能的集成，并确保兼容性。 考虑为旧版本客户端提供位图重建功能。 后续行动计划： 研发团队进行位图索引实现方案的设计和开发。 与其他团队协作，确保位图索引与现有RBD功能的兼容性。 对旧版本客户端进行测试，确保位图重建功能的可用性。 关键词： RBD 位图（bitmap） 一致性标志 锁机制 共享写入 克隆 快照 缩放 兼容性 重建","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 2) - RGW: bucket index scalability","slug":"CDS_G_H_Day_2_-_RGW_-_bucket_index_scalability","date":"2014-06-25T16:00:00.000Z","updated":"2014-06-25T16:00:00.000Z","comments":true,"path":"2014/06/26/CDS_G_H_Day_2_-_RGW_-_bucket_index_scalability/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/26/CDS_G_H_Day_2_-_RGW_-_bucket_index_scalability/","excerpt":"","text":"会议纪要： 会议主题： Ceph分布式存储系统中的桶索引可扩展性问题讨论 会议时间： 未知 参会人员： Duong（负责桶索引可扩展性的研发人员）、Federer（主持人）、Teddy（负责Ceph集群运维）、Josh、Yahoo（其他研发人员） 会议内容： 一、桶索引可扩展性问题 问题概述： 现有的桶索引实现存在可扩展性问题，主要体现在以下两方面： 单个桶索引对象的处理能力有限，只能支持10-20 RPS的请求量。 随着记录数量的增加，桶索引对象存储的更新操作会占用大量时间，影响系统性能。 解决方案： 方案一： 将桶索引对象进行分片，每个分片对应一个桶索引对象，从而提高处理能力。 方案二： 禁用桶索引功能，适用于不需要桶索引列表功能的场景。 方案三： 在创建桶时允许用户指定分片数量，并存储在桶元数据中。 二、技术细节讨论 分片存储： 将桶索引对象进行分片可以提高处理能力，但会引入新的问题，如分片管理、元数据更新等。 讨论了分片策略、元数据存储、桶索引日志等细节。 无序列表操作： 提出了一种新的无序列表操作，可以减少系统负载，但会牺牲列表的有序性。 讨论了无序列表的实现方式、性能影响等。 三、行动计划 Duong将根据讨论结果修改原型，并提交相应的Pull Request。 其他研发人员将参与审查和改进Pull Request。 讨论未来可能的桶索引自动分片功能。 四、其他事项 讨论了多部分上传的原子性问题，认为目前实现方式是安全的。 讨论了桶索引与桶索引日志的存储方式，认为应该将它们存储在同一个对象中。 五、会议总结 本次会议针对Ceph分布式存储系统中的桶索引可扩展性问题进行了深入讨论，并提出了相应的解决方案。后续将根据讨论结果进行技术实现和改进。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - CI & Teuthology Roadmap","slug":"CDS_G_H_Day_1_-_CI_Teuthology_Roadmap","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_CI_Teuthology_Roadmap/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_CI_Teuthology_Roadmap/","excerpt":"","text":"会议纪要 会议主题： Ceph CI和Tutorials路线图讨论 参会人员： Sage, Zach, Alfredo, L, Greg, Luis等 会议内容： 1. Toothology路线图 Zach介绍了Toothology的最新进展，包括： 将Toothology任务从框架工作中分离出来，以便更好地扩展和维护。 将队列和锁定机制迁移到一个新的服务Paddles，并使用Bito作为UI。 对Toothology内部作业调度方式进行改进。 计划使用OpenStack作为后端来部署虚拟机，以简化Toothology的安装和设置。 讨论了Toothology测试套件对裸金属机器的依赖性，以及如何使用虚拟机进行测试。 讨论了如何使Toothology更具通用性，以便测试其他分布式系统。 2. CI流程改进 讨论了如何改进Ceph的CI流程，以确保所有代码更改在合并到主分支之前都经过充分测试。 提出了使用类似Linux Next的方法，通过建立一个每晚构建的临时分支，并在此分支上运行完整测试套件。 讨论了如何使用Jenkins或Travis CI等工具来实现这一目标，并确保测试结果能够及时反馈给开发者。 讨论了如何处理失败的构建，以及如何将测试结果注释到相关的Pull Request中。 3. 其他讨论 讨论了如何命名集成分支，以及如何管理历史构建。 讨论了是否使用Jenkins或Travis CI作为CI工具，并考虑了各自的优缺点。 讨论了如何改进Jenkins配置，以提高其效率和可维护性。 行动计划： Zach继续推进Toothology的开发工作。 讨论组将制定详细的CI流程改进计划，并选择合适的工具和策略。 相关人员将负责实现CI流程改进计划，并进行测试和验证。 备注： 会议中提到了一些关键的技术术语，如Toothology、Paddles、Bito、OpenStack、Jenkins、Travis CI等。 会议中讨论了一些具体的实现细节，如分支命名、测试结果反馈等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - Calamari Development","slug":"CDS_G_H_Day_1_-_Calamari_Development","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_Calamari_Development/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_Calamari_Development/","excerpt":"","text":"会议纪要 会议主题： Calamari 开发讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： John Gregor, Sage, Patrick等 会议内容： 一、Calamari 开发计划 Crush 管理功能： 高优先级功能，即将加入 Calamari REST API。 目的：支持 Erasure Code 池和 Cache Tiering 等特性。 主要工作： 实现 Crush Map 的 CRUD 操作。 将 OSD 和主机映射到 Crush 节点。 处理 Ceph 配置文件中的 Crush Location 问题。 其他工作： 清理使用 Salt 私有接口的代码。 将 Diamond 和 Graphite 的分支合并到上游。 改进打包方式，简化前端构建过程。 移除 DoSulu 插件管理器。 二、社区合作 Dashing Ceph 和 Sef-Dash： 讨论了将社区项目代码整合到 Calamari 的可能性。 目前 UI 开发资源有限，优先考虑将社区贡献的 UI 设计理念整合到 Calamari。 Ink Scope： 讨论了 Ink Scope 项目与 Calamari 的合作可能性。 鼓励社区成员参与 UI 开发。 三、其他事项 文档聚合： 讨论了将文档聚合到 ceph.com 的可能性。 Ceph 官网： 讨论了 Ceph 官网的重构计划。 行动计划： John Gregor 和 Sage 负责推进 Crush 管理功能的开发。 Sage 负责清理使用 Salt 私有接口的代码。 Sage 负责将 Diamond 和 Graphite 的分支合并到上游。 Sage 负责改进打包方式，简化前端构建过程。 Sage 负责移除 DoSulu 插件管理器。 社区成员参与 UI 开发。 讨论文档聚合和 Ceph 官网的重构计划。 会议总结： 本次会议讨论了 Calamari 的开发计划、社区合作以及其他相关事项。会议明确了下一步的工作计划和行动计划，为 Calamari 的发展奠定了基础。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - CMake Update","slug":"CDS_G_H_Day_1_-_CMake_Update","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_CMake_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_CMake_Update/","excerpt":"","text":"会议纪要 会议主题： Ceph 项目中 CMake 更新及 CI 技术讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Matt Benjamin, Ilya Dryomov, Adam Emerson, Luis, Luke, Dan（可能还有其他未提及的人员） 会议内容： 一、CMake 更新 项目背景： 为了提高构建速度，特别是多核机器上的构建速度，项目组开始将构建系统从 Autoconf/Makefile 转换为 CMake。 进展情况： Ali（实习生）完成了初步的转换工作，但后续人员在不同分支上进行了修改。 第一版 CMake 构建系统与 Autoconf/Makefile 基本一致，但缺少了测试等部分。 项目组通过减少重复构建的对象数量和简化文件结构，提高了构建速度。 目前，CMake 版本已合并到 Firefly 分支，并添加了测试。 下一步计划： 将 CMake 版本合并到 master 分支。 检查是否存在遗漏的目标或其他问题。 确保所有边缘情况都能正常工作，例如库检测、构建脚本等。 移植 CMake 到 Civic Web 等其他子模块。 二、CI 技术讨论 议题： 讨论 CI 技术的选择和优先级。 讨论内容： 评估了 Jenkins、GitLab CI/CD 等不同的 CI 工具。 讨论了 CI 工具的集成、测试覆盖范围、性能等问题。 讨论了不同分支的测试策略。 结论： 项目组对 CMake 的未来持乐观态度。 将 CMake 合并到 master 分支。 继续讨论 CI 技术的选择和实施计划。 三、其他事项 Ilya Dryomov 正在研究构建目标在源树外部的情况。 项目组将继续关注 Civic Web 等其他子模块的 CMake 移植工作。 后续行动计划： Matt Benjamin 将在当天晚些时候推送 CMake 的 master 分支原型。 项目组将检查 CMake 版本中是否存在遗漏的目标或其他问题。 项目组将讨论 CI 技术的选择和实施计划。 备注： 会议中提到了一些计算机科学/ceph 领域的英文关键词，例如：CMake, Autoconf, Makefile, Jenkins, GitLab CI/CD, Civic Web, RocksDB, BlueStore, RBD, CRC, Autoconf, Makefile, Jenkins, GitLab CI/CD 等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - Erasure Coding Update","slug":"CDS_G_H_Day_1_-_Erasure_Coding_Update","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_Erasure_Coding_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_Erasure_Coding_Update/","excerpt":"","text":"会议纪要 会议时间： （未提及具体时间） 会议地点： （未提及具体地点） 参会人员： （未提及具体姓名） Veronica（负责Google Summer of Code项目及相关工作） L（负责Erasure Coding插件优化） Andreas（负责Isa插件原型） 会议主题： Erasure Coding插件优化 初始问题：Erasure Coding的初始代码支持方式较为奇怪，因为没有初始配置文件。 改进计划：提交了一个pending pull request，添加对通用AR配置文件的支持，以便定义针对QA、本地可修复代码或其他参数变体的作业。 插件优化：目前主要关注稳定化插件并进行了基准测试，但尚未对性能不佳的部分进行优化。 ARM处理器性能：讨论了ARM处理器上的性能问题，特别是对于冷存储应用。希望有人能够提供ARM机器进行基准测试。 JF Complete维护和贡献 当前状态：SEF中已同步最新稳定版本。 待解决问题：一个pending pull request（ticket 8071）正在测试中。 本地可修复代码 基准测试：已进行基准测试，但未分析调用图以确定4K和1MB解码之间的差异。 性能问题：存在显著的性能差异，但仍然足够好。 Isa插件原型 实现：Andreas已成功实现了一个插件，该插件在Intel CPU上比Gaser更快。 包装问题：需要确定如何打包该库，因为它可以以静态库或共享库的形式提供。 可靠性模型和代码 当前状态：Veronica正在尝试根据当前模型的假设实现Rados Erasure Code。 基准测试工具：提到了一个用于基准测试Erasure Code的CPU开销的工具。 决定事项： 对Erasure Coding插件进行优化，并关注ARM处理器上的性能。 继续维护和贡献JF Complete。 对本地可修复代码进行基准测试和分析。 将Isa插件原型集成到JF中。 Veronia将继续研究可靠性模型和代码。 后续行动计划： L将继续优化Erasure Coding插件。 Veronica将继续研究可靠性模型和代码。 Andreas将解决Isa插件的包装问题，并尝试将其集成到JF中。 所有参与者将关注ARM处理器上的性能问题。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - Cold Storage Pools","slug":"CDS_G_H_Day_1_-_Cold_Storage_Pools","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_Cold_Storage_Pools/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_Cold_Storage_Pools/","excerpt":"","text":"会议纪要 会议主题： 冷存储池讨论 参会人员： Roger Weeks（HGST），Samuel Saguy，以及其他未具名参与者 会议内容： 背景： 讨论如何实现一个存储池，其中的数据可以被写入且几乎不会进行重平衡或重写，或者重写非常不频繁。 旨在为冷存储提供解决方案，即介于磁带和活跃访问数据之间的存储层。 目标是提高数据访问速度，同时减少数据移动和存储成本。 主要议题： 如何实现数据在写入后几乎不会移动？ 如何平衡数据移动和冗余性？ 如何实现高效的数据访问？ 讨论要点： 冷存储池： 将冷数据存储在一个独立的池中，并使用特定的策略来管理数据移动和冗余性。 PG温映射： 使用PG温映射来限制数据移动，并确保数据在写入后几乎不会移动。 PG强制映射： 为管理员提供一个工具，可以强制将PG映射到特定的位置，从而实现更精细的控制。 Silo架构： 将存储部署为多个独立的池，每个池用于存储特定类型的数据。 缓存层： 使用缓存层来缓冲数据，并减少对冷存储的访问频率。 RAID方法： 使用RAID方法来提高数据冗余性，并实现更静态的数据映射。 决定事项： 探索使用PG温映射和PG强制映射来实现数据几乎不会移动。 考虑使用Silo架构来存储不同类型的数据。 研究使用缓存层来减少对冷存储的访问频率。 考虑使用RAID方法来提高数据冗余性。 后续行动计划： Roger将撰写有关冷存储池的详细文档。 团队将研究不同的实现方案，并选择最适合Ceph的方案。 团队将与其他Ceph社区成员合作，以推动冷存储池的实现。 关键术语： 冷存储 数据移动 冗余性 PG温映射 PG强制映射 Silo架构 缓存层 RAID方法","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - OSD: Locally Repairable Codes","slug":"CDS_G_H_Day_1_-_OSD_-_Locally_Repairable_Codes","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_OSD_-_Locally_Repairable_Codes/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_OSD_-_Locally_Repairable_Codes/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日 参会人员： L（本地可修复代码提案人），Sam，Andrea，其他Ceph研发人员 会议主题： 本地可修复代码（Locally Repairable Codes, LRC）的讨论与方案 会议内容： 1. 本地可修复代码介绍 L介绍了本地可修复代码的概念，即通过编码技术将数据块编码成多个数据块和校验块，使得在数据块丢失时，可以在同一机架内进行修复，避免跨机架的数据传输，节省带宽。 该方案使用现有的Erasure Code插件进行编码和解码，通过组合不同的编码块实现本地修复。 2. 数据块重映射 为了实现本地修复，需要将数据块映射到特定的OSD上。L提出了将数据块映射委托给Erasure Code插件的想法，以便更灵活地控制数据块的存储位置。 提案中包含一个端口请求（port request 1911），用于修改Erasure Code后端，使其能够查询插件以获取数据块的位置。 3. 语法和配置 L提出了在RCode配置文件中添加一个新的键“layers”，用于指定要使用的Erasure Code插件。 此外，还讨论了RSet步骤的配置，以及是否需要将规则集步骤集成到配置中。 4. 解码过程 讨论了在解码过程中如何选择合适的编码层进行修复，以及如何处理不同数量的数据块丢失情况。 提出了使用成本函数来评估不同修复方案的代价，并选择成本最低的方案。 5. 本地修复 讨论了本地修复的实现方式，以及如何避免跨数据中心的数据传输。 认为本地修复的实现相对简单，不需要在Primary节点中进行复杂的操作。 6. 编码算法 讨论了是否可以在不同层使用不同的编码算法，以及如何处理一些特定的编码方案。 7. 其他讨论 讨论了Facebook和Azure等公司提出的本地可修复代码方案，以及如何将这些方案融入到Ceph中。 后续行动计划： L将继续完善本地可修复代码的提案，并与其他研发人员讨论和改进。 Sam和Andrea将协助L进行相关工作。 其他研发人员将根据讨论结果提供反馈和建议。 关键词： 本地可修复代码（LRC），Erasure Code，数据块重映射，RSet步骤，解码，本地修复，编码算法","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - MON: dispatch messages while waiting for IO to complete","slug":"CDS_G_H_Day_1_-_MON_-_dispatch_messages_while_waiting_for_IO_to_complete","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_MON_-_dispatch_messages_while_waiting_for_IO_to_complete/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_MON_-_dispatch_messages_while_waiting_for_IO_to_complete/","excerpt":"","text":"会议纪要 会议时间： [请填写会议时间] 参会人员： [请填写参会人员名单] 会议主题： Ceph Monitor消息派发及I/O操作优化 会议内容： 1. 问题背景 Ceph Monitor在重负载下，执行I/O操作时，处理消息的能力受限，导致等待时间长，影响整体性能。 主要问题在于单线程处理所有消息，当执行I/O操作时，其他消息处理被阻塞。 2. 解决方案 提出为Monitor添加新的Paxos节点，将控制权交给另一个线程，在等待I/O操作完成期间继续执行其他任务。 将I/O操作异步化，避免阻塞消息处理。 考虑使用读写锁机制，保护对状态信息的访问。 3. 实施步骤 首先，将I/O操作异步化，将任务提交给Key-Value存储，并等待回调。 使用现有的Work Queue类创建工作线程，将事务指针传递给工作线程。 在安全的地方异步执行工作，并在完成后进行清理。 使用Work Queue的flush方法，等待异步操作完成。 4. 注意事项 确保异步操作在安全点进行，避免影响其他事件。 保持读写操作分离，确保持久化数据不会阻塞临时数据。 考虑将存储源分为已提交和未提交两部分，提高性能。 5. 后续行动计划 完成异步化I/O操作的代码实现。 测试新方案，评估性能提升效果。 根据测试结果，进一步优化方案。 6. 关键词 Monitor 消息派发 I/O操作 异步化 Paxos 读写锁 Work Queue Key-Value存储 7. 总结 本次会议讨论了Ceph Monitor消息派发及I/O操作优化方案，并制定了后续行动计划。通过异步化I/O操作和读写锁机制，可以有效提高Monitor的处理性能。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) -  Calamari Intro","slug":"CDS_G_H_Day_1_-_Calamari_Intro","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_Calamari_Intro/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_Calamari_Intro/","excerpt":"","text":"会议纪要 会议主题： Calamari 分布式存储介绍及开发讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： John Spray, Gregory Meighan, 以及其他相关人员 会议内容： 1. Calamari 介绍 Calamari 是一个基于 JavaScript 的用户界面，通过 HTTP 与 Calamari 服务器通信。 Calamari 服务器作为前端，负责处理所有运行在其上的功能，包括 Apache、Graphite、Calamari REST 和 Calamari Web。 Lulu 是 Calamari 的业务逻辑组件，负责运行远程操作和检查进度。 SaltStack 用于远程操作和配置管理。 Calamari 与 Ceph 集群的接口通过 VAR 和 Liberate 实现。 2. Calamari 与其他 API 的关系 Calamari 与 Ceph REST API 有重叠，但 Calamari 提供更高级别的视图和功能。 Calamari API 旨在简化与 Ceph 的集成，并提供更易于使用的工具。 3. Calamari 的部署 Calamari 的部署相对复杂，需要处理许多依赖项。 社区正在努力简化 Calamari 的部署，包括打包和测试。 Calamari 的部署需要依赖较新的软件版本，例如 SaltStack。 4. Calamari 用户界面 Calamari 提供一个直观的用户界面，用于监控和管理工作负载。 用户界面包括仪表板、OSD 工作台、主机视图、集群配置、池管理和存储池视图。 Calamari 支持扩展，可以通过编写额外的 Python 服务来实现。 5. Calamari 的扩展 Calamari 使用现有的插件接口，例如 SaltStack 和 Django。 可以通过编写额外的 Python 服务来扩展 Calamari 的功能。 6. 讨论要点 如何简化 Calamari 的部署。 如何提高 Calamari 的安全性，例如通过角色访问控制。 如何扩展 Calamari 的功能。 后续行动计划： 社区将共同努力简化 Calamari 的部署。 Calamari 团队将继续开发新的功能，并提高 Calamari 的安全性。 Calamari 社区将继续讨论和改进 Calamari。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - RBD review","slug":"CDS_G_H_Day_1_-_RBD_review","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_RBD_review/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_RBD_review/","excerpt":"","text":"会议纪要 会议主题： RBD（Rados Block Device）功能回顾与讨论 会议时间： 2023年10月27日 参会人员： Sage, Josh, Sarah, Adam, Greg 等 会议内容： 1. RBD 日志记录与镜像功能讨论 日志记录： RBD 日志记录功能旨在实现异步复制，支持跨数据中心或集群的数据复制。 日志记录会将所有数据操作写入日志文件，并通过 Raft 对象进行条带化存储。 读取日志文件并重新播放到其他集群或池，实现数据的异步复制。 需要解决的问题包括日志文件的存储位置、镜像代理的结构和同步机制等。 镜像代理： 需要设计一个能够协调多个代理之间工作负载的镜像代理。 可以考虑使用一个调度过程来管理需要镜像的图像列表，并为每个图像运行子进程进行镜像。 镜像代理可以在目标集群中运行，以避免网络接口成为瓶颈。 2. RBD 功能讨论 多站点复制： 目前可以使用 RBD 快照和快照镜像实现多站点复制，但实时性较差。 新的异步复制功能可以实现更近实时的多站点复制。 默认缓存： 可以考虑将缓存设置为默认选项，以提高性能。 需要确定合适的默认缓存策略。 对象缓存： 修复了对象缓存中的一些性能问题。 可以考虑改进对象缓存的性能。 RBD df 命令： 可以使用 RBD df 命令查看已分配的空间和实际使用空间。 iSCSI 集成： 目前 iSCSI 集成功能有限，需要改进。 需要提供更完善的文档和工具。 用户空间 passthrough： 可以考虑使用用户空间 passthrough 来利用 RBD 的新特性。 性能监控： 可以改进性能监控功能，以更好地监控 RBD 集群的性能。 客户端识别： 可以改进客户端识别功能，以便更好地跟踪不同客户端的 I/O 模式。 3. RBD 丢弃功能 RBD 丢弃功能已接近完成，但仍有一些问题需要解决。 将进行更多的测试，以确保该功能的可靠性。 4. 其他事项 将讨论 RBD 的格式化、条带化等功能。 后续行动计划： Josh 将负责 RBD 日志记录和镜像功能的设计和实现。 其他开发人员将负责 RBD 其他功能的改进和优化。 将继续进行 RBD 丢弃功能的测试和修复。 将讨论 RBD 的格式化、条带化等功能。 备注： 会议中提到了一些计算机科学/ceph 领域的英文关键词，如 Raft、Raft 对象、条带化、异步复制、多站点复制、快照、缓存、性能监控、客户端识别等。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - OSD: Scrub/SnapTrim IO Prioritization","slug":"CDS_G_H_Day_1_-_OSD_-_Scrub_SnapTrim_IO_Prioritization","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_OSD_-_Scrub_SnapTrim_IO_Prioritization/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_OSD_-_Scrub_SnapTrim_IO_Prioritization/","excerpt":"","text":"会议纪要 会议时间： 下午 会议主题： OSD操作优化讨论，重点为scrub、snap trim和IO优先级调整。 参会人员： Sam（主持人）、其他研发人员 会议内容： 1. scrub snap trim IO优先级讨论 问题： 目前存在一些后台IO密集型任务，需要优先级调整以避免影响客户端IO。 解决方案： 将后台任务分配到独立的线程池，并减少其线程数量。 使用内核的IO优先级机制降低这些线程的优先级。 将scrub、snap trim、backfill等任务封装成工作项，并放入OSD操作队列（OSD oport Q）中。 利用OSD oport Q的令牌桶机制平衡恢复请求与客户端请求。 考虑将所有工作项统一放入操作队列中，包括scrub、snap trim、backfill、replica scrub等。 确定每个工作项的成本和优先级，可能需要通过配置选项进行设置。 2. 操作队列（oper Q）与工作项 操作队列： 操作队列用于处理各种操作请求，包括scrub、snap trim、backfill等。 工作项： 将scrub、snap trim等任务封装成工作项，并放入操作队列中。 优先级： 操作队列根据优先级和成本处理工作项。对于优先级高于63的工作项，使用严格优先级队列；对于优先级低于63的工作项，根据成本进行动态调整。 3. PG移除 PG移除操作可以保留在现有的线程池中，并设置较低的优先级，以避免其被饿死。 4. IO优先级 IO优先级调整可以与操作队列结合使用，以实现更精细的控制。 对于scrub操作，需要在锁的获取和释放之间进行优先级调整。 5. 后续行动计划 完善scrub、snap trim等任务的优先级和成本设置。 考虑将所有工作项统一放入操作队列中。 对PG移除操作进行优先级调整。 会议总结： 本次会议讨论了OSD操作优化的相关议题，提出了改进方案，并制定了后续行动计划。通过优化操作队列和IO优先级，可以提高系统性能和稳定性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - OSD: Scrub & Repair","slug":"CDS_G_H_Day_1_-_OSD_-_Scrub_Repair","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_OSD_-_Scrub_Repair/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_OSD_-_Scrub_Repair/","excerpt":"","text":"会议纪要 会议时间： 2023年11月 (具体日期未提及) 会议地点： 线上会议 参会人员： (未提及具体姓名，以下用“与会者”代替) 会议主题： Ceph 分布式存储系统中的 OSD Scrub 和 Repair 功能讨论 会议内容： 一、主要议题 Scrub 和 Repair 问题： 当前 Scrub 功能存在不一致性时，需要手动分析中央日志，难以识别具体问题。 建议增加接口，让 OSD 在 Scrub PG 时跟踪不一致性，并记录到 LevelDB 中。 不一致性信息与活跃区间逻辑绑定，便于后续处理。 接口设计： 需要定义所有对象不一致的方式，作为基础数据结构。 OSD 遇到不一致对象时，使用该数据结构描述并记录到 LevelDB。 增加一个查询不一致 PG 的接口，以及查询特定对象不一致信息的接口。 增加修复不一致对象的接口，并考虑异步执行。 实现细节： 使用 SnapMapper 等架构设备记录不一致信息。 使用新的 Radius API，需要提供 Epic 序列号，以便比较请求。 增加读取特定副本的接口，以及修复副本的接口。 考虑将修复操作与 Radius 操作分离。 一致性信息结构： 不一致性信息应包含与对象和一致性设计相关的所有信息。 需要避免在结构中遗漏信息，否则无法传播给 Liberators。 Replica 修复： 对于副本，可以使用列表指定用于修复的正确副本。 可以考虑将修复操作与 Radius 操作分离。 自动修复： 可以在 Scrub 命令中使用接口实现自动修复，或设置自动修复策略。 内部 OSD 元数据不一致： 内部 OSD 元数据不一致可以通过修改对象信息来解决。 可以考虑将修复操作与 Radius 操作分离。 二、决定事项 增加接口，让 OSD 在 Scrub PG 时跟踪不一致性，并记录到 LevelDB 中。 定义不一致信息的数据结构，并记录到 LevelDB 中。 增加查询不一致 PG 和对象的接口。 增加修复不一致对象的接口，并考虑异步执行。 考虑将修复操作与 Radius 操作分离。 实现自动修复功能。 考虑将内部 OSD 元数据不一致的修复操作与 Radius 操作分离。 三、后续行动计划 与会者将根据会议讨论结果进行代码实现。 定期进行代码审查和讨论。 完成功能开发后，进行测试和验证。 四、其他事项 会议中讨论了使用 Radius API 或 PGTell 接口的问题，最终决定使用 Radius API。 会议决定将修复操作与 Radius 操作分离，以避免引入过多的复杂性。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - librados review","slug":"CDS_G_H_Day_1_-_librados_review","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_librados_review/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_librados_review/","excerpt":"","text":"会议纪要 会议主题： Ceph 分布式存储项目会议，重点讨论 Liberatos 代码库的审查、开发流程、技术领导角色引入、发布周期以及 OSD 审查。 会议关键细节： 开发流程与参与方式： 通过邮件列表（如 self-dev@ceph.com、calamari-dev@ceph.com、packaging-maintainers@ceph.com）和 IRC（irc.otc.net）参与开发讨论。 使用 GitHub 提交代码和 pull request。 利用 feature tracker 寻找工作机会并报告 bug。 技术领导角色引入：为特定组件指定技术架构负责人，负责代码审查、优先级排序和项目方向。 关键人员： 核心 Rados：Sam Jess Rados 块设备：Josh Durkin Rados Gateway：Yehuda 文件系统：Greg、Jung Yan Calamari：Gregory Amino 测试框架：Zach 部署工具：Deza Chef cookbooks：Gilham Electron 测试基础设施： Get：构建和测试不同发行版和软件包。 Popit：集成测试基础设施的 Web 前端。 发布周期： 过去采用每季度一次的命名版本发布，包含两个月编码和一个月 QA。 最近采用每季度一次的 Firefighter 版本，由于新功能集成挑战，导致时间表延迟。 未来考虑采用定期发布，稳定现有功能，不急于合并新功能。 是否继续每季度一次的命名发布存在争议，需要进一步讨论。 Liberatos 审查： 内部线程模型更改：为提高 IOPS 性能，将全局锁分解为多个更小的锁，使用读写锁和原子操作。 并行读取：通过并行读取副本以减少延迟。 跟踪：捕获和回放 Liberatos 级别的跟踪，以便在开发过程中模拟实际工作负载。 OSD 审查： 会议中未详细讨论，需要进一步了解。 讨论的主要议题： 如何吸引更多开发者参与 Ceph 项目。 引入技术领导角色，明确责任和职责。 确定发布周期，平衡稳定性和新功能。 改进 Liberatos 和 OSD 的性能和功能。 决定的事项： 继续讨论发布周期，并在邮件列表上提出意见。 继续推进 Liberatos 和 OSD 的改进工作。 鼓励更多开发者参与 Ceph 项目。 后续行动计划： 继续讨论发布周期，并在邮件列表上提出意见。 完成 Liberatos 和 OSD 的改进工作。 鼓励更多开发者参与 Ceph 项目，并为他们提供支持。 备注： 会议中提到的一些英文关键词： Ceph Liberatos OSD Rados Calamari GitHub pull request feature tracker CI/CD IOPS latency consistency scrubbing repair blueprint trace replay","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - Wiki IA","slug":"CDS_G_H_Day_1_-_Wiki_IA","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_Wiki_IA/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_Wiki_IA/","excerpt":"","text":"会议纪要 会议时间： 2023年11月某日（具体日期未提及） 会议地点： 线上会议 参会人员： 主持人（疑似Ceph研发人员）、Eric（新用户委员会主席，来自法国西部）、其他与会者 会议主题： 讨论Ceph社区资源整合和Wiki页面建设方案 关键细节： 主持人介绍了Ceph社区资源整合的需求，包括演讲者信息、事件日历、社区贡献者工具、程序指南、硬件兼容性指南、社区周边产品、贡献原因、学术推广、编排和部署工具、提交者名单、路线图、Chum Bucket和Paper Cuts、高价值文档等。 主持人提出了Wiki页面建设的初步方案，并对页面结构进行了讨论。 与会者对Wiki页面建设方案进行了反馈，并提出了一些改进意见。 主持人表示将开始实施Wiki页面建设方案，并呼吁大家积极参与。 讨论的主要议题： Ceph社区资源整合 Wiki页面建设方案 页面结构优化 决定的事项： 开始实施Wiki页面建设方案 呼吁大家积极参与Wiki页面建设 后续行动计划： 主持人将负责Wiki页面建设的主要工作 与会者将根据自身兴趣和能力，参与Wiki页面建设的相关工作 定期召开会议，讨论Wiki页面建设进展情况 关键词： Ceph社区 Wiki页面 资源整合 页面结构 Chum Bucket Paper Cuts 学术推广 编排和部署工具 提交者名单 路线图","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]},{"title":"CDS G/H (Day 1) - RDMA Update","slug":"CDS_G_H_Day_1_-_RDMA_Update","date":"2014-06-23T16:00:00.000Z","updated":"2014-06-24T16:00:00.000Z","comments":true,"path":"2014/06/24/CDS_G_H_Day_1_-_RDMA_Update/","link":"","permalink":"https://sean10.github.io/VideoSummary/2014/06/24/CDS_G_H_Day_1_-_RDMA_Update/","excerpt":"","text":"会议纪要 会议主题： RDMA更新及未来计划讨论 会议时间： 2023年11月（具体日期未提及） 参会人员： Matt, Benjamin, Seth, 以及其他相关研发人员 会议内容： 一、RDMA更新 Firefly升级： Firefly升级正在进行中，目前进展顺利。 Excelio消息接口更改： Excelio更新了内部消息接口，从固定数组16个元素减少到4个，并允许动态分配更大的数组。这可能会影响IO链式操作，需要进一步测试和优化。 性能回归： Firefly升级后，发现存在性能回归问题，已采取措施解决，目前性能已恢复至 Emperor水平，甚至有所提升。 优化： 通过重新组织缓冲区和缓冲区列表，优化了与ATO2的交互，可能对性能有所贡献。 单消息传递器： 讨论了使用单个编译或运行时选择的传递器，而不是多个传递器，以提高效率和可维护性。 通道支持： 讨论了在Excel传递器和传递器中添加通道支持，以实现不同消息流的优先级控制和更高效的连接管理。 地址类型编码： 讨论了更改地址类型编码，以支持更高效的地址存储和混合协议访问。 API迁移： 讨论了将用户从旧API迁移到新API，以简化代码并提高可维护性。 二、后续行动计划 Matt将测试新的IO缓冲区分配策略，并针对可能的问题进行优化。 Matt将继续进行性能测试，确保Firefly升级后的性能符合预期。 Matt将完成单消息传递器的实现，并开始实施Markdown功能。 Seth将完成Excelio分支的整理和测试，并准备合并到主分支。 团队将讨论并确定混合协议访问的需求和实现方案。 三、其他讨论 讨论了多协议访问的需求和实现方案，包括IPv4和IPv6的混合使用。 讨论了传递器创建函数的改进，以支持不同的传输类型。 四、会议总结 本次会议对RDMA的更新和未来计划进行了全面讨论，明确了后续行动计划，并确定了下一步的工作重点。","categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]}],"categories":[{"name":"视频总结","slug":"video-summary","permalink":"https://sean10.github.io/VideoSummary/categories/video-summary/"}],"tags":[]}